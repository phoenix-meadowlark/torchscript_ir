GoogLeNet(
  (conv1): BasicConv2d(
    (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
  (conv2): BasicConv2d(
    (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (conv3): BasicConv2d(
    (conv): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
  )
  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
  (inception3a): Inception(
    (branch1): BasicConv2d(
      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
      (1): BasicConv2d(
        (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception3b): Inception(
    (branch1): BasicConv2d(
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(32, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
      (1): BasicConv2d(
        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (maxpool3): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=True)
  (inception4a): Inception(
    (branch1): BasicConv2d(
      (conv): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(208, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(16, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(16, 48, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
      (1): BasicConv2d(
        (conv): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4b): Inception(
    (branch1): BasicConv2d(
      (conv): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(224, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
      (1): BasicConv2d(
        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4c): Inception(
    (branch1): BasicConv2d(
      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(24, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(24, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
      (1): BasicConv2d(
        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4d): Inception(
    (branch1): BasicConv2d(
      (conv): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(112, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(144, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(288, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
      (1): BasicConv2d(
        (conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception4e): Inception(
    (branch1): BasicConv2d(
      (conv): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
      (1): BasicConv2d(
        (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (maxpool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=True)
  (inception5a): Inception(
    (branch1): BasicConv2d(
      (conv): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(32, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
      (1): BasicConv2d(
        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (inception5b): Inception(
    (branch1): BasicConv2d(
      (conv): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (branch2): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch3): Sequential(
      (0): BasicConv2d(
        (conv): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
      (1): BasicConv2d(
        (conv): Conv2d(48, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (branch4): Sequential(
      (0): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=True)
      (1): BasicConv2d(
        (conv): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (aux1): InceptionAux(
    (conv): BasicConv2d(
      (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc2): Linear(in_features=1024, out_features=1000, bias=True)
  )
  (aux2): InceptionAux(
    (conv): BasicConv2d(
      (conv): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)
    )
    (fc1): Linear(in_features=2048, out_features=1024, bias=True)
    (fc2): Linear(in_features=1024, out_features=1000, bias=True)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (dropout): Dropout(p=0.2, inplace=False)
  (fc): Linear(in_features=1024, out_features=1000, bias=True)
)

GoogLeNet.aux1
GoogLeNet.aux2
InceptionAux.forward
  graph(%self : __torch__.torchvision.models.googlenet.InceptionAux,
        %x.1 : Tensor):
    %25 : Function = prim::Constant[name="dropout"]()
    %24 : bool = prim::Constant[value=0]()
    %19 : Function = prim::Constant[name="relu"]()
    %18 : bool = prim::Constant[value=1]() # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:274:40
    %13 : int = prim::Constant[value=-1]()
    %6 : Function = prim::Constant[name="adaptive_avg_pool2d"]()
    %3 : int = prim::Constant[value=4]() # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:268:38
    %12 : int = prim::Constant[value=1]() # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:272:29
    %22 : float = prim::Constant[value=0.69999999999999996]() # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:276:25
    %5 : int[] = prim::ListConstruct(%3, %3)
    %x.3 : Tensor = prim::CallFunction(%6, %x.1, %5) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:268:12
    %8 : __torch__.torchvision.models.googlenet.BasicConv2d = prim::GetAttr[name="conv"](%self)
    %x.5 : Tensor = prim::CallMethod[name="forward"](%8, %x.3) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:270:12
    %x.7 : Tensor = aten::flatten(%x.5, %12, %13) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:272:12
    %15 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="fc1"](%self)
    %17 : Tensor = prim::CallMethod[name="forward"](%15, %x.7) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:274:19
    %x.9 : Tensor = prim::CallFunction(%19, %17, %18) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:274:12
    %23 : bool = prim::GetAttr[name="training"](%self)
    %x.11 : Tensor = prim::CallFunction(%25, %x.9, %22, %23, %24) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:276:12
    %27 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="fc2"](%self)
    %x.13 : Tensor = prim::CallMethod[name="forward"](%27, %x.11) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:278:12
    return (%x.13)

GoogLeNet.avgpool
AdaptiveAvgPool2d.forward
  graph(%self : __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d,
        %input.1 : Tensor):
    %7 : Function = prim::Constant[name="adaptive_avg_pool2d"]()
    %3 : int = prim::Constant[value=1]() # torch/nn/modules/pooling.py:1111:44
    %6 : int[] = prim::ListConstruct(%3, %3)
    %8 : Tensor = prim::CallFunction(%7, %input.1, %6) # torch/nn/modules/pooling.py:1111:15
    return (%8)

GoogLeNet.conv1
GoogLeNet.conv2
GoogLeNet.conv3
BasicConv2d.forward
Inception.branch1
InceptionAux.conv
  graph(%self : __torch__.torchvision.models.googlenet.BasicConv2d,
        %x.1 : Tensor):
    %10 : Function = prim::Constant[name="relu"]()
    %9 : bool = prim::Constant[value=1]() # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:294:33
    %2 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="conv"](%self)
    %x.3 : Tensor = prim::CallMethod[name="forward"](%2, %x.1) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:292:12
    %5 : __torch__.torch.nn.modules.batchnorm.BatchNorm2d = prim::GetAttr[name="bn"](%self)
    %x.5 : Tensor = prim::CallMethod[name="forward"](%5, %x.3) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:293:12
    %11 : Tensor = prim::CallFunction(%10, %x.5, %9) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:294:15
    return (%11)

GoogLeNet.dropout
Dropout.forward
  graph(%self : __torch__.torch.nn.modules.dropout.Dropout,
        %input.1 : Tensor):
    %6 : Function = prim::Constant[name="dropout"]()
    %5 : bool = prim::Constant[value=0]() # torch/nn/modules/dropout.py:58:55
    %3 : float = prim::Constant[value=0.20000000000000001]() # torch/nn/modules/dropout.py:58:32
    %4 : bool = prim::GetAttr[name="training"](%self)
    %7 : Tensor = prim::CallFunction(%6, %input.1, %3, %4, %5) # torch/nn/modules/dropout.py:58:15
    return (%7)

GoogLeNet.fc
InceptionAux.fc1
InceptionAux.fc2
Linear.forward
  graph(%self : __torch__.torch.nn.modules.linear.Linear,
        %input.1 : Tensor):
    %5 : Function = prim::Constant[name="linear"]()
    %3 : Tensor = prim::GetAttr[name="weight"](%self)
    %4 : Tensor = prim::GetAttr[name="bias"](%self)
    %6 : Tensor = prim::CallFunction(%5, %input.1, %3, %4) # torch/nn/modules/linear.py:91:15
    return (%6)

GoogLeNet.forward
  graph(%self : __torch__.torchvision.models.googlenet.GoogLeNet,
        %x.1 : Tensor):
    %17 : int = prim::Constant[value=2]()
    %16 : str = prim::Constant[value="Scripted GoogleNet always returns GoogleNetOutputs Tuple"]() # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:209:30
    %11 : bool = prim::Constant[value=0]() # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:206:22
    %10 : bool = prim::Constant[value=1]() # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:206:40
    %x.3 : Tensor = prim::CallMethod[name="_transform_input"](%self, %x.1) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:204:12
    %5 : (Tensor, Tensor?, Tensor?) = prim::CallMethod[name="_forward"](%self, %x.3) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:205:24
    %x.5 : Tensor, %aux1.1 : Tensor?, %aux2.1 : Tensor? = prim::TupleUnpack(%5)
    %9 : bool = prim::GetAttr[name="training"](%self)
    %aux_defined.1 : bool = prim::If(%9) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:206:22
      block0():
        -> (%10)
      block1():
        -> (%11)
    %15 : bool = aten::__not__(%aux_defined.1) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:208:15
     = prim::If(%15) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:208:12
      block0():
         = aten::warn(%16, %17) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:209:16
        -> ()
      block1():
        -> ()
    %22 : NamedTuple(logits : Tensor, aux_logits2 : Tensor?, aux_logits1 : Tensor?) = prim::TupleConstruct(%x.5, %aux2.1, %aux1.1) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:210:19
    return (%22)

GoogLeNet.inception3a
GoogLeNet.inception3b
GoogLeNet.inception4a
GoogLeNet.inception4b
GoogLeNet.inception4c
GoogLeNet.inception4d
GoogLeNet.inception4e
GoogLeNet.inception5a
GoogLeNet.inception5b
Inception.forward
  graph(%self : __torch__.torchvision.models.googlenet.Inception,
        %x.1 : Tensor):
    %5 : int = prim::Constant[value=1]() # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:252:34
    %outputs.1 : Tensor[] = prim::CallMethod[name="_forward"](%self, %x.1) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:251:18
    %6 : Tensor = aten::cat(%outputs.1, %5) # torch/hub/pytorch_vision_master/torchvision/models/googlenet.py:252:15
    return (%6)

GoogLeNet.maxpool1
GoogLeNet.maxpool2
GoogLeNet.maxpool3
MaxPool2d.forward
  graph(%self : __torch__.torch.nn.modules.pooling.MaxPool2d,
        %input.1 : Tensor):
    %13 : Function = prim::Constant[name="_max_pool2d"]()
    %8 : bool = prim::Constant[value=0]() # torch/nn/modules/pooling.py:159:28
    %7 : bool = prim::Constant[value=1]() # torch/nn/modules/pooling.py:158:57
    %6 : int = prim::Constant[value=1]() # torch/nn/modules/pooling.py:158:42
    %5 : int = prim::Constant[value=0]() # torch/nn/modules/pooling.py:158:28
    %4 : int = prim::Constant[value=2]() # torch/nn/modules/pooling.py:157:53
    %3 : int = prim::Constant[value=3]() # torch/nn/modules/pooling.py:157:35
    %9 : int[] = prim::ListConstruct(%3, %3)
    %10 : int[] = prim::ListConstruct(%4, %4)
    %11 : int[] = prim::ListConstruct(%5, %5)
    %12 : int[] = prim::ListConstruct(%6, %6)
    %14 : Tensor = prim::CallFunction(%13, %input.1, %9, %10, %11, %12, %7, %8) # torch/nn/modules/pooling.py:157:15
    return (%14)

GoogLeNet.maxpool4
MaxPool2d.forward
  graph(%self : __torch__.torch.nn.modules.pooling.MaxPool2d,
        %input.1 : Tensor):
    %13 : Function = prim::Constant[name="_max_pool2d"]()
    %8 : bool = prim::Constant[value=0]() # torch/nn/modules/pooling.py:159:28
    %7 : bool = prim::Constant[value=1]() # torch/nn/modules/pooling.py:158:57
    %6 : int = prim::Constant[value=1]() # torch/nn/modules/pooling.py:158:42
    %5 : int = prim::Constant[value=0]() # torch/nn/modules/pooling.py:158:28
    %3 : int = prim::Constant[value=2]() # torch/nn/modules/pooling.py:157:35
    %9 : int[] = prim::ListConstruct(%3, %3)
    %10 : int[] = prim::ListConstruct(%3, %3)
    %11 : int[] = prim::ListConstruct(%5, %5)
    %12 : int[] = prim::ListConstruct(%6, %6)
    %14 : Tensor = prim::CallFunction(%13, %input.1, %9, %10, %11, %12, %7, %8) # torch/nn/modules/pooling.py:157:15
    return (%14)

BasicConv2d.bn
BatchNorm2d.forward
  graph(%self : __torch__.torch.nn.modules.batchnorm.BatchNorm2d,
        %input.1 : Tensor):
    %65 : Function = prim::Constant[name="batch_norm"]()
    %64 : float = prim::Constant[value=0.001]() # torch/nn/modules/batchnorm.py:136:77
    %32 : bool = prim::Constant[value=0]() # torch/nn/modules/batchnorm.py:125:27
    %bn_training.1 : bool = prim::Constant[value=1]() # torch/nn/modules/batchnorm.py:123:26
    %exponential_average_factor.1 : float = prim::Constant[value=0.10000000000000001]() # torch/nn/modules/batchnorm.py:108:41
    %16 : int = prim::Constant[value=1]() # torch/nn/modules/batchnorm.py:113:70
    %3 : None = prim::CallMethod[name="_check_input_dim"](%self, %input.1) # torch/nn/modules/batchnorm.py:100:8
    %8 : bool = prim::GetAttr[name="training"](%self)
     = prim::If(%8) # torch/nn/modules/batchnorm.py:110:11
      block0():
        %85 : Tensor = prim::GetAttr[name="num_batches_tracked"](%self)
        %87 : Tensor = aten::add(%85, %16, %16) # torch/nn/modules/batchnorm.py:113:43
         = prim::SetAttr[name="num_batches_tracked"](%self, %87)
        -> ()
      block1():
        -> ()
    %28 : bool = prim::GetAttr[name="training"](%self)
    %bn_training : bool = prim::If(%28) # torch/nn/modules/batchnorm.py:122:8
      block0():
        -> (%bn_training.1)
      block1():
        -> (%32)
    %49 : Tensor = prim::GetAttr[name="running_mean"](%self)
    %57 : Tensor = prim::GetAttr[name="running_var"](%self)
    %60 : Tensor = prim::GetAttr[name="weight"](%self)
    %61 : Tensor = prim::GetAttr[name="bias"](%self)
    %66 : Tensor = prim::CallFunction(%65, %input.1, %49, %57, %60, %61, %bn_training, %exponential_average_factor.1, %64) # torch/nn/modules/batchnorm.py:131:15
    return (%66)

BasicConv2d.conv
Conv2d.forward
  graph(%self : __torch__.torch.nn.modules.conv.Conv2d,
        %input.1 : Tensor):
    %3 : Tensor = prim::GetAttr[name="weight"](%self)
    %4 : Tensor = prim::CallMethod[name="_conv_forward"](%self, %input.1, %3) # torch/nn/modules/conv.py:419:15
    return (%4)

Inception.branch2
Inception.branch3
Sequential.forward
  graph(%self : __torch__.torch.nn.modules.container.Sequential,
        %input.1 : Tensor):
    %3 : __torch__.torchvision.models.googlenet.BasicConv2d = prim::GetAttr[name="0"](%self)
    %5 : __torch__.torchvision.models.googlenet.BasicConv2d = prim::GetAttr[name="1"](%self)
    %input.3 : Tensor = prim::CallMethod[name="forward"](%3, %input.1) # torch/nn/modules/container.py:117:20
    %input.5 : Tensor = prim::CallMethod[name="forward"](%5, %input.3) # torch/nn/modules/container.py:117:20
    return (%input.5)

Inception.branch4
Sequential.forward
  graph(%self : __torch__.torch.nn.modules.container.Sequential,
        %input.1 : Tensor):
    %3 : __torch__.torch.nn.modules.pooling.MaxPool2d = prim::GetAttr[name="0"](%self)
    %5 : __torch__.torchvision.models.googlenet.BasicConv2d = prim::GetAttr[name="1"](%self)
    %input.3 : Tensor = prim::CallMethod[name="forward"](%3, %input.1) # torch/nn/modules/container.py:117:20
    %input.5 : Tensor = prim::CallMethod[name="forward"](%5, %input.3) # torch/nn/modules/container.py:117:20
    return (%input.5)

MaxPool2d.forward
  graph(%self : __torch__.torch.nn.modules.pooling.MaxPool2d,
        %input.1 : Tensor):
    %13 : Function = prim::Constant[name="_max_pool2d"]()
    %8 : bool = prim::Constant[value=0]() # torch/nn/modules/pooling.py:159:28
    %7 : bool = prim::Constant[value=1]() # torch/nn/modules/pooling.py:158:57
    %4 : int = prim::Constant[value=1]() # torch/nn/modules/pooling.py:157:53
    %3 : int = prim::Constant[value=3]() # torch/nn/modules/pooling.py:157:35
    %9 : int[] = prim::ListConstruct(%3, %3)
    %10 : int[] = prim::ListConstruct(%4, %4)
    %11 : int[] = prim::ListConstruct(%4, %4)
    %12 : int[] = prim::ListConstruct(%4, %4)
    %14 : Tensor = prim::CallFunction(%13, %input.1, %9, %10, %11, %12, %7, %8) # torch/nn/modules/pooling.py:157:15
    return (%14)

