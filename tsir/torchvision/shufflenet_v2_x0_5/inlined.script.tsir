graph(%self : __torch__.torchvision.models.shufflenetv2.ShuffleNetV2,
      %x.1 : Tensor):
  %3 : int = prim::Constant[value=96]() # torch/nn/modules/conv.py:414:53
  %4 : int = prim::Constant[value=48]() # torch/nn/modules/conv.py:414:53
  %5 : int = prim::Constant[value=-1]() # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:26
  %6 : int = prim::Constant[value=24]() # torch/nn/modules/conv.py:414:53
  %7 : int = prim::Constant[value=1]() # torch/nn/modules/conv.py:414:38
  %8 : bool = prim::Constant[value=1]() # torch/nn/functional.py:2016:33
  %9 : int = prim::Constant[value=0]() # torch/nn/functional.py:1991:22
  %10 : str = prim::Constant[value="Exception"]() # torch/nn/modules/batchnorm.py:277:12
  %11 : int = prim::Constant[value=4]() # torch/nn/modules/batchnorm.py:276:26
  %exponential_average_factor.2 : float = prim::Constant[value=0.10000000000000001]() # torch/nn/modules/batchnorm.py:108:41
  %13 : float = prim::Constant[value=1.0000000000000001e-05]() # torch/nn/modules/batchnorm.py:136:77
  %14 : int = prim::Constant[value=3]() # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:133:23
  %15 : int = prim::Constant[value=2]() # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:133:20
  %16 : bool = prim::Constant[value=0]()
  %17 : None = prim::Constant()
  %18 : __torch__.torch.nn.modules.container.___torch_mangle_1022.Sequential = prim::GetAttr[name="conv1"](%self)
  %19 : __torch__.torch.nn.modules.conv.___torch_mangle_698.Conv2d = prim::GetAttr[name="0"](%18)
  %20 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%18)
  %21 : Tensor = prim::GetAttr[name="weight"](%19)
  %22 : Tensor? = prim::GetAttr[name="bias"](%19)
  %23 : int[] = prim::ListConstruct(%15, %15)
  %24 : int[] = prim::ListConstruct(%7, %7)
  %25 : int[] = prim::ListConstruct(%7, %7)
  %input.185 : Tensor = aten::conv2d(%x.1, %21, %22, %23, %24, %25, %7) # torch/nn/modules/conv.py:415:15
  %27 : int = aten::dim(%input.185) # torch/nn/modules/batchnorm.py:276:11
  %28 : bool = aten::ne(%27, %11) # torch/nn/modules/batchnorm.py:276:11
   = prim::If(%28) # torch/nn/modules/batchnorm.py:276:8
    block0():
       = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
      -> ()
    block1():
      -> ()
  %29 : bool = prim::GetAttr[name="training"](%20)
   = prim::If(%29) # torch/nn/modules/batchnorm.py:110:11
    block0():
      %30 : Tensor = prim::GetAttr[name="num_batches_tracked"](%20)
      %31 : Tensor = aten::add(%30, %7, %7) # torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%20, %31)
      -> ()
    block1():
      -> ()
  %32 : bool = prim::GetAttr[name="training"](%20)
  %33 : Tensor = prim::GetAttr[name="running_mean"](%20)
  %34 : Tensor = prim::GetAttr[name="running_var"](%20)
  %35 : Tensor = prim::GetAttr[name="weight"](%20)
  %36 : Tensor = prim::GetAttr[name="bias"](%20)
   = prim::If(%32) # torch/nn/functional.py:2011:4
    block0():
      %37 : int[] = aten::size(%input.185) # torch/nn/functional.py:2012:27
      %size_prods.272 : int = aten::__getitem__(%37, %9) # torch/nn/functional.py:1991:17
      %39 : int = aten::len(%37) # torch/nn/functional.py:1992:19
      %40 : int = aten::sub(%39, %15) # torch/nn/functional.py:1992:19
      %size_prods.273 : int = prim::Loop(%40, %8, %size_prods.272) # torch/nn/functional.py:1992:4
        block0(%i.69 : int, %size_prods.274 : int):
          %44 : int = aten::add(%i.69, %15) # torch/nn/functional.py:1993:27
          %45 : int = aten::__getitem__(%37, %44) # torch/nn/functional.py:1993:22
          %size_prods.275 : int = aten::mul(%size_prods.274, %45) # torch/nn/functional.py:1993:8
          -> (%8, %size_prods.275)
      %47 : bool = aten::eq(%size_prods.273, %7) # torch/nn/functional.py:1994:7
       = prim::If(%47) # torch/nn/functional.py:1994:4
        block0():
           = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.184 : Tensor = aten::batch_norm(%input.185, %35, %36, %33, %34, %32, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
  %x.3 : Tensor = aten::relu_(%input.184) # torch/nn/functional.py:1117:17
  %50 : int[] = prim::ListConstruct(%14, %14)
  %51 : int[] = prim::ListConstruct(%15, %15)
  %52 : int[] = prim::ListConstruct(%7, %7)
  %53 : int[] = prim::ListConstruct(%7, %7)
  %x.31 : Tensor = aten::max_pool2d(%x.3, %50, %51, %52, %53, %16) # torch/nn/functional.py:575:11
  %55 : __torch__.torch.nn.modules.container.___torch_mangle_1029.Sequential = prim::GetAttr[name="stage2"](%self)
  %56 : __torch__.torchvision.models.shufflenetv2.InvertedResidual = prim::GetAttr[name="0"](%55)
  %57 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1028.InvertedResidual = prim::GetAttr[name="1"](%55)
  %58 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1028.InvertedResidual = prim::GetAttr[name="2"](%55)
  %59 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1028.InvertedResidual = prim::GetAttr[name="3"](%55)
  %60 : int = prim::GetAttr[name="stride"](%56)
  %61 : bool = aten::eq(%60, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.8 : Tensor = prim::If(%61) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %63 : Tensor[] = aten::chunk(%x.31, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.11 : Tensor, %x2.11 : Tensor = prim::ListUnpack(%63)
      %66 : __torch__.torch.nn.modules.container.___torch_mangle_1025.Sequential = prim::GetAttr[name="branch2"](%56)
      %67 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="0"](%66)
      %68 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%66)
      %69 : __torch__.torch.nn.modules.conv.___torch_mangle_629.Conv2d = prim::GetAttr[name="3"](%66)
      %70 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="4"](%66)
      %71 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="5"](%66)
      %72 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="6"](%66)
      %73 : Tensor = prim::GetAttr[name="weight"](%67)
      %74 : Tensor? = prim::GetAttr[name="bias"](%67)
      %75 : int[] = prim::ListConstruct(%7, %7)
      %76 : int[] = prim::ListConstruct(%9, %9)
      %77 : int[] = prim::ListConstruct(%7, %7)
      %input.166 : Tensor = aten::conv2d(%x2.11, %73, %74, %75, %76, %77, %7) # torch/nn/modules/conv.py:415:15
      %79 : int = aten::dim(%input.166) # torch/nn/modules/batchnorm.py:276:11
      %80 : bool = aten::ne(%79, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%80) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %81 : bool = prim::GetAttr[name="training"](%68)
       = prim::If(%81) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %82 : Tensor = prim::GetAttr[name="num_batches_tracked"](%68)
          %83 : Tensor = aten::add(%82, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%68, %83)
          -> ()
        block1():
          -> ()
      %84 : bool = prim::GetAttr[name="training"](%68)
      %85 : Tensor = prim::GetAttr[name="running_mean"](%68)
      %86 : Tensor = prim::GetAttr[name="running_var"](%68)
      %87 : Tensor = prim::GetAttr[name="weight"](%68)
      %88 : Tensor = prim::GetAttr[name="bias"](%68)
       = prim::If(%84) # torch/nn/functional.py:2011:4
        block0():
          %89 : int[] = aten::size(%input.166) # torch/nn/functional.py:2012:27
          %size_prods.276 : int = aten::__getitem__(%89, %9) # torch/nn/functional.py:1991:17
          %91 : int = aten::len(%89) # torch/nn/functional.py:1992:19
          %92 : int = aten::sub(%91, %15) # torch/nn/functional.py:1992:19
          %size_prods.277 : int = prim::Loop(%92, %8, %size_prods.276) # torch/nn/functional.py:1992:4
            block0(%i.70 : int, %size_prods.278 : int):
              %96 : int = aten::add(%i.70, %15) # torch/nn/functional.py:1993:27
              %97 : int = aten::__getitem__(%89, %96) # torch/nn/functional.py:1993:22
              %size_prods.279 : int = aten::mul(%size_prods.278, %97) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.279)
          %99 : bool = aten::eq(%size_prods.277, %7) # torch/nn/functional.py:1994:7
           = prim::If(%99) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.183 : Tensor = aten::batch_norm(%input.166, %87, %88, %85, %86, %84, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.200 : Tensor = aten::relu_(%input.183) # torch/nn/functional.py:1117:17
      %102 : Tensor = prim::GetAttr[name="weight"](%69)
      %103 : Tensor? = prim::GetAttr[name="bias"](%69)
      %104 : int[] = prim::ListConstruct(%15, %15)
      %105 : int[] = prim::ListConstruct(%7, %7)
      %106 : int[] = prim::ListConstruct(%7, %7)
      %input.217 : Tensor = aten::conv2d(%input.200, %102, %103, %104, %105, %106, %6) # torch/nn/modules/conv.py:415:15
      %108 : int = aten::dim(%input.217) # torch/nn/modules/batchnorm.py:276:11
      %109 : bool = aten::ne(%108, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%109) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %110 : bool = prim::GetAttr[name="training"](%70)
       = prim::If(%110) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %111 : Tensor = prim::GetAttr[name="num_batches_tracked"](%70)
          %112 : Tensor = aten::add(%111, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%70, %112)
          -> ()
        block1():
          -> ()
      %113 : bool = prim::GetAttr[name="training"](%70)
      %114 : Tensor = prim::GetAttr[name="running_mean"](%70)
      %115 : Tensor = prim::GetAttr[name="running_var"](%70)
      %116 : Tensor = prim::GetAttr[name="weight"](%70)
      %117 : Tensor = prim::GetAttr[name="bias"](%70)
       = prim::If(%113) # torch/nn/functional.py:2011:4
        block0():
          %118 : int[] = aten::size(%input.217) # torch/nn/functional.py:2012:27
          %size_prods.280 : int = aten::__getitem__(%118, %9) # torch/nn/functional.py:1991:17
          %120 : int = aten::len(%118) # torch/nn/functional.py:1992:19
          %121 : int = aten::sub(%120, %15) # torch/nn/functional.py:1992:19
          %size_prods.281 : int = prim::Loop(%121, %8, %size_prods.280) # torch/nn/functional.py:1992:4
            block0(%i.71 : int, %size_prods.282 : int):
              %125 : int = aten::add(%i.71, %15) # torch/nn/functional.py:1993:27
              %126 : int = aten::__getitem__(%118, %125) # torch/nn/functional.py:1993:22
              %size_prods.283 : int = aten::mul(%size_prods.282, %126) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.283)
          %128 : bool = aten::eq(%size_prods.281, %7) # torch/nn/functional.py:1994:7
           = prim::If(%128) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.186 : Tensor = aten::batch_norm(%input.217, %116, %117, %114, %115, %113, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %130 : Tensor = prim::GetAttr[name="weight"](%71)
      %131 : Tensor? = prim::GetAttr[name="bias"](%71)
      %132 : int[] = prim::ListConstruct(%7, %7)
      %133 : int[] = prim::ListConstruct(%9, %9)
      %134 : int[] = prim::ListConstruct(%7, %7)
      %input.149 : Tensor = aten::conv2d(%input.186, %130, %131, %132, %133, %134, %7) # torch/nn/modules/conv.py:415:15
      %136 : int = aten::dim(%input.149) # torch/nn/modules/batchnorm.py:276:11
      %137 : bool = aten::ne(%136, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%137) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %138 : bool = prim::GetAttr[name="training"](%72)
       = prim::If(%138) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %139 : Tensor = prim::GetAttr[name="num_batches_tracked"](%72)
          %140 : Tensor = aten::add(%139, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%72, %140)
          -> ()
        block1():
          -> ()
      %141 : bool = prim::GetAttr[name="training"](%72)
      %142 : Tensor = prim::GetAttr[name="running_mean"](%72)
      %143 : Tensor = prim::GetAttr[name="running_var"](%72)
      %144 : Tensor = prim::GetAttr[name="weight"](%72)
      %145 : Tensor = prim::GetAttr[name="bias"](%72)
       = prim::If(%141) # torch/nn/functional.py:2011:4
        block0():
          %146 : int[] = aten::size(%input.149) # torch/nn/functional.py:2012:27
          %size_prods.200 : int = aten::__getitem__(%146, %9) # torch/nn/functional.py:1991:17
          %148 : int = aten::len(%146) # torch/nn/functional.py:1992:19
          %149 : int = aten::sub(%148, %15) # torch/nn/functional.py:1992:19
          %size_prods.201 : int = prim::Loop(%149, %8, %size_prods.200) # torch/nn/functional.py:1992:4
            block0(%i.51 : int, %size_prods.202 : int):
              %153 : int = aten::add(%i.51, %15) # torch/nn/functional.py:1993:27
              %154 : int = aten::__getitem__(%146, %153) # torch/nn/functional.py:1993:22
              %size_prods.203 : int = aten::mul(%size_prods.202, %154) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.203)
          %156 : bool = aten::eq(%size_prods.201, %7) # torch/nn/functional.py:1994:7
           = prim::If(%156) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.192 : Tensor = aten::batch_norm(%input.149, %144, %145, %142, %143, %141, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.193 : Tensor = aten::relu_(%input.192) # torch/nn/functional.py:1117:17
      %159 : Tensor[] = prim::ListConstruct(%x1.11, %input.193)
      %out.31 : Tensor = aten::cat(%159, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.31)
    block1():
      %161 : __torch__.torch.nn.modules.container.___torch_mangle_1024.Sequential = prim::GetAttr[name="branch1"](%56)
      %162 : __torch__.torch.nn.modules.conv.___torch_mangle_629.Conv2d = prim::GetAttr[name="0"](%161)
      %163 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%161)
      %164 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="2"](%161)
      %165 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="3"](%161)
      %166 : Tensor = prim::GetAttr[name="weight"](%162)
      %167 : Tensor? = prim::GetAttr[name="bias"](%162)
      %168 : int[] = prim::ListConstruct(%15, %15)
      %169 : int[] = prim::ListConstruct(%7, %7)
      %170 : int[] = prim::ListConstruct(%7, %7)
      %input.187 : Tensor = aten::conv2d(%x.31, %166, %167, %168, %169, %170, %6) # torch/nn/modules/conv.py:415:15
      %172 : int = aten::dim(%input.187) # torch/nn/modules/batchnorm.py:276:11
      %173 : bool = aten::ne(%172, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%173) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %174 : bool = prim::GetAttr[name="training"](%163)
       = prim::If(%174) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %175 : Tensor = prim::GetAttr[name="num_batches_tracked"](%163)
          %176 : Tensor = aten::add(%175, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%163, %176)
          -> ()
        block1():
          -> ()
      %177 : bool = prim::GetAttr[name="training"](%163)
      %178 : Tensor = prim::GetAttr[name="running_mean"](%163)
      %179 : Tensor = prim::GetAttr[name="running_var"](%163)
      %180 : Tensor = prim::GetAttr[name="weight"](%163)
      %181 : Tensor = prim::GetAttr[name="bias"](%163)
       = prim::If(%177) # torch/nn/functional.py:2011:4
        block0():
          %182 : int[] = aten::size(%input.187) # torch/nn/functional.py:2012:27
          %size_prods.204 : int = aten::__getitem__(%182, %9) # torch/nn/functional.py:1991:17
          %184 : int = aten::len(%182) # torch/nn/functional.py:1992:19
          %185 : int = aten::sub(%184, %15) # torch/nn/functional.py:1992:19
          %size_prods.205 : int = prim::Loop(%185, %8, %size_prods.204) # torch/nn/functional.py:1992:4
            block0(%i.52 : int, %size_prods.206 : int):
              %189 : int = aten::add(%i.52, %15) # torch/nn/functional.py:1993:27
              %190 : int = aten::__getitem__(%182, %189) # torch/nn/functional.py:1993:22
              %size_prods.207 : int = aten::mul(%size_prods.206, %190) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.207)
          %192 : bool = aten::eq(%size_prods.205, %7) # torch/nn/functional.py:1994:7
           = prim::If(%192) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.189 : Tensor = aten::batch_norm(%input.187, %180, %181, %178, %179, %177, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %194 : Tensor = prim::GetAttr[name="weight"](%164)
      %195 : Tensor? = prim::GetAttr[name="bias"](%164)
      %196 : int[] = prim::ListConstruct(%7, %7)
      %197 : int[] = prim::ListConstruct(%9, %9)
      %198 : int[] = prim::ListConstruct(%7, %7)
      %input.190 : Tensor = aten::conv2d(%input.189, %194, %195, %196, %197, %198, %7) # torch/nn/modules/conv.py:415:15
      %200 : int = aten::dim(%input.190) # torch/nn/modules/batchnorm.py:276:11
      %201 : bool = aten::ne(%200, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%201) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %202 : bool = prim::GetAttr[name="training"](%165)
       = prim::If(%202) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %203 : Tensor = prim::GetAttr[name="num_batches_tracked"](%165)
          %204 : Tensor = aten::add(%203, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%165, %204)
          -> ()
        block1():
          -> ()
      %205 : bool = prim::GetAttr[name="training"](%165)
      %206 : Tensor = prim::GetAttr[name="running_mean"](%165)
      %207 : Tensor = prim::GetAttr[name="running_var"](%165)
      %208 : Tensor = prim::GetAttr[name="weight"](%165)
      %209 : Tensor = prim::GetAttr[name="bias"](%165)
       = prim::If(%205) # torch/nn/functional.py:2011:4
        block0():
          %210 : int[] = aten::size(%input.190) # torch/nn/functional.py:2012:27
          %size_prods.208 : int = aten::__getitem__(%210, %9) # torch/nn/functional.py:1991:17
          %212 : int = aten::len(%210) # torch/nn/functional.py:1992:19
          %213 : int = aten::sub(%212, %15) # torch/nn/functional.py:1992:19
          %size_prods.209 : int = prim::Loop(%213, %8, %size_prods.208) # torch/nn/functional.py:1992:4
            block0(%i.53 : int, %size_prods.210 : int):
              %217 : int = aten::add(%i.53, %15) # torch/nn/functional.py:1993:27
              %218 : int = aten::__getitem__(%210, %217) # torch/nn/functional.py:1993:22
              %size_prods.211 : int = aten::mul(%size_prods.210, %218) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.211)
          %220 : bool = aten::eq(%size_prods.209, %7) # torch/nn/functional.py:1994:7
           = prim::If(%220) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.197 : Tensor = aten::batch_norm(%input.190, %208, %209, %206, %207, %205, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.198 : Tensor = aten::relu_(%input.197) # torch/nn/functional.py:1117:17
      %223 : __torch__.torch.nn.modules.container.___torch_mangle_1025.Sequential = prim::GetAttr[name="branch2"](%56)
      %224 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="0"](%223)
      %225 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%223)
      %226 : __torch__.torch.nn.modules.conv.___torch_mangle_629.Conv2d = prim::GetAttr[name="3"](%223)
      %227 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="4"](%223)
      %228 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="5"](%223)
      %229 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="6"](%223)
      %230 : Tensor = prim::GetAttr[name="weight"](%224)
      %231 : Tensor? = prim::GetAttr[name="bias"](%224)
      %232 : int[] = prim::ListConstruct(%7, %7)
      %233 : int[] = prim::ListConstruct(%9, %9)
      %234 : int[] = prim::ListConstruct(%7, %7)
      %input.191 : Tensor = aten::conv2d(%x.31, %230, %231, %232, %233, %234, %7) # torch/nn/modules/conv.py:415:15
      %236 : int = aten::dim(%input.191) # torch/nn/modules/batchnorm.py:276:11
      %237 : bool = aten::ne(%236, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%237) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %238 : bool = prim::GetAttr[name="training"](%225)
       = prim::If(%238) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %239 : Tensor = prim::GetAttr[name="num_batches_tracked"](%225)
          %240 : Tensor = aten::add(%239, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%225, %240)
          -> ()
        block1():
          -> ()
      %241 : bool = prim::GetAttr[name="training"](%225)
      %242 : Tensor = prim::GetAttr[name="running_mean"](%225)
      %243 : Tensor = prim::GetAttr[name="running_var"](%225)
      %244 : Tensor = prim::GetAttr[name="weight"](%225)
      %245 : Tensor = prim::GetAttr[name="bias"](%225)
       = prim::If(%241) # torch/nn/functional.py:2011:4
        block0():
          %246 : int[] = aten::size(%input.191) # torch/nn/functional.py:2012:27
          %size_prods.212 : int = aten::__getitem__(%246, %9) # torch/nn/functional.py:1991:17
          %248 : int = aten::len(%246) # torch/nn/functional.py:1992:19
          %249 : int = aten::sub(%248, %15) # torch/nn/functional.py:1992:19
          %size_prods.213 : int = prim::Loop(%249, %8, %size_prods.212) # torch/nn/functional.py:1992:4
            block0(%i.54 : int, %size_prods.214 : int):
              %253 : int = aten::add(%i.54, %15) # torch/nn/functional.py:1993:27
              %254 : int = aten::__getitem__(%246, %253) # torch/nn/functional.py:1993:22
              %size_prods.215 : int = aten::mul(%size_prods.214, %254) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.215)
          %256 : bool = aten::eq(%size_prods.213, %7) # torch/nn/functional.py:1994:7
           = prim::If(%256) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.194 : Tensor = aten::batch_norm(%input.191, %244, %245, %242, %243, %241, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.195 : Tensor = aten::relu_(%input.194) # torch/nn/functional.py:1117:17
      %259 : Tensor = prim::GetAttr[name="weight"](%226)
      %260 : Tensor? = prim::GetAttr[name="bias"](%226)
      %261 : int[] = prim::ListConstruct(%15, %15)
      %262 : int[] = prim::ListConstruct(%7, %7)
      %263 : int[] = prim::ListConstruct(%7, %7)
      %input.196 : Tensor = aten::conv2d(%input.195, %259, %260, %261, %262, %263, %6) # torch/nn/modules/conv.py:415:15
      %265 : int = aten::dim(%input.196) # torch/nn/modules/batchnorm.py:276:11
      %266 : bool = aten::ne(%265, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%266) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %267 : bool = prim::GetAttr[name="training"](%227)
       = prim::If(%267) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %268 : Tensor = prim::GetAttr[name="num_batches_tracked"](%227)
          %269 : Tensor = aten::add(%268, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%227, %269)
          -> ()
        block1():
          -> ()
      %270 : bool = prim::GetAttr[name="training"](%227)
      %271 : Tensor = prim::GetAttr[name="running_mean"](%227)
      %272 : Tensor = prim::GetAttr[name="running_var"](%227)
      %273 : Tensor = prim::GetAttr[name="weight"](%227)
      %274 : Tensor = prim::GetAttr[name="bias"](%227)
       = prim::If(%270) # torch/nn/functional.py:2011:4
        block0():
          %275 : int[] = aten::size(%input.196) # torch/nn/functional.py:2012:27
          %size_prods.216 : int = aten::__getitem__(%275, %9) # torch/nn/functional.py:1991:17
          %277 : int = aten::len(%275) # torch/nn/functional.py:1992:19
          %278 : int = aten::sub(%277, %15) # torch/nn/functional.py:1992:19
          %size_prods.217 : int = prim::Loop(%278, %8, %size_prods.216) # torch/nn/functional.py:1992:4
            block0(%i.55 : int, %size_prods.218 : int):
              %282 : int = aten::add(%i.55, %15) # torch/nn/functional.py:1993:27
              %283 : int = aten::__getitem__(%275, %282) # torch/nn/functional.py:1993:22
              %size_prods.219 : int = aten::mul(%size_prods.218, %283) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.219)
          %285 : bool = aten::eq(%size_prods.217, %7) # torch/nn/functional.py:1994:7
           = prim::If(%285) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.199 : Tensor = aten::batch_norm(%input.196, %273, %274, %271, %272, %270, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %287 : Tensor = prim::GetAttr[name="weight"](%228)
      %288 : Tensor? = prim::GetAttr[name="bias"](%228)
      %289 : int[] = prim::ListConstruct(%7, %7)
      %290 : int[] = prim::ListConstruct(%9, %9)
      %291 : int[] = prim::ListConstruct(%7, %7)
      %input.144 : Tensor = aten::conv2d(%input.199, %287, %288, %289, %290, %291, %7) # torch/nn/modules/conv.py:415:15
      %293 : int = aten::dim(%input.144) # torch/nn/modules/batchnorm.py:276:11
      %294 : bool = aten::ne(%293, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%294) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %295 : bool = prim::GetAttr[name="training"](%229)
       = prim::If(%295) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %296 : Tensor = prim::GetAttr[name="num_batches_tracked"](%229)
          %297 : Tensor = aten::add(%296, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%229, %297)
          -> ()
        block1():
          -> ()
      %298 : bool = prim::GetAttr[name="training"](%229)
      %299 : Tensor = prim::GetAttr[name="running_mean"](%229)
      %300 : Tensor = prim::GetAttr[name="running_var"](%229)
      %301 : Tensor = prim::GetAttr[name="weight"](%229)
      %302 : Tensor = prim::GetAttr[name="bias"](%229)
       = prim::If(%298) # torch/nn/functional.py:2011:4
        block0():
          %303 : int[] = aten::size(%input.144) # torch/nn/functional.py:2012:27
          %size_prods.220 : int = aten::__getitem__(%303, %9) # torch/nn/functional.py:1991:17
          %305 : int = aten::len(%303) # torch/nn/functional.py:1992:19
          %306 : int = aten::sub(%305, %15) # torch/nn/functional.py:1992:19
          %size_prods.221 : int = prim::Loop(%306, %8, %size_prods.220) # torch/nn/functional.py:1992:4
            block0(%i.56 : int, %size_prods.222 : int):
              %310 : int = aten::add(%i.56, %15) # torch/nn/functional.py:1993:27
              %311 : int = aten::__getitem__(%303, %310) # torch/nn/functional.py:1993:22
              %size_prods.223 : int = aten::mul(%size_prods.222, %311) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.223)
          %313 : bool = aten::eq(%size_prods.221, %7) # torch/nn/functional.py:1994:7
           = prim::If(%313) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.145 : Tensor = aten::batch_norm(%input.144, %301, %302, %299, %300, %298, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.146 : Tensor = aten::relu_(%input.145) # torch/nn/functional.py:1117:17
      %316 : Tensor[] = prim::ListConstruct(%input.198, %input.146)
      %out.32 : Tensor = aten::cat(%316, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.32)
  %318 : Tensor = prim::data(%out.8)
  %319 : int[] = aten::size(%318) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.11 : int, %num_channels.11 : int, %height.11 : int, %width.11 : int = prim::ListUnpack(%319)
  %channels_per_group.11 : int = aten::floordiv(%num_channels.11, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %325 : int[] = prim::ListConstruct(%batchsize.11, %15, %channels_per_group.11, %height.11, %width.11)
  %x.32 : Tensor = aten::view(%out.8, %325) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %327 : Tensor = aten::transpose(%x.32, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.20 : Tensor = aten::contiguous(%327, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %329 : int[] = prim::ListConstruct(%batchsize.11, %5, %height.11, %width.11)
  %input.152 : Tensor = aten::view(%x.20, %329) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %331 : int = prim::GetAttr[name="stride"](%57)
  %332 : bool = aten::eq(%331, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.27 : Tensor = prim::If(%332) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %334 : Tensor[] = aten::chunk(%input.152, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.9 : Tensor, %x2.9 : Tensor = prim::ListUnpack(%334)
      %337 : __torch__.torch.nn.modules.container.___torch_mangle_1027.Sequential = prim::GetAttr[name="branch2"](%57)
      %338 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="0"](%337)
      %339 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%337)
      %340 : __torch__.torch.nn.modules.conv.___torch_mangle_699.Conv2d = prim::GetAttr[name="3"](%337)
      %341 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="4"](%337)
      %342 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="5"](%337)
      %343 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="6"](%337)
      %344 : Tensor = prim::GetAttr[name="weight"](%338)
      %345 : Tensor? = prim::GetAttr[name="bias"](%338)
      %346 : int[] = prim::ListConstruct(%7, %7)
      %347 : int[] = prim::ListConstruct(%9, %9)
      %348 : int[] = prim::ListConstruct(%7, %7)
      %input.147 : Tensor = aten::conv2d(%x2.9, %344, %345, %346, %347, %348, %7) # torch/nn/modules/conv.py:415:15
      %350 : int = aten::dim(%input.147) # torch/nn/modules/batchnorm.py:276:11
      %351 : bool = aten::ne(%350, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%351) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %352 : bool = prim::GetAttr[name="training"](%339)
       = prim::If(%352) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %353 : Tensor = prim::GetAttr[name="num_batches_tracked"](%339)
          %354 : Tensor = aten::add(%353, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%339, %354)
          -> ()
        block1():
          -> ()
      %355 : bool = prim::GetAttr[name="training"](%339)
      %356 : Tensor = prim::GetAttr[name="running_mean"](%339)
      %357 : Tensor = prim::GetAttr[name="running_var"](%339)
      %358 : Tensor = prim::GetAttr[name="weight"](%339)
      %359 : Tensor = prim::GetAttr[name="bias"](%339)
       = prim::If(%355) # torch/nn/functional.py:2011:4
        block0():
          %360 : int[] = aten::size(%input.147) # torch/nn/functional.py:2012:27
          %size_prods.224 : int = aten::__getitem__(%360, %9) # torch/nn/functional.py:1991:17
          %362 : int = aten::len(%360) # torch/nn/functional.py:1992:19
          %363 : int = aten::sub(%362, %15) # torch/nn/functional.py:1992:19
          %size_prods.225 : int = prim::Loop(%363, %8, %size_prods.224) # torch/nn/functional.py:1992:4
            block0(%i.57 : int, %size_prods.226 : int):
              %367 : int = aten::add(%i.57, %15) # torch/nn/functional.py:1993:27
              %368 : int = aten::__getitem__(%360, %367) # torch/nn/functional.py:1993:22
              %size_prods.227 : int = aten::mul(%size_prods.226, %368) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.227)
          %370 : bool = aten::eq(%size_prods.225, %7) # torch/nn/functional.py:1994:7
           = prim::If(%370) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.148 : Tensor = aten::batch_norm(%input.147, %358, %359, %356, %357, %355, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.150 : Tensor = aten::relu_(%input.148) # torch/nn/functional.py:1117:17
      %373 : Tensor = prim::GetAttr[name="weight"](%340)
      %374 : Tensor? = prim::GetAttr[name="bias"](%340)
      %375 : int[] = prim::ListConstruct(%7, %7)
      %376 : int[] = prim::ListConstruct(%7, %7)
      %377 : int[] = prim::ListConstruct(%7, %7)
      %input.151 : Tensor = aten::conv2d(%input.150, %373, %374, %375, %376, %377, %6) # torch/nn/modules/conv.py:415:15
      %379 : int = aten::dim(%input.151) # torch/nn/modules/batchnorm.py:276:11
      %380 : bool = aten::ne(%379, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%380) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %381 : bool = prim::GetAttr[name="training"](%341)
       = prim::If(%381) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %382 : Tensor = prim::GetAttr[name="num_batches_tracked"](%341)
          %383 : Tensor = aten::add(%382, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%341, %383)
          -> ()
        block1():
          -> ()
      %384 : bool = prim::GetAttr[name="training"](%341)
      %385 : Tensor = prim::GetAttr[name="running_mean"](%341)
      %386 : Tensor = prim::GetAttr[name="running_var"](%341)
      %387 : Tensor = prim::GetAttr[name="weight"](%341)
      %388 : Tensor = prim::GetAttr[name="bias"](%341)
       = prim::If(%384) # torch/nn/functional.py:2011:4
        block0():
          %389 : int[] = aten::size(%input.151) # torch/nn/functional.py:2012:27
          %size_prods.228 : int = aten::__getitem__(%389, %9) # torch/nn/functional.py:1991:17
          %391 : int = aten::len(%389) # torch/nn/functional.py:1992:19
          %392 : int = aten::sub(%391, %15) # torch/nn/functional.py:1992:19
          %size_prods.229 : int = prim::Loop(%392, %8, %size_prods.228) # torch/nn/functional.py:1992:4
            block0(%i.58 : int, %size_prods.230 : int):
              %396 : int = aten::add(%i.58, %15) # torch/nn/functional.py:1993:27
              %397 : int = aten::__getitem__(%389, %396) # torch/nn/functional.py:1993:22
              %size_prods.231 : int = aten::mul(%size_prods.230, %397) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.231)
          %399 : bool = aten::eq(%size_prods.229, %7) # torch/nn/functional.py:1994:7
           = prim::If(%399) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.153 : Tensor = aten::batch_norm(%input.151, %387, %388, %385, %386, %384, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %401 : Tensor = prim::GetAttr[name="weight"](%342)
      %402 : Tensor? = prim::GetAttr[name="bias"](%342)
      %403 : int[] = prim::ListConstruct(%7, %7)
      %404 : int[] = prim::ListConstruct(%9, %9)
      %405 : int[] = prim::ListConstruct(%7, %7)
      %input.154 : Tensor = aten::conv2d(%input.153, %401, %402, %403, %404, %405, %7) # torch/nn/modules/conv.py:415:15
      %407 : int = aten::dim(%input.154) # torch/nn/modules/batchnorm.py:276:11
      %408 : bool = aten::ne(%407, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%408) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %409 : bool = prim::GetAttr[name="training"](%343)
       = prim::If(%409) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %410 : Tensor = prim::GetAttr[name="num_batches_tracked"](%343)
          %411 : Tensor = aten::add(%410, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%343, %411)
          -> ()
        block1():
          -> ()
      %412 : bool = prim::GetAttr[name="training"](%343)
      %413 : Tensor = prim::GetAttr[name="running_mean"](%343)
      %414 : Tensor = prim::GetAttr[name="running_var"](%343)
      %415 : Tensor = prim::GetAttr[name="weight"](%343)
      %416 : Tensor = prim::GetAttr[name="bias"](%343)
       = prim::If(%412) # torch/nn/functional.py:2011:4
        block0():
          %417 : int[] = aten::size(%input.154) # torch/nn/functional.py:2012:27
          %size_prods.232 : int = aten::__getitem__(%417, %9) # torch/nn/functional.py:1991:17
          %419 : int = aten::len(%417) # torch/nn/functional.py:1992:19
          %420 : int = aten::sub(%419, %15) # torch/nn/functional.py:1992:19
          %size_prods.233 : int = prim::Loop(%420, %8, %size_prods.232) # torch/nn/functional.py:1992:4
            block0(%i.59 : int, %size_prods.234 : int):
              %424 : int = aten::add(%i.59, %15) # torch/nn/functional.py:1993:27
              %425 : int = aten::__getitem__(%417, %424) # torch/nn/functional.py:1993:22
              %size_prods.235 : int = aten::mul(%size_prods.234, %425) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.235)
          %427 : bool = aten::eq(%size_prods.233, %7) # torch/nn/functional.py:1994:7
           = prim::If(%427) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.155 : Tensor = aten::batch_norm(%input.154, %415, %416, %413, %414, %412, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.156 : Tensor = aten::relu_(%input.155) # torch/nn/functional.py:1117:17
      %430 : Tensor[] = prim::ListConstruct(%x1.9, %input.156)
      %out.25 : Tensor = aten::cat(%430, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.25)
    block1():
      %432 : __torch__.torch.nn.modules.container.___torch_mangle_1027.Sequential = prim::GetAttr[name="branch2"](%57)
      %433 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="0"](%432)
      %434 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%432)
      %435 : __torch__.torch.nn.modules.conv.___torch_mangle_699.Conv2d = prim::GetAttr[name="3"](%432)
      %436 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="4"](%432)
      %437 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="5"](%432)
      %438 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="6"](%432)
      %439 : Tensor = prim::GetAttr[name="weight"](%433)
      %440 : Tensor? = prim::GetAttr[name="bias"](%433)
      %441 : int[] = prim::ListConstruct(%7, %7)
      %442 : int[] = prim::ListConstruct(%9, %9)
      %443 : int[] = prim::ListConstruct(%7, %7)
      %input.157 : Tensor = aten::conv2d(%input.152, %439, %440, %441, %442, %443, %7) # torch/nn/modules/conv.py:415:15
      %445 : int = aten::dim(%input.157) # torch/nn/modules/batchnorm.py:276:11
      %446 : bool = aten::ne(%445, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%446) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %447 : bool = prim::GetAttr[name="training"](%434)
       = prim::If(%447) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %448 : Tensor = prim::GetAttr[name="num_batches_tracked"](%434)
          %449 : Tensor = aten::add(%448, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%434, %449)
          -> ()
        block1():
          -> ()
      %450 : bool = prim::GetAttr[name="training"](%434)
      %451 : Tensor = prim::GetAttr[name="running_mean"](%434)
      %452 : Tensor = prim::GetAttr[name="running_var"](%434)
      %453 : Tensor = prim::GetAttr[name="weight"](%434)
      %454 : Tensor = prim::GetAttr[name="bias"](%434)
       = prim::If(%450) # torch/nn/functional.py:2011:4
        block0():
          %455 : int[] = aten::size(%input.157) # torch/nn/functional.py:2012:27
          %size_prods.236 : int = aten::__getitem__(%455, %9) # torch/nn/functional.py:1991:17
          %457 : int = aten::len(%455) # torch/nn/functional.py:1992:19
          %458 : int = aten::sub(%457, %15) # torch/nn/functional.py:1992:19
          %size_prods.237 : int = prim::Loop(%458, %8, %size_prods.236) # torch/nn/functional.py:1992:4
            block0(%i.60 : int, %size_prods.238 : int):
              %462 : int = aten::add(%i.60, %15) # torch/nn/functional.py:1993:27
              %463 : int = aten::__getitem__(%455, %462) # torch/nn/functional.py:1993:22
              %size_prods.239 : int = aten::mul(%size_prods.238, %463) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.239)
          %465 : bool = aten::eq(%size_prods.237, %7) # torch/nn/functional.py:1994:7
           = prim::If(%465) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.158 : Tensor = aten::batch_norm(%input.157, %453, %454, %451, %452, %450, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.159 : Tensor = aten::relu_(%input.158) # torch/nn/functional.py:1117:17
      %468 : Tensor = prim::GetAttr[name="weight"](%435)
      %469 : Tensor? = prim::GetAttr[name="bias"](%435)
      %470 : int[] = prim::ListConstruct(%7, %7)
      %471 : int[] = prim::ListConstruct(%7, %7)
      %472 : int[] = prim::ListConstruct(%7, %7)
      %input.160 : Tensor = aten::conv2d(%input.159, %468, %469, %470, %471, %472, %6) # torch/nn/modules/conv.py:415:15
      %474 : int = aten::dim(%input.160) # torch/nn/modules/batchnorm.py:276:11
      %475 : bool = aten::ne(%474, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%475) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %476 : bool = prim::GetAttr[name="training"](%436)
       = prim::If(%476) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %477 : Tensor = prim::GetAttr[name="num_batches_tracked"](%436)
          %478 : Tensor = aten::add(%477, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%436, %478)
          -> ()
        block1():
          -> ()
      %479 : bool = prim::GetAttr[name="training"](%436)
      %480 : Tensor = prim::GetAttr[name="running_mean"](%436)
      %481 : Tensor = prim::GetAttr[name="running_var"](%436)
      %482 : Tensor = prim::GetAttr[name="weight"](%436)
      %483 : Tensor = prim::GetAttr[name="bias"](%436)
       = prim::If(%479) # torch/nn/functional.py:2011:4
        block0():
          %484 : int[] = aten::size(%input.160) # torch/nn/functional.py:2012:27
          %size_prods.240 : int = aten::__getitem__(%484, %9) # torch/nn/functional.py:1991:17
          %486 : int = aten::len(%484) # torch/nn/functional.py:1992:19
          %487 : int = aten::sub(%486, %15) # torch/nn/functional.py:1992:19
          %size_prods.241 : int = prim::Loop(%487, %8, %size_prods.240) # torch/nn/functional.py:1992:4
            block0(%i.61 : int, %size_prods.242 : int):
              %491 : int = aten::add(%i.61, %15) # torch/nn/functional.py:1993:27
              %492 : int = aten::__getitem__(%484, %491) # torch/nn/functional.py:1993:22
              %size_prods.243 : int = aten::mul(%size_prods.242, %492) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.243)
          %494 : bool = aten::eq(%size_prods.241, %7) # torch/nn/functional.py:1994:7
           = prim::If(%494) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.161 : Tensor = aten::batch_norm(%input.160, %482, %483, %480, %481, %479, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %496 : Tensor = prim::GetAttr[name="weight"](%437)
      %497 : Tensor? = prim::GetAttr[name="bias"](%437)
      %498 : int[] = prim::ListConstruct(%7, %7)
      %499 : int[] = prim::ListConstruct(%9, %9)
      %500 : int[] = prim::ListConstruct(%7, %7)
      %input.162 : Tensor = aten::conv2d(%input.161, %496, %497, %498, %499, %500, %7) # torch/nn/modules/conv.py:415:15
      %502 : int = aten::dim(%input.162) # torch/nn/modules/batchnorm.py:276:11
      %503 : bool = aten::ne(%502, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%503) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %504 : bool = prim::GetAttr[name="training"](%438)
       = prim::If(%504) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %505 : Tensor = prim::GetAttr[name="num_batches_tracked"](%438)
          %506 : Tensor = aten::add(%505, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%438, %506)
          -> ()
        block1():
          -> ()
      %507 : bool = prim::GetAttr[name="training"](%438)
      %508 : Tensor = prim::GetAttr[name="running_mean"](%438)
      %509 : Tensor = prim::GetAttr[name="running_var"](%438)
      %510 : Tensor = prim::GetAttr[name="weight"](%438)
      %511 : Tensor = prim::GetAttr[name="bias"](%438)
       = prim::If(%507) # torch/nn/functional.py:2011:4
        block0():
          %512 : int[] = aten::size(%input.162) # torch/nn/functional.py:2012:27
          %size_prods.244 : int = aten::__getitem__(%512, %9) # torch/nn/functional.py:1991:17
          %514 : int = aten::len(%512) # torch/nn/functional.py:1992:19
          %515 : int = aten::sub(%514, %15) # torch/nn/functional.py:1992:19
          %size_prods.245 : int = prim::Loop(%515, %8, %size_prods.244) # torch/nn/functional.py:1992:4
            block0(%i.62 : int, %size_prods.246 : int):
              %519 : int = aten::add(%i.62, %15) # torch/nn/functional.py:1993:27
              %520 : int = aten::__getitem__(%512, %519) # torch/nn/functional.py:1993:22
              %size_prods.247 : int = aten::mul(%size_prods.246, %520) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.247)
          %522 : bool = aten::eq(%size_prods.245, %7) # torch/nn/functional.py:1994:7
           = prim::If(%522) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.163 : Tensor = aten::batch_norm(%input.162, %510, %511, %508, %509, %507, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.164 : Tensor = aten::relu_(%input.163) # torch/nn/functional.py:1117:17
      %525 : Tensor[] = prim::ListConstruct(%input.152, %input.164)
      %out.26 : Tensor = aten::cat(%525, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.26)
  %527 : Tensor = prim::data(%out.27)
  %528 : int[] = aten::size(%527) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.9 : int, %num_channels.9 : int, %height.9 : int, %width.9 : int = prim::ListUnpack(%528)
  %channels_per_group.9 : int = aten::floordiv(%num_channels.9, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %534 : int[] = prim::ListConstruct(%batchsize.9, %15, %channels_per_group.9, %height.9, %width.9)
  %x.21 : Tensor = aten::view(%out.27, %534) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %536 : Tensor = aten::transpose(%x.21, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.22 : Tensor = aten::contiguous(%536, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %538 : int[] = prim::ListConstruct(%batchsize.9, %5, %height.9, %width.9)
  %input.170 : Tensor = aten::view(%x.22, %538) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %540 : int = prim::GetAttr[name="stride"](%58)
  %541 : bool = aten::eq(%540, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.30 : Tensor = prim::If(%541) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %543 : Tensor[] = aten::chunk(%input.170, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.10 : Tensor, %x2.10 : Tensor = prim::ListUnpack(%543)
      %546 : __torch__.torch.nn.modules.container.___torch_mangle_1027.Sequential = prim::GetAttr[name="branch2"](%58)
      %547 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="0"](%546)
      %548 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%546)
      %549 : __torch__.torch.nn.modules.conv.___torch_mangle_699.Conv2d = prim::GetAttr[name="3"](%546)
      %550 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="4"](%546)
      %551 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="5"](%546)
      %552 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="6"](%546)
      %553 : Tensor = prim::GetAttr[name="weight"](%547)
      %554 : Tensor? = prim::GetAttr[name="bias"](%547)
      %555 : int[] = prim::ListConstruct(%7, %7)
      %556 : int[] = prim::ListConstruct(%9, %9)
      %557 : int[] = prim::ListConstruct(%7, %7)
      %input.165 : Tensor = aten::conv2d(%x2.10, %553, %554, %555, %556, %557, %7) # torch/nn/modules/conv.py:415:15
      %559 : int = aten::dim(%input.165) # torch/nn/modules/batchnorm.py:276:11
      %560 : bool = aten::ne(%559, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%560) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %561 : bool = prim::GetAttr[name="training"](%548)
       = prim::If(%561) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %562 : Tensor = prim::GetAttr[name="num_batches_tracked"](%548)
          %563 : Tensor = aten::add(%562, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%548, %563)
          -> ()
        block1():
          -> ()
      %564 : bool = prim::GetAttr[name="training"](%548)
      %565 : Tensor = prim::GetAttr[name="running_mean"](%548)
      %566 : Tensor = prim::GetAttr[name="running_var"](%548)
      %567 : Tensor = prim::GetAttr[name="weight"](%548)
      %568 : Tensor = prim::GetAttr[name="bias"](%548)
       = prim::If(%564) # torch/nn/functional.py:2011:4
        block0():
          %569 : int[] = aten::size(%input.165) # torch/nn/functional.py:2012:27
          %size_prods.248 : int = aten::__getitem__(%569, %9) # torch/nn/functional.py:1991:17
          %571 : int = aten::len(%569) # torch/nn/functional.py:1992:19
          %572 : int = aten::sub(%571, %15) # torch/nn/functional.py:1992:19
          %size_prods.249 : int = prim::Loop(%572, %8, %size_prods.248) # torch/nn/functional.py:1992:4
            block0(%i.63 : int, %size_prods.250 : int):
              %576 : int = aten::add(%i.63, %15) # torch/nn/functional.py:1993:27
              %577 : int = aten::__getitem__(%569, %576) # torch/nn/functional.py:1993:22
              %size_prods.251 : int = aten::mul(%size_prods.250, %577) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.251)
          %579 : bool = aten::eq(%size_prods.249, %7) # torch/nn/functional.py:1994:7
           = prim::If(%579) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.167 : Tensor = aten::batch_norm(%input.165, %567, %568, %565, %566, %564, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.168 : Tensor = aten::relu_(%input.167) # torch/nn/functional.py:1117:17
      %582 : Tensor = prim::GetAttr[name="weight"](%549)
      %583 : Tensor? = prim::GetAttr[name="bias"](%549)
      %584 : int[] = prim::ListConstruct(%7, %7)
      %585 : int[] = prim::ListConstruct(%7, %7)
      %586 : int[] = prim::ListConstruct(%7, %7)
      %input.169 : Tensor = aten::conv2d(%input.168, %582, %583, %584, %585, %586, %6) # torch/nn/modules/conv.py:415:15
      %588 : int = aten::dim(%input.169) # torch/nn/modules/batchnorm.py:276:11
      %589 : bool = aten::ne(%588, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%589) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %590 : bool = prim::GetAttr[name="training"](%550)
       = prim::If(%590) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %591 : Tensor = prim::GetAttr[name="num_batches_tracked"](%550)
          %592 : Tensor = aten::add(%591, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%550, %592)
          -> ()
        block1():
          -> ()
      %593 : bool = prim::GetAttr[name="training"](%550)
      %594 : Tensor = prim::GetAttr[name="running_mean"](%550)
      %595 : Tensor = prim::GetAttr[name="running_var"](%550)
      %596 : Tensor = prim::GetAttr[name="weight"](%550)
      %597 : Tensor = prim::GetAttr[name="bias"](%550)
       = prim::If(%593) # torch/nn/functional.py:2011:4
        block0():
          %598 : int[] = aten::size(%input.169) # torch/nn/functional.py:2012:27
          %size_prods.252 : int = aten::__getitem__(%598, %9) # torch/nn/functional.py:1991:17
          %600 : int = aten::len(%598) # torch/nn/functional.py:1992:19
          %601 : int = aten::sub(%600, %15) # torch/nn/functional.py:1992:19
          %size_prods.253 : int = prim::Loop(%601, %8, %size_prods.252) # torch/nn/functional.py:1992:4
            block0(%i.64 : int, %size_prods.254 : int):
              %605 : int = aten::add(%i.64, %15) # torch/nn/functional.py:1993:27
              %606 : int = aten::__getitem__(%598, %605) # torch/nn/functional.py:1993:22
              %size_prods.255 : int = aten::mul(%size_prods.254, %606) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.255)
          %608 : bool = aten::eq(%size_prods.253, %7) # torch/nn/functional.py:1994:7
           = prim::If(%608) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.171 : Tensor = aten::batch_norm(%input.169, %596, %597, %594, %595, %593, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %610 : Tensor = prim::GetAttr[name="weight"](%551)
      %611 : Tensor? = prim::GetAttr[name="bias"](%551)
      %612 : int[] = prim::ListConstruct(%7, %7)
      %613 : int[] = prim::ListConstruct(%9, %9)
      %614 : int[] = prim::ListConstruct(%7, %7)
      %input.172 : Tensor = aten::conv2d(%input.171, %610, %611, %612, %613, %614, %7) # torch/nn/modules/conv.py:415:15
      %616 : int = aten::dim(%input.172) # torch/nn/modules/batchnorm.py:276:11
      %617 : bool = aten::ne(%616, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%617) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %618 : bool = prim::GetAttr[name="training"](%552)
       = prim::If(%618) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %619 : Tensor = prim::GetAttr[name="num_batches_tracked"](%552)
          %620 : Tensor = aten::add(%619, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%552, %620)
          -> ()
        block1():
          -> ()
      %621 : bool = prim::GetAttr[name="training"](%552)
      %622 : Tensor = prim::GetAttr[name="running_mean"](%552)
      %623 : Tensor = prim::GetAttr[name="running_var"](%552)
      %624 : Tensor = prim::GetAttr[name="weight"](%552)
      %625 : Tensor = prim::GetAttr[name="bias"](%552)
       = prim::If(%621) # torch/nn/functional.py:2011:4
        block0():
          %626 : int[] = aten::size(%input.172) # torch/nn/functional.py:2012:27
          %size_prods.256 : int = aten::__getitem__(%626, %9) # torch/nn/functional.py:1991:17
          %628 : int = aten::len(%626) # torch/nn/functional.py:1992:19
          %629 : int = aten::sub(%628, %15) # torch/nn/functional.py:1992:19
          %size_prods.257 : int = prim::Loop(%629, %8, %size_prods.256) # torch/nn/functional.py:1992:4
            block0(%i.65 : int, %size_prods.258 : int):
              %633 : int = aten::add(%i.65, %15) # torch/nn/functional.py:1993:27
              %634 : int = aten::__getitem__(%626, %633) # torch/nn/functional.py:1993:22
              %size_prods.259 : int = aten::mul(%size_prods.258, %634) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.259)
          %636 : bool = aten::eq(%size_prods.257, %7) # torch/nn/functional.py:1994:7
           = prim::If(%636) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.173 : Tensor = aten::batch_norm(%input.172, %624, %625, %622, %623, %621, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.174 : Tensor = aten::relu_(%input.173) # torch/nn/functional.py:1117:17
      %639 : Tensor[] = prim::ListConstruct(%x1.10, %input.174)
      %out.28 : Tensor = aten::cat(%639, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.28)
    block1():
      %641 : __torch__.torch.nn.modules.container.___torch_mangle_1027.Sequential = prim::GetAttr[name="branch2"](%58)
      %642 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="0"](%641)
      %643 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%641)
      %644 : __torch__.torch.nn.modules.conv.___torch_mangle_699.Conv2d = prim::GetAttr[name="3"](%641)
      %645 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="4"](%641)
      %646 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="5"](%641)
      %647 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="6"](%641)
      %648 : Tensor = prim::GetAttr[name="weight"](%642)
      %649 : Tensor? = prim::GetAttr[name="bias"](%642)
      %650 : int[] = prim::ListConstruct(%7, %7)
      %651 : int[] = prim::ListConstruct(%9, %9)
      %652 : int[] = prim::ListConstruct(%7, %7)
      %input.175 : Tensor = aten::conv2d(%input.170, %648, %649, %650, %651, %652, %7) # torch/nn/modules/conv.py:415:15
      %654 : int = aten::dim(%input.175) # torch/nn/modules/batchnorm.py:276:11
      %655 : bool = aten::ne(%654, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%655) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %656 : bool = prim::GetAttr[name="training"](%643)
       = prim::If(%656) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %657 : Tensor = prim::GetAttr[name="num_batches_tracked"](%643)
          %658 : Tensor = aten::add(%657, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%643, %658)
          -> ()
        block1():
          -> ()
      %659 : bool = prim::GetAttr[name="training"](%643)
      %660 : Tensor = prim::GetAttr[name="running_mean"](%643)
      %661 : Tensor = prim::GetAttr[name="running_var"](%643)
      %662 : Tensor = prim::GetAttr[name="weight"](%643)
      %663 : Tensor = prim::GetAttr[name="bias"](%643)
       = prim::If(%659) # torch/nn/functional.py:2011:4
        block0():
          %664 : int[] = aten::size(%input.175) # torch/nn/functional.py:2012:27
          %size_prods.260 : int = aten::__getitem__(%664, %9) # torch/nn/functional.py:1991:17
          %666 : int = aten::len(%664) # torch/nn/functional.py:1992:19
          %667 : int = aten::sub(%666, %15) # torch/nn/functional.py:1992:19
          %size_prods.261 : int = prim::Loop(%667, %8, %size_prods.260) # torch/nn/functional.py:1992:4
            block0(%i.66 : int, %size_prods.262 : int):
              %671 : int = aten::add(%i.66, %15) # torch/nn/functional.py:1993:27
              %672 : int = aten::__getitem__(%664, %671) # torch/nn/functional.py:1993:22
              %size_prods.263 : int = aten::mul(%size_prods.262, %672) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.263)
          %674 : bool = aten::eq(%size_prods.261, %7) # torch/nn/functional.py:1994:7
           = prim::If(%674) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.176 : Tensor = aten::batch_norm(%input.175, %662, %663, %660, %661, %659, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.177 : Tensor = aten::relu_(%input.176) # torch/nn/functional.py:1117:17
      %677 : Tensor = prim::GetAttr[name="weight"](%644)
      %678 : Tensor? = prim::GetAttr[name="bias"](%644)
      %679 : int[] = prim::ListConstruct(%7, %7)
      %680 : int[] = prim::ListConstruct(%7, %7)
      %681 : int[] = prim::ListConstruct(%7, %7)
      %input.178 : Tensor = aten::conv2d(%input.177, %677, %678, %679, %680, %681, %6) # torch/nn/modules/conv.py:415:15
      %683 : int = aten::dim(%input.178) # torch/nn/modules/batchnorm.py:276:11
      %684 : bool = aten::ne(%683, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%684) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %685 : bool = prim::GetAttr[name="training"](%645)
       = prim::If(%685) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %686 : Tensor = prim::GetAttr[name="num_batches_tracked"](%645)
          %687 : Tensor = aten::add(%686, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%645, %687)
          -> ()
        block1():
          -> ()
      %688 : bool = prim::GetAttr[name="training"](%645)
      %689 : Tensor = prim::GetAttr[name="running_mean"](%645)
      %690 : Tensor = prim::GetAttr[name="running_var"](%645)
      %691 : Tensor = prim::GetAttr[name="weight"](%645)
      %692 : Tensor = prim::GetAttr[name="bias"](%645)
       = prim::If(%688) # torch/nn/functional.py:2011:4
        block0():
          %693 : int[] = aten::size(%input.178) # torch/nn/functional.py:2012:27
          %size_prods.264 : int = aten::__getitem__(%693, %9) # torch/nn/functional.py:1991:17
          %695 : int = aten::len(%693) # torch/nn/functional.py:1992:19
          %696 : int = aten::sub(%695, %15) # torch/nn/functional.py:1992:19
          %size_prods.265 : int = prim::Loop(%696, %8, %size_prods.264) # torch/nn/functional.py:1992:4
            block0(%i.67 : int, %size_prods.266 : int):
              %700 : int = aten::add(%i.67, %15) # torch/nn/functional.py:1993:27
              %701 : int = aten::__getitem__(%693, %700) # torch/nn/functional.py:1993:22
              %size_prods.267 : int = aten::mul(%size_prods.266, %701) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.267)
          %703 : bool = aten::eq(%size_prods.265, %7) # torch/nn/functional.py:1994:7
           = prim::If(%703) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.179 : Tensor = aten::batch_norm(%input.178, %691, %692, %689, %690, %688, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %705 : Tensor = prim::GetAttr[name="weight"](%646)
      %706 : Tensor? = prim::GetAttr[name="bias"](%646)
      %707 : int[] = prim::ListConstruct(%7, %7)
      %708 : int[] = prim::ListConstruct(%9, %9)
      %709 : int[] = prim::ListConstruct(%7, %7)
      %input.180 : Tensor = aten::conv2d(%input.179, %705, %706, %707, %708, %709, %7) # torch/nn/modules/conv.py:415:15
      %711 : int = aten::dim(%input.180) # torch/nn/modules/batchnorm.py:276:11
      %712 : bool = aten::ne(%711, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%712) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %713 : bool = prim::GetAttr[name="training"](%647)
       = prim::If(%713) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %714 : Tensor = prim::GetAttr[name="num_batches_tracked"](%647)
          %715 : Tensor = aten::add(%714, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%647, %715)
          -> ()
        block1():
          -> ()
      %716 : bool = prim::GetAttr[name="training"](%647)
      %717 : Tensor = prim::GetAttr[name="running_mean"](%647)
      %718 : Tensor = prim::GetAttr[name="running_var"](%647)
      %719 : Tensor = prim::GetAttr[name="weight"](%647)
      %720 : Tensor = prim::GetAttr[name="bias"](%647)
       = prim::If(%716) # torch/nn/functional.py:2011:4
        block0():
          %721 : int[] = aten::size(%input.180) # torch/nn/functional.py:2012:27
          %size_prods.268 : int = aten::__getitem__(%721, %9) # torch/nn/functional.py:1991:17
          %723 : int = aten::len(%721) # torch/nn/functional.py:1992:19
          %724 : int = aten::sub(%723, %15) # torch/nn/functional.py:1992:19
          %size_prods.269 : int = prim::Loop(%724, %8, %size_prods.268) # torch/nn/functional.py:1992:4
            block0(%i.68 : int, %size_prods.270 : int):
              %728 : int = aten::add(%i.68, %15) # torch/nn/functional.py:1993:27
              %729 : int = aten::__getitem__(%721, %728) # torch/nn/functional.py:1993:22
              %size_prods.271 : int = aten::mul(%size_prods.270, %729) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.271)
          %731 : bool = aten::eq(%size_prods.269, %7) # torch/nn/functional.py:1994:7
           = prim::If(%731) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.181 : Tensor = aten::batch_norm(%input.180, %719, %720, %717, %718, %716, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.182 : Tensor = aten::relu_(%input.181) # torch/nn/functional.py:1117:17
      %734 : Tensor[] = prim::ListConstruct(%input.170, %input.182)
      %out.29 : Tensor = aten::cat(%734, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.29)
  %736 : Tensor = prim::data(%out.30)
  %737 : int[] = aten::size(%736) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.10 : int, %num_channels.10 : int, %height.10 : int, %width.10 : int = prim::ListUnpack(%737)
  %channels_per_group.10 : int = aten::floordiv(%num_channels.10, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %743 : int[] = prim::ListConstruct(%batchsize.10, %15, %channels_per_group.10, %height.10, %width.10)
  %x.23 : Tensor = aten::view(%out.30, %743) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %745 : Tensor = aten::transpose(%x.23, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.24 : Tensor = aten::contiguous(%745, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %747 : int[] = prim::ListConstruct(%batchsize.10, %5, %height.10, %width.10)
  %input.188 : Tensor = aten::view(%x.24, %747) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %749 : int = prim::GetAttr[name="stride"](%59)
  %750 : bool = aten::eq(%749, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.33 : Tensor = prim::If(%750) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %752 : Tensor[] = aten::chunk(%input.188, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.12 : Tensor, %x2.12 : Tensor = prim::ListUnpack(%752)
      %755 : __torch__.torch.nn.modules.container.___torch_mangle_1027.Sequential = prim::GetAttr[name="branch2"](%59)
      %756 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="0"](%755)
      %757 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%755)
      %758 : __torch__.torch.nn.modules.conv.___torch_mangle_699.Conv2d = prim::GetAttr[name="3"](%755)
      %759 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="4"](%755)
      %760 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="5"](%755)
      %761 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="6"](%755)
      %762 : Tensor = prim::GetAttr[name="weight"](%756)
      %763 : Tensor? = prim::GetAttr[name="bias"](%756)
      %764 : int[] = prim::ListConstruct(%7, %7)
      %765 : int[] = prim::ListConstruct(%9, %9)
      %766 : int[] = prim::ListConstruct(%7, %7)
      %input.201 : Tensor = aten::conv2d(%x2.12, %762, %763, %764, %765, %766, %7) # torch/nn/modules/conv.py:415:15
      %768 : int = aten::dim(%input.201) # torch/nn/modules/batchnorm.py:276:11
      %769 : bool = aten::ne(%768, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%769) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %770 : bool = prim::GetAttr[name="training"](%757)
       = prim::If(%770) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %771 : Tensor = prim::GetAttr[name="num_batches_tracked"](%757)
          %772 : Tensor = aten::add(%771, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%757, %772)
          -> ()
        block1():
          -> ()
      %773 : bool = prim::GetAttr[name="training"](%757)
      %774 : Tensor = prim::GetAttr[name="running_mean"](%757)
      %775 : Tensor = prim::GetAttr[name="running_var"](%757)
      %776 : Tensor = prim::GetAttr[name="weight"](%757)
      %777 : Tensor = prim::GetAttr[name="bias"](%757)
       = prim::If(%773) # torch/nn/functional.py:2011:4
        block0():
          %778 : int[] = aten::size(%input.201) # torch/nn/functional.py:2012:27
          %size_prods.284 : int = aten::__getitem__(%778, %9) # torch/nn/functional.py:1991:17
          %780 : int = aten::len(%778) # torch/nn/functional.py:1992:19
          %781 : int = aten::sub(%780, %15) # torch/nn/functional.py:1992:19
          %size_prods.285 : int = prim::Loop(%781, %8, %size_prods.284) # torch/nn/functional.py:1992:4
            block0(%i.72 : int, %size_prods.286 : int):
              %785 : int = aten::add(%i.72, %15) # torch/nn/functional.py:1993:27
              %786 : int = aten::__getitem__(%778, %785) # torch/nn/functional.py:1993:22
              %size_prods.287 : int = aten::mul(%size_prods.286, %786) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.287)
          %788 : bool = aten::eq(%size_prods.285, %7) # torch/nn/functional.py:1994:7
           = prim::If(%788) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.202 : Tensor = aten::batch_norm(%input.201, %776, %777, %774, %775, %773, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.203 : Tensor = aten::relu_(%input.202) # torch/nn/functional.py:1117:17
      %791 : Tensor = prim::GetAttr[name="weight"](%758)
      %792 : Tensor? = prim::GetAttr[name="bias"](%758)
      %793 : int[] = prim::ListConstruct(%7, %7)
      %794 : int[] = prim::ListConstruct(%7, %7)
      %795 : int[] = prim::ListConstruct(%7, %7)
      %input.204 : Tensor = aten::conv2d(%input.203, %791, %792, %793, %794, %795, %6) # torch/nn/modules/conv.py:415:15
      %797 : int = aten::dim(%input.204) # torch/nn/modules/batchnorm.py:276:11
      %798 : bool = aten::ne(%797, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%798) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %799 : bool = prim::GetAttr[name="training"](%759)
       = prim::If(%799) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %800 : Tensor = prim::GetAttr[name="num_batches_tracked"](%759)
          %801 : Tensor = aten::add(%800, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%759, %801)
          -> ()
        block1():
          -> ()
      %802 : bool = prim::GetAttr[name="training"](%759)
      %803 : Tensor = prim::GetAttr[name="running_mean"](%759)
      %804 : Tensor = prim::GetAttr[name="running_var"](%759)
      %805 : Tensor = prim::GetAttr[name="weight"](%759)
      %806 : Tensor = prim::GetAttr[name="bias"](%759)
       = prim::If(%802) # torch/nn/functional.py:2011:4
        block0():
          %807 : int[] = aten::size(%input.204) # torch/nn/functional.py:2012:27
          %size_prods.288 : int = aten::__getitem__(%807, %9) # torch/nn/functional.py:1991:17
          %809 : int = aten::len(%807) # torch/nn/functional.py:1992:19
          %810 : int = aten::sub(%809, %15) # torch/nn/functional.py:1992:19
          %size_prods.289 : int = prim::Loop(%810, %8, %size_prods.288) # torch/nn/functional.py:1992:4
            block0(%i.73 : int, %size_prods.290 : int):
              %814 : int = aten::add(%i.73, %15) # torch/nn/functional.py:1993:27
              %815 : int = aten::__getitem__(%807, %814) # torch/nn/functional.py:1993:22
              %size_prods.291 : int = aten::mul(%size_prods.290, %815) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.291)
          %817 : bool = aten::eq(%size_prods.289, %7) # torch/nn/functional.py:1994:7
           = prim::If(%817) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.205 : Tensor = aten::batch_norm(%input.204, %805, %806, %803, %804, %802, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %819 : Tensor = prim::GetAttr[name="weight"](%760)
      %820 : Tensor? = prim::GetAttr[name="bias"](%760)
      %821 : int[] = prim::ListConstruct(%7, %7)
      %822 : int[] = prim::ListConstruct(%9, %9)
      %823 : int[] = prim::ListConstruct(%7, %7)
      %input.206 : Tensor = aten::conv2d(%input.205, %819, %820, %821, %822, %823, %7) # torch/nn/modules/conv.py:415:15
      %825 : int = aten::dim(%input.206) # torch/nn/modules/batchnorm.py:276:11
      %826 : bool = aten::ne(%825, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%826) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %827 : bool = prim::GetAttr[name="training"](%761)
       = prim::If(%827) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %828 : Tensor = prim::GetAttr[name="num_batches_tracked"](%761)
          %829 : Tensor = aten::add(%828, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%761, %829)
          -> ()
        block1():
          -> ()
      %830 : bool = prim::GetAttr[name="training"](%761)
      %831 : Tensor = prim::GetAttr[name="running_mean"](%761)
      %832 : Tensor = prim::GetAttr[name="running_var"](%761)
      %833 : Tensor = prim::GetAttr[name="weight"](%761)
      %834 : Tensor = prim::GetAttr[name="bias"](%761)
       = prim::If(%830) # torch/nn/functional.py:2011:4
        block0():
          %835 : int[] = aten::size(%input.206) # torch/nn/functional.py:2012:27
          %size_prods.292 : int = aten::__getitem__(%835, %9) # torch/nn/functional.py:1991:17
          %837 : int = aten::len(%835) # torch/nn/functional.py:1992:19
          %838 : int = aten::sub(%837, %15) # torch/nn/functional.py:1992:19
          %size_prods.293 : int = prim::Loop(%838, %8, %size_prods.292) # torch/nn/functional.py:1992:4
            block0(%i.74 : int, %size_prods.294 : int):
              %842 : int = aten::add(%i.74, %15) # torch/nn/functional.py:1993:27
              %843 : int = aten::__getitem__(%835, %842) # torch/nn/functional.py:1993:22
              %size_prods.295 : int = aten::mul(%size_prods.294, %843) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.295)
          %845 : bool = aten::eq(%size_prods.293, %7) # torch/nn/functional.py:1994:7
           = prim::If(%845) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.207 : Tensor = aten::batch_norm(%input.206, %833, %834, %831, %832, %830, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.208 : Tensor = aten::relu_(%input.207) # torch/nn/functional.py:1117:17
      %848 : Tensor[] = prim::ListConstruct(%x1.12, %input.208)
      %out.34 : Tensor = aten::cat(%848, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.34)
    block1():
      %850 : __torch__.torch.nn.modules.container.___torch_mangle_1027.Sequential = prim::GetAttr[name="branch2"](%59)
      %851 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="0"](%850)
      %852 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%850)
      %853 : __torch__.torch.nn.modules.conv.___torch_mangle_699.Conv2d = prim::GetAttr[name="3"](%850)
      %854 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="4"](%850)
      %855 : __torch__.torch.nn.modules.conv.___torch_mangle_1023.Conv2d = prim::GetAttr[name="5"](%850)
      %856 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="6"](%850)
      %857 : Tensor = prim::GetAttr[name="weight"](%851)
      %858 : Tensor? = prim::GetAttr[name="bias"](%851)
      %859 : int[] = prim::ListConstruct(%7, %7)
      %860 : int[] = prim::ListConstruct(%9, %9)
      %861 : int[] = prim::ListConstruct(%7, %7)
      %input.209 : Tensor = aten::conv2d(%input.188, %857, %858, %859, %860, %861, %7) # torch/nn/modules/conv.py:415:15
      %863 : int = aten::dim(%input.209) # torch/nn/modules/batchnorm.py:276:11
      %864 : bool = aten::ne(%863, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%864) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %865 : bool = prim::GetAttr[name="training"](%852)
       = prim::If(%865) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %866 : Tensor = prim::GetAttr[name="num_batches_tracked"](%852)
          %867 : Tensor = aten::add(%866, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%852, %867)
          -> ()
        block1():
          -> ()
      %868 : bool = prim::GetAttr[name="training"](%852)
      %869 : Tensor = prim::GetAttr[name="running_mean"](%852)
      %870 : Tensor = prim::GetAttr[name="running_var"](%852)
      %871 : Tensor = prim::GetAttr[name="weight"](%852)
      %872 : Tensor = prim::GetAttr[name="bias"](%852)
       = prim::If(%868) # torch/nn/functional.py:2011:4
        block0():
          %873 : int[] = aten::size(%input.209) # torch/nn/functional.py:2012:27
          %size_prods.296 : int = aten::__getitem__(%873, %9) # torch/nn/functional.py:1991:17
          %875 : int = aten::len(%873) # torch/nn/functional.py:1992:19
          %876 : int = aten::sub(%875, %15) # torch/nn/functional.py:1992:19
          %size_prods.297 : int = prim::Loop(%876, %8, %size_prods.296) # torch/nn/functional.py:1992:4
            block0(%i.75 : int, %size_prods.298 : int):
              %880 : int = aten::add(%i.75, %15) # torch/nn/functional.py:1993:27
              %881 : int = aten::__getitem__(%873, %880) # torch/nn/functional.py:1993:22
              %size_prods.299 : int = aten::mul(%size_prods.298, %881) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.299)
          %883 : bool = aten::eq(%size_prods.297, %7) # torch/nn/functional.py:1994:7
           = prim::If(%883) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.210 : Tensor = aten::batch_norm(%input.209, %871, %872, %869, %870, %868, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.211 : Tensor = aten::relu_(%input.210) # torch/nn/functional.py:1117:17
      %886 : Tensor = prim::GetAttr[name="weight"](%853)
      %887 : Tensor? = prim::GetAttr[name="bias"](%853)
      %888 : int[] = prim::ListConstruct(%7, %7)
      %889 : int[] = prim::ListConstruct(%7, %7)
      %890 : int[] = prim::ListConstruct(%7, %7)
      %input.212 : Tensor = aten::conv2d(%input.211, %886, %887, %888, %889, %890, %6) # torch/nn/modules/conv.py:415:15
      %892 : int = aten::dim(%input.212) # torch/nn/modules/batchnorm.py:276:11
      %893 : bool = aten::ne(%892, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%893) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %894 : bool = prim::GetAttr[name="training"](%854)
       = prim::If(%894) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %895 : Tensor = prim::GetAttr[name="num_batches_tracked"](%854)
          %896 : Tensor = aten::add(%895, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%854, %896)
          -> ()
        block1():
          -> ()
      %897 : bool = prim::GetAttr[name="training"](%854)
      %898 : Tensor = prim::GetAttr[name="running_mean"](%854)
      %899 : Tensor = prim::GetAttr[name="running_var"](%854)
      %900 : Tensor = prim::GetAttr[name="weight"](%854)
      %901 : Tensor = prim::GetAttr[name="bias"](%854)
       = prim::If(%897) # torch/nn/functional.py:2011:4
        block0():
          %902 : int[] = aten::size(%input.212) # torch/nn/functional.py:2012:27
          %size_prods.300 : int = aten::__getitem__(%902, %9) # torch/nn/functional.py:1991:17
          %904 : int = aten::len(%902) # torch/nn/functional.py:1992:19
          %905 : int = aten::sub(%904, %15) # torch/nn/functional.py:1992:19
          %size_prods.301 : int = prim::Loop(%905, %8, %size_prods.300) # torch/nn/functional.py:1992:4
            block0(%i.76 : int, %size_prods.302 : int):
              %909 : int = aten::add(%i.76, %15) # torch/nn/functional.py:1993:27
              %910 : int = aten::__getitem__(%902, %909) # torch/nn/functional.py:1993:22
              %size_prods.303 : int = aten::mul(%size_prods.302, %910) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.303)
          %912 : bool = aten::eq(%size_prods.301, %7) # torch/nn/functional.py:1994:7
           = prim::If(%912) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.213 : Tensor = aten::batch_norm(%input.212, %900, %901, %898, %899, %897, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %914 : Tensor = prim::GetAttr[name="weight"](%855)
      %915 : Tensor? = prim::GetAttr[name="bias"](%855)
      %916 : int[] = prim::ListConstruct(%7, %7)
      %917 : int[] = prim::ListConstruct(%9, %9)
      %918 : int[] = prim::ListConstruct(%7, %7)
      %input.214 : Tensor = aten::conv2d(%input.213, %914, %915, %916, %917, %918, %7) # torch/nn/modules/conv.py:415:15
      %920 : int = aten::dim(%input.214) # torch/nn/modules/batchnorm.py:276:11
      %921 : bool = aten::ne(%920, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%921) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %922 : bool = prim::GetAttr[name="training"](%856)
       = prim::If(%922) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %923 : Tensor = prim::GetAttr[name="num_batches_tracked"](%856)
          %924 : Tensor = aten::add(%923, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%856, %924)
          -> ()
        block1():
          -> ()
      %925 : bool = prim::GetAttr[name="training"](%856)
      %926 : Tensor = prim::GetAttr[name="running_mean"](%856)
      %927 : Tensor = prim::GetAttr[name="running_var"](%856)
      %928 : Tensor = prim::GetAttr[name="weight"](%856)
      %929 : Tensor = prim::GetAttr[name="bias"](%856)
       = prim::If(%925) # torch/nn/functional.py:2011:4
        block0():
          %930 : int[] = aten::size(%input.214) # torch/nn/functional.py:2012:27
          %size_prods.304 : int = aten::__getitem__(%930, %9) # torch/nn/functional.py:1991:17
          %932 : int = aten::len(%930) # torch/nn/functional.py:1992:19
          %933 : int = aten::sub(%932, %15) # torch/nn/functional.py:1992:19
          %size_prods.305 : int = prim::Loop(%933, %8, %size_prods.304) # torch/nn/functional.py:1992:4
            block0(%i.77 : int, %size_prods.306 : int):
              %937 : int = aten::add(%i.77, %15) # torch/nn/functional.py:1993:27
              %938 : int = aten::__getitem__(%930, %937) # torch/nn/functional.py:1993:22
              %size_prods.307 : int = aten::mul(%size_prods.306, %938) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.307)
          %940 : bool = aten::eq(%size_prods.305, %7) # torch/nn/functional.py:1994:7
           = prim::If(%940) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.215 : Tensor = aten::batch_norm(%input.214, %928, %929, %926, %927, %925, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.216 : Tensor = aten::relu_(%input.215) # torch/nn/functional.py:1117:17
      %943 : Tensor[] = prim::ListConstruct(%input.188, %input.216)
      %out.35 : Tensor = aten::cat(%943, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.35)
  %945 : Tensor = prim::data(%out.33)
  %946 : int[] = aten::size(%945) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.12 : int, %num_channels.12 : int, %height.12 : int, %width.12 : int = prim::ListUnpack(%946)
  %channels_per_group.12 : int = aten::floordiv(%num_channels.12, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %952 : int[] = prim::ListConstruct(%batchsize.12, %15, %channels_per_group.12, %height.12, %width.12)
  %x.33 : Tensor = aten::view(%out.33, %952) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %954 : Tensor = aten::transpose(%x.33, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.34 : Tensor = aten::contiguous(%954, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %956 : int[] = prim::ListConstruct(%batchsize.12, %5, %height.12, %width.12)
  %x.27 : Tensor = aten::view(%x.34, %956) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %958 : __torch__.torch.nn.modules.container.___torch_mangle_1037.Sequential = prim::GetAttr[name="stage3"](%self)
  %959 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1034.InvertedResidual = prim::GetAttr[name="0"](%958)
  %960 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1036.InvertedResidual = prim::GetAttr[name="1"](%958)
  %961 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1036.InvertedResidual = prim::GetAttr[name="2"](%958)
  %962 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1036.InvertedResidual = prim::GetAttr[name="3"](%958)
  %963 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1036.InvertedResidual = prim::GetAttr[name="4"](%958)
  %964 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1036.InvertedResidual = prim::GetAttr[name="5"](%958)
  %965 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1036.InvertedResidual = prim::GetAttr[name="6"](%958)
  %966 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1036.InvertedResidual = prim::GetAttr[name="7"](%958)
  %967 : int = prim::GetAttr[name="stride"](%959)
  %968 : bool = aten::eq(%967, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.36 : Tensor = prim::If(%968) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %970 : Tensor[] = aten::chunk(%x.27, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.13 : Tensor, %x2.13 : Tensor = prim::ListUnpack(%970)
      %973 : __torch__.torch.nn.modules.container.___torch_mangle_1033.Sequential = prim::GetAttr[name="branch2"](%959)
      %974 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%973)
      %975 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%973)
      %976 : __torch__.torch.nn.modules.conv.___torch_mangle_700.Conv2d = prim::GetAttr[name="3"](%973)
      %977 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%973)
      %978 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%973)
      %979 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%973)
      %980 : Tensor = prim::GetAttr[name="weight"](%974)
      %981 : Tensor? = prim::GetAttr[name="bias"](%974)
      %982 : int[] = prim::ListConstruct(%7, %7)
      %983 : int[] = prim::ListConstruct(%9, %9)
      %984 : int[] = prim::ListConstruct(%7, %7)
      %input.221 : Tensor = aten::conv2d(%x2.13, %980, %981, %982, %983, %984, %7) # torch/nn/modules/conv.py:415:15
      %986 : int = aten::dim(%input.221) # torch/nn/modules/batchnorm.py:276:11
      %987 : bool = aten::ne(%986, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%987) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %988 : bool = prim::GetAttr[name="training"](%975)
       = prim::If(%988) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %989 : Tensor = prim::GetAttr[name="num_batches_tracked"](%975)
          %990 : Tensor = aten::add(%989, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%975, %990)
          -> ()
        block1():
          -> ()
      %991 : bool = prim::GetAttr[name="training"](%975)
      %992 : Tensor = prim::GetAttr[name="running_mean"](%975)
      %993 : Tensor = prim::GetAttr[name="running_var"](%975)
      %994 : Tensor = prim::GetAttr[name="weight"](%975)
      %995 : Tensor = prim::GetAttr[name="bias"](%975)
       = prim::If(%991) # torch/nn/functional.py:2011:4
        block0():
          %996 : int[] = aten::size(%input.221) # torch/nn/functional.py:2012:27
          %size_prods.308 : int = aten::__getitem__(%996, %9) # torch/nn/functional.py:1991:17
          %998 : int = aten::len(%996) # torch/nn/functional.py:1992:19
          %999 : int = aten::sub(%998, %15) # torch/nn/functional.py:1992:19
          %size_prods.309 : int = prim::Loop(%999, %8, %size_prods.308) # torch/nn/functional.py:1992:4
            block0(%i.78 : int, %size_prods.310 : int):
              %1003 : int = aten::add(%i.78, %15) # torch/nn/functional.py:1993:27
              %1004 : int = aten::__getitem__(%996, %1003) # torch/nn/functional.py:1993:22
              %size_prods.311 : int = aten::mul(%size_prods.310, %1004) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.311)
          %1006 : bool = aten::eq(%size_prods.309, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1006) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.225 : Tensor = aten::batch_norm(%input.221, %994, %995, %992, %993, %991, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.226 : Tensor = aten::relu_(%input.225) # torch/nn/functional.py:1117:17
      %1009 : Tensor = prim::GetAttr[name="weight"](%976)
      %1010 : Tensor? = prim::GetAttr[name="bias"](%976)
      %1011 : int[] = prim::ListConstruct(%15, %15)
      %1012 : int[] = prim::ListConstruct(%7, %7)
      %1013 : int[] = prim::ListConstruct(%7, %7)
      %input.227 : Tensor = aten::conv2d(%input.226, %1009, %1010, %1011, %1012, %1013, %4) # torch/nn/modules/conv.py:415:15
      %1015 : int = aten::dim(%input.227) # torch/nn/modules/batchnorm.py:276:11
      %1016 : bool = aten::ne(%1015, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1016) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1017 : bool = prim::GetAttr[name="training"](%977)
       = prim::If(%1017) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1018 : Tensor = prim::GetAttr[name="num_batches_tracked"](%977)
          %1019 : Tensor = aten::add(%1018, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%977, %1019)
          -> ()
        block1():
          -> ()
      %1020 : bool = prim::GetAttr[name="training"](%977)
      %1021 : Tensor = prim::GetAttr[name="running_mean"](%977)
      %1022 : Tensor = prim::GetAttr[name="running_var"](%977)
      %1023 : Tensor = prim::GetAttr[name="weight"](%977)
      %1024 : Tensor = prim::GetAttr[name="bias"](%977)
       = prim::If(%1020) # torch/nn/functional.py:2011:4
        block0():
          %1025 : int[] = aten::size(%input.227) # torch/nn/functional.py:2012:27
          %size_prods.312 : int = aten::__getitem__(%1025, %9) # torch/nn/functional.py:1991:17
          %1027 : int = aten::len(%1025) # torch/nn/functional.py:1992:19
          %1028 : int = aten::sub(%1027, %15) # torch/nn/functional.py:1992:19
          %size_prods.313 : int = prim::Loop(%1028, %8, %size_prods.312) # torch/nn/functional.py:1992:4
            block0(%i.79 : int, %size_prods.314 : int):
              %1032 : int = aten::add(%i.79, %15) # torch/nn/functional.py:1993:27
              %1033 : int = aten::__getitem__(%1025, %1032) # torch/nn/functional.py:1993:22
              %size_prods.315 : int = aten::mul(%size_prods.314, %1033) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.315)
          %1035 : bool = aten::eq(%size_prods.313, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1035) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.230 : Tensor = aten::batch_norm(%input.227, %1023, %1024, %1021, %1022, %1020, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1037 : Tensor = prim::GetAttr[name="weight"](%978)
      %1038 : Tensor? = prim::GetAttr[name="bias"](%978)
      %1039 : int[] = prim::ListConstruct(%7, %7)
      %1040 : int[] = prim::ListConstruct(%9, %9)
      %1041 : int[] = prim::ListConstruct(%7, %7)
      %input.222 : Tensor = aten::conv2d(%input.230, %1037, %1038, %1039, %1040, %1041, %7) # torch/nn/modules/conv.py:415:15
      %1043 : int = aten::dim(%input.222) # torch/nn/modules/batchnorm.py:276:11
      %1044 : bool = aten::ne(%1043, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1044) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1045 : bool = prim::GetAttr[name="training"](%979)
       = prim::If(%1045) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1046 : Tensor = prim::GetAttr[name="num_batches_tracked"](%979)
          %1047 : Tensor = aten::add(%1046, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%979, %1047)
          -> ()
        block1():
          -> ()
      %1048 : bool = prim::GetAttr[name="training"](%979)
      %1049 : Tensor = prim::GetAttr[name="running_mean"](%979)
      %1050 : Tensor = prim::GetAttr[name="running_var"](%979)
      %1051 : Tensor = prim::GetAttr[name="weight"](%979)
      %1052 : Tensor = prim::GetAttr[name="bias"](%979)
       = prim::If(%1048) # torch/nn/functional.py:2011:4
        block0():
          %1053 : int[] = aten::size(%input.222) # torch/nn/functional.py:2012:27
          %size_prods.316 : int = aten::__getitem__(%1053, %9) # torch/nn/functional.py:1991:17
          %1055 : int = aten::len(%1053) # torch/nn/functional.py:1992:19
          %1056 : int = aten::sub(%1055, %15) # torch/nn/functional.py:1992:19
          %size_prods.317 : int = prim::Loop(%1056, %8, %size_prods.316) # torch/nn/functional.py:1992:4
            block0(%i.80 : int, %size_prods.318 : int):
              %1060 : int = aten::add(%i.80, %15) # torch/nn/functional.py:1993:27
              %1061 : int = aten::__getitem__(%1053, %1060) # torch/nn/functional.py:1993:22
              %size_prods.319 : int = aten::mul(%size_prods.318, %1061) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.319)
          %1063 : bool = aten::eq(%size_prods.317, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1063) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.223 : Tensor = aten::batch_norm(%input.222, %1051, %1052, %1049, %1050, %1048, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.224 : Tensor = aten::relu_(%input.223) # torch/nn/functional.py:1117:17
      %1066 : Tensor[] = prim::ListConstruct(%x1.13, %input.224)
      %out.37 : Tensor = aten::cat(%1066, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.37)
    block1():
      %1068 : __torch__.torch.nn.modules.container.___torch_mangle_1032.Sequential = prim::GetAttr[name="branch1"](%959)
      %1069 : __torch__.torch.nn.modules.conv.___torch_mangle_700.Conv2d = prim::GetAttr[name="0"](%1068)
      %1070 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1068)
      %1071 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="2"](%1068)
      %1072 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="3"](%1068)
      %1073 : Tensor = prim::GetAttr[name="weight"](%1069)
      %1074 : Tensor? = prim::GetAttr[name="bias"](%1069)
      %1075 : int[] = prim::ListConstruct(%15, %15)
      %1076 : int[] = prim::ListConstruct(%7, %7)
      %1077 : int[] = prim::ListConstruct(%7, %7)
      %input.231 : Tensor = aten::conv2d(%x.27, %1073, %1074, %1075, %1076, %1077, %4) # torch/nn/modules/conv.py:415:15
      %1079 : int = aten::dim(%input.231) # torch/nn/modules/batchnorm.py:276:11
      %1080 : bool = aten::ne(%1079, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1080) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1081 : bool = prim::GetAttr[name="training"](%1070)
       = prim::If(%1081) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1082 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1070)
          %1083 : Tensor = aten::add(%1082, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1070, %1083)
          -> ()
        block1():
          -> ()
      %1084 : bool = prim::GetAttr[name="training"](%1070)
      %1085 : Tensor = prim::GetAttr[name="running_mean"](%1070)
      %1086 : Tensor = prim::GetAttr[name="running_var"](%1070)
      %1087 : Tensor = prim::GetAttr[name="weight"](%1070)
      %1088 : Tensor = prim::GetAttr[name="bias"](%1070)
       = prim::If(%1084) # torch/nn/functional.py:2011:4
        block0():
          %1089 : int[] = aten::size(%input.231) # torch/nn/functional.py:2012:27
          %size_prods.320 : int = aten::__getitem__(%1089, %9) # torch/nn/functional.py:1991:17
          %1091 : int = aten::len(%1089) # torch/nn/functional.py:1992:19
          %1092 : int = aten::sub(%1091, %15) # torch/nn/functional.py:1992:19
          %size_prods.321 : int = prim::Loop(%1092, %8, %size_prods.320) # torch/nn/functional.py:1992:4
            block0(%i.81 : int, %size_prods.322 : int):
              %1096 : int = aten::add(%i.81, %15) # torch/nn/functional.py:1993:27
              %1097 : int = aten::__getitem__(%1089, %1096) # torch/nn/functional.py:1993:22
              %size_prods.323 : int = aten::mul(%size_prods.322, %1097) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.323)
          %1099 : bool = aten::eq(%size_prods.321, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1099) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.232 : Tensor = aten::batch_norm(%input.231, %1087, %1088, %1085, %1086, %1084, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1101 : Tensor = prim::GetAttr[name="weight"](%1071)
      %1102 : Tensor? = prim::GetAttr[name="bias"](%1071)
      %1103 : int[] = prim::ListConstruct(%7, %7)
      %1104 : int[] = prim::ListConstruct(%9, %9)
      %1105 : int[] = prim::ListConstruct(%7, %7)
      %input.233 : Tensor = aten::conv2d(%input.232, %1101, %1102, %1103, %1104, %1105, %7) # torch/nn/modules/conv.py:415:15
      %1107 : int = aten::dim(%input.233) # torch/nn/modules/batchnorm.py:276:11
      %1108 : bool = aten::ne(%1107, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1108) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1109 : bool = prim::GetAttr[name="training"](%1072)
       = prim::If(%1109) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1110 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1072)
          %1111 : Tensor = aten::add(%1110, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1072, %1111)
          -> ()
        block1():
          -> ()
      %1112 : bool = prim::GetAttr[name="training"](%1072)
      %1113 : Tensor = prim::GetAttr[name="running_mean"](%1072)
      %1114 : Tensor = prim::GetAttr[name="running_var"](%1072)
      %1115 : Tensor = prim::GetAttr[name="weight"](%1072)
      %1116 : Tensor = prim::GetAttr[name="bias"](%1072)
       = prim::If(%1112) # torch/nn/functional.py:2011:4
        block0():
          %1117 : int[] = aten::size(%input.233) # torch/nn/functional.py:2012:27
          %size_prods.324 : int = aten::__getitem__(%1117, %9) # torch/nn/functional.py:1991:17
          %1119 : int = aten::len(%1117) # torch/nn/functional.py:1992:19
          %1120 : int = aten::sub(%1119, %15) # torch/nn/functional.py:1992:19
          %size_prods.325 : int = prim::Loop(%1120, %8, %size_prods.324) # torch/nn/functional.py:1992:4
            block0(%i.82 : int, %size_prods.326 : int):
              %1124 : int = aten::add(%i.82, %15) # torch/nn/functional.py:1993:27
              %1125 : int = aten::__getitem__(%1117, %1124) # torch/nn/functional.py:1993:22
              %size_prods.327 : int = aten::mul(%size_prods.326, %1125) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.327)
          %1127 : bool = aten::eq(%size_prods.325, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1127) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.228 : Tensor = aten::batch_norm(%input.233, %1115, %1116, %1113, %1114, %1112, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.229 : Tensor = aten::relu_(%input.228) # torch/nn/functional.py:1117:17
      %1130 : __torch__.torch.nn.modules.container.___torch_mangle_1033.Sequential = prim::GetAttr[name="branch2"](%959)
      %1131 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%1130)
      %1132 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1130)
      %1133 : __torch__.torch.nn.modules.conv.___torch_mangle_700.Conv2d = prim::GetAttr[name="3"](%1130)
      %1134 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%1130)
      %1135 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%1130)
      %1136 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%1130)
      %1137 : Tensor = prim::GetAttr[name="weight"](%1131)
      %1138 : Tensor? = prim::GetAttr[name="bias"](%1131)
      %1139 : int[] = prim::ListConstruct(%7, %7)
      %1140 : int[] = prim::ListConstruct(%9, %9)
      %1141 : int[] = prim::ListConstruct(%7, %7)
      %input.234 : Tensor = aten::conv2d(%x.27, %1137, %1138, %1139, %1140, %1141, %7) # torch/nn/modules/conv.py:415:15
      %1143 : int = aten::dim(%input.234) # torch/nn/modules/batchnorm.py:276:11
      %1144 : bool = aten::ne(%1143, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1144) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1145 : bool = prim::GetAttr[name="training"](%1132)
       = prim::If(%1145) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1146 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1132)
          %1147 : Tensor = aten::add(%1146, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1132, %1147)
          -> ()
        block1():
          -> ()
      %1148 : bool = prim::GetAttr[name="training"](%1132)
      %1149 : Tensor = prim::GetAttr[name="running_mean"](%1132)
      %1150 : Tensor = prim::GetAttr[name="running_var"](%1132)
      %1151 : Tensor = prim::GetAttr[name="weight"](%1132)
      %1152 : Tensor = prim::GetAttr[name="bias"](%1132)
       = prim::If(%1148) # torch/nn/functional.py:2011:4
        block0():
          %1153 : int[] = aten::size(%input.234) # torch/nn/functional.py:2012:27
          %size_prods.328 : int = aten::__getitem__(%1153, %9) # torch/nn/functional.py:1991:17
          %1155 : int = aten::len(%1153) # torch/nn/functional.py:1992:19
          %1156 : int = aten::sub(%1155, %15) # torch/nn/functional.py:1992:19
          %size_prods.329 : int = prim::Loop(%1156, %8, %size_prods.328) # torch/nn/functional.py:1992:4
            block0(%i.83 : int, %size_prods.330 : int):
              %1160 : int = aten::add(%i.83, %15) # torch/nn/functional.py:1993:27
              %1161 : int = aten::__getitem__(%1153, %1160) # torch/nn/functional.py:1993:22
              %size_prods.331 : int = aten::mul(%size_prods.330, %1161) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.331)
          %1163 : bool = aten::eq(%size_prods.329, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1163) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.235 : Tensor = aten::batch_norm(%input.234, %1151, %1152, %1149, %1150, %1148, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.236 : Tensor = aten::relu_(%input.235) # torch/nn/functional.py:1117:17
      %1166 : Tensor = prim::GetAttr[name="weight"](%1133)
      %1167 : Tensor? = prim::GetAttr[name="bias"](%1133)
      %1168 : int[] = prim::ListConstruct(%15, %15)
      %1169 : int[] = prim::ListConstruct(%7, %7)
      %1170 : int[] = prim::ListConstruct(%7, %7)
      %input.237 : Tensor = aten::conv2d(%input.236, %1166, %1167, %1168, %1169, %1170, %4) # torch/nn/modules/conv.py:415:15
      %1172 : int = aten::dim(%input.237) # torch/nn/modules/batchnorm.py:276:11
      %1173 : bool = aten::ne(%1172, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1173) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1174 : bool = prim::GetAttr[name="training"](%1134)
       = prim::If(%1174) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1175 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1134)
          %1176 : Tensor = aten::add(%1175, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1134, %1176)
          -> ()
        block1():
          -> ()
      %1177 : bool = prim::GetAttr[name="training"](%1134)
      %1178 : Tensor = prim::GetAttr[name="running_mean"](%1134)
      %1179 : Tensor = prim::GetAttr[name="running_var"](%1134)
      %1180 : Tensor = prim::GetAttr[name="weight"](%1134)
      %1181 : Tensor = prim::GetAttr[name="bias"](%1134)
       = prim::If(%1177) # torch/nn/functional.py:2011:4
        block0():
          %1182 : int[] = aten::size(%input.237) # torch/nn/functional.py:2012:27
          %size_prods.332 : int = aten::__getitem__(%1182, %9) # torch/nn/functional.py:1991:17
          %1184 : int = aten::len(%1182) # torch/nn/functional.py:1992:19
          %1185 : int = aten::sub(%1184, %15) # torch/nn/functional.py:1992:19
          %size_prods.333 : int = prim::Loop(%1185, %8, %size_prods.332) # torch/nn/functional.py:1992:4
            block0(%i.84 : int, %size_prods.334 : int):
              %1189 : int = aten::add(%i.84, %15) # torch/nn/functional.py:1993:27
              %1190 : int = aten::__getitem__(%1182, %1189) # torch/nn/functional.py:1993:22
              %size_prods.335 : int = aten::mul(%size_prods.334, %1190) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.335)
          %1192 : bool = aten::eq(%size_prods.333, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1192) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.239 : Tensor = aten::batch_norm(%input.237, %1180, %1181, %1178, %1179, %1177, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1194 : Tensor = prim::GetAttr[name="weight"](%1135)
      %1195 : Tensor? = prim::GetAttr[name="bias"](%1135)
      %1196 : int[] = prim::ListConstruct(%7, %7)
      %1197 : int[] = prim::ListConstruct(%9, %9)
      %1198 : int[] = prim::ListConstruct(%7, %7)
      %input.240 : Tensor = aten::conv2d(%input.239, %1194, %1195, %1196, %1197, %1198, %7) # torch/nn/modules/conv.py:415:15
      %1200 : int = aten::dim(%input.240) # torch/nn/modules/batchnorm.py:276:11
      %1201 : bool = aten::ne(%1200, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1201) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1202 : bool = prim::GetAttr[name="training"](%1136)
       = prim::If(%1202) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1203 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1136)
          %1204 : Tensor = aten::add(%1203, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1136, %1204)
          -> ()
        block1():
          -> ()
      %1205 : bool = prim::GetAttr[name="training"](%1136)
      %1206 : Tensor = prim::GetAttr[name="running_mean"](%1136)
      %1207 : Tensor = prim::GetAttr[name="running_var"](%1136)
      %1208 : Tensor = prim::GetAttr[name="weight"](%1136)
      %1209 : Tensor = prim::GetAttr[name="bias"](%1136)
       = prim::If(%1205) # torch/nn/functional.py:2011:4
        block0():
          %1210 : int[] = aten::size(%input.240) # torch/nn/functional.py:2012:27
          %size_prods.336 : int = aten::__getitem__(%1210, %9) # torch/nn/functional.py:1991:17
          %1212 : int = aten::len(%1210) # torch/nn/functional.py:1992:19
          %1213 : int = aten::sub(%1212, %15) # torch/nn/functional.py:1992:19
          %size_prods.337 : int = prim::Loop(%1213, %8, %size_prods.336) # torch/nn/functional.py:1992:4
            block0(%i.85 : int, %size_prods.338 : int):
              %1217 : int = aten::add(%i.85, %15) # torch/nn/functional.py:1993:27
              %1218 : int = aten::__getitem__(%1210, %1217) # torch/nn/functional.py:1993:22
              %size_prods.339 : int = aten::mul(%size_prods.338, %1218) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.339)
          %1220 : bool = aten::eq(%size_prods.337, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1220) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.241 : Tensor = aten::batch_norm(%input.240, %1208, %1209, %1206, %1207, %1205, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.242 : Tensor = aten::relu_(%input.241) # torch/nn/functional.py:1117:17
      %1223 : Tensor[] = prim::ListConstruct(%input.229, %input.242)
      %out.38 : Tensor = aten::cat(%1223, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.38)
  %1225 : Tensor = prim::data(%out.36)
  %1226 : int[] = aten::size(%1225) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.13 : int, %num_channels.13 : int, %height.13 : int, %width.13 : int = prim::ListUnpack(%1226)
  %channels_per_group.13 : int = aten::floordiv(%num_channels.13, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %1232 : int[] = prim::ListConstruct(%batchsize.13, %15, %channels_per_group.13, %height.13, %width.13)
  %x.35 : Tensor = aten::view(%out.36, %1232) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %1234 : Tensor = aten::transpose(%x.35, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.36 : Tensor = aten::contiguous(%1234, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %1236 : int[] = prim::ListConstruct(%batchsize.13, %5, %height.13, %width.13)
  %input.238 : Tensor = aten::view(%x.36, %1236) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %1238 : int = prim::GetAttr[name="stride"](%960)
  %1239 : bool = aten::eq(%1238, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.39 : Tensor = prim::If(%1239) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %1241 : Tensor[] = aten::chunk(%input.238, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.14 : Tensor, %x2.14 : Tensor = prim::ListUnpack(%1241)
      %1244 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%960)
      %1245 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%1244)
      %1246 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1244)
      %1247 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%1244)
      %1248 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%1244)
      %1249 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%1244)
      %1250 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%1244)
      %1251 : Tensor = prim::GetAttr[name="weight"](%1245)
      %1252 : Tensor? = prim::GetAttr[name="bias"](%1245)
      %1253 : int[] = prim::ListConstruct(%7, %7)
      %1254 : int[] = prim::ListConstruct(%9, %9)
      %1255 : int[] = prim::ListConstruct(%7, %7)
      %input.243 : Tensor = aten::conv2d(%x2.14, %1251, %1252, %1253, %1254, %1255, %7) # torch/nn/modules/conv.py:415:15
      %1257 : int = aten::dim(%input.243) # torch/nn/modules/batchnorm.py:276:11
      %1258 : bool = aten::ne(%1257, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1258) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1259 : bool = prim::GetAttr[name="training"](%1246)
       = prim::If(%1259) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1260 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1246)
          %1261 : Tensor = aten::add(%1260, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1246, %1261)
          -> ()
        block1():
          -> ()
      %1262 : bool = prim::GetAttr[name="training"](%1246)
      %1263 : Tensor = prim::GetAttr[name="running_mean"](%1246)
      %1264 : Tensor = prim::GetAttr[name="running_var"](%1246)
      %1265 : Tensor = prim::GetAttr[name="weight"](%1246)
      %1266 : Tensor = prim::GetAttr[name="bias"](%1246)
       = prim::If(%1262) # torch/nn/functional.py:2011:4
        block0():
          %1267 : int[] = aten::size(%input.243) # torch/nn/functional.py:2012:27
          %size_prods.340 : int = aten::__getitem__(%1267, %9) # torch/nn/functional.py:1991:17
          %1269 : int = aten::len(%1267) # torch/nn/functional.py:1992:19
          %1270 : int = aten::sub(%1269, %15) # torch/nn/functional.py:1992:19
          %size_prods.341 : int = prim::Loop(%1270, %8, %size_prods.340) # torch/nn/functional.py:1992:4
            block0(%i.86 : int, %size_prods.342 : int):
              %1274 : int = aten::add(%i.86, %15) # torch/nn/functional.py:1993:27
              %1275 : int = aten::__getitem__(%1267, %1274) # torch/nn/functional.py:1993:22
              %size_prods.343 : int = aten::mul(%size_prods.342, %1275) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.343)
          %1277 : bool = aten::eq(%size_prods.341, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1277) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.244 : Tensor = aten::batch_norm(%input.243, %1265, %1266, %1263, %1264, %1262, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.245 : Tensor = aten::relu_(%input.244) # torch/nn/functional.py:1117:17
      %1280 : Tensor = prim::GetAttr[name="weight"](%1247)
      %1281 : Tensor? = prim::GetAttr[name="bias"](%1247)
      %1282 : int[] = prim::ListConstruct(%7, %7)
      %1283 : int[] = prim::ListConstruct(%7, %7)
      %1284 : int[] = prim::ListConstruct(%7, %7)
      %input.246 : Tensor = aten::conv2d(%input.245, %1280, %1281, %1282, %1283, %1284, %4) # torch/nn/modules/conv.py:415:15
      %1286 : int = aten::dim(%input.246) # torch/nn/modules/batchnorm.py:276:11
      %1287 : bool = aten::ne(%1286, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1287) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1288 : bool = prim::GetAttr[name="training"](%1248)
       = prim::If(%1288) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1289 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1248)
          %1290 : Tensor = aten::add(%1289, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1248, %1290)
          -> ()
        block1():
          -> ()
      %1291 : bool = prim::GetAttr[name="training"](%1248)
      %1292 : Tensor = prim::GetAttr[name="running_mean"](%1248)
      %1293 : Tensor = prim::GetAttr[name="running_var"](%1248)
      %1294 : Tensor = prim::GetAttr[name="weight"](%1248)
      %1295 : Tensor = prim::GetAttr[name="bias"](%1248)
       = prim::If(%1291) # torch/nn/functional.py:2011:4
        block0():
          %1296 : int[] = aten::size(%input.246) # torch/nn/functional.py:2012:27
          %size_prods.344 : int = aten::__getitem__(%1296, %9) # torch/nn/functional.py:1991:17
          %1298 : int = aten::len(%1296) # torch/nn/functional.py:1992:19
          %1299 : int = aten::sub(%1298, %15) # torch/nn/functional.py:1992:19
          %size_prods.345 : int = prim::Loop(%1299, %8, %size_prods.344) # torch/nn/functional.py:1992:4
            block0(%i.87 : int, %size_prods.346 : int):
              %1303 : int = aten::add(%i.87, %15) # torch/nn/functional.py:1993:27
              %1304 : int = aten::__getitem__(%1296, %1303) # torch/nn/functional.py:1993:22
              %size_prods.347 : int = aten::mul(%size_prods.346, %1304) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.347)
          %1306 : bool = aten::eq(%size_prods.345, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1306) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.247 : Tensor = aten::batch_norm(%input.246, %1294, %1295, %1292, %1293, %1291, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1308 : Tensor = prim::GetAttr[name="weight"](%1249)
      %1309 : Tensor? = prim::GetAttr[name="bias"](%1249)
      %1310 : int[] = prim::ListConstruct(%7, %7)
      %1311 : int[] = prim::ListConstruct(%9, %9)
      %1312 : int[] = prim::ListConstruct(%7, %7)
      %input.248 : Tensor = aten::conv2d(%input.247, %1308, %1309, %1310, %1311, %1312, %7) # torch/nn/modules/conv.py:415:15
      %1314 : int = aten::dim(%input.248) # torch/nn/modules/batchnorm.py:276:11
      %1315 : bool = aten::ne(%1314, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1315) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1316 : bool = prim::GetAttr[name="training"](%1250)
       = prim::If(%1316) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1317 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1250)
          %1318 : Tensor = aten::add(%1317, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1250, %1318)
          -> ()
        block1():
          -> ()
      %1319 : bool = prim::GetAttr[name="training"](%1250)
      %1320 : Tensor = prim::GetAttr[name="running_mean"](%1250)
      %1321 : Tensor = prim::GetAttr[name="running_var"](%1250)
      %1322 : Tensor = prim::GetAttr[name="weight"](%1250)
      %1323 : Tensor = prim::GetAttr[name="bias"](%1250)
       = prim::If(%1319) # torch/nn/functional.py:2011:4
        block0():
          %1324 : int[] = aten::size(%input.248) # torch/nn/functional.py:2012:27
          %size_prods.348 : int = aten::__getitem__(%1324, %9) # torch/nn/functional.py:1991:17
          %1326 : int = aten::len(%1324) # torch/nn/functional.py:1992:19
          %1327 : int = aten::sub(%1326, %15) # torch/nn/functional.py:1992:19
          %size_prods.349 : int = prim::Loop(%1327, %8, %size_prods.348) # torch/nn/functional.py:1992:4
            block0(%i.88 : int, %size_prods.350 : int):
              %1331 : int = aten::add(%i.88, %15) # torch/nn/functional.py:1993:27
              %1332 : int = aten::__getitem__(%1324, %1331) # torch/nn/functional.py:1993:22
              %size_prods.351 : int = aten::mul(%size_prods.350, %1332) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.351)
          %1334 : bool = aten::eq(%size_prods.349, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1334) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.249 : Tensor = aten::batch_norm(%input.248, %1322, %1323, %1320, %1321, %1319, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.250 : Tensor = aten::relu_(%input.249) # torch/nn/functional.py:1117:17
      %1337 : Tensor[] = prim::ListConstruct(%x1.14, %input.250)
      %out.40 : Tensor = aten::cat(%1337, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.40)
    block1():
      %1339 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%960)
      %1340 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%1339)
      %1341 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1339)
      %1342 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%1339)
      %1343 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%1339)
      %1344 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%1339)
      %1345 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%1339)
      %1346 : Tensor = prim::GetAttr[name="weight"](%1340)
      %1347 : Tensor? = prim::GetAttr[name="bias"](%1340)
      %1348 : int[] = prim::ListConstruct(%7, %7)
      %1349 : int[] = prim::ListConstruct(%9, %9)
      %1350 : int[] = prim::ListConstruct(%7, %7)
      %input.251 : Tensor = aten::conv2d(%input.238, %1346, %1347, %1348, %1349, %1350, %7) # torch/nn/modules/conv.py:415:15
      %1352 : int = aten::dim(%input.251) # torch/nn/modules/batchnorm.py:276:11
      %1353 : bool = aten::ne(%1352, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1353) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1354 : bool = prim::GetAttr[name="training"](%1341)
       = prim::If(%1354) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1355 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1341)
          %1356 : Tensor = aten::add(%1355, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1341, %1356)
          -> ()
        block1():
          -> ()
      %1357 : bool = prim::GetAttr[name="training"](%1341)
      %1358 : Tensor = prim::GetAttr[name="running_mean"](%1341)
      %1359 : Tensor = prim::GetAttr[name="running_var"](%1341)
      %1360 : Tensor = prim::GetAttr[name="weight"](%1341)
      %1361 : Tensor = prim::GetAttr[name="bias"](%1341)
       = prim::If(%1357) # torch/nn/functional.py:2011:4
        block0():
          %1362 : int[] = aten::size(%input.251) # torch/nn/functional.py:2012:27
          %size_prods.352 : int = aten::__getitem__(%1362, %9) # torch/nn/functional.py:1991:17
          %1364 : int = aten::len(%1362) # torch/nn/functional.py:1992:19
          %1365 : int = aten::sub(%1364, %15) # torch/nn/functional.py:1992:19
          %size_prods.353 : int = prim::Loop(%1365, %8, %size_prods.352) # torch/nn/functional.py:1992:4
            block0(%i.89 : int, %size_prods.354 : int):
              %1369 : int = aten::add(%i.89, %15) # torch/nn/functional.py:1993:27
              %1370 : int = aten::__getitem__(%1362, %1369) # torch/nn/functional.py:1993:22
              %size_prods.355 : int = aten::mul(%size_prods.354, %1370) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.355)
          %1372 : bool = aten::eq(%size_prods.353, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1372) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.252 : Tensor = aten::batch_norm(%input.251, %1360, %1361, %1358, %1359, %1357, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.253 : Tensor = aten::relu_(%input.252) # torch/nn/functional.py:1117:17
      %1375 : Tensor = prim::GetAttr[name="weight"](%1342)
      %1376 : Tensor? = prim::GetAttr[name="bias"](%1342)
      %1377 : int[] = prim::ListConstruct(%7, %7)
      %1378 : int[] = prim::ListConstruct(%7, %7)
      %1379 : int[] = prim::ListConstruct(%7, %7)
      %input.254 : Tensor = aten::conv2d(%input.253, %1375, %1376, %1377, %1378, %1379, %4) # torch/nn/modules/conv.py:415:15
      %1381 : int = aten::dim(%input.254) # torch/nn/modules/batchnorm.py:276:11
      %1382 : bool = aten::ne(%1381, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1382) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1383 : bool = prim::GetAttr[name="training"](%1343)
       = prim::If(%1383) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1384 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1343)
          %1385 : Tensor = aten::add(%1384, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1343, %1385)
          -> ()
        block1():
          -> ()
      %1386 : bool = prim::GetAttr[name="training"](%1343)
      %1387 : Tensor = prim::GetAttr[name="running_mean"](%1343)
      %1388 : Tensor = prim::GetAttr[name="running_var"](%1343)
      %1389 : Tensor = prim::GetAttr[name="weight"](%1343)
      %1390 : Tensor = prim::GetAttr[name="bias"](%1343)
       = prim::If(%1386) # torch/nn/functional.py:2011:4
        block0():
          %1391 : int[] = aten::size(%input.254) # torch/nn/functional.py:2012:27
          %size_prods.356 : int = aten::__getitem__(%1391, %9) # torch/nn/functional.py:1991:17
          %1393 : int = aten::len(%1391) # torch/nn/functional.py:1992:19
          %1394 : int = aten::sub(%1393, %15) # torch/nn/functional.py:1992:19
          %size_prods.357 : int = prim::Loop(%1394, %8, %size_prods.356) # torch/nn/functional.py:1992:4
            block0(%i.90 : int, %size_prods.358 : int):
              %1398 : int = aten::add(%i.90, %15) # torch/nn/functional.py:1993:27
              %1399 : int = aten::__getitem__(%1391, %1398) # torch/nn/functional.py:1993:22
              %size_prods.359 : int = aten::mul(%size_prods.358, %1399) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.359)
          %1401 : bool = aten::eq(%size_prods.357, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1401) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.256 : Tensor = aten::batch_norm(%input.254, %1389, %1390, %1387, %1388, %1386, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1403 : Tensor = prim::GetAttr[name="weight"](%1344)
      %1404 : Tensor? = prim::GetAttr[name="bias"](%1344)
      %1405 : int[] = prim::ListConstruct(%7, %7)
      %1406 : int[] = prim::ListConstruct(%9, %9)
      %1407 : int[] = prim::ListConstruct(%7, %7)
      %input.257 : Tensor = aten::conv2d(%input.256, %1403, %1404, %1405, %1406, %1407, %7) # torch/nn/modules/conv.py:415:15
      %1409 : int = aten::dim(%input.257) # torch/nn/modules/batchnorm.py:276:11
      %1410 : bool = aten::ne(%1409, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1410) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1411 : bool = prim::GetAttr[name="training"](%1345)
       = prim::If(%1411) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1412 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1345)
          %1413 : Tensor = aten::add(%1412, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1345, %1413)
          -> ()
        block1():
          -> ()
      %1414 : bool = prim::GetAttr[name="training"](%1345)
      %1415 : Tensor = prim::GetAttr[name="running_mean"](%1345)
      %1416 : Tensor = prim::GetAttr[name="running_var"](%1345)
      %1417 : Tensor = prim::GetAttr[name="weight"](%1345)
      %1418 : Tensor = prim::GetAttr[name="bias"](%1345)
       = prim::If(%1414) # torch/nn/functional.py:2011:4
        block0():
          %1419 : int[] = aten::size(%input.257) # torch/nn/functional.py:2012:27
          %size_prods.360 : int = aten::__getitem__(%1419, %9) # torch/nn/functional.py:1991:17
          %1421 : int = aten::len(%1419) # torch/nn/functional.py:1992:19
          %1422 : int = aten::sub(%1421, %15) # torch/nn/functional.py:1992:19
          %size_prods.361 : int = prim::Loop(%1422, %8, %size_prods.360) # torch/nn/functional.py:1992:4
            block0(%i.91 : int, %size_prods.362 : int):
              %1426 : int = aten::add(%i.91, %15) # torch/nn/functional.py:1993:27
              %1427 : int = aten::__getitem__(%1419, %1426) # torch/nn/functional.py:1993:22
              %size_prods.363 : int = aten::mul(%size_prods.362, %1427) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.363)
          %1429 : bool = aten::eq(%size_prods.361, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1429) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.258 : Tensor = aten::batch_norm(%input.257, %1417, %1418, %1415, %1416, %1414, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.259 : Tensor = aten::relu_(%input.258) # torch/nn/functional.py:1117:17
      %1432 : Tensor[] = prim::ListConstruct(%input.238, %input.259)
      %out.41 : Tensor = aten::cat(%1432, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.41)
  %1434 : Tensor = prim::data(%out.39)
  %1435 : int[] = aten::size(%1434) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.14 : int, %num_channels.14 : int, %height.14 : int, %width.14 : int = prim::ListUnpack(%1435)
  %channels_per_group.14 : int = aten::floordiv(%num_channels.14, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %1441 : int[] = prim::ListConstruct(%batchsize.14, %15, %channels_per_group.14, %height.14, %width.14)
  %x.37 : Tensor = aten::view(%out.39, %1441) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %1443 : Tensor = aten::transpose(%x.37, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.38 : Tensor = aten::contiguous(%1443, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %1445 : int[] = prim::ListConstruct(%batchsize.14, %5, %height.14, %width.14)
  %input.255 : Tensor = aten::view(%x.38, %1445) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %1447 : int = prim::GetAttr[name="stride"](%961)
  %1448 : bool = aten::eq(%1447, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.42 : Tensor = prim::If(%1448) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %1450 : Tensor[] = aten::chunk(%input.255, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.15 : Tensor, %x2.15 : Tensor = prim::ListUnpack(%1450)
      %1453 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%961)
      %1454 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%1453)
      %1455 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1453)
      %1456 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%1453)
      %1457 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%1453)
      %1458 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%1453)
      %1459 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%1453)
      %1460 : Tensor = prim::GetAttr[name="weight"](%1454)
      %1461 : Tensor? = prim::GetAttr[name="bias"](%1454)
      %1462 : int[] = prim::ListConstruct(%7, %7)
      %1463 : int[] = prim::ListConstruct(%9, %9)
      %1464 : int[] = prim::ListConstruct(%7, %7)
      %input.260 : Tensor = aten::conv2d(%x2.15, %1460, %1461, %1462, %1463, %1464, %7) # torch/nn/modules/conv.py:415:15
      %1466 : int = aten::dim(%input.260) # torch/nn/modules/batchnorm.py:276:11
      %1467 : bool = aten::ne(%1466, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1467) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1468 : bool = prim::GetAttr[name="training"](%1455)
       = prim::If(%1468) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1469 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1455)
          %1470 : Tensor = aten::add(%1469, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1455, %1470)
          -> ()
        block1():
          -> ()
      %1471 : bool = prim::GetAttr[name="training"](%1455)
      %1472 : Tensor = prim::GetAttr[name="running_mean"](%1455)
      %1473 : Tensor = prim::GetAttr[name="running_var"](%1455)
      %1474 : Tensor = prim::GetAttr[name="weight"](%1455)
      %1475 : Tensor = prim::GetAttr[name="bias"](%1455)
       = prim::If(%1471) # torch/nn/functional.py:2011:4
        block0():
          %1476 : int[] = aten::size(%input.260) # torch/nn/functional.py:2012:27
          %size_prods.364 : int = aten::__getitem__(%1476, %9) # torch/nn/functional.py:1991:17
          %1478 : int = aten::len(%1476) # torch/nn/functional.py:1992:19
          %1479 : int = aten::sub(%1478, %15) # torch/nn/functional.py:1992:19
          %size_prods.365 : int = prim::Loop(%1479, %8, %size_prods.364) # torch/nn/functional.py:1992:4
            block0(%i.92 : int, %size_prods.366 : int):
              %1483 : int = aten::add(%i.92, %15) # torch/nn/functional.py:1993:27
              %1484 : int = aten::__getitem__(%1476, %1483) # torch/nn/functional.py:1993:22
              %size_prods.367 : int = aten::mul(%size_prods.366, %1484) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.367)
          %1486 : bool = aten::eq(%size_prods.365, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1486) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.261 : Tensor = aten::batch_norm(%input.260, %1474, %1475, %1472, %1473, %1471, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.262 : Tensor = aten::relu_(%input.261) # torch/nn/functional.py:1117:17
      %1489 : Tensor = prim::GetAttr[name="weight"](%1456)
      %1490 : Tensor? = prim::GetAttr[name="bias"](%1456)
      %1491 : int[] = prim::ListConstruct(%7, %7)
      %1492 : int[] = prim::ListConstruct(%7, %7)
      %1493 : int[] = prim::ListConstruct(%7, %7)
      %input.263 : Tensor = aten::conv2d(%input.262, %1489, %1490, %1491, %1492, %1493, %4) # torch/nn/modules/conv.py:415:15
      %1495 : int = aten::dim(%input.263) # torch/nn/modules/batchnorm.py:276:11
      %1496 : bool = aten::ne(%1495, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1496) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1497 : bool = prim::GetAttr[name="training"](%1457)
       = prim::If(%1497) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1498 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1457)
          %1499 : Tensor = aten::add(%1498, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1457, %1499)
          -> ()
        block1():
          -> ()
      %1500 : bool = prim::GetAttr[name="training"](%1457)
      %1501 : Tensor = prim::GetAttr[name="running_mean"](%1457)
      %1502 : Tensor = prim::GetAttr[name="running_var"](%1457)
      %1503 : Tensor = prim::GetAttr[name="weight"](%1457)
      %1504 : Tensor = prim::GetAttr[name="bias"](%1457)
       = prim::If(%1500) # torch/nn/functional.py:2011:4
        block0():
          %1505 : int[] = aten::size(%input.263) # torch/nn/functional.py:2012:27
          %size_prods.368 : int = aten::__getitem__(%1505, %9) # torch/nn/functional.py:1991:17
          %1507 : int = aten::len(%1505) # torch/nn/functional.py:1992:19
          %1508 : int = aten::sub(%1507, %15) # torch/nn/functional.py:1992:19
          %size_prods.369 : int = prim::Loop(%1508, %8, %size_prods.368) # torch/nn/functional.py:1992:4
            block0(%i.93 : int, %size_prods.370 : int):
              %1512 : int = aten::add(%i.93, %15) # torch/nn/functional.py:1993:27
              %1513 : int = aten::__getitem__(%1505, %1512) # torch/nn/functional.py:1993:22
              %size_prods.371 : int = aten::mul(%size_prods.370, %1513) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.371)
          %1515 : bool = aten::eq(%size_prods.369, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1515) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.264 : Tensor = aten::batch_norm(%input.263, %1503, %1504, %1501, %1502, %1500, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1517 : Tensor = prim::GetAttr[name="weight"](%1458)
      %1518 : Tensor? = prim::GetAttr[name="bias"](%1458)
      %1519 : int[] = prim::ListConstruct(%7, %7)
      %1520 : int[] = prim::ListConstruct(%9, %9)
      %1521 : int[] = prim::ListConstruct(%7, %7)
      %input.265 : Tensor = aten::conv2d(%input.264, %1517, %1518, %1519, %1520, %1521, %7) # torch/nn/modules/conv.py:415:15
      %1523 : int = aten::dim(%input.265) # torch/nn/modules/batchnorm.py:276:11
      %1524 : bool = aten::ne(%1523, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1524) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1525 : bool = prim::GetAttr[name="training"](%1459)
       = prim::If(%1525) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1526 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1459)
          %1527 : Tensor = aten::add(%1526, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1459, %1527)
          -> ()
        block1():
          -> ()
      %1528 : bool = prim::GetAttr[name="training"](%1459)
      %1529 : Tensor = prim::GetAttr[name="running_mean"](%1459)
      %1530 : Tensor = prim::GetAttr[name="running_var"](%1459)
      %1531 : Tensor = prim::GetAttr[name="weight"](%1459)
      %1532 : Tensor = prim::GetAttr[name="bias"](%1459)
       = prim::If(%1528) # torch/nn/functional.py:2011:4
        block0():
          %1533 : int[] = aten::size(%input.265) # torch/nn/functional.py:2012:27
          %size_prods.372 : int = aten::__getitem__(%1533, %9) # torch/nn/functional.py:1991:17
          %1535 : int = aten::len(%1533) # torch/nn/functional.py:1992:19
          %1536 : int = aten::sub(%1535, %15) # torch/nn/functional.py:1992:19
          %size_prods.373 : int = prim::Loop(%1536, %8, %size_prods.372) # torch/nn/functional.py:1992:4
            block0(%i.94 : int, %size_prods.374 : int):
              %1540 : int = aten::add(%i.94, %15) # torch/nn/functional.py:1993:27
              %1541 : int = aten::__getitem__(%1533, %1540) # torch/nn/functional.py:1993:22
              %size_prods.375 : int = aten::mul(%size_prods.374, %1541) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.375)
          %1543 : bool = aten::eq(%size_prods.373, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1543) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.266 : Tensor = aten::batch_norm(%input.265, %1531, %1532, %1529, %1530, %1528, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.267 : Tensor = aten::relu_(%input.266) # torch/nn/functional.py:1117:17
      %1546 : Tensor[] = prim::ListConstruct(%x1.15, %input.267)
      %out.43 : Tensor = aten::cat(%1546, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.43)
    block1():
      %1548 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%961)
      %1549 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%1548)
      %1550 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1548)
      %1551 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%1548)
      %1552 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%1548)
      %1553 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%1548)
      %1554 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%1548)
      %1555 : Tensor = prim::GetAttr[name="weight"](%1549)
      %1556 : Tensor? = prim::GetAttr[name="bias"](%1549)
      %1557 : int[] = prim::ListConstruct(%7, %7)
      %1558 : int[] = prim::ListConstruct(%9, %9)
      %1559 : int[] = prim::ListConstruct(%7, %7)
      %input.268 : Tensor = aten::conv2d(%input.255, %1555, %1556, %1557, %1558, %1559, %7) # torch/nn/modules/conv.py:415:15
      %1561 : int = aten::dim(%input.268) # torch/nn/modules/batchnorm.py:276:11
      %1562 : bool = aten::ne(%1561, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1562) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1563 : bool = prim::GetAttr[name="training"](%1550)
       = prim::If(%1563) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1564 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1550)
          %1565 : Tensor = aten::add(%1564, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1550, %1565)
          -> ()
        block1():
          -> ()
      %1566 : bool = prim::GetAttr[name="training"](%1550)
      %1567 : Tensor = prim::GetAttr[name="running_mean"](%1550)
      %1568 : Tensor = prim::GetAttr[name="running_var"](%1550)
      %1569 : Tensor = prim::GetAttr[name="weight"](%1550)
      %1570 : Tensor = prim::GetAttr[name="bias"](%1550)
       = prim::If(%1566) # torch/nn/functional.py:2011:4
        block0():
          %1571 : int[] = aten::size(%input.268) # torch/nn/functional.py:2012:27
          %size_prods.376 : int = aten::__getitem__(%1571, %9) # torch/nn/functional.py:1991:17
          %1573 : int = aten::len(%1571) # torch/nn/functional.py:1992:19
          %1574 : int = aten::sub(%1573, %15) # torch/nn/functional.py:1992:19
          %size_prods.377 : int = prim::Loop(%1574, %8, %size_prods.376) # torch/nn/functional.py:1992:4
            block0(%i.95 : int, %size_prods.378 : int):
              %1578 : int = aten::add(%i.95, %15) # torch/nn/functional.py:1993:27
              %1579 : int = aten::__getitem__(%1571, %1578) # torch/nn/functional.py:1993:22
              %size_prods.379 : int = aten::mul(%size_prods.378, %1579) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.379)
          %1581 : bool = aten::eq(%size_prods.377, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1581) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.269 : Tensor = aten::batch_norm(%input.268, %1569, %1570, %1567, %1568, %1566, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.270 : Tensor = aten::relu_(%input.269) # torch/nn/functional.py:1117:17
      %1584 : Tensor = prim::GetAttr[name="weight"](%1551)
      %1585 : Tensor? = prim::GetAttr[name="bias"](%1551)
      %1586 : int[] = prim::ListConstruct(%7, %7)
      %1587 : int[] = prim::ListConstruct(%7, %7)
      %1588 : int[] = prim::ListConstruct(%7, %7)
      %input.271 : Tensor = aten::conv2d(%input.270, %1584, %1585, %1586, %1587, %1588, %4) # torch/nn/modules/conv.py:415:15
      %1590 : int = aten::dim(%input.271) # torch/nn/modules/batchnorm.py:276:11
      %1591 : bool = aten::ne(%1590, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1591) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1592 : bool = prim::GetAttr[name="training"](%1552)
       = prim::If(%1592) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1593 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1552)
          %1594 : Tensor = aten::add(%1593, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1552, %1594)
          -> ()
        block1():
          -> ()
      %1595 : bool = prim::GetAttr[name="training"](%1552)
      %1596 : Tensor = prim::GetAttr[name="running_mean"](%1552)
      %1597 : Tensor = prim::GetAttr[name="running_var"](%1552)
      %1598 : Tensor = prim::GetAttr[name="weight"](%1552)
      %1599 : Tensor = prim::GetAttr[name="bias"](%1552)
       = prim::If(%1595) # torch/nn/functional.py:2011:4
        block0():
          %1600 : int[] = aten::size(%input.271) # torch/nn/functional.py:2012:27
          %size_prods.380 : int = aten::__getitem__(%1600, %9) # torch/nn/functional.py:1991:17
          %1602 : int = aten::len(%1600) # torch/nn/functional.py:1992:19
          %1603 : int = aten::sub(%1602, %15) # torch/nn/functional.py:1992:19
          %size_prods.381 : int = prim::Loop(%1603, %8, %size_prods.380) # torch/nn/functional.py:1992:4
            block0(%i.96 : int, %size_prods.382 : int):
              %1607 : int = aten::add(%i.96, %15) # torch/nn/functional.py:1993:27
              %1608 : int = aten::__getitem__(%1600, %1607) # torch/nn/functional.py:1993:22
              %size_prods.383 : int = aten::mul(%size_prods.382, %1608) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.383)
          %1610 : bool = aten::eq(%size_prods.381, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1610) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.76 : Tensor = aten::batch_norm(%input.271, %1598, %1599, %1596, %1597, %1595, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1612 : Tensor = prim::GetAttr[name="weight"](%1553)
      %1613 : Tensor? = prim::GetAttr[name="bias"](%1553)
      %1614 : int[] = prim::ListConstruct(%7, %7)
      %1615 : int[] = prim::ListConstruct(%9, %9)
      %1616 : int[] = prim::ListConstruct(%7, %7)
      %input.77 : Tensor = aten::conv2d(%input.76, %1612, %1613, %1614, %1615, %1616, %7) # torch/nn/modules/conv.py:415:15
      %1618 : int = aten::dim(%input.77) # torch/nn/modules/batchnorm.py:276:11
      %1619 : bool = aten::ne(%1618, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1619) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1620 : bool = prim::GetAttr[name="training"](%1554)
       = prim::If(%1620) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1621 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1554)
          %1622 : Tensor = aten::add(%1621, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1554, %1622)
          -> ()
        block1():
          -> ()
      %1623 : bool = prim::GetAttr[name="training"](%1554)
      %1624 : Tensor = prim::GetAttr[name="running_mean"](%1554)
      %1625 : Tensor = prim::GetAttr[name="running_var"](%1554)
      %1626 : Tensor = prim::GetAttr[name="weight"](%1554)
      %1627 : Tensor = prim::GetAttr[name="bias"](%1554)
       = prim::If(%1623) # torch/nn/functional.py:2011:4
        block0():
          %1628 : int[] = aten::size(%input.77) # torch/nn/functional.py:2012:27
          %size_prods.384 : int = aten::__getitem__(%1628, %9) # torch/nn/functional.py:1991:17
          %1630 : int = aten::len(%1628) # torch/nn/functional.py:1992:19
          %1631 : int = aten::sub(%1630, %15) # torch/nn/functional.py:1992:19
          %size_prods.385 : int = prim::Loop(%1631, %8, %size_prods.384) # torch/nn/functional.py:1992:4
            block0(%i.97 : int, %size_prods.386 : int):
              %1635 : int = aten::add(%i.97, %15) # torch/nn/functional.py:1993:27
              %1636 : int = aten::__getitem__(%1628, %1635) # torch/nn/functional.py:1993:22
              %size_prods.387 : int = aten::mul(%size_prods.386, %1636) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.387)
          %1638 : bool = aten::eq(%size_prods.385, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1638) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.78 : Tensor = aten::batch_norm(%input.77, %1626, %1627, %1624, %1625, %1623, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.79 : Tensor = aten::relu_(%input.78) # torch/nn/functional.py:1117:17
      %1641 : Tensor[] = prim::ListConstruct(%input.255, %input.79)
      %out.44 : Tensor = aten::cat(%1641, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.44)
  %1643 : Tensor = prim::data(%out.42)
  %1644 : int[] = aten::size(%1643) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.15 : int, %num_channels.15 : int, %height.15 : int, %width.15 : int = prim::ListUnpack(%1644)
  %channels_per_group.15 : int = aten::floordiv(%num_channels.15, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %1650 : int[] = prim::ListConstruct(%batchsize.15, %15, %channels_per_group.15, %height.15, %width.15)
  %x.39 : Tensor = aten::view(%out.42, %1650) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %1652 : Tensor = aten::transpose(%x.39, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.40 : Tensor = aten::contiguous(%1652, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %1654 : int[] = prim::ListConstruct(%batchsize.15, %5, %height.15, %width.15)
  %input.272 : Tensor = aten::view(%x.40, %1654) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %1656 : int = prim::GetAttr[name="stride"](%962)
  %1657 : bool = aten::eq(%1656, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.15 : Tensor = prim::If(%1657) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %1659 : Tensor[] = aten::chunk(%input.272, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.5 : Tensor, %x2.5 : Tensor = prim::ListUnpack(%1659)
      %1662 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%962)
      %1663 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%1662)
      %1664 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1662)
      %1665 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%1662)
      %1666 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%1662)
      %1667 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%1662)
      %1668 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%1662)
      %1669 : Tensor = prim::GetAttr[name="weight"](%1663)
      %1670 : Tensor? = prim::GetAttr[name="bias"](%1663)
      %1671 : int[] = prim::ListConstruct(%7, %7)
      %1672 : int[] = prim::ListConstruct(%9, %9)
      %1673 : int[] = prim::ListConstruct(%7, %7)
      %input.80 : Tensor = aten::conv2d(%x2.5, %1669, %1670, %1671, %1672, %1673, %7) # torch/nn/modules/conv.py:415:15
      %1675 : int = aten::dim(%input.80) # torch/nn/modules/batchnorm.py:276:11
      %1676 : bool = aten::ne(%1675, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1676) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1677 : bool = prim::GetAttr[name="training"](%1664)
       = prim::If(%1677) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1678 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1664)
          %1679 : Tensor = aten::add(%1678, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1664, %1679)
          -> ()
        block1():
          -> ()
      %1680 : bool = prim::GetAttr[name="training"](%1664)
      %1681 : Tensor = prim::GetAttr[name="running_mean"](%1664)
      %1682 : Tensor = prim::GetAttr[name="running_var"](%1664)
      %1683 : Tensor = prim::GetAttr[name="weight"](%1664)
      %1684 : Tensor = prim::GetAttr[name="bias"](%1664)
       = prim::If(%1680) # torch/nn/functional.py:2011:4
        block0():
          %1685 : int[] = aten::size(%input.80) # torch/nn/functional.py:2012:27
          %size_prods.104 : int = aten::__getitem__(%1685, %9) # torch/nn/functional.py:1991:17
          %1687 : int = aten::len(%1685) # torch/nn/functional.py:1992:19
          %1688 : int = aten::sub(%1687, %15) # torch/nn/functional.py:1992:19
          %size_prods.105 : int = prim::Loop(%1688, %8, %size_prods.104) # torch/nn/functional.py:1992:4
            block0(%i.27 : int, %size_prods.106 : int):
              %1692 : int = aten::add(%i.27, %15) # torch/nn/functional.py:1993:27
              %1693 : int = aten::__getitem__(%1685, %1692) # torch/nn/functional.py:1993:22
              %size_prods.107 : int = aten::mul(%size_prods.106, %1693) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.107)
          %1695 : bool = aten::eq(%size_prods.105, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1695) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.81 : Tensor = aten::batch_norm(%input.80, %1683, %1684, %1681, %1682, %1680, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.82 : Tensor = aten::relu_(%input.81) # torch/nn/functional.py:1117:17
      %1698 : Tensor = prim::GetAttr[name="weight"](%1665)
      %1699 : Tensor? = prim::GetAttr[name="bias"](%1665)
      %1700 : int[] = prim::ListConstruct(%7, %7)
      %1701 : int[] = prim::ListConstruct(%7, %7)
      %1702 : int[] = prim::ListConstruct(%7, %7)
      %input.83 : Tensor = aten::conv2d(%input.82, %1698, %1699, %1700, %1701, %1702, %4) # torch/nn/modules/conv.py:415:15
      %1704 : int = aten::dim(%input.83) # torch/nn/modules/batchnorm.py:276:11
      %1705 : bool = aten::ne(%1704, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1705) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1706 : bool = prim::GetAttr[name="training"](%1666)
       = prim::If(%1706) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1707 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1666)
          %1708 : Tensor = aten::add(%1707, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1666, %1708)
          -> ()
        block1():
          -> ()
      %1709 : bool = prim::GetAttr[name="training"](%1666)
      %1710 : Tensor = prim::GetAttr[name="running_mean"](%1666)
      %1711 : Tensor = prim::GetAttr[name="running_var"](%1666)
      %1712 : Tensor = prim::GetAttr[name="weight"](%1666)
      %1713 : Tensor = prim::GetAttr[name="bias"](%1666)
       = prim::If(%1709) # torch/nn/functional.py:2011:4
        block0():
          %1714 : int[] = aten::size(%input.83) # torch/nn/functional.py:2012:27
          %size_prods.108 : int = aten::__getitem__(%1714, %9) # torch/nn/functional.py:1991:17
          %1716 : int = aten::len(%1714) # torch/nn/functional.py:1992:19
          %1717 : int = aten::sub(%1716, %15) # torch/nn/functional.py:1992:19
          %size_prods.109 : int = prim::Loop(%1717, %8, %size_prods.108) # torch/nn/functional.py:1992:4
            block0(%i.28 : int, %size_prods.110 : int):
              %1721 : int = aten::add(%i.28, %15) # torch/nn/functional.py:1993:27
              %1722 : int = aten::__getitem__(%1714, %1721) # torch/nn/functional.py:1993:22
              %size_prods.111 : int = aten::mul(%size_prods.110, %1722) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.111)
          %1724 : bool = aten::eq(%size_prods.109, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1724) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.84 : Tensor = aten::batch_norm(%input.83, %1712, %1713, %1710, %1711, %1709, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1726 : Tensor = prim::GetAttr[name="weight"](%1667)
      %1727 : Tensor? = prim::GetAttr[name="bias"](%1667)
      %1728 : int[] = prim::ListConstruct(%7, %7)
      %1729 : int[] = prim::ListConstruct(%9, %9)
      %1730 : int[] = prim::ListConstruct(%7, %7)
      %input.85 : Tensor = aten::conv2d(%input.84, %1726, %1727, %1728, %1729, %1730, %7) # torch/nn/modules/conv.py:415:15
      %1732 : int = aten::dim(%input.85) # torch/nn/modules/batchnorm.py:276:11
      %1733 : bool = aten::ne(%1732, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1733) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1734 : bool = prim::GetAttr[name="training"](%1668)
       = prim::If(%1734) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1735 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1668)
          %1736 : Tensor = aten::add(%1735, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1668, %1736)
          -> ()
        block1():
          -> ()
      %1737 : bool = prim::GetAttr[name="training"](%1668)
      %1738 : Tensor = prim::GetAttr[name="running_mean"](%1668)
      %1739 : Tensor = prim::GetAttr[name="running_var"](%1668)
      %1740 : Tensor = prim::GetAttr[name="weight"](%1668)
      %1741 : Tensor = prim::GetAttr[name="bias"](%1668)
       = prim::If(%1737) # torch/nn/functional.py:2011:4
        block0():
          %1742 : int[] = aten::size(%input.85) # torch/nn/functional.py:2012:27
          %size_prods.112 : int = aten::__getitem__(%1742, %9) # torch/nn/functional.py:1991:17
          %1744 : int = aten::len(%1742) # torch/nn/functional.py:1992:19
          %1745 : int = aten::sub(%1744, %15) # torch/nn/functional.py:1992:19
          %size_prods.113 : int = prim::Loop(%1745, %8, %size_prods.112) # torch/nn/functional.py:1992:4
            block0(%i.29 : int, %size_prods.114 : int):
              %1749 : int = aten::add(%i.29, %15) # torch/nn/functional.py:1993:27
              %1750 : int = aten::__getitem__(%1742, %1749) # torch/nn/functional.py:1993:22
              %size_prods.115 : int = aten::mul(%size_prods.114, %1750) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.115)
          %1752 : bool = aten::eq(%size_prods.113, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1752) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.86 : Tensor = aten::batch_norm(%input.85, %1740, %1741, %1738, %1739, %1737, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.87 : Tensor = aten::relu_(%input.86) # torch/nn/functional.py:1117:17
      %1755 : Tensor[] = prim::ListConstruct(%x1.5, %input.87)
      %out.13 : Tensor = aten::cat(%1755, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.13)
    block1():
      %1757 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%962)
      %1758 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%1757)
      %1759 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1757)
      %1760 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%1757)
      %1761 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%1757)
      %1762 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%1757)
      %1763 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%1757)
      %1764 : Tensor = prim::GetAttr[name="weight"](%1758)
      %1765 : Tensor? = prim::GetAttr[name="bias"](%1758)
      %1766 : int[] = prim::ListConstruct(%7, %7)
      %1767 : int[] = prim::ListConstruct(%9, %9)
      %1768 : int[] = prim::ListConstruct(%7, %7)
      %input.88 : Tensor = aten::conv2d(%input.272, %1764, %1765, %1766, %1767, %1768, %7) # torch/nn/modules/conv.py:415:15
      %1770 : int = aten::dim(%input.88) # torch/nn/modules/batchnorm.py:276:11
      %1771 : bool = aten::ne(%1770, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1771) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1772 : bool = prim::GetAttr[name="training"](%1759)
       = prim::If(%1772) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1773 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1759)
          %1774 : Tensor = aten::add(%1773, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1759, %1774)
          -> ()
        block1():
          -> ()
      %1775 : bool = prim::GetAttr[name="training"](%1759)
      %1776 : Tensor = prim::GetAttr[name="running_mean"](%1759)
      %1777 : Tensor = prim::GetAttr[name="running_var"](%1759)
      %1778 : Tensor = prim::GetAttr[name="weight"](%1759)
      %1779 : Tensor = prim::GetAttr[name="bias"](%1759)
       = prim::If(%1775) # torch/nn/functional.py:2011:4
        block0():
          %1780 : int[] = aten::size(%input.88) # torch/nn/functional.py:2012:27
          %size_prods.116 : int = aten::__getitem__(%1780, %9) # torch/nn/functional.py:1991:17
          %1782 : int = aten::len(%1780) # torch/nn/functional.py:1992:19
          %1783 : int = aten::sub(%1782, %15) # torch/nn/functional.py:1992:19
          %size_prods.117 : int = prim::Loop(%1783, %8, %size_prods.116) # torch/nn/functional.py:1992:4
            block0(%i.30 : int, %size_prods.118 : int):
              %1787 : int = aten::add(%i.30, %15) # torch/nn/functional.py:1993:27
              %1788 : int = aten::__getitem__(%1780, %1787) # torch/nn/functional.py:1993:22
              %size_prods.119 : int = aten::mul(%size_prods.118, %1788) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.119)
          %1790 : bool = aten::eq(%size_prods.117, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1790) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.89 : Tensor = aten::batch_norm(%input.88, %1778, %1779, %1776, %1777, %1775, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.90 : Tensor = aten::relu_(%input.89) # torch/nn/functional.py:1117:17
      %1793 : Tensor = prim::GetAttr[name="weight"](%1760)
      %1794 : Tensor? = prim::GetAttr[name="bias"](%1760)
      %1795 : int[] = prim::ListConstruct(%7, %7)
      %1796 : int[] = prim::ListConstruct(%7, %7)
      %1797 : int[] = prim::ListConstruct(%7, %7)
      %input.91 : Tensor = aten::conv2d(%input.90, %1793, %1794, %1795, %1796, %1797, %4) # torch/nn/modules/conv.py:415:15
      %1799 : int = aten::dim(%input.91) # torch/nn/modules/batchnorm.py:276:11
      %1800 : bool = aten::ne(%1799, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1800) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1801 : bool = prim::GetAttr[name="training"](%1761)
       = prim::If(%1801) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1802 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1761)
          %1803 : Tensor = aten::add(%1802, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1761, %1803)
          -> ()
        block1():
          -> ()
      %1804 : bool = prim::GetAttr[name="training"](%1761)
      %1805 : Tensor = prim::GetAttr[name="running_mean"](%1761)
      %1806 : Tensor = prim::GetAttr[name="running_var"](%1761)
      %1807 : Tensor = prim::GetAttr[name="weight"](%1761)
      %1808 : Tensor = prim::GetAttr[name="bias"](%1761)
       = prim::If(%1804) # torch/nn/functional.py:2011:4
        block0():
          %1809 : int[] = aten::size(%input.91) # torch/nn/functional.py:2012:27
          %size_prods.120 : int = aten::__getitem__(%1809, %9) # torch/nn/functional.py:1991:17
          %1811 : int = aten::len(%1809) # torch/nn/functional.py:1992:19
          %1812 : int = aten::sub(%1811, %15) # torch/nn/functional.py:1992:19
          %size_prods.121 : int = prim::Loop(%1812, %8, %size_prods.120) # torch/nn/functional.py:1992:4
            block0(%i.31 : int, %size_prods.122 : int):
              %1816 : int = aten::add(%i.31, %15) # torch/nn/functional.py:1993:27
              %1817 : int = aten::__getitem__(%1809, %1816) # torch/nn/functional.py:1993:22
              %size_prods.123 : int = aten::mul(%size_prods.122, %1817) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.123)
          %1819 : bool = aten::eq(%size_prods.121, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1819) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.92 : Tensor = aten::batch_norm(%input.91, %1807, %1808, %1805, %1806, %1804, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1821 : Tensor = prim::GetAttr[name="weight"](%1762)
      %1822 : Tensor? = prim::GetAttr[name="bias"](%1762)
      %1823 : int[] = prim::ListConstruct(%7, %7)
      %1824 : int[] = prim::ListConstruct(%9, %9)
      %1825 : int[] = prim::ListConstruct(%7, %7)
      %input.93 : Tensor = aten::conv2d(%input.92, %1821, %1822, %1823, %1824, %1825, %7) # torch/nn/modules/conv.py:415:15
      %1827 : int = aten::dim(%input.93) # torch/nn/modules/batchnorm.py:276:11
      %1828 : bool = aten::ne(%1827, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1828) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1829 : bool = prim::GetAttr[name="training"](%1763)
       = prim::If(%1829) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1830 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1763)
          %1831 : Tensor = aten::add(%1830, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1763, %1831)
          -> ()
        block1():
          -> ()
      %1832 : bool = prim::GetAttr[name="training"](%1763)
      %1833 : Tensor = prim::GetAttr[name="running_mean"](%1763)
      %1834 : Tensor = prim::GetAttr[name="running_var"](%1763)
      %1835 : Tensor = prim::GetAttr[name="weight"](%1763)
      %1836 : Tensor = prim::GetAttr[name="bias"](%1763)
       = prim::If(%1832) # torch/nn/functional.py:2011:4
        block0():
          %1837 : int[] = aten::size(%input.93) # torch/nn/functional.py:2012:27
          %size_prods.124 : int = aten::__getitem__(%1837, %9) # torch/nn/functional.py:1991:17
          %1839 : int = aten::len(%1837) # torch/nn/functional.py:1992:19
          %1840 : int = aten::sub(%1839, %15) # torch/nn/functional.py:1992:19
          %size_prods.125 : int = prim::Loop(%1840, %8, %size_prods.124) # torch/nn/functional.py:1992:4
            block0(%i.32 : int, %size_prods.126 : int):
              %1844 : int = aten::add(%i.32, %15) # torch/nn/functional.py:1993:27
              %1845 : int = aten::__getitem__(%1837, %1844) # torch/nn/functional.py:1993:22
              %size_prods.127 : int = aten::mul(%size_prods.126, %1845) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.127)
          %1847 : bool = aten::eq(%size_prods.125, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1847) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.94 : Tensor = aten::batch_norm(%input.93, %1835, %1836, %1833, %1834, %1832, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.95 : Tensor = aten::relu_(%input.94) # torch/nn/functional.py:1117:17
      %1850 : Tensor[] = prim::ListConstruct(%input.272, %input.95)
      %out.14 : Tensor = aten::cat(%1850, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.14)
  %1852 : Tensor = prim::data(%out.15)
  %1853 : int[] = aten::size(%1852) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.5 : int, %num_channels.5 : int, %height.5 : int, %width.5 : int = prim::ListUnpack(%1853)
  %channels_per_group.5 : int = aten::floordiv(%num_channels.5, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %1859 : int[] = prim::ListConstruct(%batchsize.5, %15, %channels_per_group.5, %height.5, %width.5)
  %x.12 : Tensor = aten::view(%out.15, %1859) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %1861 : Tensor = aten::transpose(%x.12, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.13 : Tensor = aten::contiguous(%1861, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %1863 : int[] = prim::ListConstruct(%batchsize.5, %5, %height.5, %width.5)
  %input.289 : Tensor = aten::view(%x.13, %1863) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %1865 : int = prim::GetAttr[name="stride"](%963)
  %1866 : bool = aten::eq(%1865, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.18 : Tensor = prim::If(%1866) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %1868 : Tensor[] = aten::chunk(%input.289, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.6 : Tensor, %x2.6 : Tensor = prim::ListUnpack(%1868)
      %1871 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%963)
      %1872 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%1871)
      %1873 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1871)
      %1874 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%1871)
      %1875 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%1871)
      %1876 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%1871)
      %1877 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%1871)
      %1878 : Tensor = prim::GetAttr[name="weight"](%1872)
      %1879 : Tensor? = prim::GetAttr[name="bias"](%1872)
      %1880 : int[] = prim::ListConstruct(%7, %7)
      %1881 : int[] = prim::ListConstruct(%9, %9)
      %1882 : int[] = prim::ListConstruct(%7, %7)
      %input.96 : Tensor = aten::conv2d(%x2.6, %1878, %1879, %1880, %1881, %1882, %7) # torch/nn/modules/conv.py:415:15
      %1884 : int = aten::dim(%input.96) # torch/nn/modules/batchnorm.py:276:11
      %1885 : bool = aten::ne(%1884, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1885) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1886 : bool = prim::GetAttr[name="training"](%1873)
       = prim::If(%1886) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1887 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1873)
          %1888 : Tensor = aten::add(%1887, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1873, %1888)
          -> ()
        block1():
          -> ()
      %1889 : bool = prim::GetAttr[name="training"](%1873)
      %1890 : Tensor = prim::GetAttr[name="running_mean"](%1873)
      %1891 : Tensor = prim::GetAttr[name="running_var"](%1873)
      %1892 : Tensor = prim::GetAttr[name="weight"](%1873)
      %1893 : Tensor = prim::GetAttr[name="bias"](%1873)
       = prim::If(%1889) # torch/nn/functional.py:2011:4
        block0():
          %1894 : int[] = aten::size(%input.96) # torch/nn/functional.py:2012:27
          %size_prods.128 : int = aten::__getitem__(%1894, %9) # torch/nn/functional.py:1991:17
          %1896 : int = aten::len(%1894) # torch/nn/functional.py:1992:19
          %1897 : int = aten::sub(%1896, %15) # torch/nn/functional.py:1992:19
          %size_prods.129 : int = prim::Loop(%1897, %8, %size_prods.128) # torch/nn/functional.py:1992:4
            block0(%i.33 : int, %size_prods.130 : int):
              %1901 : int = aten::add(%i.33, %15) # torch/nn/functional.py:1993:27
              %1902 : int = aten::__getitem__(%1894, %1901) # torch/nn/functional.py:1993:22
              %size_prods.131 : int = aten::mul(%size_prods.130, %1902) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.131)
          %1904 : bool = aten::eq(%size_prods.129, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1904) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.97 : Tensor = aten::batch_norm(%input.96, %1892, %1893, %1890, %1891, %1889, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.98 : Tensor = aten::relu_(%input.97) # torch/nn/functional.py:1117:17
      %1907 : Tensor = prim::GetAttr[name="weight"](%1874)
      %1908 : Tensor? = prim::GetAttr[name="bias"](%1874)
      %1909 : int[] = prim::ListConstruct(%7, %7)
      %1910 : int[] = prim::ListConstruct(%7, %7)
      %1911 : int[] = prim::ListConstruct(%7, %7)
      %input.99 : Tensor = aten::conv2d(%input.98, %1907, %1908, %1909, %1910, %1911, %4) # torch/nn/modules/conv.py:415:15
      %1913 : int = aten::dim(%input.99) # torch/nn/modules/batchnorm.py:276:11
      %1914 : bool = aten::ne(%1913, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1914) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1915 : bool = prim::GetAttr[name="training"](%1875)
       = prim::If(%1915) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1916 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1875)
          %1917 : Tensor = aten::add(%1916, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1875, %1917)
          -> ()
        block1():
          -> ()
      %1918 : bool = prim::GetAttr[name="training"](%1875)
      %1919 : Tensor = prim::GetAttr[name="running_mean"](%1875)
      %1920 : Tensor = prim::GetAttr[name="running_var"](%1875)
      %1921 : Tensor = prim::GetAttr[name="weight"](%1875)
      %1922 : Tensor = prim::GetAttr[name="bias"](%1875)
       = prim::If(%1918) # torch/nn/functional.py:2011:4
        block0():
          %1923 : int[] = aten::size(%input.99) # torch/nn/functional.py:2012:27
          %size_prods.132 : int = aten::__getitem__(%1923, %9) # torch/nn/functional.py:1991:17
          %1925 : int = aten::len(%1923) # torch/nn/functional.py:1992:19
          %1926 : int = aten::sub(%1925, %15) # torch/nn/functional.py:1992:19
          %size_prods.133 : int = prim::Loop(%1926, %8, %size_prods.132) # torch/nn/functional.py:1992:4
            block0(%i.34 : int, %size_prods.134 : int):
              %1930 : int = aten::add(%i.34, %15) # torch/nn/functional.py:1993:27
              %1931 : int = aten::__getitem__(%1923, %1930) # torch/nn/functional.py:1993:22
              %size_prods.135 : int = aten::mul(%size_prods.134, %1931) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.135)
          %1933 : bool = aten::eq(%size_prods.133, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1933) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.100 : Tensor = aten::batch_norm(%input.99, %1921, %1922, %1919, %1920, %1918, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %1935 : Tensor = prim::GetAttr[name="weight"](%1876)
      %1936 : Tensor? = prim::GetAttr[name="bias"](%1876)
      %1937 : int[] = prim::ListConstruct(%7, %7)
      %1938 : int[] = prim::ListConstruct(%9, %9)
      %1939 : int[] = prim::ListConstruct(%7, %7)
      %input.101 : Tensor = aten::conv2d(%input.100, %1935, %1936, %1937, %1938, %1939, %7) # torch/nn/modules/conv.py:415:15
      %1941 : int = aten::dim(%input.101) # torch/nn/modules/batchnorm.py:276:11
      %1942 : bool = aten::ne(%1941, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1942) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1943 : bool = prim::GetAttr[name="training"](%1877)
       = prim::If(%1943) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1944 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1877)
          %1945 : Tensor = aten::add(%1944, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1877, %1945)
          -> ()
        block1():
          -> ()
      %1946 : bool = prim::GetAttr[name="training"](%1877)
      %1947 : Tensor = prim::GetAttr[name="running_mean"](%1877)
      %1948 : Tensor = prim::GetAttr[name="running_var"](%1877)
      %1949 : Tensor = prim::GetAttr[name="weight"](%1877)
      %1950 : Tensor = prim::GetAttr[name="bias"](%1877)
       = prim::If(%1946) # torch/nn/functional.py:2011:4
        block0():
          %1951 : int[] = aten::size(%input.101) # torch/nn/functional.py:2012:27
          %size_prods.136 : int = aten::__getitem__(%1951, %9) # torch/nn/functional.py:1991:17
          %1953 : int = aten::len(%1951) # torch/nn/functional.py:1992:19
          %1954 : int = aten::sub(%1953, %15) # torch/nn/functional.py:1992:19
          %size_prods.137 : int = prim::Loop(%1954, %8, %size_prods.136) # torch/nn/functional.py:1992:4
            block0(%i.35 : int, %size_prods.138 : int):
              %1958 : int = aten::add(%i.35, %15) # torch/nn/functional.py:1993:27
              %1959 : int = aten::__getitem__(%1951, %1958) # torch/nn/functional.py:1993:22
              %size_prods.139 : int = aten::mul(%size_prods.138, %1959) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.139)
          %1961 : bool = aten::eq(%size_prods.137, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1961) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.102 : Tensor = aten::batch_norm(%input.101, %1949, %1950, %1947, %1948, %1946, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.103 : Tensor = aten::relu_(%input.102) # torch/nn/functional.py:1117:17
      %1964 : Tensor[] = prim::ListConstruct(%x1.6, %input.103)
      %out.16 : Tensor = aten::cat(%1964, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.16)
    block1():
      %1966 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%963)
      %1967 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%1966)
      %1968 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%1966)
      %1969 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%1966)
      %1970 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%1966)
      %1971 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%1966)
      %1972 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%1966)
      %1973 : Tensor = prim::GetAttr[name="weight"](%1967)
      %1974 : Tensor? = prim::GetAttr[name="bias"](%1967)
      %1975 : int[] = prim::ListConstruct(%7, %7)
      %1976 : int[] = prim::ListConstruct(%9, %9)
      %1977 : int[] = prim::ListConstruct(%7, %7)
      %input.104 : Tensor = aten::conv2d(%input.289, %1973, %1974, %1975, %1976, %1977, %7) # torch/nn/modules/conv.py:415:15
      %1979 : int = aten::dim(%input.104) # torch/nn/modules/batchnorm.py:276:11
      %1980 : bool = aten::ne(%1979, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1980) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1981 : bool = prim::GetAttr[name="training"](%1968)
       = prim::If(%1981) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1982 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1968)
          %1983 : Tensor = aten::add(%1982, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1968, %1983)
          -> ()
        block1():
          -> ()
      %1984 : bool = prim::GetAttr[name="training"](%1968)
      %1985 : Tensor = prim::GetAttr[name="running_mean"](%1968)
      %1986 : Tensor = prim::GetAttr[name="running_var"](%1968)
      %1987 : Tensor = prim::GetAttr[name="weight"](%1968)
      %1988 : Tensor = prim::GetAttr[name="bias"](%1968)
       = prim::If(%1984) # torch/nn/functional.py:2011:4
        block0():
          %1989 : int[] = aten::size(%input.104) # torch/nn/functional.py:2012:27
          %size_prods.140 : int = aten::__getitem__(%1989, %9) # torch/nn/functional.py:1991:17
          %1991 : int = aten::len(%1989) # torch/nn/functional.py:1992:19
          %1992 : int = aten::sub(%1991, %15) # torch/nn/functional.py:1992:19
          %size_prods.141 : int = prim::Loop(%1992, %8, %size_prods.140) # torch/nn/functional.py:1992:4
            block0(%i.36 : int, %size_prods.142 : int):
              %1996 : int = aten::add(%i.36, %15) # torch/nn/functional.py:1993:27
              %1997 : int = aten::__getitem__(%1989, %1996) # torch/nn/functional.py:1993:22
              %size_prods.143 : int = aten::mul(%size_prods.142, %1997) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.143)
          %1999 : bool = aten::eq(%size_prods.141, %7) # torch/nn/functional.py:1994:7
           = prim::If(%1999) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.105 : Tensor = aten::batch_norm(%input.104, %1987, %1988, %1985, %1986, %1984, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.106 : Tensor = aten::relu_(%input.105) # torch/nn/functional.py:1117:17
      %2002 : Tensor = prim::GetAttr[name="weight"](%1969)
      %2003 : Tensor? = prim::GetAttr[name="bias"](%1969)
      %2004 : int[] = prim::ListConstruct(%7, %7)
      %2005 : int[] = prim::ListConstruct(%7, %7)
      %2006 : int[] = prim::ListConstruct(%7, %7)
      %input.107 : Tensor = aten::conv2d(%input.106, %2002, %2003, %2004, %2005, %2006, %4) # torch/nn/modules/conv.py:415:15
      %2008 : int = aten::dim(%input.107) # torch/nn/modules/batchnorm.py:276:11
      %2009 : bool = aten::ne(%2008, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2009) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2010 : bool = prim::GetAttr[name="training"](%1970)
       = prim::If(%2010) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2011 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1970)
          %2012 : Tensor = aten::add(%2011, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1970, %2012)
          -> ()
        block1():
          -> ()
      %2013 : bool = prim::GetAttr[name="training"](%1970)
      %2014 : Tensor = prim::GetAttr[name="running_mean"](%1970)
      %2015 : Tensor = prim::GetAttr[name="running_var"](%1970)
      %2016 : Tensor = prim::GetAttr[name="weight"](%1970)
      %2017 : Tensor = prim::GetAttr[name="bias"](%1970)
       = prim::If(%2013) # torch/nn/functional.py:2011:4
        block0():
          %2018 : int[] = aten::size(%input.107) # torch/nn/functional.py:2012:27
          %size_prods.144 : int = aten::__getitem__(%2018, %9) # torch/nn/functional.py:1991:17
          %2020 : int = aten::len(%2018) # torch/nn/functional.py:1992:19
          %2021 : int = aten::sub(%2020, %15) # torch/nn/functional.py:1992:19
          %size_prods.145 : int = prim::Loop(%2021, %8, %size_prods.144) # torch/nn/functional.py:1992:4
            block0(%i.37 : int, %size_prods.146 : int):
              %2025 : int = aten::add(%i.37, %15) # torch/nn/functional.py:1993:27
              %2026 : int = aten::__getitem__(%2018, %2025) # torch/nn/functional.py:1993:22
              %size_prods.147 : int = aten::mul(%size_prods.146, %2026) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.147)
          %2028 : bool = aten::eq(%size_prods.145, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2028) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.108 : Tensor = aten::batch_norm(%input.107, %2016, %2017, %2014, %2015, %2013, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2030 : Tensor = prim::GetAttr[name="weight"](%1971)
      %2031 : Tensor? = prim::GetAttr[name="bias"](%1971)
      %2032 : int[] = prim::ListConstruct(%7, %7)
      %2033 : int[] = prim::ListConstruct(%9, %9)
      %2034 : int[] = prim::ListConstruct(%7, %7)
      %input.109 : Tensor = aten::conv2d(%input.108, %2030, %2031, %2032, %2033, %2034, %7) # torch/nn/modules/conv.py:415:15
      %2036 : int = aten::dim(%input.109) # torch/nn/modules/batchnorm.py:276:11
      %2037 : bool = aten::ne(%2036, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2037) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2038 : bool = prim::GetAttr[name="training"](%1972)
       = prim::If(%2038) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2039 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1972)
          %2040 : Tensor = aten::add(%2039, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1972, %2040)
          -> ()
        block1():
          -> ()
      %2041 : bool = prim::GetAttr[name="training"](%1972)
      %2042 : Tensor = prim::GetAttr[name="running_mean"](%1972)
      %2043 : Tensor = prim::GetAttr[name="running_var"](%1972)
      %2044 : Tensor = prim::GetAttr[name="weight"](%1972)
      %2045 : Tensor = prim::GetAttr[name="bias"](%1972)
       = prim::If(%2041) # torch/nn/functional.py:2011:4
        block0():
          %2046 : int[] = aten::size(%input.109) # torch/nn/functional.py:2012:27
          %size_prods.148 : int = aten::__getitem__(%2046, %9) # torch/nn/functional.py:1991:17
          %2048 : int = aten::len(%2046) # torch/nn/functional.py:1992:19
          %2049 : int = aten::sub(%2048, %15) # torch/nn/functional.py:1992:19
          %size_prods.149 : int = prim::Loop(%2049, %8, %size_prods.148) # torch/nn/functional.py:1992:4
            block0(%i.38 : int, %size_prods.150 : int):
              %2053 : int = aten::add(%i.38, %15) # torch/nn/functional.py:1993:27
              %2054 : int = aten::__getitem__(%2046, %2053) # torch/nn/functional.py:1993:22
              %size_prods.151 : int = aten::mul(%size_prods.150, %2054) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.151)
          %2056 : bool = aten::eq(%size_prods.149, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2056) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.110 : Tensor = aten::batch_norm(%input.109, %2044, %2045, %2042, %2043, %2041, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.111 : Tensor = aten::relu_(%input.110) # torch/nn/functional.py:1117:17
      %2059 : Tensor[] = prim::ListConstruct(%input.289, %input.111)
      %out.17 : Tensor = aten::cat(%2059, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.17)
  %2061 : Tensor = prim::data(%out.18)
  %2062 : int[] = aten::size(%2061) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.6 : int, %num_channels.6 : int, %height.6 : int, %width.6 : int = prim::ListUnpack(%2062)
  %channels_per_group.6 : int = aten::floordiv(%num_channels.6, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2068 : int[] = prim::ListConstruct(%batchsize.6, %15, %channels_per_group.6, %height.6, %width.6)
  %x.14 : Tensor = aten::view(%out.18, %2068) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2070 : Tensor = aten::transpose(%x.14, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.15 : Tensor = aten::contiguous(%2070, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2072 : int[] = prim::ListConstruct(%batchsize.6, %5, %height.6, %width.6)
  %input.220 : Tensor = aten::view(%x.15, %2072) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2074 : int = prim::GetAttr[name="stride"](%964)
  %2075 : bool = aten::eq(%2074, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.21 : Tensor = prim::If(%2075) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2077 : Tensor[] = aten::chunk(%input.220, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.7 : Tensor, %x2.7 : Tensor = prim::ListUnpack(%2077)
      %2080 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%964)
      %2081 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%2080)
      %2082 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%2080)
      %2083 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%2080)
      %2084 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%2080)
      %2085 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%2080)
      %2086 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%2080)
      %2087 : Tensor = prim::GetAttr[name="weight"](%2081)
      %2088 : Tensor? = prim::GetAttr[name="bias"](%2081)
      %2089 : int[] = prim::ListConstruct(%7, %7)
      %2090 : int[] = prim::ListConstruct(%9, %9)
      %2091 : int[] = prim::ListConstruct(%7, %7)
      %input.112 : Tensor = aten::conv2d(%x2.7, %2087, %2088, %2089, %2090, %2091, %7) # torch/nn/modules/conv.py:415:15
      %2093 : int = aten::dim(%input.112) # torch/nn/modules/batchnorm.py:276:11
      %2094 : bool = aten::ne(%2093, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2094) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2095 : bool = prim::GetAttr[name="training"](%2082)
       = prim::If(%2095) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2096 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2082)
          %2097 : Tensor = aten::add(%2096, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2082, %2097)
          -> ()
        block1():
          -> ()
      %2098 : bool = prim::GetAttr[name="training"](%2082)
      %2099 : Tensor = prim::GetAttr[name="running_mean"](%2082)
      %2100 : Tensor = prim::GetAttr[name="running_var"](%2082)
      %2101 : Tensor = prim::GetAttr[name="weight"](%2082)
      %2102 : Tensor = prim::GetAttr[name="bias"](%2082)
       = prim::If(%2098) # torch/nn/functional.py:2011:4
        block0():
          %2103 : int[] = aten::size(%input.112) # torch/nn/functional.py:2012:27
          %size_prods.152 : int = aten::__getitem__(%2103, %9) # torch/nn/functional.py:1991:17
          %2105 : int = aten::len(%2103) # torch/nn/functional.py:1992:19
          %2106 : int = aten::sub(%2105, %15) # torch/nn/functional.py:1992:19
          %size_prods.153 : int = prim::Loop(%2106, %8, %size_prods.152) # torch/nn/functional.py:1992:4
            block0(%i.39 : int, %size_prods.154 : int):
              %2110 : int = aten::add(%i.39, %15) # torch/nn/functional.py:1993:27
              %2111 : int = aten::__getitem__(%2103, %2110) # torch/nn/functional.py:1993:22
              %size_prods.155 : int = aten::mul(%size_prods.154, %2111) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.155)
          %2113 : bool = aten::eq(%size_prods.153, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2113) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.113 : Tensor = aten::batch_norm(%input.112, %2101, %2102, %2099, %2100, %2098, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.114 : Tensor = aten::relu_(%input.113) # torch/nn/functional.py:1117:17
      %2116 : Tensor = prim::GetAttr[name="weight"](%2083)
      %2117 : Tensor? = prim::GetAttr[name="bias"](%2083)
      %2118 : int[] = prim::ListConstruct(%7, %7)
      %2119 : int[] = prim::ListConstruct(%7, %7)
      %2120 : int[] = prim::ListConstruct(%7, %7)
      %input.115 : Tensor = aten::conv2d(%input.114, %2116, %2117, %2118, %2119, %2120, %4) # torch/nn/modules/conv.py:415:15
      %2122 : int = aten::dim(%input.115) # torch/nn/modules/batchnorm.py:276:11
      %2123 : bool = aten::ne(%2122, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2123) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2124 : bool = prim::GetAttr[name="training"](%2084)
       = prim::If(%2124) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2125 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2084)
          %2126 : Tensor = aten::add(%2125, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2084, %2126)
          -> ()
        block1():
          -> ()
      %2127 : bool = prim::GetAttr[name="training"](%2084)
      %2128 : Tensor = prim::GetAttr[name="running_mean"](%2084)
      %2129 : Tensor = prim::GetAttr[name="running_var"](%2084)
      %2130 : Tensor = prim::GetAttr[name="weight"](%2084)
      %2131 : Tensor = prim::GetAttr[name="bias"](%2084)
       = prim::If(%2127) # torch/nn/functional.py:2011:4
        block0():
          %2132 : int[] = aten::size(%input.115) # torch/nn/functional.py:2012:27
          %size_prods.156 : int = aten::__getitem__(%2132, %9) # torch/nn/functional.py:1991:17
          %2134 : int = aten::len(%2132) # torch/nn/functional.py:1992:19
          %2135 : int = aten::sub(%2134, %15) # torch/nn/functional.py:1992:19
          %size_prods.157 : int = prim::Loop(%2135, %8, %size_prods.156) # torch/nn/functional.py:1992:4
            block0(%i.40 : int, %size_prods.158 : int):
              %2139 : int = aten::add(%i.40, %15) # torch/nn/functional.py:1993:27
              %2140 : int = aten::__getitem__(%2132, %2139) # torch/nn/functional.py:1993:22
              %size_prods.159 : int = aten::mul(%size_prods.158, %2140) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.159)
          %2142 : bool = aten::eq(%size_prods.157, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2142) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.116 : Tensor = aten::batch_norm(%input.115, %2130, %2131, %2128, %2129, %2127, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2144 : Tensor = prim::GetAttr[name="weight"](%2085)
      %2145 : Tensor? = prim::GetAttr[name="bias"](%2085)
      %2146 : int[] = prim::ListConstruct(%7, %7)
      %2147 : int[] = prim::ListConstruct(%9, %9)
      %2148 : int[] = prim::ListConstruct(%7, %7)
      %input.117 : Tensor = aten::conv2d(%input.116, %2144, %2145, %2146, %2147, %2148, %7) # torch/nn/modules/conv.py:415:15
      %2150 : int = aten::dim(%input.117) # torch/nn/modules/batchnorm.py:276:11
      %2151 : bool = aten::ne(%2150, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2151) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2152 : bool = prim::GetAttr[name="training"](%2086)
       = prim::If(%2152) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2153 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2086)
          %2154 : Tensor = aten::add(%2153, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2086, %2154)
          -> ()
        block1():
          -> ()
      %2155 : bool = prim::GetAttr[name="training"](%2086)
      %2156 : Tensor = prim::GetAttr[name="running_mean"](%2086)
      %2157 : Tensor = prim::GetAttr[name="running_var"](%2086)
      %2158 : Tensor = prim::GetAttr[name="weight"](%2086)
      %2159 : Tensor = prim::GetAttr[name="bias"](%2086)
       = prim::If(%2155) # torch/nn/functional.py:2011:4
        block0():
          %2160 : int[] = aten::size(%input.117) # torch/nn/functional.py:2012:27
          %size_prods.160 : int = aten::__getitem__(%2160, %9) # torch/nn/functional.py:1991:17
          %2162 : int = aten::len(%2160) # torch/nn/functional.py:1992:19
          %2163 : int = aten::sub(%2162, %15) # torch/nn/functional.py:1992:19
          %size_prods.161 : int = prim::Loop(%2163, %8, %size_prods.160) # torch/nn/functional.py:1992:4
            block0(%i.41 : int, %size_prods.162 : int):
              %2167 : int = aten::add(%i.41, %15) # torch/nn/functional.py:1993:27
              %2168 : int = aten::__getitem__(%2160, %2167) # torch/nn/functional.py:1993:22
              %size_prods.163 : int = aten::mul(%size_prods.162, %2168) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.163)
          %2170 : bool = aten::eq(%size_prods.161, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2170) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.118 : Tensor = aten::batch_norm(%input.117, %2158, %2159, %2156, %2157, %2155, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.119 : Tensor = aten::relu_(%input.118) # torch/nn/functional.py:1117:17
      %2173 : Tensor[] = prim::ListConstruct(%x1.7, %input.119)
      %out.19 : Tensor = aten::cat(%2173, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.19)
    block1():
      %2175 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%964)
      %2176 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%2175)
      %2177 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%2175)
      %2178 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%2175)
      %2179 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%2175)
      %2180 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%2175)
      %2181 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%2175)
      %2182 : Tensor = prim::GetAttr[name="weight"](%2176)
      %2183 : Tensor? = prim::GetAttr[name="bias"](%2176)
      %2184 : int[] = prim::ListConstruct(%7, %7)
      %2185 : int[] = prim::ListConstruct(%9, %9)
      %2186 : int[] = prim::ListConstruct(%7, %7)
      %input.120 : Tensor = aten::conv2d(%input.220, %2182, %2183, %2184, %2185, %2186, %7) # torch/nn/modules/conv.py:415:15
      %2188 : int = aten::dim(%input.120) # torch/nn/modules/batchnorm.py:276:11
      %2189 : bool = aten::ne(%2188, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2189) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2190 : bool = prim::GetAttr[name="training"](%2177)
       = prim::If(%2190) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2191 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2177)
          %2192 : Tensor = aten::add(%2191, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2177, %2192)
          -> ()
        block1():
          -> ()
      %2193 : bool = prim::GetAttr[name="training"](%2177)
      %2194 : Tensor = prim::GetAttr[name="running_mean"](%2177)
      %2195 : Tensor = prim::GetAttr[name="running_var"](%2177)
      %2196 : Tensor = prim::GetAttr[name="weight"](%2177)
      %2197 : Tensor = prim::GetAttr[name="bias"](%2177)
       = prim::If(%2193) # torch/nn/functional.py:2011:4
        block0():
          %2198 : int[] = aten::size(%input.120) # torch/nn/functional.py:2012:27
          %size_prods.164 : int = aten::__getitem__(%2198, %9) # torch/nn/functional.py:1991:17
          %2200 : int = aten::len(%2198) # torch/nn/functional.py:1992:19
          %2201 : int = aten::sub(%2200, %15) # torch/nn/functional.py:1992:19
          %size_prods.165 : int = prim::Loop(%2201, %8, %size_prods.164) # torch/nn/functional.py:1992:4
            block0(%i.42 : int, %size_prods.166 : int):
              %2205 : int = aten::add(%i.42, %15) # torch/nn/functional.py:1993:27
              %2206 : int = aten::__getitem__(%2198, %2205) # torch/nn/functional.py:1993:22
              %size_prods.167 : int = aten::mul(%size_prods.166, %2206) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.167)
          %2208 : bool = aten::eq(%size_prods.165, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2208) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.121 : Tensor = aten::batch_norm(%input.120, %2196, %2197, %2194, %2195, %2193, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.122 : Tensor = aten::relu_(%input.121) # torch/nn/functional.py:1117:17
      %2211 : Tensor = prim::GetAttr[name="weight"](%2178)
      %2212 : Tensor? = prim::GetAttr[name="bias"](%2178)
      %2213 : int[] = prim::ListConstruct(%7, %7)
      %2214 : int[] = prim::ListConstruct(%7, %7)
      %2215 : int[] = prim::ListConstruct(%7, %7)
      %input.123 : Tensor = aten::conv2d(%input.122, %2211, %2212, %2213, %2214, %2215, %4) # torch/nn/modules/conv.py:415:15
      %2217 : int = aten::dim(%input.123) # torch/nn/modules/batchnorm.py:276:11
      %2218 : bool = aten::ne(%2217, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2218) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2219 : bool = prim::GetAttr[name="training"](%2179)
       = prim::If(%2219) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2220 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2179)
          %2221 : Tensor = aten::add(%2220, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2179, %2221)
          -> ()
        block1():
          -> ()
      %2222 : bool = prim::GetAttr[name="training"](%2179)
      %2223 : Tensor = prim::GetAttr[name="running_mean"](%2179)
      %2224 : Tensor = prim::GetAttr[name="running_var"](%2179)
      %2225 : Tensor = prim::GetAttr[name="weight"](%2179)
      %2226 : Tensor = prim::GetAttr[name="bias"](%2179)
       = prim::If(%2222) # torch/nn/functional.py:2011:4
        block0():
          %2227 : int[] = aten::size(%input.123) # torch/nn/functional.py:2012:27
          %size_prods.168 : int = aten::__getitem__(%2227, %9) # torch/nn/functional.py:1991:17
          %2229 : int = aten::len(%2227) # torch/nn/functional.py:1992:19
          %2230 : int = aten::sub(%2229, %15) # torch/nn/functional.py:1992:19
          %size_prods.169 : int = prim::Loop(%2230, %8, %size_prods.168) # torch/nn/functional.py:1992:4
            block0(%i.43 : int, %size_prods.170 : int):
              %2234 : int = aten::add(%i.43, %15) # torch/nn/functional.py:1993:27
              %2235 : int = aten::__getitem__(%2227, %2234) # torch/nn/functional.py:1993:22
              %size_prods.171 : int = aten::mul(%size_prods.170, %2235) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.171)
          %2237 : bool = aten::eq(%size_prods.169, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2237) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.124 : Tensor = aten::batch_norm(%input.123, %2225, %2226, %2223, %2224, %2222, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2239 : Tensor = prim::GetAttr[name="weight"](%2180)
      %2240 : Tensor? = prim::GetAttr[name="bias"](%2180)
      %2241 : int[] = prim::ListConstruct(%7, %7)
      %2242 : int[] = prim::ListConstruct(%9, %9)
      %2243 : int[] = prim::ListConstruct(%7, %7)
      %input.125 : Tensor = aten::conv2d(%input.124, %2239, %2240, %2241, %2242, %2243, %7) # torch/nn/modules/conv.py:415:15
      %2245 : int = aten::dim(%input.125) # torch/nn/modules/batchnorm.py:276:11
      %2246 : bool = aten::ne(%2245, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2246) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2247 : bool = prim::GetAttr[name="training"](%2181)
       = prim::If(%2247) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2248 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2181)
          %2249 : Tensor = aten::add(%2248, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2181, %2249)
          -> ()
        block1():
          -> ()
      %2250 : bool = prim::GetAttr[name="training"](%2181)
      %2251 : Tensor = prim::GetAttr[name="running_mean"](%2181)
      %2252 : Tensor = prim::GetAttr[name="running_var"](%2181)
      %2253 : Tensor = prim::GetAttr[name="weight"](%2181)
      %2254 : Tensor = prim::GetAttr[name="bias"](%2181)
       = prim::If(%2250) # torch/nn/functional.py:2011:4
        block0():
          %2255 : int[] = aten::size(%input.125) # torch/nn/functional.py:2012:27
          %size_prods.172 : int = aten::__getitem__(%2255, %9) # torch/nn/functional.py:1991:17
          %2257 : int = aten::len(%2255) # torch/nn/functional.py:1992:19
          %2258 : int = aten::sub(%2257, %15) # torch/nn/functional.py:1992:19
          %size_prods.173 : int = prim::Loop(%2258, %8, %size_prods.172) # torch/nn/functional.py:1992:4
            block0(%i.44 : int, %size_prods.174 : int):
              %2262 : int = aten::add(%i.44, %15) # torch/nn/functional.py:1993:27
              %2263 : int = aten::__getitem__(%2255, %2262) # torch/nn/functional.py:1993:22
              %size_prods.175 : int = aten::mul(%size_prods.174, %2263) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.175)
          %2265 : bool = aten::eq(%size_prods.173, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2265) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.126 : Tensor = aten::batch_norm(%input.125, %2253, %2254, %2251, %2252, %2250, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.127 : Tensor = aten::relu_(%input.126) # torch/nn/functional.py:1117:17
      %2268 : Tensor[] = prim::ListConstruct(%input.220, %input.127)
      %out.20 : Tensor = aten::cat(%2268, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.20)
  %2270 : Tensor = prim::data(%out.21)
  %2271 : int[] = aten::size(%2270) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.7 : int, %num_channels.7 : int, %height.7 : int, %width.7 : int = prim::ListUnpack(%2271)
  %channels_per_group.7 : int = aten::floordiv(%num_channels.7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2277 : int[] = prim::ListConstruct(%batchsize.7, %15, %channels_per_group.7, %height.7, %width.7)
  %x.16 : Tensor = aten::view(%out.21, %2277) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2279 : Tensor = aten::transpose(%x.16, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.17 : Tensor = aten::contiguous(%2279, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2281 : int[] = prim::ListConstruct(%batchsize.7, %5, %height.7, %width.7)
  %input.218 : Tensor = aten::view(%x.17, %2281) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2283 : int = prim::GetAttr[name="stride"](%965)
  %2284 : bool = aten::eq(%2283, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.24 : Tensor = prim::If(%2284) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2286 : Tensor[] = aten::chunk(%input.218, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.8 : Tensor, %x2.8 : Tensor = prim::ListUnpack(%2286)
      %2289 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%965)
      %2290 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%2289)
      %2291 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%2289)
      %2292 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%2289)
      %2293 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%2289)
      %2294 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%2289)
      %2295 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%2289)
      %2296 : Tensor = prim::GetAttr[name="weight"](%2290)
      %2297 : Tensor? = prim::GetAttr[name="bias"](%2290)
      %2298 : int[] = prim::ListConstruct(%7, %7)
      %2299 : int[] = prim::ListConstruct(%9, %9)
      %2300 : int[] = prim::ListConstruct(%7, %7)
      %input.128 : Tensor = aten::conv2d(%x2.8, %2296, %2297, %2298, %2299, %2300, %7) # torch/nn/modules/conv.py:415:15
      %2302 : int = aten::dim(%input.128) # torch/nn/modules/batchnorm.py:276:11
      %2303 : bool = aten::ne(%2302, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2303) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2304 : bool = prim::GetAttr[name="training"](%2291)
       = prim::If(%2304) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2305 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2291)
          %2306 : Tensor = aten::add(%2305, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2291, %2306)
          -> ()
        block1():
          -> ()
      %2307 : bool = prim::GetAttr[name="training"](%2291)
      %2308 : Tensor = prim::GetAttr[name="running_mean"](%2291)
      %2309 : Tensor = prim::GetAttr[name="running_var"](%2291)
      %2310 : Tensor = prim::GetAttr[name="weight"](%2291)
      %2311 : Tensor = prim::GetAttr[name="bias"](%2291)
       = prim::If(%2307) # torch/nn/functional.py:2011:4
        block0():
          %2312 : int[] = aten::size(%input.128) # torch/nn/functional.py:2012:27
          %size_prods.176 : int = aten::__getitem__(%2312, %9) # torch/nn/functional.py:1991:17
          %2314 : int = aten::len(%2312) # torch/nn/functional.py:1992:19
          %2315 : int = aten::sub(%2314, %15) # torch/nn/functional.py:1992:19
          %size_prods.177 : int = prim::Loop(%2315, %8, %size_prods.176) # torch/nn/functional.py:1992:4
            block0(%i.45 : int, %size_prods.178 : int):
              %2319 : int = aten::add(%i.45, %15) # torch/nn/functional.py:1993:27
              %2320 : int = aten::__getitem__(%2312, %2319) # torch/nn/functional.py:1993:22
              %size_prods.179 : int = aten::mul(%size_prods.178, %2320) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.179)
          %2322 : bool = aten::eq(%size_prods.177, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2322) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.129 : Tensor = aten::batch_norm(%input.128, %2310, %2311, %2308, %2309, %2307, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.130 : Tensor = aten::relu_(%input.129) # torch/nn/functional.py:1117:17
      %2325 : Tensor = prim::GetAttr[name="weight"](%2292)
      %2326 : Tensor? = prim::GetAttr[name="bias"](%2292)
      %2327 : int[] = prim::ListConstruct(%7, %7)
      %2328 : int[] = prim::ListConstruct(%7, %7)
      %2329 : int[] = prim::ListConstruct(%7, %7)
      %input.131 : Tensor = aten::conv2d(%input.130, %2325, %2326, %2327, %2328, %2329, %4) # torch/nn/modules/conv.py:415:15
      %2331 : int = aten::dim(%input.131) # torch/nn/modules/batchnorm.py:276:11
      %2332 : bool = aten::ne(%2331, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2332) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2333 : bool = prim::GetAttr[name="training"](%2293)
       = prim::If(%2333) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2334 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2293)
          %2335 : Tensor = aten::add(%2334, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2293, %2335)
          -> ()
        block1():
          -> ()
      %2336 : bool = prim::GetAttr[name="training"](%2293)
      %2337 : Tensor = prim::GetAttr[name="running_mean"](%2293)
      %2338 : Tensor = prim::GetAttr[name="running_var"](%2293)
      %2339 : Tensor = prim::GetAttr[name="weight"](%2293)
      %2340 : Tensor = prim::GetAttr[name="bias"](%2293)
       = prim::If(%2336) # torch/nn/functional.py:2011:4
        block0():
          %2341 : int[] = aten::size(%input.131) # torch/nn/functional.py:2012:27
          %size_prods.180 : int = aten::__getitem__(%2341, %9) # torch/nn/functional.py:1991:17
          %2343 : int = aten::len(%2341) # torch/nn/functional.py:1992:19
          %2344 : int = aten::sub(%2343, %15) # torch/nn/functional.py:1992:19
          %size_prods.181 : int = prim::Loop(%2344, %8, %size_prods.180) # torch/nn/functional.py:1992:4
            block0(%i.46 : int, %size_prods.182 : int):
              %2348 : int = aten::add(%i.46, %15) # torch/nn/functional.py:1993:27
              %2349 : int = aten::__getitem__(%2341, %2348) # torch/nn/functional.py:1993:22
              %size_prods.183 : int = aten::mul(%size_prods.182, %2349) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.183)
          %2351 : bool = aten::eq(%size_prods.181, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2351) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.132 : Tensor = aten::batch_norm(%input.131, %2339, %2340, %2337, %2338, %2336, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2353 : Tensor = prim::GetAttr[name="weight"](%2294)
      %2354 : Tensor? = prim::GetAttr[name="bias"](%2294)
      %2355 : int[] = prim::ListConstruct(%7, %7)
      %2356 : int[] = prim::ListConstruct(%9, %9)
      %2357 : int[] = prim::ListConstruct(%7, %7)
      %input.133 : Tensor = aten::conv2d(%input.132, %2353, %2354, %2355, %2356, %2357, %7) # torch/nn/modules/conv.py:415:15
      %2359 : int = aten::dim(%input.133) # torch/nn/modules/batchnorm.py:276:11
      %2360 : bool = aten::ne(%2359, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2360) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2361 : bool = prim::GetAttr[name="training"](%2295)
       = prim::If(%2361) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2362 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2295)
          %2363 : Tensor = aten::add(%2362, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2295, %2363)
          -> ()
        block1():
          -> ()
      %2364 : bool = prim::GetAttr[name="training"](%2295)
      %2365 : Tensor = prim::GetAttr[name="running_mean"](%2295)
      %2366 : Tensor = prim::GetAttr[name="running_var"](%2295)
      %2367 : Tensor = prim::GetAttr[name="weight"](%2295)
      %2368 : Tensor = prim::GetAttr[name="bias"](%2295)
       = prim::If(%2364) # torch/nn/functional.py:2011:4
        block0():
          %2369 : int[] = aten::size(%input.133) # torch/nn/functional.py:2012:27
          %size_prods.184 : int = aten::__getitem__(%2369, %9) # torch/nn/functional.py:1991:17
          %2371 : int = aten::len(%2369) # torch/nn/functional.py:1992:19
          %2372 : int = aten::sub(%2371, %15) # torch/nn/functional.py:1992:19
          %size_prods.185 : int = prim::Loop(%2372, %8, %size_prods.184) # torch/nn/functional.py:1992:4
            block0(%i.47 : int, %size_prods.186 : int):
              %2376 : int = aten::add(%i.47, %15) # torch/nn/functional.py:1993:27
              %2377 : int = aten::__getitem__(%2369, %2376) # torch/nn/functional.py:1993:22
              %size_prods.187 : int = aten::mul(%size_prods.186, %2377) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.187)
          %2379 : bool = aten::eq(%size_prods.185, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2379) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.134 : Tensor = aten::batch_norm(%input.133, %2367, %2368, %2365, %2366, %2364, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.135 : Tensor = aten::relu_(%input.134) # torch/nn/functional.py:1117:17
      %2382 : Tensor[] = prim::ListConstruct(%x1.8, %input.135)
      %out.22 : Tensor = aten::cat(%2382, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.22)
    block1():
      %2384 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%965)
      %2385 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%2384)
      %2386 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%2384)
      %2387 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%2384)
      %2388 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%2384)
      %2389 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%2384)
      %2390 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%2384)
      %2391 : Tensor = prim::GetAttr[name="weight"](%2385)
      %2392 : Tensor? = prim::GetAttr[name="bias"](%2385)
      %2393 : int[] = prim::ListConstruct(%7, %7)
      %2394 : int[] = prim::ListConstruct(%9, %9)
      %2395 : int[] = prim::ListConstruct(%7, %7)
      %input.136 : Tensor = aten::conv2d(%input.218, %2391, %2392, %2393, %2394, %2395, %7) # torch/nn/modules/conv.py:415:15
      %2397 : int = aten::dim(%input.136) # torch/nn/modules/batchnorm.py:276:11
      %2398 : bool = aten::ne(%2397, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2398) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2399 : bool = prim::GetAttr[name="training"](%2386)
       = prim::If(%2399) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2400 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2386)
          %2401 : Tensor = aten::add(%2400, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2386, %2401)
          -> ()
        block1():
          -> ()
      %2402 : bool = prim::GetAttr[name="training"](%2386)
      %2403 : Tensor = prim::GetAttr[name="running_mean"](%2386)
      %2404 : Tensor = prim::GetAttr[name="running_var"](%2386)
      %2405 : Tensor = prim::GetAttr[name="weight"](%2386)
      %2406 : Tensor = prim::GetAttr[name="bias"](%2386)
       = prim::If(%2402) # torch/nn/functional.py:2011:4
        block0():
          %2407 : int[] = aten::size(%input.136) # torch/nn/functional.py:2012:27
          %size_prods.188 : int = aten::__getitem__(%2407, %9) # torch/nn/functional.py:1991:17
          %2409 : int = aten::len(%2407) # torch/nn/functional.py:1992:19
          %2410 : int = aten::sub(%2409, %15) # torch/nn/functional.py:1992:19
          %size_prods.189 : int = prim::Loop(%2410, %8, %size_prods.188) # torch/nn/functional.py:1992:4
            block0(%i.48 : int, %size_prods.190 : int):
              %2414 : int = aten::add(%i.48, %15) # torch/nn/functional.py:1993:27
              %2415 : int = aten::__getitem__(%2407, %2414) # torch/nn/functional.py:1993:22
              %size_prods.191 : int = aten::mul(%size_prods.190, %2415) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.191)
          %2417 : bool = aten::eq(%size_prods.189, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2417) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.137 : Tensor = aten::batch_norm(%input.136, %2405, %2406, %2403, %2404, %2402, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.138 : Tensor = aten::relu_(%input.137) # torch/nn/functional.py:1117:17
      %2420 : Tensor = prim::GetAttr[name="weight"](%2387)
      %2421 : Tensor? = prim::GetAttr[name="bias"](%2387)
      %2422 : int[] = prim::ListConstruct(%7, %7)
      %2423 : int[] = prim::ListConstruct(%7, %7)
      %2424 : int[] = prim::ListConstruct(%7, %7)
      %input.139 : Tensor = aten::conv2d(%input.138, %2420, %2421, %2422, %2423, %2424, %4) # torch/nn/modules/conv.py:415:15
      %2426 : int = aten::dim(%input.139) # torch/nn/modules/batchnorm.py:276:11
      %2427 : bool = aten::ne(%2426, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2427) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2428 : bool = prim::GetAttr[name="training"](%2388)
       = prim::If(%2428) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2429 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2388)
          %2430 : Tensor = aten::add(%2429, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2388, %2430)
          -> ()
        block1():
          -> ()
      %2431 : bool = prim::GetAttr[name="training"](%2388)
      %2432 : Tensor = prim::GetAttr[name="running_mean"](%2388)
      %2433 : Tensor = prim::GetAttr[name="running_var"](%2388)
      %2434 : Tensor = prim::GetAttr[name="weight"](%2388)
      %2435 : Tensor = prim::GetAttr[name="bias"](%2388)
       = prim::If(%2431) # torch/nn/functional.py:2011:4
        block0():
          %2436 : int[] = aten::size(%input.139) # torch/nn/functional.py:2012:27
          %size_prods.192 : int = aten::__getitem__(%2436, %9) # torch/nn/functional.py:1991:17
          %2438 : int = aten::len(%2436) # torch/nn/functional.py:1992:19
          %2439 : int = aten::sub(%2438, %15) # torch/nn/functional.py:1992:19
          %size_prods.193 : int = prim::Loop(%2439, %8, %size_prods.192) # torch/nn/functional.py:1992:4
            block0(%i.49 : int, %size_prods.194 : int):
              %2443 : int = aten::add(%i.49, %15) # torch/nn/functional.py:1993:27
              %2444 : int = aten::__getitem__(%2436, %2443) # torch/nn/functional.py:1993:22
              %size_prods.195 : int = aten::mul(%size_prods.194, %2444) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.195)
          %2446 : bool = aten::eq(%size_prods.193, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2446) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.140 : Tensor = aten::batch_norm(%input.139, %2434, %2435, %2432, %2433, %2431, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2448 : Tensor = prim::GetAttr[name="weight"](%2389)
      %2449 : Tensor? = prim::GetAttr[name="bias"](%2389)
      %2450 : int[] = prim::ListConstruct(%7, %7)
      %2451 : int[] = prim::ListConstruct(%9, %9)
      %2452 : int[] = prim::ListConstruct(%7, %7)
      %input.141 : Tensor = aten::conv2d(%input.140, %2448, %2449, %2450, %2451, %2452, %7) # torch/nn/modules/conv.py:415:15
      %2454 : int = aten::dim(%input.141) # torch/nn/modules/batchnorm.py:276:11
      %2455 : bool = aten::ne(%2454, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2455) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2456 : bool = prim::GetAttr[name="training"](%2390)
       = prim::If(%2456) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2457 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2390)
          %2458 : Tensor = aten::add(%2457, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2390, %2458)
          -> ()
        block1():
          -> ()
      %2459 : bool = prim::GetAttr[name="training"](%2390)
      %2460 : Tensor = prim::GetAttr[name="running_mean"](%2390)
      %2461 : Tensor = prim::GetAttr[name="running_var"](%2390)
      %2462 : Tensor = prim::GetAttr[name="weight"](%2390)
      %2463 : Tensor = prim::GetAttr[name="bias"](%2390)
       = prim::If(%2459) # torch/nn/functional.py:2011:4
        block0():
          %2464 : int[] = aten::size(%input.141) # torch/nn/functional.py:2012:27
          %size_prods.196 : int = aten::__getitem__(%2464, %9) # torch/nn/functional.py:1991:17
          %2466 : int = aten::len(%2464) # torch/nn/functional.py:1992:19
          %2467 : int = aten::sub(%2466, %15) # torch/nn/functional.py:1992:19
          %size_prods.197 : int = prim::Loop(%2467, %8, %size_prods.196) # torch/nn/functional.py:1992:4
            block0(%i.50 : int, %size_prods.198 : int):
              %2471 : int = aten::add(%i.50, %15) # torch/nn/functional.py:1993:27
              %2472 : int = aten::__getitem__(%2464, %2471) # torch/nn/functional.py:1993:22
              %size_prods.199 : int = aten::mul(%size_prods.198, %2472) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.199)
          %2474 : bool = aten::eq(%size_prods.197, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2474) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.142 : Tensor = aten::batch_norm(%input.141, %2462, %2463, %2460, %2461, %2459, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.143 : Tensor = aten::relu_(%input.142) # torch/nn/functional.py:1117:17
      %2477 : Tensor[] = prim::ListConstruct(%input.218, %input.143)
      %out.23 : Tensor = aten::cat(%2477, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.23)
  %2479 : Tensor = prim::data(%out.24)
  %2480 : int[] = aten::size(%2479) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.8 : int, %num_channels.8 : int, %height.8 : int, %width.8 : int = prim::ListUnpack(%2480)
  %channels_per_group.8 : int = aten::floordiv(%num_channels.8, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2486 : int[] = prim::ListConstruct(%batchsize.8, %15, %channels_per_group.8, %height.8, %width.8)
  %x.18 : Tensor = aten::view(%out.24, %2486) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2488 : Tensor = aten::transpose(%x.18, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.19 : Tensor = aten::contiguous(%2488, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2490 : int[] = prim::ListConstruct(%batchsize.8, %5, %height.8, %width.8)
  %input.219 : Tensor = aten::view(%x.19, %2490) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2492 : int = prim::GetAttr[name="stride"](%966)
  %2493 : bool = aten::eq(%2492, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.45 : Tensor = prim::If(%2493) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2495 : Tensor[] = aten::chunk(%input.219, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.16 : Tensor, %x2.16 : Tensor = prim::ListUnpack(%2495)
      %2498 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%966)
      %2499 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%2498)
      %2500 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%2498)
      %2501 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%2498)
      %2502 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%2498)
      %2503 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%2498)
      %2504 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%2498)
      %2505 : Tensor = prim::GetAttr[name="weight"](%2499)
      %2506 : Tensor? = prim::GetAttr[name="bias"](%2499)
      %2507 : int[] = prim::ListConstruct(%7, %7)
      %2508 : int[] = prim::ListConstruct(%9, %9)
      %2509 : int[] = prim::ListConstruct(%7, %7)
      %input.273 : Tensor = aten::conv2d(%x2.16, %2505, %2506, %2507, %2508, %2509, %7) # torch/nn/modules/conv.py:415:15
      %2511 : int = aten::dim(%input.273) # torch/nn/modules/batchnorm.py:276:11
      %2512 : bool = aten::ne(%2511, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2512) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2513 : bool = prim::GetAttr[name="training"](%2500)
       = prim::If(%2513) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2514 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2500)
          %2515 : Tensor = aten::add(%2514, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2500, %2515)
          -> ()
        block1():
          -> ()
      %2516 : bool = prim::GetAttr[name="training"](%2500)
      %2517 : Tensor = prim::GetAttr[name="running_mean"](%2500)
      %2518 : Tensor = prim::GetAttr[name="running_var"](%2500)
      %2519 : Tensor = prim::GetAttr[name="weight"](%2500)
      %2520 : Tensor = prim::GetAttr[name="bias"](%2500)
       = prim::If(%2516) # torch/nn/functional.py:2011:4
        block0():
          %2521 : int[] = aten::size(%input.273) # torch/nn/functional.py:2012:27
          %size_prods.388 : int = aten::__getitem__(%2521, %9) # torch/nn/functional.py:1991:17
          %2523 : int = aten::len(%2521) # torch/nn/functional.py:1992:19
          %2524 : int = aten::sub(%2523, %15) # torch/nn/functional.py:1992:19
          %size_prods.389 : int = prim::Loop(%2524, %8, %size_prods.388) # torch/nn/functional.py:1992:4
            block0(%i.98 : int, %size_prods.390 : int):
              %2528 : int = aten::add(%i.98, %15) # torch/nn/functional.py:1993:27
              %2529 : int = aten::__getitem__(%2521, %2528) # torch/nn/functional.py:1993:22
              %size_prods.391 : int = aten::mul(%size_prods.390, %2529) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.391)
          %2531 : bool = aten::eq(%size_prods.389, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2531) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.274 : Tensor = aten::batch_norm(%input.273, %2519, %2520, %2517, %2518, %2516, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.275 : Tensor = aten::relu_(%input.274) # torch/nn/functional.py:1117:17
      %2534 : Tensor = prim::GetAttr[name="weight"](%2501)
      %2535 : Tensor? = prim::GetAttr[name="bias"](%2501)
      %2536 : int[] = prim::ListConstruct(%7, %7)
      %2537 : int[] = prim::ListConstruct(%7, %7)
      %2538 : int[] = prim::ListConstruct(%7, %7)
      %input.276 : Tensor = aten::conv2d(%input.275, %2534, %2535, %2536, %2537, %2538, %4) # torch/nn/modules/conv.py:415:15
      %2540 : int = aten::dim(%input.276) # torch/nn/modules/batchnorm.py:276:11
      %2541 : bool = aten::ne(%2540, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2541) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2542 : bool = prim::GetAttr[name="training"](%2502)
       = prim::If(%2542) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2543 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2502)
          %2544 : Tensor = aten::add(%2543, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2502, %2544)
          -> ()
        block1():
          -> ()
      %2545 : bool = prim::GetAttr[name="training"](%2502)
      %2546 : Tensor = prim::GetAttr[name="running_mean"](%2502)
      %2547 : Tensor = prim::GetAttr[name="running_var"](%2502)
      %2548 : Tensor = prim::GetAttr[name="weight"](%2502)
      %2549 : Tensor = prim::GetAttr[name="bias"](%2502)
       = prim::If(%2545) # torch/nn/functional.py:2011:4
        block0():
          %2550 : int[] = aten::size(%input.276) # torch/nn/functional.py:2012:27
          %size_prods.392 : int = aten::__getitem__(%2550, %9) # torch/nn/functional.py:1991:17
          %2552 : int = aten::len(%2550) # torch/nn/functional.py:1992:19
          %2553 : int = aten::sub(%2552, %15) # torch/nn/functional.py:1992:19
          %size_prods.393 : int = prim::Loop(%2553, %8, %size_prods.392) # torch/nn/functional.py:1992:4
            block0(%i.99 : int, %size_prods.394 : int):
              %2557 : int = aten::add(%i.99, %15) # torch/nn/functional.py:1993:27
              %2558 : int = aten::__getitem__(%2550, %2557) # torch/nn/functional.py:1993:22
              %size_prods.395 : int = aten::mul(%size_prods.394, %2558) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.395)
          %2560 : bool = aten::eq(%size_prods.393, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2560) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.277 : Tensor = aten::batch_norm(%input.276, %2548, %2549, %2546, %2547, %2545, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2562 : Tensor = prim::GetAttr[name="weight"](%2503)
      %2563 : Tensor? = prim::GetAttr[name="bias"](%2503)
      %2564 : int[] = prim::ListConstruct(%7, %7)
      %2565 : int[] = prim::ListConstruct(%9, %9)
      %2566 : int[] = prim::ListConstruct(%7, %7)
      %input.278 : Tensor = aten::conv2d(%input.277, %2562, %2563, %2564, %2565, %2566, %7) # torch/nn/modules/conv.py:415:15
      %2568 : int = aten::dim(%input.278) # torch/nn/modules/batchnorm.py:276:11
      %2569 : bool = aten::ne(%2568, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2569) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2570 : bool = prim::GetAttr[name="training"](%2504)
       = prim::If(%2570) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2571 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2504)
          %2572 : Tensor = aten::add(%2571, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2504, %2572)
          -> ()
        block1():
          -> ()
      %2573 : bool = prim::GetAttr[name="training"](%2504)
      %2574 : Tensor = prim::GetAttr[name="running_mean"](%2504)
      %2575 : Tensor = prim::GetAttr[name="running_var"](%2504)
      %2576 : Tensor = prim::GetAttr[name="weight"](%2504)
      %2577 : Tensor = prim::GetAttr[name="bias"](%2504)
       = prim::If(%2573) # torch/nn/functional.py:2011:4
        block0():
          %2578 : int[] = aten::size(%input.278) # torch/nn/functional.py:2012:27
          %size_prods.396 : int = aten::__getitem__(%2578, %9) # torch/nn/functional.py:1991:17
          %2580 : int = aten::len(%2578) # torch/nn/functional.py:1992:19
          %2581 : int = aten::sub(%2580, %15) # torch/nn/functional.py:1992:19
          %size_prods.397 : int = prim::Loop(%2581, %8, %size_prods.396) # torch/nn/functional.py:1992:4
            block0(%i.100 : int, %size_prods.398 : int):
              %2585 : int = aten::add(%i.100, %15) # torch/nn/functional.py:1993:27
              %2586 : int = aten::__getitem__(%2578, %2585) # torch/nn/functional.py:1993:22
              %size_prods.399 : int = aten::mul(%size_prods.398, %2586) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.399)
          %2588 : bool = aten::eq(%size_prods.397, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2588) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.279 : Tensor = aten::batch_norm(%input.278, %2576, %2577, %2574, %2575, %2573, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.280 : Tensor = aten::relu_(%input.279) # torch/nn/functional.py:1117:17
      %2591 : Tensor[] = prim::ListConstruct(%x1.16, %input.280)
      %out.46 : Tensor = aten::cat(%2591, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.46)
    block1():
      %2593 : __torch__.torch.nn.modules.container.___torch_mangle_1035.Sequential = prim::GetAttr[name="branch2"](%966)
      %2594 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="0"](%2593)
      %2595 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="1"](%2593)
      %2596 : __torch__.torch.nn.modules.conv.___torch_mangle_634.Conv2d = prim::GetAttr[name="3"](%2593)
      %2597 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="4"](%2593)
      %2598 : __torch__.torch.nn.modules.conv.___torch_mangle_1031.Conv2d = prim::GetAttr[name="5"](%2593)
      %2599 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1030.BatchNorm2d = prim::GetAttr[name="6"](%2593)
      %2600 : Tensor = prim::GetAttr[name="weight"](%2594)
      %2601 : Tensor? = prim::GetAttr[name="bias"](%2594)
      %2602 : int[] = prim::ListConstruct(%7, %7)
      %2603 : int[] = prim::ListConstruct(%9, %9)
      %2604 : int[] = prim::ListConstruct(%7, %7)
      %input.281 : Tensor = aten::conv2d(%input.219, %2600, %2601, %2602, %2603, %2604, %7) # torch/nn/modules/conv.py:415:15
      %2606 : int = aten::dim(%input.281) # torch/nn/modules/batchnorm.py:276:11
      %2607 : bool = aten::ne(%2606, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2607) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2608 : bool = prim::GetAttr[name="training"](%2595)
       = prim::If(%2608) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2609 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2595)
          %2610 : Tensor = aten::add(%2609, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2595, %2610)
          -> ()
        block1():
          -> ()
      %2611 : bool = prim::GetAttr[name="training"](%2595)
      %2612 : Tensor = prim::GetAttr[name="running_mean"](%2595)
      %2613 : Tensor = prim::GetAttr[name="running_var"](%2595)
      %2614 : Tensor = prim::GetAttr[name="weight"](%2595)
      %2615 : Tensor = prim::GetAttr[name="bias"](%2595)
       = prim::If(%2611) # torch/nn/functional.py:2011:4
        block0():
          %2616 : int[] = aten::size(%input.281) # torch/nn/functional.py:2012:27
          %size_prods.400 : int = aten::__getitem__(%2616, %9) # torch/nn/functional.py:1991:17
          %2618 : int = aten::len(%2616) # torch/nn/functional.py:1992:19
          %2619 : int = aten::sub(%2618, %15) # torch/nn/functional.py:1992:19
          %size_prods.401 : int = prim::Loop(%2619, %8, %size_prods.400) # torch/nn/functional.py:1992:4
            block0(%i.101 : int, %size_prods.402 : int):
              %2623 : int = aten::add(%i.101, %15) # torch/nn/functional.py:1993:27
              %2624 : int = aten::__getitem__(%2616, %2623) # torch/nn/functional.py:1993:22
              %size_prods.403 : int = aten::mul(%size_prods.402, %2624) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.403)
          %2626 : bool = aten::eq(%size_prods.401, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2626) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.282 : Tensor = aten::batch_norm(%input.281, %2614, %2615, %2612, %2613, %2611, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.283 : Tensor = aten::relu_(%input.282) # torch/nn/functional.py:1117:17
      %2629 : Tensor = prim::GetAttr[name="weight"](%2596)
      %2630 : Tensor? = prim::GetAttr[name="bias"](%2596)
      %2631 : int[] = prim::ListConstruct(%7, %7)
      %2632 : int[] = prim::ListConstruct(%7, %7)
      %2633 : int[] = prim::ListConstruct(%7, %7)
      %input.284 : Tensor = aten::conv2d(%input.283, %2629, %2630, %2631, %2632, %2633, %4) # torch/nn/modules/conv.py:415:15
      %2635 : int = aten::dim(%input.284) # torch/nn/modules/batchnorm.py:276:11
      %2636 : bool = aten::ne(%2635, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2636) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2637 : bool = prim::GetAttr[name="training"](%2597)
       = prim::If(%2637) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2638 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2597)
          %2639 : Tensor = aten::add(%2638, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2597, %2639)
          -> ()
        block1():
          -> ()
      %2640 : bool = prim::GetAttr[name="training"](%2597)
      %2641 : Tensor = prim::GetAttr[name="running_mean"](%2597)
      %2642 : Tensor = prim::GetAttr[name="running_var"](%2597)
      %2643 : Tensor = prim::GetAttr[name="weight"](%2597)
      %2644 : Tensor = prim::GetAttr[name="bias"](%2597)
       = prim::If(%2640) # torch/nn/functional.py:2011:4
        block0():
          %2645 : int[] = aten::size(%input.284) # torch/nn/functional.py:2012:27
          %size_prods.404 : int = aten::__getitem__(%2645, %9) # torch/nn/functional.py:1991:17
          %2647 : int = aten::len(%2645) # torch/nn/functional.py:1992:19
          %2648 : int = aten::sub(%2647, %15) # torch/nn/functional.py:1992:19
          %size_prods.405 : int = prim::Loop(%2648, %8, %size_prods.404) # torch/nn/functional.py:1992:4
            block0(%i.102 : int, %size_prods.406 : int):
              %2652 : int = aten::add(%i.102, %15) # torch/nn/functional.py:1993:27
              %2653 : int = aten::__getitem__(%2645, %2652) # torch/nn/functional.py:1993:22
              %size_prods.407 : int = aten::mul(%size_prods.406, %2653) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.407)
          %2655 : bool = aten::eq(%size_prods.405, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2655) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.285 : Tensor = aten::batch_norm(%input.284, %2643, %2644, %2641, %2642, %2640, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2657 : Tensor = prim::GetAttr[name="weight"](%2598)
      %2658 : Tensor? = prim::GetAttr[name="bias"](%2598)
      %2659 : int[] = prim::ListConstruct(%7, %7)
      %2660 : int[] = prim::ListConstruct(%9, %9)
      %2661 : int[] = prim::ListConstruct(%7, %7)
      %input.286 : Tensor = aten::conv2d(%input.285, %2657, %2658, %2659, %2660, %2661, %7) # torch/nn/modules/conv.py:415:15
      %2663 : int = aten::dim(%input.286) # torch/nn/modules/batchnorm.py:276:11
      %2664 : bool = aten::ne(%2663, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2664) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2665 : bool = prim::GetAttr[name="training"](%2599)
       = prim::If(%2665) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2666 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2599)
          %2667 : Tensor = aten::add(%2666, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2599, %2667)
          -> ()
        block1():
          -> ()
      %2668 : bool = prim::GetAttr[name="training"](%2599)
      %2669 : Tensor = prim::GetAttr[name="running_mean"](%2599)
      %2670 : Tensor = prim::GetAttr[name="running_var"](%2599)
      %2671 : Tensor = prim::GetAttr[name="weight"](%2599)
      %2672 : Tensor = prim::GetAttr[name="bias"](%2599)
       = prim::If(%2668) # torch/nn/functional.py:2011:4
        block0():
          %2673 : int[] = aten::size(%input.286) # torch/nn/functional.py:2012:27
          %size_prods.408 : int = aten::__getitem__(%2673, %9) # torch/nn/functional.py:1991:17
          %2675 : int = aten::len(%2673) # torch/nn/functional.py:1992:19
          %2676 : int = aten::sub(%2675, %15) # torch/nn/functional.py:1992:19
          %size_prods.409 : int = prim::Loop(%2676, %8, %size_prods.408) # torch/nn/functional.py:1992:4
            block0(%i.103 : int, %size_prods.410 : int):
              %2680 : int = aten::add(%i.103, %15) # torch/nn/functional.py:1993:27
              %2681 : int = aten::__getitem__(%2673, %2680) # torch/nn/functional.py:1993:22
              %size_prods.411 : int = aten::mul(%size_prods.410, %2681) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.411)
          %2683 : bool = aten::eq(%size_prods.409, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2683) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.287 : Tensor = aten::batch_norm(%input.286, %2671, %2672, %2669, %2670, %2668, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.288 : Tensor = aten::relu_(%input.287) # torch/nn/functional.py:1117:17
      %2686 : Tensor[] = prim::ListConstruct(%input.219, %input.288)
      %out.47 : Tensor = aten::cat(%2686, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.47)
  %2688 : Tensor = prim::data(%out.45)
  %2689 : int[] = aten::size(%2688) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.16 : int, %num_channels.16 : int, %height.16 : int, %width.16 : int = prim::ListUnpack(%2689)
  %channels_per_group.16 : int = aten::floordiv(%num_channels.16, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2695 : int[] = prim::ListConstruct(%batchsize.16, %15, %channels_per_group.16, %height.16, %width.16)
  %x.41 : Tensor = aten::view(%out.45, %2695) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2697 : Tensor = aten::transpose(%x.41, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.42 : Tensor = aten::contiguous(%2697, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2699 : int[] = prim::ListConstruct(%batchsize.16, %5, %height.16, %width.16)
  %x.25 : Tensor = aten::view(%x.42, %2699) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2701 : __torch__.torch.nn.modules.container.___torch_mangle_1044.Sequential = prim::GetAttr[name="stage4"](%self)
  %2702 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1041.InvertedResidual = prim::GetAttr[name="0"](%2701)
  %2703 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1043.InvertedResidual = prim::GetAttr[name="1"](%2701)
  %2704 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1043.InvertedResidual = prim::GetAttr[name="2"](%2701)
  %2705 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1043.InvertedResidual = prim::GetAttr[name="3"](%2701)
  %2706 : int = prim::GetAttr[name="stride"](%2702)
  %2707 : bool = aten::eq(%2706, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.3 : Tensor = prim::If(%2707) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2709 : Tensor[] = aten::chunk(%x.25, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.2 : Tensor, %x2.2 : Tensor = prim::ListUnpack(%2709)
      %2712 : __torch__.torch.nn.modules.container.___torch_mangle_1040.Sequential = prim::GetAttr[name="branch2"](%2702)
      %2713 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="0"](%2712)
      %2714 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="1"](%2712)
      %2715 : __torch__.torch.nn.modules.conv.___torch_mangle_884.Conv2d = prim::GetAttr[name="3"](%2712)
      %2716 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="4"](%2712)
      %2717 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="5"](%2712)
      %2718 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="6"](%2712)
      %2719 : Tensor = prim::GetAttr[name="weight"](%2713)
      %2720 : Tensor? = prim::GetAttr[name="bias"](%2713)
      %2721 : int[] = prim::ListConstruct(%7, %7)
      %2722 : int[] = prim::ListConstruct(%9, %9)
      %2723 : int[] = prim::ListConstruct(%7, %7)
      %input.28 : Tensor = aten::conv2d(%x2.2, %2719, %2720, %2721, %2722, %2723, %7) # torch/nn/modules/conv.py:415:15
      %2725 : int = aten::dim(%input.28) # torch/nn/modules/batchnorm.py:276:11
      %2726 : bool = aten::ne(%2725, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2726) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2727 : bool = prim::GetAttr[name="training"](%2714)
       = prim::If(%2727) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2728 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2714)
          %2729 : Tensor = aten::add(%2728, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2714, %2729)
          -> ()
        block1():
          -> ()
      %2730 : bool = prim::GetAttr[name="training"](%2714)
      %2731 : Tensor = prim::GetAttr[name="running_mean"](%2714)
      %2732 : Tensor = prim::GetAttr[name="running_var"](%2714)
      %2733 : Tensor = prim::GetAttr[name="weight"](%2714)
      %2734 : Tensor = prim::GetAttr[name="bias"](%2714)
       = prim::If(%2730) # torch/nn/functional.py:2011:4
        block0():
          %2735 : int[] = aten::size(%input.28) # torch/nn/functional.py:2012:27
          %size_prods.32 : int = aten::__getitem__(%2735, %9) # torch/nn/functional.py:1991:17
          %2737 : int = aten::len(%2735) # torch/nn/functional.py:1992:19
          %2738 : int = aten::sub(%2737, %15) # torch/nn/functional.py:1992:19
          %size_prods.33 : int = prim::Loop(%2738, %8, %size_prods.32) # torch/nn/functional.py:1992:4
            block0(%i.9 : int, %size_prods.34 : int):
              %2742 : int = aten::add(%i.9, %15) # torch/nn/functional.py:1993:27
              %2743 : int = aten::__getitem__(%2735, %2742) # torch/nn/functional.py:1993:22
              %size_prods.35 : int = aten::mul(%size_prods.34, %2743) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.35)
          %2745 : bool = aten::eq(%size_prods.33, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2745) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.29 : Tensor = aten::batch_norm(%input.28, %2733, %2734, %2731, %2732, %2730, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.30 : Tensor = aten::relu_(%input.29) # torch/nn/functional.py:1117:17
      %2748 : Tensor = prim::GetAttr[name="weight"](%2715)
      %2749 : Tensor? = prim::GetAttr[name="bias"](%2715)
      %2750 : int[] = prim::ListConstruct(%15, %15)
      %2751 : int[] = prim::ListConstruct(%7, %7)
      %2752 : int[] = prim::ListConstruct(%7, %7)
      %input.31 : Tensor = aten::conv2d(%input.30, %2748, %2749, %2750, %2751, %2752, %3) # torch/nn/modules/conv.py:415:15
      %2754 : int = aten::dim(%input.31) # torch/nn/modules/batchnorm.py:276:11
      %2755 : bool = aten::ne(%2754, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2755) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2756 : bool = prim::GetAttr[name="training"](%2716)
       = prim::If(%2756) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2757 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2716)
          %2758 : Tensor = aten::add(%2757, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2716, %2758)
          -> ()
        block1():
          -> ()
      %2759 : bool = prim::GetAttr[name="training"](%2716)
      %2760 : Tensor = prim::GetAttr[name="running_mean"](%2716)
      %2761 : Tensor = prim::GetAttr[name="running_var"](%2716)
      %2762 : Tensor = prim::GetAttr[name="weight"](%2716)
      %2763 : Tensor = prim::GetAttr[name="bias"](%2716)
       = prim::If(%2759) # torch/nn/functional.py:2011:4
        block0():
          %2764 : int[] = aten::size(%input.31) # torch/nn/functional.py:2012:27
          %size_prods.24 : int = aten::__getitem__(%2764, %9) # torch/nn/functional.py:1991:17
          %2766 : int = aten::len(%2764) # torch/nn/functional.py:1992:19
          %2767 : int = aten::sub(%2766, %15) # torch/nn/functional.py:1992:19
          %size_prods.25 : int = prim::Loop(%2767, %8, %size_prods.24) # torch/nn/functional.py:1992:4
            block0(%i.7 : int, %size_prods.26 : int):
              %2771 : int = aten::add(%i.7, %15) # torch/nn/functional.py:1993:27
              %2772 : int = aten::__getitem__(%2764, %2771) # torch/nn/functional.py:1993:22
              %size_prods.27 : int = aten::mul(%size_prods.26, %2772) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.27)
          %2774 : bool = aten::eq(%size_prods.25, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2774) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.32 : Tensor = aten::batch_norm(%input.31, %2762, %2763, %2760, %2761, %2759, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2776 : Tensor = prim::GetAttr[name="weight"](%2717)
      %2777 : Tensor? = prim::GetAttr[name="bias"](%2717)
      %2778 : int[] = prim::ListConstruct(%7, %7)
      %2779 : int[] = prim::ListConstruct(%9, %9)
      %2780 : int[] = prim::ListConstruct(%7, %7)
      %input.21 : Tensor = aten::conv2d(%input.32, %2776, %2777, %2778, %2779, %2780, %7) # torch/nn/modules/conv.py:415:15
      %2782 : int = aten::dim(%input.21) # torch/nn/modules/batchnorm.py:276:11
      %2783 : bool = aten::ne(%2782, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2783) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2784 : bool = prim::GetAttr[name="training"](%2718)
       = prim::If(%2784) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2785 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2718)
          %2786 : Tensor = aten::add(%2785, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2718, %2786)
          -> ()
        block1():
          -> ()
      %2787 : bool = prim::GetAttr[name="training"](%2718)
      %2788 : Tensor = prim::GetAttr[name="running_mean"](%2718)
      %2789 : Tensor = prim::GetAttr[name="running_var"](%2718)
      %2790 : Tensor = prim::GetAttr[name="weight"](%2718)
      %2791 : Tensor = prim::GetAttr[name="bias"](%2718)
       = prim::If(%2787) # torch/nn/functional.py:2011:4
        block0():
          %2792 : int[] = aten::size(%input.21) # torch/nn/functional.py:2012:27
          %size_prods.36 : int = aten::__getitem__(%2792, %9) # torch/nn/functional.py:1991:17
          %2794 : int = aten::len(%2792) # torch/nn/functional.py:1992:19
          %2795 : int = aten::sub(%2794, %15) # torch/nn/functional.py:1992:19
          %size_prods.37 : int = prim::Loop(%2795, %8, %size_prods.36) # torch/nn/functional.py:1992:4
            block0(%i.10 : int, %size_prods.38 : int):
              %2799 : int = aten::add(%i.10, %15) # torch/nn/functional.py:1993:27
              %2800 : int = aten::__getitem__(%2792, %2799) # torch/nn/functional.py:1993:22
              %size_prods.39 : int = aten::mul(%size_prods.38, %2800) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.39)
          %2802 : bool = aten::eq(%size_prods.37, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2802) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.22 : Tensor = aten::batch_norm(%input.21, %2790, %2791, %2788, %2789, %2787, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.23 : Tensor = aten::relu_(%input.22) # torch/nn/functional.py:1117:17
      %2805 : Tensor[] = prim::ListConstruct(%x1.2, %input.23)
      %out.4 : Tensor = aten::cat(%2805, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.4)
    block1():
      %2807 : __torch__.torch.nn.modules.container.___torch_mangle_1039.Sequential = prim::GetAttr[name="branch1"](%2702)
      %2808 : __torch__.torch.nn.modules.conv.___torch_mangle_884.Conv2d = prim::GetAttr[name="0"](%2807)
      %2809 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="1"](%2807)
      %2810 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="2"](%2807)
      %2811 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="3"](%2807)
      %2812 : Tensor = prim::GetAttr[name="weight"](%2808)
      %2813 : Tensor? = prim::GetAttr[name="bias"](%2808)
      %2814 : int[] = prim::ListConstruct(%15, %15)
      %2815 : int[] = prim::ListConstruct(%7, %7)
      %2816 : int[] = prim::ListConstruct(%7, %7)
      %input.33 : Tensor = aten::conv2d(%x.25, %2812, %2813, %2814, %2815, %2816, %3) # torch/nn/modules/conv.py:415:15
      %2818 : int = aten::dim(%input.33) # torch/nn/modules/batchnorm.py:276:11
      %2819 : bool = aten::ne(%2818, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2819) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2820 : bool = prim::GetAttr[name="training"](%2809)
       = prim::If(%2820) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2821 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2809)
          %2822 : Tensor = aten::add(%2821, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2809, %2822)
          -> ()
        block1():
          -> ()
      %2823 : bool = prim::GetAttr[name="training"](%2809)
      %2824 : Tensor = prim::GetAttr[name="running_mean"](%2809)
      %2825 : Tensor = prim::GetAttr[name="running_var"](%2809)
      %2826 : Tensor = prim::GetAttr[name="weight"](%2809)
      %2827 : Tensor = prim::GetAttr[name="bias"](%2809)
       = prim::If(%2823) # torch/nn/functional.py:2011:4
        block0():
          %2828 : int[] = aten::size(%input.33) # torch/nn/functional.py:2012:27
          %size_prods.40 : int = aten::__getitem__(%2828, %9) # torch/nn/functional.py:1991:17
          %2830 : int = aten::len(%2828) # torch/nn/functional.py:1992:19
          %2831 : int = aten::sub(%2830, %15) # torch/nn/functional.py:1992:19
          %size_prods.41 : int = prim::Loop(%2831, %8, %size_prods.40) # torch/nn/functional.py:1992:4
            block0(%i.11 : int, %size_prods.42 : int):
              %2835 : int = aten::add(%i.11, %15) # torch/nn/functional.py:1993:27
              %2836 : int = aten::__getitem__(%2828, %2835) # torch/nn/functional.py:1993:22
              %size_prods.43 : int = aten::mul(%size_prods.42, %2836) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.43)
          %2838 : bool = aten::eq(%size_prods.41, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2838) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.34 : Tensor = aten::batch_norm(%input.33, %2826, %2827, %2824, %2825, %2823, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2840 : Tensor = prim::GetAttr[name="weight"](%2810)
      %2841 : Tensor? = prim::GetAttr[name="bias"](%2810)
      %2842 : int[] = prim::ListConstruct(%7, %7)
      %2843 : int[] = prim::ListConstruct(%9, %9)
      %2844 : int[] = prim::ListConstruct(%7, %7)
      %input.35 : Tensor = aten::conv2d(%input.34, %2840, %2841, %2842, %2843, %2844, %7) # torch/nn/modules/conv.py:415:15
      %2846 : int = aten::dim(%input.35) # torch/nn/modules/batchnorm.py:276:11
      %2847 : bool = aten::ne(%2846, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2847) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2848 : bool = prim::GetAttr[name="training"](%2811)
       = prim::If(%2848) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2849 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2811)
          %2850 : Tensor = aten::add(%2849, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2811, %2850)
          -> ()
        block1():
          -> ()
      %2851 : bool = prim::GetAttr[name="training"](%2811)
      %2852 : Tensor = prim::GetAttr[name="running_mean"](%2811)
      %2853 : Tensor = prim::GetAttr[name="running_var"](%2811)
      %2854 : Tensor = prim::GetAttr[name="weight"](%2811)
      %2855 : Tensor = prim::GetAttr[name="bias"](%2811)
       = prim::If(%2851) # torch/nn/functional.py:2011:4
        block0():
          %2856 : int[] = aten::size(%input.35) # torch/nn/functional.py:2012:27
          %size_prods.28 : int = aten::__getitem__(%2856, %9) # torch/nn/functional.py:1991:17
          %2858 : int = aten::len(%2856) # torch/nn/functional.py:1992:19
          %2859 : int = aten::sub(%2858, %15) # torch/nn/functional.py:1992:19
          %size_prods.29 : int = prim::Loop(%2859, %8, %size_prods.28) # torch/nn/functional.py:1992:4
            block0(%i.8 : int, %size_prods.30 : int):
              %2863 : int = aten::add(%i.8, %15) # torch/nn/functional.py:1993:27
              %2864 : int = aten::__getitem__(%2856, %2863) # torch/nn/functional.py:1993:22
              %size_prods.31 : int = aten::mul(%size_prods.30, %2864) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.31)
          %2866 : bool = aten::eq(%size_prods.29, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2866) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.19 : Tensor = aten::batch_norm(%input.35, %2854, %2855, %2852, %2853, %2851, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.20 : Tensor = aten::relu_(%input.19) # torch/nn/functional.py:1117:17
      %2869 : __torch__.torch.nn.modules.container.___torch_mangle_1040.Sequential = prim::GetAttr[name="branch2"](%2702)
      %2870 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="0"](%2869)
      %2871 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="1"](%2869)
      %2872 : __torch__.torch.nn.modules.conv.___torch_mangle_884.Conv2d = prim::GetAttr[name="3"](%2869)
      %2873 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="4"](%2869)
      %2874 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="5"](%2869)
      %2875 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="6"](%2869)
      %2876 : Tensor = prim::GetAttr[name="weight"](%2870)
      %2877 : Tensor? = prim::GetAttr[name="bias"](%2870)
      %2878 : int[] = prim::ListConstruct(%7, %7)
      %2879 : int[] = prim::ListConstruct(%9, %9)
      %2880 : int[] = prim::ListConstruct(%7, %7)
      %input.36 : Tensor = aten::conv2d(%x.25, %2876, %2877, %2878, %2879, %2880, %7) # torch/nn/modules/conv.py:415:15
      %2882 : int = aten::dim(%input.36) # torch/nn/modules/batchnorm.py:276:11
      %2883 : bool = aten::ne(%2882, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2883) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2884 : bool = prim::GetAttr[name="training"](%2871)
       = prim::If(%2884) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2885 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2871)
          %2886 : Tensor = aten::add(%2885, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2871, %2886)
          -> ()
        block1():
          -> ()
      %2887 : bool = prim::GetAttr[name="training"](%2871)
      %2888 : Tensor = prim::GetAttr[name="running_mean"](%2871)
      %2889 : Tensor = prim::GetAttr[name="running_var"](%2871)
      %2890 : Tensor = prim::GetAttr[name="weight"](%2871)
      %2891 : Tensor = prim::GetAttr[name="bias"](%2871)
       = prim::If(%2887) # torch/nn/functional.py:2011:4
        block0():
          %2892 : int[] = aten::size(%input.36) # torch/nn/functional.py:2012:27
          %size_prods.44 : int = aten::__getitem__(%2892, %9) # torch/nn/functional.py:1991:17
          %2894 : int = aten::len(%2892) # torch/nn/functional.py:1992:19
          %2895 : int = aten::sub(%2894, %15) # torch/nn/functional.py:1992:19
          %size_prods.45 : int = prim::Loop(%2895, %8, %size_prods.44) # torch/nn/functional.py:1992:4
            block0(%i.12 : int, %size_prods.46 : int):
              %2899 : int = aten::add(%i.12, %15) # torch/nn/functional.py:1993:27
              %2900 : int = aten::__getitem__(%2892, %2899) # torch/nn/functional.py:1993:22
              %size_prods.47 : int = aten::mul(%size_prods.46, %2900) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.47)
          %2902 : bool = aten::eq(%size_prods.45, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2902) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.37 : Tensor = aten::batch_norm(%input.36, %2890, %2891, %2888, %2889, %2887, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.38 : Tensor = aten::relu_(%input.37) # torch/nn/functional.py:1117:17
      %2905 : Tensor = prim::GetAttr[name="weight"](%2872)
      %2906 : Tensor? = prim::GetAttr[name="bias"](%2872)
      %2907 : int[] = prim::ListConstruct(%15, %15)
      %2908 : int[] = prim::ListConstruct(%7, %7)
      %2909 : int[] = prim::ListConstruct(%7, %7)
      %input.39 : Tensor = aten::conv2d(%input.38, %2905, %2906, %2907, %2908, %2909, %3) # torch/nn/modules/conv.py:415:15
      %2911 : int = aten::dim(%input.39) # torch/nn/modules/batchnorm.py:276:11
      %2912 : bool = aten::ne(%2911, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2912) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2913 : bool = prim::GetAttr[name="training"](%2873)
       = prim::If(%2913) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2914 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2873)
          %2915 : Tensor = aten::add(%2914, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2873, %2915)
          -> ()
        block1():
          -> ()
      %2916 : bool = prim::GetAttr[name="training"](%2873)
      %2917 : Tensor = prim::GetAttr[name="running_mean"](%2873)
      %2918 : Tensor = prim::GetAttr[name="running_var"](%2873)
      %2919 : Tensor = prim::GetAttr[name="weight"](%2873)
      %2920 : Tensor = prim::GetAttr[name="bias"](%2873)
       = prim::If(%2916) # torch/nn/functional.py:2011:4
        block0():
          %2921 : int[] = aten::size(%input.39) # torch/nn/functional.py:2012:27
          %size_prods.48 : int = aten::__getitem__(%2921, %9) # torch/nn/functional.py:1991:17
          %2923 : int = aten::len(%2921) # torch/nn/functional.py:1992:19
          %2924 : int = aten::sub(%2923, %15) # torch/nn/functional.py:1992:19
          %size_prods.49 : int = prim::Loop(%2924, %8, %size_prods.48) # torch/nn/functional.py:1992:4
            block0(%i.13 : int, %size_prods.50 : int):
              %2928 : int = aten::add(%i.13, %15) # torch/nn/functional.py:1993:27
              %2929 : int = aten::__getitem__(%2921, %2928) # torch/nn/functional.py:1993:22
              %size_prods.51 : int = aten::mul(%size_prods.50, %2929) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.51)
          %2931 : bool = aten::eq(%size_prods.49, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2931) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.40 : Tensor = aten::batch_norm(%input.39, %2919, %2920, %2917, %2918, %2916, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %2933 : Tensor = prim::GetAttr[name="weight"](%2874)
      %2934 : Tensor? = prim::GetAttr[name="bias"](%2874)
      %2935 : int[] = prim::ListConstruct(%7, %7)
      %2936 : int[] = prim::ListConstruct(%9, %9)
      %2937 : int[] = prim::ListConstruct(%7, %7)
      %input.41 : Tensor = aten::conv2d(%input.40, %2933, %2934, %2935, %2936, %2937, %7) # torch/nn/modules/conv.py:415:15
      %2939 : int = aten::dim(%input.41) # torch/nn/modules/batchnorm.py:276:11
      %2940 : bool = aten::ne(%2939, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2940) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2941 : bool = prim::GetAttr[name="training"](%2875)
       = prim::If(%2941) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2942 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2875)
          %2943 : Tensor = aten::add(%2942, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2875, %2943)
          -> ()
        block1():
          -> ()
      %2944 : bool = prim::GetAttr[name="training"](%2875)
      %2945 : Tensor = prim::GetAttr[name="running_mean"](%2875)
      %2946 : Tensor = prim::GetAttr[name="running_var"](%2875)
      %2947 : Tensor = prim::GetAttr[name="weight"](%2875)
      %2948 : Tensor = prim::GetAttr[name="bias"](%2875)
       = prim::If(%2944) # torch/nn/functional.py:2011:4
        block0():
          %2949 : int[] = aten::size(%input.41) # torch/nn/functional.py:2012:27
          %size_prods.52 : int = aten::__getitem__(%2949, %9) # torch/nn/functional.py:1991:17
          %2951 : int = aten::len(%2949) # torch/nn/functional.py:1992:19
          %2952 : int = aten::sub(%2951, %15) # torch/nn/functional.py:1992:19
          %size_prods.53 : int = prim::Loop(%2952, %8, %size_prods.52) # torch/nn/functional.py:1992:4
            block0(%i.14 : int, %size_prods.54 : int):
              %2956 : int = aten::add(%i.14, %15) # torch/nn/functional.py:1993:27
              %2957 : int = aten::__getitem__(%2949, %2956) # torch/nn/functional.py:1993:22
              %size_prods.55 : int = aten::mul(%size_prods.54, %2957) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.55)
          %2959 : bool = aten::eq(%size_prods.53, %7) # torch/nn/functional.py:1994:7
           = prim::If(%2959) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.42 : Tensor = aten::batch_norm(%input.41, %2947, %2948, %2945, %2946, %2944, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.43 : Tensor = aten::relu_(%input.42) # torch/nn/functional.py:1117:17
      %2962 : Tensor[] = prim::ListConstruct(%input.20, %input.43)
      %out.5 : Tensor = aten::cat(%2962, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.5)
  %2964 : Tensor = prim::data(%out.3)
  %2965 : int[] = aten::size(%2964) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.2 : int, %num_channels.2 : int, %height.2 : int, %width.2 : int = prim::ListUnpack(%2965)
  %channels_per_group.2 : int = aten::floordiv(%num_channels.2, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2971 : int[] = prim::ListConstruct(%batchsize.2, %15, %channels_per_group.2, %height.2, %width.2)
  %x.5 : Tensor = aten::view(%out.3, %2971) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2973 : Tensor = aten::transpose(%x.5, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.7 : Tensor = aten::contiguous(%2973, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2975 : int[] = prim::ListConstruct(%batchsize.2, %5, %height.2, %width.2)
  %input.24 : Tensor = aten::view(%x.7, %2975) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2977 : int = prim::GetAttr[name="stride"](%2703)
  %2978 : bool = aten::eq(%2977, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.6 : Tensor = prim::If(%2978) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2980 : Tensor[] = aten::chunk(%input.24, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.3 : Tensor, %x2.3 : Tensor = prim::ListUnpack(%2980)
      %2983 : __torch__.torch.nn.modules.container.___torch_mangle_1042.Sequential = prim::GetAttr[name="branch2"](%2703)
      %2984 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="0"](%2983)
      %2985 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="1"](%2983)
      %2986 : __torch__.torch.nn.modules.conv.___torch_mangle_816.Conv2d = prim::GetAttr[name="3"](%2983)
      %2987 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="4"](%2983)
      %2988 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="5"](%2983)
      %2989 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="6"](%2983)
      %2990 : Tensor = prim::GetAttr[name="weight"](%2984)
      %2991 : Tensor? = prim::GetAttr[name="bias"](%2984)
      %2992 : int[] = prim::ListConstruct(%7, %7)
      %2993 : int[] = prim::ListConstruct(%9, %9)
      %2994 : int[] = prim::ListConstruct(%7, %7)
      %input.44 : Tensor = aten::conv2d(%x2.3, %2990, %2991, %2992, %2993, %2994, %7) # torch/nn/modules/conv.py:415:15
      %2996 : int = aten::dim(%input.44) # torch/nn/modules/batchnorm.py:276:11
      %2997 : bool = aten::ne(%2996, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2997) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2998 : bool = prim::GetAttr[name="training"](%2985)
       = prim::If(%2998) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2999 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2985)
          %3000 : Tensor = aten::add(%2999, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2985, %3000)
          -> ()
        block1():
          -> ()
      %3001 : bool = prim::GetAttr[name="training"](%2985)
      %3002 : Tensor = prim::GetAttr[name="running_mean"](%2985)
      %3003 : Tensor = prim::GetAttr[name="running_var"](%2985)
      %3004 : Tensor = prim::GetAttr[name="weight"](%2985)
      %3005 : Tensor = prim::GetAttr[name="bias"](%2985)
       = prim::If(%3001) # torch/nn/functional.py:2011:4
        block0():
          %3006 : int[] = aten::size(%input.44) # torch/nn/functional.py:2012:27
          %size_prods.56 : int = aten::__getitem__(%3006, %9) # torch/nn/functional.py:1991:17
          %3008 : int = aten::len(%3006) # torch/nn/functional.py:1992:19
          %3009 : int = aten::sub(%3008, %15) # torch/nn/functional.py:1992:19
          %size_prods.57 : int = prim::Loop(%3009, %8, %size_prods.56) # torch/nn/functional.py:1992:4
            block0(%i.15 : int, %size_prods.58 : int):
              %3013 : int = aten::add(%i.15, %15) # torch/nn/functional.py:1993:27
              %3014 : int = aten::__getitem__(%3006, %3013) # torch/nn/functional.py:1993:22
              %size_prods.59 : int = aten::mul(%size_prods.58, %3014) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.59)
          %3016 : bool = aten::eq(%size_prods.57, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3016) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.45 : Tensor = aten::batch_norm(%input.44, %3004, %3005, %3002, %3003, %3001, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.46 : Tensor = aten::relu_(%input.45) # torch/nn/functional.py:1117:17
      %3019 : Tensor = prim::GetAttr[name="weight"](%2986)
      %3020 : Tensor? = prim::GetAttr[name="bias"](%2986)
      %3021 : int[] = prim::ListConstruct(%7, %7)
      %3022 : int[] = prim::ListConstruct(%7, %7)
      %3023 : int[] = prim::ListConstruct(%7, %7)
      %input.47 : Tensor = aten::conv2d(%input.46, %3019, %3020, %3021, %3022, %3023, %3) # torch/nn/modules/conv.py:415:15
      %3025 : int = aten::dim(%input.47) # torch/nn/modules/batchnorm.py:276:11
      %3026 : bool = aten::ne(%3025, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3026) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3027 : bool = prim::GetAttr[name="training"](%2987)
       = prim::If(%3027) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3028 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2987)
          %3029 : Tensor = aten::add(%3028, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2987, %3029)
          -> ()
        block1():
          -> ()
      %3030 : bool = prim::GetAttr[name="training"](%2987)
      %3031 : Tensor = prim::GetAttr[name="running_mean"](%2987)
      %3032 : Tensor = prim::GetAttr[name="running_var"](%2987)
      %3033 : Tensor = prim::GetAttr[name="weight"](%2987)
      %3034 : Tensor = prim::GetAttr[name="bias"](%2987)
       = prim::If(%3030) # torch/nn/functional.py:2011:4
        block0():
          %3035 : int[] = aten::size(%input.47) # torch/nn/functional.py:2012:27
          %size_prods.60 : int = aten::__getitem__(%3035, %9) # torch/nn/functional.py:1991:17
          %3037 : int = aten::len(%3035) # torch/nn/functional.py:1992:19
          %3038 : int = aten::sub(%3037, %15) # torch/nn/functional.py:1992:19
          %size_prods.61 : int = prim::Loop(%3038, %8, %size_prods.60) # torch/nn/functional.py:1992:4
            block0(%i.16 : int, %size_prods.62 : int):
              %3042 : int = aten::add(%i.16, %15) # torch/nn/functional.py:1993:27
              %3043 : int = aten::__getitem__(%3035, %3042) # torch/nn/functional.py:1993:22
              %size_prods.63 : int = aten::mul(%size_prods.62, %3043) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.63)
          %3045 : bool = aten::eq(%size_prods.61, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3045) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.48 : Tensor = aten::batch_norm(%input.47, %3033, %3034, %3031, %3032, %3030, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %3047 : Tensor = prim::GetAttr[name="weight"](%2988)
      %3048 : Tensor? = prim::GetAttr[name="bias"](%2988)
      %3049 : int[] = prim::ListConstruct(%7, %7)
      %3050 : int[] = prim::ListConstruct(%9, %9)
      %3051 : int[] = prim::ListConstruct(%7, %7)
      %input.49 : Tensor = aten::conv2d(%input.48, %3047, %3048, %3049, %3050, %3051, %7) # torch/nn/modules/conv.py:415:15
      %3053 : int = aten::dim(%input.49) # torch/nn/modules/batchnorm.py:276:11
      %3054 : bool = aten::ne(%3053, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3054) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3055 : bool = prim::GetAttr[name="training"](%2989)
       = prim::If(%3055) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3056 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2989)
          %3057 : Tensor = aten::add(%3056, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2989, %3057)
          -> ()
        block1():
          -> ()
      %3058 : bool = prim::GetAttr[name="training"](%2989)
      %3059 : Tensor = prim::GetAttr[name="running_mean"](%2989)
      %3060 : Tensor = prim::GetAttr[name="running_var"](%2989)
      %3061 : Tensor = prim::GetAttr[name="weight"](%2989)
      %3062 : Tensor = prim::GetAttr[name="bias"](%2989)
       = prim::If(%3058) # torch/nn/functional.py:2011:4
        block0():
          %3063 : int[] = aten::size(%input.49) # torch/nn/functional.py:2012:27
          %size_prods.64 : int = aten::__getitem__(%3063, %9) # torch/nn/functional.py:1991:17
          %3065 : int = aten::len(%3063) # torch/nn/functional.py:1992:19
          %3066 : int = aten::sub(%3065, %15) # torch/nn/functional.py:1992:19
          %size_prods.65 : int = prim::Loop(%3066, %8, %size_prods.64) # torch/nn/functional.py:1992:4
            block0(%i.17 : int, %size_prods.66 : int):
              %3070 : int = aten::add(%i.17, %15) # torch/nn/functional.py:1993:27
              %3071 : int = aten::__getitem__(%3063, %3070) # torch/nn/functional.py:1993:22
              %size_prods.67 : int = aten::mul(%size_prods.66, %3071) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.67)
          %3073 : bool = aten::eq(%size_prods.65, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3073) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.50 : Tensor = aten::batch_norm(%input.49, %3061, %3062, %3059, %3060, %3058, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.51 : Tensor = aten::relu_(%input.50) # torch/nn/functional.py:1117:17
      %3076 : Tensor[] = prim::ListConstruct(%x1.3, %input.51)
      %out.7 : Tensor = aten::cat(%3076, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.7)
    block1():
      %3078 : __torch__.torch.nn.modules.container.___torch_mangle_1042.Sequential = prim::GetAttr[name="branch2"](%2703)
      %3079 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="0"](%3078)
      %3080 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="1"](%3078)
      %3081 : __torch__.torch.nn.modules.conv.___torch_mangle_816.Conv2d = prim::GetAttr[name="3"](%3078)
      %3082 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="4"](%3078)
      %3083 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="5"](%3078)
      %3084 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="6"](%3078)
      %3085 : Tensor = prim::GetAttr[name="weight"](%3079)
      %3086 : Tensor? = prim::GetAttr[name="bias"](%3079)
      %3087 : int[] = prim::ListConstruct(%7, %7)
      %3088 : int[] = prim::ListConstruct(%9, %9)
      %3089 : int[] = prim::ListConstruct(%7, %7)
      %input.52 : Tensor = aten::conv2d(%input.24, %3085, %3086, %3087, %3088, %3089, %7) # torch/nn/modules/conv.py:415:15
      %3091 : int = aten::dim(%input.52) # torch/nn/modules/batchnorm.py:276:11
      %3092 : bool = aten::ne(%3091, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3092) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3093 : bool = prim::GetAttr[name="training"](%3080)
       = prim::If(%3093) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3094 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3080)
          %3095 : Tensor = aten::add(%3094, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3080, %3095)
          -> ()
        block1():
          -> ()
      %3096 : bool = prim::GetAttr[name="training"](%3080)
      %3097 : Tensor = prim::GetAttr[name="running_mean"](%3080)
      %3098 : Tensor = prim::GetAttr[name="running_var"](%3080)
      %3099 : Tensor = prim::GetAttr[name="weight"](%3080)
      %3100 : Tensor = prim::GetAttr[name="bias"](%3080)
       = prim::If(%3096) # torch/nn/functional.py:2011:4
        block0():
          %3101 : int[] = aten::size(%input.52) # torch/nn/functional.py:2012:27
          %size_prods.68 : int = aten::__getitem__(%3101, %9) # torch/nn/functional.py:1991:17
          %3103 : int = aten::len(%3101) # torch/nn/functional.py:1992:19
          %3104 : int = aten::sub(%3103, %15) # torch/nn/functional.py:1992:19
          %size_prods.69 : int = prim::Loop(%3104, %8, %size_prods.68) # torch/nn/functional.py:1992:4
            block0(%i.18 : int, %size_prods.70 : int):
              %3108 : int = aten::add(%i.18, %15) # torch/nn/functional.py:1993:27
              %3109 : int = aten::__getitem__(%3101, %3108) # torch/nn/functional.py:1993:22
              %size_prods.71 : int = aten::mul(%size_prods.70, %3109) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.71)
          %3111 : bool = aten::eq(%size_prods.69, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3111) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.53 : Tensor = aten::batch_norm(%input.52, %3099, %3100, %3097, %3098, %3096, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.54 : Tensor = aten::relu_(%input.53) # torch/nn/functional.py:1117:17
      %3114 : Tensor = prim::GetAttr[name="weight"](%3081)
      %3115 : Tensor? = prim::GetAttr[name="bias"](%3081)
      %3116 : int[] = prim::ListConstruct(%7, %7)
      %3117 : int[] = prim::ListConstruct(%7, %7)
      %3118 : int[] = prim::ListConstruct(%7, %7)
      %input.55 : Tensor = aten::conv2d(%input.54, %3114, %3115, %3116, %3117, %3118, %3) # torch/nn/modules/conv.py:415:15
      %3120 : int = aten::dim(%input.55) # torch/nn/modules/batchnorm.py:276:11
      %3121 : bool = aten::ne(%3120, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3121) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3122 : bool = prim::GetAttr[name="training"](%3082)
       = prim::If(%3122) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3123 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3082)
          %3124 : Tensor = aten::add(%3123, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3082, %3124)
          -> ()
        block1():
          -> ()
      %3125 : bool = prim::GetAttr[name="training"](%3082)
      %3126 : Tensor = prim::GetAttr[name="running_mean"](%3082)
      %3127 : Tensor = prim::GetAttr[name="running_var"](%3082)
      %3128 : Tensor = prim::GetAttr[name="weight"](%3082)
      %3129 : Tensor = prim::GetAttr[name="bias"](%3082)
       = prim::If(%3125) # torch/nn/functional.py:2011:4
        block0():
          %3130 : int[] = aten::size(%input.55) # torch/nn/functional.py:2012:27
          %size_prods.72 : int = aten::__getitem__(%3130, %9) # torch/nn/functional.py:1991:17
          %3132 : int = aten::len(%3130) # torch/nn/functional.py:1992:19
          %3133 : int = aten::sub(%3132, %15) # torch/nn/functional.py:1992:19
          %size_prods.73 : int = prim::Loop(%3133, %8, %size_prods.72) # torch/nn/functional.py:1992:4
            block0(%i.19 : int, %size_prods.74 : int):
              %3137 : int = aten::add(%i.19, %15) # torch/nn/functional.py:1993:27
              %3138 : int = aten::__getitem__(%3130, %3137) # torch/nn/functional.py:1993:22
              %size_prods.75 : int = aten::mul(%size_prods.74, %3138) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.75)
          %3140 : bool = aten::eq(%size_prods.73, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3140) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.56 : Tensor = aten::batch_norm(%input.55, %3128, %3129, %3126, %3127, %3125, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %3142 : Tensor = prim::GetAttr[name="weight"](%3083)
      %3143 : Tensor? = prim::GetAttr[name="bias"](%3083)
      %3144 : int[] = prim::ListConstruct(%7, %7)
      %3145 : int[] = prim::ListConstruct(%9, %9)
      %3146 : int[] = prim::ListConstruct(%7, %7)
      %input.57 : Tensor = aten::conv2d(%input.56, %3142, %3143, %3144, %3145, %3146, %7) # torch/nn/modules/conv.py:415:15
      %3148 : int = aten::dim(%input.57) # torch/nn/modules/batchnorm.py:276:11
      %3149 : bool = aten::ne(%3148, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3149) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3150 : bool = prim::GetAttr[name="training"](%3084)
       = prim::If(%3150) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3151 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3084)
          %3152 : Tensor = aten::add(%3151, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3084, %3152)
          -> ()
        block1():
          -> ()
      %3153 : bool = prim::GetAttr[name="training"](%3084)
      %3154 : Tensor = prim::GetAttr[name="running_mean"](%3084)
      %3155 : Tensor = prim::GetAttr[name="running_var"](%3084)
      %3156 : Tensor = prim::GetAttr[name="weight"](%3084)
      %3157 : Tensor = prim::GetAttr[name="bias"](%3084)
       = prim::If(%3153) # torch/nn/functional.py:2011:4
        block0():
          %3158 : int[] = aten::size(%input.57) # torch/nn/functional.py:2012:27
          %size_prods.76 : int = aten::__getitem__(%3158, %9) # torch/nn/functional.py:1991:17
          %3160 : int = aten::len(%3158) # torch/nn/functional.py:1992:19
          %3161 : int = aten::sub(%3160, %15) # torch/nn/functional.py:1992:19
          %size_prods.77 : int = prim::Loop(%3161, %8, %size_prods.76) # torch/nn/functional.py:1992:4
            block0(%i.20 : int, %size_prods.78 : int):
              %3165 : int = aten::add(%i.20, %15) # torch/nn/functional.py:1993:27
              %3166 : int = aten::__getitem__(%3158, %3165) # torch/nn/functional.py:1993:22
              %size_prods.79 : int = aten::mul(%size_prods.78, %3166) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.79)
          %3168 : bool = aten::eq(%size_prods.77, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3168) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.58 : Tensor = aten::batch_norm(%input.57, %3156, %3157, %3154, %3155, %3153, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.59 : Tensor = aten::relu_(%input.58) # torch/nn/functional.py:1117:17
      %3171 : Tensor[] = prim::ListConstruct(%input.24, %input.59)
      %out.9 : Tensor = aten::cat(%3171, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.9)
  %3173 : Tensor = prim::data(%out.6)
  %3174 : int[] = aten::size(%3173) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.3 : int, %num_channels.3 : int, %height.3 : int, %width.3 : int = prim::ListUnpack(%3174)
  %channels_per_group.3 : int = aten::floordiv(%num_channels.3, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %3180 : int[] = prim::ListConstruct(%batchsize.3, %15, %channels_per_group.3, %height.3, %width.3)
  %x.8 : Tensor = aten::view(%out.6, %3180) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %3182 : Tensor = aten::transpose(%x.8, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.9 : Tensor = aten::contiguous(%3182, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %3184 : int[] = prim::ListConstruct(%batchsize.3, %5, %height.3, %width.3)
  %input.25 : Tensor = aten::view(%x.9, %3184) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %3186 : int = prim::GetAttr[name="stride"](%2704)
  %3187 : bool = aten::eq(%3186, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.12 : Tensor = prim::If(%3187) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %3189 : Tensor[] = aten::chunk(%input.25, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.4 : Tensor, %x2.4 : Tensor = prim::ListUnpack(%3189)
      %3192 : __torch__.torch.nn.modules.container.___torch_mangle_1042.Sequential = prim::GetAttr[name="branch2"](%2704)
      %3193 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="0"](%3192)
      %3194 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="1"](%3192)
      %3195 : __torch__.torch.nn.modules.conv.___torch_mangle_816.Conv2d = prim::GetAttr[name="3"](%3192)
      %3196 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="4"](%3192)
      %3197 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="5"](%3192)
      %3198 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="6"](%3192)
      %3199 : Tensor = prim::GetAttr[name="weight"](%3193)
      %3200 : Tensor? = prim::GetAttr[name="bias"](%3193)
      %3201 : int[] = prim::ListConstruct(%7, %7)
      %3202 : int[] = prim::ListConstruct(%9, %9)
      %3203 : int[] = prim::ListConstruct(%7, %7)
      %input.60 : Tensor = aten::conv2d(%x2.4, %3199, %3200, %3201, %3202, %3203, %7) # torch/nn/modules/conv.py:415:15
      %3205 : int = aten::dim(%input.60) # torch/nn/modules/batchnorm.py:276:11
      %3206 : bool = aten::ne(%3205, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3206) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3207 : bool = prim::GetAttr[name="training"](%3194)
       = prim::If(%3207) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3208 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3194)
          %3209 : Tensor = aten::add(%3208, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3194, %3209)
          -> ()
        block1():
          -> ()
      %3210 : bool = prim::GetAttr[name="training"](%3194)
      %3211 : Tensor = prim::GetAttr[name="running_mean"](%3194)
      %3212 : Tensor = prim::GetAttr[name="running_var"](%3194)
      %3213 : Tensor = prim::GetAttr[name="weight"](%3194)
      %3214 : Tensor = prim::GetAttr[name="bias"](%3194)
       = prim::If(%3210) # torch/nn/functional.py:2011:4
        block0():
          %3215 : int[] = aten::size(%input.60) # torch/nn/functional.py:2012:27
          %size_prods.80 : int = aten::__getitem__(%3215, %9) # torch/nn/functional.py:1991:17
          %3217 : int = aten::len(%3215) # torch/nn/functional.py:1992:19
          %3218 : int = aten::sub(%3217, %15) # torch/nn/functional.py:1992:19
          %size_prods.81 : int = prim::Loop(%3218, %8, %size_prods.80) # torch/nn/functional.py:1992:4
            block0(%i.21 : int, %size_prods.82 : int):
              %3222 : int = aten::add(%i.21, %15) # torch/nn/functional.py:1993:27
              %3223 : int = aten::__getitem__(%3215, %3222) # torch/nn/functional.py:1993:22
              %size_prods.83 : int = aten::mul(%size_prods.82, %3223) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.83)
          %3225 : bool = aten::eq(%size_prods.81, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3225) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.61 : Tensor = aten::batch_norm(%input.60, %3213, %3214, %3211, %3212, %3210, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.62 : Tensor = aten::relu_(%input.61) # torch/nn/functional.py:1117:17
      %3228 : Tensor = prim::GetAttr[name="weight"](%3195)
      %3229 : Tensor? = prim::GetAttr[name="bias"](%3195)
      %3230 : int[] = prim::ListConstruct(%7, %7)
      %3231 : int[] = prim::ListConstruct(%7, %7)
      %3232 : int[] = prim::ListConstruct(%7, %7)
      %input.63 : Tensor = aten::conv2d(%input.62, %3228, %3229, %3230, %3231, %3232, %3) # torch/nn/modules/conv.py:415:15
      %3234 : int = aten::dim(%input.63) # torch/nn/modules/batchnorm.py:276:11
      %3235 : bool = aten::ne(%3234, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3235) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3236 : bool = prim::GetAttr[name="training"](%3196)
       = prim::If(%3236) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3237 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3196)
          %3238 : Tensor = aten::add(%3237, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3196, %3238)
          -> ()
        block1():
          -> ()
      %3239 : bool = prim::GetAttr[name="training"](%3196)
      %3240 : Tensor = prim::GetAttr[name="running_mean"](%3196)
      %3241 : Tensor = prim::GetAttr[name="running_var"](%3196)
      %3242 : Tensor = prim::GetAttr[name="weight"](%3196)
      %3243 : Tensor = prim::GetAttr[name="bias"](%3196)
       = prim::If(%3239) # torch/nn/functional.py:2011:4
        block0():
          %3244 : int[] = aten::size(%input.63) # torch/nn/functional.py:2012:27
          %size_prods.84 : int = aten::__getitem__(%3244, %9) # torch/nn/functional.py:1991:17
          %3246 : int = aten::len(%3244) # torch/nn/functional.py:1992:19
          %3247 : int = aten::sub(%3246, %15) # torch/nn/functional.py:1992:19
          %size_prods.85 : int = prim::Loop(%3247, %8, %size_prods.84) # torch/nn/functional.py:1992:4
            block0(%i.22 : int, %size_prods.86 : int):
              %3251 : int = aten::add(%i.22, %15) # torch/nn/functional.py:1993:27
              %3252 : int = aten::__getitem__(%3244, %3251) # torch/nn/functional.py:1993:22
              %size_prods.87 : int = aten::mul(%size_prods.86, %3252) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.87)
          %3254 : bool = aten::eq(%size_prods.85, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3254) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.64 : Tensor = aten::batch_norm(%input.63, %3242, %3243, %3240, %3241, %3239, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %3256 : Tensor = prim::GetAttr[name="weight"](%3197)
      %3257 : Tensor? = prim::GetAttr[name="bias"](%3197)
      %3258 : int[] = prim::ListConstruct(%7, %7)
      %3259 : int[] = prim::ListConstruct(%9, %9)
      %3260 : int[] = prim::ListConstruct(%7, %7)
      %input.65 : Tensor = aten::conv2d(%input.64, %3256, %3257, %3258, %3259, %3260, %7) # torch/nn/modules/conv.py:415:15
      %3262 : int = aten::dim(%input.65) # torch/nn/modules/batchnorm.py:276:11
      %3263 : bool = aten::ne(%3262, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3263) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3264 : bool = prim::GetAttr[name="training"](%3198)
       = prim::If(%3264) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3265 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3198)
          %3266 : Tensor = aten::add(%3265, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3198, %3266)
          -> ()
        block1():
          -> ()
      %3267 : bool = prim::GetAttr[name="training"](%3198)
      %3268 : Tensor = prim::GetAttr[name="running_mean"](%3198)
      %3269 : Tensor = prim::GetAttr[name="running_var"](%3198)
      %3270 : Tensor = prim::GetAttr[name="weight"](%3198)
      %3271 : Tensor = prim::GetAttr[name="bias"](%3198)
       = prim::If(%3267) # torch/nn/functional.py:2011:4
        block0():
          %3272 : int[] = aten::size(%input.65) # torch/nn/functional.py:2012:27
          %size_prods.88 : int = aten::__getitem__(%3272, %9) # torch/nn/functional.py:1991:17
          %3274 : int = aten::len(%3272) # torch/nn/functional.py:1992:19
          %3275 : int = aten::sub(%3274, %15) # torch/nn/functional.py:1992:19
          %size_prods.89 : int = prim::Loop(%3275, %8, %size_prods.88) # torch/nn/functional.py:1992:4
            block0(%i.23 : int, %size_prods.90 : int):
              %3279 : int = aten::add(%i.23, %15) # torch/nn/functional.py:1993:27
              %3280 : int = aten::__getitem__(%3272, %3279) # torch/nn/functional.py:1993:22
              %size_prods.91 : int = aten::mul(%size_prods.90, %3280) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.91)
          %3282 : bool = aten::eq(%size_prods.89, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3282) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.66 : Tensor = aten::batch_norm(%input.65, %3270, %3271, %3268, %3269, %3267, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.67 : Tensor = aten::relu_(%input.66) # torch/nn/functional.py:1117:17
      %3285 : Tensor[] = prim::ListConstruct(%x1.4, %input.67)
      %out.10 : Tensor = aten::cat(%3285, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.10)
    block1():
      %3287 : __torch__.torch.nn.modules.container.___torch_mangle_1042.Sequential = prim::GetAttr[name="branch2"](%2704)
      %3288 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="0"](%3287)
      %3289 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="1"](%3287)
      %3290 : __torch__.torch.nn.modules.conv.___torch_mangle_816.Conv2d = prim::GetAttr[name="3"](%3287)
      %3291 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="4"](%3287)
      %3292 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="5"](%3287)
      %3293 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="6"](%3287)
      %3294 : Tensor = prim::GetAttr[name="weight"](%3288)
      %3295 : Tensor? = prim::GetAttr[name="bias"](%3288)
      %3296 : int[] = prim::ListConstruct(%7, %7)
      %3297 : int[] = prim::ListConstruct(%9, %9)
      %3298 : int[] = prim::ListConstruct(%7, %7)
      %input.68 : Tensor = aten::conv2d(%input.25, %3294, %3295, %3296, %3297, %3298, %7) # torch/nn/modules/conv.py:415:15
      %3300 : int = aten::dim(%input.68) # torch/nn/modules/batchnorm.py:276:11
      %3301 : bool = aten::ne(%3300, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3301) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3302 : bool = prim::GetAttr[name="training"](%3289)
       = prim::If(%3302) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3303 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3289)
          %3304 : Tensor = aten::add(%3303, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3289, %3304)
          -> ()
        block1():
          -> ()
      %3305 : bool = prim::GetAttr[name="training"](%3289)
      %3306 : Tensor = prim::GetAttr[name="running_mean"](%3289)
      %3307 : Tensor = prim::GetAttr[name="running_var"](%3289)
      %3308 : Tensor = prim::GetAttr[name="weight"](%3289)
      %3309 : Tensor = prim::GetAttr[name="bias"](%3289)
       = prim::If(%3305) # torch/nn/functional.py:2011:4
        block0():
          %3310 : int[] = aten::size(%input.68) # torch/nn/functional.py:2012:27
          %size_prods.92 : int = aten::__getitem__(%3310, %9) # torch/nn/functional.py:1991:17
          %3312 : int = aten::len(%3310) # torch/nn/functional.py:1992:19
          %3313 : int = aten::sub(%3312, %15) # torch/nn/functional.py:1992:19
          %size_prods.93 : int = prim::Loop(%3313, %8, %size_prods.92) # torch/nn/functional.py:1992:4
            block0(%i.24 : int, %size_prods.94 : int):
              %3317 : int = aten::add(%i.24, %15) # torch/nn/functional.py:1993:27
              %3318 : int = aten::__getitem__(%3310, %3317) # torch/nn/functional.py:1993:22
              %size_prods.95 : int = aten::mul(%size_prods.94, %3318) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.95)
          %3320 : bool = aten::eq(%size_prods.93, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3320) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.69 : Tensor = aten::batch_norm(%input.68, %3308, %3309, %3306, %3307, %3305, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.70 : Tensor = aten::relu_(%input.69) # torch/nn/functional.py:1117:17
      %3323 : Tensor = prim::GetAttr[name="weight"](%3290)
      %3324 : Tensor? = prim::GetAttr[name="bias"](%3290)
      %3325 : int[] = prim::ListConstruct(%7, %7)
      %3326 : int[] = prim::ListConstruct(%7, %7)
      %3327 : int[] = prim::ListConstruct(%7, %7)
      %input.71 : Tensor = aten::conv2d(%input.70, %3323, %3324, %3325, %3326, %3327, %3) # torch/nn/modules/conv.py:415:15
      %3329 : int = aten::dim(%input.71) # torch/nn/modules/batchnorm.py:276:11
      %3330 : bool = aten::ne(%3329, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3330) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3331 : bool = prim::GetAttr[name="training"](%3291)
       = prim::If(%3331) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3332 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3291)
          %3333 : Tensor = aten::add(%3332, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3291, %3333)
          -> ()
        block1():
          -> ()
      %3334 : bool = prim::GetAttr[name="training"](%3291)
      %3335 : Tensor = prim::GetAttr[name="running_mean"](%3291)
      %3336 : Tensor = prim::GetAttr[name="running_var"](%3291)
      %3337 : Tensor = prim::GetAttr[name="weight"](%3291)
      %3338 : Tensor = prim::GetAttr[name="bias"](%3291)
       = prim::If(%3334) # torch/nn/functional.py:2011:4
        block0():
          %3339 : int[] = aten::size(%input.71) # torch/nn/functional.py:2012:27
          %size_prods.96 : int = aten::__getitem__(%3339, %9) # torch/nn/functional.py:1991:17
          %3341 : int = aten::len(%3339) # torch/nn/functional.py:1992:19
          %3342 : int = aten::sub(%3341, %15) # torch/nn/functional.py:1992:19
          %size_prods.97 : int = prim::Loop(%3342, %8, %size_prods.96) # torch/nn/functional.py:1992:4
            block0(%i.25 : int, %size_prods.98 : int):
              %3346 : int = aten::add(%i.25, %15) # torch/nn/functional.py:1993:27
              %3347 : int = aten::__getitem__(%3339, %3346) # torch/nn/functional.py:1993:22
              %size_prods.99 : int = aten::mul(%size_prods.98, %3347) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.99)
          %3349 : bool = aten::eq(%size_prods.97, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3349) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.72 : Tensor = aten::batch_norm(%input.71, %3337, %3338, %3335, %3336, %3334, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %3351 : Tensor = prim::GetAttr[name="weight"](%3292)
      %3352 : Tensor? = prim::GetAttr[name="bias"](%3292)
      %3353 : int[] = prim::ListConstruct(%7, %7)
      %3354 : int[] = prim::ListConstruct(%9, %9)
      %3355 : int[] = prim::ListConstruct(%7, %7)
      %input.73 : Tensor = aten::conv2d(%input.72, %3351, %3352, %3353, %3354, %3355, %7) # torch/nn/modules/conv.py:415:15
      %3357 : int = aten::dim(%input.73) # torch/nn/modules/batchnorm.py:276:11
      %3358 : bool = aten::ne(%3357, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3358) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3359 : bool = prim::GetAttr[name="training"](%3293)
       = prim::If(%3359) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3360 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3293)
          %3361 : Tensor = aten::add(%3360, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3293, %3361)
          -> ()
        block1():
          -> ()
      %3362 : bool = prim::GetAttr[name="training"](%3293)
      %3363 : Tensor = prim::GetAttr[name="running_mean"](%3293)
      %3364 : Tensor = prim::GetAttr[name="running_var"](%3293)
      %3365 : Tensor = prim::GetAttr[name="weight"](%3293)
      %3366 : Tensor = prim::GetAttr[name="bias"](%3293)
       = prim::If(%3362) # torch/nn/functional.py:2011:4
        block0():
          %3367 : int[] = aten::size(%input.73) # torch/nn/functional.py:2012:27
          %size_prods.100 : int = aten::__getitem__(%3367, %9) # torch/nn/functional.py:1991:17
          %3369 : int = aten::len(%3367) # torch/nn/functional.py:1992:19
          %3370 : int = aten::sub(%3369, %15) # torch/nn/functional.py:1992:19
          %size_prods.101 : int = prim::Loop(%3370, %8, %size_prods.100) # torch/nn/functional.py:1992:4
            block0(%i.26 : int, %size_prods.102 : int):
              %3374 : int = aten::add(%i.26, %15) # torch/nn/functional.py:1993:27
              %3375 : int = aten::__getitem__(%3367, %3374) # torch/nn/functional.py:1993:22
              %size_prods.103 : int = aten::mul(%size_prods.102, %3375) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.103)
          %3377 : bool = aten::eq(%size_prods.101, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3377) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.74 : Tensor = aten::batch_norm(%input.73, %3365, %3366, %3363, %3364, %3362, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.75 : Tensor = aten::relu_(%input.74) # torch/nn/functional.py:1117:17
      %3380 : Tensor[] = prim::ListConstruct(%input.25, %input.75)
      %out.11 : Tensor = aten::cat(%3380, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.11)
  %3382 : Tensor = prim::data(%out.12)
  %3383 : int[] = aten::size(%3382) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.4 : int, %num_channels.4 : int, %height.4 : int, %width.4 : int = prim::ListUnpack(%3383)
  %channels_per_group.4 : int = aten::floordiv(%num_channels.4, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %3389 : int[] = prim::ListConstruct(%batchsize.4, %15, %channels_per_group.4, %height.4, %width.4)
  %x.10 : Tensor = aten::view(%out.12, %3389) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %3391 : Tensor = aten::transpose(%x.10, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.11 : Tensor = aten::contiguous(%3391, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %3393 : int[] = prim::ListConstruct(%batchsize.4, %5, %height.4, %width.4)
  %input.26 : Tensor = aten::view(%x.11, %3393) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %3395 : int = prim::GetAttr[name="stride"](%2705)
  %3396 : bool = aten::eq(%3395, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out : Tensor = prim::If(%3396) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %3398 : Tensor[] = aten::chunk(%input.26, %15, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.1 : Tensor, %x2.1 : Tensor = prim::ListUnpack(%3398)
      %3401 : __torch__.torch.nn.modules.container.___torch_mangle_1042.Sequential = prim::GetAttr[name="branch2"](%2705)
      %3402 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="0"](%3401)
      %3403 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="1"](%3401)
      %3404 : __torch__.torch.nn.modules.conv.___torch_mangle_816.Conv2d = prim::GetAttr[name="3"](%3401)
      %3405 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="4"](%3401)
      %3406 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="5"](%3401)
      %3407 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="6"](%3401)
      %3408 : Tensor = prim::GetAttr[name="weight"](%3402)
      %3409 : Tensor? = prim::GetAttr[name="bias"](%3402)
      %3410 : int[] = prim::ListConstruct(%7, %7)
      %3411 : int[] = prim::ListConstruct(%9, %9)
      %3412 : int[] = prim::ListConstruct(%7, %7)
      %input.4 : Tensor = aten::conv2d(%x2.1, %3408, %3409, %3410, %3411, %3412, %7) # torch/nn/modules/conv.py:415:15
      %3414 : int = aten::dim(%input.4) # torch/nn/modules/batchnorm.py:276:11
      %3415 : bool = aten::ne(%3414, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3415) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3416 : bool = prim::GetAttr[name="training"](%3403)
       = prim::If(%3416) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3417 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3403)
          %3418 : Tensor = aten::add(%3417, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3403, %3418)
          -> ()
        block1():
          -> ()
      %3419 : bool = prim::GetAttr[name="training"](%3403)
      %3420 : Tensor = prim::GetAttr[name="running_mean"](%3403)
      %3421 : Tensor = prim::GetAttr[name="running_var"](%3403)
      %3422 : Tensor = prim::GetAttr[name="weight"](%3403)
      %3423 : Tensor = prim::GetAttr[name="bias"](%3403)
       = prim::If(%3419) # torch/nn/functional.py:2011:4
        block0():
          %3424 : int[] = aten::size(%input.4) # torch/nn/functional.py:2012:27
          %size_prods.12 : int = aten::__getitem__(%3424, %9) # torch/nn/functional.py:1991:17
          %3426 : int = aten::len(%3424) # torch/nn/functional.py:1992:19
          %3427 : int = aten::sub(%3426, %15) # torch/nn/functional.py:1992:19
          %size_prods.13 : int = prim::Loop(%3427, %8, %size_prods.12) # torch/nn/functional.py:1992:4
            block0(%i.4 : int, %size_prods.14 : int):
              %3431 : int = aten::add(%i.4, %15) # torch/nn/functional.py:1993:27
              %3432 : int = aten::__getitem__(%3424, %3431) # torch/nn/functional.py:1993:22
              %size_prods.15 : int = aten::mul(%size_prods.14, %3432) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.15)
          %3434 : bool = aten::eq(%size_prods.13, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3434) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.6 : Tensor = aten::batch_norm(%input.4, %3422, %3423, %3420, %3421, %3419, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.8 : Tensor = aten::relu_(%input.6) # torch/nn/functional.py:1117:17
      %3437 : Tensor = prim::GetAttr[name="weight"](%3404)
      %3438 : Tensor? = prim::GetAttr[name="bias"](%3404)
      %3439 : int[] = prim::ListConstruct(%7, %7)
      %3440 : int[] = prim::ListConstruct(%7, %7)
      %3441 : int[] = prim::ListConstruct(%7, %7)
      %input.10 : Tensor = aten::conv2d(%input.8, %3437, %3438, %3439, %3440, %3441, %3) # torch/nn/modules/conv.py:415:15
      %3443 : int = aten::dim(%input.10) # torch/nn/modules/batchnorm.py:276:11
      %3444 : bool = aten::ne(%3443, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3444) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3445 : bool = prim::GetAttr[name="training"](%3405)
       = prim::If(%3445) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3446 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3405)
          %3447 : Tensor = aten::add(%3446, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3405, %3447)
          -> ()
        block1():
          -> ()
      %3448 : bool = prim::GetAttr[name="training"](%3405)
      %3449 : Tensor = prim::GetAttr[name="running_mean"](%3405)
      %3450 : Tensor = prim::GetAttr[name="running_var"](%3405)
      %3451 : Tensor = prim::GetAttr[name="weight"](%3405)
      %3452 : Tensor = prim::GetAttr[name="bias"](%3405)
       = prim::If(%3448) # torch/nn/functional.py:2011:4
        block0():
          %3453 : int[] = aten::size(%input.10) # torch/nn/functional.py:2012:27
          %size_prods.16 : int = aten::__getitem__(%3453, %9) # torch/nn/functional.py:1991:17
          %3455 : int = aten::len(%3453) # torch/nn/functional.py:1992:19
          %3456 : int = aten::sub(%3455, %15) # torch/nn/functional.py:1992:19
          %size_prods.17 : int = prim::Loop(%3456, %8, %size_prods.16) # torch/nn/functional.py:1992:4
            block0(%i.5 : int, %size_prods.18 : int):
              %3460 : int = aten::add(%i.5, %15) # torch/nn/functional.py:1993:27
              %3461 : int = aten::__getitem__(%3453, %3460) # torch/nn/functional.py:1993:22
              %size_prods.19 : int = aten::mul(%size_prods.18, %3461) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.19)
          %3463 : bool = aten::eq(%size_prods.17, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3463) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.12 : Tensor = aten::batch_norm(%input.10, %3451, %3452, %3449, %3450, %3448, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %3465 : Tensor = prim::GetAttr[name="weight"](%3406)
      %3466 : Tensor? = prim::GetAttr[name="bias"](%3406)
      %3467 : int[] = prim::ListConstruct(%7, %7)
      %3468 : int[] = prim::ListConstruct(%9, %9)
      %3469 : int[] = prim::ListConstruct(%7, %7)
      %input.14 : Tensor = aten::conv2d(%input.12, %3465, %3466, %3467, %3468, %3469, %7) # torch/nn/modules/conv.py:415:15
      %3471 : int = aten::dim(%input.14) # torch/nn/modules/batchnorm.py:276:11
      %3472 : bool = aten::ne(%3471, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3472) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3473 : bool = prim::GetAttr[name="training"](%3407)
       = prim::If(%3473) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3474 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3407)
          %3475 : Tensor = aten::add(%3474, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3407, %3475)
          -> ()
        block1():
          -> ()
      %3476 : bool = prim::GetAttr[name="training"](%3407)
      %3477 : Tensor = prim::GetAttr[name="running_mean"](%3407)
      %3478 : Tensor = prim::GetAttr[name="running_var"](%3407)
      %3479 : Tensor = prim::GetAttr[name="weight"](%3407)
      %3480 : Tensor = prim::GetAttr[name="bias"](%3407)
       = prim::If(%3476) # torch/nn/functional.py:2011:4
        block0():
          %3481 : int[] = aten::size(%input.14) # torch/nn/functional.py:2012:27
          %size_prods.20 : int = aten::__getitem__(%3481, %9) # torch/nn/functional.py:1991:17
          %3483 : int = aten::len(%3481) # torch/nn/functional.py:1992:19
          %3484 : int = aten::sub(%3483, %15) # torch/nn/functional.py:1992:19
          %size_prods.21 : int = prim::Loop(%3484, %8, %size_prods.20) # torch/nn/functional.py:1992:4
            block0(%i.6 : int, %size_prods.22 : int):
              %3488 : int = aten::add(%i.6, %15) # torch/nn/functional.py:1993:27
              %3489 : int = aten::__getitem__(%3481, %3488) # torch/nn/functional.py:1993:22
              %size_prods.23 : int = aten::mul(%size_prods.22, %3489) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.23)
          %3491 : bool = aten::eq(%size_prods.21, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3491) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.16 : Tensor = aten::batch_norm(%input.14, %3479, %3480, %3477, %3478, %3476, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.18 : Tensor = aten::relu_(%input.16) # torch/nn/functional.py:1117:17
      %3494 : Tensor[] = prim::ListConstruct(%x1.1, %input.18)
      %out.1 : Tensor = aten::cat(%3494, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.1)
    block1():
      %3496 : __torch__.torch.nn.modules.container.___torch_mangle_1042.Sequential = prim::GetAttr[name="branch2"](%2705)
      %3497 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="0"](%3496)
      %3498 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="1"](%3496)
      %3499 : __torch__.torch.nn.modules.conv.___torch_mangle_816.Conv2d = prim::GetAttr[name="3"](%3496)
      %3500 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="4"](%3496)
      %3501 : __torch__.torch.nn.modules.conv.___torch_mangle_1038.Conv2d = prim::GetAttr[name="5"](%3496)
      %3502 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_73.BatchNorm2d = prim::GetAttr[name="6"](%3496)
      %3503 : Tensor = prim::GetAttr[name="weight"](%3497)
      %3504 : Tensor? = prim::GetAttr[name="bias"](%3497)
      %3505 : int[] = prim::ListConstruct(%7, %7)
      %3506 : int[] = prim::ListConstruct(%9, %9)
      %3507 : int[] = prim::ListConstruct(%7, %7)
      %input.27 : Tensor = aten::conv2d(%input.26, %3503, %3504, %3505, %3506, %3507, %7) # torch/nn/modules/conv.py:415:15
      %3509 : int = aten::dim(%input.27) # torch/nn/modules/batchnorm.py:276:11
      %3510 : bool = aten::ne(%3509, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3510) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3511 : bool = prim::GetAttr[name="training"](%3498)
       = prim::If(%3511) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3512 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3498)
          %3513 : Tensor = aten::add(%3512, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3498, %3513)
          -> ()
        block1():
          -> ()
      %3514 : bool = prim::GetAttr[name="training"](%3498)
      %3515 : Tensor = prim::GetAttr[name="running_mean"](%3498)
      %3516 : Tensor = prim::GetAttr[name="running_var"](%3498)
      %3517 : Tensor = prim::GetAttr[name="weight"](%3498)
      %3518 : Tensor = prim::GetAttr[name="bias"](%3498)
       = prim::If(%3514) # torch/nn/functional.py:2011:4
        block0():
          %3519 : int[] = aten::size(%input.27) # torch/nn/functional.py:2012:27
          %size_prods.2 : int = aten::__getitem__(%3519, %9) # torch/nn/functional.py:1991:17
          %3521 : int = aten::len(%3519) # torch/nn/functional.py:1992:19
          %3522 : int = aten::sub(%3521, %15) # torch/nn/functional.py:1992:19
          %size_prods.4 : int = prim::Loop(%3522, %8, %size_prods.2) # torch/nn/functional.py:1992:4
            block0(%i.2 : int, %size_prods.7 : int):
              %3526 : int = aten::add(%i.2, %15) # torch/nn/functional.py:1993:27
              %3527 : int = aten::__getitem__(%3519, %3526) # torch/nn/functional.py:1993:22
              %size_prods.5 : int = aten::mul(%size_prods.7, %3527) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.5)
          %3529 : bool = aten::eq(%size_prods.4, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3529) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.290 : Tensor = aten::batch_norm(%input.27, %3517, %3518, %3515, %3516, %3514, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.291 : Tensor = aten::relu_(%input.290) # torch/nn/functional.py:1117:17
      %3532 : Tensor = prim::GetAttr[name="weight"](%3499)
      %3533 : Tensor? = prim::GetAttr[name="bias"](%3499)
      %3534 : int[] = prim::ListConstruct(%7, %7)
      %3535 : int[] = prim::ListConstruct(%7, %7)
      %3536 : int[] = prim::ListConstruct(%7, %7)
      %input.9 : Tensor = aten::conv2d(%input.291, %3532, %3533, %3534, %3535, %3536, %3) # torch/nn/modules/conv.py:415:15
      %3538 : int = aten::dim(%input.9) # torch/nn/modules/batchnorm.py:276:11
      %3539 : bool = aten::ne(%3538, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3539) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3540 : bool = prim::GetAttr[name="training"](%3500)
       = prim::If(%3540) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3541 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3500)
          %3542 : Tensor = aten::add(%3541, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3500, %3542)
          -> ()
        block1():
          -> ()
      %3543 : bool = prim::GetAttr[name="training"](%3500)
      %3544 : Tensor = prim::GetAttr[name="running_mean"](%3500)
      %3545 : Tensor = prim::GetAttr[name="running_var"](%3500)
      %3546 : Tensor = prim::GetAttr[name="weight"](%3500)
      %3547 : Tensor = prim::GetAttr[name="bias"](%3500)
       = prim::If(%3543) # torch/nn/functional.py:2011:4
        block0():
          %3548 : int[] = aten::size(%input.9) # torch/nn/functional.py:2012:27
          %size_prods.8 : int = aten::__getitem__(%3548, %9) # torch/nn/functional.py:1991:17
          %3550 : int = aten::len(%3548) # torch/nn/functional.py:1992:19
          %3551 : int = aten::sub(%3550, %15) # torch/nn/functional.py:1992:19
          %size_prods.9 : int = prim::Loop(%3551, %8, %size_prods.8) # torch/nn/functional.py:1992:4
            block0(%i.3 : int, %size_prods.10 : int):
              %3555 : int = aten::add(%i.3, %15) # torch/nn/functional.py:1993:27
              %3556 : int = aten::__getitem__(%3548, %3555) # torch/nn/functional.py:1993:22
              %size_prods.11 : int = aten::mul(%size_prods.10, %3556) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.11)
          %3558 : bool = aten::eq(%size_prods.9, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3558) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.11 : Tensor = aten::batch_norm(%input.9, %3546, %3547, %3544, %3545, %3543, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %3560 : Tensor = prim::GetAttr[name="weight"](%3501)
      %3561 : Tensor? = prim::GetAttr[name="bias"](%3501)
      %3562 : int[] = prim::ListConstruct(%7, %7)
      %3563 : int[] = prim::ListConstruct(%9, %9)
      %3564 : int[] = prim::ListConstruct(%7, %7)
      %input.13 : Tensor = aten::conv2d(%input.11, %3560, %3561, %3562, %3563, %3564, %7) # torch/nn/modules/conv.py:415:15
      %3566 : int = aten::dim(%input.13) # torch/nn/modules/batchnorm.py:276:11
      %3567 : bool = aten::ne(%3566, %11) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3567) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3568 : bool = prim::GetAttr[name="training"](%3502)
       = prim::If(%3568) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3569 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3502)
          %3570 : Tensor = aten::add(%3569, %7, %7) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3502, %3570)
          -> ()
        block1():
          -> ()
      %3571 : bool = prim::GetAttr[name="training"](%3502)
      %3572 : Tensor = prim::GetAttr[name="running_mean"](%3502)
      %3573 : Tensor = prim::GetAttr[name="running_var"](%3502)
      %3574 : Tensor = prim::GetAttr[name="weight"](%3502)
      %3575 : Tensor = prim::GetAttr[name="bias"](%3502)
       = prim::If(%3571) # torch/nn/functional.py:2011:4
        block0():
          %3576 : int[] = aten::size(%input.13) # torch/nn/functional.py:2012:27
          %size_prods.412 : int = aten::__getitem__(%3576, %9) # torch/nn/functional.py:1991:17
          %3578 : int = aten::len(%3576) # torch/nn/functional.py:1992:19
          %3579 : int = aten::sub(%3578, %15) # torch/nn/functional.py:1992:19
          %size_prods.413 : int = prim::Loop(%3579, %8, %size_prods.412) # torch/nn/functional.py:1992:4
            block0(%i.104 : int, %size_prods.414 : int):
              %3583 : int = aten::add(%i.104, %15) # torch/nn/functional.py:1993:27
              %3584 : int = aten::__getitem__(%3576, %3583) # torch/nn/functional.py:1993:22
              %size_prods.415 : int = aten::mul(%size_prods.414, %3584) # torch/nn/functional.py:1993:8
              -> (%8, %size_prods.415)
          %3586 : bool = aten::eq(%size_prods.413, %7) # torch/nn/functional.py:1994:7
           = prim::If(%3586) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.15 : Tensor = aten::batch_norm(%input.13, %3574, %3575, %3572, %3573, %3571, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
      %input.17 : Tensor = aten::relu_(%input.15) # torch/nn/functional.py:1117:17
      %3589 : Tensor[] = prim::ListConstruct(%input.26, %input.17)
      %out.2 : Tensor = aten::cat(%3589, %7) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.2)
  %3591 : Tensor = prim::data(%out)
  %3592 : int[] = aten::size(%3591) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.1 : int, %num_channels.1 : int, %height.1 : int, %width.1 : int = prim::ListUnpack(%3592)
  %channels_per_group.1 : int = aten::floordiv(%num_channels.1, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %3598 : int[] = prim::ListConstruct(%batchsize.1, %15, %channels_per_group.1, %height.1, %width.1)
  %x.4 : Tensor = aten::view(%out, %3598) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %3600 : Tensor = aten::transpose(%x.4, %7, %15) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.6 : Tensor = aten::contiguous(%3600, %9) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %3602 : int[] = prim::ListConstruct(%batchsize.1, %5, %height.1, %width.1)
  %x.29 : Tensor = aten::view(%x.6, %3602) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %3604 : __torch__.torch.nn.modules.container.___torch_mangle_1046.Sequential = prim::GetAttr[name="conv5"](%self)
  %3605 : __torch__.torch.nn.modules.conv.___torch_mangle_1045.Conv2d = prim::GetAttr[name="0"](%3604)
  %3606 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_31.BatchNorm2d = prim::GetAttr[name="1"](%3604)
  %3607 : Tensor = prim::GetAttr[name="weight"](%3605)
  %3608 : Tensor? = prim::GetAttr[name="bias"](%3605)
  %3609 : int[] = prim::ListConstruct(%7, %7)
  %3610 : int[] = prim::ListConstruct(%9, %9)
  %3611 : int[] = prim::ListConstruct(%7, %7)
  %input.3 : Tensor = aten::conv2d(%x.29, %3607, %3608, %3609, %3610, %3611, %7) # torch/nn/modules/conv.py:415:15
  %3613 : int = aten::dim(%input.3) # torch/nn/modules/batchnorm.py:276:11
  %3614 : bool = aten::ne(%3613, %11) # torch/nn/modules/batchnorm.py:276:11
   = prim::If(%3614) # torch/nn/modules/batchnorm.py:276:8
    block0():
       = prim::RaiseException(%10) # torch/nn/modules/batchnorm.py:277:12
      -> ()
    block1():
      -> ()
  %3615 : bool = prim::GetAttr[name="training"](%3606)
   = prim::If(%3615) # torch/nn/modules/batchnorm.py:110:11
    block0():
      %3616 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3606)
      %3617 : Tensor = aten::add(%3616, %7, %7) # torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3606, %3617)
      -> ()
    block1():
      -> ()
  %3618 : bool = prim::GetAttr[name="training"](%3606)
  %3619 : Tensor = prim::GetAttr[name="running_mean"](%3606)
  %3620 : Tensor = prim::GetAttr[name="running_var"](%3606)
  %3621 : Tensor = prim::GetAttr[name="weight"](%3606)
  %3622 : Tensor = prim::GetAttr[name="bias"](%3606)
   = prim::If(%3618) # torch/nn/functional.py:2011:4
    block0():
      %3623 : int[] = aten::size(%input.3) # torch/nn/functional.py:2012:27
      %size_prods.1 : int = aten::__getitem__(%3623, %9) # torch/nn/functional.py:1991:17
      %3625 : int = aten::len(%3623) # torch/nn/functional.py:1992:19
      %3626 : int = aten::sub(%3625, %15) # torch/nn/functional.py:1992:19
      %size_prods : int = prim::Loop(%3626, %8, %size_prods.1) # torch/nn/functional.py:1992:4
        block0(%i.1 : int, %size_prods.6 : int):
          %3630 : int = aten::add(%i.1, %15) # torch/nn/functional.py:1993:27
          %3631 : int = aten::__getitem__(%3623, %3630) # torch/nn/functional.py:1993:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %3631) # torch/nn/functional.py:1993:8
          -> (%8, %size_prods.3)
      %3633 : bool = aten::eq(%size_prods, %7) # torch/nn/functional.py:1994:7
       = prim::If(%3633) # torch/nn/functional.py:1994:4
        block0():
           = prim::RaiseException(%10) # torch/nn/functional.py:1995:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.5 : Tensor = aten::batch_norm(%input.3, %3621, %3622, %3619, %3620, %3618, %exponential_average_factor.2, %13, %8) # torch/nn/functional.py:2014:11
  %x.26 : Tensor = aten::relu_(%input.5) # torch/nn/functional.py:1117:17
  %3636 : int[] = prim::ListConstruct(%15, %14)
  %x.28 : Tensor = aten::mean(%x.26, %3636, %16, %17) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:133:12
  %3638 : __torch__.torch.nn.modules.linear.___torch_mangle_161.Linear = prim::GetAttr[name="fc"](%self)
  %3639 : Tensor = prim::GetAttr[name="weight"](%3638)
  %3640 : Tensor = prim::GetAttr[name="bias"](%3638)
  %3641 : int = aten::dim(%x.28) # torch/nn/functional.py:1672:7
  %3642 : bool = aten::eq(%3641, %15) # torch/nn/functional.py:1672:7
  %x.30 : Tensor = prim::If(%3642) # torch/nn/functional.py:1672:4
    block0():
      %3644 : Tensor = aten::t(%3639) # torch/nn/functional.py:1674:39
      %ret.1 : Tensor = aten::addmm(%3640, %x.28, %3644, %7, %7) # torch/nn/functional.py:1674:14
      -> (%ret.1)
    block1():
      %3646 : Tensor = aten::t(%3639) # torch/nn/functional.py:1676:30
      %output.1 : Tensor = aten::matmul(%x.28, %3646) # torch/nn/functional.py:1676:17
      %output.3 : Tensor = aten::add_(%output.1, %3640, %7) # torch/nn/functional.py:1678:12
      -> (%output.3)
  return (%x.30)
