graph(%self : __torch__.torchvision.models.alexnet.AlexNet,
      %x.1 : Tensor):
  %2 : int = prim::Constant[value=-1]()
  %3 : int = prim::Constant[value=1]() # torch/hub/pytorch_vision_master/torchvision/models/alexnet.py:47:29
  %4 : __torch__.torch.nn.modules.container.Sequential = prim::GetAttr[name="features"](%self)
  %11 : bool = prim::Constant[value=0]() # torch/nn/modules/pooling.py:158:57
  %12 : int = prim::Constant[value=0]() # torch/nn/modules/pooling.py:158:28
  %13 : int = prim::Constant[value=3]() # torch/nn/modules/pooling.py:157:35
  %14 : int = prim::Constant[value=4]() # torch/nn/modules/conv.py:413:47
  %15 : int = prim::Constant[value=1]() # torch/nn/modules/conv.py:414:38
  %16 : int = prim::Constant[value=2]() # torch/nn/modules/conv.py:416:24
  %17 : __torch__.torch.nn.modules.conv.Conv2d = prim::GetAttr[name="0"](%4)
  %18 : __torch__.torch.nn.modules.conv.___torch_mangle_0.Conv2d = prim::GetAttr[name="3"](%4)
  %19 : __torch__.torch.nn.modules.conv.___torch_mangle_1.Conv2d = prim::GetAttr[name="6"](%4)
  %20 : __torch__.torch.nn.modules.conv.___torch_mangle_2.Conv2d = prim::GetAttr[name="8"](%4)
  %21 : __torch__.torch.nn.modules.conv.___torch_mangle_3.Conv2d = prim::GetAttr[name="10"](%4)
  %22 : Tensor = prim::GetAttr[name="weight"](%17)
  %23 : Tensor? = prim::GetAttr[name="bias"](%17)
  %24 : int[] = prim::ListConstruct(%14, %14)
  %25 : int[] = prim::ListConstruct(%16, %16)
  %26 : int[] = prim::ListConstruct(%15, %15)
  %input.4 : Tensor = aten::conv2d(%x.1, %22, %23, %24, %25, %26, %15) # torch/nn/modules/conv.py:415:15
  %input.6 : Tensor = aten::relu_(%input.4) # torch/nn/functional.py:1117:17
  %29 : int[] = prim::ListConstruct(%13, %13)
  %30 : int[] = prim::ListConstruct(%16, %16)
  %31 : int[] = prim::ListConstruct(%12, %12)
  %32 : int[] = prim::ListConstruct(%15, %15)
  %input.8 : Tensor = aten::max_pool2d(%input.6, %29, %30, %31, %32, %11) # torch/nn/functional.py:575:11
  %34 : Tensor = prim::GetAttr[name="weight"](%18)
  %35 : Tensor? = prim::GetAttr[name="bias"](%18)
  %36 : int[] = prim::ListConstruct(%15, %15)
  %37 : int[] = prim::ListConstruct(%16, %16)
  %38 : int[] = prim::ListConstruct(%15, %15)
  %input.10 : Tensor = aten::conv2d(%input.8, %34, %35, %36, %37, %38, %15) # torch/nn/modules/conv.py:415:15
  %input.12 : Tensor = aten::relu_(%input.10) # torch/nn/functional.py:1117:17
  %41 : int[] = prim::ListConstruct(%13, %13)
  %42 : int[] = prim::ListConstruct(%16, %16)
  %43 : int[] = prim::ListConstruct(%12, %12)
  %44 : int[] = prim::ListConstruct(%15, %15)
  %input.14 : Tensor = aten::max_pool2d(%input.12, %41, %42, %43, %44, %11) # torch/nn/functional.py:575:11
  %46 : Tensor = prim::GetAttr[name="weight"](%19)
  %47 : Tensor? = prim::GetAttr[name="bias"](%19)
  %48 : int[] = prim::ListConstruct(%15, %15)
  %49 : int[] = prim::ListConstruct(%15, %15)
  %50 : int[] = prim::ListConstruct(%15, %15)
  %input.16 : Tensor = aten::conv2d(%input.14, %46, %47, %48, %49, %50, %15) # torch/nn/modules/conv.py:415:15
  %input.17 : Tensor = aten::relu_(%input.16) # torch/nn/functional.py:1117:17
  %53 : Tensor = prim::GetAttr[name="weight"](%20)
  %54 : Tensor? = prim::GetAttr[name="bias"](%20)
  %55 : int[] = prim::ListConstruct(%15, %15)
  %56 : int[] = prim::ListConstruct(%15, %15)
  %57 : int[] = prim::ListConstruct(%15, %15)
  %input.19 : Tensor = aten::conv2d(%input.17, %53, %54, %55, %56, %57, %15) # torch/nn/modules/conv.py:415:15
  %input.21 : Tensor = aten::relu_(%input.19) # torch/nn/functional.py:1117:17
  %60 : Tensor = prim::GetAttr[name="weight"](%21)
  %61 : Tensor? = prim::GetAttr[name="bias"](%21)
  %62 : int[] = prim::ListConstruct(%15, %15)
  %63 : int[] = prim::ListConstruct(%15, %15)
  %64 : int[] = prim::ListConstruct(%15, %15)
  %input.23 : Tensor = aten::conv2d(%input.21, %60, %61, %62, %63, %64, %15) # torch/nn/modules/conv.py:415:15
  %input.25 : Tensor = aten::relu_(%input.23) # torch/nn/functional.py:1117:17
  %67 : int[] = prim::ListConstruct(%13, %13)
  %68 : int[] = prim::ListConstruct(%16, %16)
  %69 : int[] = prim::ListConstruct(%12, %12)
  %70 : int[] = prim::ListConstruct(%15, %15)
  %x.3 : Tensor = aten::max_pool2d(%input.25, %67, %68, %69, %70, %11) # torch/nn/functional.py:575:11
  %6 : __torch__.torch.nn.modules.pooling.AdaptiveAvgPool2d = prim::GetAttr[name="avgpool"](%self)
  %72 : int = prim::Constant[value=2]()
  %73 : str = prim::Constant[value="Exception"]() # <string>:5:2
  %74 : int = prim::Constant[value=6]() # torch/nn/modules/pooling.py:1111:44
  %75 : int[] = prim::ListConstruct(%74, %74)
  %76 : int[] = aten::size(%x.3) # torch/nn/functional.py:925:51
  %77 : int = aten::len(%76) # <string>:5:9
  %78 : bool = aten::gt(%77, %72) # <string>:5:9
   = prim::If(%78) # <string>:5:2
    block0():
      -> ()
    block1():
       = prim::RaiseException(%73) # <string>:5:2
      -> ()
  %x.5 : Tensor = aten::adaptive_avg_pool2d(%x.3, %75) # torch/nn/functional.py:926:11
  %x.7 : Tensor = aten::flatten(%x.5, %3, %2) # torch/hub/pytorch_vision_master/torchvision/models/alexnet.py:47:12
  %9 : __torch__.torch.nn.modules.container.___torch_mangle_6.Sequential = prim::GetAttr[name="classifier"](%self)
  %80 : int = prim::Constant[value=2]() # torch/nn/functional.py:1672:22
  %81 : int = prim::Constant[value=1]()
  %82 : float = prim::Constant[value=0.5]() # torch/nn/modules/dropout.py:58:32
  %83 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="0"](%9)
  %84 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="1"](%9)
  %85 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="3"](%9)
  %86 : __torch__.torch.nn.modules.linear.___torch_mangle_4.Linear = prim::GetAttr[name="4"](%9)
  %87 : __torch__.torch.nn.modules.linear.___torch_mangle_5.Linear = prim::GetAttr[name="6"](%9)
  %88 : bool = prim::GetAttr[name="training"](%83)
  %input.3 : Tensor = aten::dropout(%x.7, %82, %88) # torch/nn/functional.py:973:17
  %90 : Tensor = prim::GetAttr[name="weight"](%84)
  %91 : Tensor = prim::GetAttr[name="bias"](%84)
  %92 : int = aten::dim(%input.3) # torch/nn/functional.py:1672:7
  %93 : bool = aten::eq(%92, %80) # torch/nn/functional.py:1672:7
  %input.5 : Tensor = prim::If(%93) # torch/nn/functional.py:1672:4
    block0():
      %95 : Tensor = aten::t(%90) # torch/nn/functional.py:1674:39
      %ret.2 : Tensor = aten::addmm(%91, %input.3, %95, %81, %81) # torch/nn/functional.py:1674:14
      -> (%ret.2)
    block1():
      %97 : Tensor = aten::t(%90) # torch/nn/functional.py:1676:30
      %output.2 : Tensor = aten::matmul(%input.3, %97) # torch/nn/functional.py:1676:17
      %output.4 : Tensor = aten::add_(%output.2, %91, %81) # torch/nn/functional.py:1678:12
      -> (%output.4)
  %input.7 : Tensor = aten::relu_(%input.5) # torch/nn/functional.py:1117:17
  %101 : bool = prim::GetAttr[name="training"](%85)
  %input.9 : Tensor = aten::dropout(%input.7, %82, %101) # torch/nn/functional.py:973:17
  %103 : Tensor = prim::GetAttr[name="weight"](%86)
  %104 : Tensor = prim::GetAttr[name="bias"](%86)
  %105 : int = aten::dim(%input.9) # torch/nn/functional.py:1672:7
  %106 : bool = aten::eq(%105, %80) # torch/nn/functional.py:1672:7
  %input.11 : Tensor = prim::If(%106) # torch/nn/functional.py:1672:4
    block0():
      %108 : Tensor = aten::t(%103) # torch/nn/functional.py:1674:39
      %ret.3 : Tensor = aten::addmm(%104, %input.9, %108, %81, %81) # torch/nn/functional.py:1674:14
      -> (%ret.3)
    block1():
      %110 : Tensor = aten::t(%103) # torch/nn/functional.py:1676:30
      %output.5 : Tensor = aten::matmul(%input.9, %110) # torch/nn/functional.py:1676:17
      %output.6 : Tensor = aten::add_(%output.5, %104, %81) # torch/nn/functional.py:1678:12
      -> (%output.6)
  %input.13 : Tensor = aten::relu_(%input.11) # torch/nn/functional.py:1117:17
  %114 : Tensor = prim::GetAttr[name="weight"](%87)
  %115 : Tensor = prim::GetAttr[name="bias"](%87)
  %116 : int = aten::dim(%input.13) # torch/nn/functional.py:1672:7
  %117 : bool = aten::eq(%116, %80) # torch/nn/functional.py:1672:7
  %x.9 : Tensor = prim::If(%117) # torch/nn/functional.py:1672:4
    block0():
      %119 : Tensor = aten::t(%114) # torch/nn/functional.py:1674:39
      %ret.1 : Tensor = aten::addmm(%115, %input.13, %119, %81, %81) # torch/nn/functional.py:1674:14
      -> (%ret.1)
    block1():
      %121 : Tensor = aten::t(%114) # torch/nn/functional.py:1676:30
      %output.1 : Tensor = aten::matmul(%input.13, %121) # torch/nn/functional.py:1676:17
      %output.3 : Tensor = aten::add_(%output.1, %115, %81) # torch/nn/functional.py:1678:12
      -> (%output.3)
  return (%x.9)
