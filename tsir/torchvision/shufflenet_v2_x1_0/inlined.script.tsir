graph(%self : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1080.ShuffleNetV2,
      %x.1 : Tensor):
  %3 : int = prim::Constant[value=232]() # torch/nn/modules/conv.py:414:53
  %4 : int = prim::Constant[value=116]() # torch/nn/modules/conv.py:414:53
  %5 : int = prim::Constant[value=-1]() # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:26
  %6 : int = prim::Constant[value=24]() # torch/nn/modules/conv.py:414:53
  %7 : int = prim::Constant[value=58]() # torch/nn/modules/conv.py:414:53
  %8 : int = prim::Constant[value=1]() # torch/nn/modules/conv.py:414:38
  %9 : bool = prim::Constant[value=1]() # torch/nn/functional.py:2016:33
  %10 : int = prim::Constant[value=0]() # torch/nn/functional.py:1991:22
  %11 : str = prim::Constant[value="Exception"]() # torch/nn/modules/batchnorm.py:277:12
  %12 : int = prim::Constant[value=4]() # torch/nn/modules/batchnorm.py:276:26
  %exponential_average_factor.2 : float = prim::Constant[value=0.10000000000000001]() # torch/nn/modules/batchnorm.py:108:41
  %14 : float = prim::Constant[value=1.0000000000000001e-05]() # torch/nn/modules/batchnorm.py:136:77
  %15 : int = prim::Constant[value=3]() # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:133:23
  %16 : int = prim::Constant[value=2]() # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:133:20
  %17 : bool = prim::Constant[value=0]()
  %18 : None = prim::Constant()
  %19 : __torch__.torch.nn.modules.container.___torch_mangle_1022.Sequential = prim::GetAttr[name="conv1"](%self)
  %20 : __torch__.torch.nn.modules.conv.___torch_mangle_698.Conv2d = prim::GetAttr[name="0"](%19)
  %21 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%19)
  %22 : Tensor = prim::GetAttr[name="weight"](%20)
  %23 : Tensor? = prim::GetAttr[name="bias"](%20)
  %24 : int[] = prim::ListConstruct(%16, %16)
  %25 : int[] = prim::ListConstruct(%8, %8)
  %26 : int[] = prim::ListConstruct(%8, %8)
  %input.185 : Tensor = aten::conv2d(%x.1, %22, %23, %24, %25, %26, %8) # torch/nn/modules/conv.py:415:15
  %28 : int = aten::dim(%input.185) # torch/nn/modules/batchnorm.py:276:11
  %29 : bool = aten::ne(%28, %12) # torch/nn/modules/batchnorm.py:276:11
   = prim::If(%29) # torch/nn/modules/batchnorm.py:276:8
    block0():
       = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
      -> ()
    block1():
      -> ()
  %30 : bool = prim::GetAttr[name="training"](%21)
   = prim::If(%30) # torch/nn/modules/batchnorm.py:110:11
    block0():
      %31 : Tensor = prim::GetAttr[name="num_batches_tracked"](%21)
      %32 : Tensor = aten::add(%31, %8, %8) # torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%21, %32)
      -> ()
    block1():
      -> ()
  %33 : bool = prim::GetAttr[name="training"](%21)
  %34 : Tensor = prim::GetAttr[name="running_mean"](%21)
  %35 : Tensor = prim::GetAttr[name="running_var"](%21)
  %36 : Tensor = prim::GetAttr[name="weight"](%21)
  %37 : Tensor = prim::GetAttr[name="bias"](%21)
   = prim::If(%33) # torch/nn/functional.py:2011:4
    block0():
      %38 : int[] = aten::size(%input.185) # torch/nn/functional.py:2012:27
      %size_prods.272 : int = aten::__getitem__(%38, %10) # torch/nn/functional.py:1991:17
      %40 : int = aten::len(%38) # torch/nn/functional.py:1992:19
      %41 : int = aten::sub(%40, %16) # torch/nn/functional.py:1992:19
      %size_prods.273 : int = prim::Loop(%41, %9, %size_prods.272) # torch/nn/functional.py:1992:4
        block0(%i.69 : int, %size_prods.274 : int):
          %45 : int = aten::add(%i.69, %16) # torch/nn/functional.py:1993:27
          %46 : int = aten::__getitem__(%38, %45) # torch/nn/functional.py:1993:22
          %size_prods.275 : int = aten::mul(%size_prods.274, %46) # torch/nn/functional.py:1993:8
          -> (%9, %size_prods.275)
      %48 : bool = aten::eq(%size_prods.273, %8) # torch/nn/functional.py:1994:7
       = prim::If(%48) # torch/nn/functional.py:1994:4
        block0():
           = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.184 : Tensor = aten::batch_norm(%input.185, %36, %37, %34, %35, %33, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
  %x.3 : Tensor = aten::relu_(%input.184) # torch/nn/functional.py:1117:17
  %51 : int[] = prim::ListConstruct(%15, %15)
  %52 : int[] = prim::ListConstruct(%16, %16)
  %53 : int[] = prim::ListConstruct(%8, %8)
  %54 : int[] = prim::ListConstruct(%8, %8)
  %x.31 : Tensor = aten::max_pool2d(%x.3, %51, %52, %53, %54, %17) # torch/nn/functional.py:575:11
  %56 : __torch__.torch.nn.modules.container.___torch_mangle_1057.Sequential = prim::GetAttr[name="stage2"](%self)
  %57 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1053.InvertedResidual = prim::GetAttr[name="0"](%56)
  %58 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1056.InvertedResidual = prim::GetAttr[name="1"](%56)
  %59 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1056.InvertedResidual = prim::GetAttr[name="2"](%56)
  %60 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1056.InvertedResidual = prim::GetAttr[name="3"](%56)
  %61 : int = prim::GetAttr[name="stride"](%57)
  %62 : bool = aten::eq(%61, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.8 : Tensor = prim::If(%62) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %64 : Tensor[] = aten::chunk(%x.31, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.11 : Tensor, %x2.11 : Tensor = prim::ListUnpack(%64)
      %67 : __torch__.torch.nn.modules.container.___torch_mangle_1052.Sequential = prim::GetAttr[name="branch2"](%57)
      %68 : __torch__.torch.nn.modules.conv.___torch_mangle_1047.Conv2d = prim::GetAttr[name="0"](%67)
      %69 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="1"](%67)
      %70 : __torch__.torch.nn.modules.conv.___torch_mangle_1050.Conv2d = prim::GetAttr[name="3"](%67)
      %71 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="4"](%67)
      %72 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="5"](%67)
      %73 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="6"](%67)
      %74 : Tensor = prim::GetAttr[name="weight"](%68)
      %75 : Tensor? = prim::GetAttr[name="bias"](%68)
      %76 : int[] = prim::ListConstruct(%8, %8)
      %77 : int[] = prim::ListConstruct(%10, %10)
      %78 : int[] = prim::ListConstruct(%8, %8)
      %input.166 : Tensor = aten::conv2d(%x2.11, %74, %75, %76, %77, %78, %8) # torch/nn/modules/conv.py:415:15
      %80 : int = aten::dim(%input.166) # torch/nn/modules/batchnorm.py:276:11
      %81 : bool = aten::ne(%80, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%81) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %82 : bool = prim::GetAttr[name="training"](%69)
       = prim::If(%82) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %83 : Tensor = prim::GetAttr[name="num_batches_tracked"](%69)
          %84 : Tensor = aten::add(%83, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%69, %84)
          -> ()
        block1():
          -> ()
      %85 : bool = prim::GetAttr[name="training"](%69)
      %86 : Tensor = prim::GetAttr[name="running_mean"](%69)
      %87 : Tensor = prim::GetAttr[name="running_var"](%69)
      %88 : Tensor = prim::GetAttr[name="weight"](%69)
      %89 : Tensor = prim::GetAttr[name="bias"](%69)
       = prim::If(%85) # torch/nn/functional.py:2011:4
        block0():
          %90 : int[] = aten::size(%input.166) # torch/nn/functional.py:2012:27
          %size_prods.276 : int = aten::__getitem__(%90, %10) # torch/nn/functional.py:1991:17
          %92 : int = aten::len(%90) # torch/nn/functional.py:1992:19
          %93 : int = aten::sub(%92, %16) # torch/nn/functional.py:1992:19
          %size_prods.277 : int = prim::Loop(%93, %9, %size_prods.276) # torch/nn/functional.py:1992:4
            block0(%i.70 : int, %size_prods.278 : int):
              %97 : int = aten::add(%i.70, %16) # torch/nn/functional.py:1993:27
              %98 : int = aten::__getitem__(%90, %97) # torch/nn/functional.py:1993:22
              %size_prods.279 : int = aten::mul(%size_prods.278, %98) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.279)
          %100 : bool = aten::eq(%size_prods.277, %8) # torch/nn/functional.py:1994:7
           = prim::If(%100) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.183 : Tensor = aten::batch_norm(%input.166, %88, %89, %86, %87, %85, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.200 : Tensor = aten::relu_(%input.183) # torch/nn/functional.py:1117:17
      %103 : Tensor = prim::GetAttr[name="weight"](%70)
      %104 : Tensor? = prim::GetAttr[name="bias"](%70)
      %105 : int[] = prim::ListConstruct(%16, %16)
      %106 : int[] = prim::ListConstruct(%8, %8)
      %107 : int[] = prim::ListConstruct(%8, %8)
      %input.217 : Tensor = aten::conv2d(%input.200, %103, %104, %105, %106, %107, %7) # torch/nn/modules/conv.py:415:15
      %109 : int = aten::dim(%input.217) # torch/nn/modules/batchnorm.py:276:11
      %110 : bool = aten::ne(%109, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%110) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %111 : bool = prim::GetAttr[name="training"](%71)
       = prim::If(%111) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %112 : Tensor = prim::GetAttr[name="num_batches_tracked"](%71)
          %113 : Tensor = aten::add(%112, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%71, %113)
          -> ()
        block1():
          -> ()
      %114 : bool = prim::GetAttr[name="training"](%71)
      %115 : Tensor = prim::GetAttr[name="running_mean"](%71)
      %116 : Tensor = prim::GetAttr[name="running_var"](%71)
      %117 : Tensor = prim::GetAttr[name="weight"](%71)
      %118 : Tensor = prim::GetAttr[name="bias"](%71)
       = prim::If(%114) # torch/nn/functional.py:2011:4
        block0():
          %119 : int[] = aten::size(%input.217) # torch/nn/functional.py:2012:27
          %size_prods.280 : int = aten::__getitem__(%119, %10) # torch/nn/functional.py:1991:17
          %121 : int = aten::len(%119) # torch/nn/functional.py:1992:19
          %122 : int = aten::sub(%121, %16) # torch/nn/functional.py:1992:19
          %size_prods.281 : int = prim::Loop(%122, %9, %size_prods.280) # torch/nn/functional.py:1992:4
            block0(%i.71 : int, %size_prods.282 : int):
              %126 : int = aten::add(%i.71, %16) # torch/nn/functional.py:1993:27
              %127 : int = aten::__getitem__(%119, %126) # torch/nn/functional.py:1993:22
              %size_prods.283 : int = aten::mul(%size_prods.282, %127) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.283)
          %129 : bool = aten::eq(%size_prods.281, %8) # torch/nn/functional.py:1994:7
           = prim::If(%129) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.186 : Tensor = aten::batch_norm(%input.217, %117, %118, %115, %116, %114, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %131 : Tensor = prim::GetAttr[name="weight"](%72)
      %132 : Tensor? = prim::GetAttr[name="bias"](%72)
      %133 : int[] = prim::ListConstruct(%8, %8)
      %134 : int[] = prim::ListConstruct(%10, %10)
      %135 : int[] = prim::ListConstruct(%8, %8)
      %input.149 : Tensor = aten::conv2d(%input.186, %131, %132, %133, %134, %135, %8) # torch/nn/modules/conv.py:415:15
      %137 : int = aten::dim(%input.149) # torch/nn/modules/batchnorm.py:276:11
      %138 : bool = aten::ne(%137, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%138) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %139 : bool = prim::GetAttr[name="training"](%73)
       = prim::If(%139) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %140 : Tensor = prim::GetAttr[name="num_batches_tracked"](%73)
          %141 : Tensor = aten::add(%140, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%73, %141)
          -> ()
        block1():
          -> ()
      %142 : bool = prim::GetAttr[name="training"](%73)
      %143 : Tensor = prim::GetAttr[name="running_mean"](%73)
      %144 : Tensor = prim::GetAttr[name="running_var"](%73)
      %145 : Tensor = prim::GetAttr[name="weight"](%73)
      %146 : Tensor = prim::GetAttr[name="bias"](%73)
       = prim::If(%142) # torch/nn/functional.py:2011:4
        block0():
          %147 : int[] = aten::size(%input.149) # torch/nn/functional.py:2012:27
          %size_prods.200 : int = aten::__getitem__(%147, %10) # torch/nn/functional.py:1991:17
          %149 : int = aten::len(%147) # torch/nn/functional.py:1992:19
          %150 : int = aten::sub(%149, %16) # torch/nn/functional.py:1992:19
          %size_prods.201 : int = prim::Loop(%150, %9, %size_prods.200) # torch/nn/functional.py:1992:4
            block0(%i.51 : int, %size_prods.202 : int):
              %154 : int = aten::add(%i.51, %16) # torch/nn/functional.py:1993:27
              %155 : int = aten::__getitem__(%147, %154) # torch/nn/functional.py:1993:22
              %size_prods.203 : int = aten::mul(%size_prods.202, %155) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.203)
          %157 : bool = aten::eq(%size_prods.201, %8) # torch/nn/functional.py:1994:7
           = prim::If(%157) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.192 : Tensor = aten::batch_norm(%input.149, %145, %146, %143, %144, %142, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.193 : Tensor = aten::relu_(%input.192) # torch/nn/functional.py:1117:17
      %160 : Tensor[] = prim::ListConstruct(%x1.11, %input.193)
      %out.31 : Tensor = aten::cat(%160, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.31)
    block1():
      %162 : __torch__.torch.nn.modules.container.___torch_mangle_1049.Sequential = prim::GetAttr[name="branch1"](%57)
      %163 : __torch__.torch.nn.modules.conv.___torch_mangle_629.Conv2d = prim::GetAttr[name="0"](%162)
      %164 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_887.BatchNorm2d = prim::GetAttr[name="1"](%162)
      %165 : __torch__.torch.nn.modules.conv.___torch_mangle_1047.Conv2d = prim::GetAttr[name="2"](%162)
      %166 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="3"](%162)
      %167 : Tensor = prim::GetAttr[name="weight"](%163)
      %168 : Tensor? = prim::GetAttr[name="bias"](%163)
      %169 : int[] = prim::ListConstruct(%16, %16)
      %170 : int[] = prim::ListConstruct(%8, %8)
      %171 : int[] = prim::ListConstruct(%8, %8)
      %input.187 : Tensor = aten::conv2d(%x.31, %167, %168, %169, %170, %171, %6) # torch/nn/modules/conv.py:415:15
      %173 : int = aten::dim(%input.187) # torch/nn/modules/batchnorm.py:276:11
      %174 : bool = aten::ne(%173, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%174) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %175 : bool = prim::GetAttr[name="training"](%164)
       = prim::If(%175) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %176 : Tensor = prim::GetAttr[name="num_batches_tracked"](%164)
          %177 : Tensor = aten::add(%176, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%164, %177)
          -> ()
        block1():
          -> ()
      %178 : bool = prim::GetAttr[name="training"](%164)
      %179 : Tensor = prim::GetAttr[name="running_mean"](%164)
      %180 : Tensor = prim::GetAttr[name="running_var"](%164)
      %181 : Tensor = prim::GetAttr[name="weight"](%164)
      %182 : Tensor = prim::GetAttr[name="bias"](%164)
       = prim::If(%178) # torch/nn/functional.py:2011:4
        block0():
          %183 : int[] = aten::size(%input.187) # torch/nn/functional.py:2012:27
          %size_prods.204 : int = aten::__getitem__(%183, %10) # torch/nn/functional.py:1991:17
          %185 : int = aten::len(%183) # torch/nn/functional.py:1992:19
          %186 : int = aten::sub(%185, %16) # torch/nn/functional.py:1992:19
          %size_prods.205 : int = prim::Loop(%186, %9, %size_prods.204) # torch/nn/functional.py:1992:4
            block0(%i.52 : int, %size_prods.206 : int):
              %190 : int = aten::add(%i.52, %16) # torch/nn/functional.py:1993:27
              %191 : int = aten::__getitem__(%183, %190) # torch/nn/functional.py:1993:22
              %size_prods.207 : int = aten::mul(%size_prods.206, %191) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.207)
          %193 : bool = aten::eq(%size_prods.205, %8) # torch/nn/functional.py:1994:7
           = prim::If(%193) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.189 : Tensor = aten::batch_norm(%input.187, %181, %182, %179, %180, %178, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %195 : Tensor = prim::GetAttr[name="weight"](%165)
      %196 : Tensor? = prim::GetAttr[name="bias"](%165)
      %197 : int[] = prim::ListConstruct(%8, %8)
      %198 : int[] = prim::ListConstruct(%10, %10)
      %199 : int[] = prim::ListConstruct(%8, %8)
      %input.190 : Tensor = aten::conv2d(%input.189, %195, %196, %197, %198, %199, %8) # torch/nn/modules/conv.py:415:15
      %201 : int = aten::dim(%input.190) # torch/nn/modules/batchnorm.py:276:11
      %202 : bool = aten::ne(%201, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%202) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %203 : bool = prim::GetAttr[name="training"](%166)
       = prim::If(%203) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %204 : Tensor = prim::GetAttr[name="num_batches_tracked"](%166)
          %205 : Tensor = aten::add(%204, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%166, %205)
          -> ()
        block1():
          -> ()
      %206 : bool = prim::GetAttr[name="training"](%166)
      %207 : Tensor = prim::GetAttr[name="running_mean"](%166)
      %208 : Tensor = prim::GetAttr[name="running_var"](%166)
      %209 : Tensor = prim::GetAttr[name="weight"](%166)
      %210 : Tensor = prim::GetAttr[name="bias"](%166)
       = prim::If(%206) # torch/nn/functional.py:2011:4
        block0():
          %211 : int[] = aten::size(%input.190) # torch/nn/functional.py:2012:27
          %size_prods.208 : int = aten::__getitem__(%211, %10) # torch/nn/functional.py:1991:17
          %213 : int = aten::len(%211) # torch/nn/functional.py:1992:19
          %214 : int = aten::sub(%213, %16) # torch/nn/functional.py:1992:19
          %size_prods.209 : int = prim::Loop(%214, %9, %size_prods.208) # torch/nn/functional.py:1992:4
            block0(%i.53 : int, %size_prods.210 : int):
              %218 : int = aten::add(%i.53, %16) # torch/nn/functional.py:1993:27
              %219 : int = aten::__getitem__(%211, %218) # torch/nn/functional.py:1993:22
              %size_prods.211 : int = aten::mul(%size_prods.210, %219) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.211)
          %221 : bool = aten::eq(%size_prods.209, %8) # torch/nn/functional.py:1994:7
           = prim::If(%221) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.197 : Tensor = aten::batch_norm(%input.190, %209, %210, %207, %208, %206, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.198 : Tensor = aten::relu_(%input.197) # torch/nn/functional.py:1117:17
      %224 : __torch__.torch.nn.modules.container.___torch_mangle_1052.Sequential = prim::GetAttr[name="branch2"](%57)
      %225 : __torch__.torch.nn.modules.conv.___torch_mangle_1047.Conv2d = prim::GetAttr[name="0"](%224)
      %226 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="1"](%224)
      %227 : __torch__.torch.nn.modules.conv.___torch_mangle_1050.Conv2d = prim::GetAttr[name="3"](%224)
      %228 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="4"](%224)
      %229 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="5"](%224)
      %230 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="6"](%224)
      %231 : Tensor = prim::GetAttr[name="weight"](%225)
      %232 : Tensor? = prim::GetAttr[name="bias"](%225)
      %233 : int[] = prim::ListConstruct(%8, %8)
      %234 : int[] = prim::ListConstruct(%10, %10)
      %235 : int[] = prim::ListConstruct(%8, %8)
      %input.191 : Tensor = aten::conv2d(%x.31, %231, %232, %233, %234, %235, %8) # torch/nn/modules/conv.py:415:15
      %237 : int = aten::dim(%input.191) # torch/nn/modules/batchnorm.py:276:11
      %238 : bool = aten::ne(%237, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%238) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %239 : bool = prim::GetAttr[name="training"](%226)
       = prim::If(%239) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %240 : Tensor = prim::GetAttr[name="num_batches_tracked"](%226)
          %241 : Tensor = aten::add(%240, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%226, %241)
          -> ()
        block1():
          -> ()
      %242 : bool = prim::GetAttr[name="training"](%226)
      %243 : Tensor = prim::GetAttr[name="running_mean"](%226)
      %244 : Tensor = prim::GetAttr[name="running_var"](%226)
      %245 : Tensor = prim::GetAttr[name="weight"](%226)
      %246 : Tensor = prim::GetAttr[name="bias"](%226)
       = prim::If(%242) # torch/nn/functional.py:2011:4
        block0():
          %247 : int[] = aten::size(%input.191) # torch/nn/functional.py:2012:27
          %size_prods.212 : int = aten::__getitem__(%247, %10) # torch/nn/functional.py:1991:17
          %249 : int = aten::len(%247) # torch/nn/functional.py:1992:19
          %250 : int = aten::sub(%249, %16) # torch/nn/functional.py:1992:19
          %size_prods.213 : int = prim::Loop(%250, %9, %size_prods.212) # torch/nn/functional.py:1992:4
            block0(%i.54 : int, %size_prods.214 : int):
              %254 : int = aten::add(%i.54, %16) # torch/nn/functional.py:1993:27
              %255 : int = aten::__getitem__(%247, %254) # torch/nn/functional.py:1993:22
              %size_prods.215 : int = aten::mul(%size_prods.214, %255) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.215)
          %257 : bool = aten::eq(%size_prods.213, %8) # torch/nn/functional.py:1994:7
           = prim::If(%257) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.194 : Tensor = aten::batch_norm(%input.191, %245, %246, %243, %244, %242, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.195 : Tensor = aten::relu_(%input.194) # torch/nn/functional.py:1117:17
      %260 : Tensor = prim::GetAttr[name="weight"](%227)
      %261 : Tensor? = prim::GetAttr[name="bias"](%227)
      %262 : int[] = prim::ListConstruct(%16, %16)
      %263 : int[] = prim::ListConstruct(%8, %8)
      %264 : int[] = prim::ListConstruct(%8, %8)
      %input.196 : Tensor = aten::conv2d(%input.195, %260, %261, %262, %263, %264, %7) # torch/nn/modules/conv.py:415:15
      %266 : int = aten::dim(%input.196) # torch/nn/modules/batchnorm.py:276:11
      %267 : bool = aten::ne(%266, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%267) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %268 : bool = prim::GetAttr[name="training"](%228)
       = prim::If(%268) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %269 : Tensor = prim::GetAttr[name="num_batches_tracked"](%228)
          %270 : Tensor = aten::add(%269, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%228, %270)
          -> ()
        block1():
          -> ()
      %271 : bool = prim::GetAttr[name="training"](%228)
      %272 : Tensor = prim::GetAttr[name="running_mean"](%228)
      %273 : Tensor = prim::GetAttr[name="running_var"](%228)
      %274 : Tensor = prim::GetAttr[name="weight"](%228)
      %275 : Tensor = prim::GetAttr[name="bias"](%228)
       = prim::If(%271) # torch/nn/functional.py:2011:4
        block0():
          %276 : int[] = aten::size(%input.196) # torch/nn/functional.py:2012:27
          %size_prods.216 : int = aten::__getitem__(%276, %10) # torch/nn/functional.py:1991:17
          %278 : int = aten::len(%276) # torch/nn/functional.py:1992:19
          %279 : int = aten::sub(%278, %16) # torch/nn/functional.py:1992:19
          %size_prods.217 : int = prim::Loop(%279, %9, %size_prods.216) # torch/nn/functional.py:1992:4
            block0(%i.55 : int, %size_prods.218 : int):
              %283 : int = aten::add(%i.55, %16) # torch/nn/functional.py:1993:27
              %284 : int = aten::__getitem__(%276, %283) # torch/nn/functional.py:1993:22
              %size_prods.219 : int = aten::mul(%size_prods.218, %284) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.219)
          %286 : bool = aten::eq(%size_prods.217, %8) # torch/nn/functional.py:1994:7
           = prim::If(%286) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.199 : Tensor = aten::batch_norm(%input.196, %274, %275, %272, %273, %271, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %288 : Tensor = prim::GetAttr[name="weight"](%229)
      %289 : Tensor? = prim::GetAttr[name="bias"](%229)
      %290 : int[] = prim::ListConstruct(%8, %8)
      %291 : int[] = prim::ListConstruct(%10, %10)
      %292 : int[] = prim::ListConstruct(%8, %8)
      %input.144 : Tensor = aten::conv2d(%input.199, %288, %289, %290, %291, %292, %8) # torch/nn/modules/conv.py:415:15
      %294 : int = aten::dim(%input.144) # torch/nn/modules/batchnorm.py:276:11
      %295 : bool = aten::ne(%294, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%295) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %296 : bool = prim::GetAttr[name="training"](%230)
       = prim::If(%296) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %297 : Tensor = prim::GetAttr[name="num_batches_tracked"](%230)
          %298 : Tensor = aten::add(%297, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%230, %298)
          -> ()
        block1():
          -> ()
      %299 : bool = prim::GetAttr[name="training"](%230)
      %300 : Tensor = prim::GetAttr[name="running_mean"](%230)
      %301 : Tensor = prim::GetAttr[name="running_var"](%230)
      %302 : Tensor = prim::GetAttr[name="weight"](%230)
      %303 : Tensor = prim::GetAttr[name="bias"](%230)
       = prim::If(%299) # torch/nn/functional.py:2011:4
        block0():
          %304 : int[] = aten::size(%input.144) # torch/nn/functional.py:2012:27
          %size_prods.220 : int = aten::__getitem__(%304, %10) # torch/nn/functional.py:1991:17
          %306 : int = aten::len(%304) # torch/nn/functional.py:1992:19
          %307 : int = aten::sub(%306, %16) # torch/nn/functional.py:1992:19
          %size_prods.221 : int = prim::Loop(%307, %9, %size_prods.220) # torch/nn/functional.py:1992:4
            block0(%i.56 : int, %size_prods.222 : int):
              %311 : int = aten::add(%i.56, %16) # torch/nn/functional.py:1993:27
              %312 : int = aten::__getitem__(%304, %311) # torch/nn/functional.py:1993:22
              %size_prods.223 : int = aten::mul(%size_prods.222, %312) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.223)
          %314 : bool = aten::eq(%size_prods.221, %8) # torch/nn/functional.py:1994:7
           = prim::If(%314) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.145 : Tensor = aten::batch_norm(%input.144, %302, %303, %300, %301, %299, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.146 : Tensor = aten::relu_(%input.145) # torch/nn/functional.py:1117:17
      %317 : Tensor[] = prim::ListConstruct(%input.198, %input.146)
      %out.32 : Tensor = aten::cat(%317, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.32)
  %319 : Tensor = prim::data(%out.8)
  %320 : int[] = aten::size(%319) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.11 : int, %num_channels.11 : int, %height.11 : int, %width.11 : int = prim::ListUnpack(%320)
  %channels_per_group.11 : int = aten::floordiv(%num_channels.11, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %326 : int[] = prim::ListConstruct(%batchsize.11, %16, %channels_per_group.11, %height.11, %width.11)
  %x.32 : Tensor = aten::view(%out.8, %326) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %328 : Tensor = aten::transpose(%x.32, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.20 : Tensor = aten::contiguous(%328, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %330 : int[] = prim::ListConstruct(%batchsize.11, %5, %height.11, %width.11)
  %input.152 : Tensor = aten::view(%x.20, %330) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %332 : int = prim::GetAttr[name="stride"](%58)
  %333 : bool = aten::eq(%332, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.27 : Tensor = prim::If(%333) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %335 : Tensor[] = aten::chunk(%input.152, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.9 : Tensor, %x2.9 : Tensor = prim::ListUnpack(%335)
      %338 : __torch__.torch.nn.modules.container.___torch_mangle_1055.Sequential = prim::GetAttr[name="branch2"](%58)
      %339 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="0"](%338)
      %340 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="1"](%338)
      %341 : __torch__.torch.nn.modules.conv.___torch_mangle_1054.Conv2d = prim::GetAttr[name="3"](%338)
      %342 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="4"](%338)
      %343 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="5"](%338)
      %344 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="6"](%338)
      %345 : Tensor = prim::GetAttr[name="weight"](%339)
      %346 : Tensor? = prim::GetAttr[name="bias"](%339)
      %347 : int[] = prim::ListConstruct(%8, %8)
      %348 : int[] = prim::ListConstruct(%10, %10)
      %349 : int[] = prim::ListConstruct(%8, %8)
      %input.147 : Tensor = aten::conv2d(%x2.9, %345, %346, %347, %348, %349, %8) # torch/nn/modules/conv.py:415:15
      %351 : int = aten::dim(%input.147) # torch/nn/modules/batchnorm.py:276:11
      %352 : bool = aten::ne(%351, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%352) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %353 : bool = prim::GetAttr[name="training"](%340)
       = prim::If(%353) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %354 : Tensor = prim::GetAttr[name="num_batches_tracked"](%340)
          %355 : Tensor = aten::add(%354, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%340, %355)
          -> ()
        block1():
          -> ()
      %356 : bool = prim::GetAttr[name="training"](%340)
      %357 : Tensor = prim::GetAttr[name="running_mean"](%340)
      %358 : Tensor = prim::GetAttr[name="running_var"](%340)
      %359 : Tensor = prim::GetAttr[name="weight"](%340)
      %360 : Tensor = prim::GetAttr[name="bias"](%340)
       = prim::If(%356) # torch/nn/functional.py:2011:4
        block0():
          %361 : int[] = aten::size(%input.147) # torch/nn/functional.py:2012:27
          %size_prods.224 : int = aten::__getitem__(%361, %10) # torch/nn/functional.py:1991:17
          %363 : int = aten::len(%361) # torch/nn/functional.py:1992:19
          %364 : int = aten::sub(%363, %16) # torch/nn/functional.py:1992:19
          %size_prods.225 : int = prim::Loop(%364, %9, %size_prods.224) # torch/nn/functional.py:1992:4
            block0(%i.57 : int, %size_prods.226 : int):
              %368 : int = aten::add(%i.57, %16) # torch/nn/functional.py:1993:27
              %369 : int = aten::__getitem__(%361, %368) # torch/nn/functional.py:1993:22
              %size_prods.227 : int = aten::mul(%size_prods.226, %369) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.227)
          %371 : bool = aten::eq(%size_prods.225, %8) # torch/nn/functional.py:1994:7
           = prim::If(%371) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.148 : Tensor = aten::batch_norm(%input.147, %359, %360, %357, %358, %356, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.150 : Tensor = aten::relu_(%input.148) # torch/nn/functional.py:1117:17
      %374 : Tensor = prim::GetAttr[name="weight"](%341)
      %375 : Tensor? = prim::GetAttr[name="bias"](%341)
      %376 : int[] = prim::ListConstruct(%8, %8)
      %377 : int[] = prim::ListConstruct(%8, %8)
      %378 : int[] = prim::ListConstruct(%8, %8)
      %input.151 : Tensor = aten::conv2d(%input.150, %374, %375, %376, %377, %378, %7) # torch/nn/modules/conv.py:415:15
      %380 : int = aten::dim(%input.151) # torch/nn/modules/batchnorm.py:276:11
      %381 : bool = aten::ne(%380, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%381) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %382 : bool = prim::GetAttr[name="training"](%342)
       = prim::If(%382) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %383 : Tensor = prim::GetAttr[name="num_batches_tracked"](%342)
          %384 : Tensor = aten::add(%383, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%342, %384)
          -> ()
        block1():
          -> ()
      %385 : bool = prim::GetAttr[name="training"](%342)
      %386 : Tensor = prim::GetAttr[name="running_mean"](%342)
      %387 : Tensor = prim::GetAttr[name="running_var"](%342)
      %388 : Tensor = prim::GetAttr[name="weight"](%342)
      %389 : Tensor = prim::GetAttr[name="bias"](%342)
       = prim::If(%385) # torch/nn/functional.py:2011:4
        block0():
          %390 : int[] = aten::size(%input.151) # torch/nn/functional.py:2012:27
          %size_prods.228 : int = aten::__getitem__(%390, %10) # torch/nn/functional.py:1991:17
          %392 : int = aten::len(%390) # torch/nn/functional.py:1992:19
          %393 : int = aten::sub(%392, %16) # torch/nn/functional.py:1992:19
          %size_prods.229 : int = prim::Loop(%393, %9, %size_prods.228) # torch/nn/functional.py:1992:4
            block0(%i.58 : int, %size_prods.230 : int):
              %397 : int = aten::add(%i.58, %16) # torch/nn/functional.py:1993:27
              %398 : int = aten::__getitem__(%390, %397) # torch/nn/functional.py:1993:22
              %size_prods.231 : int = aten::mul(%size_prods.230, %398) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.231)
          %400 : bool = aten::eq(%size_prods.229, %8) # torch/nn/functional.py:1994:7
           = prim::If(%400) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.153 : Tensor = aten::batch_norm(%input.151, %388, %389, %386, %387, %385, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %402 : Tensor = prim::GetAttr[name="weight"](%343)
      %403 : Tensor? = prim::GetAttr[name="bias"](%343)
      %404 : int[] = prim::ListConstruct(%8, %8)
      %405 : int[] = prim::ListConstruct(%10, %10)
      %406 : int[] = prim::ListConstruct(%8, %8)
      %input.154 : Tensor = aten::conv2d(%input.153, %402, %403, %404, %405, %406, %8) # torch/nn/modules/conv.py:415:15
      %408 : int = aten::dim(%input.154) # torch/nn/modules/batchnorm.py:276:11
      %409 : bool = aten::ne(%408, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%409) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %410 : bool = prim::GetAttr[name="training"](%344)
       = prim::If(%410) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %411 : Tensor = prim::GetAttr[name="num_batches_tracked"](%344)
          %412 : Tensor = aten::add(%411, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%344, %412)
          -> ()
        block1():
          -> ()
      %413 : bool = prim::GetAttr[name="training"](%344)
      %414 : Tensor = prim::GetAttr[name="running_mean"](%344)
      %415 : Tensor = prim::GetAttr[name="running_var"](%344)
      %416 : Tensor = prim::GetAttr[name="weight"](%344)
      %417 : Tensor = prim::GetAttr[name="bias"](%344)
       = prim::If(%413) # torch/nn/functional.py:2011:4
        block0():
          %418 : int[] = aten::size(%input.154) # torch/nn/functional.py:2012:27
          %size_prods.232 : int = aten::__getitem__(%418, %10) # torch/nn/functional.py:1991:17
          %420 : int = aten::len(%418) # torch/nn/functional.py:1992:19
          %421 : int = aten::sub(%420, %16) # torch/nn/functional.py:1992:19
          %size_prods.233 : int = prim::Loop(%421, %9, %size_prods.232) # torch/nn/functional.py:1992:4
            block0(%i.59 : int, %size_prods.234 : int):
              %425 : int = aten::add(%i.59, %16) # torch/nn/functional.py:1993:27
              %426 : int = aten::__getitem__(%418, %425) # torch/nn/functional.py:1993:22
              %size_prods.235 : int = aten::mul(%size_prods.234, %426) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.235)
          %428 : bool = aten::eq(%size_prods.233, %8) # torch/nn/functional.py:1994:7
           = prim::If(%428) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.155 : Tensor = aten::batch_norm(%input.154, %416, %417, %414, %415, %413, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.156 : Tensor = aten::relu_(%input.155) # torch/nn/functional.py:1117:17
      %431 : Tensor[] = prim::ListConstruct(%x1.9, %input.156)
      %out.25 : Tensor = aten::cat(%431, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.25)
    block1():
      %433 : __torch__.torch.nn.modules.container.___torch_mangle_1055.Sequential = prim::GetAttr[name="branch2"](%58)
      %434 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="0"](%433)
      %435 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="1"](%433)
      %436 : __torch__.torch.nn.modules.conv.___torch_mangle_1054.Conv2d = prim::GetAttr[name="3"](%433)
      %437 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="4"](%433)
      %438 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="5"](%433)
      %439 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="6"](%433)
      %440 : Tensor = prim::GetAttr[name="weight"](%434)
      %441 : Tensor? = prim::GetAttr[name="bias"](%434)
      %442 : int[] = prim::ListConstruct(%8, %8)
      %443 : int[] = prim::ListConstruct(%10, %10)
      %444 : int[] = prim::ListConstruct(%8, %8)
      %input.157 : Tensor = aten::conv2d(%input.152, %440, %441, %442, %443, %444, %8) # torch/nn/modules/conv.py:415:15
      %446 : int = aten::dim(%input.157) # torch/nn/modules/batchnorm.py:276:11
      %447 : bool = aten::ne(%446, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%447) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %448 : bool = prim::GetAttr[name="training"](%435)
       = prim::If(%448) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %449 : Tensor = prim::GetAttr[name="num_batches_tracked"](%435)
          %450 : Tensor = aten::add(%449, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%435, %450)
          -> ()
        block1():
          -> ()
      %451 : bool = prim::GetAttr[name="training"](%435)
      %452 : Tensor = prim::GetAttr[name="running_mean"](%435)
      %453 : Tensor = prim::GetAttr[name="running_var"](%435)
      %454 : Tensor = prim::GetAttr[name="weight"](%435)
      %455 : Tensor = prim::GetAttr[name="bias"](%435)
       = prim::If(%451) # torch/nn/functional.py:2011:4
        block0():
          %456 : int[] = aten::size(%input.157) # torch/nn/functional.py:2012:27
          %size_prods.236 : int = aten::__getitem__(%456, %10) # torch/nn/functional.py:1991:17
          %458 : int = aten::len(%456) # torch/nn/functional.py:1992:19
          %459 : int = aten::sub(%458, %16) # torch/nn/functional.py:1992:19
          %size_prods.237 : int = prim::Loop(%459, %9, %size_prods.236) # torch/nn/functional.py:1992:4
            block0(%i.60 : int, %size_prods.238 : int):
              %463 : int = aten::add(%i.60, %16) # torch/nn/functional.py:1993:27
              %464 : int = aten::__getitem__(%456, %463) # torch/nn/functional.py:1993:22
              %size_prods.239 : int = aten::mul(%size_prods.238, %464) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.239)
          %466 : bool = aten::eq(%size_prods.237, %8) # torch/nn/functional.py:1994:7
           = prim::If(%466) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.158 : Tensor = aten::batch_norm(%input.157, %454, %455, %452, %453, %451, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.159 : Tensor = aten::relu_(%input.158) # torch/nn/functional.py:1117:17
      %469 : Tensor = prim::GetAttr[name="weight"](%436)
      %470 : Tensor? = prim::GetAttr[name="bias"](%436)
      %471 : int[] = prim::ListConstruct(%8, %8)
      %472 : int[] = prim::ListConstruct(%8, %8)
      %473 : int[] = prim::ListConstruct(%8, %8)
      %input.160 : Tensor = aten::conv2d(%input.159, %469, %470, %471, %472, %473, %7) # torch/nn/modules/conv.py:415:15
      %475 : int = aten::dim(%input.160) # torch/nn/modules/batchnorm.py:276:11
      %476 : bool = aten::ne(%475, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%476) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %477 : bool = prim::GetAttr[name="training"](%437)
       = prim::If(%477) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %478 : Tensor = prim::GetAttr[name="num_batches_tracked"](%437)
          %479 : Tensor = aten::add(%478, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%437, %479)
          -> ()
        block1():
          -> ()
      %480 : bool = prim::GetAttr[name="training"](%437)
      %481 : Tensor = prim::GetAttr[name="running_mean"](%437)
      %482 : Tensor = prim::GetAttr[name="running_var"](%437)
      %483 : Tensor = prim::GetAttr[name="weight"](%437)
      %484 : Tensor = prim::GetAttr[name="bias"](%437)
       = prim::If(%480) # torch/nn/functional.py:2011:4
        block0():
          %485 : int[] = aten::size(%input.160) # torch/nn/functional.py:2012:27
          %size_prods.240 : int = aten::__getitem__(%485, %10) # torch/nn/functional.py:1991:17
          %487 : int = aten::len(%485) # torch/nn/functional.py:1992:19
          %488 : int = aten::sub(%487, %16) # torch/nn/functional.py:1992:19
          %size_prods.241 : int = prim::Loop(%488, %9, %size_prods.240) # torch/nn/functional.py:1992:4
            block0(%i.61 : int, %size_prods.242 : int):
              %492 : int = aten::add(%i.61, %16) # torch/nn/functional.py:1993:27
              %493 : int = aten::__getitem__(%485, %492) # torch/nn/functional.py:1993:22
              %size_prods.243 : int = aten::mul(%size_prods.242, %493) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.243)
          %495 : bool = aten::eq(%size_prods.241, %8) # torch/nn/functional.py:1994:7
           = prim::If(%495) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.161 : Tensor = aten::batch_norm(%input.160, %483, %484, %481, %482, %480, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %497 : Tensor = prim::GetAttr[name="weight"](%438)
      %498 : Tensor? = prim::GetAttr[name="bias"](%438)
      %499 : int[] = prim::ListConstruct(%8, %8)
      %500 : int[] = prim::ListConstruct(%10, %10)
      %501 : int[] = prim::ListConstruct(%8, %8)
      %input.162 : Tensor = aten::conv2d(%input.161, %497, %498, %499, %500, %501, %8) # torch/nn/modules/conv.py:415:15
      %503 : int = aten::dim(%input.162) # torch/nn/modules/batchnorm.py:276:11
      %504 : bool = aten::ne(%503, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%504) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %505 : bool = prim::GetAttr[name="training"](%439)
       = prim::If(%505) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %506 : Tensor = prim::GetAttr[name="num_batches_tracked"](%439)
          %507 : Tensor = aten::add(%506, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%439, %507)
          -> ()
        block1():
          -> ()
      %508 : bool = prim::GetAttr[name="training"](%439)
      %509 : Tensor = prim::GetAttr[name="running_mean"](%439)
      %510 : Tensor = prim::GetAttr[name="running_var"](%439)
      %511 : Tensor = prim::GetAttr[name="weight"](%439)
      %512 : Tensor = prim::GetAttr[name="bias"](%439)
       = prim::If(%508) # torch/nn/functional.py:2011:4
        block0():
          %513 : int[] = aten::size(%input.162) # torch/nn/functional.py:2012:27
          %size_prods.244 : int = aten::__getitem__(%513, %10) # torch/nn/functional.py:1991:17
          %515 : int = aten::len(%513) # torch/nn/functional.py:1992:19
          %516 : int = aten::sub(%515, %16) # torch/nn/functional.py:1992:19
          %size_prods.245 : int = prim::Loop(%516, %9, %size_prods.244) # torch/nn/functional.py:1992:4
            block0(%i.62 : int, %size_prods.246 : int):
              %520 : int = aten::add(%i.62, %16) # torch/nn/functional.py:1993:27
              %521 : int = aten::__getitem__(%513, %520) # torch/nn/functional.py:1993:22
              %size_prods.247 : int = aten::mul(%size_prods.246, %521) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.247)
          %523 : bool = aten::eq(%size_prods.245, %8) # torch/nn/functional.py:1994:7
           = prim::If(%523) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.163 : Tensor = aten::batch_norm(%input.162, %511, %512, %509, %510, %508, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.164 : Tensor = aten::relu_(%input.163) # torch/nn/functional.py:1117:17
      %526 : Tensor[] = prim::ListConstruct(%input.152, %input.164)
      %out.26 : Tensor = aten::cat(%526, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.26)
  %528 : Tensor = prim::data(%out.27)
  %529 : int[] = aten::size(%528) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.9 : int, %num_channels.9 : int, %height.9 : int, %width.9 : int = prim::ListUnpack(%529)
  %channels_per_group.9 : int = aten::floordiv(%num_channels.9, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %535 : int[] = prim::ListConstruct(%batchsize.9, %16, %channels_per_group.9, %height.9, %width.9)
  %x.21 : Tensor = aten::view(%out.27, %535) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %537 : Tensor = aten::transpose(%x.21, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.22 : Tensor = aten::contiguous(%537, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %539 : int[] = prim::ListConstruct(%batchsize.9, %5, %height.9, %width.9)
  %input.170 : Tensor = aten::view(%x.22, %539) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %541 : int = prim::GetAttr[name="stride"](%59)
  %542 : bool = aten::eq(%541, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.30 : Tensor = prim::If(%542) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %544 : Tensor[] = aten::chunk(%input.170, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.10 : Tensor, %x2.10 : Tensor = prim::ListUnpack(%544)
      %547 : __torch__.torch.nn.modules.container.___torch_mangle_1055.Sequential = prim::GetAttr[name="branch2"](%59)
      %548 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="0"](%547)
      %549 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="1"](%547)
      %550 : __torch__.torch.nn.modules.conv.___torch_mangle_1054.Conv2d = prim::GetAttr[name="3"](%547)
      %551 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="4"](%547)
      %552 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="5"](%547)
      %553 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="6"](%547)
      %554 : Tensor = prim::GetAttr[name="weight"](%548)
      %555 : Tensor? = prim::GetAttr[name="bias"](%548)
      %556 : int[] = prim::ListConstruct(%8, %8)
      %557 : int[] = prim::ListConstruct(%10, %10)
      %558 : int[] = prim::ListConstruct(%8, %8)
      %input.165 : Tensor = aten::conv2d(%x2.10, %554, %555, %556, %557, %558, %8) # torch/nn/modules/conv.py:415:15
      %560 : int = aten::dim(%input.165) # torch/nn/modules/batchnorm.py:276:11
      %561 : bool = aten::ne(%560, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%561) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %562 : bool = prim::GetAttr[name="training"](%549)
       = prim::If(%562) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %563 : Tensor = prim::GetAttr[name="num_batches_tracked"](%549)
          %564 : Tensor = aten::add(%563, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%549, %564)
          -> ()
        block1():
          -> ()
      %565 : bool = prim::GetAttr[name="training"](%549)
      %566 : Tensor = prim::GetAttr[name="running_mean"](%549)
      %567 : Tensor = prim::GetAttr[name="running_var"](%549)
      %568 : Tensor = prim::GetAttr[name="weight"](%549)
      %569 : Tensor = prim::GetAttr[name="bias"](%549)
       = prim::If(%565) # torch/nn/functional.py:2011:4
        block0():
          %570 : int[] = aten::size(%input.165) # torch/nn/functional.py:2012:27
          %size_prods.248 : int = aten::__getitem__(%570, %10) # torch/nn/functional.py:1991:17
          %572 : int = aten::len(%570) # torch/nn/functional.py:1992:19
          %573 : int = aten::sub(%572, %16) # torch/nn/functional.py:1992:19
          %size_prods.249 : int = prim::Loop(%573, %9, %size_prods.248) # torch/nn/functional.py:1992:4
            block0(%i.63 : int, %size_prods.250 : int):
              %577 : int = aten::add(%i.63, %16) # torch/nn/functional.py:1993:27
              %578 : int = aten::__getitem__(%570, %577) # torch/nn/functional.py:1993:22
              %size_prods.251 : int = aten::mul(%size_prods.250, %578) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.251)
          %580 : bool = aten::eq(%size_prods.249, %8) # torch/nn/functional.py:1994:7
           = prim::If(%580) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.167 : Tensor = aten::batch_norm(%input.165, %568, %569, %566, %567, %565, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.168 : Tensor = aten::relu_(%input.167) # torch/nn/functional.py:1117:17
      %583 : Tensor = prim::GetAttr[name="weight"](%550)
      %584 : Tensor? = prim::GetAttr[name="bias"](%550)
      %585 : int[] = prim::ListConstruct(%8, %8)
      %586 : int[] = prim::ListConstruct(%8, %8)
      %587 : int[] = prim::ListConstruct(%8, %8)
      %input.169 : Tensor = aten::conv2d(%input.168, %583, %584, %585, %586, %587, %7) # torch/nn/modules/conv.py:415:15
      %589 : int = aten::dim(%input.169) # torch/nn/modules/batchnorm.py:276:11
      %590 : bool = aten::ne(%589, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%590) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %591 : bool = prim::GetAttr[name="training"](%551)
       = prim::If(%591) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %592 : Tensor = prim::GetAttr[name="num_batches_tracked"](%551)
          %593 : Tensor = aten::add(%592, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%551, %593)
          -> ()
        block1():
          -> ()
      %594 : bool = prim::GetAttr[name="training"](%551)
      %595 : Tensor = prim::GetAttr[name="running_mean"](%551)
      %596 : Tensor = prim::GetAttr[name="running_var"](%551)
      %597 : Tensor = prim::GetAttr[name="weight"](%551)
      %598 : Tensor = prim::GetAttr[name="bias"](%551)
       = prim::If(%594) # torch/nn/functional.py:2011:4
        block0():
          %599 : int[] = aten::size(%input.169) # torch/nn/functional.py:2012:27
          %size_prods.252 : int = aten::__getitem__(%599, %10) # torch/nn/functional.py:1991:17
          %601 : int = aten::len(%599) # torch/nn/functional.py:1992:19
          %602 : int = aten::sub(%601, %16) # torch/nn/functional.py:1992:19
          %size_prods.253 : int = prim::Loop(%602, %9, %size_prods.252) # torch/nn/functional.py:1992:4
            block0(%i.64 : int, %size_prods.254 : int):
              %606 : int = aten::add(%i.64, %16) # torch/nn/functional.py:1993:27
              %607 : int = aten::__getitem__(%599, %606) # torch/nn/functional.py:1993:22
              %size_prods.255 : int = aten::mul(%size_prods.254, %607) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.255)
          %609 : bool = aten::eq(%size_prods.253, %8) # torch/nn/functional.py:1994:7
           = prim::If(%609) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.171 : Tensor = aten::batch_norm(%input.169, %597, %598, %595, %596, %594, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %611 : Tensor = prim::GetAttr[name="weight"](%552)
      %612 : Tensor? = prim::GetAttr[name="bias"](%552)
      %613 : int[] = prim::ListConstruct(%8, %8)
      %614 : int[] = prim::ListConstruct(%10, %10)
      %615 : int[] = prim::ListConstruct(%8, %8)
      %input.172 : Tensor = aten::conv2d(%input.171, %611, %612, %613, %614, %615, %8) # torch/nn/modules/conv.py:415:15
      %617 : int = aten::dim(%input.172) # torch/nn/modules/batchnorm.py:276:11
      %618 : bool = aten::ne(%617, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%618) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %619 : bool = prim::GetAttr[name="training"](%553)
       = prim::If(%619) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %620 : Tensor = prim::GetAttr[name="num_batches_tracked"](%553)
          %621 : Tensor = aten::add(%620, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%553, %621)
          -> ()
        block1():
          -> ()
      %622 : bool = prim::GetAttr[name="training"](%553)
      %623 : Tensor = prim::GetAttr[name="running_mean"](%553)
      %624 : Tensor = prim::GetAttr[name="running_var"](%553)
      %625 : Tensor = prim::GetAttr[name="weight"](%553)
      %626 : Tensor = prim::GetAttr[name="bias"](%553)
       = prim::If(%622) # torch/nn/functional.py:2011:4
        block0():
          %627 : int[] = aten::size(%input.172) # torch/nn/functional.py:2012:27
          %size_prods.256 : int = aten::__getitem__(%627, %10) # torch/nn/functional.py:1991:17
          %629 : int = aten::len(%627) # torch/nn/functional.py:1992:19
          %630 : int = aten::sub(%629, %16) # torch/nn/functional.py:1992:19
          %size_prods.257 : int = prim::Loop(%630, %9, %size_prods.256) # torch/nn/functional.py:1992:4
            block0(%i.65 : int, %size_prods.258 : int):
              %634 : int = aten::add(%i.65, %16) # torch/nn/functional.py:1993:27
              %635 : int = aten::__getitem__(%627, %634) # torch/nn/functional.py:1993:22
              %size_prods.259 : int = aten::mul(%size_prods.258, %635) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.259)
          %637 : bool = aten::eq(%size_prods.257, %8) # torch/nn/functional.py:1994:7
           = prim::If(%637) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.173 : Tensor = aten::batch_norm(%input.172, %625, %626, %623, %624, %622, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.174 : Tensor = aten::relu_(%input.173) # torch/nn/functional.py:1117:17
      %640 : Tensor[] = prim::ListConstruct(%x1.10, %input.174)
      %out.28 : Tensor = aten::cat(%640, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.28)
    block1():
      %642 : __torch__.torch.nn.modules.container.___torch_mangle_1055.Sequential = prim::GetAttr[name="branch2"](%59)
      %643 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="0"](%642)
      %644 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="1"](%642)
      %645 : __torch__.torch.nn.modules.conv.___torch_mangle_1054.Conv2d = prim::GetAttr[name="3"](%642)
      %646 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="4"](%642)
      %647 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="5"](%642)
      %648 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="6"](%642)
      %649 : Tensor = prim::GetAttr[name="weight"](%643)
      %650 : Tensor? = prim::GetAttr[name="bias"](%643)
      %651 : int[] = prim::ListConstruct(%8, %8)
      %652 : int[] = prim::ListConstruct(%10, %10)
      %653 : int[] = prim::ListConstruct(%8, %8)
      %input.175 : Tensor = aten::conv2d(%input.170, %649, %650, %651, %652, %653, %8) # torch/nn/modules/conv.py:415:15
      %655 : int = aten::dim(%input.175) # torch/nn/modules/batchnorm.py:276:11
      %656 : bool = aten::ne(%655, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%656) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %657 : bool = prim::GetAttr[name="training"](%644)
       = prim::If(%657) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %658 : Tensor = prim::GetAttr[name="num_batches_tracked"](%644)
          %659 : Tensor = aten::add(%658, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%644, %659)
          -> ()
        block1():
          -> ()
      %660 : bool = prim::GetAttr[name="training"](%644)
      %661 : Tensor = prim::GetAttr[name="running_mean"](%644)
      %662 : Tensor = prim::GetAttr[name="running_var"](%644)
      %663 : Tensor = prim::GetAttr[name="weight"](%644)
      %664 : Tensor = prim::GetAttr[name="bias"](%644)
       = prim::If(%660) # torch/nn/functional.py:2011:4
        block0():
          %665 : int[] = aten::size(%input.175) # torch/nn/functional.py:2012:27
          %size_prods.260 : int = aten::__getitem__(%665, %10) # torch/nn/functional.py:1991:17
          %667 : int = aten::len(%665) # torch/nn/functional.py:1992:19
          %668 : int = aten::sub(%667, %16) # torch/nn/functional.py:1992:19
          %size_prods.261 : int = prim::Loop(%668, %9, %size_prods.260) # torch/nn/functional.py:1992:4
            block0(%i.66 : int, %size_prods.262 : int):
              %672 : int = aten::add(%i.66, %16) # torch/nn/functional.py:1993:27
              %673 : int = aten::__getitem__(%665, %672) # torch/nn/functional.py:1993:22
              %size_prods.263 : int = aten::mul(%size_prods.262, %673) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.263)
          %675 : bool = aten::eq(%size_prods.261, %8) # torch/nn/functional.py:1994:7
           = prim::If(%675) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.176 : Tensor = aten::batch_norm(%input.175, %663, %664, %661, %662, %660, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.177 : Tensor = aten::relu_(%input.176) # torch/nn/functional.py:1117:17
      %678 : Tensor = prim::GetAttr[name="weight"](%645)
      %679 : Tensor? = prim::GetAttr[name="bias"](%645)
      %680 : int[] = prim::ListConstruct(%8, %8)
      %681 : int[] = prim::ListConstruct(%8, %8)
      %682 : int[] = prim::ListConstruct(%8, %8)
      %input.178 : Tensor = aten::conv2d(%input.177, %678, %679, %680, %681, %682, %7) # torch/nn/modules/conv.py:415:15
      %684 : int = aten::dim(%input.178) # torch/nn/modules/batchnorm.py:276:11
      %685 : bool = aten::ne(%684, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%685) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %686 : bool = prim::GetAttr[name="training"](%646)
       = prim::If(%686) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %687 : Tensor = prim::GetAttr[name="num_batches_tracked"](%646)
          %688 : Tensor = aten::add(%687, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%646, %688)
          -> ()
        block1():
          -> ()
      %689 : bool = prim::GetAttr[name="training"](%646)
      %690 : Tensor = prim::GetAttr[name="running_mean"](%646)
      %691 : Tensor = prim::GetAttr[name="running_var"](%646)
      %692 : Tensor = prim::GetAttr[name="weight"](%646)
      %693 : Tensor = prim::GetAttr[name="bias"](%646)
       = prim::If(%689) # torch/nn/functional.py:2011:4
        block0():
          %694 : int[] = aten::size(%input.178) # torch/nn/functional.py:2012:27
          %size_prods.264 : int = aten::__getitem__(%694, %10) # torch/nn/functional.py:1991:17
          %696 : int = aten::len(%694) # torch/nn/functional.py:1992:19
          %697 : int = aten::sub(%696, %16) # torch/nn/functional.py:1992:19
          %size_prods.265 : int = prim::Loop(%697, %9, %size_prods.264) # torch/nn/functional.py:1992:4
            block0(%i.67 : int, %size_prods.266 : int):
              %701 : int = aten::add(%i.67, %16) # torch/nn/functional.py:1993:27
              %702 : int = aten::__getitem__(%694, %701) # torch/nn/functional.py:1993:22
              %size_prods.267 : int = aten::mul(%size_prods.266, %702) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.267)
          %704 : bool = aten::eq(%size_prods.265, %8) # torch/nn/functional.py:1994:7
           = prim::If(%704) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.179 : Tensor = aten::batch_norm(%input.178, %692, %693, %690, %691, %689, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %706 : Tensor = prim::GetAttr[name="weight"](%647)
      %707 : Tensor? = prim::GetAttr[name="bias"](%647)
      %708 : int[] = prim::ListConstruct(%8, %8)
      %709 : int[] = prim::ListConstruct(%10, %10)
      %710 : int[] = prim::ListConstruct(%8, %8)
      %input.180 : Tensor = aten::conv2d(%input.179, %706, %707, %708, %709, %710, %8) # torch/nn/modules/conv.py:415:15
      %712 : int = aten::dim(%input.180) # torch/nn/modules/batchnorm.py:276:11
      %713 : bool = aten::ne(%712, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%713) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %714 : bool = prim::GetAttr[name="training"](%648)
       = prim::If(%714) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %715 : Tensor = prim::GetAttr[name="num_batches_tracked"](%648)
          %716 : Tensor = aten::add(%715, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%648, %716)
          -> ()
        block1():
          -> ()
      %717 : bool = prim::GetAttr[name="training"](%648)
      %718 : Tensor = prim::GetAttr[name="running_mean"](%648)
      %719 : Tensor = prim::GetAttr[name="running_var"](%648)
      %720 : Tensor = prim::GetAttr[name="weight"](%648)
      %721 : Tensor = prim::GetAttr[name="bias"](%648)
       = prim::If(%717) # torch/nn/functional.py:2011:4
        block0():
          %722 : int[] = aten::size(%input.180) # torch/nn/functional.py:2012:27
          %size_prods.268 : int = aten::__getitem__(%722, %10) # torch/nn/functional.py:1991:17
          %724 : int = aten::len(%722) # torch/nn/functional.py:1992:19
          %725 : int = aten::sub(%724, %16) # torch/nn/functional.py:1992:19
          %size_prods.269 : int = prim::Loop(%725, %9, %size_prods.268) # torch/nn/functional.py:1992:4
            block0(%i.68 : int, %size_prods.270 : int):
              %729 : int = aten::add(%i.68, %16) # torch/nn/functional.py:1993:27
              %730 : int = aten::__getitem__(%722, %729) # torch/nn/functional.py:1993:22
              %size_prods.271 : int = aten::mul(%size_prods.270, %730) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.271)
          %732 : bool = aten::eq(%size_prods.269, %8) # torch/nn/functional.py:1994:7
           = prim::If(%732) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.181 : Tensor = aten::batch_norm(%input.180, %720, %721, %718, %719, %717, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.182 : Tensor = aten::relu_(%input.181) # torch/nn/functional.py:1117:17
      %735 : Tensor[] = prim::ListConstruct(%input.170, %input.182)
      %out.29 : Tensor = aten::cat(%735, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.29)
  %737 : Tensor = prim::data(%out.30)
  %738 : int[] = aten::size(%737) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.10 : int, %num_channels.10 : int, %height.10 : int, %width.10 : int = prim::ListUnpack(%738)
  %channels_per_group.10 : int = aten::floordiv(%num_channels.10, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %744 : int[] = prim::ListConstruct(%batchsize.10, %16, %channels_per_group.10, %height.10, %width.10)
  %x.23 : Tensor = aten::view(%out.30, %744) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %746 : Tensor = aten::transpose(%x.23, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.24 : Tensor = aten::contiguous(%746, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %748 : int[] = prim::ListConstruct(%batchsize.10, %5, %height.10, %width.10)
  %input.188 : Tensor = aten::view(%x.24, %748) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %750 : int = prim::GetAttr[name="stride"](%60)
  %751 : bool = aten::eq(%750, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.33 : Tensor = prim::If(%751) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %753 : Tensor[] = aten::chunk(%input.188, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.12 : Tensor, %x2.12 : Tensor = prim::ListUnpack(%753)
      %756 : __torch__.torch.nn.modules.container.___torch_mangle_1055.Sequential = prim::GetAttr[name="branch2"](%60)
      %757 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="0"](%756)
      %758 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="1"](%756)
      %759 : __torch__.torch.nn.modules.conv.___torch_mangle_1054.Conv2d = prim::GetAttr[name="3"](%756)
      %760 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="4"](%756)
      %761 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="5"](%756)
      %762 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="6"](%756)
      %763 : Tensor = prim::GetAttr[name="weight"](%757)
      %764 : Tensor? = prim::GetAttr[name="bias"](%757)
      %765 : int[] = prim::ListConstruct(%8, %8)
      %766 : int[] = prim::ListConstruct(%10, %10)
      %767 : int[] = prim::ListConstruct(%8, %8)
      %input.201 : Tensor = aten::conv2d(%x2.12, %763, %764, %765, %766, %767, %8) # torch/nn/modules/conv.py:415:15
      %769 : int = aten::dim(%input.201) # torch/nn/modules/batchnorm.py:276:11
      %770 : bool = aten::ne(%769, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%770) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %771 : bool = prim::GetAttr[name="training"](%758)
       = prim::If(%771) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %772 : Tensor = prim::GetAttr[name="num_batches_tracked"](%758)
          %773 : Tensor = aten::add(%772, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%758, %773)
          -> ()
        block1():
          -> ()
      %774 : bool = prim::GetAttr[name="training"](%758)
      %775 : Tensor = prim::GetAttr[name="running_mean"](%758)
      %776 : Tensor = prim::GetAttr[name="running_var"](%758)
      %777 : Tensor = prim::GetAttr[name="weight"](%758)
      %778 : Tensor = prim::GetAttr[name="bias"](%758)
       = prim::If(%774) # torch/nn/functional.py:2011:4
        block0():
          %779 : int[] = aten::size(%input.201) # torch/nn/functional.py:2012:27
          %size_prods.284 : int = aten::__getitem__(%779, %10) # torch/nn/functional.py:1991:17
          %781 : int = aten::len(%779) # torch/nn/functional.py:1992:19
          %782 : int = aten::sub(%781, %16) # torch/nn/functional.py:1992:19
          %size_prods.285 : int = prim::Loop(%782, %9, %size_prods.284) # torch/nn/functional.py:1992:4
            block0(%i.72 : int, %size_prods.286 : int):
              %786 : int = aten::add(%i.72, %16) # torch/nn/functional.py:1993:27
              %787 : int = aten::__getitem__(%779, %786) # torch/nn/functional.py:1993:22
              %size_prods.287 : int = aten::mul(%size_prods.286, %787) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.287)
          %789 : bool = aten::eq(%size_prods.285, %8) # torch/nn/functional.py:1994:7
           = prim::If(%789) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.202 : Tensor = aten::batch_norm(%input.201, %777, %778, %775, %776, %774, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.203 : Tensor = aten::relu_(%input.202) # torch/nn/functional.py:1117:17
      %792 : Tensor = prim::GetAttr[name="weight"](%759)
      %793 : Tensor? = prim::GetAttr[name="bias"](%759)
      %794 : int[] = prim::ListConstruct(%8, %8)
      %795 : int[] = prim::ListConstruct(%8, %8)
      %796 : int[] = prim::ListConstruct(%8, %8)
      %input.204 : Tensor = aten::conv2d(%input.203, %792, %793, %794, %795, %796, %7) # torch/nn/modules/conv.py:415:15
      %798 : int = aten::dim(%input.204) # torch/nn/modules/batchnorm.py:276:11
      %799 : bool = aten::ne(%798, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%799) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %800 : bool = prim::GetAttr[name="training"](%760)
       = prim::If(%800) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %801 : Tensor = prim::GetAttr[name="num_batches_tracked"](%760)
          %802 : Tensor = aten::add(%801, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%760, %802)
          -> ()
        block1():
          -> ()
      %803 : bool = prim::GetAttr[name="training"](%760)
      %804 : Tensor = prim::GetAttr[name="running_mean"](%760)
      %805 : Tensor = prim::GetAttr[name="running_var"](%760)
      %806 : Tensor = prim::GetAttr[name="weight"](%760)
      %807 : Tensor = prim::GetAttr[name="bias"](%760)
       = prim::If(%803) # torch/nn/functional.py:2011:4
        block0():
          %808 : int[] = aten::size(%input.204) # torch/nn/functional.py:2012:27
          %size_prods.288 : int = aten::__getitem__(%808, %10) # torch/nn/functional.py:1991:17
          %810 : int = aten::len(%808) # torch/nn/functional.py:1992:19
          %811 : int = aten::sub(%810, %16) # torch/nn/functional.py:1992:19
          %size_prods.289 : int = prim::Loop(%811, %9, %size_prods.288) # torch/nn/functional.py:1992:4
            block0(%i.73 : int, %size_prods.290 : int):
              %815 : int = aten::add(%i.73, %16) # torch/nn/functional.py:1993:27
              %816 : int = aten::__getitem__(%808, %815) # torch/nn/functional.py:1993:22
              %size_prods.291 : int = aten::mul(%size_prods.290, %816) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.291)
          %818 : bool = aten::eq(%size_prods.289, %8) # torch/nn/functional.py:1994:7
           = prim::If(%818) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.205 : Tensor = aten::batch_norm(%input.204, %806, %807, %804, %805, %803, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %820 : Tensor = prim::GetAttr[name="weight"](%761)
      %821 : Tensor? = prim::GetAttr[name="bias"](%761)
      %822 : int[] = prim::ListConstruct(%8, %8)
      %823 : int[] = prim::ListConstruct(%10, %10)
      %824 : int[] = prim::ListConstruct(%8, %8)
      %input.206 : Tensor = aten::conv2d(%input.205, %820, %821, %822, %823, %824, %8) # torch/nn/modules/conv.py:415:15
      %826 : int = aten::dim(%input.206) # torch/nn/modules/batchnorm.py:276:11
      %827 : bool = aten::ne(%826, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%827) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %828 : bool = prim::GetAttr[name="training"](%762)
       = prim::If(%828) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %829 : Tensor = prim::GetAttr[name="num_batches_tracked"](%762)
          %830 : Tensor = aten::add(%829, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%762, %830)
          -> ()
        block1():
          -> ()
      %831 : bool = prim::GetAttr[name="training"](%762)
      %832 : Tensor = prim::GetAttr[name="running_mean"](%762)
      %833 : Tensor = prim::GetAttr[name="running_var"](%762)
      %834 : Tensor = prim::GetAttr[name="weight"](%762)
      %835 : Tensor = prim::GetAttr[name="bias"](%762)
       = prim::If(%831) # torch/nn/functional.py:2011:4
        block0():
          %836 : int[] = aten::size(%input.206) # torch/nn/functional.py:2012:27
          %size_prods.292 : int = aten::__getitem__(%836, %10) # torch/nn/functional.py:1991:17
          %838 : int = aten::len(%836) # torch/nn/functional.py:1992:19
          %839 : int = aten::sub(%838, %16) # torch/nn/functional.py:1992:19
          %size_prods.293 : int = prim::Loop(%839, %9, %size_prods.292) # torch/nn/functional.py:1992:4
            block0(%i.74 : int, %size_prods.294 : int):
              %843 : int = aten::add(%i.74, %16) # torch/nn/functional.py:1993:27
              %844 : int = aten::__getitem__(%836, %843) # torch/nn/functional.py:1993:22
              %size_prods.295 : int = aten::mul(%size_prods.294, %844) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.295)
          %846 : bool = aten::eq(%size_prods.293, %8) # torch/nn/functional.py:1994:7
           = prim::If(%846) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.207 : Tensor = aten::batch_norm(%input.206, %834, %835, %832, %833, %831, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.208 : Tensor = aten::relu_(%input.207) # torch/nn/functional.py:1117:17
      %849 : Tensor[] = prim::ListConstruct(%x1.12, %input.208)
      %out.34 : Tensor = aten::cat(%849, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.34)
    block1():
      %851 : __torch__.torch.nn.modules.container.___torch_mangle_1055.Sequential = prim::GetAttr[name="branch2"](%60)
      %852 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="0"](%851)
      %853 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="1"](%851)
      %854 : __torch__.torch.nn.modules.conv.___torch_mangle_1054.Conv2d = prim::GetAttr[name="3"](%851)
      %855 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="4"](%851)
      %856 : __torch__.torch.nn.modules.conv.___torch_mangle_1051.Conv2d = prim::GetAttr[name="5"](%851)
      %857 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1048.BatchNorm2d = prim::GetAttr[name="6"](%851)
      %858 : Tensor = prim::GetAttr[name="weight"](%852)
      %859 : Tensor? = prim::GetAttr[name="bias"](%852)
      %860 : int[] = prim::ListConstruct(%8, %8)
      %861 : int[] = prim::ListConstruct(%10, %10)
      %862 : int[] = prim::ListConstruct(%8, %8)
      %input.209 : Tensor = aten::conv2d(%input.188, %858, %859, %860, %861, %862, %8) # torch/nn/modules/conv.py:415:15
      %864 : int = aten::dim(%input.209) # torch/nn/modules/batchnorm.py:276:11
      %865 : bool = aten::ne(%864, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%865) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %866 : bool = prim::GetAttr[name="training"](%853)
       = prim::If(%866) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %867 : Tensor = prim::GetAttr[name="num_batches_tracked"](%853)
          %868 : Tensor = aten::add(%867, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%853, %868)
          -> ()
        block1():
          -> ()
      %869 : bool = prim::GetAttr[name="training"](%853)
      %870 : Tensor = prim::GetAttr[name="running_mean"](%853)
      %871 : Tensor = prim::GetAttr[name="running_var"](%853)
      %872 : Tensor = prim::GetAttr[name="weight"](%853)
      %873 : Tensor = prim::GetAttr[name="bias"](%853)
       = prim::If(%869) # torch/nn/functional.py:2011:4
        block0():
          %874 : int[] = aten::size(%input.209) # torch/nn/functional.py:2012:27
          %size_prods.296 : int = aten::__getitem__(%874, %10) # torch/nn/functional.py:1991:17
          %876 : int = aten::len(%874) # torch/nn/functional.py:1992:19
          %877 : int = aten::sub(%876, %16) # torch/nn/functional.py:1992:19
          %size_prods.297 : int = prim::Loop(%877, %9, %size_prods.296) # torch/nn/functional.py:1992:4
            block0(%i.75 : int, %size_prods.298 : int):
              %881 : int = aten::add(%i.75, %16) # torch/nn/functional.py:1993:27
              %882 : int = aten::__getitem__(%874, %881) # torch/nn/functional.py:1993:22
              %size_prods.299 : int = aten::mul(%size_prods.298, %882) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.299)
          %884 : bool = aten::eq(%size_prods.297, %8) # torch/nn/functional.py:1994:7
           = prim::If(%884) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.210 : Tensor = aten::batch_norm(%input.209, %872, %873, %870, %871, %869, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.211 : Tensor = aten::relu_(%input.210) # torch/nn/functional.py:1117:17
      %887 : Tensor = prim::GetAttr[name="weight"](%854)
      %888 : Tensor? = prim::GetAttr[name="bias"](%854)
      %889 : int[] = prim::ListConstruct(%8, %8)
      %890 : int[] = prim::ListConstruct(%8, %8)
      %891 : int[] = prim::ListConstruct(%8, %8)
      %input.212 : Tensor = aten::conv2d(%input.211, %887, %888, %889, %890, %891, %7) # torch/nn/modules/conv.py:415:15
      %893 : int = aten::dim(%input.212) # torch/nn/modules/batchnorm.py:276:11
      %894 : bool = aten::ne(%893, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%894) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %895 : bool = prim::GetAttr[name="training"](%855)
       = prim::If(%895) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %896 : Tensor = prim::GetAttr[name="num_batches_tracked"](%855)
          %897 : Tensor = aten::add(%896, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%855, %897)
          -> ()
        block1():
          -> ()
      %898 : bool = prim::GetAttr[name="training"](%855)
      %899 : Tensor = prim::GetAttr[name="running_mean"](%855)
      %900 : Tensor = prim::GetAttr[name="running_var"](%855)
      %901 : Tensor = prim::GetAttr[name="weight"](%855)
      %902 : Tensor = prim::GetAttr[name="bias"](%855)
       = prim::If(%898) # torch/nn/functional.py:2011:4
        block0():
          %903 : int[] = aten::size(%input.212) # torch/nn/functional.py:2012:27
          %size_prods.300 : int = aten::__getitem__(%903, %10) # torch/nn/functional.py:1991:17
          %905 : int = aten::len(%903) # torch/nn/functional.py:1992:19
          %906 : int = aten::sub(%905, %16) # torch/nn/functional.py:1992:19
          %size_prods.301 : int = prim::Loop(%906, %9, %size_prods.300) # torch/nn/functional.py:1992:4
            block0(%i.76 : int, %size_prods.302 : int):
              %910 : int = aten::add(%i.76, %16) # torch/nn/functional.py:1993:27
              %911 : int = aten::__getitem__(%903, %910) # torch/nn/functional.py:1993:22
              %size_prods.303 : int = aten::mul(%size_prods.302, %911) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.303)
          %913 : bool = aten::eq(%size_prods.301, %8) # torch/nn/functional.py:1994:7
           = prim::If(%913) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.213 : Tensor = aten::batch_norm(%input.212, %901, %902, %899, %900, %898, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %915 : Tensor = prim::GetAttr[name="weight"](%856)
      %916 : Tensor? = prim::GetAttr[name="bias"](%856)
      %917 : int[] = prim::ListConstruct(%8, %8)
      %918 : int[] = prim::ListConstruct(%10, %10)
      %919 : int[] = prim::ListConstruct(%8, %8)
      %input.214 : Tensor = aten::conv2d(%input.213, %915, %916, %917, %918, %919, %8) # torch/nn/modules/conv.py:415:15
      %921 : int = aten::dim(%input.214) # torch/nn/modules/batchnorm.py:276:11
      %922 : bool = aten::ne(%921, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%922) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %923 : bool = prim::GetAttr[name="training"](%857)
       = prim::If(%923) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %924 : Tensor = prim::GetAttr[name="num_batches_tracked"](%857)
          %925 : Tensor = aten::add(%924, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%857, %925)
          -> ()
        block1():
          -> ()
      %926 : bool = prim::GetAttr[name="training"](%857)
      %927 : Tensor = prim::GetAttr[name="running_mean"](%857)
      %928 : Tensor = prim::GetAttr[name="running_var"](%857)
      %929 : Tensor = prim::GetAttr[name="weight"](%857)
      %930 : Tensor = prim::GetAttr[name="bias"](%857)
       = prim::If(%926) # torch/nn/functional.py:2011:4
        block0():
          %931 : int[] = aten::size(%input.214) # torch/nn/functional.py:2012:27
          %size_prods.304 : int = aten::__getitem__(%931, %10) # torch/nn/functional.py:1991:17
          %933 : int = aten::len(%931) # torch/nn/functional.py:1992:19
          %934 : int = aten::sub(%933, %16) # torch/nn/functional.py:1992:19
          %size_prods.305 : int = prim::Loop(%934, %9, %size_prods.304) # torch/nn/functional.py:1992:4
            block0(%i.77 : int, %size_prods.306 : int):
              %938 : int = aten::add(%i.77, %16) # torch/nn/functional.py:1993:27
              %939 : int = aten::__getitem__(%931, %938) # torch/nn/functional.py:1993:22
              %size_prods.307 : int = aten::mul(%size_prods.306, %939) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.307)
          %941 : bool = aten::eq(%size_prods.305, %8) # torch/nn/functional.py:1994:7
           = prim::If(%941) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.215 : Tensor = aten::batch_norm(%input.214, %929, %930, %927, %928, %926, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.216 : Tensor = aten::relu_(%input.215) # torch/nn/functional.py:1117:17
      %944 : Tensor[] = prim::ListConstruct(%input.188, %input.216)
      %out.35 : Tensor = aten::cat(%944, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.35)
  %946 : Tensor = prim::data(%out.33)
  %947 : int[] = aten::size(%946) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.12 : int, %num_channels.12 : int, %height.12 : int, %width.12 : int = prim::ListUnpack(%947)
  %channels_per_group.12 : int = aten::floordiv(%num_channels.12, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %953 : int[] = prim::ListConstruct(%batchsize.12, %16, %channels_per_group.12, %height.12, %width.12)
  %x.33 : Tensor = aten::view(%out.33, %953) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %955 : Tensor = aten::transpose(%x.33, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.34 : Tensor = aten::contiguous(%955, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %957 : int[] = prim::ListConstruct(%batchsize.12, %5, %height.12, %width.12)
  %x.27 : Tensor = aten::view(%x.34, %957) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %959 : __torch__.torch.nn.modules.container.___torch_mangle_1067.Sequential = prim::GetAttr[name="stage3"](%self)
  %960 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1063.InvertedResidual = prim::GetAttr[name="0"](%959)
  %961 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1066.InvertedResidual = prim::GetAttr[name="1"](%959)
  %962 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1066.InvertedResidual = prim::GetAttr[name="2"](%959)
  %963 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1066.InvertedResidual = prim::GetAttr[name="3"](%959)
  %964 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1066.InvertedResidual = prim::GetAttr[name="4"](%959)
  %965 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1066.InvertedResidual = prim::GetAttr[name="5"](%959)
  %966 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1066.InvertedResidual = prim::GetAttr[name="6"](%959)
  %967 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1066.InvertedResidual = prim::GetAttr[name="7"](%959)
  %968 : int = prim::GetAttr[name="stride"](%960)
  %969 : bool = aten::eq(%968, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.36 : Tensor = prim::If(%969) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %971 : Tensor[] = aten::chunk(%x.27, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.13 : Tensor, %x2.13 : Tensor = prim::ListUnpack(%971)
      %974 : __torch__.torch.nn.modules.container.___torch_mangle_1062.Sequential = prim::GetAttr[name="branch2"](%960)
      %975 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%974)
      %976 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%974)
      %977 : __torch__.torch.nn.modules.conv.___torch_mangle_1058.Conv2d = prim::GetAttr[name="3"](%974)
      %978 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%974)
      %979 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%974)
      %980 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%974)
      %981 : Tensor = prim::GetAttr[name="weight"](%975)
      %982 : Tensor? = prim::GetAttr[name="bias"](%975)
      %983 : int[] = prim::ListConstruct(%8, %8)
      %984 : int[] = prim::ListConstruct(%10, %10)
      %985 : int[] = prim::ListConstruct(%8, %8)
      %input.221 : Tensor = aten::conv2d(%x2.13, %981, %982, %983, %984, %985, %8) # torch/nn/modules/conv.py:415:15
      %987 : int = aten::dim(%input.221) # torch/nn/modules/batchnorm.py:276:11
      %988 : bool = aten::ne(%987, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%988) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %989 : bool = prim::GetAttr[name="training"](%976)
       = prim::If(%989) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %990 : Tensor = prim::GetAttr[name="num_batches_tracked"](%976)
          %991 : Tensor = aten::add(%990, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%976, %991)
          -> ()
        block1():
          -> ()
      %992 : bool = prim::GetAttr[name="training"](%976)
      %993 : Tensor = prim::GetAttr[name="running_mean"](%976)
      %994 : Tensor = prim::GetAttr[name="running_var"](%976)
      %995 : Tensor = prim::GetAttr[name="weight"](%976)
      %996 : Tensor = prim::GetAttr[name="bias"](%976)
       = prim::If(%992) # torch/nn/functional.py:2011:4
        block0():
          %997 : int[] = aten::size(%input.221) # torch/nn/functional.py:2012:27
          %size_prods.308 : int = aten::__getitem__(%997, %10) # torch/nn/functional.py:1991:17
          %999 : int = aten::len(%997) # torch/nn/functional.py:1992:19
          %1000 : int = aten::sub(%999, %16) # torch/nn/functional.py:1992:19
          %size_prods.309 : int = prim::Loop(%1000, %9, %size_prods.308) # torch/nn/functional.py:1992:4
            block0(%i.78 : int, %size_prods.310 : int):
              %1004 : int = aten::add(%i.78, %16) # torch/nn/functional.py:1993:27
              %1005 : int = aten::__getitem__(%997, %1004) # torch/nn/functional.py:1993:22
              %size_prods.311 : int = aten::mul(%size_prods.310, %1005) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.311)
          %1007 : bool = aten::eq(%size_prods.309, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1007) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.225 : Tensor = aten::batch_norm(%input.221, %995, %996, %993, %994, %992, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.226 : Tensor = aten::relu_(%input.225) # torch/nn/functional.py:1117:17
      %1010 : Tensor = prim::GetAttr[name="weight"](%977)
      %1011 : Tensor? = prim::GetAttr[name="bias"](%977)
      %1012 : int[] = prim::ListConstruct(%16, %16)
      %1013 : int[] = prim::ListConstruct(%8, %8)
      %1014 : int[] = prim::ListConstruct(%8, %8)
      %input.227 : Tensor = aten::conv2d(%input.226, %1010, %1011, %1012, %1013, %1014, %4) # torch/nn/modules/conv.py:415:15
      %1016 : int = aten::dim(%input.227) # torch/nn/modules/batchnorm.py:276:11
      %1017 : bool = aten::ne(%1016, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1017) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1018 : bool = prim::GetAttr[name="training"](%978)
       = prim::If(%1018) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1019 : Tensor = prim::GetAttr[name="num_batches_tracked"](%978)
          %1020 : Tensor = aten::add(%1019, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%978, %1020)
          -> ()
        block1():
          -> ()
      %1021 : bool = prim::GetAttr[name="training"](%978)
      %1022 : Tensor = prim::GetAttr[name="running_mean"](%978)
      %1023 : Tensor = prim::GetAttr[name="running_var"](%978)
      %1024 : Tensor = prim::GetAttr[name="weight"](%978)
      %1025 : Tensor = prim::GetAttr[name="bias"](%978)
       = prim::If(%1021) # torch/nn/functional.py:2011:4
        block0():
          %1026 : int[] = aten::size(%input.227) # torch/nn/functional.py:2012:27
          %size_prods.312 : int = aten::__getitem__(%1026, %10) # torch/nn/functional.py:1991:17
          %1028 : int = aten::len(%1026) # torch/nn/functional.py:1992:19
          %1029 : int = aten::sub(%1028, %16) # torch/nn/functional.py:1992:19
          %size_prods.313 : int = prim::Loop(%1029, %9, %size_prods.312) # torch/nn/functional.py:1992:4
            block0(%i.79 : int, %size_prods.314 : int):
              %1033 : int = aten::add(%i.79, %16) # torch/nn/functional.py:1993:27
              %1034 : int = aten::__getitem__(%1026, %1033) # torch/nn/functional.py:1993:22
              %size_prods.315 : int = aten::mul(%size_prods.314, %1034) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.315)
          %1036 : bool = aten::eq(%size_prods.313, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1036) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.230 : Tensor = aten::batch_norm(%input.227, %1024, %1025, %1022, %1023, %1021, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1038 : Tensor = prim::GetAttr[name="weight"](%979)
      %1039 : Tensor? = prim::GetAttr[name="bias"](%979)
      %1040 : int[] = prim::ListConstruct(%8, %8)
      %1041 : int[] = prim::ListConstruct(%10, %10)
      %1042 : int[] = prim::ListConstruct(%8, %8)
      %input.222 : Tensor = aten::conv2d(%input.230, %1038, %1039, %1040, %1041, %1042, %8) # torch/nn/modules/conv.py:415:15
      %1044 : int = aten::dim(%input.222) # torch/nn/modules/batchnorm.py:276:11
      %1045 : bool = aten::ne(%1044, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1045) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1046 : bool = prim::GetAttr[name="training"](%980)
       = prim::If(%1046) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1047 : Tensor = prim::GetAttr[name="num_batches_tracked"](%980)
          %1048 : Tensor = aten::add(%1047, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%980, %1048)
          -> ()
        block1():
          -> ()
      %1049 : bool = prim::GetAttr[name="training"](%980)
      %1050 : Tensor = prim::GetAttr[name="running_mean"](%980)
      %1051 : Tensor = prim::GetAttr[name="running_var"](%980)
      %1052 : Tensor = prim::GetAttr[name="weight"](%980)
      %1053 : Tensor = prim::GetAttr[name="bias"](%980)
       = prim::If(%1049) # torch/nn/functional.py:2011:4
        block0():
          %1054 : int[] = aten::size(%input.222) # torch/nn/functional.py:2012:27
          %size_prods.316 : int = aten::__getitem__(%1054, %10) # torch/nn/functional.py:1991:17
          %1056 : int = aten::len(%1054) # torch/nn/functional.py:1992:19
          %1057 : int = aten::sub(%1056, %16) # torch/nn/functional.py:1992:19
          %size_prods.317 : int = prim::Loop(%1057, %9, %size_prods.316) # torch/nn/functional.py:1992:4
            block0(%i.80 : int, %size_prods.318 : int):
              %1061 : int = aten::add(%i.80, %16) # torch/nn/functional.py:1993:27
              %1062 : int = aten::__getitem__(%1054, %1061) # torch/nn/functional.py:1993:22
              %size_prods.319 : int = aten::mul(%size_prods.318, %1062) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.319)
          %1064 : bool = aten::eq(%size_prods.317, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1064) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.223 : Tensor = aten::batch_norm(%input.222, %1052, %1053, %1050, %1051, %1049, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.224 : Tensor = aten::relu_(%input.223) # torch/nn/functional.py:1117:17
      %1067 : Tensor[] = prim::ListConstruct(%x1.13, %input.224)
      %out.37 : Tensor = aten::cat(%1067, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.37)
    block1():
      %1069 : __torch__.torch.nn.modules.container.___torch_mangle_1061.Sequential = prim::GetAttr[name="branch1"](%960)
      %1070 : __torch__.torch.nn.modules.conv.___torch_mangle_1058.Conv2d = prim::GetAttr[name="0"](%1069)
      %1071 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1069)
      %1072 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="2"](%1069)
      %1073 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="3"](%1069)
      %1074 : Tensor = prim::GetAttr[name="weight"](%1070)
      %1075 : Tensor? = prim::GetAttr[name="bias"](%1070)
      %1076 : int[] = prim::ListConstruct(%16, %16)
      %1077 : int[] = prim::ListConstruct(%8, %8)
      %1078 : int[] = prim::ListConstruct(%8, %8)
      %input.231 : Tensor = aten::conv2d(%x.27, %1074, %1075, %1076, %1077, %1078, %4) # torch/nn/modules/conv.py:415:15
      %1080 : int = aten::dim(%input.231) # torch/nn/modules/batchnorm.py:276:11
      %1081 : bool = aten::ne(%1080, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1081) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1082 : bool = prim::GetAttr[name="training"](%1071)
       = prim::If(%1082) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1083 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1071)
          %1084 : Tensor = aten::add(%1083, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1071, %1084)
          -> ()
        block1():
          -> ()
      %1085 : bool = prim::GetAttr[name="training"](%1071)
      %1086 : Tensor = prim::GetAttr[name="running_mean"](%1071)
      %1087 : Tensor = prim::GetAttr[name="running_var"](%1071)
      %1088 : Tensor = prim::GetAttr[name="weight"](%1071)
      %1089 : Tensor = prim::GetAttr[name="bias"](%1071)
       = prim::If(%1085) # torch/nn/functional.py:2011:4
        block0():
          %1090 : int[] = aten::size(%input.231) # torch/nn/functional.py:2012:27
          %size_prods.320 : int = aten::__getitem__(%1090, %10) # torch/nn/functional.py:1991:17
          %1092 : int = aten::len(%1090) # torch/nn/functional.py:1992:19
          %1093 : int = aten::sub(%1092, %16) # torch/nn/functional.py:1992:19
          %size_prods.321 : int = prim::Loop(%1093, %9, %size_prods.320) # torch/nn/functional.py:1992:4
            block0(%i.81 : int, %size_prods.322 : int):
              %1097 : int = aten::add(%i.81, %16) # torch/nn/functional.py:1993:27
              %1098 : int = aten::__getitem__(%1090, %1097) # torch/nn/functional.py:1993:22
              %size_prods.323 : int = aten::mul(%size_prods.322, %1098) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.323)
          %1100 : bool = aten::eq(%size_prods.321, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1100) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.232 : Tensor = aten::batch_norm(%input.231, %1088, %1089, %1086, %1087, %1085, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1102 : Tensor = prim::GetAttr[name="weight"](%1072)
      %1103 : Tensor? = prim::GetAttr[name="bias"](%1072)
      %1104 : int[] = prim::ListConstruct(%8, %8)
      %1105 : int[] = prim::ListConstruct(%10, %10)
      %1106 : int[] = prim::ListConstruct(%8, %8)
      %input.233 : Tensor = aten::conv2d(%input.232, %1102, %1103, %1104, %1105, %1106, %8) # torch/nn/modules/conv.py:415:15
      %1108 : int = aten::dim(%input.233) # torch/nn/modules/batchnorm.py:276:11
      %1109 : bool = aten::ne(%1108, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1109) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1110 : bool = prim::GetAttr[name="training"](%1073)
       = prim::If(%1110) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1111 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1073)
          %1112 : Tensor = aten::add(%1111, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1073, %1112)
          -> ()
        block1():
          -> ()
      %1113 : bool = prim::GetAttr[name="training"](%1073)
      %1114 : Tensor = prim::GetAttr[name="running_mean"](%1073)
      %1115 : Tensor = prim::GetAttr[name="running_var"](%1073)
      %1116 : Tensor = prim::GetAttr[name="weight"](%1073)
      %1117 : Tensor = prim::GetAttr[name="bias"](%1073)
       = prim::If(%1113) # torch/nn/functional.py:2011:4
        block0():
          %1118 : int[] = aten::size(%input.233) # torch/nn/functional.py:2012:27
          %size_prods.324 : int = aten::__getitem__(%1118, %10) # torch/nn/functional.py:1991:17
          %1120 : int = aten::len(%1118) # torch/nn/functional.py:1992:19
          %1121 : int = aten::sub(%1120, %16) # torch/nn/functional.py:1992:19
          %size_prods.325 : int = prim::Loop(%1121, %9, %size_prods.324) # torch/nn/functional.py:1992:4
            block0(%i.82 : int, %size_prods.326 : int):
              %1125 : int = aten::add(%i.82, %16) # torch/nn/functional.py:1993:27
              %1126 : int = aten::__getitem__(%1118, %1125) # torch/nn/functional.py:1993:22
              %size_prods.327 : int = aten::mul(%size_prods.326, %1126) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.327)
          %1128 : bool = aten::eq(%size_prods.325, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1128) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.228 : Tensor = aten::batch_norm(%input.233, %1116, %1117, %1114, %1115, %1113, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.229 : Tensor = aten::relu_(%input.228) # torch/nn/functional.py:1117:17
      %1131 : __torch__.torch.nn.modules.container.___torch_mangle_1062.Sequential = prim::GetAttr[name="branch2"](%960)
      %1132 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%1131)
      %1133 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1131)
      %1134 : __torch__.torch.nn.modules.conv.___torch_mangle_1058.Conv2d = prim::GetAttr[name="3"](%1131)
      %1135 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%1131)
      %1136 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%1131)
      %1137 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%1131)
      %1138 : Tensor = prim::GetAttr[name="weight"](%1132)
      %1139 : Tensor? = prim::GetAttr[name="bias"](%1132)
      %1140 : int[] = prim::ListConstruct(%8, %8)
      %1141 : int[] = prim::ListConstruct(%10, %10)
      %1142 : int[] = prim::ListConstruct(%8, %8)
      %input.234 : Tensor = aten::conv2d(%x.27, %1138, %1139, %1140, %1141, %1142, %8) # torch/nn/modules/conv.py:415:15
      %1144 : int = aten::dim(%input.234) # torch/nn/modules/batchnorm.py:276:11
      %1145 : bool = aten::ne(%1144, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1145) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1146 : bool = prim::GetAttr[name="training"](%1133)
       = prim::If(%1146) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1147 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1133)
          %1148 : Tensor = aten::add(%1147, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1133, %1148)
          -> ()
        block1():
          -> ()
      %1149 : bool = prim::GetAttr[name="training"](%1133)
      %1150 : Tensor = prim::GetAttr[name="running_mean"](%1133)
      %1151 : Tensor = prim::GetAttr[name="running_var"](%1133)
      %1152 : Tensor = prim::GetAttr[name="weight"](%1133)
      %1153 : Tensor = prim::GetAttr[name="bias"](%1133)
       = prim::If(%1149) # torch/nn/functional.py:2011:4
        block0():
          %1154 : int[] = aten::size(%input.234) # torch/nn/functional.py:2012:27
          %size_prods.328 : int = aten::__getitem__(%1154, %10) # torch/nn/functional.py:1991:17
          %1156 : int = aten::len(%1154) # torch/nn/functional.py:1992:19
          %1157 : int = aten::sub(%1156, %16) # torch/nn/functional.py:1992:19
          %size_prods.329 : int = prim::Loop(%1157, %9, %size_prods.328) # torch/nn/functional.py:1992:4
            block0(%i.83 : int, %size_prods.330 : int):
              %1161 : int = aten::add(%i.83, %16) # torch/nn/functional.py:1993:27
              %1162 : int = aten::__getitem__(%1154, %1161) # torch/nn/functional.py:1993:22
              %size_prods.331 : int = aten::mul(%size_prods.330, %1162) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.331)
          %1164 : bool = aten::eq(%size_prods.329, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1164) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.235 : Tensor = aten::batch_norm(%input.234, %1152, %1153, %1150, %1151, %1149, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.236 : Tensor = aten::relu_(%input.235) # torch/nn/functional.py:1117:17
      %1167 : Tensor = prim::GetAttr[name="weight"](%1134)
      %1168 : Tensor? = prim::GetAttr[name="bias"](%1134)
      %1169 : int[] = prim::ListConstruct(%16, %16)
      %1170 : int[] = prim::ListConstruct(%8, %8)
      %1171 : int[] = prim::ListConstruct(%8, %8)
      %input.237 : Tensor = aten::conv2d(%input.236, %1167, %1168, %1169, %1170, %1171, %4) # torch/nn/modules/conv.py:415:15
      %1173 : int = aten::dim(%input.237) # torch/nn/modules/batchnorm.py:276:11
      %1174 : bool = aten::ne(%1173, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1174) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1175 : bool = prim::GetAttr[name="training"](%1135)
       = prim::If(%1175) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1176 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1135)
          %1177 : Tensor = aten::add(%1176, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1135, %1177)
          -> ()
        block1():
          -> ()
      %1178 : bool = prim::GetAttr[name="training"](%1135)
      %1179 : Tensor = prim::GetAttr[name="running_mean"](%1135)
      %1180 : Tensor = prim::GetAttr[name="running_var"](%1135)
      %1181 : Tensor = prim::GetAttr[name="weight"](%1135)
      %1182 : Tensor = prim::GetAttr[name="bias"](%1135)
       = prim::If(%1178) # torch/nn/functional.py:2011:4
        block0():
          %1183 : int[] = aten::size(%input.237) # torch/nn/functional.py:2012:27
          %size_prods.332 : int = aten::__getitem__(%1183, %10) # torch/nn/functional.py:1991:17
          %1185 : int = aten::len(%1183) # torch/nn/functional.py:1992:19
          %1186 : int = aten::sub(%1185, %16) # torch/nn/functional.py:1992:19
          %size_prods.333 : int = prim::Loop(%1186, %9, %size_prods.332) # torch/nn/functional.py:1992:4
            block0(%i.84 : int, %size_prods.334 : int):
              %1190 : int = aten::add(%i.84, %16) # torch/nn/functional.py:1993:27
              %1191 : int = aten::__getitem__(%1183, %1190) # torch/nn/functional.py:1993:22
              %size_prods.335 : int = aten::mul(%size_prods.334, %1191) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.335)
          %1193 : bool = aten::eq(%size_prods.333, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1193) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.239 : Tensor = aten::batch_norm(%input.237, %1181, %1182, %1179, %1180, %1178, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1195 : Tensor = prim::GetAttr[name="weight"](%1136)
      %1196 : Tensor? = prim::GetAttr[name="bias"](%1136)
      %1197 : int[] = prim::ListConstruct(%8, %8)
      %1198 : int[] = prim::ListConstruct(%10, %10)
      %1199 : int[] = prim::ListConstruct(%8, %8)
      %input.240 : Tensor = aten::conv2d(%input.239, %1195, %1196, %1197, %1198, %1199, %8) # torch/nn/modules/conv.py:415:15
      %1201 : int = aten::dim(%input.240) # torch/nn/modules/batchnorm.py:276:11
      %1202 : bool = aten::ne(%1201, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1202) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1203 : bool = prim::GetAttr[name="training"](%1137)
       = prim::If(%1203) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1204 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1137)
          %1205 : Tensor = aten::add(%1204, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1137, %1205)
          -> ()
        block1():
          -> ()
      %1206 : bool = prim::GetAttr[name="training"](%1137)
      %1207 : Tensor = prim::GetAttr[name="running_mean"](%1137)
      %1208 : Tensor = prim::GetAttr[name="running_var"](%1137)
      %1209 : Tensor = prim::GetAttr[name="weight"](%1137)
      %1210 : Tensor = prim::GetAttr[name="bias"](%1137)
       = prim::If(%1206) # torch/nn/functional.py:2011:4
        block0():
          %1211 : int[] = aten::size(%input.240) # torch/nn/functional.py:2012:27
          %size_prods.336 : int = aten::__getitem__(%1211, %10) # torch/nn/functional.py:1991:17
          %1213 : int = aten::len(%1211) # torch/nn/functional.py:1992:19
          %1214 : int = aten::sub(%1213, %16) # torch/nn/functional.py:1992:19
          %size_prods.337 : int = prim::Loop(%1214, %9, %size_prods.336) # torch/nn/functional.py:1992:4
            block0(%i.85 : int, %size_prods.338 : int):
              %1218 : int = aten::add(%i.85, %16) # torch/nn/functional.py:1993:27
              %1219 : int = aten::__getitem__(%1211, %1218) # torch/nn/functional.py:1993:22
              %size_prods.339 : int = aten::mul(%size_prods.338, %1219) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.339)
          %1221 : bool = aten::eq(%size_prods.337, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1221) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.241 : Tensor = aten::batch_norm(%input.240, %1209, %1210, %1207, %1208, %1206, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.242 : Tensor = aten::relu_(%input.241) # torch/nn/functional.py:1117:17
      %1224 : Tensor[] = prim::ListConstruct(%input.229, %input.242)
      %out.38 : Tensor = aten::cat(%1224, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.38)
  %1226 : Tensor = prim::data(%out.36)
  %1227 : int[] = aten::size(%1226) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.13 : int, %num_channels.13 : int, %height.13 : int, %width.13 : int = prim::ListUnpack(%1227)
  %channels_per_group.13 : int = aten::floordiv(%num_channels.13, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %1233 : int[] = prim::ListConstruct(%batchsize.13, %16, %channels_per_group.13, %height.13, %width.13)
  %x.35 : Tensor = aten::view(%out.36, %1233) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %1235 : Tensor = aten::transpose(%x.35, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.36 : Tensor = aten::contiguous(%1235, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %1237 : int[] = prim::ListConstruct(%batchsize.13, %5, %height.13, %width.13)
  %input.238 : Tensor = aten::view(%x.36, %1237) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %1239 : int = prim::GetAttr[name="stride"](%961)
  %1240 : bool = aten::eq(%1239, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.39 : Tensor = prim::If(%1240) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %1242 : Tensor[] = aten::chunk(%input.238, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.14 : Tensor, %x2.14 : Tensor = prim::ListUnpack(%1242)
      %1245 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%961)
      %1246 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%1245)
      %1247 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1245)
      %1248 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%1245)
      %1249 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%1245)
      %1250 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%1245)
      %1251 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%1245)
      %1252 : Tensor = prim::GetAttr[name="weight"](%1246)
      %1253 : Tensor? = prim::GetAttr[name="bias"](%1246)
      %1254 : int[] = prim::ListConstruct(%8, %8)
      %1255 : int[] = prim::ListConstruct(%10, %10)
      %1256 : int[] = prim::ListConstruct(%8, %8)
      %input.243 : Tensor = aten::conv2d(%x2.14, %1252, %1253, %1254, %1255, %1256, %8) # torch/nn/modules/conv.py:415:15
      %1258 : int = aten::dim(%input.243) # torch/nn/modules/batchnorm.py:276:11
      %1259 : bool = aten::ne(%1258, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1259) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1260 : bool = prim::GetAttr[name="training"](%1247)
       = prim::If(%1260) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1261 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1247)
          %1262 : Tensor = aten::add(%1261, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1247, %1262)
          -> ()
        block1():
          -> ()
      %1263 : bool = prim::GetAttr[name="training"](%1247)
      %1264 : Tensor = prim::GetAttr[name="running_mean"](%1247)
      %1265 : Tensor = prim::GetAttr[name="running_var"](%1247)
      %1266 : Tensor = prim::GetAttr[name="weight"](%1247)
      %1267 : Tensor = prim::GetAttr[name="bias"](%1247)
       = prim::If(%1263) # torch/nn/functional.py:2011:4
        block0():
          %1268 : int[] = aten::size(%input.243) # torch/nn/functional.py:2012:27
          %size_prods.340 : int = aten::__getitem__(%1268, %10) # torch/nn/functional.py:1991:17
          %1270 : int = aten::len(%1268) # torch/nn/functional.py:1992:19
          %1271 : int = aten::sub(%1270, %16) # torch/nn/functional.py:1992:19
          %size_prods.341 : int = prim::Loop(%1271, %9, %size_prods.340) # torch/nn/functional.py:1992:4
            block0(%i.86 : int, %size_prods.342 : int):
              %1275 : int = aten::add(%i.86, %16) # torch/nn/functional.py:1993:27
              %1276 : int = aten::__getitem__(%1268, %1275) # torch/nn/functional.py:1993:22
              %size_prods.343 : int = aten::mul(%size_prods.342, %1276) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.343)
          %1278 : bool = aten::eq(%size_prods.341, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1278) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.244 : Tensor = aten::batch_norm(%input.243, %1266, %1267, %1264, %1265, %1263, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.245 : Tensor = aten::relu_(%input.244) # torch/nn/functional.py:1117:17
      %1281 : Tensor = prim::GetAttr[name="weight"](%1248)
      %1282 : Tensor? = prim::GetAttr[name="bias"](%1248)
      %1283 : int[] = prim::ListConstruct(%8, %8)
      %1284 : int[] = prim::ListConstruct(%8, %8)
      %1285 : int[] = prim::ListConstruct(%8, %8)
      %input.246 : Tensor = aten::conv2d(%input.245, %1281, %1282, %1283, %1284, %1285, %4) # torch/nn/modules/conv.py:415:15
      %1287 : int = aten::dim(%input.246) # torch/nn/modules/batchnorm.py:276:11
      %1288 : bool = aten::ne(%1287, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1288) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1289 : bool = prim::GetAttr[name="training"](%1249)
       = prim::If(%1289) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1290 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1249)
          %1291 : Tensor = aten::add(%1290, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1249, %1291)
          -> ()
        block1():
          -> ()
      %1292 : bool = prim::GetAttr[name="training"](%1249)
      %1293 : Tensor = prim::GetAttr[name="running_mean"](%1249)
      %1294 : Tensor = prim::GetAttr[name="running_var"](%1249)
      %1295 : Tensor = prim::GetAttr[name="weight"](%1249)
      %1296 : Tensor = prim::GetAttr[name="bias"](%1249)
       = prim::If(%1292) # torch/nn/functional.py:2011:4
        block0():
          %1297 : int[] = aten::size(%input.246) # torch/nn/functional.py:2012:27
          %size_prods.344 : int = aten::__getitem__(%1297, %10) # torch/nn/functional.py:1991:17
          %1299 : int = aten::len(%1297) # torch/nn/functional.py:1992:19
          %1300 : int = aten::sub(%1299, %16) # torch/nn/functional.py:1992:19
          %size_prods.345 : int = prim::Loop(%1300, %9, %size_prods.344) # torch/nn/functional.py:1992:4
            block0(%i.87 : int, %size_prods.346 : int):
              %1304 : int = aten::add(%i.87, %16) # torch/nn/functional.py:1993:27
              %1305 : int = aten::__getitem__(%1297, %1304) # torch/nn/functional.py:1993:22
              %size_prods.347 : int = aten::mul(%size_prods.346, %1305) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.347)
          %1307 : bool = aten::eq(%size_prods.345, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1307) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.247 : Tensor = aten::batch_norm(%input.246, %1295, %1296, %1293, %1294, %1292, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1309 : Tensor = prim::GetAttr[name="weight"](%1250)
      %1310 : Tensor? = prim::GetAttr[name="bias"](%1250)
      %1311 : int[] = prim::ListConstruct(%8, %8)
      %1312 : int[] = prim::ListConstruct(%10, %10)
      %1313 : int[] = prim::ListConstruct(%8, %8)
      %input.248 : Tensor = aten::conv2d(%input.247, %1309, %1310, %1311, %1312, %1313, %8) # torch/nn/modules/conv.py:415:15
      %1315 : int = aten::dim(%input.248) # torch/nn/modules/batchnorm.py:276:11
      %1316 : bool = aten::ne(%1315, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1316) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1317 : bool = prim::GetAttr[name="training"](%1251)
       = prim::If(%1317) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1318 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1251)
          %1319 : Tensor = aten::add(%1318, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1251, %1319)
          -> ()
        block1():
          -> ()
      %1320 : bool = prim::GetAttr[name="training"](%1251)
      %1321 : Tensor = prim::GetAttr[name="running_mean"](%1251)
      %1322 : Tensor = prim::GetAttr[name="running_var"](%1251)
      %1323 : Tensor = prim::GetAttr[name="weight"](%1251)
      %1324 : Tensor = prim::GetAttr[name="bias"](%1251)
       = prim::If(%1320) # torch/nn/functional.py:2011:4
        block0():
          %1325 : int[] = aten::size(%input.248) # torch/nn/functional.py:2012:27
          %size_prods.348 : int = aten::__getitem__(%1325, %10) # torch/nn/functional.py:1991:17
          %1327 : int = aten::len(%1325) # torch/nn/functional.py:1992:19
          %1328 : int = aten::sub(%1327, %16) # torch/nn/functional.py:1992:19
          %size_prods.349 : int = prim::Loop(%1328, %9, %size_prods.348) # torch/nn/functional.py:1992:4
            block0(%i.88 : int, %size_prods.350 : int):
              %1332 : int = aten::add(%i.88, %16) # torch/nn/functional.py:1993:27
              %1333 : int = aten::__getitem__(%1325, %1332) # torch/nn/functional.py:1993:22
              %size_prods.351 : int = aten::mul(%size_prods.350, %1333) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.351)
          %1335 : bool = aten::eq(%size_prods.349, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1335) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.249 : Tensor = aten::batch_norm(%input.248, %1323, %1324, %1321, %1322, %1320, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.250 : Tensor = aten::relu_(%input.249) # torch/nn/functional.py:1117:17
      %1338 : Tensor[] = prim::ListConstruct(%x1.14, %input.250)
      %out.40 : Tensor = aten::cat(%1338, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.40)
    block1():
      %1340 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%961)
      %1341 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%1340)
      %1342 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1340)
      %1343 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%1340)
      %1344 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%1340)
      %1345 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%1340)
      %1346 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%1340)
      %1347 : Tensor = prim::GetAttr[name="weight"](%1341)
      %1348 : Tensor? = prim::GetAttr[name="bias"](%1341)
      %1349 : int[] = prim::ListConstruct(%8, %8)
      %1350 : int[] = prim::ListConstruct(%10, %10)
      %1351 : int[] = prim::ListConstruct(%8, %8)
      %input.251 : Tensor = aten::conv2d(%input.238, %1347, %1348, %1349, %1350, %1351, %8) # torch/nn/modules/conv.py:415:15
      %1353 : int = aten::dim(%input.251) # torch/nn/modules/batchnorm.py:276:11
      %1354 : bool = aten::ne(%1353, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1354) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1355 : bool = prim::GetAttr[name="training"](%1342)
       = prim::If(%1355) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1356 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1342)
          %1357 : Tensor = aten::add(%1356, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1342, %1357)
          -> ()
        block1():
          -> ()
      %1358 : bool = prim::GetAttr[name="training"](%1342)
      %1359 : Tensor = prim::GetAttr[name="running_mean"](%1342)
      %1360 : Tensor = prim::GetAttr[name="running_var"](%1342)
      %1361 : Tensor = prim::GetAttr[name="weight"](%1342)
      %1362 : Tensor = prim::GetAttr[name="bias"](%1342)
       = prim::If(%1358) # torch/nn/functional.py:2011:4
        block0():
          %1363 : int[] = aten::size(%input.251) # torch/nn/functional.py:2012:27
          %size_prods.352 : int = aten::__getitem__(%1363, %10) # torch/nn/functional.py:1991:17
          %1365 : int = aten::len(%1363) # torch/nn/functional.py:1992:19
          %1366 : int = aten::sub(%1365, %16) # torch/nn/functional.py:1992:19
          %size_prods.353 : int = prim::Loop(%1366, %9, %size_prods.352) # torch/nn/functional.py:1992:4
            block0(%i.89 : int, %size_prods.354 : int):
              %1370 : int = aten::add(%i.89, %16) # torch/nn/functional.py:1993:27
              %1371 : int = aten::__getitem__(%1363, %1370) # torch/nn/functional.py:1993:22
              %size_prods.355 : int = aten::mul(%size_prods.354, %1371) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.355)
          %1373 : bool = aten::eq(%size_prods.353, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1373) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.252 : Tensor = aten::batch_norm(%input.251, %1361, %1362, %1359, %1360, %1358, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.253 : Tensor = aten::relu_(%input.252) # torch/nn/functional.py:1117:17
      %1376 : Tensor = prim::GetAttr[name="weight"](%1343)
      %1377 : Tensor? = prim::GetAttr[name="bias"](%1343)
      %1378 : int[] = prim::ListConstruct(%8, %8)
      %1379 : int[] = prim::ListConstruct(%8, %8)
      %1380 : int[] = prim::ListConstruct(%8, %8)
      %input.254 : Tensor = aten::conv2d(%input.253, %1376, %1377, %1378, %1379, %1380, %4) # torch/nn/modules/conv.py:415:15
      %1382 : int = aten::dim(%input.254) # torch/nn/modules/batchnorm.py:276:11
      %1383 : bool = aten::ne(%1382, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1383) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1384 : bool = prim::GetAttr[name="training"](%1344)
       = prim::If(%1384) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1385 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1344)
          %1386 : Tensor = aten::add(%1385, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1344, %1386)
          -> ()
        block1():
          -> ()
      %1387 : bool = prim::GetAttr[name="training"](%1344)
      %1388 : Tensor = prim::GetAttr[name="running_mean"](%1344)
      %1389 : Tensor = prim::GetAttr[name="running_var"](%1344)
      %1390 : Tensor = prim::GetAttr[name="weight"](%1344)
      %1391 : Tensor = prim::GetAttr[name="bias"](%1344)
       = prim::If(%1387) # torch/nn/functional.py:2011:4
        block0():
          %1392 : int[] = aten::size(%input.254) # torch/nn/functional.py:2012:27
          %size_prods.356 : int = aten::__getitem__(%1392, %10) # torch/nn/functional.py:1991:17
          %1394 : int = aten::len(%1392) # torch/nn/functional.py:1992:19
          %1395 : int = aten::sub(%1394, %16) # torch/nn/functional.py:1992:19
          %size_prods.357 : int = prim::Loop(%1395, %9, %size_prods.356) # torch/nn/functional.py:1992:4
            block0(%i.90 : int, %size_prods.358 : int):
              %1399 : int = aten::add(%i.90, %16) # torch/nn/functional.py:1993:27
              %1400 : int = aten::__getitem__(%1392, %1399) # torch/nn/functional.py:1993:22
              %size_prods.359 : int = aten::mul(%size_prods.358, %1400) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.359)
          %1402 : bool = aten::eq(%size_prods.357, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1402) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.256 : Tensor = aten::batch_norm(%input.254, %1390, %1391, %1388, %1389, %1387, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1404 : Tensor = prim::GetAttr[name="weight"](%1345)
      %1405 : Tensor? = prim::GetAttr[name="bias"](%1345)
      %1406 : int[] = prim::ListConstruct(%8, %8)
      %1407 : int[] = prim::ListConstruct(%10, %10)
      %1408 : int[] = prim::ListConstruct(%8, %8)
      %input.257 : Tensor = aten::conv2d(%input.256, %1404, %1405, %1406, %1407, %1408, %8) # torch/nn/modules/conv.py:415:15
      %1410 : int = aten::dim(%input.257) # torch/nn/modules/batchnorm.py:276:11
      %1411 : bool = aten::ne(%1410, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1411) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1412 : bool = prim::GetAttr[name="training"](%1346)
       = prim::If(%1412) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1413 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1346)
          %1414 : Tensor = aten::add(%1413, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1346, %1414)
          -> ()
        block1():
          -> ()
      %1415 : bool = prim::GetAttr[name="training"](%1346)
      %1416 : Tensor = prim::GetAttr[name="running_mean"](%1346)
      %1417 : Tensor = prim::GetAttr[name="running_var"](%1346)
      %1418 : Tensor = prim::GetAttr[name="weight"](%1346)
      %1419 : Tensor = prim::GetAttr[name="bias"](%1346)
       = prim::If(%1415) # torch/nn/functional.py:2011:4
        block0():
          %1420 : int[] = aten::size(%input.257) # torch/nn/functional.py:2012:27
          %size_prods.360 : int = aten::__getitem__(%1420, %10) # torch/nn/functional.py:1991:17
          %1422 : int = aten::len(%1420) # torch/nn/functional.py:1992:19
          %1423 : int = aten::sub(%1422, %16) # torch/nn/functional.py:1992:19
          %size_prods.361 : int = prim::Loop(%1423, %9, %size_prods.360) # torch/nn/functional.py:1992:4
            block0(%i.91 : int, %size_prods.362 : int):
              %1427 : int = aten::add(%i.91, %16) # torch/nn/functional.py:1993:27
              %1428 : int = aten::__getitem__(%1420, %1427) # torch/nn/functional.py:1993:22
              %size_prods.363 : int = aten::mul(%size_prods.362, %1428) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.363)
          %1430 : bool = aten::eq(%size_prods.361, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1430) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.258 : Tensor = aten::batch_norm(%input.257, %1418, %1419, %1416, %1417, %1415, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.259 : Tensor = aten::relu_(%input.258) # torch/nn/functional.py:1117:17
      %1433 : Tensor[] = prim::ListConstruct(%input.238, %input.259)
      %out.41 : Tensor = aten::cat(%1433, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.41)
  %1435 : Tensor = prim::data(%out.39)
  %1436 : int[] = aten::size(%1435) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.14 : int, %num_channels.14 : int, %height.14 : int, %width.14 : int = prim::ListUnpack(%1436)
  %channels_per_group.14 : int = aten::floordiv(%num_channels.14, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %1442 : int[] = prim::ListConstruct(%batchsize.14, %16, %channels_per_group.14, %height.14, %width.14)
  %x.37 : Tensor = aten::view(%out.39, %1442) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %1444 : Tensor = aten::transpose(%x.37, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.38 : Tensor = aten::contiguous(%1444, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %1446 : int[] = prim::ListConstruct(%batchsize.14, %5, %height.14, %width.14)
  %input.255 : Tensor = aten::view(%x.38, %1446) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %1448 : int = prim::GetAttr[name="stride"](%962)
  %1449 : bool = aten::eq(%1448, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.42 : Tensor = prim::If(%1449) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %1451 : Tensor[] = aten::chunk(%input.255, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.15 : Tensor, %x2.15 : Tensor = prim::ListUnpack(%1451)
      %1454 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%962)
      %1455 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%1454)
      %1456 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1454)
      %1457 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%1454)
      %1458 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%1454)
      %1459 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%1454)
      %1460 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%1454)
      %1461 : Tensor = prim::GetAttr[name="weight"](%1455)
      %1462 : Tensor? = prim::GetAttr[name="bias"](%1455)
      %1463 : int[] = prim::ListConstruct(%8, %8)
      %1464 : int[] = prim::ListConstruct(%10, %10)
      %1465 : int[] = prim::ListConstruct(%8, %8)
      %input.260 : Tensor = aten::conv2d(%x2.15, %1461, %1462, %1463, %1464, %1465, %8) # torch/nn/modules/conv.py:415:15
      %1467 : int = aten::dim(%input.260) # torch/nn/modules/batchnorm.py:276:11
      %1468 : bool = aten::ne(%1467, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1468) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1469 : bool = prim::GetAttr[name="training"](%1456)
       = prim::If(%1469) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1470 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1456)
          %1471 : Tensor = aten::add(%1470, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1456, %1471)
          -> ()
        block1():
          -> ()
      %1472 : bool = prim::GetAttr[name="training"](%1456)
      %1473 : Tensor = prim::GetAttr[name="running_mean"](%1456)
      %1474 : Tensor = prim::GetAttr[name="running_var"](%1456)
      %1475 : Tensor = prim::GetAttr[name="weight"](%1456)
      %1476 : Tensor = prim::GetAttr[name="bias"](%1456)
       = prim::If(%1472) # torch/nn/functional.py:2011:4
        block0():
          %1477 : int[] = aten::size(%input.260) # torch/nn/functional.py:2012:27
          %size_prods.364 : int = aten::__getitem__(%1477, %10) # torch/nn/functional.py:1991:17
          %1479 : int = aten::len(%1477) # torch/nn/functional.py:1992:19
          %1480 : int = aten::sub(%1479, %16) # torch/nn/functional.py:1992:19
          %size_prods.365 : int = prim::Loop(%1480, %9, %size_prods.364) # torch/nn/functional.py:1992:4
            block0(%i.92 : int, %size_prods.366 : int):
              %1484 : int = aten::add(%i.92, %16) # torch/nn/functional.py:1993:27
              %1485 : int = aten::__getitem__(%1477, %1484) # torch/nn/functional.py:1993:22
              %size_prods.367 : int = aten::mul(%size_prods.366, %1485) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.367)
          %1487 : bool = aten::eq(%size_prods.365, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1487) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.261 : Tensor = aten::batch_norm(%input.260, %1475, %1476, %1473, %1474, %1472, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.262 : Tensor = aten::relu_(%input.261) # torch/nn/functional.py:1117:17
      %1490 : Tensor = prim::GetAttr[name="weight"](%1457)
      %1491 : Tensor? = prim::GetAttr[name="bias"](%1457)
      %1492 : int[] = prim::ListConstruct(%8, %8)
      %1493 : int[] = prim::ListConstruct(%8, %8)
      %1494 : int[] = prim::ListConstruct(%8, %8)
      %input.263 : Tensor = aten::conv2d(%input.262, %1490, %1491, %1492, %1493, %1494, %4) # torch/nn/modules/conv.py:415:15
      %1496 : int = aten::dim(%input.263) # torch/nn/modules/batchnorm.py:276:11
      %1497 : bool = aten::ne(%1496, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1497) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1498 : bool = prim::GetAttr[name="training"](%1458)
       = prim::If(%1498) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1499 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1458)
          %1500 : Tensor = aten::add(%1499, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1458, %1500)
          -> ()
        block1():
          -> ()
      %1501 : bool = prim::GetAttr[name="training"](%1458)
      %1502 : Tensor = prim::GetAttr[name="running_mean"](%1458)
      %1503 : Tensor = prim::GetAttr[name="running_var"](%1458)
      %1504 : Tensor = prim::GetAttr[name="weight"](%1458)
      %1505 : Tensor = prim::GetAttr[name="bias"](%1458)
       = prim::If(%1501) # torch/nn/functional.py:2011:4
        block0():
          %1506 : int[] = aten::size(%input.263) # torch/nn/functional.py:2012:27
          %size_prods.368 : int = aten::__getitem__(%1506, %10) # torch/nn/functional.py:1991:17
          %1508 : int = aten::len(%1506) # torch/nn/functional.py:1992:19
          %1509 : int = aten::sub(%1508, %16) # torch/nn/functional.py:1992:19
          %size_prods.369 : int = prim::Loop(%1509, %9, %size_prods.368) # torch/nn/functional.py:1992:4
            block0(%i.93 : int, %size_prods.370 : int):
              %1513 : int = aten::add(%i.93, %16) # torch/nn/functional.py:1993:27
              %1514 : int = aten::__getitem__(%1506, %1513) # torch/nn/functional.py:1993:22
              %size_prods.371 : int = aten::mul(%size_prods.370, %1514) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.371)
          %1516 : bool = aten::eq(%size_prods.369, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1516) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.264 : Tensor = aten::batch_norm(%input.263, %1504, %1505, %1502, %1503, %1501, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1518 : Tensor = prim::GetAttr[name="weight"](%1459)
      %1519 : Tensor? = prim::GetAttr[name="bias"](%1459)
      %1520 : int[] = prim::ListConstruct(%8, %8)
      %1521 : int[] = prim::ListConstruct(%10, %10)
      %1522 : int[] = prim::ListConstruct(%8, %8)
      %input.265 : Tensor = aten::conv2d(%input.264, %1518, %1519, %1520, %1521, %1522, %8) # torch/nn/modules/conv.py:415:15
      %1524 : int = aten::dim(%input.265) # torch/nn/modules/batchnorm.py:276:11
      %1525 : bool = aten::ne(%1524, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1525) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1526 : bool = prim::GetAttr[name="training"](%1460)
       = prim::If(%1526) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1527 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1460)
          %1528 : Tensor = aten::add(%1527, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1460, %1528)
          -> ()
        block1():
          -> ()
      %1529 : bool = prim::GetAttr[name="training"](%1460)
      %1530 : Tensor = prim::GetAttr[name="running_mean"](%1460)
      %1531 : Tensor = prim::GetAttr[name="running_var"](%1460)
      %1532 : Tensor = prim::GetAttr[name="weight"](%1460)
      %1533 : Tensor = prim::GetAttr[name="bias"](%1460)
       = prim::If(%1529) # torch/nn/functional.py:2011:4
        block0():
          %1534 : int[] = aten::size(%input.265) # torch/nn/functional.py:2012:27
          %size_prods.372 : int = aten::__getitem__(%1534, %10) # torch/nn/functional.py:1991:17
          %1536 : int = aten::len(%1534) # torch/nn/functional.py:1992:19
          %1537 : int = aten::sub(%1536, %16) # torch/nn/functional.py:1992:19
          %size_prods.373 : int = prim::Loop(%1537, %9, %size_prods.372) # torch/nn/functional.py:1992:4
            block0(%i.94 : int, %size_prods.374 : int):
              %1541 : int = aten::add(%i.94, %16) # torch/nn/functional.py:1993:27
              %1542 : int = aten::__getitem__(%1534, %1541) # torch/nn/functional.py:1993:22
              %size_prods.375 : int = aten::mul(%size_prods.374, %1542) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.375)
          %1544 : bool = aten::eq(%size_prods.373, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1544) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.266 : Tensor = aten::batch_norm(%input.265, %1532, %1533, %1530, %1531, %1529, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.267 : Tensor = aten::relu_(%input.266) # torch/nn/functional.py:1117:17
      %1547 : Tensor[] = prim::ListConstruct(%x1.15, %input.267)
      %out.43 : Tensor = aten::cat(%1547, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.43)
    block1():
      %1549 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%962)
      %1550 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%1549)
      %1551 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1549)
      %1552 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%1549)
      %1553 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%1549)
      %1554 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%1549)
      %1555 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%1549)
      %1556 : Tensor = prim::GetAttr[name="weight"](%1550)
      %1557 : Tensor? = prim::GetAttr[name="bias"](%1550)
      %1558 : int[] = prim::ListConstruct(%8, %8)
      %1559 : int[] = prim::ListConstruct(%10, %10)
      %1560 : int[] = prim::ListConstruct(%8, %8)
      %input.268 : Tensor = aten::conv2d(%input.255, %1556, %1557, %1558, %1559, %1560, %8) # torch/nn/modules/conv.py:415:15
      %1562 : int = aten::dim(%input.268) # torch/nn/modules/batchnorm.py:276:11
      %1563 : bool = aten::ne(%1562, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1563) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1564 : bool = prim::GetAttr[name="training"](%1551)
       = prim::If(%1564) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1565 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1551)
          %1566 : Tensor = aten::add(%1565, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1551, %1566)
          -> ()
        block1():
          -> ()
      %1567 : bool = prim::GetAttr[name="training"](%1551)
      %1568 : Tensor = prim::GetAttr[name="running_mean"](%1551)
      %1569 : Tensor = prim::GetAttr[name="running_var"](%1551)
      %1570 : Tensor = prim::GetAttr[name="weight"](%1551)
      %1571 : Tensor = prim::GetAttr[name="bias"](%1551)
       = prim::If(%1567) # torch/nn/functional.py:2011:4
        block0():
          %1572 : int[] = aten::size(%input.268) # torch/nn/functional.py:2012:27
          %size_prods.376 : int = aten::__getitem__(%1572, %10) # torch/nn/functional.py:1991:17
          %1574 : int = aten::len(%1572) # torch/nn/functional.py:1992:19
          %1575 : int = aten::sub(%1574, %16) # torch/nn/functional.py:1992:19
          %size_prods.377 : int = prim::Loop(%1575, %9, %size_prods.376) # torch/nn/functional.py:1992:4
            block0(%i.95 : int, %size_prods.378 : int):
              %1579 : int = aten::add(%i.95, %16) # torch/nn/functional.py:1993:27
              %1580 : int = aten::__getitem__(%1572, %1579) # torch/nn/functional.py:1993:22
              %size_prods.379 : int = aten::mul(%size_prods.378, %1580) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.379)
          %1582 : bool = aten::eq(%size_prods.377, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1582) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.269 : Tensor = aten::batch_norm(%input.268, %1570, %1571, %1568, %1569, %1567, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.270 : Tensor = aten::relu_(%input.269) # torch/nn/functional.py:1117:17
      %1585 : Tensor = prim::GetAttr[name="weight"](%1552)
      %1586 : Tensor? = prim::GetAttr[name="bias"](%1552)
      %1587 : int[] = prim::ListConstruct(%8, %8)
      %1588 : int[] = prim::ListConstruct(%8, %8)
      %1589 : int[] = prim::ListConstruct(%8, %8)
      %input.271 : Tensor = aten::conv2d(%input.270, %1585, %1586, %1587, %1588, %1589, %4) # torch/nn/modules/conv.py:415:15
      %1591 : int = aten::dim(%input.271) # torch/nn/modules/batchnorm.py:276:11
      %1592 : bool = aten::ne(%1591, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1592) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1593 : bool = prim::GetAttr[name="training"](%1553)
       = prim::If(%1593) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1594 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1553)
          %1595 : Tensor = aten::add(%1594, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1553, %1595)
          -> ()
        block1():
          -> ()
      %1596 : bool = prim::GetAttr[name="training"](%1553)
      %1597 : Tensor = prim::GetAttr[name="running_mean"](%1553)
      %1598 : Tensor = prim::GetAttr[name="running_var"](%1553)
      %1599 : Tensor = prim::GetAttr[name="weight"](%1553)
      %1600 : Tensor = prim::GetAttr[name="bias"](%1553)
       = prim::If(%1596) # torch/nn/functional.py:2011:4
        block0():
          %1601 : int[] = aten::size(%input.271) # torch/nn/functional.py:2012:27
          %size_prods.380 : int = aten::__getitem__(%1601, %10) # torch/nn/functional.py:1991:17
          %1603 : int = aten::len(%1601) # torch/nn/functional.py:1992:19
          %1604 : int = aten::sub(%1603, %16) # torch/nn/functional.py:1992:19
          %size_prods.381 : int = prim::Loop(%1604, %9, %size_prods.380) # torch/nn/functional.py:1992:4
            block0(%i.96 : int, %size_prods.382 : int):
              %1608 : int = aten::add(%i.96, %16) # torch/nn/functional.py:1993:27
              %1609 : int = aten::__getitem__(%1601, %1608) # torch/nn/functional.py:1993:22
              %size_prods.383 : int = aten::mul(%size_prods.382, %1609) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.383)
          %1611 : bool = aten::eq(%size_prods.381, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1611) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.76 : Tensor = aten::batch_norm(%input.271, %1599, %1600, %1597, %1598, %1596, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1613 : Tensor = prim::GetAttr[name="weight"](%1554)
      %1614 : Tensor? = prim::GetAttr[name="bias"](%1554)
      %1615 : int[] = prim::ListConstruct(%8, %8)
      %1616 : int[] = prim::ListConstruct(%10, %10)
      %1617 : int[] = prim::ListConstruct(%8, %8)
      %input.77 : Tensor = aten::conv2d(%input.76, %1613, %1614, %1615, %1616, %1617, %8) # torch/nn/modules/conv.py:415:15
      %1619 : int = aten::dim(%input.77) # torch/nn/modules/batchnorm.py:276:11
      %1620 : bool = aten::ne(%1619, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1620) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1621 : bool = prim::GetAttr[name="training"](%1555)
       = prim::If(%1621) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1622 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1555)
          %1623 : Tensor = aten::add(%1622, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1555, %1623)
          -> ()
        block1():
          -> ()
      %1624 : bool = prim::GetAttr[name="training"](%1555)
      %1625 : Tensor = prim::GetAttr[name="running_mean"](%1555)
      %1626 : Tensor = prim::GetAttr[name="running_var"](%1555)
      %1627 : Tensor = prim::GetAttr[name="weight"](%1555)
      %1628 : Tensor = prim::GetAttr[name="bias"](%1555)
       = prim::If(%1624) # torch/nn/functional.py:2011:4
        block0():
          %1629 : int[] = aten::size(%input.77) # torch/nn/functional.py:2012:27
          %size_prods.384 : int = aten::__getitem__(%1629, %10) # torch/nn/functional.py:1991:17
          %1631 : int = aten::len(%1629) # torch/nn/functional.py:1992:19
          %1632 : int = aten::sub(%1631, %16) # torch/nn/functional.py:1992:19
          %size_prods.385 : int = prim::Loop(%1632, %9, %size_prods.384) # torch/nn/functional.py:1992:4
            block0(%i.97 : int, %size_prods.386 : int):
              %1636 : int = aten::add(%i.97, %16) # torch/nn/functional.py:1993:27
              %1637 : int = aten::__getitem__(%1629, %1636) # torch/nn/functional.py:1993:22
              %size_prods.387 : int = aten::mul(%size_prods.386, %1637) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.387)
          %1639 : bool = aten::eq(%size_prods.385, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1639) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.78 : Tensor = aten::batch_norm(%input.77, %1627, %1628, %1625, %1626, %1624, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.79 : Tensor = aten::relu_(%input.78) # torch/nn/functional.py:1117:17
      %1642 : Tensor[] = prim::ListConstruct(%input.255, %input.79)
      %out.44 : Tensor = aten::cat(%1642, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.44)
  %1644 : Tensor = prim::data(%out.42)
  %1645 : int[] = aten::size(%1644) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.15 : int, %num_channels.15 : int, %height.15 : int, %width.15 : int = prim::ListUnpack(%1645)
  %channels_per_group.15 : int = aten::floordiv(%num_channels.15, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %1651 : int[] = prim::ListConstruct(%batchsize.15, %16, %channels_per_group.15, %height.15, %width.15)
  %x.39 : Tensor = aten::view(%out.42, %1651) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %1653 : Tensor = aten::transpose(%x.39, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.40 : Tensor = aten::contiguous(%1653, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %1655 : int[] = prim::ListConstruct(%batchsize.15, %5, %height.15, %width.15)
  %input.272 : Tensor = aten::view(%x.40, %1655) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %1657 : int = prim::GetAttr[name="stride"](%963)
  %1658 : bool = aten::eq(%1657, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.15 : Tensor = prim::If(%1658) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %1660 : Tensor[] = aten::chunk(%input.272, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.5 : Tensor, %x2.5 : Tensor = prim::ListUnpack(%1660)
      %1663 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%963)
      %1664 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%1663)
      %1665 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1663)
      %1666 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%1663)
      %1667 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%1663)
      %1668 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%1663)
      %1669 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%1663)
      %1670 : Tensor = prim::GetAttr[name="weight"](%1664)
      %1671 : Tensor? = prim::GetAttr[name="bias"](%1664)
      %1672 : int[] = prim::ListConstruct(%8, %8)
      %1673 : int[] = prim::ListConstruct(%10, %10)
      %1674 : int[] = prim::ListConstruct(%8, %8)
      %input.80 : Tensor = aten::conv2d(%x2.5, %1670, %1671, %1672, %1673, %1674, %8) # torch/nn/modules/conv.py:415:15
      %1676 : int = aten::dim(%input.80) # torch/nn/modules/batchnorm.py:276:11
      %1677 : bool = aten::ne(%1676, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1677) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1678 : bool = prim::GetAttr[name="training"](%1665)
       = prim::If(%1678) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1679 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1665)
          %1680 : Tensor = aten::add(%1679, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1665, %1680)
          -> ()
        block1():
          -> ()
      %1681 : bool = prim::GetAttr[name="training"](%1665)
      %1682 : Tensor = prim::GetAttr[name="running_mean"](%1665)
      %1683 : Tensor = prim::GetAttr[name="running_var"](%1665)
      %1684 : Tensor = prim::GetAttr[name="weight"](%1665)
      %1685 : Tensor = prim::GetAttr[name="bias"](%1665)
       = prim::If(%1681) # torch/nn/functional.py:2011:4
        block0():
          %1686 : int[] = aten::size(%input.80) # torch/nn/functional.py:2012:27
          %size_prods.104 : int = aten::__getitem__(%1686, %10) # torch/nn/functional.py:1991:17
          %1688 : int = aten::len(%1686) # torch/nn/functional.py:1992:19
          %1689 : int = aten::sub(%1688, %16) # torch/nn/functional.py:1992:19
          %size_prods.105 : int = prim::Loop(%1689, %9, %size_prods.104) # torch/nn/functional.py:1992:4
            block0(%i.27 : int, %size_prods.106 : int):
              %1693 : int = aten::add(%i.27, %16) # torch/nn/functional.py:1993:27
              %1694 : int = aten::__getitem__(%1686, %1693) # torch/nn/functional.py:1993:22
              %size_prods.107 : int = aten::mul(%size_prods.106, %1694) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.107)
          %1696 : bool = aten::eq(%size_prods.105, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1696) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.81 : Tensor = aten::batch_norm(%input.80, %1684, %1685, %1682, %1683, %1681, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.82 : Tensor = aten::relu_(%input.81) # torch/nn/functional.py:1117:17
      %1699 : Tensor = prim::GetAttr[name="weight"](%1666)
      %1700 : Tensor? = prim::GetAttr[name="bias"](%1666)
      %1701 : int[] = prim::ListConstruct(%8, %8)
      %1702 : int[] = prim::ListConstruct(%8, %8)
      %1703 : int[] = prim::ListConstruct(%8, %8)
      %input.83 : Tensor = aten::conv2d(%input.82, %1699, %1700, %1701, %1702, %1703, %4) # torch/nn/modules/conv.py:415:15
      %1705 : int = aten::dim(%input.83) # torch/nn/modules/batchnorm.py:276:11
      %1706 : bool = aten::ne(%1705, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1706) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1707 : bool = prim::GetAttr[name="training"](%1667)
       = prim::If(%1707) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1708 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1667)
          %1709 : Tensor = aten::add(%1708, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1667, %1709)
          -> ()
        block1():
          -> ()
      %1710 : bool = prim::GetAttr[name="training"](%1667)
      %1711 : Tensor = prim::GetAttr[name="running_mean"](%1667)
      %1712 : Tensor = prim::GetAttr[name="running_var"](%1667)
      %1713 : Tensor = prim::GetAttr[name="weight"](%1667)
      %1714 : Tensor = prim::GetAttr[name="bias"](%1667)
       = prim::If(%1710) # torch/nn/functional.py:2011:4
        block0():
          %1715 : int[] = aten::size(%input.83) # torch/nn/functional.py:2012:27
          %size_prods.108 : int = aten::__getitem__(%1715, %10) # torch/nn/functional.py:1991:17
          %1717 : int = aten::len(%1715) # torch/nn/functional.py:1992:19
          %1718 : int = aten::sub(%1717, %16) # torch/nn/functional.py:1992:19
          %size_prods.109 : int = prim::Loop(%1718, %9, %size_prods.108) # torch/nn/functional.py:1992:4
            block0(%i.28 : int, %size_prods.110 : int):
              %1722 : int = aten::add(%i.28, %16) # torch/nn/functional.py:1993:27
              %1723 : int = aten::__getitem__(%1715, %1722) # torch/nn/functional.py:1993:22
              %size_prods.111 : int = aten::mul(%size_prods.110, %1723) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.111)
          %1725 : bool = aten::eq(%size_prods.109, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1725) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.84 : Tensor = aten::batch_norm(%input.83, %1713, %1714, %1711, %1712, %1710, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1727 : Tensor = prim::GetAttr[name="weight"](%1668)
      %1728 : Tensor? = prim::GetAttr[name="bias"](%1668)
      %1729 : int[] = prim::ListConstruct(%8, %8)
      %1730 : int[] = prim::ListConstruct(%10, %10)
      %1731 : int[] = prim::ListConstruct(%8, %8)
      %input.85 : Tensor = aten::conv2d(%input.84, %1727, %1728, %1729, %1730, %1731, %8) # torch/nn/modules/conv.py:415:15
      %1733 : int = aten::dim(%input.85) # torch/nn/modules/batchnorm.py:276:11
      %1734 : bool = aten::ne(%1733, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1734) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1735 : bool = prim::GetAttr[name="training"](%1669)
       = prim::If(%1735) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1736 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1669)
          %1737 : Tensor = aten::add(%1736, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1669, %1737)
          -> ()
        block1():
          -> ()
      %1738 : bool = prim::GetAttr[name="training"](%1669)
      %1739 : Tensor = prim::GetAttr[name="running_mean"](%1669)
      %1740 : Tensor = prim::GetAttr[name="running_var"](%1669)
      %1741 : Tensor = prim::GetAttr[name="weight"](%1669)
      %1742 : Tensor = prim::GetAttr[name="bias"](%1669)
       = prim::If(%1738) # torch/nn/functional.py:2011:4
        block0():
          %1743 : int[] = aten::size(%input.85) # torch/nn/functional.py:2012:27
          %size_prods.112 : int = aten::__getitem__(%1743, %10) # torch/nn/functional.py:1991:17
          %1745 : int = aten::len(%1743) # torch/nn/functional.py:1992:19
          %1746 : int = aten::sub(%1745, %16) # torch/nn/functional.py:1992:19
          %size_prods.113 : int = prim::Loop(%1746, %9, %size_prods.112) # torch/nn/functional.py:1992:4
            block0(%i.29 : int, %size_prods.114 : int):
              %1750 : int = aten::add(%i.29, %16) # torch/nn/functional.py:1993:27
              %1751 : int = aten::__getitem__(%1743, %1750) # torch/nn/functional.py:1993:22
              %size_prods.115 : int = aten::mul(%size_prods.114, %1751) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.115)
          %1753 : bool = aten::eq(%size_prods.113, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1753) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.86 : Tensor = aten::batch_norm(%input.85, %1741, %1742, %1739, %1740, %1738, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.87 : Tensor = aten::relu_(%input.86) # torch/nn/functional.py:1117:17
      %1756 : Tensor[] = prim::ListConstruct(%x1.5, %input.87)
      %out.13 : Tensor = aten::cat(%1756, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.13)
    block1():
      %1758 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%963)
      %1759 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%1758)
      %1760 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1758)
      %1761 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%1758)
      %1762 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%1758)
      %1763 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%1758)
      %1764 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%1758)
      %1765 : Tensor = prim::GetAttr[name="weight"](%1759)
      %1766 : Tensor? = prim::GetAttr[name="bias"](%1759)
      %1767 : int[] = prim::ListConstruct(%8, %8)
      %1768 : int[] = prim::ListConstruct(%10, %10)
      %1769 : int[] = prim::ListConstruct(%8, %8)
      %input.88 : Tensor = aten::conv2d(%input.272, %1765, %1766, %1767, %1768, %1769, %8) # torch/nn/modules/conv.py:415:15
      %1771 : int = aten::dim(%input.88) # torch/nn/modules/batchnorm.py:276:11
      %1772 : bool = aten::ne(%1771, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1772) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1773 : bool = prim::GetAttr[name="training"](%1760)
       = prim::If(%1773) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1774 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1760)
          %1775 : Tensor = aten::add(%1774, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1760, %1775)
          -> ()
        block1():
          -> ()
      %1776 : bool = prim::GetAttr[name="training"](%1760)
      %1777 : Tensor = prim::GetAttr[name="running_mean"](%1760)
      %1778 : Tensor = prim::GetAttr[name="running_var"](%1760)
      %1779 : Tensor = prim::GetAttr[name="weight"](%1760)
      %1780 : Tensor = prim::GetAttr[name="bias"](%1760)
       = prim::If(%1776) # torch/nn/functional.py:2011:4
        block0():
          %1781 : int[] = aten::size(%input.88) # torch/nn/functional.py:2012:27
          %size_prods.116 : int = aten::__getitem__(%1781, %10) # torch/nn/functional.py:1991:17
          %1783 : int = aten::len(%1781) # torch/nn/functional.py:1992:19
          %1784 : int = aten::sub(%1783, %16) # torch/nn/functional.py:1992:19
          %size_prods.117 : int = prim::Loop(%1784, %9, %size_prods.116) # torch/nn/functional.py:1992:4
            block0(%i.30 : int, %size_prods.118 : int):
              %1788 : int = aten::add(%i.30, %16) # torch/nn/functional.py:1993:27
              %1789 : int = aten::__getitem__(%1781, %1788) # torch/nn/functional.py:1993:22
              %size_prods.119 : int = aten::mul(%size_prods.118, %1789) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.119)
          %1791 : bool = aten::eq(%size_prods.117, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1791) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.89 : Tensor = aten::batch_norm(%input.88, %1779, %1780, %1777, %1778, %1776, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.90 : Tensor = aten::relu_(%input.89) # torch/nn/functional.py:1117:17
      %1794 : Tensor = prim::GetAttr[name="weight"](%1761)
      %1795 : Tensor? = prim::GetAttr[name="bias"](%1761)
      %1796 : int[] = prim::ListConstruct(%8, %8)
      %1797 : int[] = prim::ListConstruct(%8, %8)
      %1798 : int[] = prim::ListConstruct(%8, %8)
      %input.91 : Tensor = aten::conv2d(%input.90, %1794, %1795, %1796, %1797, %1798, %4) # torch/nn/modules/conv.py:415:15
      %1800 : int = aten::dim(%input.91) # torch/nn/modules/batchnorm.py:276:11
      %1801 : bool = aten::ne(%1800, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1801) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1802 : bool = prim::GetAttr[name="training"](%1762)
       = prim::If(%1802) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1803 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1762)
          %1804 : Tensor = aten::add(%1803, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1762, %1804)
          -> ()
        block1():
          -> ()
      %1805 : bool = prim::GetAttr[name="training"](%1762)
      %1806 : Tensor = prim::GetAttr[name="running_mean"](%1762)
      %1807 : Tensor = prim::GetAttr[name="running_var"](%1762)
      %1808 : Tensor = prim::GetAttr[name="weight"](%1762)
      %1809 : Tensor = prim::GetAttr[name="bias"](%1762)
       = prim::If(%1805) # torch/nn/functional.py:2011:4
        block0():
          %1810 : int[] = aten::size(%input.91) # torch/nn/functional.py:2012:27
          %size_prods.120 : int = aten::__getitem__(%1810, %10) # torch/nn/functional.py:1991:17
          %1812 : int = aten::len(%1810) # torch/nn/functional.py:1992:19
          %1813 : int = aten::sub(%1812, %16) # torch/nn/functional.py:1992:19
          %size_prods.121 : int = prim::Loop(%1813, %9, %size_prods.120) # torch/nn/functional.py:1992:4
            block0(%i.31 : int, %size_prods.122 : int):
              %1817 : int = aten::add(%i.31, %16) # torch/nn/functional.py:1993:27
              %1818 : int = aten::__getitem__(%1810, %1817) # torch/nn/functional.py:1993:22
              %size_prods.123 : int = aten::mul(%size_prods.122, %1818) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.123)
          %1820 : bool = aten::eq(%size_prods.121, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1820) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.92 : Tensor = aten::batch_norm(%input.91, %1808, %1809, %1806, %1807, %1805, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1822 : Tensor = prim::GetAttr[name="weight"](%1763)
      %1823 : Tensor? = prim::GetAttr[name="bias"](%1763)
      %1824 : int[] = prim::ListConstruct(%8, %8)
      %1825 : int[] = prim::ListConstruct(%10, %10)
      %1826 : int[] = prim::ListConstruct(%8, %8)
      %input.93 : Tensor = aten::conv2d(%input.92, %1822, %1823, %1824, %1825, %1826, %8) # torch/nn/modules/conv.py:415:15
      %1828 : int = aten::dim(%input.93) # torch/nn/modules/batchnorm.py:276:11
      %1829 : bool = aten::ne(%1828, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1829) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1830 : bool = prim::GetAttr[name="training"](%1764)
       = prim::If(%1830) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1831 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1764)
          %1832 : Tensor = aten::add(%1831, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1764, %1832)
          -> ()
        block1():
          -> ()
      %1833 : bool = prim::GetAttr[name="training"](%1764)
      %1834 : Tensor = prim::GetAttr[name="running_mean"](%1764)
      %1835 : Tensor = prim::GetAttr[name="running_var"](%1764)
      %1836 : Tensor = prim::GetAttr[name="weight"](%1764)
      %1837 : Tensor = prim::GetAttr[name="bias"](%1764)
       = prim::If(%1833) # torch/nn/functional.py:2011:4
        block0():
          %1838 : int[] = aten::size(%input.93) # torch/nn/functional.py:2012:27
          %size_prods.124 : int = aten::__getitem__(%1838, %10) # torch/nn/functional.py:1991:17
          %1840 : int = aten::len(%1838) # torch/nn/functional.py:1992:19
          %1841 : int = aten::sub(%1840, %16) # torch/nn/functional.py:1992:19
          %size_prods.125 : int = prim::Loop(%1841, %9, %size_prods.124) # torch/nn/functional.py:1992:4
            block0(%i.32 : int, %size_prods.126 : int):
              %1845 : int = aten::add(%i.32, %16) # torch/nn/functional.py:1993:27
              %1846 : int = aten::__getitem__(%1838, %1845) # torch/nn/functional.py:1993:22
              %size_prods.127 : int = aten::mul(%size_prods.126, %1846) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.127)
          %1848 : bool = aten::eq(%size_prods.125, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1848) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.94 : Tensor = aten::batch_norm(%input.93, %1836, %1837, %1834, %1835, %1833, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.95 : Tensor = aten::relu_(%input.94) # torch/nn/functional.py:1117:17
      %1851 : Tensor[] = prim::ListConstruct(%input.272, %input.95)
      %out.14 : Tensor = aten::cat(%1851, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.14)
  %1853 : Tensor = prim::data(%out.15)
  %1854 : int[] = aten::size(%1853) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.5 : int, %num_channels.5 : int, %height.5 : int, %width.5 : int = prim::ListUnpack(%1854)
  %channels_per_group.5 : int = aten::floordiv(%num_channels.5, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %1860 : int[] = prim::ListConstruct(%batchsize.5, %16, %channels_per_group.5, %height.5, %width.5)
  %x.12 : Tensor = aten::view(%out.15, %1860) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %1862 : Tensor = aten::transpose(%x.12, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.13 : Tensor = aten::contiguous(%1862, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %1864 : int[] = prim::ListConstruct(%batchsize.5, %5, %height.5, %width.5)
  %input.289 : Tensor = aten::view(%x.13, %1864) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %1866 : int = prim::GetAttr[name="stride"](%964)
  %1867 : bool = aten::eq(%1866, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.18 : Tensor = prim::If(%1867) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %1869 : Tensor[] = aten::chunk(%input.289, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.6 : Tensor, %x2.6 : Tensor = prim::ListUnpack(%1869)
      %1872 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%964)
      %1873 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%1872)
      %1874 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1872)
      %1875 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%1872)
      %1876 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%1872)
      %1877 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%1872)
      %1878 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%1872)
      %1879 : Tensor = prim::GetAttr[name="weight"](%1873)
      %1880 : Tensor? = prim::GetAttr[name="bias"](%1873)
      %1881 : int[] = prim::ListConstruct(%8, %8)
      %1882 : int[] = prim::ListConstruct(%10, %10)
      %1883 : int[] = prim::ListConstruct(%8, %8)
      %input.96 : Tensor = aten::conv2d(%x2.6, %1879, %1880, %1881, %1882, %1883, %8) # torch/nn/modules/conv.py:415:15
      %1885 : int = aten::dim(%input.96) # torch/nn/modules/batchnorm.py:276:11
      %1886 : bool = aten::ne(%1885, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1886) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1887 : bool = prim::GetAttr[name="training"](%1874)
       = prim::If(%1887) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1888 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1874)
          %1889 : Tensor = aten::add(%1888, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1874, %1889)
          -> ()
        block1():
          -> ()
      %1890 : bool = prim::GetAttr[name="training"](%1874)
      %1891 : Tensor = prim::GetAttr[name="running_mean"](%1874)
      %1892 : Tensor = prim::GetAttr[name="running_var"](%1874)
      %1893 : Tensor = prim::GetAttr[name="weight"](%1874)
      %1894 : Tensor = prim::GetAttr[name="bias"](%1874)
       = prim::If(%1890) # torch/nn/functional.py:2011:4
        block0():
          %1895 : int[] = aten::size(%input.96) # torch/nn/functional.py:2012:27
          %size_prods.128 : int = aten::__getitem__(%1895, %10) # torch/nn/functional.py:1991:17
          %1897 : int = aten::len(%1895) # torch/nn/functional.py:1992:19
          %1898 : int = aten::sub(%1897, %16) # torch/nn/functional.py:1992:19
          %size_prods.129 : int = prim::Loop(%1898, %9, %size_prods.128) # torch/nn/functional.py:1992:4
            block0(%i.33 : int, %size_prods.130 : int):
              %1902 : int = aten::add(%i.33, %16) # torch/nn/functional.py:1993:27
              %1903 : int = aten::__getitem__(%1895, %1902) # torch/nn/functional.py:1993:22
              %size_prods.131 : int = aten::mul(%size_prods.130, %1903) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.131)
          %1905 : bool = aten::eq(%size_prods.129, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1905) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.97 : Tensor = aten::batch_norm(%input.96, %1893, %1894, %1891, %1892, %1890, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.98 : Tensor = aten::relu_(%input.97) # torch/nn/functional.py:1117:17
      %1908 : Tensor = prim::GetAttr[name="weight"](%1875)
      %1909 : Tensor? = prim::GetAttr[name="bias"](%1875)
      %1910 : int[] = prim::ListConstruct(%8, %8)
      %1911 : int[] = prim::ListConstruct(%8, %8)
      %1912 : int[] = prim::ListConstruct(%8, %8)
      %input.99 : Tensor = aten::conv2d(%input.98, %1908, %1909, %1910, %1911, %1912, %4) # torch/nn/modules/conv.py:415:15
      %1914 : int = aten::dim(%input.99) # torch/nn/modules/batchnorm.py:276:11
      %1915 : bool = aten::ne(%1914, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1915) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1916 : bool = prim::GetAttr[name="training"](%1876)
       = prim::If(%1916) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1917 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1876)
          %1918 : Tensor = aten::add(%1917, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1876, %1918)
          -> ()
        block1():
          -> ()
      %1919 : bool = prim::GetAttr[name="training"](%1876)
      %1920 : Tensor = prim::GetAttr[name="running_mean"](%1876)
      %1921 : Tensor = prim::GetAttr[name="running_var"](%1876)
      %1922 : Tensor = prim::GetAttr[name="weight"](%1876)
      %1923 : Tensor = prim::GetAttr[name="bias"](%1876)
       = prim::If(%1919) # torch/nn/functional.py:2011:4
        block0():
          %1924 : int[] = aten::size(%input.99) # torch/nn/functional.py:2012:27
          %size_prods.132 : int = aten::__getitem__(%1924, %10) # torch/nn/functional.py:1991:17
          %1926 : int = aten::len(%1924) # torch/nn/functional.py:1992:19
          %1927 : int = aten::sub(%1926, %16) # torch/nn/functional.py:1992:19
          %size_prods.133 : int = prim::Loop(%1927, %9, %size_prods.132) # torch/nn/functional.py:1992:4
            block0(%i.34 : int, %size_prods.134 : int):
              %1931 : int = aten::add(%i.34, %16) # torch/nn/functional.py:1993:27
              %1932 : int = aten::__getitem__(%1924, %1931) # torch/nn/functional.py:1993:22
              %size_prods.135 : int = aten::mul(%size_prods.134, %1932) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.135)
          %1934 : bool = aten::eq(%size_prods.133, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1934) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.100 : Tensor = aten::batch_norm(%input.99, %1922, %1923, %1920, %1921, %1919, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %1936 : Tensor = prim::GetAttr[name="weight"](%1877)
      %1937 : Tensor? = prim::GetAttr[name="bias"](%1877)
      %1938 : int[] = prim::ListConstruct(%8, %8)
      %1939 : int[] = prim::ListConstruct(%10, %10)
      %1940 : int[] = prim::ListConstruct(%8, %8)
      %input.101 : Tensor = aten::conv2d(%input.100, %1936, %1937, %1938, %1939, %1940, %8) # torch/nn/modules/conv.py:415:15
      %1942 : int = aten::dim(%input.101) # torch/nn/modules/batchnorm.py:276:11
      %1943 : bool = aten::ne(%1942, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1943) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1944 : bool = prim::GetAttr[name="training"](%1878)
       = prim::If(%1944) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1945 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1878)
          %1946 : Tensor = aten::add(%1945, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1878, %1946)
          -> ()
        block1():
          -> ()
      %1947 : bool = prim::GetAttr[name="training"](%1878)
      %1948 : Tensor = prim::GetAttr[name="running_mean"](%1878)
      %1949 : Tensor = prim::GetAttr[name="running_var"](%1878)
      %1950 : Tensor = prim::GetAttr[name="weight"](%1878)
      %1951 : Tensor = prim::GetAttr[name="bias"](%1878)
       = prim::If(%1947) # torch/nn/functional.py:2011:4
        block0():
          %1952 : int[] = aten::size(%input.101) # torch/nn/functional.py:2012:27
          %size_prods.136 : int = aten::__getitem__(%1952, %10) # torch/nn/functional.py:1991:17
          %1954 : int = aten::len(%1952) # torch/nn/functional.py:1992:19
          %1955 : int = aten::sub(%1954, %16) # torch/nn/functional.py:1992:19
          %size_prods.137 : int = prim::Loop(%1955, %9, %size_prods.136) # torch/nn/functional.py:1992:4
            block0(%i.35 : int, %size_prods.138 : int):
              %1959 : int = aten::add(%i.35, %16) # torch/nn/functional.py:1993:27
              %1960 : int = aten::__getitem__(%1952, %1959) # torch/nn/functional.py:1993:22
              %size_prods.139 : int = aten::mul(%size_prods.138, %1960) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.139)
          %1962 : bool = aten::eq(%size_prods.137, %8) # torch/nn/functional.py:1994:7
           = prim::If(%1962) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.102 : Tensor = aten::batch_norm(%input.101, %1950, %1951, %1948, %1949, %1947, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.103 : Tensor = aten::relu_(%input.102) # torch/nn/functional.py:1117:17
      %1965 : Tensor[] = prim::ListConstruct(%x1.6, %input.103)
      %out.16 : Tensor = aten::cat(%1965, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.16)
    block1():
      %1967 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%964)
      %1968 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%1967)
      %1969 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%1967)
      %1970 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%1967)
      %1971 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%1967)
      %1972 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%1967)
      %1973 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%1967)
      %1974 : Tensor = prim::GetAttr[name="weight"](%1968)
      %1975 : Tensor? = prim::GetAttr[name="bias"](%1968)
      %1976 : int[] = prim::ListConstruct(%8, %8)
      %1977 : int[] = prim::ListConstruct(%10, %10)
      %1978 : int[] = prim::ListConstruct(%8, %8)
      %input.104 : Tensor = aten::conv2d(%input.289, %1974, %1975, %1976, %1977, %1978, %8) # torch/nn/modules/conv.py:415:15
      %1980 : int = aten::dim(%input.104) # torch/nn/modules/batchnorm.py:276:11
      %1981 : bool = aten::ne(%1980, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%1981) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %1982 : bool = prim::GetAttr[name="training"](%1969)
       = prim::If(%1982) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %1983 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1969)
          %1984 : Tensor = aten::add(%1983, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1969, %1984)
          -> ()
        block1():
          -> ()
      %1985 : bool = prim::GetAttr[name="training"](%1969)
      %1986 : Tensor = prim::GetAttr[name="running_mean"](%1969)
      %1987 : Tensor = prim::GetAttr[name="running_var"](%1969)
      %1988 : Tensor = prim::GetAttr[name="weight"](%1969)
      %1989 : Tensor = prim::GetAttr[name="bias"](%1969)
       = prim::If(%1985) # torch/nn/functional.py:2011:4
        block0():
          %1990 : int[] = aten::size(%input.104) # torch/nn/functional.py:2012:27
          %size_prods.140 : int = aten::__getitem__(%1990, %10) # torch/nn/functional.py:1991:17
          %1992 : int = aten::len(%1990) # torch/nn/functional.py:1992:19
          %1993 : int = aten::sub(%1992, %16) # torch/nn/functional.py:1992:19
          %size_prods.141 : int = prim::Loop(%1993, %9, %size_prods.140) # torch/nn/functional.py:1992:4
            block0(%i.36 : int, %size_prods.142 : int):
              %1997 : int = aten::add(%i.36, %16) # torch/nn/functional.py:1993:27
              %1998 : int = aten::__getitem__(%1990, %1997) # torch/nn/functional.py:1993:22
              %size_prods.143 : int = aten::mul(%size_prods.142, %1998) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.143)
          %2000 : bool = aten::eq(%size_prods.141, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2000) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.105 : Tensor = aten::batch_norm(%input.104, %1988, %1989, %1986, %1987, %1985, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.106 : Tensor = aten::relu_(%input.105) # torch/nn/functional.py:1117:17
      %2003 : Tensor = prim::GetAttr[name="weight"](%1970)
      %2004 : Tensor? = prim::GetAttr[name="bias"](%1970)
      %2005 : int[] = prim::ListConstruct(%8, %8)
      %2006 : int[] = prim::ListConstruct(%8, %8)
      %2007 : int[] = prim::ListConstruct(%8, %8)
      %input.107 : Tensor = aten::conv2d(%input.106, %2003, %2004, %2005, %2006, %2007, %4) # torch/nn/modules/conv.py:415:15
      %2009 : int = aten::dim(%input.107) # torch/nn/modules/batchnorm.py:276:11
      %2010 : bool = aten::ne(%2009, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2010) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2011 : bool = prim::GetAttr[name="training"](%1971)
       = prim::If(%2011) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2012 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1971)
          %2013 : Tensor = aten::add(%2012, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1971, %2013)
          -> ()
        block1():
          -> ()
      %2014 : bool = prim::GetAttr[name="training"](%1971)
      %2015 : Tensor = prim::GetAttr[name="running_mean"](%1971)
      %2016 : Tensor = prim::GetAttr[name="running_var"](%1971)
      %2017 : Tensor = prim::GetAttr[name="weight"](%1971)
      %2018 : Tensor = prim::GetAttr[name="bias"](%1971)
       = prim::If(%2014) # torch/nn/functional.py:2011:4
        block0():
          %2019 : int[] = aten::size(%input.107) # torch/nn/functional.py:2012:27
          %size_prods.144 : int = aten::__getitem__(%2019, %10) # torch/nn/functional.py:1991:17
          %2021 : int = aten::len(%2019) # torch/nn/functional.py:1992:19
          %2022 : int = aten::sub(%2021, %16) # torch/nn/functional.py:1992:19
          %size_prods.145 : int = prim::Loop(%2022, %9, %size_prods.144) # torch/nn/functional.py:1992:4
            block0(%i.37 : int, %size_prods.146 : int):
              %2026 : int = aten::add(%i.37, %16) # torch/nn/functional.py:1993:27
              %2027 : int = aten::__getitem__(%2019, %2026) # torch/nn/functional.py:1993:22
              %size_prods.147 : int = aten::mul(%size_prods.146, %2027) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.147)
          %2029 : bool = aten::eq(%size_prods.145, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2029) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.108 : Tensor = aten::batch_norm(%input.107, %2017, %2018, %2015, %2016, %2014, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2031 : Tensor = prim::GetAttr[name="weight"](%1972)
      %2032 : Tensor? = prim::GetAttr[name="bias"](%1972)
      %2033 : int[] = prim::ListConstruct(%8, %8)
      %2034 : int[] = prim::ListConstruct(%10, %10)
      %2035 : int[] = prim::ListConstruct(%8, %8)
      %input.109 : Tensor = aten::conv2d(%input.108, %2031, %2032, %2033, %2034, %2035, %8) # torch/nn/modules/conv.py:415:15
      %2037 : int = aten::dim(%input.109) # torch/nn/modules/batchnorm.py:276:11
      %2038 : bool = aten::ne(%2037, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2038) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2039 : bool = prim::GetAttr[name="training"](%1973)
       = prim::If(%2039) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2040 : Tensor = prim::GetAttr[name="num_batches_tracked"](%1973)
          %2041 : Tensor = aten::add(%2040, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%1973, %2041)
          -> ()
        block1():
          -> ()
      %2042 : bool = prim::GetAttr[name="training"](%1973)
      %2043 : Tensor = prim::GetAttr[name="running_mean"](%1973)
      %2044 : Tensor = prim::GetAttr[name="running_var"](%1973)
      %2045 : Tensor = prim::GetAttr[name="weight"](%1973)
      %2046 : Tensor = prim::GetAttr[name="bias"](%1973)
       = prim::If(%2042) # torch/nn/functional.py:2011:4
        block0():
          %2047 : int[] = aten::size(%input.109) # torch/nn/functional.py:2012:27
          %size_prods.148 : int = aten::__getitem__(%2047, %10) # torch/nn/functional.py:1991:17
          %2049 : int = aten::len(%2047) # torch/nn/functional.py:1992:19
          %2050 : int = aten::sub(%2049, %16) # torch/nn/functional.py:1992:19
          %size_prods.149 : int = prim::Loop(%2050, %9, %size_prods.148) # torch/nn/functional.py:1992:4
            block0(%i.38 : int, %size_prods.150 : int):
              %2054 : int = aten::add(%i.38, %16) # torch/nn/functional.py:1993:27
              %2055 : int = aten::__getitem__(%2047, %2054) # torch/nn/functional.py:1993:22
              %size_prods.151 : int = aten::mul(%size_prods.150, %2055) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.151)
          %2057 : bool = aten::eq(%size_prods.149, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2057) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.110 : Tensor = aten::batch_norm(%input.109, %2045, %2046, %2043, %2044, %2042, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.111 : Tensor = aten::relu_(%input.110) # torch/nn/functional.py:1117:17
      %2060 : Tensor[] = prim::ListConstruct(%input.289, %input.111)
      %out.17 : Tensor = aten::cat(%2060, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.17)
  %2062 : Tensor = prim::data(%out.18)
  %2063 : int[] = aten::size(%2062) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.6 : int, %num_channels.6 : int, %height.6 : int, %width.6 : int = prim::ListUnpack(%2063)
  %channels_per_group.6 : int = aten::floordiv(%num_channels.6, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2069 : int[] = prim::ListConstruct(%batchsize.6, %16, %channels_per_group.6, %height.6, %width.6)
  %x.14 : Tensor = aten::view(%out.18, %2069) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2071 : Tensor = aten::transpose(%x.14, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.15 : Tensor = aten::contiguous(%2071, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2073 : int[] = prim::ListConstruct(%batchsize.6, %5, %height.6, %width.6)
  %input.220 : Tensor = aten::view(%x.15, %2073) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2075 : int = prim::GetAttr[name="stride"](%965)
  %2076 : bool = aten::eq(%2075, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.21 : Tensor = prim::If(%2076) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2078 : Tensor[] = aten::chunk(%input.220, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.7 : Tensor, %x2.7 : Tensor = prim::ListUnpack(%2078)
      %2081 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%965)
      %2082 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%2081)
      %2083 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%2081)
      %2084 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%2081)
      %2085 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%2081)
      %2086 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%2081)
      %2087 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%2081)
      %2088 : Tensor = prim::GetAttr[name="weight"](%2082)
      %2089 : Tensor? = prim::GetAttr[name="bias"](%2082)
      %2090 : int[] = prim::ListConstruct(%8, %8)
      %2091 : int[] = prim::ListConstruct(%10, %10)
      %2092 : int[] = prim::ListConstruct(%8, %8)
      %input.112 : Tensor = aten::conv2d(%x2.7, %2088, %2089, %2090, %2091, %2092, %8) # torch/nn/modules/conv.py:415:15
      %2094 : int = aten::dim(%input.112) # torch/nn/modules/batchnorm.py:276:11
      %2095 : bool = aten::ne(%2094, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2095) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2096 : bool = prim::GetAttr[name="training"](%2083)
       = prim::If(%2096) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2097 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2083)
          %2098 : Tensor = aten::add(%2097, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2083, %2098)
          -> ()
        block1():
          -> ()
      %2099 : bool = prim::GetAttr[name="training"](%2083)
      %2100 : Tensor = prim::GetAttr[name="running_mean"](%2083)
      %2101 : Tensor = prim::GetAttr[name="running_var"](%2083)
      %2102 : Tensor = prim::GetAttr[name="weight"](%2083)
      %2103 : Tensor = prim::GetAttr[name="bias"](%2083)
       = prim::If(%2099) # torch/nn/functional.py:2011:4
        block0():
          %2104 : int[] = aten::size(%input.112) # torch/nn/functional.py:2012:27
          %size_prods.152 : int = aten::__getitem__(%2104, %10) # torch/nn/functional.py:1991:17
          %2106 : int = aten::len(%2104) # torch/nn/functional.py:1992:19
          %2107 : int = aten::sub(%2106, %16) # torch/nn/functional.py:1992:19
          %size_prods.153 : int = prim::Loop(%2107, %9, %size_prods.152) # torch/nn/functional.py:1992:4
            block0(%i.39 : int, %size_prods.154 : int):
              %2111 : int = aten::add(%i.39, %16) # torch/nn/functional.py:1993:27
              %2112 : int = aten::__getitem__(%2104, %2111) # torch/nn/functional.py:1993:22
              %size_prods.155 : int = aten::mul(%size_prods.154, %2112) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.155)
          %2114 : bool = aten::eq(%size_prods.153, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2114) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.113 : Tensor = aten::batch_norm(%input.112, %2102, %2103, %2100, %2101, %2099, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.114 : Tensor = aten::relu_(%input.113) # torch/nn/functional.py:1117:17
      %2117 : Tensor = prim::GetAttr[name="weight"](%2084)
      %2118 : Tensor? = prim::GetAttr[name="bias"](%2084)
      %2119 : int[] = prim::ListConstruct(%8, %8)
      %2120 : int[] = prim::ListConstruct(%8, %8)
      %2121 : int[] = prim::ListConstruct(%8, %8)
      %input.115 : Tensor = aten::conv2d(%input.114, %2117, %2118, %2119, %2120, %2121, %4) # torch/nn/modules/conv.py:415:15
      %2123 : int = aten::dim(%input.115) # torch/nn/modules/batchnorm.py:276:11
      %2124 : bool = aten::ne(%2123, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2124) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2125 : bool = prim::GetAttr[name="training"](%2085)
       = prim::If(%2125) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2126 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2085)
          %2127 : Tensor = aten::add(%2126, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2085, %2127)
          -> ()
        block1():
          -> ()
      %2128 : bool = prim::GetAttr[name="training"](%2085)
      %2129 : Tensor = prim::GetAttr[name="running_mean"](%2085)
      %2130 : Tensor = prim::GetAttr[name="running_var"](%2085)
      %2131 : Tensor = prim::GetAttr[name="weight"](%2085)
      %2132 : Tensor = prim::GetAttr[name="bias"](%2085)
       = prim::If(%2128) # torch/nn/functional.py:2011:4
        block0():
          %2133 : int[] = aten::size(%input.115) # torch/nn/functional.py:2012:27
          %size_prods.156 : int = aten::__getitem__(%2133, %10) # torch/nn/functional.py:1991:17
          %2135 : int = aten::len(%2133) # torch/nn/functional.py:1992:19
          %2136 : int = aten::sub(%2135, %16) # torch/nn/functional.py:1992:19
          %size_prods.157 : int = prim::Loop(%2136, %9, %size_prods.156) # torch/nn/functional.py:1992:4
            block0(%i.40 : int, %size_prods.158 : int):
              %2140 : int = aten::add(%i.40, %16) # torch/nn/functional.py:1993:27
              %2141 : int = aten::__getitem__(%2133, %2140) # torch/nn/functional.py:1993:22
              %size_prods.159 : int = aten::mul(%size_prods.158, %2141) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.159)
          %2143 : bool = aten::eq(%size_prods.157, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2143) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.116 : Tensor = aten::batch_norm(%input.115, %2131, %2132, %2129, %2130, %2128, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2145 : Tensor = prim::GetAttr[name="weight"](%2086)
      %2146 : Tensor? = prim::GetAttr[name="bias"](%2086)
      %2147 : int[] = prim::ListConstruct(%8, %8)
      %2148 : int[] = prim::ListConstruct(%10, %10)
      %2149 : int[] = prim::ListConstruct(%8, %8)
      %input.117 : Tensor = aten::conv2d(%input.116, %2145, %2146, %2147, %2148, %2149, %8) # torch/nn/modules/conv.py:415:15
      %2151 : int = aten::dim(%input.117) # torch/nn/modules/batchnorm.py:276:11
      %2152 : bool = aten::ne(%2151, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2152) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2153 : bool = prim::GetAttr[name="training"](%2087)
       = prim::If(%2153) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2154 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2087)
          %2155 : Tensor = aten::add(%2154, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2087, %2155)
          -> ()
        block1():
          -> ()
      %2156 : bool = prim::GetAttr[name="training"](%2087)
      %2157 : Tensor = prim::GetAttr[name="running_mean"](%2087)
      %2158 : Tensor = prim::GetAttr[name="running_var"](%2087)
      %2159 : Tensor = prim::GetAttr[name="weight"](%2087)
      %2160 : Tensor = prim::GetAttr[name="bias"](%2087)
       = prim::If(%2156) # torch/nn/functional.py:2011:4
        block0():
          %2161 : int[] = aten::size(%input.117) # torch/nn/functional.py:2012:27
          %size_prods.160 : int = aten::__getitem__(%2161, %10) # torch/nn/functional.py:1991:17
          %2163 : int = aten::len(%2161) # torch/nn/functional.py:1992:19
          %2164 : int = aten::sub(%2163, %16) # torch/nn/functional.py:1992:19
          %size_prods.161 : int = prim::Loop(%2164, %9, %size_prods.160) # torch/nn/functional.py:1992:4
            block0(%i.41 : int, %size_prods.162 : int):
              %2168 : int = aten::add(%i.41, %16) # torch/nn/functional.py:1993:27
              %2169 : int = aten::__getitem__(%2161, %2168) # torch/nn/functional.py:1993:22
              %size_prods.163 : int = aten::mul(%size_prods.162, %2169) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.163)
          %2171 : bool = aten::eq(%size_prods.161, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2171) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.118 : Tensor = aten::batch_norm(%input.117, %2159, %2160, %2157, %2158, %2156, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.119 : Tensor = aten::relu_(%input.118) # torch/nn/functional.py:1117:17
      %2174 : Tensor[] = prim::ListConstruct(%x1.7, %input.119)
      %out.19 : Tensor = aten::cat(%2174, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.19)
    block1():
      %2176 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%965)
      %2177 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%2176)
      %2178 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%2176)
      %2179 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%2176)
      %2180 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%2176)
      %2181 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%2176)
      %2182 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%2176)
      %2183 : Tensor = prim::GetAttr[name="weight"](%2177)
      %2184 : Tensor? = prim::GetAttr[name="bias"](%2177)
      %2185 : int[] = prim::ListConstruct(%8, %8)
      %2186 : int[] = prim::ListConstruct(%10, %10)
      %2187 : int[] = prim::ListConstruct(%8, %8)
      %input.120 : Tensor = aten::conv2d(%input.220, %2183, %2184, %2185, %2186, %2187, %8) # torch/nn/modules/conv.py:415:15
      %2189 : int = aten::dim(%input.120) # torch/nn/modules/batchnorm.py:276:11
      %2190 : bool = aten::ne(%2189, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2190) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2191 : bool = prim::GetAttr[name="training"](%2178)
       = prim::If(%2191) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2192 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2178)
          %2193 : Tensor = aten::add(%2192, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2178, %2193)
          -> ()
        block1():
          -> ()
      %2194 : bool = prim::GetAttr[name="training"](%2178)
      %2195 : Tensor = prim::GetAttr[name="running_mean"](%2178)
      %2196 : Tensor = prim::GetAttr[name="running_var"](%2178)
      %2197 : Tensor = prim::GetAttr[name="weight"](%2178)
      %2198 : Tensor = prim::GetAttr[name="bias"](%2178)
       = prim::If(%2194) # torch/nn/functional.py:2011:4
        block0():
          %2199 : int[] = aten::size(%input.120) # torch/nn/functional.py:2012:27
          %size_prods.164 : int = aten::__getitem__(%2199, %10) # torch/nn/functional.py:1991:17
          %2201 : int = aten::len(%2199) # torch/nn/functional.py:1992:19
          %2202 : int = aten::sub(%2201, %16) # torch/nn/functional.py:1992:19
          %size_prods.165 : int = prim::Loop(%2202, %9, %size_prods.164) # torch/nn/functional.py:1992:4
            block0(%i.42 : int, %size_prods.166 : int):
              %2206 : int = aten::add(%i.42, %16) # torch/nn/functional.py:1993:27
              %2207 : int = aten::__getitem__(%2199, %2206) # torch/nn/functional.py:1993:22
              %size_prods.167 : int = aten::mul(%size_prods.166, %2207) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.167)
          %2209 : bool = aten::eq(%size_prods.165, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2209) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.121 : Tensor = aten::batch_norm(%input.120, %2197, %2198, %2195, %2196, %2194, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.122 : Tensor = aten::relu_(%input.121) # torch/nn/functional.py:1117:17
      %2212 : Tensor = prim::GetAttr[name="weight"](%2179)
      %2213 : Tensor? = prim::GetAttr[name="bias"](%2179)
      %2214 : int[] = prim::ListConstruct(%8, %8)
      %2215 : int[] = prim::ListConstruct(%8, %8)
      %2216 : int[] = prim::ListConstruct(%8, %8)
      %input.123 : Tensor = aten::conv2d(%input.122, %2212, %2213, %2214, %2215, %2216, %4) # torch/nn/modules/conv.py:415:15
      %2218 : int = aten::dim(%input.123) # torch/nn/modules/batchnorm.py:276:11
      %2219 : bool = aten::ne(%2218, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2219) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2220 : bool = prim::GetAttr[name="training"](%2180)
       = prim::If(%2220) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2221 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2180)
          %2222 : Tensor = aten::add(%2221, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2180, %2222)
          -> ()
        block1():
          -> ()
      %2223 : bool = prim::GetAttr[name="training"](%2180)
      %2224 : Tensor = prim::GetAttr[name="running_mean"](%2180)
      %2225 : Tensor = prim::GetAttr[name="running_var"](%2180)
      %2226 : Tensor = prim::GetAttr[name="weight"](%2180)
      %2227 : Tensor = prim::GetAttr[name="bias"](%2180)
       = prim::If(%2223) # torch/nn/functional.py:2011:4
        block0():
          %2228 : int[] = aten::size(%input.123) # torch/nn/functional.py:2012:27
          %size_prods.168 : int = aten::__getitem__(%2228, %10) # torch/nn/functional.py:1991:17
          %2230 : int = aten::len(%2228) # torch/nn/functional.py:1992:19
          %2231 : int = aten::sub(%2230, %16) # torch/nn/functional.py:1992:19
          %size_prods.169 : int = prim::Loop(%2231, %9, %size_prods.168) # torch/nn/functional.py:1992:4
            block0(%i.43 : int, %size_prods.170 : int):
              %2235 : int = aten::add(%i.43, %16) # torch/nn/functional.py:1993:27
              %2236 : int = aten::__getitem__(%2228, %2235) # torch/nn/functional.py:1993:22
              %size_prods.171 : int = aten::mul(%size_prods.170, %2236) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.171)
          %2238 : bool = aten::eq(%size_prods.169, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2238) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.124 : Tensor = aten::batch_norm(%input.123, %2226, %2227, %2224, %2225, %2223, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2240 : Tensor = prim::GetAttr[name="weight"](%2181)
      %2241 : Tensor? = prim::GetAttr[name="bias"](%2181)
      %2242 : int[] = prim::ListConstruct(%8, %8)
      %2243 : int[] = prim::ListConstruct(%10, %10)
      %2244 : int[] = prim::ListConstruct(%8, %8)
      %input.125 : Tensor = aten::conv2d(%input.124, %2240, %2241, %2242, %2243, %2244, %8) # torch/nn/modules/conv.py:415:15
      %2246 : int = aten::dim(%input.125) # torch/nn/modules/batchnorm.py:276:11
      %2247 : bool = aten::ne(%2246, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2247) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2248 : bool = prim::GetAttr[name="training"](%2182)
       = prim::If(%2248) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2249 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2182)
          %2250 : Tensor = aten::add(%2249, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2182, %2250)
          -> ()
        block1():
          -> ()
      %2251 : bool = prim::GetAttr[name="training"](%2182)
      %2252 : Tensor = prim::GetAttr[name="running_mean"](%2182)
      %2253 : Tensor = prim::GetAttr[name="running_var"](%2182)
      %2254 : Tensor = prim::GetAttr[name="weight"](%2182)
      %2255 : Tensor = prim::GetAttr[name="bias"](%2182)
       = prim::If(%2251) # torch/nn/functional.py:2011:4
        block0():
          %2256 : int[] = aten::size(%input.125) # torch/nn/functional.py:2012:27
          %size_prods.172 : int = aten::__getitem__(%2256, %10) # torch/nn/functional.py:1991:17
          %2258 : int = aten::len(%2256) # torch/nn/functional.py:1992:19
          %2259 : int = aten::sub(%2258, %16) # torch/nn/functional.py:1992:19
          %size_prods.173 : int = prim::Loop(%2259, %9, %size_prods.172) # torch/nn/functional.py:1992:4
            block0(%i.44 : int, %size_prods.174 : int):
              %2263 : int = aten::add(%i.44, %16) # torch/nn/functional.py:1993:27
              %2264 : int = aten::__getitem__(%2256, %2263) # torch/nn/functional.py:1993:22
              %size_prods.175 : int = aten::mul(%size_prods.174, %2264) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.175)
          %2266 : bool = aten::eq(%size_prods.173, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2266) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.126 : Tensor = aten::batch_norm(%input.125, %2254, %2255, %2252, %2253, %2251, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.127 : Tensor = aten::relu_(%input.126) # torch/nn/functional.py:1117:17
      %2269 : Tensor[] = prim::ListConstruct(%input.220, %input.127)
      %out.20 : Tensor = aten::cat(%2269, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.20)
  %2271 : Tensor = prim::data(%out.21)
  %2272 : int[] = aten::size(%2271) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.7 : int, %num_channels.7 : int, %height.7 : int, %width.7 : int = prim::ListUnpack(%2272)
  %channels_per_group.7 : int = aten::floordiv(%num_channels.7, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2278 : int[] = prim::ListConstruct(%batchsize.7, %16, %channels_per_group.7, %height.7, %width.7)
  %x.16 : Tensor = aten::view(%out.21, %2278) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2280 : Tensor = aten::transpose(%x.16, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.17 : Tensor = aten::contiguous(%2280, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2282 : int[] = prim::ListConstruct(%batchsize.7, %5, %height.7, %width.7)
  %input.218 : Tensor = aten::view(%x.17, %2282) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2284 : int = prim::GetAttr[name="stride"](%966)
  %2285 : bool = aten::eq(%2284, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.24 : Tensor = prim::If(%2285) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2287 : Tensor[] = aten::chunk(%input.218, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.8 : Tensor, %x2.8 : Tensor = prim::ListUnpack(%2287)
      %2290 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%966)
      %2291 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%2290)
      %2292 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%2290)
      %2293 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%2290)
      %2294 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%2290)
      %2295 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%2290)
      %2296 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%2290)
      %2297 : Tensor = prim::GetAttr[name="weight"](%2291)
      %2298 : Tensor? = prim::GetAttr[name="bias"](%2291)
      %2299 : int[] = prim::ListConstruct(%8, %8)
      %2300 : int[] = prim::ListConstruct(%10, %10)
      %2301 : int[] = prim::ListConstruct(%8, %8)
      %input.128 : Tensor = aten::conv2d(%x2.8, %2297, %2298, %2299, %2300, %2301, %8) # torch/nn/modules/conv.py:415:15
      %2303 : int = aten::dim(%input.128) # torch/nn/modules/batchnorm.py:276:11
      %2304 : bool = aten::ne(%2303, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2304) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2305 : bool = prim::GetAttr[name="training"](%2292)
       = prim::If(%2305) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2306 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2292)
          %2307 : Tensor = aten::add(%2306, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2292, %2307)
          -> ()
        block1():
          -> ()
      %2308 : bool = prim::GetAttr[name="training"](%2292)
      %2309 : Tensor = prim::GetAttr[name="running_mean"](%2292)
      %2310 : Tensor = prim::GetAttr[name="running_var"](%2292)
      %2311 : Tensor = prim::GetAttr[name="weight"](%2292)
      %2312 : Tensor = prim::GetAttr[name="bias"](%2292)
       = prim::If(%2308) # torch/nn/functional.py:2011:4
        block0():
          %2313 : int[] = aten::size(%input.128) # torch/nn/functional.py:2012:27
          %size_prods.176 : int = aten::__getitem__(%2313, %10) # torch/nn/functional.py:1991:17
          %2315 : int = aten::len(%2313) # torch/nn/functional.py:1992:19
          %2316 : int = aten::sub(%2315, %16) # torch/nn/functional.py:1992:19
          %size_prods.177 : int = prim::Loop(%2316, %9, %size_prods.176) # torch/nn/functional.py:1992:4
            block0(%i.45 : int, %size_prods.178 : int):
              %2320 : int = aten::add(%i.45, %16) # torch/nn/functional.py:1993:27
              %2321 : int = aten::__getitem__(%2313, %2320) # torch/nn/functional.py:1993:22
              %size_prods.179 : int = aten::mul(%size_prods.178, %2321) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.179)
          %2323 : bool = aten::eq(%size_prods.177, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2323) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.129 : Tensor = aten::batch_norm(%input.128, %2311, %2312, %2309, %2310, %2308, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.130 : Tensor = aten::relu_(%input.129) # torch/nn/functional.py:1117:17
      %2326 : Tensor = prim::GetAttr[name="weight"](%2293)
      %2327 : Tensor? = prim::GetAttr[name="bias"](%2293)
      %2328 : int[] = prim::ListConstruct(%8, %8)
      %2329 : int[] = prim::ListConstruct(%8, %8)
      %2330 : int[] = prim::ListConstruct(%8, %8)
      %input.131 : Tensor = aten::conv2d(%input.130, %2326, %2327, %2328, %2329, %2330, %4) # torch/nn/modules/conv.py:415:15
      %2332 : int = aten::dim(%input.131) # torch/nn/modules/batchnorm.py:276:11
      %2333 : bool = aten::ne(%2332, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2333) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2334 : bool = prim::GetAttr[name="training"](%2294)
       = prim::If(%2334) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2335 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2294)
          %2336 : Tensor = aten::add(%2335, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2294, %2336)
          -> ()
        block1():
          -> ()
      %2337 : bool = prim::GetAttr[name="training"](%2294)
      %2338 : Tensor = prim::GetAttr[name="running_mean"](%2294)
      %2339 : Tensor = prim::GetAttr[name="running_var"](%2294)
      %2340 : Tensor = prim::GetAttr[name="weight"](%2294)
      %2341 : Tensor = prim::GetAttr[name="bias"](%2294)
       = prim::If(%2337) # torch/nn/functional.py:2011:4
        block0():
          %2342 : int[] = aten::size(%input.131) # torch/nn/functional.py:2012:27
          %size_prods.180 : int = aten::__getitem__(%2342, %10) # torch/nn/functional.py:1991:17
          %2344 : int = aten::len(%2342) # torch/nn/functional.py:1992:19
          %2345 : int = aten::sub(%2344, %16) # torch/nn/functional.py:1992:19
          %size_prods.181 : int = prim::Loop(%2345, %9, %size_prods.180) # torch/nn/functional.py:1992:4
            block0(%i.46 : int, %size_prods.182 : int):
              %2349 : int = aten::add(%i.46, %16) # torch/nn/functional.py:1993:27
              %2350 : int = aten::__getitem__(%2342, %2349) # torch/nn/functional.py:1993:22
              %size_prods.183 : int = aten::mul(%size_prods.182, %2350) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.183)
          %2352 : bool = aten::eq(%size_prods.181, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2352) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.132 : Tensor = aten::batch_norm(%input.131, %2340, %2341, %2338, %2339, %2337, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2354 : Tensor = prim::GetAttr[name="weight"](%2295)
      %2355 : Tensor? = prim::GetAttr[name="bias"](%2295)
      %2356 : int[] = prim::ListConstruct(%8, %8)
      %2357 : int[] = prim::ListConstruct(%10, %10)
      %2358 : int[] = prim::ListConstruct(%8, %8)
      %input.133 : Tensor = aten::conv2d(%input.132, %2354, %2355, %2356, %2357, %2358, %8) # torch/nn/modules/conv.py:415:15
      %2360 : int = aten::dim(%input.133) # torch/nn/modules/batchnorm.py:276:11
      %2361 : bool = aten::ne(%2360, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2361) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2362 : bool = prim::GetAttr[name="training"](%2296)
       = prim::If(%2362) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2363 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2296)
          %2364 : Tensor = aten::add(%2363, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2296, %2364)
          -> ()
        block1():
          -> ()
      %2365 : bool = prim::GetAttr[name="training"](%2296)
      %2366 : Tensor = prim::GetAttr[name="running_mean"](%2296)
      %2367 : Tensor = prim::GetAttr[name="running_var"](%2296)
      %2368 : Tensor = prim::GetAttr[name="weight"](%2296)
      %2369 : Tensor = prim::GetAttr[name="bias"](%2296)
       = prim::If(%2365) # torch/nn/functional.py:2011:4
        block0():
          %2370 : int[] = aten::size(%input.133) # torch/nn/functional.py:2012:27
          %size_prods.184 : int = aten::__getitem__(%2370, %10) # torch/nn/functional.py:1991:17
          %2372 : int = aten::len(%2370) # torch/nn/functional.py:1992:19
          %2373 : int = aten::sub(%2372, %16) # torch/nn/functional.py:1992:19
          %size_prods.185 : int = prim::Loop(%2373, %9, %size_prods.184) # torch/nn/functional.py:1992:4
            block0(%i.47 : int, %size_prods.186 : int):
              %2377 : int = aten::add(%i.47, %16) # torch/nn/functional.py:1993:27
              %2378 : int = aten::__getitem__(%2370, %2377) # torch/nn/functional.py:1993:22
              %size_prods.187 : int = aten::mul(%size_prods.186, %2378) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.187)
          %2380 : bool = aten::eq(%size_prods.185, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2380) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.134 : Tensor = aten::batch_norm(%input.133, %2368, %2369, %2366, %2367, %2365, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.135 : Tensor = aten::relu_(%input.134) # torch/nn/functional.py:1117:17
      %2383 : Tensor[] = prim::ListConstruct(%x1.8, %input.135)
      %out.22 : Tensor = aten::cat(%2383, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.22)
    block1():
      %2385 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%966)
      %2386 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%2385)
      %2387 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%2385)
      %2388 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%2385)
      %2389 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%2385)
      %2390 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%2385)
      %2391 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%2385)
      %2392 : Tensor = prim::GetAttr[name="weight"](%2386)
      %2393 : Tensor? = prim::GetAttr[name="bias"](%2386)
      %2394 : int[] = prim::ListConstruct(%8, %8)
      %2395 : int[] = prim::ListConstruct(%10, %10)
      %2396 : int[] = prim::ListConstruct(%8, %8)
      %input.136 : Tensor = aten::conv2d(%input.218, %2392, %2393, %2394, %2395, %2396, %8) # torch/nn/modules/conv.py:415:15
      %2398 : int = aten::dim(%input.136) # torch/nn/modules/batchnorm.py:276:11
      %2399 : bool = aten::ne(%2398, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2399) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2400 : bool = prim::GetAttr[name="training"](%2387)
       = prim::If(%2400) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2401 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2387)
          %2402 : Tensor = aten::add(%2401, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2387, %2402)
          -> ()
        block1():
          -> ()
      %2403 : bool = prim::GetAttr[name="training"](%2387)
      %2404 : Tensor = prim::GetAttr[name="running_mean"](%2387)
      %2405 : Tensor = prim::GetAttr[name="running_var"](%2387)
      %2406 : Tensor = prim::GetAttr[name="weight"](%2387)
      %2407 : Tensor = prim::GetAttr[name="bias"](%2387)
       = prim::If(%2403) # torch/nn/functional.py:2011:4
        block0():
          %2408 : int[] = aten::size(%input.136) # torch/nn/functional.py:2012:27
          %size_prods.188 : int = aten::__getitem__(%2408, %10) # torch/nn/functional.py:1991:17
          %2410 : int = aten::len(%2408) # torch/nn/functional.py:1992:19
          %2411 : int = aten::sub(%2410, %16) # torch/nn/functional.py:1992:19
          %size_prods.189 : int = prim::Loop(%2411, %9, %size_prods.188) # torch/nn/functional.py:1992:4
            block0(%i.48 : int, %size_prods.190 : int):
              %2415 : int = aten::add(%i.48, %16) # torch/nn/functional.py:1993:27
              %2416 : int = aten::__getitem__(%2408, %2415) # torch/nn/functional.py:1993:22
              %size_prods.191 : int = aten::mul(%size_prods.190, %2416) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.191)
          %2418 : bool = aten::eq(%size_prods.189, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2418) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.137 : Tensor = aten::batch_norm(%input.136, %2406, %2407, %2404, %2405, %2403, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.138 : Tensor = aten::relu_(%input.137) # torch/nn/functional.py:1117:17
      %2421 : Tensor = prim::GetAttr[name="weight"](%2388)
      %2422 : Tensor? = prim::GetAttr[name="bias"](%2388)
      %2423 : int[] = prim::ListConstruct(%8, %8)
      %2424 : int[] = prim::ListConstruct(%8, %8)
      %2425 : int[] = prim::ListConstruct(%8, %8)
      %input.139 : Tensor = aten::conv2d(%input.138, %2421, %2422, %2423, %2424, %2425, %4) # torch/nn/modules/conv.py:415:15
      %2427 : int = aten::dim(%input.139) # torch/nn/modules/batchnorm.py:276:11
      %2428 : bool = aten::ne(%2427, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2428) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2429 : bool = prim::GetAttr[name="training"](%2389)
       = prim::If(%2429) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2430 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2389)
          %2431 : Tensor = aten::add(%2430, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2389, %2431)
          -> ()
        block1():
          -> ()
      %2432 : bool = prim::GetAttr[name="training"](%2389)
      %2433 : Tensor = prim::GetAttr[name="running_mean"](%2389)
      %2434 : Tensor = prim::GetAttr[name="running_var"](%2389)
      %2435 : Tensor = prim::GetAttr[name="weight"](%2389)
      %2436 : Tensor = prim::GetAttr[name="bias"](%2389)
       = prim::If(%2432) # torch/nn/functional.py:2011:4
        block0():
          %2437 : int[] = aten::size(%input.139) # torch/nn/functional.py:2012:27
          %size_prods.192 : int = aten::__getitem__(%2437, %10) # torch/nn/functional.py:1991:17
          %2439 : int = aten::len(%2437) # torch/nn/functional.py:1992:19
          %2440 : int = aten::sub(%2439, %16) # torch/nn/functional.py:1992:19
          %size_prods.193 : int = prim::Loop(%2440, %9, %size_prods.192) # torch/nn/functional.py:1992:4
            block0(%i.49 : int, %size_prods.194 : int):
              %2444 : int = aten::add(%i.49, %16) # torch/nn/functional.py:1993:27
              %2445 : int = aten::__getitem__(%2437, %2444) # torch/nn/functional.py:1993:22
              %size_prods.195 : int = aten::mul(%size_prods.194, %2445) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.195)
          %2447 : bool = aten::eq(%size_prods.193, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2447) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.140 : Tensor = aten::batch_norm(%input.139, %2435, %2436, %2433, %2434, %2432, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2449 : Tensor = prim::GetAttr[name="weight"](%2390)
      %2450 : Tensor? = prim::GetAttr[name="bias"](%2390)
      %2451 : int[] = prim::ListConstruct(%8, %8)
      %2452 : int[] = prim::ListConstruct(%10, %10)
      %2453 : int[] = prim::ListConstruct(%8, %8)
      %input.141 : Tensor = aten::conv2d(%input.140, %2449, %2450, %2451, %2452, %2453, %8) # torch/nn/modules/conv.py:415:15
      %2455 : int = aten::dim(%input.141) # torch/nn/modules/batchnorm.py:276:11
      %2456 : bool = aten::ne(%2455, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2456) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2457 : bool = prim::GetAttr[name="training"](%2391)
       = prim::If(%2457) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2458 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2391)
          %2459 : Tensor = aten::add(%2458, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2391, %2459)
          -> ()
        block1():
          -> ()
      %2460 : bool = prim::GetAttr[name="training"](%2391)
      %2461 : Tensor = prim::GetAttr[name="running_mean"](%2391)
      %2462 : Tensor = prim::GetAttr[name="running_var"](%2391)
      %2463 : Tensor = prim::GetAttr[name="weight"](%2391)
      %2464 : Tensor = prim::GetAttr[name="bias"](%2391)
       = prim::If(%2460) # torch/nn/functional.py:2011:4
        block0():
          %2465 : int[] = aten::size(%input.141) # torch/nn/functional.py:2012:27
          %size_prods.196 : int = aten::__getitem__(%2465, %10) # torch/nn/functional.py:1991:17
          %2467 : int = aten::len(%2465) # torch/nn/functional.py:1992:19
          %2468 : int = aten::sub(%2467, %16) # torch/nn/functional.py:1992:19
          %size_prods.197 : int = prim::Loop(%2468, %9, %size_prods.196) # torch/nn/functional.py:1992:4
            block0(%i.50 : int, %size_prods.198 : int):
              %2472 : int = aten::add(%i.50, %16) # torch/nn/functional.py:1993:27
              %2473 : int = aten::__getitem__(%2465, %2472) # torch/nn/functional.py:1993:22
              %size_prods.199 : int = aten::mul(%size_prods.198, %2473) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.199)
          %2475 : bool = aten::eq(%size_prods.197, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2475) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.142 : Tensor = aten::batch_norm(%input.141, %2463, %2464, %2461, %2462, %2460, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.143 : Tensor = aten::relu_(%input.142) # torch/nn/functional.py:1117:17
      %2478 : Tensor[] = prim::ListConstruct(%input.218, %input.143)
      %out.23 : Tensor = aten::cat(%2478, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.23)
  %2480 : Tensor = prim::data(%out.24)
  %2481 : int[] = aten::size(%2480) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.8 : int, %num_channels.8 : int, %height.8 : int, %width.8 : int = prim::ListUnpack(%2481)
  %channels_per_group.8 : int = aten::floordiv(%num_channels.8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2487 : int[] = prim::ListConstruct(%batchsize.8, %16, %channels_per_group.8, %height.8, %width.8)
  %x.18 : Tensor = aten::view(%out.24, %2487) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2489 : Tensor = aten::transpose(%x.18, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.19 : Tensor = aten::contiguous(%2489, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2491 : int[] = prim::ListConstruct(%batchsize.8, %5, %height.8, %width.8)
  %input.219 : Tensor = aten::view(%x.19, %2491) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2493 : int = prim::GetAttr[name="stride"](%967)
  %2494 : bool = aten::eq(%2493, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.45 : Tensor = prim::If(%2494) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2496 : Tensor[] = aten::chunk(%input.219, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.16 : Tensor, %x2.16 : Tensor = prim::ListUnpack(%2496)
      %2499 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%967)
      %2500 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%2499)
      %2501 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%2499)
      %2502 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%2499)
      %2503 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%2499)
      %2504 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%2499)
      %2505 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%2499)
      %2506 : Tensor = prim::GetAttr[name="weight"](%2500)
      %2507 : Tensor? = prim::GetAttr[name="bias"](%2500)
      %2508 : int[] = prim::ListConstruct(%8, %8)
      %2509 : int[] = prim::ListConstruct(%10, %10)
      %2510 : int[] = prim::ListConstruct(%8, %8)
      %input.273 : Tensor = aten::conv2d(%x2.16, %2506, %2507, %2508, %2509, %2510, %8) # torch/nn/modules/conv.py:415:15
      %2512 : int = aten::dim(%input.273) # torch/nn/modules/batchnorm.py:276:11
      %2513 : bool = aten::ne(%2512, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2513) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2514 : bool = prim::GetAttr[name="training"](%2501)
       = prim::If(%2514) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2515 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2501)
          %2516 : Tensor = aten::add(%2515, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2501, %2516)
          -> ()
        block1():
          -> ()
      %2517 : bool = prim::GetAttr[name="training"](%2501)
      %2518 : Tensor = prim::GetAttr[name="running_mean"](%2501)
      %2519 : Tensor = prim::GetAttr[name="running_var"](%2501)
      %2520 : Tensor = prim::GetAttr[name="weight"](%2501)
      %2521 : Tensor = prim::GetAttr[name="bias"](%2501)
       = prim::If(%2517) # torch/nn/functional.py:2011:4
        block0():
          %2522 : int[] = aten::size(%input.273) # torch/nn/functional.py:2012:27
          %size_prods.388 : int = aten::__getitem__(%2522, %10) # torch/nn/functional.py:1991:17
          %2524 : int = aten::len(%2522) # torch/nn/functional.py:1992:19
          %2525 : int = aten::sub(%2524, %16) # torch/nn/functional.py:1992:19
          %size_prods.389 : int = prim::Loop(%2525, %9, %size_prods.388) # torch/nn/functional.py:1992:4
            block0(%i.98 : int, %size_prods.390 : int):
              %2529 : int = aten::add(%i.98, %16) # torch/nn/functional.py:1993:27
              %2530 : int = aten::__getitem__(%2522, %2529) # torch/nn/functional.py:1993:22
              %size_prods.391 : int = aten::mul(%size_prods.390, %2530) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.391)
          %2532 : bool = aten::eq(%size_prods.389, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2532) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.274 : Tensor = aten::batch_norm(%input.273, %2520, %2521, %2518, %2519, %2517, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.275 : Tensor = aten::relu_(%input.274) # torch/nn/functional.py:1117:17
      %2535 : Tensor = prim::GetAttr[name="weight"](%2502)
      %2536 : Tensor? = prim::GetAttr[name="bias"](%2502)
      %2537 : int[] = prim::ListConstruct(%8, %8)
      %2538 : int[] = prim::ListConstruct(%8, %8)
      %2539 : int[] = prim::ListConstruct(%8, %8)
      %input.276 : Tensor = aten::conv2d(%input.275, %2535, %2536, %2537, %2538, %2539, %4) # torch/nn/modules/conv.py:415:15
      %2541 : int = aten::dim(%input.276) # torch/nn/modules/batchnorm.py:276:11
      %2542 : bool = aten::ne(%2541, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2542) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2543 : bool = prim::GetAttr[name="training"](%2503)
       = prim::If(%2543) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2544 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2503)
          %2545 : Tensor = aten::add(%2544, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2503, %2545)
          -> ()
        block1():
          -> ()
      %2546 : bool = prim::GetAttr[name="training"](%2503)
      %2547 : Tensor = prim::GetAttr[name="running_mean"](%2503)
      %2548 : Tensor = prim::GetAttr[name="running_var"](%2503)
      %2549 : Tensor = prim::GetAttr[name="weight"](%2503)
      %2550 : Tensor = prim::GetAttr[name="bias"](%2503)
       = prim::If(%2546) # torch/nn/functional.py:2011:4
        block0():
          %2551 : int[] = aten::size(%input.276) # torch/nn/functional.py:2012:27
          %size_prods.392 : int = aten::__getitem__(%2551, %10) # torch/nn/functional.py:1991:17
          %2553 : int = aten::len(%2551) # torch/nn/functional.py:1992:19
          %2554 : int = aten::sub(%2553, %16) # torch/nn/functional.py:1992:19
          %size_prods.393 : int = prim::Loop(%2554, %9, %size_prods.392) # torch/nn/functional.py:1992:4
            block0(%i.99 : int, %size_prods.394 : int):
              %2558 : int = aten::add(%i.99, %16) # torch/nn/functional.py:1993:27
              %2559 : int = aten::__getitem__(%2551, %2558) # torch/nn/functional.py:1993:22
              %size_prods.395 : int = aten::mul(%size_prods.394, %2559) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.395)
          %2561 : bool = aten::eq(%size_prods.393, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2561) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.277 : Tensor = aten::batch_norm(%input.276, %2549, %2550, %2547, %2548, %2546, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2563 : Tensor = prim::GetAttr[name="weight"](%2504)
      %2564 : Tensor? = prim::GetAttr[name="bias"](%2504)
      %2565 : int[] = prim::ListConstruct(%8, %8)
      %2566 : int[] = prim::ListConstruct(%10, %10)
      %2567 : int[] = prim::ListConstruct(%8, %8)
      %input.278 : Tensor = aten::conv2d(%input.277, %2563, %2564, %2565, %2566, %2567, %8) # torch/nn/modules/conv.py:415:15
      %2569 : int = aten::dim(%input.278) # torch/nn/modules/batchnorm.py:276:11
      %2570 : bool = aten::ne(%2569, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2570) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2571 : bool = prim::GetAttr[name="training"](%2505)
       = prim::If(%2571) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2572 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2505)
          %2573 : Tensor = aten::add(%2572, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2505, %2573)
          -> ()
        block1():
          -> ()
      %2574 : bool = prim::GetAttr[name="training"](%2505)
      %2575 : Tensor = prim::GetAttr[name="running_mean"](%2505)
      %2576 : Tensor = prim::GetAttr[name="running_var"](%2505)
      %2577 : Tensor = prim::GetAttr[name="weight"](%2505)
      %2578 : Tensor = prim::GetAttr[name="bias"](%2505)
       = prim::If(%2574) # torch/nn/functional.py:2011:4
        block0():
          %2579 : int[] = aten::size(%input.278) # torch/nn/functional.py:2012:27
          %size_prods.396 : int = aten::__getitem__(%2579, %10) # torch/nn/functional.py:1991:17
          %2581 : int = aten::len(%2579) # torch/nn/functional.py:1992:19
          %2582 : int = aten::sub(%2581, %16) # torch/nn/functional.py:1992:19
          %size_prods.397 : int = prim::Loop(%2582, %9, %size_prods.396) # torch/nn/functional.py:1992:4
            block0(%i.100 : int, %size_prods.398 : int):
              %2586 : int = aten::add(%i.100, %16) # torch/nn/functional.py:1993:27
              %2587 : int = aten::__getitem__(%2579, %2586) # torch/nn/functional.py:1993:22
              %size_prods.399 : int = aten::mul(%size_prods.398, %2587) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.399)
          %2589 : bool = aten::eq(%size_prods.397, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2589) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.279 : Tensor = aten::batch_norm(%input.278, %2577, %2578, %2575, %2576, %2574, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.280 : Tensor = aten::relu_(%input.279) # torch/nn/functional.py:1117:17
      %2592 : Tensor[] = prim::ListConstruct(%x1.16, %input.280)
      %out.46 : Tensor = aten::cat(%2592, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.46)
    block1():
      %2594 : __torch__.torch.nn.modules.container.___torch_mangle_1065.Sequential = prim::GetAttr[name="branch2"](%967)
      %2595 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="0"](%2594)
      %2596 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="1"](%2594)
      %2597 : __torch__.torch.nn.modules.conv.___torch_mangle_1064.Conv2d = prim::GetAttr[name="3"](%2594)
      %2598 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="4"](%2594)
      %2599 : __torch__.torch.nn.modules.conv.___torch_mangle_1060.Conv2d = prim::GetAttr[name="5"](%2594)
      %2600 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1059.BatchNorm2d = prim::GetAttr[name="6"](%2594)
      %2601 : Tensor = prim::GetAttr[name="weight"](%2595)
      %2602 : Tensor? = prim::GetAttr[name="bias"](%2595)
      %2603 : int[] = prim::ListConstruct(%8, %8)
      %2604 : int[] = prim::ListConstruct(%10, %10)
      %2605 : int[] = prim::ListConstruct(%8, %8)
      %input.281 : Tensor = aten::conv2d(%input.219, %2601, %2602, %2603, %2604, %2605, %8) # torch/nn/modules/conv.py:415:15
      %2607 : int = aten::dim(%input.281) # torch/nn/modules/batchnorm.py:276:11
      %2608 : bool = aten::ne(%2607, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2608) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2609 : bool = prim::GetAttr[name="training"](%2596)
       = prim::If(%2609) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2610 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2596)
          %2611 : Tensor = aten::add(%2610, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2596, %2611)
          -> ()
        block1():
          -> ()
      %2612 : bool = prim::GetAttr[name="training"](%2596)
      %2613 : Tensor = prim::GetAttr[name="running_mean"](%2596)
      %2614 : Tensor = prim::GetAttr[name="running_var"](%2596)
      %2615 : Tensor = prim::GetAttr[name="weight"](%2596)
      %2616 : Tensor = prim::GetAttr[name="bias"](%2596)
       = prim::If(%2612) # torch/nn/functional.py:2011:4
        block0():
          %2617 : int[] = aten::size(%input.281) # torch/nn/functional.py:2012:27
          %size_prods.400 : int = aten::__getitem__(%2617, %10) # torch/nn/functional.py:1991:17
          %2619 : int = aten::len(%2617) # torch/nn/functional.py:1992:19
          %2620 : int = aten::sub(%2619, %16) # torch/nn/functional.py:1992:19
          %size_prods.401 : int = prim::Loop(%2620, %9, %size_prods.400) # torch/nn/functional.py:1992:4
            block0(%i.101 : int, %size_prods.402 : int):
              %2624 : int = aten::add(%i.101, %16) # torch/nn/functional.py:1993:27
              %2625 : int = aten::__getitem__(%2617, %2624) # torch/nn/functional.py:1993:22
              %size_prods.403 : int = aten::mul(%size_prods.402, %2625) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.403)
          %2627 : bool = aten::eq(%size_prods.401, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2627) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.282 : Tensor = aten::batch_norm(%input.281, %2615, %2616, %2613, %2614, %2612, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.283 : Tensor = aten::relu_(%input.282) # torch/nn/functional.py:1117:17
      %2630 : Tensor = prim::GetAttr[name="weight"](%2597)
      %2631 : Tensor? = prim::GetAttr[name="bias"](%2597)
      %2632 : int[] = prim::ListConstruct(%8, %8)
      %2633 : int[] = prim::ListConstruct(%8, %8)
      %2634 : int[] = prim::ListConstruct(%8, %8)
      %input.284 : Tensor = aten::conv2d(%input.283, %2630, %2631, %2632, %2633, %2634, %4) # torch/nn/modules/conv.py:415:15
      %2636 : int = aten::dim(%input.284) # torch/nn/modules/batchnorm.py:276:11
      %2637 : bool = aten::ne(%2636, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2637) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2638 : bool = prim::GetAttr[name="training"](%2598)
       = prim::If(%2638) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2639 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2598)
          %2640 : Tensor = aten::add(%2639, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2598, %2640)
          -> ()
        block1():
          -> ()
      %2641 : bool = prim::GetAttr[name="training"](%2598)
      %2642 : Tensor = prim::GetAttr[name="running_mean"](%2598)
      %2643 : Tensor = prim::GetAttr[name="running_var"](%2598)
      %2644 : Tensor = prim::GetAttr[name="weight"](%2598)
      %2645 : Tensor = prim::GetAttr[name="bias"](%2598)
       = prim::If(%2641) # torch/nn/functional.py:2011:4
        block0():
          %2646 : int[] = aten::size(%input.284) # torch/nn/functional.py:2012:27
          %size_prods.404 : int = aten::__getitem__(%2646, %10) # torch/nn/functional.py:1991:17
          %2648 : int = aten::len(%2646) # torch/nn/functional.py:1992:19
          %2649 : int = aten::sub(%2648, %16) # torch/nn/functional.py:1992:19
          %size_prods.405 : int = prim::Loop(%2649, %9, %size_prods.404) # torch/nn/functional.py:1992:4
            block0(%i.102 : int, %size_prods.406 : int):
              %2653 : int = aten::add(%i.102, %16) # torch/nn/functional.py:1993:27
              %2654 : int = aten::__getitem__(%2646, %2653) # torch/nn/functional.py:1993:22
              %size_prods.407 : int = aten::mul(%size_prods.406, %2654) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.407)
          %2656 : bool = aten::eq(%size_prods.405, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2656) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.285 : Tensor = aten::batch_norm(%input.284, %2644, %2645, %2642, %2643, %2641, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2658 : Tensor = prim::GetAttr[name="weight"](%2599)
      %2659 : Tensor? = prim::GetAttr[name="bias"](%2599)
      %2660 : int[] = prim::ListConstruct(%8, %8)
      %2661 : int[] = prim::ListConstruct(%10, %10)
      %2662 : int[] = prim::ListConstruct(%8, %8)
      %input.286 : Tensor = aten::conv2d(%input.285, %2658, %2659, %2660, %2661, %2662, %8) # torch/nn/modules/conv.py:415:15
      %2664 : int = aten::dim(%input.286) # torch/nn/modules/batchnorm.py:276:11
      %2665 : bool = aten::ne(%2664, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2665) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2666 : bool = prim::GetAttr[name="training"](%2600)
       = prim::If(%2666) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2667 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2600)
          %2668 : Tensor = aten::add(%2667, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2600, %2668)
          -> ()
        block1():
          -> ()
      %2669 : bool = prim::GetAttr[name="training"](%2600)
      %2670 : Tensor = prim::GetAttr[name="running_mean"](%2600)
      %2671 : Tensor = prim::GetAttr[name="running_var"](%2600)
      %2672 : Tensor = prim::GetAttr[name="weight"](%2600)
      %2673 : Tensor = prim::GetAttr[name="bias"](%2600)
       = prim::If(%2669) # torch/nn/functional.py:2011:4
        block0():
          %2674 : int[] = aten::size(%input.286) # torch/nn/functional.py:2012:27
          %size_prods.408 : int = aten::__getitem__(%2674, %10) # torch/nn/functional.py:1991:17
          %2676 : int = aten::len(%2674) # torch/nn/functional.py:1992:19
          %2677 : int = aten::sub(%2676, %16) # torch/nn/functional.py:1992:19
          %size_prods.409 : int = prim::Loop(%2677, %9, %size_prods.408) # torch/nn/functional.py:1992:4
            block0(%i.103 : int, %size_prods.410 : int):
              %2681 : int = aten::add(%i.103, %16) # torch/nn/functional.py:1993:27
              %2682 : int = aten::__getitem__(%2674, %2681) # torch/nn/functional.py:1993:22
              %size_prods.411 : int = aten::mul(%size_prods.410, %2682) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.411)
          %2684 : bool = aten::eq(%size_prods.409, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2684) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.287 : Tensor = aten::batch_norm(%input.286, %2672, %2673, %2670, %2671, %2669, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.288 : Tensor = aten::relu_(%input.287) # torch/nn/functional.py:1117:17
      %2687 : Tensor[] = prim::ListConstruct(%input.219, %input.288)
      %out.47 : Tensor = aten::cat(%2687, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.47)
  %2689 : Tensor = prim::data(%out.45)
  %2690 : int[] = aten::size(%2689) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.16 : int, %num_channels.16 : int, %height.16 : int, %width.16 : int = prim::ListUnpack(%2690)
  %channels_per_group.16 : int = aten::floordiv(%num_channels.16, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2696 : int[] = prim::ListConstruct(%batchsize.16, %16, %channels_per_group.16, %height.16, %width.16)
  %x.41 : Tensor = aten::view(%out.45, %2696) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2698 : Tensor = aten::transpose(%x.41, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.42 : Tensor = aten::contiguous(%2698, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2700 : int[] = prim::ListConstruct(%batchsize.16, %5, %height.16, %width.16)
  %x.25 : Tensor = aten::view(%x.42, %2700) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2702 : __torch__.torch.nn.modules.container.___torch_mangle_1077.Sequential = prim::GetAttr[name="stage4"](%self)
  %2703 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1073.InvertedResidual = prim::GetAttr[name="0"](%2702)
  %2704 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1076.InvertedResidual = prim::GetAttr[name="1"](%2702)
  %2705 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1076.InvertedResidual = prim::GetAttr[name="2"](%2702)
  %2706 : __torch__.torchvision.models.shufflenetv2.___torch_mangle_1076.InvertedResidual = prim::GetAttr[name="3"](%2702)
  %2707 : int = prim::GetAttr[name="stride"](%2703)
  %2708 : bool = aten::eq(%2707, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.3 : Tensor = prim::If(%2708) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2710 : Tensor[] = aten::chunk(%x.25, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.2 : Tensor, %x2.2 : Tensor = prim::ListUnpack(%2710)
      %2713 : __torch__.torch.nn.modules.container.___torch_mangle_1072.Sequential = prim::GetAttr[name="branch2"](%2703)
      %2714 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="0"](%2713)
      %2715 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="1"](%2713)
      %2716 : __torch__.torch.nn.modules.conv.___torch_mangle_1068.Conv2d = prim::GetAttr[name="3"](%2713)
      %2717 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="4"](%2713)
      %2718 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="5"](%2713)
      %2719 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="6"](%2713)
      %2720 : Tensor = prim::GetAttr[name="weight"](%2714)
      %2721 : Tensor? = prim::GetAttr[name="bias"](%2714)
      %2722 : int[] = prim::ListConstruct(%8, %8)
      %2723 : int[] = prim::ListConstruct(%10, %10)
      %2724 : int[] = prim::ListConstruct(%8, %8)
      %input.28 : Tensor = aten::conv2d(%x2.2, %2720, %2721, %2722, %2723, %2724, %8) # torch/nn/modules/conv.py:415:15
      %2726 : int = aten::dim(%input.28) # torch/nn/modules/batchnorm.py:276:11
      %2727 : bool = aten::ne(%2726, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2727) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2728 : bool = prim::GetAttr[name="training"](%2715)
       = prim::If(%2728) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2729 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2715)
          %2730 : Tensor = aten::add(%2729, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2715, %2730)
          -> ()
        block1():
          -> ()
      %2731 : bool = prim::GetAttr[name="training"](%2715)
      %2732 : Tensor = prim::GetAttr[name="running_mean"](%2715)
      %2733 : Tensor = prim::GetAttr[name="running_var"](%2715)
      %2734 : Tensor = prim::GetAttr[name="weight"](%2715)
      %2735 : Tensor = prim::GetAttr[name="bias"](%2715)
       = prim::If(%2731) # torch/nn/functional.py:2011:4
        block0():
          %2736 : int[] = aten::size(%input.28) # torch/nn/functional.py:2012:27
          %size_prods.32 : int = aten::__getitem__(%2736, %10) # torch/nn/functional.py:1991:17
          %2738 : int = aten::len(%2736) # torch/nn/functional.py:1992:19
          %2739 : int = aten::sub(%2738, %16) # torch/nn/functional.py:1992:19
          %size_prods.33 : int = prim::Loop(%2739, %9, %size_prods.32) # torch/nn/functional.py:1992:4
            block0(%i.9 : int, %size_prods.34 : int):
              %2743 : int = aten::add(%i.9, %16) # torch/nn/functional.py:1993:27
              %2744 : int = aten::__getitem__(%2736, %2743) # torch/nn/functional.py:1993:22
              %size_prods.35 : int = aten::mul(%size_prods.34, %2744) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.35)
          %2746 : bool = aten::eq(%size_prods.33, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2746) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.29 : Tensor = aten::batch_norm(%input.28, %2734, %2735, %2732, %2733, %2731, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.30 : Tensor = aten::relu_(%input.29) # torch/nn/functional.py:1117:17
      %2749 : Tensor = prim::GetAttr[name="weight"](%2716)
      %2750 : Tensor? = prim::GetAttr[name="bias"](%2716)
      %2751 : int[] = prim::ListConstruct(%16, %16)
      %2752 : int[] = prim::ListConstruct(%8, %8)
      %2753 : int[] = prim::ListConstruct(%8, %8)
      %input.31 : Tensor = aten::conv2d(%input.30, %2749, %2750, %2751, %2752, %2753, %3) # torch/nn/modules/conv.py:415:15
      %2755 : int = aten::dim(%input.31) # torch/nn/modules/batchnorm.py:276:11
      %2756 : bool = aten::ne(%2755, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2756) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2757 : bool = prim::GetAttr[name="training"](%2717)
       = prim::If(%2757) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2758 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2717)
          %2759 : Tensor = aten::add(%2758, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2717, %2759)
          -> ()
        block1():
          -> ()
      %2760 : bool = prim::GetAttr[name="training"](%2717)
      %2761 : Tensor = prim::GetAttr[name="running_mean"](%2717)
      %2762 : Tensor = prim::GetAttr[name="running_var"](%2717)
      %2763 : Tensor = prim::GetAttr[name="weight"](%2717)
      %2764 : Tensor = prim::GetAttr[name="bias"](%2717)
       = prim::If(%2760) # torch/nn/functional.py:2011:4
        block0():
          %2765 : int[] = aten::size(%input.31) # torch/nn/functional.py:2012:27
          %size_prods.24 : int = aten::__getitem__(%2765, %10) # torch/nn/functional.py:1991:17
          %2767 : int = aten::len(%2765) # torch/nn/functional.py:1992:19
          %2768 : int = aten::sub(%2767, %16) # torch/nn/functional.py:1992:19
          %size_prods.25 : int = prim::Loop(%2768, %9, %size_prods.24) # torch/nn/functional.py:1992:4
            block0(%i.7 : int, %size_prods.26 : int):
              %2772 : int = aten::add(%i.7, %16) # torch/nn/functional.py:1993:27
              %2773 : int = aten::__getitem__(%2765, %2772) # torch/nn/functional.py:1993:22
              %size_prods.27 : int = aten::mul(%size_prods.26, %2773) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.27)
          %2775 : bool = aten::eq(%size_prods.25, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2775) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.32 : Tensor = aten::batch_norm(%input.31, %2763, %2764, %2761, %2762, %2760, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2777 : Tensor = prim::GetAttr[name="weight"](%2718)
      %2778 : Tensor? = prim::GetAttr[name="bias"](%2718)
      %2779 : int[] = prim::ListConstruct(%8, %8)
      %2780 : int[] = prim::ListConstruct(%10, %10)
      %2781 : int[] = prim::ListConstruct(%8, %8)
      %input.21 : Tensor = aten::conv2d(%input.32, %2777, %2778, %2779, %2780, %2781, %8) # torch/nn/modules/conv.py:415:15
      %2783 : int = aten::dim(%input.21) # torch/nn/modules/batchnorm.py:276:11
      %2784 : bool = aten::ne(%2783, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2784) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2785 : bool = prim::GetAttr[name="training"](%2719)
       = prim::If(%2785) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2786 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2719)
          %2787 : Tensor = aten::add(%2786, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2719, %2787)
          -> ()
        block1():
          -> ()
      %2788 : bool = prim::GetAttr[name="training"](%2719)
      %2789 : Tensor = prim::GetAttr[name="running_mean"](%2719)
      %2790 : Tensor = prim::GetAttr[name="running_var"](%2719)
      %2791 : Tensor = prim::GetAttr[name="weight"](%2719)
      %2792 : Tensor = prim::GetAttr[name="bias"](%2719)
       = prim::If(%2788) # torch/nn/functional.py:2011:4
        block0():
          %2793 : int[] = aten::size(%input.21) # torch/nn/functional.py:2012:27
          %size_prods.36 : int = aten::__getitem__(%2793, %10) # torch/nn/functional.py:1991:17
          %2795 : int = aten::len(%2793) # torch/nn/functional.py:1992:19
          %2796 : int = aten::sub(%2795, %16) # torch/nn/functional.py:1992:19
          %size_prods.37 : int = prim::Loop(%2796, %9, %size_prods.36) # torch/nn/functional.py:1992:4
            block0(%i.10 : int, %size_prods.38 : int):
              %2800 : int = aten::add(%i.10, %16) # torch/nn/functional.py:1993:27
              %2801 : int = aten::__getitem__(%2793, %2800) # torch/nn/functional.py:1993:22
              %size_prods.39 : int = aten::mul(%size_prods.38, %2801) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.39)
          %2803 : bool = aten::eq(%size_prods.37, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2803) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.22 : Tensor = aten::batch_norm(%input.21, %2791, %2792, %2789, %2790, %2788, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.23 : Tensor = aten::relu_(%input.22) # torch/nn/functional.py:1117:17
      %2806 : Tensor[] = prim::ListConstruct(%x1.2, %input.23)
      %out.4 : Tensor = aten::cat(%2806, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.4)
    block1():
      %2808 : __torch__.torch.nn.modules.container.___torch_mangle_1071.Sequential = prim::GetAttr[name="branch1"](%2703)
      %2809 : __torch__.torch.nn.modules.conv.___torch_mangle_1068.Conv2d = prim::GetAttr[name="0"](%2808)
      %2810 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="1"](%2808)
      %2811 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="2"](%2808)
      %2812 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="3"](%2808)
      %2813 : Tensor = prim::GetAttr[name="weight"](%2809)
      %2814 : Tensor? = prim::GetAttr[name="bias"](%2809)
      %2815 : int[] = prim::ListConstruct(%16, %16)
      %2816 : int[] = prim::ListConstruct(%8, %8)
      %2817 : int[] = prim::ListConstruct(%8, %8)
      %input.33 : Tensor = aten::conv2d(%x.25, %2813, %2814, %2815, %2816, %2817, %3) # torch/nn/modules/conv.py:415:15
      %2819 : int = aten::dim(%input.33) # torch/nn/modules/batchnorm.py:276:11
      %2820 : bool = aten::ne(%2819, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2820) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2821 : bool = prim::GetAttr[name="training"](%2810)
       = prim::If(%2821) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2822 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2810)
          %2823 : Tensor = aten::add(%2822, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2810, %2823)
          -> ()
        block1():
          -> ()
      %2824 : bool = prim::GetAttr[name="training"](%2810)
      %2825 : Tensor = prim::GetAttr[name="running_mean"](%2810)
      %2826 : Tensor = prim::GetAttr[name="running_var"](%2810)
      %2827 : Tensor = prim::GetAttr[name="weight"](%2810)
      %2828 : Tensor = prim::GetAttr[name="bias"](%2810)
       = prim::If(%2824) # torch/nn/functional.py:2011:4
        block0():
          %2829 : int[] = aten::size(%input.33) # torch/nn/functional.py:2012:27
          %size_prods.40 : int = aten::__getitem__(%2829, %10) # torch/nn/functional.py:1991:17
          %2831 : int = aten::len(%2829) # torch/nn/functional.py:1992:19
          %2832 : int = aten::sub(%2831, %16) # torch/nn/functional.py:1992:19
          %size_prods.41 : int = prim::Loop(%2832, %9, %size_prods.40) # torch/nn/functional.py:1992:4
            block0(%i.11 : int, %size_prods.42 : int):
              %2836 : int = aten::add(%i.11, %16) # torch/nn/functional.py:1993:27
              %2837 : int = aten::__getitem__(%2829, %2836) # torch/nn/functional.py:1993:22
              %size_prods.43 : int = aten::mul(%size_prods.42, %2837) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.43)
          %2839 : bool = aten::eq(%size_prods.41, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2839) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.34 : Tensor = aten::batch_norm(%input.33, %2827, %2828, %2825, %2826, %2824, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2841 : Tensor = prim::GetAttr[name="weight"](%2811)
      %2842 : Tensor? = prim::GetAttr[name="bias"](%2811)
      %2843 : int[] = prim::ListConstruct(%8, %8)
      %2844 : int[] = prim::ListConstruct(%10, %10)
      %2845 : int[] = prim::ListConstruct(%8, %8)
      %input.35 : Tensor = aten::conv2d(%input.34, %2841, %2842, %2843, %2844, %2845, %8) # torch/nn/modules/conv.py:415:15
      %2847 : int = aten::dim(%input.35) # torch/nn/modules/batchnorm.py:276:11
      %2848 : bool = aten::ne(%2847, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2848) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2849 : bool = prim::GetAttr[name="training"](%2812)
       = prim::If(%2849) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2850 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2812)
          %2851 : Tensor = aten::add(%2850, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2812, %2851)
          -> ()
        block1():
          -> ()
      %2852 : bool = prim::GetAttr[name="training"](%2812)
      %2853 : Tensor = prim::GetAttr[name="running_mean"](%2812)
      %2854 : Tensor = prim::GetAttr[name="running_var"](%2812)
      %2855 : Tensor = prim::GetAttr[name="weight"](%2812)
      %2856 : Tensor = prim::GetAttr[name="bias"](%2812)
       = prim::If(%2852) # torch/nn/functional.py:2011:4
        block0():
          %2857 : int[] = aten::size(%input.35) # torch/nn/functional.py:2012:27
          %size_prods.28 : int = aten::__getitem__(%2857, %10) # torch/nn/functional.py:1991:17
          %2859 : int = aten::len(%2857) # torch/nn/functional.py:1992:19
          %2860 : int = aten::sub(%2859, %16) # torch/nn/functional.py:1992:19
          %size_prods.29 : int = prim::Loop(%2860, %9, %size_prods.28) # torch/nn/functional.py:1992:4
            block0(%i.8 : int, %size_prods.30 : int):
              %2864 : int = aten::add(%i.8, %16) # torch/nn/functional.py:1993:27
              %2865 : int = aten::__getitem__(%2857, %2864) # torch/nn/functional.py:1993:22
              %size_prods.31 : int = aten::mul(%size_prods.30, %2865) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.31)
          %2867 : bool = aten::eq(%size_prods.29, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2867) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.19 : Tensor = aten::batch_norm(%input.35, %2855, %2856, %2853, %2854, %2852, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.20 : Tensor = aten::relu_(%input.19) # torch/nn/functional.py:1117:17
      %2870 : __torch__.torch.nn.modules.container.___torch_mangle_1072.Sequential = prim::GetAttr[name="branch2"](%2703)
      %2871 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="0"](%2870)
      %2872 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="1"](%2870)
      %2873 : __torch__.torch.nn.modules.conv.___torch_mangle_1068.Conv2d = prim::GetAttr[name="3"](%2870)
      %2874 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="4"](%2870)
      %2875 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="5"](%2870)
      %2876 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="6"](%2870)
      %2877 : Tensor = prim::GetAttr[name="weight"](%2871)
      %2878 : Tensor? = prim::GetAttr[name="bias"](%2871)
      %2879 : int[] = prim::ListConstruct(%8, %8)
      %2880 : int[] = prim::ListConstruct(%10, %10)
      %2881 : int[] = prim::ListConstruct(%8, %8)
      %input.36 : Tensor = aten::conv2d(%x.25, %2877, %2878, %2879, %2880, %2881, %8) # torch/nn/modules/conv.py:415:15
      %2883 : int = aten::dim(%input.36) # torch/nn/modules/batchnorm.py:276:11
      %2884 : bool = aten::ne(%2883, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2884) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2885 : bool = prim::GetAttr[name="training"](%2872)
       = prim::If(%2885) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2886 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2872)
          %2887 : Tensor = aten::add(%2886, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2872, %2887)
          -> ()
        block1():
          -> ()
      %2888 : bool = prim::GetAttr[name="training"](%2872)
      %2889 : Tensor = prim::GetAttr[name="running_mean"](%2872)
      %2890 : Tensor = prim::GetAttr[name="running_var"](%2872)
      %2891 : Tensor = prim::GetAttr[name="weight"](%2872)
      %2892 : Tensor = prim::GetAttr[name="bias"](%2872)
       = prim::If(%2888) # torch/nn/functional.py:2011:4
        block0():
          %2893 : int[] = aten::size(%input.36) # torch/nn/functional.py:2012:27
          %size_prods.44 : int = aten::__getitem__(%2893, %10) # torch/nn/functional.py:1991:17
          %2895 : int = aten::len(%2893) # torch/nn/functional.py:1992:19
          %2896 : int = aten::sub(%2895, %16) # torch/nn/functional.py:1992:19
          %size_prods.45 : int = prim::Loop(%2896, %9, %size_prods.44) # torch/nn/functional.py:1992:4
            block0(%i.12 : int, %size_prods.46 : int):
              %2900 : int = aten::add(%i.12, %16) # torch/nn/functional.py:1993:27
              %2901 : int = aten::__getitem__(%2893, %2900) # torch/nn/functional.py:1993:22
              %size_prods.47 : int = aten::mul(%size_prods.46, %2901) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.47)
          %2903 : bool = aten::eq(%size_prods.45, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2903) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.37 : Tensor = aten::batch_norm(%input.36, %2891, %2892, %2889, %2890, %2888, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.38 : Tensor = aten::relu_(%input.37) # torch/nn/functional.py:1117:17
      %2906 : Tensor = prim::GetAttr[name="weight"](%2873)
      %2907 : Tensor? = prim::GetAttr[name="bias"](%2873)
      %2908 : int[] = prim::ListConstruct(%16, %16)
      %2909 : int[] = prim::ListConstruct(%8, %8)
      %2910 : int[] = prim::ListConstruct(%8, %8)
      %input.39 : Tensor = aten::conv2d(%input.38, %2906, %2907, %2908, %2909, %2910, %3) # torch/nn/modules/conv.py:415:15
      %2912 : int = aten::dim(%input.39) # torch/nn/modules/batchnorm.py:276:11
      %2913 : bool = aten::ne(%2912, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2913) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2914 : bool = prim::GetAttr[name="training"](%2874)
       = prim::If(%2914) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2915 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2874)
          %2916 : Tensor = aten::add(%2915, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2874, %2916)
          -> ()
        block1():
          -> ()
      %2917 : bool = prim::GetAttr[name="training"](%2874)
      %2918 : Tensor = prim::GetAttr[name="running_mean"](%2874)
      %2919 : Tensor = prim::GetAttr[name="running_var"](%2874)
      %2920 : Tensor = prim::GetAttr[name="weight"](%2874)
      %2921 : Tensor = prim::GetAttr[name="bias"](%2874)
       = prim::If(%2917) # torch/nn/functional.py:2011:4
        block0():
          %2922 : int[] = aten::size(%input.39) # torch/nn/functional.py:2012:27
          %size_prods.48 : int = aten::__getitem__(%2922, %10) # torch/nn/functional.py:1991:17
          %2924 : int = aten::len(%2922) # torch/nn/functional.py:1992:19
          %2925 : int = aten::sub(%2924, %16) # torch/nn/functional.py:1992:19
          %size_prods.49 : int = prim::Loop(%2925, %9, %size_prods.48) # torch/nn/functional.py:1992:4
            block0(%i.13 : int, %size_prods.50 : int):
              %2929 : int = aten::add(%i.13, %16) # torch/nn/functional.py:1993:27
              %2930 : int = aten::__getitem__(%2922, %2929) # torch/nn/functional.py:1993:22
              %size_prods.51 : int = aten::mul(%size_prods.50, %2930) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.51)
          %2932 : bool = aten::eq(%size_prods.49, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2932) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.40 : Tensor = aten::batch_norm(%input.39, %2920, %2921, %2918, %2919, %2917, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %2934 : Tensor = prim::GetAttr[name="weight"](%2875)
      %2935 : Tensor? = prim::GetAttr[name="bias"](%2875)
      %2936 : int[] = prim::ListConstruct(%8, %8)
      %2937 : int[] = prim::ListConstruct(%10, %10)
      %2938 : int[] = prim::ListConstruct(%8, %8)
      %input.41 : Tensor = aten::conv2d(%input.40, %2934, %2935, %2936, %2937, %2938, %8) # torch/nn/modules/conv.py:415:15
      %2940 : int = aten::dim(%input.41) # torch/nn/modules/batchnorm.py:276:11
      %2941 : bool = aten::ne(%2940, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2941) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2942 : bool = prim::GetAttr[name="training"](%2876)
       = prim::If(%2942) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %2943 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2876)
          %2944 : Tensor = aten::add(%2943, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2876, %2944)
          -> ()
        block1():
          -> ()
      %2945 : bool = prim::GetAttr[name="training"](%2876)
      %2946 : Tensor = prim::GetAttr[name="running_mean"](%2876)
      %2947 : Tensor = prim::GetAttr[name="running_var"](%2876)
      %2948 : Tensor = prim::GetAttr[name="weight"](%2876)
      %2949 : Tensor = prim::GetAttr[name="bias"](%2876)
       = prim::If(%2945) # torch/nn/functional.py:2011:4
        block0():
          %2950 : int[] = aten::size(%input.41) # torch/nn/functional.py:2012:27
          %size_prods.52 : int = aten::__getitem__(%2950, %10) # torch/nn/functional.py:1991:17
          %2952 : int = aten::len(%2950) # torch/nn/functional.py:1992:19
          %2953 : int = aten::sub(%2952, %16) # torch/nn/functional.py:1992:19
          %size_prods.53 : int = prim::Loop(%2953, %9, %size_prods.52) # torch/nn/functional.py:1992:4
            block0(%i.14 : int, %size_prods.54 : int):
              %2957 : int = aten::add(%i.14, %16) # torch/nn/functional.py:1993:27
              %2958 : int = aten::__getitem__(%2950, %2957) # torch/nn/functional.py:1993:22
              %size_prods.55 : int = aten::mul(%size_prods.54, %2958) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.55)
          %2960 : bool = aten::eq(%size_prods.53, %8) # torch/nn/functional.py:1994:7
           = prim::If(%2960) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.42 : Tensor = aten::batch_norm(%input.41, %2948, %2949, %2946, %2947, %2945, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.43 : Tensor = aten::relu_(%input.42) # torch/nn/functional.py:1117:17
      %2963 : Tensor[] = prim::ListConstruct(%input.20, %input.43)
      %out.5 : Tensor = aten::cat(%2963, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.5)
  %2965 : Tensor = prim::data(%out.3)
  %2966 : int[] = aten::size(%2965) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.2 : int, %num_channels.2 : int, %height.2 : int, %width.2 : int = prim::ListUnpack(%2966)
  %channels_per_group.2 : int = aten::floordiv(%num_channels.2, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %2972 : int[] = prim::ListConstruct(%batchsize.2, %16, %channels_per_group.2, %height.2, %width.2)
  %x.5 : Tensor = aten::view(%out.3, %2972) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %2974 : Tensor = aten::transpose(%x.5, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.7 : Tensor = aten::contiguous(%2974, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %2976 : int[] = prim::ListConstruct(%batchsize.2, %5, %height.2, %width.2)
  %input.24 : Tensor = aten::view(%x.7, %2976) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %2978 : int = prim::GetAttr[name="stride"](%2704)
  %2979 : bool = aten::eq(%2978, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.6 : Tensor = prim::If(%2979) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %2981 : Tensor[] = aten::chunk(%input.24, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.3 : Tensor, %x2.3 : Tensor = prim::ListUnpack(%2981)
      %2984 : __torch__.torch.nn.modules.container.___torch_mangle_1075.Sequential = prim::GetAttr[name="branch2"](%2704)
      %2985 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="0"](%2984)
      %2986 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="1"](%2984)
      %2987 : __torch__.torch.nn.modules.conv.___torch_mangle_1074.Conv2d = prim::GetAttr[name="3"](%2984)
      %2988 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="4"](%2984)
      %2989 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="5"](%2984)
      %2990 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="6"](%2984)
      %2991 : Tensor = prim::GetAttr[name="weight"](%2985)
      %2992 : Tensor? = prim::GetAttr[name="bias"](%2985)
      %2993 : int[] = prim::ListConstruct(%8, %8)
      %2994 : int[] = prim::ListConstruct(%10, %10)
      %2995 : int[] = prim::ListConstruct(%8, %8)
      %input.44 : Tensor = aten::conv2d(%x2.3, %2991, %2992, %2993, %2994, %2995, %8) # torch/nn/modules/conv.py:415:15
      %2997 : int = aten::dim(%input.44) # torch/nn/modules/batchnorm.py:276:11
      %2998 : bool = aten::ne(%2997, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%2998) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %2999 : bool = prim::GetAttr[name="training"](%2986)
       = prim::If(%2999) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3000 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2986)
          %3001 : Tensor = aten::add(%3000, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2986, %3001)
          -> ()
        block1():
          -> ()
      %3002 : bool = prim::GetAttr[name="training"](%2986)
      %3003 : Tensor = prim::GetAttr[name="running_mean"](%2986)
      %3004 : Tensor = prim::GetAttr[name="running_var"](%2986)
      %3005 : Tensor = prim::GetAttr[name="weight"](%2986)
      %3006 : Tensor = prim::GetAttr[name="bias"](%2986)
       = prim::If(%3002) # torch/nn/functional.py:2011:4
        block0():
          %3007 : int[] = aten::size(%input.44) # torch/nn/functional.py:2012:27
          %size_prods.56 : int = aten::__getitem__(%3007, %10) # torch/nn/functional.py:1991:17
          %3009 : int = aten::len(%3007) # torch/nn/functional.py:1992:19
          %3010 : int = aten::sub(%3009, %16) # torch/nn/functional.py:1992:19
          %size_prods.57 : int = prim::Loop(%3010, %9, %size_prods.56) # torch/nn/functional.py:1992:4
            block0(%i.15 : int, %size_prods.58 : int):
              %3014 : int = aten::add(%i.15, %16) # torch/nn/functional.py:1993:27
              %3015 : int = aten::__getitem__(%3007, %3014) # torch/nn/functional.py:1993:22
              %size_prods.59 : int = aten::mul(%size_prods.58, %3015) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.59)
          %3017 : bool = aten::eq(%size_prods.57, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3017) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.45 : Tensor = aten::batch_norm(%input.44, %3005, %3006, %3003, %3004, %3002, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.46 : Tensor = aten::relu_(%input.45) # torch/nn/functional.py:1117:17
      %3020 : Tensor = prim::GetAttr[name="weight"](%2987)
      %3021 : Tensor? = prim::GetAttr[name="bias"](%2987)
      %3022 : int[] = prim::ListConstruct(%8, %8)
      %3023 : int[] = prim::ListConstruct(%8, %8)
      %3024 : int[] = prim::ListConstruct(%8, %8)
      %input.47 : Tensor = aten::conv2d(%input.46, %3020, %3021, %3022, %3023, %3024, %3) # torch/nn/modules/conv.py:415:15
      %3026 : int = aten::dim(%input.47) # torch/nn/modules/batchnorm.py:276:11
      %3027 : bool = aten::ne(%3026, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3027) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3028 : bool = prim::GetAttr[name="training"](%2988)
       = prim::If(%3028) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3029 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2988)
          %3030 : Tensor = aten::add(%3029, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2988, %3030)
          -> ()
        block1():
          -> ()
      %3031 : bool = prim::GetAttr[name="training"](%2988)
      %3032 : Tensor = prim::GetAttr[name="running_mean"](%2988)
      %3033 : Tensor = prim::GetAttr[name="running_var"](%2988)
      %3034 : Tensor = prim::GetAttr[name="weight"](%2988)
      %3035 : Tensor = prim::GetAttr[name="bias"](%2988)
       = prim::If(%3031) # torch/nn/functional.py:2011:4
        block0():
          %3036 : int[] = aten::size(%input.47) # torch/nn/functional.py:2012:27
          %size_prods.60 : int = aten::__getitem__(%3036, %10) # torch/nn/functional.py:1991:17
          %3038 : int = aten::len(%3036) # torch/nn/functional.py:1992:19
          %3039 : int = aten::sub(%3038, %16) # torch/nn/functional.py:1992:19
          %size_prods.61 : int = prim::Loop(%3039, %9, %size_prods.60) # torch/nn/functional.py:1992:4
            block0(%i.16 : int, %size_prods.62 : int):
              %3043 : int = aten::add(%i.16, %16) # torch/nn/functional.py:1993:27
              %3044 : int = aten::__getitem__(%3036, %3043) # torch/nn/functional.py:1993:22
              %size_prods.63 : int = aten::mul(%size_prods.62, %3044) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.63)
          %3046 : bool = aten::eq(%size_prods.61, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3046) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.48 : Tensor = aten::batch_norm(%input.47, %3034, %3035, %3032, %3033, %3031, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %3048 : Tensor = prim::GetAttr[name="weight"](%2989)
      %3049 : Tensor? = prim::GetAttr[name="bias"](%2989)
      %3050 : int[] = prim::ListConstruct(%8, %8)
      %3051 : int[] = prim::ListConstruct(%10, %10)
      %3052 : int[] = prim::ListConstruct(%8, %8)
      %input.49 : Tensor = aten::conv2d(%input.48, %3048, %3049, %3050, %3051, %3052, %8) # torch/nn/modules/conv.py:415:15
      %3054 : int = aten::dim(%input.49) # torch/nn/modules/batchnorm.py:276:11
      %3055 : bool = aten::ne(%3054, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3055) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3056 : bool = prim::GetAttr[name="training"](%2990)
       = prim::If(%3056) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3057 : Tensor = prim::GetAttr[name="num_batches_tracked"](%2990)
          %3058 : Tensor = aten::add(%3057, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%2990, %3058)
          -> ()
        block1():
          -> ()
      %3059 : bool = prim::GetAttr[name="training"](%2990)
      %3060 : Tensor = prim::GetAttr[name="running_mean"](%2990)
      %3061 : Tensor = prim::GetAttr[name="running_var"](%2990)
      %3062 : Tensor = prim::GetAttr[name="weight"](%2990)
      %3063 : Tensor = prim::GetAttr[name="bias"](%2990)
       = prim::If(%3059) # torch/nn/functional.py:2011:4
        block0():
          %3064 : int[] = aten::size(%input.49) # torch/nn/functional.py:2012:27
          %size_prods.64 : int = aten::__getitem__(%3064, %10) # torch/nn/functional.py:1991:17
          %3066 : int = aten::len(%3064) # torch/nn/functional.py:1992:19
          %3067 : int = aten::sub(%3066, %16) # torch/nn/functional.py:1992:19
          %size_prods.65 : int = prim::Loop(%3067, %9, %size_prods.64) # torch/nn/functional.py:1992:4
            block0(%i.17 : int, %size_prods.66 : int):
              %3071 : int = aten::add(%i.17, %16) # torch/nn/functional.py:1993:27
              %3072 : int = aten::__getitem__(%3064, %3071) # torch/nn/functional.py:1993:22
              %size_prods.67 : int = aten::mul(%size_prods.66, %3072) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.67)
          %3074 : bool = aten::eq(%size_prods.65, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3074) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.50 : Tensor = aten::batch_norm(%input.49, %3062, %3063, %3060, %3061, %3059, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.51 : Tensor = aten::relu_(%input.50) # torch/nn/functional.py:1117:17
      %3077 : Tensor[] = prim::ListConstruct(%x1.3, %input.51)
      %out.7 : Tensor = aten::cat(%3077, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.7)
    block1():
      %3079 : __torch__.torch.nn.modules.container.___torch_mangle_1075.Sequential = prim::GetAttr[name="branch2"](%2704)
      %3080 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="0"](%3079)
      %3081 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="1"](%3079)
      %3082 : __torch__.torch.nn.modules.conv.___torch_mangle_1074.Conv2d = prim::GetAttr[name="3"](%3079)
      %3083 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="4"](%3079)
      %3084 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="5"](%3079)
      %3085 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="6"](%3079)
      %3086 : Tensor = prim::GetAttr[name="weight"](%3080)
      %3087 : Tensor? = prim::GetAttr[name="bias"](%3080)
      %3088 : int[] = prim::ListConstruct(%8, %8)
      %3089 : int[] = prim::ListConstruct(%10, %10)
      %3090 : int[] = prim::ListConstruct(%8, %8)
      %input.52 : Tensor = aten::conv2d(%input.24, %3086, %3087, %3088, %3089, %3090, %8) # torch/nn/modules/conv.py:415:15
      %3092 : int = aten::dim(%input.52) # torch/nn/modules/batchnorm.py:276:11
      %3093 : bool = aten::ne(%3092, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3093) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3094 : bool = prim::GetAttr[name="training"](%3081)
       = prim::If(%3094) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3095 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3081)
          %3096 : Tensor = aten::add(%3095, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3081, %3096)
          -> ()
        block1():
          -> ()
      %3097 : bool = prim::GetAttr[name="training"](%3081)
      %3098 : Tensor = prim::GetAttr[name="running_mean"](%3081)
      %3099 : Tensor = prim::GetAttr[name="running_var"](%3081)
      %3100 : Tensor = prim::GetAttr[name="weight"](%3081)
      %3101 : Tensor = prim::GetAttr[name="bias"](%3081)
       = prim::If(%3097) # torch/nn/functional.py:2011:4
        block0():
          %3102 : int[] = aten::size(%input.52) # torch/nn/functional.py:2012:27
          %size_prods.68 : int = aten::__getitem__(%3102, %10) # torch/nn/functional.py:1991:17
          %3104 : int = aten::len(%3102) # torch/nn/functional.py:1992:19
          %3105 : int = aten::sub(%3104, %16) # torch/nn/functional.py:1992:19
          %size_prods.69 : int = prim::Loop(%3105, %9, %size_prods.68) # torch/nn/functional.py:1992:4
            block0(%i.18 : int, %size_prods.70 : int):
              %3109 : int = aten::add(%i.18, %16) # torch/nn/functional.py:1993:27
              %3110 : int = aten::__getitem__(%3102, %3109) # torch/nn/functional.py:1993:22
              %size_prods.71 : int = aten::mul(%size_prods.70, %3110) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.71)
          %3112 : bool = aten::eq(%size_prods.69, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3112) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.53 : Tensor = aten::batch_norm(%input.52, %3100, %3101, %3098, %3099, %3097, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.54 : Tensor = aten::relu_(%input.53) # torch/nn/functional.py:1117:17
      %3115 : Tensor = prim::GetAttr[name="weight"](%3082)
      %3116 : Tensor? = prim::GetAttr[name="bias"](%3082)
      %3117 : int[] = prim::ListConstruct(%8, %8)
      %3118 : int[] = prim::ListConstruct(%8, %8)
      %3119 : int[] = prim::ListConstruct(%8, %8)
      %input.55 : Tensor = aten::conv2d(%input.54, %3115, %3116, %3117, %3118, %3119, %3) # torch/nn/modules/conv.py:415:15
      %3121 : int = aten::dim(%input.55) # torch/nn/modules/batchnorm.py:276:11
      %3122 : bool = aten::ne(%3121, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3122) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3123 : bool = prim::GetAttr[name="training"](%3083)
       = prim::If(%3123) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3124 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3083)
          %3125 : Tensor = aten::add(%3124, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3083, %3125)
          -> ()
        block1():
          -> ()
      %3126 : bool = prim::GetAttr[name="training"](%3083)
      %3127 : Tensor = prim::GetAttr[name="running_mean"](%3083)
      %3128 : Tensor = prim::GetAttr[name="running_var"](%3083)
      %3129 : Tensor = prim::GetAttr[name="weight"](%3083)
      %3130 : Tensor = prim::GetAttr[name="bias"](%3083)
       = prim::If(%3126) # torch/nn/functional.py:2011:4
        block0():
          %3131 : int[] = aten::size(%input.55) # torch/nn/functional.py:2012:27
          %size_prods.72 : int = aten::__getitem__(%3131, %10) # torch/nn/functional.py:1991:17
          %3133 : int = aten::len(%3131) # torch/nn/functional.py:1992:19
          %3134 : int = aten::sub(%3133, %16) # torch/nn/functional.py:1992:19
          %size_prods.73 : int = prim::Loop(%3134, %9, %size_prods.72) # torch/nn/functional.py:1992:4
            block0(%i.19 : int, %size_prods.74 : int):
              %3138 : int = aten::add(%i.19, %16) # torch/nn/functional.py:1993:27
              %3139 : int = aten::__getitem__(%3131, %3138) # torch/nn/functional.py:1993:22
              %size_prods.75 : int = aten::mul(%size_prods.74, %3139) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.75)
          %3141 : bool = aten::eq(%size_prods.73, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3141) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.56 : Tensor = aten::batch_norm(%input.55, %3129, %3130, %3127, %3128, %3126, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %3143 : Tensor = prim::GetAttr[name="weight"](%3084)
      %3144 : Tensor? = prim::GetAttr[name="bias"](%3084)
      %3145 : int[] = prim::ListConstruct(%8, %8)
      %3146 : int[] = prim::ListConstruct(%10, %10)
      %3147 : int[] = prim::ListConstruct(%8, %8)
      %input.57 : Tensor = aten::conv2d(%input.56, %3143, %3144, %3145, %3146, %3147, %8) # torch/nn/modules/conv.py:415:15
      %3149 : int = aten::dim(%input.57) # torch/nn/modules/batchnorm.py:276:11
      %3150 : bool = aten::ne(%3149, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3150) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3151 : bool = prim::GetAttr[name="training"](%3085)
       = prim::If(%3151) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3152 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3085)
          %3153 : Tensor = aten::add(%3152, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3085, %3153)
          -> ()
        block1():
          -> ()
      %3154 : bool = prim::GetAttr[name="training"](%3085)
      %3155 : Tensor = prim::GetAttr[name="running_mean"](%3085)
      %3156 : Tensor = prim::GetAttr[name="running_var"](%3085)
      %3157 : Tensor = prim::GetAttr[name="weight"](%3085)
      %3158 : Tensor = prim::GetAttr[name="bias"](%3085)
       = prim::If(%3154) # torch/nn/functional.py:2011:4
        block0():
          %3159 : int[] = aten::size(%input.57) # torch/nn/functional.py:2012:27
          %size_prods.76 : int = aten::__getitem__(%3159, %10) # torch/nn/functional.py:1991:17
          %3161 : int = aten::len(%3159) # torch/nn/functional.py:1992:19
          %3162 : int = aten::sub(%3161, %16) # torch/nn/functional.py:1992:19
          %size_prods.77 : int = prim::Loop(%3162, %9, %size_prods.76) # torch/nn/functional.py:1992:4
            block0(%i.20 : int, %size_prods.78 : int):
              %3166 : int = aten::add(%i.20, %16) # torch/nn/functional.py:1993:27
              %3167 : int = aten::__getitem__(%3159, %3166) # torch/nn/functional.py:1993:22
              %size_prods.79 : int = aten::mul(%size_prods.78, %3167) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.79)
          %3169 : bool = aten::eq(%size_prods.77, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3169) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.58 : Tensor = aten::batch_norm(%input.57, %3157, %3158, %3155, %3156, %3154, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.59 : Tensor = aten::relu_(%input.58) # torch/nn/functional.py:1117:17
      %3172 : Tensor[] = prim::ListConstruct(%input.24, %input.59)
      %out.9 : Tensor = aten::cat(%3172, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.9)
  %3174 : Tensor = prim::data(%out.6)
  %3175 : int[] = aten::size(%3174) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.3 : int, %num_channels.3 : int, %height.3 : int, %width.3 : int = prim::ListUnpack(%3175)
  %channels_per_group.3 : int = aten::floordiv(%num_channels.3, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %3181 : int[] = prim::ListConstruct(%batchsize.3, %16, %channels_per_group.3, %height.3, %width.3)
  %x.8 : Tensor = aten::view(%out.6, %3181) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %3183 : Tensor = aten::transpose(%x.8, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.9 : Tensor = aten::contiguous(%3183, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %3185 : int[] = prim::ListConstruct(%batchsize.3, %5, %height.3, %width.3)
  %input.25 : Tensor = aten::view(%x.9, %3185) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %3187 : int = prim::GetAttr[name="stride"](%2705)
  %3188 : bool = aten::eq(%3187, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out.12 : Tensor = prim::If(%3188) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %3190 : Tensor[] = aten::chunk(%input.25, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.4 : Tensor, %x2.4 : Tensor = prim::ListUnpack(%3190)
      %3193 : __torch__.torch.nn.modules.container.___torch_mangle_1075.Sequential = prim::GetAttr[name="branch2"](%2705)
      %3194 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="0"](%3193)
      %3195 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="1"](%3193)
      %3196 : __torch__.torch.nn.modules.conv.___torch_mangle_1074.Conv2d = prim::GetAttr[name="3"](%3193)
      %3197 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="4"](%3193)
      %3198 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="5"](%3193)
      %3199 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="6"](%3193)
      %3200 : Tensor = prim::GetAttr[name="weight"](%3194)
      %3201 : Tensor? = prim::GetAttr[name="bias"](%3194)
      %3202 : int[] = prim::ListConstruct(%8, %8)
      %3203 : int[] = prim::ListConstruct(%10, %10)
      %3204 : int[] = prim::ListConstruct(%8, %8)
      %input.60 : Tensor = aten::conv2d(%x2.4, %3200, %3201, %3202, %3203, %3204, %8) # torch/nn/modules/conv.py:415:15
      %3206 : int = aten::dim(%input.60) # torch/nn/modules/batchnorm.py:276:11
      %3207 : bool = aten::ne(%3206, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3207) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3208 : bool = prim::GetAttr[name="training"](%3195)
       = prim::If(%3208) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3209 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3195)
          %3210 : Tensor = aten::add(%3209, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3195, %3210)
          -> ()
        block1():
          -> ()
      %3211 : bool = prim::GetAttr[name="training"](%3195)
      %3212 : Tensor = prim::GetAttr[name="running_mean"](%3195)
      %3213 : Tensor = prim::GetAttr[name="running_var"](%3195)
      %3214 : Tensor = prim::GetAttr[name="weight"](%3195)
      %3215 : Tensor = prim::GetAttr[name="bias"](%3195)
       = prim::If(%3211) # torch/nn/functional.py:2011:4
        block0():
          %3216 : int[] = aten::size(%input.60) # torch/nn/functional.py:2012:27
          %size_prods.80 : int = aten::__getitem__(%3216, %10) # torch/nn/functional.py:1991:17
          %3218 : int = aten::len(%3216) # torch/nn/functional.py:1992:19
          %3219 : int = aten::sub(%3218, %16) # torch/nn/functional.py:1992:19
          %size_prods.81 : int = prim::Loop(%3219, %9, %size_prods.80) # torch/nn/functional.py:1992:4
            block0(%i.21 : int, %size_prods.82 : int):
              %3223 : int = aten::add(%i.21, %16) # torch/nn/functional.py:1993:27
              %3224 : int = aten::__getitem__(%3216, %3223) # torch/nn/functional.py:1993:22
              %size_prods.83 : int = aten::mul(%size_prods.82, %3224) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.83)
          %3226 : bool = aten::eq(%size_prods.81, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3226) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.61 : Tensor = aten::batch_norm(%input.60, %3214, %3215, %3212, %3213, %3211, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.62 : Tensor = aten::relu_(%input.61) # torch/nn/functional.py:1117:17
      %3229 : Tensor = prim::GetAttr[name="weight"](%3196)
      %3230 : Tensor? = prim::GetAttr[name="bias"](%3196)
      %3231 : int[] = prim::ListConstruct(%8, %8)
      %3232 : int[] = prim::ListConstruct(%8, %8)
      %3233 : int[] = prim::ListConstruct(%8, %8)
      %input.63 : Tensor = aten::conv2d(%input.62, %3229, %3230, %3231, %3232, %3233, %3) # torch/nn/modules/conv.py:415:15
      %3235 : int = aten::dim(%input.63) # torch/nn/modules/batchnorm.py:276:11
      %3236 : bool = aten::ne(%3235, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3236) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3237 : bool = prim::GetAttr[name="training"](%3197)
       = prim::If(%3237) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3238 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3197)
          %3239 : Tensor = aten::add(%3238, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3197, %3239)
          -> ()
        block1():
          -> ()
      %3240 : bool = prim::GetAttr[name="training"](%3197)
      %3241 : Tensor = prim::GetAttr[name="running_mean"](%3197)
      %3242 : Tensor = prim::GetAttr[name="running_var"](%3197)
      %3243 : Tensor = prim::GetAttr[name="weight"](%3197)
      %3244 : Tensor = prim::GetAttr[name="bias"](%3197)
       = prim::If(%3240) # torch/nn/functional.py:2011:4
        block0():
          %3245 : int[] = aten::size(%input.63) # torch/nn/functional.py:2012:27
          %size_prods.84 : int = aten::__getitem__(%3245, %10) # torch/nn/functional.py:1991:17
          %3247 : int = aten::len(%3245) # torch/nn/functional.py:1992:19
          %3248 : int = aten::sub(%3247, %16) # torch/nn/functional.py:1992:19
          %size_prods.85 : int = prim::Loop(%3248, %9, %size_prods.84) # torch/nn/functional.py:1992:4
            block0(%i.22 : int, %size_prods.86 : int):
              %3252 : int = aten::add(%i.22, %16) # torch/nn/functional.py:1993:27
              %3253 : int = aten::__getitem__(%3245, %3252) # torch/nn/functional.py:1993:22
              %size_prods.87 : int = aten::mul(%size_prods.86, %3253) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.87)
          %3255 : bool = aten::eq(%size_prods.85, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3255) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.64 : Tensor = aten::batch_norm(%input.63, %3243, %3244, %3241, %3242, %3240, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %3257 : Tensor = prim::GetAttr[name="weight"](%3198)
      %3258 : Tensor? = prim::GetAttr[name="bias"](%3198)
      %3259 : int[] = prim::ListConstruct(%8, %8)
      %3260 : int[] = prim::ListConstruct(%10, %10)
      %3261 : int[] = prim::ListConstruct(%8, %8)
      %input.65 : Tensor = aten::conv2d(%input.64, %3257, %3258, %3259, %3260, %3261, %8) # torch/nn/modules/conv.py:415:15
      %3263 : int = aten::dim(%input.65) # torch/nn/modules/batchnorm.py:276:11
      %3264 : bool = aten::ne(%3263, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3264) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3265 : bool = prim::GetAttr[name="training"](%3199)
       = prim::If(%3265) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3266 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3199)
          %3267 : Tensor = aten::add(%3266, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3199, %3267)
          -> ()
        block1():
          -> ()
      %3268 : bool = prim::GetAttr[name="training"](%3199)
      %3269 : Tensor = prim::GetAttr[name="running_mean"](%3199)
      %3270 : Tensor = prim::GetAttr[name="running_var"](%3199)
      %3271 : Tensor = prim::GetAttr[name="weight"](%3199)
      %3272 : Tensor = prim::GetAttr[name="bias"](%3199)
       = prim::If(%3268) # torch/nn/functional.py:2011:4
        block0():
          %3273 : int[] = aten::size(%input.65) # torch/nn/functional.py:2012:27
          %size_prods.88 : int = aten::__getitem__(%3273, %10) # torch/nn/functional.py:1991:17
          %3275 : int = aten::len(%3273) # torch/nn/functional.py:1992:19
          %3276 : int = aten::sub(%3275, %16) # torch/nn/functional.py:1992:19
          %size_prods.89 : int = prim::Loop(%3276, %9, %size_prods.88) # torch/nn/functional.py:1992:4
            block0(%i.23 : int, %size_prods.90 : int):
              %3280 : int = aten::add(%i.23, %16) # torch/nn/functional.py:1993:27
              %3281 : int = aten::__getitem__(%3273, %3280) # torch/nn/functional.py:1993:22
              %size_prods.91 : int = aten::mul(%size_prods.90, %3281) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.91)
          %3283 : bool = aten::eq(%size_prods.89, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3283) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.66 : Tensor = aten::batch_norm(%input.65, %3271, %3272, %3269, %3270, %3268, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.67 : Tensor = aten::relu_(%input.66) # torch/nn/functional.py:1117:17
      %3286 : Tensor[] = prim::ListConstruct(%x1.4, %input.67)
      %out.10 : Tensor = aten::cat(%3286, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.10)
    block1():
      %3288 : __torch__.torch.nn.modules.container.___torch_mangle_1075.Sequential = prim::GetAttr[name="branch2"](%2705)
      %3289 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="0"](%3288)
      %3290 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="1"](%3288)
      %3291 : __torch__.torch.nn.modules.conv.___torch_mangle_1074.Conv2d = prim::GetAttr[name="3"](%3288)
      %3292 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="4"](%3288)
      %3293 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="5"](%3288)
      %3294 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="6"](%3288)
      %3295 : Tensor = prim::GetAttr[name="weight"](%3289)
      %3296 : Tensor? = prim::GetAttr[name="bias"](%3289)
      %3297 : int[] = prim::ListConstruct(%8, %8)
      %3298 : int[] = prim::ListConstruct(%10, %10)
      %3299 : int[] = prim::ListConstruct(%8, %8)
      %input.68 : Tensor = aten::conv2d(%input.25, %3295, %3296, %3297, %3298, %3299, %8) # torch/nn/modules/conv.py:415:15
      %3301 : int = aten::dim(%input.68) # torch/nn/modules/batchnorm.py:276:11
      %3302 : bool = aten::ne(%3301, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3302) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3303 : bool = prim::GetAttr[name="training"](%3290)
       = prim::If(%3303) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3304 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3290)
          %3305 : Tensor = aten::add(%3304, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3290, %3305)
          -> ()
        block1():
          -> ()
      %3306 : bool = prim::GetAttr[name="training"](%3290)
      %3307 : Tensor = prim::GetAttr[name="running_mean"](%3290)
      %3308 : Tensor = prim::GetAttr[name="running_var"](%3290)
      %3309 : Tensor = prim::GetAttr[name="weight"](%3290)
      %3310 : Tensor = prim::GetAttr[name="bias"](%3290)
       = prim::If(%3306) # torch/nn/functional.py:2011:4
        block0():
          %3311 : int[] = aten::size(%input.68) # torch/nn/functional.py:2012:27
          %size_prods.92 : int = aten::__getitem__(%3311, %10) # torch/nn/functional.py:1991:17
          %3313 : int = aten::len(%3311) # torch/nn/functional.py:1992:19
          %3314 : int = aten::sub(%3313, %16) # torch/nn/functional.py:1992:19
          %size_prods.93 : int = prim::Loop(%3314, %9, %size_prods.92) # torch/nn/functional.py:1992:4
            block0(%i.24 : int, %size_prods.94 : int):
              %3318 : int = aten::add(%i.24, %16) # torch/nn/functional.py:1993:27
              %3319 : int = aten::__getitem__(%3311, %3318) # torch/nn/functional.py:1993:22
              %size_prods.95 : int = aten::mul(%size_prods.94, %3319) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.95)
          %3321 : bool = aten::eq(%size_prods.93, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3321) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.69 : Tensor = aten::batch_norm(%input.68, %3309, %3310, %3307, %3308, %3306, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.70 : Tensor = aten::relu_(%input.69) # torch/nn/functional.py:1117:17
      %3324 : Tensor = prim::GetAttr[name="weight"](%3291)
      %3325 : Tensor? = prim::GetAttr[name="bias"](%3291)
      %3326 : int[] = prim::ListConstruct(%8, %8)
      %3327 : int[] = prim::ListConstruct(%8, %8)
      %3328 : int[] = prim::ListConstruct(%8, %8)
      %input.71 : Tensor = aten::conv2d(%input.70, %3324, %3325, %3326, %3327, %3328, %3) # torch/nn/modules/conv.py:415:15
      %3330 : int = aten::dim(%input.71) # torch/nn/modules/batchnorm.py:276:11
      %3331 : bool = aten::ne(%3330, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3331) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3332 : bool = prim::GetAttr[name="training"](%3292)
       = prim::If(%3332) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3333 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3292)
          %3334 : Tensor = aten::add(%3333, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3292, %3334)
          -> ()
        block1():
          -> ()
      %3335 : bool = prim::GetAttr[name="training"](%3292)
      %3336 : Tensor = prim::GetAttr[name="running_mean"](%3292)
      %3337 : Tensor = prim::GetAttr[name="running_var"](%3292)
      %3338 : Tensor = prim::GetAttr[name="weight"](%3292)
      %3339 : Tensor = prim::GetAttr[name="bias"](%3292)
       = prim::If(%3335) # torch/nn/functional.py:2011:4
        block0():
          %3340 : int[] = aten::size(%input.71) # torch/nn/functional.py:2012:27
          %size_prods.96 : int = aten::__getitem__(%3340, %10) # torch/nn/functional.py:1991:17
          %3342 : int = aten::len(%3340) # torch/nn/functional.py:1992:19
          %3343 : int = aten::sub(%3342, %16) # torch/nn/functional.py:1992:19
          %size_prods.97 : int = prim::Loop(%3343, %9, %size_prods.96) # torch/nn/functional.py:1992:4
            block0(%i.25 : int, %size_prods.98 : int):
              %3347 : int = aten::add(%i.25, %16) # torch/nn/functional.py:1993:27
              %3348 : int = aten::__getitem__(%3340, %3347) # torch/nn/functional.py:1993:22
              %size_prods.99 : int = aten::mul(%size_prods.98, %3348) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.99)
          %3350 : bool = aten::eq(%size_prods.97, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3350) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.72 : Tensor = aten::batch_norm(%input.71, %3338, %3339, %3336, %3337, %3335, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %3352 : Tensor = prim::GetAttr[name="weight"](%3293)
      %3353 : Tensor? = prim::GetAttr[name="bias"](%3293)
      %3354 : int[] = prim::ListConstruct(%8, %8)
      %3355 : int[] = prim::ListConstruct(%10, %10)
      %3356 : int[] = prim::ListConstruct(%8, %8)
      %input.73 : Tensor = aten::conv2d(%input.72, %3352, %3353, %3354, %3355, %3356, %8) # torch/nn/modules/conv.py:415:15
      %3358 : int = aten::dim(%input.73) # torch/nn/modules/batchnorm.py:276:11
      %3359 : bool = aten::ne(%3358, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3359) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3360 : bool = prim::GetAttr[name="training"](%3294)
       = prim::If(%3360) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3361 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3294)
          %3362 : Tensor = aten::add(%3361, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3294, %3362)
          -> ()
        block1():
          -> ()
      %3363 : bool = prim::GetAttr[name="training"](%3294)
      %3364 : Tensor = prim::GetAttr[name="running_mean"](%3294)
      %3365 : Tensor = prim::GetAttr[name="running_var"](%3294)
      %3366 : Tensor = prim::GetAttr[name="weight"](%3294)
      %3367 : Tensor = prim::GetAttr[name="bias"](%3294)
       = prim::If(%3363) # torch/nn/functional.py:2011:4
        block0():
          %3368 : int[] = aten::size(%input.73) # torch/nn/functional.py:2012:27
          %size_prods.100 : int = aten::__getitem__(%3368, %10) # torch/nn/functional.py:1991:17
          %3370 : int = aten::len(%3368) # torch/nn/functional.py:1992:19
          %3371 : int = aten::sub(%3370, %16) # torch/nn/functional.py:1992:19
          %size_prods.101 : int = prim::Loop(%3371, %9, %size_prods.100) # torch/nn/functional.py:1992:4
            block0(%i.26 : int, %size_prods.102 : int):
              %3375 : int = aten::add(%i.26, %16) # torch/nn/functional.py:1993:27
              %3376 : int = aten::__getitem__(%3368, %3375) # torch/nn/functional.py:1993:22
              %size_prods.103 : int = aten::mul(%size_prods.102, %3376) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.103)
          %3378 : bool = aten::eq(%size_prods.101, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3378) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.74 : Tensor = aten::batch_norm(%input.73, %3366, %3367, %3364, %3365, %3363, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.75 : Tensor = aten::relu_(%input.74) # torch/nn/functional.py:1117:17
      %3381 : Tensor[] = prim::ListConstruct(%input.25, %input.75)
      %out.11 : Tensor = aten::cat(%3381, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.11)
  %3383 : Tensor = prim::data(%out.12)
  %3384 : int[] = aten::size(%3383) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.4 : int, %num_channels.4 : int, %height.4 : int, %width.4 : int = prim::ListUnpack(%3384)
  %channels_per_group.4 : int = aten::floordiv(%num_channels.4, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %3390 : int[] = prim::ListConstruct(%batchsize.4, %16, %channels_per_group.4, %height.4, %width.4)
  %x.10 : Tensor = aten::view(%out.12, %3390) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %3392 : Tensor = aten::transpose(%x.10, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.11 : Tensor = aten::contiguous(%3392, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %3394 : int[] = prim::ListConstruct(%batchsize.4, %5, %height.4, %width.4)
  %input.26 : Tensor = aten::view(%x.11, %3394) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %3396 : int = prim::GetAttr[name="stride"](%2706)
  %3397 : bool = aten::eq(%3396, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:11
  %out : Tensor = prim::If(%3397) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:75:8
    block0():
      %3399 : Tensor[] = aten::chunk(%input.26, %16, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:76:21
      %x1.1 : Tensor, %x2.1 : Tensor = prim::ListUnpack(%3399)
      %3402 : __torch__.torch.nn.modules.container.___torch_mangle_1075.Sequential = prim::GetAttr[name="branch2"](%2706)
      %3403 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="0"](%3402)
      %3404 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="1"](%3402)
      %3405 : __torch__.torch.nn.modules.conv.___torch_mangle_1074.Conv2d = prim::GetAttr[name="3"](%3402)
      %3406 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="4"](%3402)
      %3407 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="5"](%3402)
      %3408 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="6"](%3402)
      %3409 : Tensor = prim::GetAttr[name="weight"](%3403)
      %3410 : Tensor? = prim::GetAttr[name="bias"](%3403)
      %3411 : int[] = prim::ListConstruct(%8, %8)
      %3412 : int[] = prim::ListConstruct(%10, %10)
      %3413 : int[] = prim::ListConstruct(%8, %8)
      %input.4 : Tensor = aten::conv2d(%x2.1, %3409, %3410, %3411, %3412, %3413, %8) # torch/nn/modules/conv.py:415:15
      %3415 : int = aten::dim(%input.4) # torch/nn/modules/batchnorm.py:276:11
      %3416 : bool = aten::ne(%3415, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3416) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3417 : bool = prim::GetAttr[name="training"](%3404)
       = prim::If(%3417) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3418 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3404)
          %3419 : Tensor = aten::add(%3418, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3404, %3419)
          -> ()
        block1():
          -> ()
      %3420 : bool = prim::GetAttr[name="training"](%3404)
      %3421 : Tensor = prim::GetAttr[name="running_mean"](%3404)
      %3422 : Tensor = prim::GetAttr[name="running_var"](%3404)
      %3423 : Tensor = prim::GetAttr[name="weight"](%3404)
      %3424 : Tensor = prim::GetAttr[name="bias"](%3404)
       = prim::If(%3420) # torch/nn/functional.py:2011:4
        block0():
          %3425 : int[] = aten::size(%input.4) # torch/nn/functional.py:2012:27
          %size_prods.12 : int = aten::__getitem__(%3425, %10) # torch/nn/functional.py:1991:17
          %3427 : int = aten::len(%3425) # torch/nn/functional.py:1992:19
          %3428 : int = aten::sub(%3427, %16) # torch/nn/functional.py:1992:19
          %size_prods.13 : int = prim::Loop(%3428, %9, %size_prods.12) # torch/nn/functional.py:1992:4
            block0(%i.4 : int, %size_prods.14 : int):
              %3432 : int = aten::add(%i.4, %16) # torch/nn/functional.py:1993:27
              %3433 : int = aten::__getitem__(%3425, %3432) # torch/nn/functional.py:1993:22
              %size_prods.15 : int = aten::mul(%size_prods.14, %3433) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.15)
          %3435 : bool = aten::eq(%size_prods.13, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3435) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.6 : Tensor = aten::batch_norm(%input.4, %3423, %3424, %3421, %3422, %3420, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.8 : Tensor = aten::relu_(%input.6) # torch/nn/functional.py:1117:17
      %3438 : Tensor = prim::GetAttr[name="weight"](%3405)
      %3439 : Tensor? = prim::GetAttr[name="bias"](%3405)
      %3440 : int[] = prim::ListConstruct(%8, %8)
      %3441 : int[] = prim::ListConstruct(%8, %8)
      %3442 : int[] = prim::ListConstruct(%8, %8)
      %input.10 : Tensor = aten::conv2d(%input.8, %3438, %3439, %3440, %3441, %3442, %3) # torch/nn/modules/conv.py:415:15
      %3444 : int = aten::dim(%input.10) # torch/nn/modules/batchnorm.py:276:11
      %3445 : bool = aten::ne(%3444, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3445) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3446 : bool = prim::GetAttr[name="training"](%3406)
       = prim::If(%3446) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3447 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3406)
          %3448 : Tensor = aten::add(%3447, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3406, %3448)
          -> ()
        block1():
          -> ()
      %3449 : bool = prim::GetAttr[name="training"](%3406)
      %3450 : Tensor = prim::GetAttr[name="running_mean"](%3406)
      %3451 : Tensor = prim::GetAttr[name="running_var"](%3406)
      %3452 : Tensor = prim::GetAttr[name="weight"](%3406)
      %3453 : Tensor = prim::GetAttr[name="bias"](%3406)
       = prim::If(%3449) # torch/nn/functional.py:2011:4
        block0():
          %3454 : int[] = aten::size(%input.10) # torch/nn/functional.py:2012:27
          %size_prods.16 : int = aten::__getitem__(%3454, %10) # torch/nn/functional.py:1991:17
          %3456 : int = aten::len(%3454) # torch/nn/functional.py:1992:19
          %3457 : int = aten::sub(%3456, %16) # torch/nn/functional.py:1992:19
          %size_prods.17 : int = prim::Loop(%3457, %9, %size_prods.16) # torch/nn/functional.py:1992:4
            block0(%i.5 : int, %size_prods.18 : int):
              %3461 : int = aten::add(%i.5, %16) # torch/nn/functional.py:1993:27
              %3462 : int = aten::__getitem__(%3454, %3461) # torch/nn/functional.py:1993:22
              %size_prods.19 : int = aten::mul(%size_prods.18, %3462) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.19)
          %3464 : bool = aten::eq(%size_prods.17, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3464) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.12 : Tensor = aten::batch_norm(%input.10, %3452, %3453, %3450, %3451, %3449, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %3466 : Tensor = prim::GetAttr[name="weight"](%3407)
      %3467 : Tensor? = prim::GetAttr[name="bias"](%3407)
      %3468 : int[] = prim::ListConstruct(%8, %8)
      %3469 : int[] = prim::ListConstruct(%10, %10)
      %3470 : int[] = prim::ListConstruct(%8, %8)
      %input.14 : Tensor = aten::conv2d(%input.12, %3466, %3467, %3468, %3469, %3470, %8) # torch/nn/modules/conv.py:415:15
      %3472 : int = aten::dim(%input.14) # torch/nn/modules/batchnorm.py:276:11
      %3473 : bool = aten::ne(%3472, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3473) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3474 : bool = prim::GetAttr[name="training"](%3408)
       = prim::If(%3474) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3475 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3408)
          %3476 : Tensor = aten::add(%3475, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3408, %3476)
          -> ()
        block1():
          -> ()
      %3477 : bool = prim::GetAttr[name="training"](%3408)
      %3478 : Tensor = prim::GetAttr[name="running_mean"](%3408)
      %3479 : Tensor = prim::GetAttr[name="running_var"](%3408)
      %3480 : Tensor = prim::GetAttr[name="weight"](%3408)
      %3481 : Tensor = prim::GetAttr[name="bias"](%3408)
       = prim::If(%3477) # torch/nn/functional.py:2011:4
        block0():
          %3482 : int[] = aten::size(%input.14) # torch/nn/functional.py:2012:27
          %size_prods.20 : int = aten::__getitem__(%3482, %10) # torch/nn/functional.py:1991:17
          %3484 : int = aten::len(%3482) # torch/nn/functional.py:1992:19
          %3485 : int = aten::sub(%3484, %16) # torch/nn/functional.py:1992:19
          %size_prods.21 : int = prim::Loop(%3485, %9, %size_prods.20) # torch/nn/functional.py:1992:4
            block0(%i.6 : int, %size_prods.22 : int):
              %3489 : int = aten::add(%i.6, %16) # torch/nn/functional.py:1993:27
              %3490 : int = aten::__getitem__(%3482, %3489) # torch/nn/functional.py:1993:22
              %size_prods.23 : int = aten::mul(%size_prods.22, %3490) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.23)
          %3492 : bool = aten::eq(%size_prods.21, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3492) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.16 : Tensor = aten::batch_norm(%input.14, %3480, %3481, %3478, %3479, %3477, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.18 : Tensor = aten::relu_(%input.16) # torch/nn/functional.py:1117:17
      %3495 : Tensor[] = prim::ListConstruct(%x1.1, %input.18)
      %out.1 : Tensor = aten::cat(%3495, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:77:18
      -> (%out.1)
    block1():
      %3497 : __torch__.torch.nn.modules.container.___torch_mangle_1075.Sequential = prim::GetAttr[name="branch2"](%2706)
      %3498 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="0"](%3497)
      %3499 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="1"](%3497)
      %3500 : __torch__.torch.nn.modules.conv.___torch_mangle_1074.Conv2d = prim::GetAttr[name="3"](%3497)
      %3501 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="4"](%3497)
      %3502 : __torch__.torch.nn.modules.conv.___torch_mangle_1070.Conv2d = prim::GetAttr[name="5"](%3497)
      %3503 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_1069.BatchNorm2d = prim::GetAttr[name="6"](%3497)
      %3504 : Tensor = prim::GetAttr[name="weight"](%3498)
      %3505 : Tensor? = prim::GetAttr[name="bias"](%3498)
      %3506 : int[] = prim::ListConstruct(%8, %8)
      %3507 : int[] = prim::ListConstruct(%10, %10)
      %3508 : int[] = prim::ListConstruct(%8, %8)
      %input.27 : Tensor = aten::conv2d(%input.26, %3504, %3505, %3506, %3507, %3508, %8) # torch/nn/modules/conv.py:415:15
      %3510 : int = aten::dim(%input.27) # torch/nn/modules/batchnorm.py:276:11
      %3511 : bool = aten::ne(%3510, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3511) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3512 : bool = prim::GetAttr[name="training"](%3499)
       = prim::If(%3512) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3513 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3499)
          %3514 : Tensor = aten::add(%3513, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3499, %3514)
          -> ()
        block1():
          -> ()
      %3515 : bool = prim::GetAttr[name="training"](%3499)
      %3516 : Tensor = prim::GetAttr[name="running_mean"](%3499)
      %3517 : Tensor = prim::GetAttr[name="running_var"](%3499)
      %3518 : Tensor = prim::GetAttr[name="weight"](%3499)
      %3519 : Tensor = prim::GetAttr[name="bias"](%3499)
       = prim::If(%3515) # torch/nn/functional.py:2011:4
        block0():
          %3520 : int[] = aten::size(%input.27) # torch/nn/functional.py:2012:27
          %size_prods.2 : int = aten::__getitem__(%3520, %10) # torch/nn/functional.py:1991:17
          %3522 : int = aten::len(%3520) # torch/nn/functional.py:1992:19
          %3523 : int = aten::sub(%3522, %16) # torch/nn/functional.py:1992:19
          %size_prods.4 : int = prim::Loop(%3523, %9, %size_prods.2) # torch/nn/functional.py:1992:4
            block0(%i.2 : int, %size_prods.7 : int):
              %3527 : int = aten::add(%i.2, %16) # torch/nn/functional.py:1993:27
              %3528 : int = aten::__getitem__(%3520, %3527) # torch/nn/functional.py:1993:22
              %size_prods.5 : int = aten::mul(%size_prods.7, %3528) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.5)
          %3530 : bool = aten::eq(%size_prods.4, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3530) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.290 : Tensor = aten::batch_norm(%input.27, %3518, %3519, %3516, %3517, %3515, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.291 : Tensor = aten::relu_(%input.290) # torch/nn/functional.py:1117:17
      %3533 : Tensor = prim::GetAttr[name="weight"](%3500)
      %3534 : Tensor? = prim::GetAttr[name="bias"](%3500)
      %3535 : int[] = prim::ListConstruct(%8, %8)
      %3536 : int[] = prim::ListConstruct(%8, %8)
      %3537 : int[] = prim::ListConstruct(%8, %8)
      %input.9 : Tensor = aten::conv2d(%input.291, %3533, %3534, %3535, %3536, %3537, %3) # torch/nn/modules/conv.py:415:15
      %3539 : int = aten::dim(%input.9) # torch/nn/modules/batchnorm.py:276:11
      %3540 : bool = aten::ne(%3539, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3540) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3541 : bool = prim::GetAttr[name="training"](%3501)
       = prim::If(%3541) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3542 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3501)
          %3543 : Tensor = aten::add(%3542, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3501, %3543)
          -> ()
        block1():
          -> ()
      %3544 : bool = prim::GetAttr[name="training"](%3501)
      %3545 : Tensor = prim::GetAttr[name="running_mean"](%3501)
      %3546 : Tensor = prim::GetAttr[name="running_var"](%3501)
      %3547 : Tensor = prim::GetAttr[name="weight"](%3501)
      %3548 : Tensor = prim::GetAttr[name="bias"](%3501)
       = prim::If(%3544) # torch/nn/functional.py:2011:4
        block0():
          %3549 : int[] = aten::size(%input.9) # torch/nn/functional.py:2012:27
          %size_prods.8 : int = aten::__getitem__(%3549, %10) # torch/nn/functional.py:1991:17
          %3551 : int = aten::len(%3549) # torch/nn/functional.py:1992:19
          %3552 : int = aten::sub(%3551, %16) # torch/nn/functional.py:1992:19
          %size_prods.9 : int = prim::Loop(%3552, %9, %size_prods.8) # torch/nn/functional.py:1992:4
            block0(%i.3 : int, %size_prods.10 : int):
              %3556 : int = aten::add(%i.3, %16) # torch/nn/functional.py:1993:27
              %3557 : int = aten::__getitem__(%3549, %3556) # torch/nn/functional.py:1993:22
              %size_prods.11 : int = aten::mul(%size_prods.10, %3557) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.11)
          %3559 : bool = aten::eq(%size_prods.9, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3559) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.11 : Tensor = aten::batch_norm(%input.9, %3547, %3548, %3545, %3546, %3544, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %3561 : Tensor = prim::GetAttr[name="weight"](%3502)
      %3562 : Tensor? = prim::GetAttr[name="bias"](%3502)
      %3563 : int[] = prim::ListConstruct(%8, %8)
      %3564 : int[] = prim::ListConstruct(%10, %10)
      %3565 : int[] = prim::ListConstruct(%8, %8)
      %input.13 : Tensor = aten::conv2d(%input.11, %3561, %3562, %3563, %3564, %3565, %8) # torch/nn/modules/conv.py:415:15
      %3567 : int = aten::dim(%input.13) # torch/nn/modules/batchnorm.py:276:11
      %3568 : bool = aten::ne(%3567, %12) # torch/nn/modules/batchnorm.py:276:11
       = prim::If(%3568) # torch/nn/modules/batchnorm.py:276:8
        block0():
           = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
          -> ()
        block1():
          -> ()
      %3569 : bool = prim::GetAttr[name="training"](%3503)
       = prim::If(%3569) # torch/nn/modules/batchnorm.py:110:11
        block0():
          %3570 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3503)
          %3571 : Tensor = aten::add(%3570, %8, %8) # torch/nn/modules/batchnorm.py:113:43
           = prim::SetAttr[name="num_batches_tracked"](%3503, %3571)
          -> ()
        block1():
          -> ()
      %3572 : bool = prim::GetAttr[name="training"](%3503)
      %3573 : Tensor = prim::GetAttr[name="running_mean"](%3503)
      %3574 : Tensor = prim::GetAttr[name="running_var"](%3503)
      %3575 : Tensor = prim::GetAttr[name="weight"](%3503)
      %3576 : Tensor = prim::GetAttr[name="bias"](%3503)
       = prim::If(%3572) # torch/nn/functional.py:2011:4
        block0():
          %3577 : int[] = aten::size(%input.13) # torch/nn/functional.py:2012:27
          %size_prods.412 : int = aten::__getitem__(%3577, %10) # torch/nn/functional.py:1991:17
          %3579 : int = aten::len(%3577) # torch/nn/functional.py:1992:19
          %3580 : int = aten::sub(%3579, %16) # torch/nn/functional.py:1992:19
          %size_prods.413 : int = prim::Loop(%3580, %9, %size_prods.412) # torch/nn/functional.py:1992:4
            block0(%i.104 : int, %size_prods.414 : int):
              %3584 : int = aten::add(%i.104, %16) # torch/nn/functional.py:1993:27
              %3585 : int = aten::__getitem__(%3577, %3584) # torch/nn/functional.py:1993:22
              %size_prods.415 : int = aten::mul(%size_prods.414, %3585) # torch/nn/functional.py:1993:8
              -> (%9, %size_prods.415)
          %3587 : bool = aten::eq(%size_prods.413, %8) # torch/nn/functional.py:1994:7
           = prim::If(%3587) # torch/nn/functional.py:1994:4
            block0():
               = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
              -> ()
            block1():
              -> ()
          -> ()
        block1():
          -> ()
      %input.15 : Tensor = aten::batch_norm(%input.13, %3575, %3576, %3573, %3574, %3572, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
      %input.17 : Tensor = aten::relu_(%input.15) # torch/nn/functional.py:1117:17
      %3590 : Tensor[] = prim::ListConstruct(%input.26, %input.17)
      %out.2 : Tensor = aten::cat(%3590, %8) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:79:18
      -> (%out.2)
  %3592 : Tensor = prim::data(%out)
  %3593 : int[] = aten::size(%3592) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:21:45
  %batchsize.1 : int, %num_channels.1 : int, %height.1 : int, %width.1 : int = prim::ListUnpack(%3593)
  %channels_per_group.1 : int = aten::floordiv(%num_channels.1, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:22:25
  %3599 : int[] = prim::ListConstruct(%batchsize.1, %16, %channels_per_group.1, %height.1, %width.1)
  %x.4 : Tensor = aten::view(%out, %3599) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:25:8
  %3601 : Tensor = aten::transpose(%x.4, %8, %16) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %x.6 : Tensor = aten::contiguous(%3601, %10) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:28:8
  %3603 : int[] = prim::ListConstruct(%batchsize.1, %5, %height.1, %width.1)
  %x.29 : Tensor = aten::view(%x.6, %3603) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:31:8
  %3605 : __torch__.torch.nn.modules.container.___torch_mangle_1079.Sequential = prim::GetAttr[name="conv5"](%self)
  %3606 : __torch__.torch.nn.modules.conv.___torch_mangle_1078.Conv2d = prim::GetAttr[name="0"](%3605)
  %3607 : __torch__.torch.nn.modules.batchnorm.___torch_mangle_31.BatchNorm2d = prim::GetAttr[name="1"](%3605)
  %3608 : Tensor = prim::GetAttr[name="weight"](%3606)
  %3609 : Tensor? = prim::GetAttr[name="bias"](%3606)
  %3610 : int[] = prim::ListConstruct(%8, %8)
  %3611 : int[] = prim::ListConstruct(%10, %10)
  %3612 : int[] = prim::ListConstruct(%8, %8)
  %input.3 : Tensor = aten::conv2d(%x.29, %3608, %3609, %3610, %3611, %3612, %8) # torch/nn/modules/conv.py:415:15
  %3614 : int = aten::dim(%input.3) # torch/nn/modules/batchnorm.py:276:11
  %3615 : bool = aten::ne(%3614, %12) # torch/nn/modules/batchnorm.py:276:11
   = prim::If(%3615) # torch/nn/modules/batchnorm.py:276:8
    block0():
       = prim::RaiseException(%11) # torch/nn/modules/batchnorm.py:277:12
      -> ()
    block1():
      -> ()
  %3616 : bool = prim::GetAttr[name="training"](%3607)
   = prim::If(%3616) # torch/nn/modules/batchnorm.py:110:11
    block0():
      %3617 : Tensor = prim::GetAttr[name="num_batches_tracked"](%3607)
      %3618 : Tensor = aten::add(%3617, %8, %8) # torch/nn/modules/batchnorm.py:113:43
       = prim::SetAttr[name="num_batches_tracked"](%3607, %3618)
      -> ()
    block1():
      -> ()
  %3619 : bool = prim::GetAttr[name="training"](%3607)
  %3620 : Tensor = prim::GetAttr[name="running_mean"](%3607)
  %3621 : Tensor = prim::GetAttr[name="running_var"](%3607)
  %3622 : Tensor = prim::GetAttr[name="weight"](%3607)
  %3623 : Tensor = prim::GetAttr[name="bias"](%3607)
   = prim::If(%3619) # torch/nn/functional.py:2011:4
    block0():
      %3624 : int[] = aten::size(%input.3) # torch/nn/functional.py:2012:27
      %size_prods.1 : int = aten::__getitem__(%3624, %10) # torch/nn/functional.py:1991:17
      %3626 : int = aten::len(%3624) # torch/nn/functional.py:1992:19
      %3627 : int = aten::sub(%3626, %16) # torch/nn/functional.py:1992:19
      %size_prods : int = prim::Loop(%3627, %9, %size_prods.1) # torch/nn/functional.py:1992:4
        block0(%i.1 : int, %size_prods.6 : int):
          %3631 : int = aten::add(%i.1, %16) # torch/nn/functional.py:1993:27
          %3632 : int = aten::__getitem__(%3624, %3631) # torch/nn/functional.py:1993:22
          %size_prods.3 : int = aten::mul(%size_prods.6, %3632) # torch/nn/functional.py:1993:8
          -> (%9, %size_prods.3)
      %3634 : bool = aten::eq(%size_prods, %8) # torch/nn/functional.py:1994:7
       = prim::If(%3634) # torch/nn/functional.py:1994:4
        block0():
           = prim::RaiseException(%11) # torch/nn/functional.py:1995:8
          -> ()
        block1():
          -> ()
      -> ()
    block1():
      -> ()
  %input.5 : Tensor = aten::batch_norm(%input.3, %3622, %3623, %3620, %3621, %3619, %exponential_average_factor.2, %14, %9) # torch/nn/functional.py:2014:11
  %x.26 : Tensor = aten::relu_(%input.5) # torch/nn/functional.py:1117:17
  %3637 : int[] = prim::ListConstruct(%16, %15)
  %x.28 : Tensor = aten::mean(%x.26, %3637, %17, %18) # torch/hub/pytorch_vision_master/torchvision/models/shufflenetv2.py:133:12
  %3639 : __torch__.torch.nn.modules.linear.___torch_mangle_161.Linear = prim::GetAttr[name="fc"](%self)
  %3640 : Tensor = prim::GetAttr[name="weight"](%3639)
  %3641 : Tensor = prim::GetAttr[name="bias"](%3639)
  %3642 : int = aten::dim(%x.28) # torch/nn/functional.py:1672:7
  %3643 : bool = aten::eq(%3642, %16) # torch/nn/functional.py:1672:7
  %x.30 : Tensor = prim::If(%3643) # torch/nn/functional.py:1672:4
    block0():
      %3645 : Tensor = aten::t(%3640) # torch/nn/functional.py:1674:39
      %ret.1 : Tensor = aten::addmm(%3641, %x.28, %3645, %8, %8) # torch/nn/functional.py:1674:14
      -> (%ret.1)
    block1():
      %3647 : Tensor = aten::t(%3640) # torch/nn/functional.py:1676:30
      %output.1 : Tensor = aten::matmul(%x.28, %3647) # torch/nn/functional.py:1676:17
      %output.3 : Tensor = aten::add_(%output.1, %3641, %8) # torch/nn/functional.py:1678:12
      -> (%output.3)
  return (%x.30)
