ReformerForMaskedLM(
  (reformer): ReformerModel(
    (embeddings): ReformerEmbeddings(
      (word_embeddings): Embedding(320, 256)
      (position_embeddings): AxialPositionEmbeddings(
        (weights): ParameterList(
            (0): Parameter containing: [torch.FloatTensor of size 64x1x64]
            (1): Parameter containing: [torch.FloatTensor of size 1x64x192]
        )
      )
    )
    (encoder): ReformerEncoder(
      (layers): ModuleList(
        (0): ReformerLayer(
          (attention): ReformerAttention(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (self_attention): LocalSelfAttention(
              (query): Linear(in_features=256, out_features=768, bias=False)
              (key): Linear(in_features=256, out_features=768, bias=False)
              (value): Linear(in_features=256, out_features=768, bias=False)
            )
            (output): ReformerSelfOutput(
              (dense): Linear(in_features=768, out_features=256, bias=False)
            )
          )
          (feed_forward): ChunkReformerFeedForward(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (dense): ReformerFeedForwardDense(
              (dense): Linear(in_features=256, out_features=512, bias=True)
            )
            (output): ReformerFeedForwardOutput(
              (dense): Linear(in_features=512, out_features=256, bias=True)
            )
          )
        )
        (1): ReformerLayer(
          (attention): ReformerAttention(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (self_attention): LSHSelfAttention(
              (query_key): Linear(in_features=256, out_features=768, bias=False)
              (value): Linear(in_features=256, out_features=768, bias=False)
            )
            (output): ReformerSelfOutput(
              (dense): Linear(in_features=768, out_features=256, bias=False)
            )
          )
          (feed_forward): ChunkReformerFeedForward(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (dense): ReformerFeedForwardDense(
              (dense): Linear(in_features=256, out_features=512, bias=True)
            )
            (output): ReformerFeedForwardOutput(
              (dense): Linear(in_features=512, out_features=256, bias=True)
            )
          )
        )
        (2): ReformerLayer(
          (attention): ReformerAttention(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (self_attention): LocalSelfAttention(
              (query): Linear(in_features=256, out_features=768, bias=False)
              (key): Linear(in_features=256, out_features=768, bias=False)
              (value): Linear(in_features=256, out_features=768, bias=False)
            )
            (output): ReformerSelfOutput(
              (dense): Linear(in_features=768, out_features=256, bias=False)
            )
          )
          (feed_forward): ChunkReformerFeedForward(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (dense): ReformerFeedForwardDense(
              (dense): Linear(in_features=256, out_features=512, bias=True)
            )
            (output): ReformerFeedForwardOutput(
              (dense): Linear(in_features=512, out_features=256, bias=True)
            )
          )
        )
        (3): ReformerLayer(
          (attention): ReformerAttention(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (self_attention): LSHSelfAttention(
              (query_key): Linear(in_features=256, out_features=768, bias=False)
              (value): Linear(in_features=256, out_features=768, bias=False)
            )
            (output): ReformerSelfOutput(
              (dense): Linear(in_features=768, out_features=256, bias=False)
            )
          )
          (feed_forward): ChunkReformerFeedForward(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (dense): ReformerFeedForwardDense(
              (dense): Linear(in_features=256, out_features=512, bias=True)
            )
            (output): ReformerFeedForwardOutput(
              (dense): Linear(in_features=512, out_features=256, bias=True)
            )
          )
        )
        (4): ReformerLayer(
          (attention): ReformerAttention(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (self_attention): LocalSelfAttention(
              (query): Linear(in_features=256, out_features=768, bias=False)
              (key): Linear(in_features=256, out_features=768, bias=False)
              (value): Linear(in_features=256, out_features=768, bias=False)
            )
            (output): ReformerSelfOutput(
              (dense): Linear(in_features=768, out_features=256, bias=False)
            )
          )
          (feed_forward): ChunkReformerFeedForward(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (dense): ReformerFeedForwardDense(
              (dense): Linear(in_features=256, out_features=512, bias=True)
            )
            (output): ReformerFeedForwardOutput(
              (dense): Linear(in_features=512, out_features=256, bias=True)
            )
          )
        )
        (5): ReformerLayer(
          (attention): ReformerAttention(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (self_attention): LSHSelfAttention(
              (query_key): Linear(in_features=256, out_features=768, bias=False)
              (value): Linear(in_features=256, out_features=768, bias=False)
            )
            (output): ReformerSelfOutput(
              (dense): Linear(in_features=768, out_features=256, bias=False)
            )
          )
          (feed_forward): ChunkReformerFeedForward(
            (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
            (dense): ReformerFeedForwardDense(
              (dense): Linear(in_features=256, out_features=512, bias=True)
            )
            (output): ReformerFeedForwardOutput(
              (dense): Linear(in_features=512, out_features=256, bias=True)
            )
          )
        )
      )
      (layer_norm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)
    )
  )
  (lm_head): ReformerOnlyLMHead(
    (decoder): Linear(in_features=512, out_features=320, bias=True)
  )
)

ReformerForMaskedLM._actual_script_module
ReformerForMaskedLM.forward
  graph(%self.1 : __torch__.transformers.modeling_reformer.ReformerForMaskedLM,
        %input_ids : Long(17:13, 13:1),
        %position_ids : Long(17:13, 13:1)):
    %2490 : __torch__.transformers.modeling_reformer.ReformerOnlyLMHead = prim::GetAttr[name="lm_head"](%self.1)
    %2485 : __torch__.transformers.modeling_reformer.ReformerModel = prim::GetAttr[name="reformer"](%self.1)
    %2616 : Tensor = prim::CallMethod[name="forward"](%2485, %input_ids, %position_ids)
    %2617 : Tensor = prim::CallMethod[name="forward"](%2490, %2616)
    %2210 : (Float(17:4160, 13:320, 320:1)) = prim::TupleConstruct(%2617)
    return (%2210)

ReformerForMaskedLM.lm_head
ReformerOnlyLMHead._actual_script_module
  graph(%self.95 : __torch__.transformers.modeling_reformer.ReformerOnlyLMHead,
        %5 : Float(17:6656, 13:512, 512:1)):
    %1 : Tensor = prim::GetAttr[name="bias"](%self.95)
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="decoder"](%self.95)
    %26 : Tensor = prim::CallMethod[name="forward"](%2, %1, %5)
    return (%26)

ReformerForMaskedLM.reformer
ReformerModel._actual_script_module
  graph(%self.2 : __torch__.transformers.modeling_reformer.ReformerModel,
        %input_ids : Long(17:13, 13:1),
        %position_ids : Long(17:13, 13:1)):
    %1 : __torch__.transformers.modeling_reformer.ReformerEncoder = prim::GetAttr[name="encoder"](%self.2)
    %2 : __torch__.transformers.modeling_reformer.ReformerEmbeddings = prim::GetAttr[name="embeddings"](%self.2)
    %7 : int = prim::Constant[value=1](), scope: __module.reformer # transformers/modeling_reformer.py:2037:0
    %8 : int = aten::size(%input_ids, %7), scope: __module.reformer # transformers/modeling_reformer.py:2037:0
    %orig_sequence_length : Long() = prim::NumToTensor(%8), scope: __module.reformer
    %19 : Tensor = prim::CallMethod[name="forward"](%2, %input_ids, %position_ids)
    %20 : Tensor = prim::CallMethod[name="forward"](%1, %19, %orig_sequence_length)
    return (%20)

ReformerModel.embeddings
ReformerEmbeddings._actual_script_module
  graph(%self.3 : __torch__.transformers.modeling_reformer.ReformerEmbeddings,
        %input_ids : Long(17:13, 13:1),
        %position_ids : Long(17:13, 13:1)):
    %3 : __torch__.transformers.modeling_reformer.AxialPositionEmbeddings = prim::GetAttr[name="position_embeddings"](%self.3)
    %4 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name="word_embeddings"](%self.3)
    %26 : Tensor = prim::CallMethod[name="forward"](%4, %input_ids)
    %20 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.embeddings # torch/nn/functional.py:973:0
    %21 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings # torch/nn/functional.py:973:0
    %inputs_embeds : Float(17:3328, 13:256, 256:1) = aten::dropout(%26, %20, %21), scope: __module.reformer/__module.reformer.embeddings # torch/nn/functional.py:973:0
    %27 : Tensor = prim::CallMethod[name="forward"](%3, %position_ids)
    %24 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings # transformers/modeling_reformer.py:265:0
    %hidden_states.1 : Float(17:3328, 13:256, 256:1) = aten::add(%inputs_embeds, %27, %24), scope: __module.reformer/__module.reformer.embeddings # transformers/modeling_reformer.py:265:0
    return (%hidden_states.1)

ReformerModel.encoder
ReformerEncoder._actual_script_module
  graph(%self.6 : __torch__.transformers.modeling_reformer.ReformerEncoder,
        %1 : Float(17:3328, 13:256, 256:1),
        %orig_sequence_length : Long()):
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.6)
    %4 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%self.6)
    %5 : __torch__.transformers.modeling_reformer.ReformerLayer = prim::GetAttr[name="5"](%4)
    %6 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%self.6)
    %7 : __torch__.transformers.modeling_reformer.ReformerLayer = prim::GetAttr[name="4"](%6)
    %8 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%self.6)
    %9 : __torch__.transformers.modeling_reformer.ReformerLayer = prim::GetAttr[name="3"](%8)
    %10 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%self.6)
    %11 : __torch__.transformers.modeling_reformer.ReformerLayer = prim::GetAttr[name="2"](%10)
    %12 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%self.6)
    %13 : __torch__.transformers.modeling_reformer.ReformerLayer = prim::GetAttr[name="1"](%12)
    %14 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="layers"](%self.6)
    %15 : __torch__.transformers.modeling_reformer.ReformerLayer = prim::GetAttr[name="0"](%14)
    %16 : Tensor[] = prim::ListConstruct(%1, %1), scope: __module.reformer/__module.reformer.encoder
    %17 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder # transformers/modeling_reformer.py:1726:0
    %hidden_states.2 : Float(17:6656, 13:512, 512:1) = aten::cat(%16, %17), scope: __module.reformer/__module.reformer.encoder # transformers/modeling_reformer.py:1726:0
    %input.56 : Float(17:6656, 13:512, 512:1) = ^_ReversibleFunction(ModuleList(
    (0): ReformerLayer(
      (attention): ReformerAttention(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (self_attention): LocalSelfAttention(
          (query): Linear(in_features=256, out_features=768, bias=False)
          (key): Linear(in_features=256, out_features=768, bias=False)
          (value): Linear(in_features=256, out_features=768, bias=False)
        )
        (output): ReformerSelfOutput(
          (dense): Linear(in_features=768, out_features=256, bias=False)
        )
      )
      (feed_forward): ChunkReformerFeedForward(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dense): ReformerFeedForwardDense(
          (dense): Linear(in_features=256, out_features=512, bias=True)
        )
        (output): ReformerFeedForwardOutput(
          (dense): Linear(in_features=512, out_features=256, bias=True)
        )
      )
    )
    (1): ReformerLayer(
      (attention): ReformerAttention(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (self_attention): LSHSelfAttention(
          (query_key): Linear(in_features=256, out_features=768, bias=False)
          (value): Linear(in_features=256, out_features=768, bias=False)
        )
        (output): ReformerSelfOutput(
          (dense): Linear(in_features=768, out_features=256, bias=False)
        )
      )
      (feed_forward): ChunkReformerFeedForward(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dense): ReformerFeedForwardDense(
          (dense): Linear(in_features=256, out_features=512, bias=True)
        )
        (output): ReformerFeedForwardOutput(
          (dense): Linear(in_features=512, out_features=256, bias=True)
        )
      )
    )
    (2): ReformerLayer(
      (attention): ReformerAttention(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (self_attention): LocalSelfAttention(
          (query): Linear(in_features=256, out_features=768, bias=False)
          (key): Linear(in_features=256, out_features=768, bias=False)
          (value): Linear(in_features=256, out_features=768, bias=False)
        )
        (output): ReformerSelfOutput(
          (dense): Linear(in_features=768, out_features=256, bias=False)
        )
      )
      (feed_forward): ChunkReformerFeedForward(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dense): ReformerFeedForwardDense(
          (dense): Linear(in_features=256, out_features=512, bias=True)
        )
        (output): ReformerFeedForwardOutput(
          (dense): Linear(in_features=512, out_features=256, bias=True)
        )
      )
    )
    (3): ReformerLayer(
      (attention): ReformerAttention(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (self_attention): LSHSelfAttention(
          (query_key): Linear(in_features=256, out_features=768, bias=False)
          (value): Linear(in_features=256, out_features=768, bias=False)
        )
        (output): ReformerSelfOutput(
          (dense): Linear(in_features=768, out_features=256, bias=False)
        )
      )
      (feed_forward): ChunkReformerFeedForward(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dense): ReformerFeedForwardDense(
          (dense): Linear(in_features=256, out_features=512, bias=True)
        )
        (output): ReformerFeedForwardOutput(
          (dense): Linear(in_features=512, out_features=256, bias=True)
        )
      )
    )
    (4): ReformerLayer(
      (attention): ReformerAttention(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (self_attention): LocalSelfAttention(
          (query): Linear(in_features=256, out_features=768, bias=False)
          (key): Linear(in_features=256, out_features=768, bias=False)
          (value): Linear(in_features=256, out_features=768, bias=False)
        )
        (output): ReformerSelfOutput(
          (dense): Linear(in_features=768, out_features=256, bias=False)
        )
      )
      (feed_forward): ChunkReformerFeedForward(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dense): ReformerFeedForwardDense(
          (dense): Linear(in_features=256, out_features=512, bias=True)
        )
        (output): ReformerFeedForwardOutput(
          (dense): Linear(in_features=512, out_features=256, bias=True)
        )
      )
    )
    (5): ReformerLayer(
      (attention): ReformerAttention(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (self_attention): LSHSelfAttention(
          (query_key): Linear(in_features=256, out_features=768, bias=False)
          (value): Linear(in_features=256, out_features=768, bias=False)
        )
        (output): ReformerSelfOutput(
          (dense): Linear(in_features=768, out_features=256, bias=False)
        )
      )
      (feed_forward): ChunkReformerFeedForward(
        (layer_norm): LayerNorm((256,), eps=1e-12, elementwise_affine=True)
        (dense): ReformerFeedForwardDense(
          (dense): Linear(in_features=256, out_features=512, bias=True)
        )
        (output): ReformerFeedForwardOutput(
          (dense): Linear(in_features=512, out_features=256, bias=True)
        )
      )
    )
  ), None, [None, None, None, None, None, None], None, [], [], [(None, None), (None, None), (None, None), (None, None), (None, None), (None, None)], False, False, False)(%hidden_states.2, %orig_sequence_length), scope: __module.reformer/__module.reformer.encoder # transformers/modeling_reformer.py:1727:0
    %20 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder # transformers/modeling_reformer.py:1609:0
    %21 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder # transformers/modeling_reformer.py:1609:0
    %22 : Tensor[] = aten::chunk(%hidden_states.2, %20, %21), scope: __module.reformer/__module.reformer.encoder # transformers/modeling_reformer.py:1609:0
    %input.2 : Float(17:6656, 13:512, 256:1), %prev_attn_output : Float(17:6656, 13:512, 256:1) = prim::ListUnpack(%22), scope: __module.reformer/__module.reformer.encoder
    %52 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%15, %input.2, %prev_attn_output)
    %26 : Float(17:3328, 13:256, 256:1), %27 : Float(17:3328, 13:256, 256:1) = prim::TupleUnpack(%52)
    %53 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%13, %26, %27)
    %29 : Float(17:3328, 13:256, 256:1), %30 : Float(17:3328, 13:256, 256:1) = prim::TupleUnpack(%53)
    %54 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%11, %29, %30)
    %32 : Float(17:3328, 13:256, 256:1), %33 : Float(17:3328, 13:256, 256:1) = prim::TupleUnpack(%54)
    %55 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%9, %32, %33)
    %35 : Float(17:3328, 13:256, 256:1), %36 : Float(17:3328, 13:256, 256:1) = prim::TupleUnpack(%55)
    %56 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%7, %35, %36)
    %38 : Float(17:3328, 13:256, 256:1), %39 : Float(17:3328, 13:256, 256:1) = prim::TupleUnpack(%56)
    %57 : (Tensor, Tensor) = prim::CallMethod[name="forward"](%5, %38, %39)
    %58 : Tensor = prim::CallMethod[name="forward"](%3, %input.56)
    %49 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder # torch/nn/functional.py:973:0
    %50 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder # torch/nn/functional.py:973:0
    %input_tensor : Float(17:6656, 13:512, 512:1) = aten::dropout(%58, %49, %50), scope: __module.reformer/__module.reformer.encoder # torch/nn/functional.py:973:0
    return (%input_tensor)

ReformerEmbeddings.position_embeddings
AxialPositionEmbeddings._actual_script_module
  graph(%self.5 : __torch__.transformers.modeling_reformer.AxialPositionEmbeddings,
        %position_ids : Long(17:13, 13:1)):
    %2 : __torch__.torch.nn.modules.container.ParameterList = prim::GetAttr[name="weights"](%self.5)
    %3 : Tensor = prim::GetAttr[name="1"](%2)
    %4 : __torch__.torch.nn.modules.container.ParameterList = prim::GetAttr[name="weights"](%self.5)
    %5 : Tensor = prim::GetAttr[name="0"](%4)
    %6 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:147:0
    %7 : int = aten::size(%position_ids, %6), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:147:0
    %batch_size.1 : Long() = prim::NumToTensor(%7), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %9 : int = aten::Int(%batch_size.1), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %10 : int = aten::Int(%batch_size.1), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %11 : int = aten::Int(%batch_size.1), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %27 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %28 : int = aten::size(%5, %27), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %29 : Long() = prim::NumToTensor(%28), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %30 : int = aten::Int(%29), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %31 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %32 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %33 : int[] = prim::ListConstruct(%11, %31, %32, %30), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %34 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %weight.4 : Float(17:0, 64:64, 64:0, 64:1) = aten::expand(%5, %33, %34), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %42 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %43 : int = aten::size(%3, %42), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %44 : Long() = prim::NumToTensor(%43), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %45 : int = aten::Int(%44), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %46 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %47 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %48 : int[] = prim::ListConstruct(%10, %46, %47, %45), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %49 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %weight.5 : Float(17:0, 64:0, 64:192, 192:1) = aten::expand(%3, %48, %49), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:151:0
    %54 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %55 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %56 : int = prim::Constant[value=9223372036854775807](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %57 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %58 : Float(17:0, 64:64, 64:0, 64:1) = aten::slice(%weight.4, %54, %55, %56, %57), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %59 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %60 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %61 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %62 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %63 : Float(17:0, 1:64, 64:0, 64:1) = aten::slice(%58, %59, %60, %61, %62), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %64 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %65 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %66 : int = prim::Constant[value=9223372036854775807](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %67 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %68 : Float(17:0, 64:0, 64:192, 192:1) = aten::slice(%weight.5, %64, %65, %66, %67), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %69 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %70 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %71 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %72 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %73 : Float(17:0, 1:0, 64:192, 192:1) = aten::slice(%68, %69, %70, %71, %72), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:193:0
    %74 : Tensor[] = prim::ListConstruct(%63, %73), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %75 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:192:0
    %position_encodings.1 : Float(17:16384, 1:16384, 64:256, 256:1) = aten::cat(%74, %75), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:192:0
    %86 : int = prim::Constant[value=3](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:195:0
    %87 : int = aten::size(%position_encodings.1, %86), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:195:0
    %88 : Long() = prim::NumToTensor(%87), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %89 : int = aten::Int(%88), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %90 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:195:0
    %91 : int[] = prim::ListConstruct(%9, %90, %89), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %position_encodings : Float(17:16384, 64:256, 256:1) = aten::reshape(%position_encodings.1, %91), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:195:0
    %93 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %94 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %95 : Float(64:256, 256:1) = aten::select(%position_encodings, %93, %94), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %96 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %97 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %98 : Long(13:1) = aten::select(%position_ids, %96, %97), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %99 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %100 : Float(13:256, 256:1) = aten::index_select(%95, %99, %98), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %101 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %102 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%100, %101), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %103 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %104 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %105 : Float(64:256, 256:1) = aten::select(%position_encodings, %103, %104), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %106 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %107 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %108 : Long(13:1) = aten::select(%position_ids, %106, %107), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %109 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %110 : Float(13:256, 256:1) = aten::index_select(%105, %109, %108), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %111 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %112 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%110, %111), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %113 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %114 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %115 : Float(64:256, 256:1) = aten::select(%position_encodings, %113, %114), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %116 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %117 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %118 : Long(13:1) = aten::select(%position_ids, %116, %117), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %119 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %120 : Float(13:256, 256:1) = aten::index_select(%115, %119, %118), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %121 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %122 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%120, %121), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %123 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %124 : int = prim::Constant[value=3](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %125 : Float(64:256, 256:1) = aten::select(%position_encodings, %123, %124), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %126 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %127 : int = prim::Constant[value=3](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %128 : Long(13:1) = aten::select(%position_ids, %126, %127), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %129 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %130 : Float(13:256, 256:1) = aten::index_select(%125, %129, %128), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %131 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %132 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%130, %131), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %133 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %134 : int = prim::Constant[value=4](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %135 : Float(64:256, 256:1) = aten::select(%position_encodings, %133, %134), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %136 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %137 : int = prim::Constant[value=4](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %138 : Long(13:1) = aten::select(%position_ids, %136, %137), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %139 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %140 : Float(13:256, 256:1) = aten::index_select(%135, %139, %138), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %141 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %142 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%140, %141), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %143 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %144 : int = prim::Constant[value=5](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %145 : Float(64:256, 256:1) = aten::select(%position_encodings, %143, %144), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %146 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %147 : int = prim::Constant[value=5](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %148 : Long(13:1) = aten::select(%position_ids, %146, %147), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %149 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %150 : Float(13:256, 256:1) = aten::index_select(%145, %149, %148), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %151 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %152 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%150, %151), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %153 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %154 : int = prim::Constant[value=6](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %155 : Float(64:256, 256:1) = aten::select(%position_encodings, %153, %154), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %156 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %157 : int = prim::Constant[value=6](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %158 : Long(13:1) = aten::select(%position_ids, %156, %157), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %159 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %160 : Float(13:256, 256:1) = aten::index_select(%155, %159, %158), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %161 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %162 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%160, %161), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %163 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %164 : int = prim::Constant[value=7](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %165 : Float(64:256, 256:1) = aten::select(%position_encodings, %163, %164), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %166 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %167 : int = prim::Constant[value=7](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %168 : Long(13:1) = aten::select(%position_ids, %166, %167), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %169 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %170 : Float(13:256, 256:1) = aten::index_select(%165, %169, %168), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %171 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %172 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%170, %171), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %173 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %174 : int = prim::Constant[value=8](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %175 : Float(64:256, 256:1) = aten::select(%position_encodings, %173, %174), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %176 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %177 : int = prim::Constant[value=8](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %178 : Long(13:1) = aten::select(%position_ids, %176, %177), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %179 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %180 : Float(13:256, 256:1) = aten::index_select(%175, %179, %178), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %181 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %182 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%180, %181), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %183 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %184 : int = prim::Constant[value=9](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %185 : Float(64:256, 256:1) = aten::select(%position_encodings, %183, %184), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %186 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %187 : int = prim::Constant[value=9](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %188 : Long(13:1) = aten::select(%position_ids, %186, %187), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %189 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %190 : Float(13:256, 256:1) = aten::index_select(%185, %189, %188), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %191 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %192 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%190, %191), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %193 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %194 : int = prim::Constant[value=10](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %195 : Float(64:256, 256:1) = aten::select(%position_encodings, %193, %194), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %196 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %197 : int = prim::Constant[value=10](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %198 : Long(13:1) = aten::select(%position_ids, %196, %197), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %199 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %200 : Float(13:256, 256:1) = aten::index_select(%195, %199, %198), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %201 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %202 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%200, %201), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %203 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %204 : int = prim::Constant[value=11](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %205 : Float(64:256, 256:1) = aten::select(%position_encodings, %203, %204), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %206 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %207 : int = prim::Constant[value=11](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %208 : Long(13:1) = aten::select(%position_ids, %206, %207), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %209 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %210 : Float(13:256, 256:1) = aten::index_select(%205, %209, %208), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %211 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %212 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%210, %211), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %213 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %214 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %215 : Float(64:256, 256:1) = aten::select(%position_encodings, %213, %214), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %216 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %217 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %218 : Long(13:1) = aten::select(%position_ids, %216, %217), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %219 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %220 : Float(13:256, 256:1) = aten::index_select(%215, %219, %218), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %221 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %222 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%220, %221), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %223 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %224 : int = prim::Constant[value=13](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %225 : Float(64:256, 256:1) = aten::select(%position_encodings, %223, %224), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %226 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %227 : int = prim::Constant[value=13](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %228 : Long(13:1) = aten::select(%position_ids, %226, %227), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %229 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %230 : Float(13:256, 256:1) = aten::index_select(%225, %229, %228), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %231 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %232 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%230, %231), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %233 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %234 : int = prim::Constant[value=14](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %235 : Float(64:256, 256:1) = aten::select(%position_encodings, %233, %234), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %236 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %237 : int = prim::Constant[value=14](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %238 : Long(13:1) = aten::select(%position_ids, %236, %237), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %239 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %240 : Float(13:256, 256:1) = aten::index_select(%235, %239, %238), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %241 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %242 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%240, %241), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %243 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %244 : int = prim::Constant[value=15](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %245 : Float(64:256, 256:1) = aten::select(%position_encodings, %243, %244), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %246 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %247 : int = prim::Constant[value=15](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %248 : Long(13:1) = aten::select(%position_ids, %246, %247), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %249 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %250 : Float(13:256, 256:1) = aten::index_select(%245, %249, %248), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %251 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %252 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%250, %251), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %253 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %254 : int = prim::Constant[value=16](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %255 : Float(64:256, 256:1) = aten::select(%position_encodings, %253, %254), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %256 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %257 : int = prim::Constant[value=16](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %258 : Long(13:1) = aten::select(%position_ids, %256, %257), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %259 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %260 : Float(13:256, 256:1) = aten::index_select(%255, %259, %258), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %261 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %262 : Float(1:3328, 13:256, 256:1) = aten::unsqueeze(%260, %261), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:200:0
    %263 : Tensor[] = prim::ListConstruct(%102, %112, %122, %132, %142, %152, %162, %172, %182, %192, %202, %212, %222, %232, %242, %252, %262), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings
    %264 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:198:0
    %position_embeddings : Float(17:3328, 13:256, 256:1) = aten::cat(%263, %264), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.position_embeddings # transformers/modeling_reformer.py:198:0
    return (%position_embeddings)

ReformerEmbeddings.word_embeddings
Embedding._actual_script_module
  graph(%self.4 : __torch__.torch.nn.modules.sparse.Embedding,
        %input_ids : Long(17:13, 13:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.4)
    %3 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.word_embeddings # torch/nn/functional.py:1814:0
    %4 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.word_embeddings # torch/nn/functional.py:1814:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.word_embeddings # torch/nn/functional.py:1814:0
    %input.1 : Float(17:3328, 13:256, 256:1) = aten::embedding(%2, %input_ids, %3, %4, %5), scope: __module.reformer/__module.reformer.embeddings/__module.reformer.embeddings.word_embeddings # torch/nn/functional.py:1814:0
    return (%input.1)

ParameterList.*
ModuleList.*
  module had no methods with graph attrs.

ReformerEncoder.layer_norm
LayerNorm._actual_script_module
  graph(%self.94 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.56 : Float(17:6656, 13:512, 512:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.94)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.94)
    %4 : int = prim::Constant[value=512](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layer_norm # torch/nn/functional.py:2048:0
    %input : Float(17:6656, 13:512, 512:1) = aten::layer_norm(%input.56, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layer_norm # torch/nn/functional.py:2048:0
    return (%input)

ReformerLayer._actual_script_module
  graph(%self.7 : __torch__.transformers.modeling_reformer.ReformerLayer,
        %input.2 : Float(17:6656, 13:512, 256:1),
        %prev_attn_output : Float(17:6656, 13:512, 256:1)):
    %3 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward = prim::GetAttr[name="feed_forward"](%self.7)
    %4 : __torch__.transformers.modeling_reformer.ReformerAttention = prim::GetAttr[name="attention"](%self.7)
    %12 : Tensor = prim::CallMethod[name="forward"](%4, %input.2)
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0 # transformers/modeling_reformer.py:1498:0
    %input_tensor.1 : Float(17:3328, 13:256, 256:1) = aten::add(%prev_attn_output, %12, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0 # transformers/modeling_reformer.py:1498:0
    %13 : Tensor = prim::CallMethod[name="forward"](%3, %input_tensor.1)
    %9 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0 # transformers/modeling_reformer.py:1508:0
    %input.11 : Float(17:3328, 13:256, 256:1) = aten::add(%input.2, %13, %9), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0 # transformers/modeling_reformer.py:1508:0
    %11 : (Float(17:3328, 13:256, 256:1), Float(17:3328, 13:256, 256:1)) = prim::TupleConstruct(%input.11, %input_tensor.1)
    return (%11)

ReformerLayer.attention
ReformerAttention._actual_script_module
  graph(%self.8 : __torch__.transformers.modeling_reformer.ReformerAttention,
        %input.2 : Float(17:6656, 13:512, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerSelfOutput = prim::GetAttr[name="output"](%self.8)
    %3 : __torch__.transformers.modeling_reformer.LocalSelfAttention = prim::GetAttr[name="self_attention"](%self.8)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.8)
    %8 : Tensor = prim::CallMethod[name="forward"](%4, %input.2)
    %9 : Tensor = prim::CallMethod[name="forward"](%3, %8)
    %10 : Tensor = prim::CallMethod[name="forward"](%2, %9)
    return (%10)

ReformerLayer.feed_forward
ChunkReformerFeedForward._actual_script_module
  graph(%self.16 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward,
        %input_tensor.1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput = prim::GetAttr[name="output"](%self.16)
    %3 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense = prim::GetAttr[name="dense"](%self.16)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.16)
    %29 : Tensor = prim::CallMethod[name="forward"](%4, %input_tensor.1)
    %30 : Tensor = prim::CallMethod[name="forward"](%3, %29)
    %31 : Tensor = prim::CallMethod[name="forward"](%2, %30)
    return (%31)

ReformerAttention.layer_norm
LayerNorm._actual_script_module
  graph(%self.9 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.2 : Float(17:6656, 13:512, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.9)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.9)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.layer_norm # torch/nn/functional.py:2048:0
    %hidden_states.3 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%input.2, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.layer_norm # torch/nn/functional.py:2048:0
    return (%hidden_states.3)

ReformerAttention.output
ReformerSelfOutput._actual_script_module
  graph(%self.14 : __torch__.transformers.modeling_reformer.ReformerSelfOutput,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.14)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.output # torch/nn/functional.py:973:0
    %attn_output.1 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.output # torch/nn/functional.py:973:0
    return (%attn_output.1)

ReformerAttention.self_attention
LocalSelfAttention._actual_script_module
  graph(%self.10 : __torch__.transformers.modeling_reformer.LocalSelfAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="value"](%self.10)
    %3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="key"](%self.10)
    %4 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="query"](%self.10)
    %213 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %214 : Tensor = prim::CallMethod[name="forward"](%3, %1)
    %215 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %28 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %29 : int = aten::size(%213, %28), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %30 : Long() = prim::NumToTensor(%29), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %31 : int = aten::Int(%30), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %32 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %33 : int = aten::size(%213, %32), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %34 : Long() = prim::NumToTensor(%33), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %35 : int = aten::Int(%34), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %39 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:302:0
    %40 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:302:0
    %41 : int[] = prim::ListConstruct(%31, %35, %39, %40), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %x.2 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%213, %41), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:302:0
    %43 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:303:0
    %44 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:303:0
    %query_vectors.1 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.2, %43, %44), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:303:0
    %46 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %47 : int = aten::size(%214, %46), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %48 : Long() = prim::NumToTensor(%47), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %49 : int = aten::Int(%48), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %50 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %51 : int = aten::size(%214, %50), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %52 : Long() = prim::NumToTensor(%51), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %53 : int = aten::Int(%52), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %57 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:302:0
    %58 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:302:0
    %59 : int[] = prim::ListConstruct(%49, %53, %57, %58), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %x.4 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%214, %59), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:302:0
    %61 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:303:0
    %62 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:303:0
    %key_vectors.1 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.4, %61, %62), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:303:0
    %64 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %65 : int = aten::size(%215, %64), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %66 : Long() = prim::NumToTensor(%65), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %67 : int = aten::Int(%66), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %68 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %69 : int = aten::size(%215, %68), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:301:0
    %70 : Long() = prim::NumToTensor(%69), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %71 : int = aten::Int(%70), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %75 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:302:0
    %76 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:302:0
    %77 : int[] = prim::ListConstruct(%67, %71, %75, %76), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %x.6 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%215, %77), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:302:0
    %79 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:303:0
    %80 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:303:0
    %value_vectors.1 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.6, %79, %80), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:303:0
    %124 : Float() = prim::Constant[value={64}](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %125 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %126 : int = prim::Constant[value=6](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %127 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %128 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %129 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %130 : Float() = aten::to(%124, %125, %126, %127, %128, %129), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %131 : Float() = aten::detach(%130), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %132 : Float() = aten::sqrt(%131), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1111:0
    %key_vectors.2 : Float(17:9984, 12:64, 13:768, 64:1) = aten::div(%key_vectors.1, %132), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1111:0
    %145 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %146 : int = prim::Constant[value=-2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %147 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_vectors.2, %145, %146), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %query_key_dots.1 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_vectors.1, %147), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %161 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1183:0
    %162 : int[] = prim::ListConstruct(%161), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %163 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1183:0
    %logits.1 : Float(17:156, 12:13, 13:1, 1:1) = aten::logsumexp(%query_key_dots.1, %162, %163), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1183:0
    %165 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1184:0
    %166 : Float(17:2028, 12:169, 13:13, 13:1) = aten::sub(%query_key_dots.1, %logits.1, %165), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1184:0
    %input.3 : Float(17:2028, 12:169, 13:13, 13:1) = aten::exp(%166), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1184:0
    %168 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # torch/nn/functional.py:973:0
    %169 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # torch/nn/functional.py:973:0
    %attention_probs.1 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.3, %168, %169), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # torch/nn/functional.py:973:0
    %out_vectors.1 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.1, %value_vectors.1), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:1197:0
    %190 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:309:0
    %191 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:309:0
    %192 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:309:0
    %193 : int = prim::Constant[value=3](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:309:0
    %194 : int[] = prim::ListConstruct(%190, %191, %192, %193), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %x.7 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%out_vectors.1, %194), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:309:0
    %196 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:310:0
    %197 : int = aten::size(%x.7, %196), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:310:0
    %198 : Long() = prim::NumToTensor(%197), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %199 : int = aten::Int(%198), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %209 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:310:0
    %210 : int = prim::Constant[value=768](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:310:0
    %211 : int[] = prim::ListConstruct(%199, %209, %210), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention
    %input.4 : Float(17:9984, 13:768, 768:1) = aten::reshape(%x.7, %211), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention # transformers/modeling_reformer.py:310:0
    return (%input.4)

LocalSelfAttention.key
Linear._actual_script_module
  graph(%self.12 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.12)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention/__module.reformer.encoder.layers.0.attention.self_attention.key # torch/nn/functional.py:1676:0
    %x.3 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention/__module.reformer.encoder.layers.0.attention.self_attention.key # torch/nn/functional.py:1676:0
    return (%x.3)

LocalSelfAttention.query
Linear._actual_script_module
  graph(%self.11 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.11)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention/__module.reformer.encoder.layers.0.attention.self_attention.query # torch/nn/functional.py:1676:0
    %x.1 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention/__module.reformer.encoder.layers.0.attention.self_attention.query # torch/nn/functional.py:1676:0
    return (%x.1)

LocalSelfAttention.value
Linear._actual_script_module
  graph(%self.13 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.13)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention/__module.reformer.encoder.layers.0.attention.self_attention.value # torch/nn/functional.py:1676:0
    %x.5 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.self_attention/__module.reformer.encoder.layers.0.attention.self_attention.value # torch/nn/functional.py:1676:0
    return (%x.5)

ReformerSelfOutput.dense
Linear._actual_script_module
  graph(%self.15 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.15)
    %3 : Float(768:1, 256:768) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.output/__module.reformer.encoder.layers.0.attention.output.dense # torch/nn/functional.py:1676:0
    %input.5 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.attention/__module.reformer.encoder.layers.0.attention.output/__module.reformer.encoder.layers.0.attention.output.dense # torch/nn/functional.py:1676:0
    return (%input.5)

ChunkReformerFeedForward.dense
ReformerFeedForwardDense._actual_script_module
  graph(%self.18 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.18)
    %8 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.dense # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.dense # torch/nn/functional.py:973:0
    %input.8 : Float(17:6656, 13:512, 512:1) = aten::dropout(%8, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.dense # torch/nn/functional.py:973:0
    %input.9 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.8), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.dense # torch/nn/functional.py:1119:0
    return (%input.9)

ChunkReformerFeedForward.layer_norm
LayerNorm._actual_script_module
  graph(%self.17 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input_tensor.1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.17)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.17)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %input.6 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%input_tensor.1, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    return (%input.6)

ChunkReformerFeedForward.output
ReformerFeedForwardOutput._actual_script_module
  graph(%self.20 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.20)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.output # torch/nn/functional.py:973:0
    %6 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.output # torch/nn/functional.py:973:0
    return (%6)

ReformerFeedForwardDense.dense
Linear._actual_script_module
  graph(%self.19 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.19)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.19)
    %4 : Float(256:1, 512:256) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.dense/__module.reformer.encoder.layers.0.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %output.1 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.dense/__module.reformer.encoder.layers.0.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.dense/__module.reformer.encoder.layers.0.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    %input.7 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.1, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.dense/__module.reformer.encoder.layers.0.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    return (%input.7)

ReformerFeedForwardOutput.dense
Linear._actual_script_module
  graph(%self.21 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.21)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.21)
    %4 : Float(512:1, 256:512) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.output/__module.reformer.encoder.layers.0.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %output.2 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.output/__module.reformer.encoder.layers.0.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.output/__module.reformer.encoder.layers.0.feed_forward.output.dense # torch/nn/functional.py:1678:0
    %input.10 : Float(17:3328, 13:256, 256:1) = aten::add_(%output.2, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.0/__module.reformer.encoder.layers.0.feed_forward/__module.reformer.encoder.layers.0.feed_forward.output/__module.reformer.encoder.layers.0.feed_forward.output.dense # torch/nn/functional.py:1678:0
    return (%input.10)

ReformerLayer._actual_script_module
  graph(%self.22 : __torch__.transformers.modeling_reformer.ReformerLayer,
        %1 : Float(17:3328, 13:256, 256:1),
        %2 : Float(17:3328, 13:256, 256:1)):
    %3 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward = prim::GetAttr[name="feed_forward"](%self.22)
    %4 : __torch__.transformers.modeling_reformer.ReformerAttention = prim::GetAttr[name="attention"](%self.22)
    %12 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1 # transformers/modeling_reformer.py:1498:0
    %input_tensor.2 : Float(17:3328, 13:256, 256:1) = aten::add(%2, %12, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1 # transformers/modeling_reformer.py:1498:0
    %13 : Tensor = prim::CallMethod[name="forward"](%3, %input_tensor.2)
    %9 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1 # transformers/modeling_reformer.py:1508:0
    %input.20 : Float(17:3328, 13:256, 256:1) = aten::add(%1, %13, %9), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1 # transformers/modeling_reformer.py:1508:0
    %11 : (Float(17:3328, 13:256, 256:1), Float(17:3328, 13:256, 256:1)) = prim::TupleConstruct(%input.20, %input_tensor.2)
    return (%11)

ReformerLayer.attention
ReformerAttention._actual_script_module
  graph(%self.23 : __torch__.transformers.modeling_reformer.ReformerAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerSelfOutput = prim::GetAttr[name="output"](%self.23)
    %3 : __torch__.transformers.modeling_reformer.LSHSelfAttention = prim::GetAttr[name="self_attention"](%self.23)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.23)
    %8 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %9 : Tensor = prim::CallMethod[name="forward"](%3, %8)
    %10 : Tensor = prim::CallMethod[name="forward"](%2, %9)
    return (%10)

ReformerLayer.feed_forward
ChunkReformerFeedForward._actual_script_module
  graph(%self.30 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward,
        %input_tensor.2 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput = prim::GetAttr[name="output"](%self.30)
    %3 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense = prim::GetAttr[name="dense"](%self.30)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.30)
    %29 : Tensor = prim::CallMethod[name="forward"](%4, %input_tensor.2)
    %30 : Tensor = prim::CallMethod[name="forward"](%3, %29)
    %31 : Tensor = prim::CallMethod[name="forward"](%2, %30)
    return (%31)

ReformerAttention.layer_norm
LayerNorm._actual_script_module
  graph(%self.24 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.24)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.24)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.layer_norm # torch/nn/functional.py:2048:0
    %hidden_states.4 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%1, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.layer_norm # torch/nn/functional.py:2048:0
    return (%hidden_states.4)

ReformerAttention.output
ReformerSelfOutput._actual_script_module
  graph(%self.28 : __torch__.transformers.modeling_reformer.ReformerSelfOutput,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.28)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.output # torch/nn/functional.py:973:0
    %attn_output.2 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.output # torch/nn/functional.py:973:0
    return (%attn_output.2)

ReformerAttention.self_attention
LSHSelfAttention._actual_script_module
  graph(%self.25 : __torch__.transformers.modeling_reformer.LSHSelfAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="self_mask_value_float32"](%self.25)
    %3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="value"](%self.25)
    %4 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="query_key"](%self.25)
    %8 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:370:0
    %9 : int = aten::size(%1, %8), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:370:0
    %sequence_length.2 : Long() = prim::NumToTensor(%9), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %11 : Scalar = aten::ScalarImplicit(%sequence_length.2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %15 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:371:0
    %16 : int = aten::size(%1, %15), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:371:0
    %batch_size.3 : Long() = prim::NumToTensor(%16), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %18 : int = aten::Int(%batch_size.3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %206 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %207 : Tensor = prim::CallMethod[name="forward"](%3, %1)
    %27 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:301:0
    %28 : int = aten::size(%206, %27), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:301:0
    %29 : Long() = prim::NumToTensor(%28), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %30 : int = aten::Int(%29), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %31 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:301:0
    %32 : int = aten::size(%206, %31), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:301:0
    %33 : Long() = prim::NumToTensor(%32), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %34 : int = aten::Int(%33), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %38 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:302:0
    %39 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:302:0
    %40 : int[] = prim::ListConstruct(%30, %34, %38, %39), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %x.9 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%206, %40), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:302:0
    %42 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:303:0
    %43 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:303:0
    %query_key_vectors.1 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.9, %42, %43), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:303:0
    %45 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:301:0
    %46 : int = aten::size(%207, %45), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:301:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %48 : int = aten::Int(%47), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %49 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:301:0
    %50 : int = aten::size(%207, %49), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:301:0
    %51 : Long() = prim::NumToTensor(%50), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %52 : int = aten::Int(%51), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %56 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:302:0
    %57 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:302:0
    %58 : int[] = prim::ListConstruct(%48, %52, %56, %57), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %x.11 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%207, %58), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:302:0
    %60 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:303:0
    %61 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:303:0
    %value_vectors.2 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.11, %60, %61), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:303:0
    %93 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %94 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:517:0
    %95 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:517:0
    %96 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:517:0
    %97 : Long(13:1) = aten::arange(%11, %93, %94, %95, %96), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:517:0
    %98 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:517:0
    %99 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:517:0
    %100 : int[] = prim::ListConstruct(%18, %98, %99), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %sorted_bucket_idx_per_hash.1 : Long(17:156, 12:13, 13:1) = aten::repeat(%97, %100), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:517:0
    %102 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:973:0
    %103 : Float(17:9984, 12:64, 13:768, 64:1) = aten::pow(%query_key_vectors.1, %102), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:973:0
    %104 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:973:0
    %105 : int[] = prim::ListConstruct(%104), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %106 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:973:0
    %107 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %variance.1 : Float(17:156, 12:13, 13:1, 1:1) = aten::mean(%103, %105, %106, %107), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:973:0
    %109 : Double() = prim::Constant[value={1e-06}](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:974:0
    %110 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:974:0
    %111 : Float(17:156, 12:13, 13:1, 1:1) = aten::add(%variance.1, %109, %110), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:974:0
    %112 : Float(17:156, 12:13, 13:1, 1:1) = aten::rsqrt(%111), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:974:0
    %vectors.1 : Float(17:9984, 12:64, 13:768, 64:1) = aten::mul(%query_key_vectors.1, %112), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:974:0
    %114 : Float() = prim::Constant[value={64}](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:965:0
    %115 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:965:0
    %116 : int = prim::Constant[value=6](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:965:0
    %117 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:965:0
    %118 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:965:0
    %119 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %120 : Float() = aten::to(%114, %115, %116, %117, %118, %119), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:965:0
    %121 : Float() = aten::detach(%120), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:965:0
    %122 : Float() = aten::rsqrt(%121), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:964:0
    %key_vectors.3 : Float(17:9984, 12:64, 13:768, 64:1) = aten::mul(%vectors.1, %122), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:964:0
    %124 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:741:0
    %125 : int = prim::Constant[value=-2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:741:0
    %126 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_vectors.3, %124, %125), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:741:0
    %query_key_dots.2 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_key_vectors.1, %126), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:741:0
    %140 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %141 : Long(17:156, 12:13, 13:1, 1:1) = aten::unsqueeze(%sorted_bucket_idx_per_hash.1, %140), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %142 : int = prim::Constant[value=-2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %143 : Long(17:156, 12:13, 1:13, 13:1) = aten::unsqueeze(%sorted_bucket_idx_per_hash.1, %142), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %144 : Bool(17:2028, 12:169, 13:13, 13:1) = aten::ne(%141, %143), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %145 : int = prim::Constant[value=11](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %146 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %147 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %148 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %149 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %150 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %151 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %self_mask.1 : Bool(17:2028, 12:169, 13:13, 13:1) = aten::to(%144, %145, %146, %147, %148, %149, %150, %151), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:798:0
    %query_key_dots.3 : Float(17:2028, 12:169, 13:13, 13:1) = aten::where(%self_mask.1, %query_key_dots.2, %2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:803:0
    %154 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:808:0
    %155 : int[] = prim::ListConstruct(%154), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %156 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:808:0
    %logits.2 : Float(17:156, 12:13, 13:1, 1:1) = aten::logsumexp(%query_key_dots.3, %155, %156), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:808:0
    %158 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:810:0
    %159 : Float(17:2028, 12:169, 13:13, 13:1) = aten::sub(%query_key_dots.3, %logits.2, %158), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:810:0
    %input.12 : Float(17:2028, 12:169, 13:13, 13:1) = aten::exp(%159), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:810:0
    %161 : float = prim::Constant[value=0.](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # torch/nn/functional.py:973:0
    %162 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # torch/nn/functional.py:973:0
    %attention_probs.2 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.12, %161, %162), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # torch/nn/functional.py:973:0
    %out_vectors.2 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.2, %value_vectors.2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:823:0
    %183 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:309:0
    %184 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:309:0
    %185 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:309:0
    %186 : int = prim::Constant[value=3](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:309:0
    %187 : int[] = prim::ListConstruct(%183, %184, %185, %186), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %x.12 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%out_vectors.2, %187), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:309:0
    %189 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:310:0
    %190 : int = aten::size(%x.12, %189), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:310:0
    %191 : Long() = prim::NumToTensor(%190), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %192 : int = aten::Int(%191), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %202 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:310:0
    %203 : int = prim::Constant[value=768](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:310:0
    %204 : int[] = prim::ListConstruct(%192, %202, %203), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention
    %input.13 : Float(17:9984, 13:768, 768:1) = aten::reshape(%x.12, %204), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention # transformers/modeling_reformer.py:310:0
    return (%input.13)

LSHSelfAttention.query_key
Linear._actual_script_module
  graph(%self.26 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.26)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention/__module.reformer.encoder.layers.1.attention.self_attention.query_key # torch/nn/functional.py:1676:0
    %x.8 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention/__module.reformer.encoder.layers.1.attention.self_attention.query_key # torch/nn/functional.py:1676:0
    return (%x.8)

LSHSelfAttention.value
Linear._actual_script_module
  graph(%self.27 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.27)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention/__module.reformer.encoder.layers.1.attention.self_attention.value # torch/nn/functional.py:1676:0
    %x.10 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.self_attention/__module.reformer.encoder.layers.1.attention.self_attention.value # torch/nn/functional.py:1676:0
    return (%x.10)

ReformerSelfOutput.dense
Linear._actual_script_module
  graph(%self.29 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.29)
    %3 : Float(768:1, 256:768) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.output/__module.reformer.encoder.layers.1.attention.output.dense # torch/nn/functional.py:1676:0
    %input.14 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.attention/__module.reformer.encoder.layers.1.attention.output/__module.reformer.encoder.layers.1.attention.output.dense # torch/nn/functional.py:1676:0
    return (%input.14)

ChunkReformerFeedForward.dense
ReformerFeedForwardDense._actual_script_module
  graph(%self.32 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.32)
    %8 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.dense # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.dense # torch/nn/functional.py:973:0
    %input.17 : Float(17:6656, 13:512, 512:1) = aten::dropout(%8, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.dense # torch/nn/functional.py:973:0
    %input.18 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.17), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.dense # torch/nn/functional.py:1119:0
    return (%input.18)

ChunkReformerFeedForward.layer_norm
LayerNorm._actual_script_module
  graph(%self.31 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input_tensor.2 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.31)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.31)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %input.15 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%input_tensor.2, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    return (%input.15)

ChunkReformerFeedForward.output
ReformerFeedForwardOutput._actual_script_module
  graph(%self.34 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.34)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.output # torch/nn/functional.py:973:0
    %6 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.output # torch/nn/functional.py:973:0
    return (%6)

ReformerFeedForwardDense.dense
Linear._actual_script_module
  graph(%self.33 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.33)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.33)
    %4 : Float(256:1, 512:256) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.dense/__module.reformer.encoder.layers.1.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %output.3 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.dense/__module.reformer.encoder.layers.1.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.dense/__module.reformer.encoder.layers.1.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    %input.16 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.3, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.dense/__module.reformer.encoder.layers.1.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    return (%input.16)

ReformerFeedForwardOutput.dense
Linear._actual_script_module
  graph(%self.35 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.35)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.35)
    %4 : Float(512:1, 256:512) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.output/__module.reformer.encoder.layers.1.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %output.4 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.output/__module.reformer.encoder.layers.1.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.output/__module.reformer.encoder.layers.1.feed_forward.output.dense # torch/nn/functional.py:1678:0
    %input.19 : Float(17:3328, 13:256, 256:1) = aten::add_(%output.4, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.1/__module.reformer.encoder.layers.1.feed_forward/__module.reformer.encoder.layers.1.feed_forward.output/__module.reformer.encoder.layers.1.feed_forward.output.dense # torch/nn/functional.py:1678:0
    return (%input.19)

ReformerLayer._actual_script_module
  graph(%self.36 : __torch__.transformers.modeling_reformer.ReformerLayer,
        %1 : Float(17:3328, 13:256, 256:1),
        %2 : Float(17:3328, 13:256, 256:1)):
    %3 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward = prim::GetAttr[name="feed_forward"](%self.36)
    %4 : __torch__.transformers.modeling_reformer.ReformerAttention = prim::GetAttr[name="attention"](%self.36)
    %12 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2 # transformers/modeling_reformer.py:1498:0
    %input_tensor.3 : Float(17:3328, 13:256, 256:1) = aten::add(%2, %12, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2 # transformers/modeling_reformer.py:1498:0
    %13 : Tensor = prim::CallMethod[name="forward"](%3, %input_tensor.3)
    %9 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2 # transformers/modeling_reformer.py:1508:0
    %input.29 : Float(17:3328, 13:256, 256:1) = aten::add(%1, %13, %9), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2 # transformers/modeling_reformer.py:1508:0
    %11 : (Float(17:3328, 13:256, 256:1), Float(17:3328, 13:256, 256:1)) = prim::TupleConstruct(%input.29, %input_tensor.3)
    return (%11)

ReformerLayer.attention
ReformerAttention._actual_script_module
  graph(%self.37 : __torch__.transformers.modeling_reformer.ReformerAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerSelfOutput = prim::GetAttr[name="output"](%self.37)
    %3 : __torch__.transformers.modeling_reformer.LocalSelfAttention = prim::GetAttr[name="self_attention"](%self.37)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.37)
    %8 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %9 : Tensor = prim::CallMethod[name="forward"](%3, %8)
    %10 : Tensor = prim::CallMethod[name="forward"](%2, %9)
    return (%10)

ReformerLayer.feed_forward
ChunkReformerFeedForward._actual_script_module
  graph(%self.45 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward,
        %input_tensor.3 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput = prim::GetAttr[name="output"](%self.45)
    %3 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense = prim::GetAttr[name="dense"](%self.45)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.45)
    %29 : Tensor = prim::CallMethod[name="forward"](%4, %input_tensor.3)
    %30 : Tensor = prim::CallMethod[name="forward"](%3, %29)
    %31 : Tensor = prim::CallMethod[name="forward"](%2, %30)
    return (%31)

ReformerAttention.layer_norm
LayerNorm._actual_script_module
  graph(%self.38 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.38)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.38)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.layer_norm # torch/nn/functional.py:2048:0
    %hidden_states.5 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%1, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.layer_norm # torch/nn/functional.py:2048:0
    return (%hidden_states.5)

ReformerAttention.output
ReformerSelfOutput._actual_script_module
  graph(%self.43 : __torch__.transformers.modeling_reformer.ReformerSelfOutput,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.43)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.output # torch/nn/functional.py:973:0
    %attn_output.3 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.output # torch/nn/functional.py:973:0
    return (%attn_output.3)

ReformerAttention.self_attention
LocalSelfAttention._actual_script_module
  graph(%self.39 : __torch__.transformers.modeling_reformer.LocalSelfAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="value"](%self.39)
    %3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="key"](%self.39)
    %4 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="query"](%self.39)
    %213 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %214 : Tensor = prim::CallMethod[name="forward"](%3, %1)
    %215 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %28 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %29 : int = aten::size(%213, %28), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %30 : Long() = prim::NumToTensor(%29), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %31 : int = aten::Int(%30), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %32 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %33 : int = aten::size(%213, %32), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %34 : Long() = prim::NumToTensor(%33), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %35 : int = aten::Int(%34), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %39 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:302:0
    %40 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:302:0
    %41 : int[] = prim::ListConstruct(%31, %35, %39, %40), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %x.14 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%213, %41), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:302:0
    %43 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:303:0
    %44 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:303:0
    %query_vectors.2 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.14, %43, %44), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:303:0
    %46 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %47 : int = aten::size(%214, %46), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %48 : Long() = prim::NumToTensor(%47), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %49 : int = aten::Int(%48), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %50 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %51 : int = aten::size(%214, %50), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %52 : Long() = prim::NumToTensor(%51), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %53 : int = aten::Int(%52), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %57 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:302:0
    %58 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:302:0
    %59 : int[] = prim::ListConstruct(%49, %53, %57, %58), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %x.16 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%214, %59), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:302:0
    %61 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:303:0
    %62 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:303:0
    %key_vectors.4 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.16, %61, %62), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:303:0
    %64 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %65 : int = aten::size(%215, %64), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %66 : Long() = prim::NumToTensor(%65), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %67 : int = aten::Int(%66), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %68 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %69 : int = aten::size(%215, %68), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:301:0
    %70 : Long() = prim::NumToTensor(%69), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %71 : int = aten::Int(%70), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %75 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:302:0
    %76 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:302:0
    %77 : int[] = prim::ListConstruct(%67, %71, %75, %76), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %x.18 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%215, %77), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:302:0
    %79 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:303:0
    %80 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:303:0
    %value_vectors.3 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.18, %79, %80), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:303:0
    %124 : Float() = prim::Constant[value={64}](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %125 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %126 : int = prim::Constant[value=6](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %127 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %128 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %129 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %130 : Float() = aten::to(%124, %125, %126, %127, %128, %129), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %131 : Float() = aten::detach(%130), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %132 : Float() = aten::sqrt(%131), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1111:0
    %key_vectors.5 : Float(17:9984, 12:64, 13:768, 64:1) = aten::div(%key_vectors.4, %132), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1111:0
    %145 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %146 : int = prim::Constant[value=-2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %147 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_vectors.5, %145, %146), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %query_key_dots.4 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_vectors.2, %147), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %161 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1183:0
    %162 : int[] = prim::ListConstruct(%161), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %163 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1183:0
    %logits.3 : Float(17:156, 12:13, 13:1, 1:1) = aten::logsumexp(%query_key_dots.4, %162, %163), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1183:0
    %165 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1184:0
    %166 : Float(17:2028, 12:169, 13:13, 13:1) = aten::sub(%query_key_dots.4, %logits.3, %165), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1184:0
    %input.21 : Float(17:2028, 12:169, 13:13, 13:1) = aten::exp(%166), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1184:0
    %168 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # torch/nn/functional.py:973:0
    %169 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # torch/nn/functional.py:973:0
    %attention_probs.3 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.21, %168, %169), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # torch/nn/functional.py:973:0
    %out_vectors.3 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.3, %value_vectors.3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:1197:0
    %190 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:309:0
    %191 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:309:0
    %192 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:309:0
    %193 : int = prim::Constant[value=3](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:309:0
    %194 : int[] = prim::ListConstruct(%190, %191, %192, %193), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %x.19 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%out_vectors.3, %194), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:309:0
    %196 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:310:0
    %197 : int = aten::size(%x.19, %196), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:310:0
    %198 : Long() = prim::NumToTensor(%197), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %199 : int = aten::Int(%198), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %209 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:310:0
    %210 : int = prim::Constant[value=768](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:310:0
    %211 : int[] = prim::ListConstruct(%199, %209, %210), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention
    %input.22 : Float(17:9984, 13:768, 768:1) = aten::reshape(%x.19, %211), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention # transformers/modeling_reformer.py:310:0
    return (%input.22)

LocalSelfAttention.key
Linear._actual_script_module
  graph(%self.41 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.41)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention/__module.reformer.encoder.layers.2.attention.self_attention.key # torch/nn/functional.py:1676:0
    %x.15 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention/__module.reformer.encoder.layers.2.attention.self_attention.key # torch/nn/functional.py:1676:0
    return (%x.15)

LocalSelfAttention.query
Linear._actual_script_module
  graph(%self.40 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.40)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention/__module.reformer.encoder.layers.2.attention.self_attention.query # torch/nn/functional.py:1676:0
    %x.13 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention/__module.reformer.encoder.layers.2.attention.self_attention.query # torch/nn/functional.py:1676:0
    return (%x.13)

LocalSelfAttention.value
Linear._actual_script_module
  graph(%self.42 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.42)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention/__module.reformer.encoder.layers.2.attention.self_attention.value # torch/nn/functional.py:1676:0
    %x.17 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.self_attention/__module.reformer.encoder.layers.2.attention.self_attention.value # torch/nn/functional.py:1676:0
    return (%x.17)

ReformerSelfOutput.dense
Linear._actual_script_module
  graph(%self.44 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.44)
    %3 : Float(768:1, 256:768) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.output/__module.reformer.encoder.layers.2.attention.output.dense # torch/nn/functional.py:1676:0
    %input.23 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.attention/__module.reformer.encoder.layers.2.attention.output/__module.reformer.encoder.layers.2.attention.output.dense # torch/nn/functional.py:1676:0
    return (%input.23)

ChunkReformerFeedForward.dense
ReformerFeedForwardDense._actual_script_module
  graph(%self.47 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.47)
    %8 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.dense # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.dense # torch/nn/functional.py:973:0
    %input.26 : Float(17:6656, 13:512, 512:1) = aten::dropout(%8, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.dense # torch/nn/functional.py:973:0
    %input.27 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.26), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.dense # torch/nn/functional.py:1119:0
    return (%input.27)

ChunkReformerFeedForward.layer_norm
LayerNorm._actual_script_module
  graph(%self.46 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input_tensor.3 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.46)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.46)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %input.24 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%input_tensor.3, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    return (%input.24)

ChunkReformerFeedForward.output
ReformerFeedForwardOutput._actual_script_module
  graph(%self.49 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.49)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.output # torch/nn/functional.py:973:0
    %6 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.output # torch/nn/functional.py:973:0
    return (%6)

ReformerFeedForwardDense.dense
Linear._actual_script_module
  graph(%self.48 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.48)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.48)
    %4 : Float(256:1, 512:256) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.dense/__module.reformer.encoder.layers.2.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %output.5 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.dense/__module.reformer.encoder.layers.2.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.dense/__module.reformer.encoder.layers.2.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    %input.25 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.5, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.dense/__module.reformer.encoder.layers.2.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    return (%input.25)

ReformerFeedForwardOutput.dense
Linear._actual_script_module
  graph(%self.50 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.50)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.50)
    %4 : Float(512:1, 256:512) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.output/__module.reformer.encoder.layers.2.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %output.6 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.output/__module.reformer.encoder.layers.2.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.output/__module.reformer.encoder.layers.2.feed_forward.output.dense # torch/nn/functional.py:1678:0
    %input.28 : Float(17:3328, 13:256, 256:1) = aten::add_(%output.6, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.2/__module.reformer.encoder.layers.2.feed_forward/__module.reformer.encoder.layers.2.feed_forward.output/__module.reformer.encoder.layers.2.feed_forward.output.dense # torch/nn/functional.py:1678:0
    return (%input.28)

ReformerLayer._actual_script_module
  graph(%self.51 : __torch__.transformers.modeling_reformer.ReformerLayer,
        %1 : Float(17:3328, 13:256, 256:1),
        %2 : Float(17:3328, 13:256, 256:1)):
    %3 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward = prim::GetAttr[name="feed_forward"](%self.51)
    %4 : __torch__.transformers.modeling_reformer.ReformerAttention = prim::GetAttr[name="attention"](%self.51)
    %12 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3 # transformers/modeling_reformer.py:1498:0
    %input_tensor.4 : Float(17:3328, 13:256, 256:1) = aten::add(%2, %12, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3 # transformers/modeling_reformer.py:1498:0
    %13 : Tensor = prim::CallMethod[name="forward"](%3, %input_tensor.4)
    %9 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3 # transformers/modeling_reformer.py:1508:0
    %input.38 : Float(17:3328, 13:256, 256:1) = aten::add(%1, %13, %9), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3 # transformers/modeling_reformer.py:1508:0
    %11 : (Float(17:3328, 13:256, 256:1), Float(17:3328, 13:256, 256:1)) = prim::TupleConstruct(%input.38, %input_tensor.4)
    return (%11)

ReformerLayer.attention
ReformerAttention._actual_script_module
  graph(%self.52 : __torch__.transformers.modeling_reformer.ReformerAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerSelfOutput = prim::GetAttr[name="output"](%self.52)
    %3 : __torch__.transformers.modeling_reformer.LSHSelfAttention = prim::GetAttr[name="self_attention"](%self.52)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.52)
    %8 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %9 : Tensor = prim::CallMethod[name="forward"](%3, %8)
    %10 : Tensor = prim::CallMethod[name="forward"](%2, %9)
    return (%10)

ReformerLayer.feed_forward
ChunkReformerFeedForward._actual_script_module
  graph(%self.59 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward,
        %input_tensor.4 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput = prim::GetAttr[name="output"](%self.59)
    %3 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense = prim::GetAttr[name="dense"](%self.59)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.59)
    %29 : Tensor = prim::CallMethod[name="forward"](%4, %input_tensor.4)
    %30 : Tensor = prim::CallMethod[name="forward"](%3, %29)
    %31 : Tensor = prim::CallMethod[name="forward"](%2, %30)
    return (%31)

ReformerAttention.layer_norm
LayerNorm._actual_script_module
  graph(%self.53 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.53)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.53)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.layer_norm # torch/nn/functional.py:2048:0
    %hidden_states.6 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%1, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.layer_norm # torch/nn/functional.py:2048:0
    return (%hidden_states.6)

ReformerAttention.output
ReformerSelfOutput._actual_script_module
  graph(%self.57 : __torch__.transformers.modeling_reformer.ReformerSelfOutput,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.57)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.output # torch/nn/functional.py:973:0
    %attn_output.4 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.output # torch/nn/functional.py:973:0
    return (%attn_output.4)

ReformerAttention.self_attention
LSHSelfAttention._actual_script_module
  graph(%self.54 : __torch__.transformers.modeling_reformer.LSHSelfAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="self_mask_value_float32"](%self.54)
    %3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="value"](%self.54)
    %4 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="query_key"](%self.54)
    %8 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:370:0
    %9 : int = aten::size(%1, %8), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:370:0
    %sequence_length.4 : Long() = prim::NumToTensor(%9), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %11 : Scalar = aten::ScalarImplicit(%sequence_length.4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %15 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:371:0
    %16 : int = aten::size(%1, %15), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:371:0
    %batch_size.5 : Long() = prim::NumToTensor(%16), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %18 : int = aten::Int(%batch_size.5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %206 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %207 : Tensor = prim::CallMethod[name="forward"](%3, %1)
    %27 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:301:0
    %28 : int = aten::size(%206, %27), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:301:0
    %29 : Long() = prim::NumToTensor(%28), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %30 : int = aten::Int(%29), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %31 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:301:0
    %32 : int = aten::size(%206, %31), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:301:0
    %33 : Long() = prim::NumToTensor(%32), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %34 : int = aten::Int(%33), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %38 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:302:0
    %39 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:302:0
    %40 : int[] = prim::ListConstruct(%30, %34, %38, %39), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %x.21 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%206, %40), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:302:0
    %42 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:303:0
    %43 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:303:0
    %query_key_vectors.2 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.21, %42, %43), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:303:0
    %45 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:301:0
    %46 : int = aten::size(%207, %45), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:301:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %48 : int = aten::Int(%47), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %49 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:301:0
    %50 : int = aten::size(%207, %49), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:301:0
    %51 : Long() = prim::NumToTensor(%50), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %52 : int = aten::Int(%51), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %56 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:302:0
    %57 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:302:0
    %58 : int[] = prim::ListConstruct(%48, %52, %56, %57), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %x.23 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%207, %58), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:302:0
    %60 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:303:0
    %61 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:303:0
    %value_vectors.4 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.23, %60, %61), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:303:0
    %93 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %94 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:517:0
    %95 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:517:0
    %96 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:517:0
    %97 : Long(13:1) = aten::arange(%11, %93, %94, %95, %96), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:517:0
    %98 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:517:0
    %99 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:517:0
    %100 : int[] = prim::ListConstruct(%18, %98, %99), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %sorted_bucket_idx_per_hash.2 : Long(17:156, 12:13, 13:1) = aten::repeat(%97, %100), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:517:0
    %102 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:973:0
    %103 : Float(17:9984, 12:64, 13:768, 64:1) = aten::pow(%query_key_vectors.2, %102), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:973:0
    %104 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:973:0
    %105 : int[] = prim::ListConstruct(%104), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %106 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:973:0
    %107 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %variance.2 : Float(17:156, 12:13, 13:1, 1:1) = aten::mean(%103, %105, %106, %107), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:973:0
    %109 : Double() = prim::Constant[value={1e-06}](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:974:0
    %110 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:974:0
    %111 : Float(17:156, 12:13, 13:1, 1:1) = aten::add(%variance.2, %109, %110), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:974:0
    %112 : Float(17:156, 12:13, 13:1, 1:1) = aten::rsqrt(%111), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:974:0
    %vectors.2 : Float(17:9984, 12:64, 13:768, 64:1) = aten::mul(%query_key_vectors.2, %112), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:974:0
    %114 : Float() = prim::Constant[value={64}](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:965:0
    %115 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:965:0
    %116 : int = prim::Constant[value=6](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:965:0
    %117 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:965:0
    %118 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:965:0
    %119 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %120 : Float() = aten::to(%114, %115, %116, %117, %118, %119), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:965:0
    %121 : Float() = aten::detach(%120), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:965:0
    %122 : Float() = aten::rsqrt(%121), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:964:0
    %key_vectors.6 : Float(17:9984, 12:64, 13:768, 64:1) = aten::mul(%vectors.2, %122), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:964:0
    %124 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:741:0
    %125 : int = prim::Constant[value=-2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:741:0
    %126 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_vectors.6, %124, %125), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:741:0
    %query_key_dots.5 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_key_vectors.2, %126), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:741:0
    %140 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %141 : Long(17:156, 12:13, 13:1, 1:1) = aten::unsqueeze(%sorted_bucket_idx_per_hash.2, %140), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %142 : int = prim::Constant[value=-2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %143 : Long(17:156, 12:13, 1:13, 13:1) = aten::unsqueeze(%sorted_bucket_idx_per_hash.2, %142), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %144 : Bool(17:2028, 12:169, 13:13, 13:1) = aten::ne(%141, %143), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %145 : int = prim::Constant[value=11](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %146 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %147 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %148 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %149 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %150 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %151 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %self_mask.2 : Bool(17:2028, 12:169, 13:13, 13:1) = aten::to(%144, %145, %146, %147, %148, %149, %150, %151), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:798:0
    %query_key_dots.6 : Float(17:2028, 12:169, 13:13, 13:1) = aten::where(%self_mask.2, %query_key_dots.5, %2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:803:0
    %154 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:808:0
    %155 : int[] = prim::ListConstruct(%154), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %156 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:808:0
    %logits.4 : Float(17:156, 12:13, 13:1, 1:1) = aten::logsumexp(%query_key_dots.6, %155, %156), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:808:0
    %158 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:810:0
    %159 : Float(17:2028, 12:169, 13:13, 13:1) = aten::sub(%query_key_dots.6, %logits.4, %158), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:810:0
    %input.30 : Float(17:2028, 12:169, 13:13, 13:1) = aten::exp(%159), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:810:0
    %161 : float = prim::Constant[value=0.](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # torch/nn/functional.py:973:0
    %162 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # torch/nn/functional.py:973:0
    %attention_probs.4 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.30, %161, %162), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # torch/nn/functional.py:973:0
    %out_vectors.4 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.4, %value_vectors.4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:823:0
    %183 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:309:0
    %184 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:309:0
    %185 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:309:0
    %186 : int = prim::Constant[value=3](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:309:0
    %187 : int[] = prim::ListConstruct(%183, %184, %185, %186), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %x.24 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%out_vectors.4, %187), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:309:0
    %189 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:310:0
    %190 : int = aten::size(%x.24, %189), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:310:0
    %191 : Long() = prim::NumToTensor(%190), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %192 : int = aten::Int(%191), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %202 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:310:0
    %203 : int = prim::Constant[value=768](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:310:0
    %204 : int[] = prim::ListConstruct(%192, %202, %203), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention
    %input.31 : Float(17:9984, 13:768, 768:1) = aten::reshape(%x.24, %204), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention # transformers/modeling_reformer.py:310:0
    return (%input.31)

LSHSelfAttention.query_key
Linear._actual_script_module
  graph(%self.55 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.55)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention/__module.reformer.encoder.layers.3.attention.self_attention.query_key # torch/nn/functional.py:1676:0
    %x.20 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention/__module.reformer.encoder.layers.3.attention.self_attention.query_key # torch/nn/functional.py:1676:0
    return (%x.20)

LSHSelfAttention.value
Linear._actual_script_module
  graph(%self.56 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.56)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention/__module.reformer.encoder.layers.3.attention.self_attention.value # torch/nn/functional.py:1676:0
    %x.22 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.self_attention/__module.reformer.encoder.layers.3.attention.self_attention.value # torch/nn/functional.py:1676:0
    return (%x.22)

ReformerSelfOutput.dense
Linear._actual_script_module
  graph(%self.58 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.58)
    %3 : Float(768:1, 256:768) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.output/__module.reformer.encoder.layers.3.attention.output.dense # torch/nn/functional.py:1676:0
    %input.32 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.attention/__module.reformer.encoder.layers.3.attention.output/__module.reformer.encoder.layers.3.attention.output.dense # torch/nn/functional.py:1676:0
    return (%input.32)

ChunkReformerFeedForward.dense
ReformerFeedForwardDense._actual_script_module
  graph(%self.61 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.61)
    %8 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.dense # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.dense # torch/nn/functional.py:973:0
    %input.35 : Float(17:6656, 13:512, 512:1) = aten::dropout(%8, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.dense # torch/nn/functional.py:973:0
    %input.36 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.35), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.dense # torch/nn/functional.py:1119:0
    return (%input.36)

ChunkReformerFeedForward.layer_norm
LayerNorm._actual_script_module
  graph(%self.60 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input_tensor.4 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.60)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.60)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %input.33 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%input_tensor.4, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    return (%input.33)

ChunkReformerFeedForward.output
ReformerFeedForwardOutput._actual_script_module
  graph(%self.63 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.63)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.output # torch/nn/functional.py:973:0
    %6 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.output # torch/nn/functional.py:973:0
    return (%6)

ReformerFeedForwardDense.dense
Linear._actual_script_module
  graph(%self.62 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.62)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.62)
    %4 : Float(256:1, 512:256) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.dense/__module.reformer.encoder.layers.3.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %output.7 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.dense/__module.reformer.encoder.layers.3.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.dense/__module.reformer.encoder.layers.3.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    %input.34 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.7, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.dense/__module.reformer.encoder.layers.3.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    return (%input.34)

ReformerFeedForwardOutput.dense
Linear._actual_script_module
  graph(%self.64 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.64)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.64)
    %4 : Float(512:1, 256:512) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.output/__module.reformer.encoder.layers.3.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %output.8 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.output/__module.reformer.encoder.layers.3.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.output/__module.reformer.encoder.layers.3.feed_forward.output.dense # torch/nn/functional.py:1678:0
    %input.37 : Float(17:3328, 13:256, 256:1) = aten::add_(%output.8, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.3/__module.reformer.encoder.layers.3.feed_forward/__module.reformer.encoder.layers.3.feed_forward.output/__module.reformer.encoder.layers.3.feed_forward.output.dense # torch/nn/functional.py:1678:0
    return (%input.37)

ReformerLayer._actual_script_module
  graph(%self.65 : __torch__.transformers.modeling_reformer.ReformerLayer,
        %1 : Float(17:3328, 13:256, 256:1),
        %2 : Float(17:3328, 13:256, 256:1)):
    %3 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward = prim::GetAttr[name="feed_forward"](%self.65)
    %4 : __torch__.transformers.modeling_reformer.ReformerAttention = prim::GetAttr[name="attention"](%self.65)
    %12 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4 # transformers/modeling_reformer.py:1498:0
    %input_tensor.5 : Float(17:3328, 13:256, 256:1) = aten::add(%2, %12, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4 # transformers/modeling_reformer.py:1498:0
    %13 : Tensor = prim::CallMethod[name="forward"](%3, %input_tensor.5)
    %9 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4 # transformers/modeling_reformer.py:1508:0
    %input.47 : Float(17:3328, 13:256, 256:1) = aten::add(%1, %13, %9), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4 # transformers/modeling_reformer.py:1508:0
    %11 : (Float(17:3328, 13:256, 256:1), Float(17:3328, 13:256, 256:1)) = prim::TupleConstruct(%input.47, %input_tensor.5)
    return (%11)

ReformerLayer.attention
ReformerAttention._actual_script_module
  graph(%self.66 : __torch__.transformers.modeling_reformer.ReformerAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerSelfOutput = prim::GetAttr[name="output"](%self.66)
    %3 : __torch__.transformers.modeling_reformer.LocalSelfAttention = prim::GetAttr[name="self_attention"](%self.66)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.66)
    %8 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %9 : Tensor = prim::CallMethod[name="forward"](%3, %8)
    %10 : Tensor = prim::CallMethod[name="forward"](%2, %9)
    return (%10)

ReformerLayer.feed_forward
ChunkReformerFeedForward._actual_script_module
  graph(%self.74 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward,
        %input_tensor.5 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput = prim::GetAttr[name="output"](%self.74)
    %3 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense = prim::GetAttr[name="dense"](%self.74)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.74)
    %29 : Tensor = prim::CallMethod[name="forward"](%4, %input_tensor.5)
    %30 : Tensor = prim::CallMethod[name="forward"](%3, %29)
    %31 : Tensor = prim::CallMethod[name="forward"](%2, %30)
    return (%31)

ReformerAttention.layer_norm
LayerNorm._actual_script_module
  graph(%self.67 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.67)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.67)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.layer_norm # torch/nn/functional.py:2048:0
    %hidden_states.7 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%1, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.layer_norm # torch/nn/functional.py:2048:0
    return (%hidden_states.7)

ReformerAttention.output
ReformerSelfOutput._actual_script_module
  graph(%self.72 : __torch__.transformers.modeling_reformer.ReformerSelfOutput,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.72)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.output # torch/nn/functional.py:973:0
    %attn_output.5 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.output # torch/nn/functional.py:973:0
    return (%attn_output.5)

ReformerAttention.self_attention
LocalSelfAttention._actual_script_module
  graph(%self.68 : __torch__.transformers.modeling_reformer.LocalSelfAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="value"](%self.68)
    %3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="key"](%self.68)
    %4 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="query"](%self.68)
    %213 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %214 : Tensor = prim::CallMethod[name="forward"](%3, %1)
    %215 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %28 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %29 : int = aten::size(%213, %28), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %30 : Long() = prim::NumToTensor(%29), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %31 : int = aten::Int(%30), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %32 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %33 : int = aten::size(%213, %32), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %34 : Long() = prim::NumToTensor(%33), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %35 : int = aten::Int(%34), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %39 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:302:0
    %40 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:302:0
    %41 : int[] = prim::ListConstruct(%31, %35, %39, %40), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %x.26 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%213, %41), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:302:0
    %43 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:303:0
    %44 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:303:0
    %query_vectors : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.26, %43, %44), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:303:0
    %46 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %47 : int = aten::size(%214, %46), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %48 : Long() = prim::NumToTensor(%47), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %49 : int = aten::Int(%48), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %50 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %51 : int = aten::size(%214, %50), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %52 : Long() = prim::NumToTensor(%51), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %53 : int = aten::Int(%52), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %57 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:302:0
    %58 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:302:0
    %59 : int[] = prim::ListConstruct(%49, %53, %57, %58), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %x.28 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%214, %59), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:302:0
    %61 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:303:0
    %62 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:303:0
    %key_vectors.7 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.28, %61, %62), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:303:0
    %64 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %65 : int = aten::size(%215, %64), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %66 : Long() = prim::NumToTensor(%65), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %67 : int = aten::Int(%66), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %68 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %69 : int = aten::size(%215, %68), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:301:0
    %70 : Long() = prim::NumToTensor(%69), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %71 : int = aten::Int(%70), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %75 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:302:0
    %76 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:302:0
    %77 : int[] = prim::ListConstruct(%67, %71, %75, %76), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %x.30 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%215, %77), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:302:0
    %79 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:303:0
    %80 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:303:0
    %value_vectors.5 : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.30, %79, %80), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:303:0
    %124 : Float() = prim::Constant[value={64}](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %125 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %126 : int = prim::Constant[value=6](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %127 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %128 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %129 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %130 : Float() = aten::to(%124, %125, %126, %127, %128, %129), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %131 : Float() = aten::detach(%130), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1112:0
    %132 : Float() = aten::sqrt(%131), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1111:0
    %key_vectors.8 : Float(17:9984, 12:64, 13:768, 64:1) = aten::div(%key_vectors.7, %132), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1111:0
    %145 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %146 : int = prim::Constant[value=-2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %147 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_vectors.8, %145, %146), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %query_key_dots.7 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_vectors, %147), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1161:0
    %161 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1183:0
    %162 : int[] = prim::ListConstruct(%161), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %163 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1183:0
    %logits.5 : Float(17:156, 12:13, 13:1, 1:1) = aten::logsumexp(%query_key_dots.7, %162, %163), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1183:0
    %165 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1184:0
    %166 : Float(17:2028, 12:169, 13:13, 13:1) = aten::sub(%query_key_dots.7, %logits.5, %165), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1184:0
    %input.39 : Float(17:2028, 12:169, 13:13, 13:1) = aten::exp(%166), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1184:0
    %168 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # torch/nn/functional.py:973:0
    %169 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # torch/nn/functional.py:973:0
    %attention_probs.5 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.39, %168, %169), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # torch/nn/functional.py:973:0
    %out_vectors.5 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs.5, %value_vectors.5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:1197:0
    %190 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:309:0
    %191 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:309:0
    %192 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:309:0
    %193 : int = prim::Constant[value=3](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:309:0
    %194 : int[] = prim::ListConstruct(%190, %191, %192, %193), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %x.31 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%out_vectors.5, %194), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:309:0
    %196 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:310:0
    %197 : int = aten::size(%x.31, %196), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:310:0
    %198 : Long() = prim::NumToTensor(%197), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %199 : int = aten::Int(%198), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %209 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:310:0
    %210 : int = prim::Constant[value=768](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:310:0
    %211 : int[] = prim::ListConstruct(%199, %209, %210), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention
    %input.40 : Float(17:9984, 13:768, 768:1) = aten::reshape(%x.31, %211), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention # transformers/modeling_reformer.py:310:0
    return (%input.40)

LocalSelfAttention.key
Linear._actual_script_module
  graph(%self.70 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.70)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention/__module.reformer.encoder.layers.4.attention.self_attention.key # torch/nn/functional.py:1676:0
    %x.27 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention/__module.reformer.encoder.layers.4.attention.self_attention.key # torch/nn/functional.py:1676:0
    return (%x.27)

LocalSelfAttention.query
Linear._actual_script_module
  graph(%self.69 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.69)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention/__module.reformer.encoder.layers.4.attention.self_attention.query # torch/nn/functional.py:1676:0
    %x.25 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention/__module.reformer.encoder.layers.4.attention.self_attention.query # torch/nn/functional.py:1676:0
    return (%x.25)

LocalSelfAttention.value
Linear._actual_script_module
  graph(%self.71 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.71)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention/__module.reformer.encoder.layers.4.attention.self_attention.value # torch/nn/functional.py:1676:0
    %x.29 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.self_attention/__module.reformer.encoder.layers.4.attention.self_attention.value # torch/nn/functional.py:1676:0
    return (%x.29)

ReformerSelfOutput.dense
Linear._actual_script_module
  graph(%self.73 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.73)
    %3 : Float(768:1, 256:768) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.output/__module.reformer.encoder.layers.4.attention.output.dense # torch/nn/functional.py:1676:0
    %input.41 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.attention/__module.reformer.encoder.layers.4.attention.output/__module.reformer.encoder.layers.4.attention.output.dense # torch/nn/functional.py:1676:0
    return (%input.41)

ChunkReformerFeedForward.dense
ReformerFeedForwardDense._actual_script_module
  graph(%self.76 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.76)
    %8 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.dense # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.dense # torch/nn/functional.py:973:0
    %input.44 : Float(17:6656, 13:512, 512:1) = aten::dropout(%8, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.dense # torch/nn/functional.py:973:0
    %input.45 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.44), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.dense # torch/nn/functional.py:1119:0
    return (%input.45)

ChunkReformerFeedForward.layer_norm
LayerNorm._actual_script_module
  graph(%self.75 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input_tensor.5 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.75)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.75)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %input.42 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%input_tensor.5, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    return (%input.42)

ChunkReformerFeedForward.output
ReformerFeedForwardOutput._actual_script_module
  graph(%self.78 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.78)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.output # torch/nn/functional.py:973:0
    %6 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.output # torch/nn/functional.py:973:0
    return (%6)

ReformerFeedForwardDense.dense
Linear._actual_script_module
  graph(%self.77 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.77)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.77)
    %4 : Float(256:1, 512:256) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.dense/__module.reformer.encoder.layers.4.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %output.9 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.dense/__module.reformer.encoder.layers.4.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.dense/__module.reformer.encoder.layers.4.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    %input.43 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.9, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.dense/__module.reformer.encoder.layers.4.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    return (%input.43)

ReformerFeedForwardOutput.dense
Linear._actual_script_module
  graph(%self.79 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.79)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.79)
    %4 : Float(512:1, 256:512) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.output/__module.reformer.encoder.layers.4.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %output.10 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.output/__module.reformer.encoder.layers.4.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.output/__module.reformer.encoder.layers.4.feed_forward.output.dense # torch/nn/functional.py:1678:0
    %input.46 : Float(17:3328, 13:256, 256:1) = aten::add_(%output.10, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.4/__module.reformer.encoder.layers.4.feed_forward/__module.reformer.encoder.layers.4.feed_forward.output/__module.reformer.encoder.layers.4.feed_forward.output.dense # torch/nn/functional.py:1678:0
    return (%input.46)

ReformerLayer._actual_script_module
  graph(%self.80 : __torch__.transformers.modeling_reformer.ReformerLayer,
        %1 : Float(17:3328, 13:256, 256:1),
        %2 : Float(17:3328, 13:256, 256:1)):
    %3 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward = prim::GetAttr[name="feed_forward"](%self.80)
    %4 : __torch__.transformers.modeling_reformer.ReformerAttention = prim::GetAttr[name="attention"](%self.80)
    %12 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5 # transformers/modeling_reformer.py:1498:0
    %input_tensor.6 : Float(17:3328, 13:256, 256:1) = aten::add(%2, %12, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5 # transformers/modeling_reformer.py:1498:0
    %13 : Tensor = prim::CallMethod[name="forward"](%3, %input_tensor.6)
    %9 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5 # transformers/modeling_reformer.py:1508:0
    %hidden_states : Float(17:3328, 13:256, 256:1) = aten::add(%1, %13, %9), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5 # transformers/modeling_reformer.py:1508:0
    %11 : (Float(17:3328, 13:256, 256:1), Float(17:3328, 13:256, 256:1)) = prim::TupleConstruct(%input_tensor.6, %hidden_states)
    return (%11)

ReformerLayer.attention
ReformerAttention._actual_script_module
  graph(%self.81 : __torch__.transformers.modeling_reformer.ReformerAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerSelfOutput = prim::GetAttr[name="output"](%self.81)
    %3 : __torch__.transformers.modeling_reformer.LSHSelfAttention = prim::GetAttr[name="self_attention"](%self.81)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.81)
    %8 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %9 : Tensor = prim::CallMethod[name="forward"](%3, %8)
    %10 : Tensor = prim::CallMethod[name="forward"](%2, %9)
    return (%10)

ReformerLayer.feed_forward
ChunkReformerFeedForward._actual_script_module
  graph(%self.88 : __torch__.transformers.modeling_reformer.ChunkReformerFeedForward,
        %input_tensor.6 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput = prim::GetAttr[name="output"](%self.88)
    %3 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense = prim::GetAttr[name="dense"](%self.88)
    %4 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="layer_norm"](%self.88)
    %29 : Tensor = prim::CallMethod[name="forward"](%4, %input_tensor.6)
    %30 : Tensor = prim::CallMethod[name="forward"](%3, %29)
    %31 : Tensor = prim::CallMethod[name="forward"](%2, %30)
    return (%31)

ReformerAttention.layer_norm
LayerNorm._actual_script_module
  graph(%self.82 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.82)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.82)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.layer_norm # torch/nn/functional.py:2048:0
    %hidden_states.8 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%1, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.layer_norm # torch/nn/functional.py:2048:0
    return (%hidden_states.8)

ReformerAttention.output
ReformerSelfOutput._actual_script_module
  graph(%self.86 : __torch__.transformers.modeling_reformer.ReformerSelfOutput,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.86)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.output # torch/nn/functional.py:973:0
    %attn_output : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.output # torch/nn/functional.py:973:0
    return (%attn_output)

ReformerAttention.self_attention
LSHSelfAttention._actual_script_module
  graph(%self.83 : __torch__.transformers.modeling_reformer.LSHSelfAttention,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="self_mask_value_float32"](%self.83)
    %3 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="value"](%self.83)
    %4 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="query_key"](%self.83)
    %8 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:370:0
    %9 : int = aten::size(%1, %8), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:370:0
    %sequence_length : Long() = prim::NumToTensor(%9), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %11 : Scalar = aten::ScalarImplicit(%sequence_length), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %15 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:371:0
    %16 : int = aten::size(%1, %15), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:371:0
    %batch_size : Long() = prim::NumToTensor(%16), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %18 : int = aten::Int(%batch_size), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %206 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %207 : Tensor = prim::CallMethod[name="forward"](%3, %1)
    %27 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:301:0
    %28 : int = aten::size(%206, %27), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:301:0
    %29 : Long() = prim::NumToTensor(%28), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %30 : int = aten::Int(%29), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %31 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:301:0
    %32 : int = aten::size(%206, %31), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:301:0
    %33 : Long() = prim::NumToTensor(%32), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %34 : int = aten::Int(%33), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %38 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:302:0
    %39 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:302:0
    %40 : int[] = prim::ListConstruct(%30, %34, %38, %39), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %x.33 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%206, %40), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:302:0
    %42 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:303:0
    %43 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:303:0
    %query_key_vectors : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.33, %42, %43), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:303:0
    %45 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:301:0
    %46 : int = aten::size(%207, %45), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:301:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %48 : int = aten::Int(%47), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %49 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:301:0
    %50 : int = aten::size(%207, %49), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:301:0
    %51 : Long() = prim::NumToTensor(%50), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %52 : int = aten::Int(%51), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %56 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:302:0
    %57 : int = prim::Constant[value=64](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:302:0
    %58 : int[] = prim::ListConstruct(%48, %52, %56, %57), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %x.35 : Float(17:9984, 13:768, 12:64, 64:1) = aten::view(%207, %58), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:302:0
    %60 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:303:0
    %61 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:303:0
    %value_vectors : Float(17:9984, 12:64, 13:768, 64:1) = aten::transpose(%x.35, %60, %61), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:303:0
    %93 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %94 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:517:0
    %95 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:517:0
    %96 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:517:0
    %97 : Long(13:1) = aten::arange(%11, %93, %94, %95, %96), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:517:0
    %98 : int = prim::Constant[value=12](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:517:0
    %99 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:517:0
    %100 : int[] = prim::ListConstruct(%18, %98, %99), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %sorted_bucket_idx_per_hash : Long(17:156, 12:13, 13:1) = aten::repeat(%97, %100), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:517:0
    %102 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:973:0
    %103 : Float(17:9984, 12:64, 13:768, 64:1) = aten::pow(%query_key_vectors, %102), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:973:0
    %104 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:973:0
    %105 : int[] = prim::ListConstruct(%104), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %106 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:973:0
    %107 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %variance : Float(17:156, 12:13, 13:1, 1:1) = aten::mean(%103, %105, %106, %107), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:973:0
    %109 : Double() = prim::Constant[value={1e-06}](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:974:0
    %110 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:974:0
    %111 : Float(17:156, 12:13, 13:1, 1:1) = aten::add(%variance, %109, %110), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:974:0
    %112 : Float(17:156, 12:13, 13:1, 1:1) = aten::rsqrt(%111), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:974:0
    %vectors : Float(17:9984, 12:64, 13:768, 64:1) = aten::mul(%query_key_vectors, %112), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:974:0
    %114 : Float() = prim::Constant[value={64}](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:965:0
    %115 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:965:0
    %116 : int = prim::Constant[value=6](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:965:0
    %117 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:965:0
    %118 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:965:0
    %119 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %120 : Float() = aten::to(%114, %115, %116, %117, %118, %119), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:965:0
    %121 : Float() = aten::detach(%120), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:965:0
    %122 : Float() = aten::rsqrt(%121), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:964:0
    %key_vectors : Float(17:9984, 12:64, 13:768, 64:1) = aten::mul(%vectors, %122), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:964:0
    %124 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:741:0
    %125 : int = prim::Constant[value=-2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:741:0
    %126 : Float(17:9984, 12:64, 64:1, 13:768) = aten::transpose(%key_vectors, %124, %125), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:741:0
    %query_key_dots.8 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%query_key_vectors, %126), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:741:0
    %140 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %141 : Long(17:156, 12:13, 13:1, 1:1) = aten::unsqueeze(%sorted_bucket_idx_per_hash, %140), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %142 : int = prim::Constant[value=-2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %143 : Long(17:156, 12:13, 1:13, 13:1) = aten::unsqueeze(%sorted_bucket_idx_per_hash, %142), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %144 : Bool(17:2028, 12:169, 13:13, 13:1) = aten::ne(%141, %143), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %145 : int = prim::Constant[value=11](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %146 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %147 : Device = prim::Constant[value="cpu"](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %148 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %149 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %150 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %151 : None = prim::Constant(), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %self_mask : Bool(17:2028, 12:169, 13:13, 13:1) = aten::to(%144, %145, %146, %147, %148, %149, %150, %151), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:798:0
    %query_key_dots : Float(17:2028, 12:169, 13:13, 13:1) = aten::where(%self_mask, %query_key_dots.8, %2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:803:0
    %154 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:808:0
    %155 : int[] = prim::ListConstruct(%154), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %156 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:808:0
    %logits : Float(17:156, 12:13, 13:1, 1:1) = aten::logsumexp(%query_key_dots, %155, %156), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:808:0
    %158 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:810:0
    %159 : Float(17:2028, 12:169, 13:13, 13:1) = aten::sub(%query_key_dots, %logits, %158), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:810:0
    %input.48 : Float(17:2028, 12:169, 13:13, 13:1) = aten::exp(%159), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:810:0
    %161 : float = prim::Constant[value=0.](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # torch/nn/functional.py:973:0
    %162 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # torch/nn/functional.py:973:0
    %attention_probs : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.48, %161, %162), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # torch/nn/functional.py:973:0
    %out_vectors : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%attention_probs, %value_vectors), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:823:0
    %183 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:309:0
    %184 : int = prim::Constant[value=2](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:309:0
    %185 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:309:0
    %186 : int = prim::Constant[value=3](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:309:0
    %187 : int[] = prim::ListConstruct(%183, %184, %185, %186), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %x : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%out_vectors, %187), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:309:0
    %189 : int = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:310:0
    %190 : int = aten::size(%x, %189), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:310:0
    %191 : Long() = prim::NumToTensor(%190), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %192 : int = aten::Int(%191), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %202 : int = prim::Constant[value=-1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:310:0
    %203 : int = prim::Constant[value=768](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:310:0
    %204 : int[] = prim::ListConstruct(%192, %202, %203), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention
    %input.49 : Float(17:9984, 13:768, 768:1) = aten::reshape(%x, %204), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention # transformers/modeling_reformer.py:310:0
    return (%input.49)

LSHSelfAttention.query_key
Linear._actual_script_module
  graph(%self.84 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.84)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention/__module.reformer.encoder.layers.5.attention.self_attention.query_key # torch/nn/functional.py:1676:0
    %x.32 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention/__module.reformer.encoder.layers.5.attention.self_attention.query_key # torch/nn/functional.py:1676:0
    return (%x.32)

LSHSelfAttention.value
Linear._actual_script_module
  graph(%self.85 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.85)
    %3 : Float(256:1, 768:256) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention/__module.reformer.encoder.layers.5.attention.self_attention.value # torch/nn/functional.py:1676:0
    %x.34 : Float(17:9984, 13:768, 768:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.self_attention/__module.reformer.encoder.layers.5.attention.self_attention.value # torch/nn/functional.py:1676:0
    return (%x.34)

ReformerSelfOutput.dense
Linear._actual_script_module
  graph(%self.87 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.87)
    %3 : Float(768:1, 256:768) = aten::t(%2), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.output/__module.reformer.encoder.layers.5.attention.output.dense # torch/nn/functional.py:1676:0
    %input.50 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.attention/__module.reformer.encoder.layers.5.attention.output/__module.reformer.encoder.layers.5.attention.output.dense # torch/nn/functional.py:1676:0
    return (%input.50)

ChunkReformerFeedForward.dense
ReformerFeedForwardDense._actual_script_module
  graph(%self.90 : __torch__.transformers.modeling_reformer.ReformerFeedForwardDense,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.90)
    %8 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.dense # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.dense # torch/nn/functional.py:973:0
    %input.53 : Float(17:6656, 13:512, 512:1) = aten::dropout(%8, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.dense # torch/nn/functional.py:973:0
    %input.54 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.53), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.dense # torch/nn/functional.py:1119:0
    return (%input.54)

ChunkReformerFeedForward.layer_norm
LayerNorm._actual_script_module
  graph(%self.89 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input_tensor.6 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.89)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.89)
    %4 : int = prim::Constant[value=256](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.layer_norm
    %6 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    %input.51 : Float(17:3328, 13:256, 256:1) = aten::layer_norm(%input_tensor.6, %5, %3, %2, %6, %7), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.layer_norm # torch/nn/functional.py:2048:0
    return (%input.51)

ChunkReformerFeedForward.output
ReformerFeedForwardOutput._actual_script_module
  graph(%self.92 : __torch__.transformers.modeling_reformer.ReformerFeedForwardOutput,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : __torch__.torch.nn.modules.linear.Linear = prim::GetAttr[name="dense"](%self.92)
    %7 : Tensor = prim::CallMethod[name="forward"](%2, %1)
    %4 : float = prim::Constant[value=0.050000000000000003](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.output # torch/nn/functional.py:973:0
    %5 : bool = prim::Constant[value=0](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.output # torch/nn/functional.py:973:0
    %6 : Float(17:3328, 13:256, 256:1) = aten::dropout(%7, %4, %5), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.output # torch/nn/functional.py:973:0
    return (%6)

ReformerFeedForwardDense.dense
Linear._actual_script_module
  graph(%self.91 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:3328, 13:256, 256:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.91)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.91)
    %4 : Float(256:1, 512:256) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.dense/__module.reformer.encoder.layers.5.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %output.11 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.dense/__module.reformer.encoder.layers.5.feed_forward.dense.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.dense/__module.reformer.encoder.layers.5.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    %input.52 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.11, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.dense/__module.reformer.encoder.layers.5.feed_forward.dense.dense # torch/nn/functional.py:1678:0
    return (%input.52)

ReformerFeedForwardOutput.dense
Linear._actual_script_module
  graph(%self.93 : __torch__.torch.nn.modules.linear.Linear,
        %1 : Float(17:6656, 13:512, 512:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.93)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.93)
    %4 : Float(512:1, 256:512) = aten::t(%3), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.output/__module.reformer.encoder.layers.5.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %output.12 : Float(17:3328, 13:256, 256:1) = aten::matmul(%1, %4), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.output/__module.reformer.encoder.layers.5.feed_forward.output.dense # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.output/__module.reformer.encoder.layers.5.feed_forward.output.dense # torch/nn/functional.py:1678:0
    %input.55 : Float(17:3328, 13:256, 256:1) = aten::add_(%output.12, %2, %6), scope: __module.reformer/__module.reformer.encoder/__module.reformer.encoder.layers.5/__module.reformer.encoder.layers.5.feed_forward/__module.reformer.encoder.layers.5.feed_forward.output/__module.reformer.encoder.layers.5.feed_forward.output.dense # torch/nn/functional.py:1678:0
    return (%input.55)

ReformerOnlyLMHead.decoder
Linear._actual_script_module
  graph(%self : __torch__.torch.nn.modules.linear.Linear,
        %bias : Float(320:1),
        %2 : Float(17:6656, 13:512, 512:1)):
    %3 : Tensor = prim::GetAttr[name="weight"](%self)
    %4 : Float(512:1, 320:512) = aten::t(%3), scope: __module.lm_head/__module.lm_head.decoder # torch/nn/functional.py:1676:0
    %output : Float(17:4160, 13:320, 320:1) = aten::matmul(%2, %4), scope: __module.lm_head/__module.lm_head.decoder # torch/nn/functional.py:1676:0
    %6 : int = prim::Constant[value=1](), scope: __module.lm_head/__module.lm_head.decoder # torch/nn/functional.py:1678:0
    %7 : Float(17:4160, 13:320, 320:1) = aten::add_(%output, %bias, %6), scope: __module.lm_head/__module.lm_head.decoder # torch/nn/functional.py:1678:0
    return (%7)

