graph(%self.1 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27641.MobileBertModel,
      %input_ids : Long(17:13, 13:1),
      %attention_mask.1 : Long(17:13, 13:1)):
  %3 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27640.MobileBertPooler = prim::GetAttr[name="pooler"](%self.1)
  %4 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27638.MobileBertEncoder = prim::GetAttr[name="encoder"](%self.1)
  %5 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26556.MobileBertEmbeddings = prim::GetAttr[name="embeddings"](%self.1)
  %6 : int = prim::Constant[value=0]() # transformers/modeling_mobilebert.py:871:0
  %7 : int = aten::size(%input_ids, %6) # transformers/modeling_mobilebert.py:871:0
  %8 : Long() = prim::NumToTensor(%7)
  %9 : int = aten::Int(%8)
  %10 : int = prim::Constant[value=1]() # transformers/modeling_mobilebert.py:871:0
  %11 : int = aten::size(%input_ids, %10) # transformers/modeling_mobilebert.py:871:0
  %12 : Long() = prim::NumToTensor(%11)
  %13 : int = aten::Int(%12)
  %14 : int[] = prim::ListConstruct(%9, %13)
  %15 : int = prim::Constant[value=4]() # transformers/modeling_mobilebert.py:882:0
  %16 : int = prim::Constant[value=0]() # transformers/modeling_mobilebert.py:882:0
  %17 : Device = prim::Constant[value="cpu"]() # transformers/modeling_mobilebert.py:882:0
  %18 : bool = prim::Constant[value=0]() # transformers/modeling_mobilebert.py:882:0
  %input.5 : Long(17:13, 13:1) = aten::zeros(%14, %15, %16, %17, %18) # transformers/modeling_mobilebert.py:882:0
  %20 : int = prim::Constant[value=0]() # transformers/modeling_utils.py:244:0
  %21 : int = prim::Constant[value=0]() # transformers/modeling_utils.py:244:0
  %22 : int = prim::Constant[value=9223372036854775807]() # transformers/modeling_utils.py:244:0
  %23 : int = prim::Constant[value=1]() # transformers/modeling_utils.py:244:0
  %24 : Long(17:13, 13:1) = aten::slice(%attention_mask.1, %20, %21, %22, %23) # transformers/modeling_utils.py:244:0
  %25 : int = prim::Constant[value=1]() # transformers/modeling_utils.py:244:0
  %26 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%24, %25) # transformers/modeling_utils.py:244:0
  %27 : int = prim::Constant[value=2]() # transformers/modeling_utils.py:244:0
  %28 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%26, %27) # transformers/modeling_utils.py:244:0
  %29 : int = prim::Constant[value=3]() # transformers/modeling_utils.py:244:0
  %30 : int = prim::Constant[value=0]() # transformers/modeling_utils.py:244:0
  %31 : int = prim::Constant[value=9223372036854775807]() # transformers/modeling_utils.py:244:0
  %32 : int = prim::Constant[value=1]() # transformers/modeling_utils.py:244:0
  %extended_attention_mask : Long(17:13, 1:13, 1:13, 13:1) = aten::slice(%28, %29, %30, %31, %32) # transformers/modeling_utils.py:244:0
  %34 : int = prim::Constant[value=6]() # transformers/modeling_utils.py:257:0
  %35 : bool = prim::Constant[value=0]() # transformers/modeling_utils.py:257:0
  %36 : bool = prim::Constant[value=0]() # transformers/modeling_utils.py:257:0
  %37 : None = prim::Constant()
  %38 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%extended_attention_mask, %34, %35, %36, %37) # transformers/modeling_utils.py:257:0
  %39 : float = prim::Constant[value=1.]() # torch/tensor.py:396:0
  %40 : int = prim::Constant[value=1]() # torch/tensor.py:396:0
  %41 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%38, %39, %40) # torch/tensor.py:396:0
  %42 : Double() = prim::Constant[value={-10000}]() # transformers/modeling_utils.py:258:0
  %attention_mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%41, %42) # transformers/modeling_utils.py:258:0
  %48 : float = prim::Constant[value=0.](), scope: __module.embeddings/__module.embeddings.dropout # torch/nn/functional.py:973:0
  %49 : int = prim::Constant[value=2](), scope: __module.embeddings # transformers/modeling_mobilebert.py:207:0
  %50 : int = prim::Constant[value=-1](), scope: __module.embeddings # transformers/modeling_mobilebert.py:211:0
  %51 : bool = prim::Constant[value=0](), scope: __module.embeddings/__module.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %52 : int = prim::Constant[value=9223372036854775807](), scope: __module.embeddings # transformers/modeling_mobilebert.py:192:0
  %53 : int = prim::Constant[value=0](), scope: __module.embeddings # transformers/modeling_mobilebert.py:192:0
  %54 : int = prim::Constant[value=1](), scope: __module.embeddings # transformers/modeling_mobilebert.py:185:0
  %55 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26554.NoNorm = prim::GetAttr[name="LayerNorm"](%5)
  %56 : __torch__.torch.nn.modules.sparse.___torch_mangle_26552.Embedding = prim::GetAttr[name="token_type_embeddings"](%5)
  %57 : __torch__.torch.nn.modules.sparse.___torch_mangle_26551.Embedding = prim::GetAttr[name="position_embeddings"](%5)
  %58 : __torch__.torch.nn.modules.linear.___torch_mangle_26553.Linear = prim::GetAttr[name="embedding_transformation"](%5)
  %59 : __torch__.torch.nn.modules.sparse.___torch_mangle_26550.Embedding = prim::GetAttr[name="word_embeddings"](%5)
  %60 : Tensor = prim::GetAttr[name="position_ids"](%5)
  %61 : int = aten::size(%input_ids, %54), scope: __module.embeddings # transformers/modeling_mobilebert.py:185:0
  %62 : Long(1:512, 512:1) = aten::slice(%60, %53, %53, %52, %54), scope: __module.embeddings # transformers/modeling_mobilebert.py:192:0
  %input.4 : Long(1:512, 13:1) = aten::slice(%62, %54, %53, %61, %54), scope: __module.embeddings # transformers/modeling_mobilebert.py:192:0
  %64 : Tensor = prim::GetAttr[name="weight"](%59)
  %inputs_embeds.1 : Float(17:1664, 13:128, 128:1) = aten::embedding(%64, %input_ids, %53, %51, %51), scope: __module.embeddings/__module.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %66 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %53, %53, %52, %54), scope: __module.embeddings # transformers/modeling_mobilebert.py:209:0
  %input.1 : Float(17:1664, 12:128, 128:1) = aten::slice(%66, %54, %54, %52, %54), scope: __module.embeddings # transformers/modeling_mobilebert.py:209:0
  %68 : int[] = prim::ListConstruct(%53, %53, %53, %54, %53, %53), scope: __module.embeddings
  %69 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.1, %68, %53), scope: __module.embeddings # torch/nn/functional.py:3552:0
  %70 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %53, %53, %52, %54), scope: __module.embeddings # transformers/modeling_mobilebert.py:211:0
  %input.2 : Float(17:1664, 12:128, 128:1) = aten::slice(%70, %54, %53, %50, %54), scope: __module.embeddings # transformers/modeling_mobilebert.py:211:0
  %72 : int[] = prim::ListConstruct(%53, %53, %54, %53, %53, %53), scope: __module.embeddings
  %73 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.2, %72, %53), scope: __module.embeddings # torch/nn/functional.py:3552:0
  %74 : Tensor[] = prim::ListConstruct(%69, %inputs_embeds.1, %73), scope: __module.embeddings
  %input.3 : Float(17:4992, 13:384, 384:1) = aten::cat(%74, %49), scope: __module.embeddings # transformers/modeling_mobilebert.py:207:0
  %76 : Tensor = prim::GetAttr[name="bias"](%58)
  %77 : Tensor = prim::GetAttr[name="weight"](%58)
  %78 : Float(384:1, 512:384) = aten::t(%77), scope: __module.embeddings/__module.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %output.1 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.3, %78), scope: __module.embeddings/__module.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %inputs_embeds : Float(17:6656, 13:512, 512:1) = aten::add_(%output.1, %76, %54), scope: __module.embeddings/__module.embeddings.embedding_transformation # torch/nn/functional.py:1678:0
  %81 : Tensor = prim::GetAttr[name="weight"](%57)
  %position_embeddings : Float(1:6656, 13:512, 512:1) = aten::embedding(%81, %input.4, %50, %51, %51), scope: __module.embeddings/__module.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %83 : Tensor = prim::GetAttr[name="weight"](%56)
  %token_type_embeddings : Float(17:6656, 13:512, 512:1) = aten::embedding(%83, %input.5, %50, %51, %51), scope: __module.embeddings/__module.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %85 : Float(17:6656, 13:512, 512:1) = aten::add(%inputs_embeds, %position_embeddings, %54), scope: __module.embeddings # transformers/modeling_mobilebert.py:222:0
  %input_tensor.1 : Float(17:6656, 13:512, 512:1) = aten::add(%85, %token_type_embeddings, %54), scope: __module.embeddings # transformers/modeling_mobilebert.py:222:0
  %87 : Tensor = prim::GetAttr[name="bias"](%55)
  %88 : Tensor = prim::GetAttr[name="weight"](%55)
  %89 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.1, %88), scope: __module.embeddings/__module.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.6 : Float(17:6656, 13:512, 512:1) = aten::add(%89, %87, %54), scope: __module.embeddings/__module.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.7 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.6, %48, %51), scope: __module.embeddings/__module.embeddings.dropout # torch/nn/functional.py:973:0
  %92 : int = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.input/__module.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %93 : int = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %94 : int = prim::Constant[value=4](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %95 : int = prim::Constant[value=32](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %96 : int = prim::Constant[value=2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %97 : int = prim::Constant[value=3](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %98 : int = prim::Constant[value=-1](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %99 : int = prim::Constant[value=-2](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %100 : Double() = prim::Constant[value={5.65685}](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %101 : None = prim::Constant(), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %102 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %103 : float = prim::Constant[value=0.10000000000000001](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %104 : int = prim::Constant[value=128](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %105 : float = prim::Constant[value=0.](), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.bottleneck/__module.encoder.layer.0.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %106 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27636.MobileBertLayer = prim::GetAttr[name="23"](%106)
  %108 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27591.MobileBertLayer = prim::GetAttr[name="22"](%108)
  %110 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27546.MobileBertLayer = prim::GetAttr[name="21"](%110)
  %112 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %113 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27501.MobileBertLayer = prim::GetAttr[name="20"](%112)
  %114 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %115 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27456.MobileBertLayer = prim::GetAttr[name="19"](%114)
  %116 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %117 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27411.MobileBertLayer = prim::GetAttr[name="18"](%116)
  %118 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27366.MobileBertLayer = prim::GetAttr[name="17"](%118)
  %120 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %121 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27321.MobileBertLayer = prim::GetAttr[name="16"](%120)
  %122 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %123 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27276.MobileBertLayer = prim::GetAttr[name="15"](%122)
  %124 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %125 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27231.MobileBertLayer = prim::GetAttr[name="14"](%124)
  %126 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27186.MobileBertLayer = prim::GetAttr[name="13"](%126)
  %128 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %129 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27141.MobileBertLayer = prim::GetAttr[name="12"](%128)
  %130 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %131 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27096.MobileBertLayer = prim::GetAttr[name="11"](%130)
  %132 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %133 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27051.MobileBertLayer = prim::GetAttr[name="10"](%132)
  %134 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27006.MobileBertLayer = prim::GetAttr[name="9"](%134)
  %136 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %137 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26961.MobileBertLayer = prim::GetAttr[name="8"](%136)
  %138 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %139 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26916.MobileBertLayer = prim::GetAttr[name="7"](%138)
  %140 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %141 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26871.MobileBertLayer = prim::GetAttr[name="6"](%140)
  %142 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %143 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26826.MobileBertLayer = prim::GetAttr[name="5"](%142)
  %144 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %145 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26781.MobileBertLayer = prim::GetAttr[name="4"](%144)
  %146 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %147 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26736.MobileBertLayer = prim::GetAttr[name="3"](%146)
  %148 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %149 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26691.MobileBertLayer = prim::GetAttr[name="2"](%148)
  %150 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %151 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26646.MobileBertLayer = prim::GetAttr[name="1"](%150)
  %152 : __torch__.torch.nn.modules.container.___torch_mangle_27637.ModuleList = prim::GetAttr[name="layer"](%4)
  %153 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26601.MobileBertLayer = prim::GetAttr[name="0"](%152)
  %154 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26574.MobileBertOutput = prim::GetAttr[name="output"](%153)
  %155 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26567.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%153)
  %156 : __torch__.torch.nn.modules.container.___torch_mangle_26600.ModuleList = prim::GetAttr[name="ffn"](%153)
  %157 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26599.FFNLayer = prim::GetAttr[name="2"](%156)
  %158 : __torch__.torch.nn.modules.container.___torch_mangle_26600.ModuleList = prim::GetAttr[name="ffn"](%153)
  %159 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26593.FFNLayer = prim::GetAttr[name="1"](%158)
  %160 : __torch__.torch.nn.modules.container.___torch_mangle_26600.ModuleList = prim::GetAttr[name="ffn"](%153)
  %161 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26587.FFNLayer = prim::GetAttr[name="0"](%160)
  %162 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26565.MobileBertAttention = prim::GetAttr[name="attention"](%153)
  %163 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26581.Bottleneck = prim::GetAttr[name="bottleneck"](%153)
  %164 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26580.BottleneckLayer = prim::GetAttr[name="attention"](%163)
  %165 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26577.BottleneckLayer = prim::GetAttr[name="input"](%163)
  %166 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26576.NoNorm = prim::GetAttr[name="LayerNorm"](%165)
  %167 : __torch__.torch.nn.modules.linear.___torch_mangle_26575.Linear = prim::GetAttr[name="dense"](%165)
  %168 : Tensor = prim::GetAttr[name="bias"](%167)
  %169 : Tensor = prim::GetAttr[name="weight"](%167)
  %170 : Float(512:1, 128:512) = aten::t(%169), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.input/__module.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.2 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %170), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.input/__module.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.2, %168, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.input/__module.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %173 : Tensor = prim::GetAttr[name="bias"](%166)
  %174 : Tensor = prim::GetAttr[name="weight"](%166)
  %175 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.2, %174), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.input/__module.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.1 : Float(17:1664, 13:128, 128:1) = aten::add(%175, %173, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.input/__module.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %177 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26579.NoNorm = prim::GetAttr[name="LayerNorm"](%164)
  %178 : __torch__.torch.nn.modules.linear.___torch_mangle_26578.Linear = prim::GetAttr[name="dense"](%164)
  %179 : Tensor = prim::GetAttr[name="bias"](%178)
  %180 : Tensor = prim::GetAttr[name="weight"](%178)
  %181 : Float(512:1, 128:512) = aten::t(%180), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.attention/__module.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.3 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %181), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.attention/__module.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.3, %179, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.attention/__module.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %184 : Tensor = prim::GetAttr[name="bias"](%177)
  %185 : Tensor = prim::GetAttr[name="weight"](%177)
  %186 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.3, %185), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.attention/__module.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.8 : Float(17:1664, 13:128, 128:1) = aten::add(%186, %184, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.bottleneck/__module.encoder.layer.0.bottleneck.attention/__module.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %188 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.8, %residual_tensor.1)
  %189 : Float(17:1664, 13:128, 128:1), %190 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%188)
  %191 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26564.MobileBertSelfOutput = prim::GetAttr[name="output"](%162)
  %192 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26561.MobileBertSelfAttention = prim::GetAttr[name="self"](%162)
  %193 : __torch__.torch.nn.modules.linear.___torch_mangle_26559.Linear = prim::GetAttr[name="value"](%192)
  %194 : __torch__.torch.nn.modules.linear.___torch_mangle_26558.Linear = prim::GetAttr[name="key"](%192)
  %195 : __torch__.torch.nn.modules.linear.___torch_mangle_26557.Linear = prim::GetAttr[name="query"](%192)
  %196 : Tensor = prim::GetAttr[name="bias"](%195)
  %197 : Tensor = prim::GetAttr[name="weight"](%195)
  %198 : Float(128:1, 128:128) = aten::t(%197), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %output.4 : Float(17:1664, 13:128, 128:1) = aten::matmul(%189, %198), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %x.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.4, %196, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %201 : Tensor = prim::GetAttr[name="bias"](%194)
  %202 : Tensor = prim::GetAttr[name="weight"](%194)
  %203 : Float(128:1, 128:128) = aten::t(%202), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %output.5 : Float(17:1664, 13:128, 128:1) = aten::matmul(%189, %203), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %x.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.5, %201, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.key # torch/nn/functional.py:1678:0
  %206 : Tensor = prim::GetAttr[name="bias"](%193)
  %207 : Tensor = prim::GetAttr[name="weight"](%193)
  %208 : Float(512:1, 128:512) = aten::t(%207), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %output.6 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %208), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %x.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.6, %206, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.value # torch/nn/functional.py:1678:0
  %211 : int = aten::size(%x.1, %93), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %212 : int = aten::size(%x.1, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %213 : int[] = prim::ListConstruct(%211, %212, %94, %95), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %x.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.1, %213), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %215 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %query_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.2, %215), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %217 : int = aten::size(%x.3, %93), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %218 : int = aten::size(%x.3, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %219 : int[] = prim::ListConstruct(%217, %218, %94, %95), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %x.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.3, %219), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %221 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %key_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.4, %221), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %223 : int = aten::size(%x.5, %93), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %224 : int = aten::size(%x.5, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %225 : int[] = prim::ListConstruct(%223, %224, %94, %95), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %x.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.5, %225), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %227 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %value_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.6, %227), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %229 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.1, %98, %99), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.1, %229), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.1, %100), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.2, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.9, %98, %101), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.10, %103, %102), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self/__module.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.1 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:280:0
  %236 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %237 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.1, %236), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%237, %93), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %239 : int = aten::size(%context_layer.2, %93), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %240 : int = aten::size(%context_layer.2, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %241 : int[] = prim::ListConstruct(%239, %240, %104), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self
  %input.11 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.2, %241), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %243 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26563.NoNorm = prim::GetAttr[name="LayerNorm"](%191)
  %244 : __torch__.torch.nn.modules.linear.___torch_mangle_26562.Linear = prim::GetAttr[name="dense"](%191)
  %245 : Tensor = prim::GetAttr[name="bias"](%244)
  %246 : Tensor = prim::GetAttr[name="weight"](%244)
  %247 : Float(128:1, 128:128) = aten::t(%246), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %output.7 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.11, %247), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.7, %245, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.1, %190, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output # transformers/modeling_mobilebert.py:301:0
  %251 : Tensor = prim::GetAttr[name="bias"](%243)
  %252 : Tensor = prim::GetAttr[name="weight"](%243)
  %253 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.4, %252), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.12 : Float(17:1664, 13:128, 128:1) = aten::add(%253, %251, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.attention/__module.encoder.layer.0.attention.output/__module.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %255 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26586.FFNOutput = prim::GetAttr[name="output"](%161)
  %256 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26583.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%161)
  %257 : __torch__.torch.nn.modules.linear.___torch_mangle_26582.Linear = prim::GetAttr[name="dense"](%256)
  %258 : Tensor = prim::GetAttr[name="bias"](%257)
  %259 : Tensor = prim::GetAttr[name="weight"](%257)
  %260 : Float(128:1, 512:128) = aten::t(%259), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.intermediate/__module.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.8 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.12, %260), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.intermediate/__module.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.13 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.8, %258, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.intermediate/__module.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.14 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.13), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %264 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26585.NoNorm = prim::GetAttr[name="LayerNorm"](%255)
  %265 : __torch__.torch.nn.modules.linear.___torch_mangle_26584.Linear = prim::GetAttr[name="dense"](%255)
  %266 : Tensor = prim::GetAttr[name="bias"](%265)
  %267 : Tensor = prim::GetAttr[name="weight"](%265)
  %268 : Float(512:1, 128:512) = aten::t(%267), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.output/__module.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.9 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.14, %268), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.output/__module.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.9, %266, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.output/__module.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.2, %input.12, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %272 : Tensor = prim::GetAttr[name="bias"](%264)
  %273 : Tensor = prim::GetAttr[name="weight"](%264)
  %274 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.5, %273), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.output/__module.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.15 : Float(17:1664, 13:128, 128:1) = aten::add(%274, %272, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.0/__module.encoder.layer.0.ffn.0.output/__module.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %276 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26592.FFNOutput = prim::GetAttr[name="output"](%159)
  %277 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26589.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%159)
  %278 : __torch__.torch.nn.modules.linear.___torch_mangle_26588.Linear = prim::GetAttr[name="dense"](%277)
  %279 : Tensor = prim::GetAttr[name="bias"](%278)
  %280 : Tensor = prim::GetAttr[name="weight"](%278)
  %281 : Float(128:1, 512:128) = aten::t(%280), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.intermediate/__module.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.10 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.15, %281), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.intermediate/__module.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.16 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.10, %279, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.intermediate/__module.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.17 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.16), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %285 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26591.NoNorm = prim::GetAttr[name="LayerNorm"](%276)
  %286 : __torch__.torch.nn.modules.linear.___torch_mangle_26590.Linear = prim::GetAttr[name="dense"](%276)
  %287 : Tensor = prim::GetAttr[name="bias"](%286)
  %288 : Tensor = prim::GetAttr[name="weight"](%286)
  %289 : Float(512:1, 128:512) = aten::t(%288), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.output/__module.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.11 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.17, %289), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.output/__module.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.11, %287, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.output/__module.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.3, %input.15, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %293 : Tensor = prim::GetAttr[name="bias"](%285)
  %294 : Tensor = prim::GetAttr[name="weight"](%285)
  %295 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.6, %294), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.output/__module.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.18 : Float(17:1664, 13:128, 128:1) = aten::add(%295, %293, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.1/__module.encoder.layer.0.ffn.1.output/__module.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %297 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26598.FFNOutput = prim::GetAttr[name="output"](%157)
  %298 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26595.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%157)
  %299 : __torch__.torch.nn.modules.linear.___torch_mangle_26594.Linear = prim::GetAttr[name="dense"](%298)
  %300 : Tensor = prim::GetAttr[name="bias"](%299)
  %301 : Tensor = prim::GetAttr[name="weight"](%299)
  %302 : Float(128:1, 512:128) = aten::t(%301), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.intermediate/__module.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.12 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.18, %302), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.intermediate/__module.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.19 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.12, %300, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.intermediate/__module.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.20 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.19), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %306 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26597.NoNorm = prim::GetAttr[name="LayerNorm"](%297)
  %307 : __torch__.torch.nn.modules.linear.___torch_mangle_26596.Linear = prim::GetAttr[name="dense"](%297)
  %308 : Tensor = prim::GetAttr[name="bias"](%307)
  %309 : Tensor = prim::GetAttr[name="weight"](%307)
  %310 : Float(512:1, 128:512) = aten::t(%309), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.output/__module.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.13 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.20, %310), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.output/__module.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.13, %308, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.output/__module.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.4, %input.18, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %314 : Tensor = prim::GetAttr[name="bias"](%306)
  %315 : Tensor = prim::GetAttr[name="weight"](%306)
  %316 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.7, %315), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.output/__module.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.21 : Float(17:1664, 13:128, 128:1) = aten::add(%316, %314, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.ffn.2/__module.encoder.layer.0.ffn.2.output/__module.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %318 : __torch__.torch.nn.modules.linear.___torch_mangle_26566.Linear = prim::GetAttr[name="dense"](%155)
  %319 : Tensor = prim::GetAttr[name="bias"](%318)
  %320 : Tensor = prim::GetAttr[name="weight"](%318)
  %321 : Float(128:1, 512:128) = aten::t(%320), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.14 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.21, %321), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.22 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.14, %319, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate/__module.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.23 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.22), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.intermediate # torch/nn/functional.py:1119:0
  %325 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26573.OutputBottleneck = prim::GetAttr[name="bottleneck"](%154)
  %326 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26569.NoNorm = prim::GetAttr[name="LayerNorm"](%154)
  %327 : __torch__.torch.nn.modules.linear.___torch_mangle_26568.Linear = prim::GetAttr[name="dense"](%154)
  %328 : Tensor = prim::GetAttr[name="bias"](%327)
  %329 : Tensor = prim::GetAttr[name="weight"](%327)
  %330 : Float(512:1, 128:512) = aten::t(%329), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %output.15 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.23, %330), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %layer_output.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.15, %328, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.1, %input.21, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output # transformers/modeling_mobilebert.py:405:0
  %334 : Tensor = prim::GetAttr[name="bias"](%326)
  %335 : Tensor = prim::GetAttr[name="weight"](%326)
  %336 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.8, %335), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.24 : Float(17:1664, 13:128, 128:1) = aten::add(%336, %334, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %338 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26571.NoNorm = prim::GetAttr[name="LayerNorm"](%325)
  %339 : __torch__.torch.nn.modules.linear.___torch_mangle_26570.Linear = prim::GetAttr[name="dense"](%325)
  %340 : Tensor = prim::GetAttr[name="bias"](%339)
  %341 : Tensor = prim::GetAttr[name="weight"](%339)
  %342 : Float(128:1, 512:128) = aten::t(%341), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.bottleneck/__module.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.16 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.24, %342), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.bottleneck/__module.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.25 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.16, %340, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.bottleneck/__module.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.5 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.25, %105, %102), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.bottleneck/__module.encoder.layer.0.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.9 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.5, %input.7, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %347 : Tensor = prim::GetAttr[name="bias"](%338)
  %348 : Tensor = prim::GetAttr[name="weight"](%338)
  %349 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.9, %348), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.bottleneck/__module.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.26 : Float(17:6656, 13:512, 512:1) = aten::add(%349, %347, %92), scope: __module.encoder/__module.encoder.layer.0/__module.encoder.layer.0.output/__module.encoder.layer.0.output.bottleneck/__module.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %351 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26619.MobileBertOutput = prim::GetAttr[name="output"](%151)
  %352 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26612.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%151)
  %353 : __torch__.torch.nn.modules.container.___torch_mangle_26645.ModuleList = prim::GetAttr[name="ffn"](%151)
  %354 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26644.FFNLayer = prim::GetAttr[name="2"](%353)
  %355 : __torch__.torch.nn.modules.container.___torch_mangle_26645.ModuleList = prim::GetAttr[name="ffn"](%151)
  %356 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26638.FFNLayer = prim::GetAttr[name="1"](%355)
  %357 : __torch__.torch.nn.modules.container.___torch_mangle_26645.ModuleList = prim::GetAttr[name="ffn"](%151)
  %358 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26632.FFNLayer = prim::GetAttr[name="0"](%357)
  %359 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26610.MobileBertAttention = prim::GetAttr[name="attention"](%151)
  %360 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26626.Bottleneck = prim::GetAttr[name="bottleneck"](%151)
  %361 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26625.BottleneckLayer = prim::GetAttr[name="attention"](%360)
  %362 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26622.BottleneckLayer = prim::GetAttr[name="input"](%360)
  %363 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26621.NoNorm = prim::GetAttr[name="LayerNorm"](%362)
  %364 : __torch__.torch.nn.modules.linear.___torch_mangle_26620.Linear = prim::GetAttr[name="dense"](%362)
  %365 : Tensor = prim::GetAttr[name="bias"](%364)
  %366 : Tensor = prim::GetAttr[name="weight"](%364)
  %367 : Float(512:1, 128:512) = aten::t(%366), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.input/__module.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.17 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %367), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.input/__module.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.17, %365, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.input/__module.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %370 : Tensor = prim::GetAttr[name="bias"](%363)
  %371 : Tensor = prim::GetAttr[name="weight"](%363)
  %372 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.10, %371), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.input/__module.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add(%372, %370, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.input/__module.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %374 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26624.NoNorm = prim::GetAttr[name="LayerNorm"](%361)
  %375 : __torch__.torch.nn.modules.linear.___torch_mangle_26623.Linear = prim::GetAttr[name="dense"](%361)
  %376 : Tensor = prim::GetAttr[name="bias"](%375)
  %377 : Tensor = prim::GetAttr[name="weight"](%375)
  %378 : Float(512:1, 128:512) = aten::t(%377), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.attention/__module.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.18 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %378), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.attention/__module.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.18, %376, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.attention/__module.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %381 : Tensor = prim::GetAttr[name="bias"](%374)
  %382 : Tensor = prim::GetAttr[name="weight"](%374)
  %383 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.11, %382), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.attention/__module.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.27 : Float(17:1664, 13:128, 128:1) = aten::add(%383, %381, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.bottleneck/__module.encoder.layer.1.bottleneck.attention/__module.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %385 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.27, %residual_tensor.2)
  %386 : Float(17:1664, 13:128, 128:1), %387 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%385)
  %388 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26609.MobileBertSelfOutput = prim::GetAttr[name="output"](%359)
  %389 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26606.MobileBertSelfAttention = prim::GetAttr[name="self"](%359)
  %390 : __torch__.torch.nn.modules.linear.___torch_mangle_26604.Linear = prim::GetAttr[name="value"](%389)
  %391 : __torch__.torch.nn.modules.linear.___torch_mangle_26603.Linear = prim::GetAttr[name="key"](%389)
  %392 : __torch__.torch.nn.modules.linear.___torch_mangle_26602.Linear = prim::GetAttr[name="query"](%389)
  %393 : Tensor = prim::GetAttr[name="bias"](%392)
  %394 : Tensor = prim::GetAttr[name="weight"](%392)
  %395 : Float(128:1, 128:128) = aten::t(%394), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %output.19 : Float(17:1664, 13:128, 128:1) = aten::matmul(%386, %395), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %x.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.19, %393, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.query # torch/nn/functional.py:1678:0
  %398 : Tensor = prim::GetAttr[name="bias"](%391)
  %399 : Tensor = prim::GetAttr[name="weight"](%391)
  %400 : Float(128:1, 128:128) = aten::t(%399), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %output.20 : Float(17:1664, 13:128, 128:1) = aten::matmul(%386, %400), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %x.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.20, %398, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.key # torch/nn/functional.py:1678:0
  %403 : Tensor = prim::GetAttr[name="bias"](%390)
  %404 : Tensor = prim::GetAttr[name="weight"](%390)
  %405 : Float(512:1, 128:512) = aten::t(%404), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %output.21 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %405), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %x.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.21, %403, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.value # torch/nn/functional.py:1678:0
  %408 : int = aten::size(%x.7, %93), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %409 : int = aten::size(%x.7, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %410 : int[] = prim::ListConstruct(%408, %409, %94, %95), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %x.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.7, %410), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %412 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %query_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.8, %412), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %414 : int = aten::size(%x.9, %93), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %415 : int = aten::size(%x.9, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %416 : int[] = prim::ListConstruct(%414, %415, %94, %95), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %x.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.9, %416), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %418 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %key_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.10, %418), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %420 : int = aten::size(%x.11, %93), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %421 : int = aten::size(%x.11, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %422 : int[] = prim::ListConstruct(%420, %421, %94, %95), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %x.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.11, %422), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %424 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %value_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.12, %424), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %426 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.2, %98, %99), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.2, %426), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.3, %100), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.4, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.28, %98, %101), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.29, %103, %102), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self/__module.encoder.layer.1.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.3 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.2, %value_layer.2), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:280:0
  %433 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %434 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.3, %433), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%434, %93), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %436 : int = aten::size(%context_layer.4, %93), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %437 : int = aten::size(%context_layer.4, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %438 : int[] = prim::ListConstruct(%436, %437, %104), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self
  %input.30 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.4, %438), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:283:0
  %440 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26608.NoNorm = prim::GetAttr[name="LayerNorm"](%388)
  %441 : __torch__.torch.nn.modules.linear.___torch_mangle_26607.Linear = prim::GetAttr[name="dense"](%388)
  %442 : Tensor = prim::GetAttr[name="bias"](%441)
  %443 : Tensor = prim::GetAttr[name="weight"](%441)
  %444 : Float(128:1, 128:128) = aten::t(%443), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %output.22 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.30, %444), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.22, %442, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.6, %387, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output # transformers/modeling_mobilebert.py:301:0
  %448 : Tensor = prim::GetAttr[name="bias"](%440)
  %449 : Tensor = prim::GetAttr[name="weight"](%440)
  %450 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.12, %449), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.31 : Float(17:1664, 13:128, 128:1) = aten::add(%450, %448, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.attention/__module.encoder.layer.1.attention.output/__module.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %452 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26631.FFNOutput = prim::GetAttr[name="output"](%358)
  %453 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26628.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%358)
  %454 : __torch__.torch.nn.modules.linear.___torch_mangle_26627.Linear = prim::GetAttr[name="dense"](%453)
  %455 : Tensor = prim::GetAttr[name="bias"](%454)
  %456 : Tensor = prim::GetAttr[name="weight"](%454)
  %457 : Float(128:1, 512:128) = aten::t(%456), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.intermediate/__module.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.23 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.31, %457), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.intermediate/__module.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.32 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.23, %455, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.intermediate/__module.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.33 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.32), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %461 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26630.NoNorm = prim::GetAttr[name="LayerNorm"](%452)
  %462 : __torch__.torch.nn.modules.linear.___torch_mangle_26629.Linear = prim::GetAttr[name="dense"](%452)
  %463 : Tensor = prim::GetAttr[name="bias"](%462)
  %464 : Tensor = prim::GetAttr[name="weight"](%462)
  %465 : Float(512:1, 128:512) = aten::t(%464), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.output/__module.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.24 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.33, %465), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.output/__module.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.24, %463, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.output/__module.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.7, %input.31, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %469 : Tensor = prim::GetAttr[name="bias"](%461)
  %470 : Tensor = prim::GetAttr[name="weight"](%461)
  %471 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.13, %470), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.output/__module.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.34 : Float(17:1664, 13:128, 128:1) = aten::add(%471, %469, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.0/__module.encoder.layer.1.ffn.0.output/__module.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %473 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26637.FFNOutput = prim::GetAttr[name="output"](%356)
  %474 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26634.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%356)
  %475 : __torch__.torch.nn.modules.linear.___torch_mangle_26633.Linear = prim::GetAttr[name="dense"](%474)
  %476 : Tensor = prim::GetAttr[name="bias"](%475)
  %477 : Tensor = prim::GetAttr[name="weight"](%475)
  %478 : Float(128:1, 512:128) = aten::t(%477), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.intermediate/__module.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.25 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.34, %478), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.intermediate/__module.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.35 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.25, %476, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.intermediate/__module.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.36 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.35), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %482 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26636.NoNorm = prim::GetAttr[name="LayerNorm"](%473)
  %483 : __torch__.torch.nn.modules.linear.___torch_mangle_26635.Linear = prim::GetAttr[name="dense"](%473)
  %484 : Tensor = prim::GetAttr[name="bias"](%483)
  %485 : Tensor = prim::GetAttr[name="weight"](%483)
  %486 : Float(512:1, 128:512) = aten::t(%485), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.output/__module.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.26 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.36, %486), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.output/__module.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.26, %484, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.output/__module.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.8, %input.34, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %490 : Tensor = prim::GetAttr[name="bias"](%482)
  %491 : Tensor = prim::GetAttr[name="weight"](%482)
  %492 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.14, %491), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.output/__module.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.37 : Float(17:1664, 13:128, 128:1) = aten::add(%492, %490, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.1/__module.encoder.layer.1.ffn.1.output/__module.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %494 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26643.FFNOutput = prim::GetAttr[name="output"](%354)
  %495 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26640.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%354)
  %496 : __torch__.torch.nn.modules.linear.___torch_mangle_26639.Linear = prim::GetAttr[name="dense"](%495)
  %497 : Tensor = prim::GetAttr[name="bias"](%496)
  %498 : Tensor = prim::GetAttr[name="weight"](%496)
  %499 : Float(128:1, 512:128) = aten::t(%498), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.intermediate/__module.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.27 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.37, %499), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.intermediate/__module.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.38 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.27, %497, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.intermediate/__module.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.39 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.38), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %503 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26642.NoNorm = prim::GetAttr[name="LayerNorm"](%494)
  %504 : __torch__.torch.nn.modules.linear.___torch_mangle_26641.Linear = prim::GetAttr[name="dense"](%494)
  %505 : Tensor = prim::GetAttr[name="bias"](%504)
  %506 : Tensor = prim::GetAttr[name="weight"](%504)
  %507 : Float(512:1, 128:512) = aten::t(%506), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.output/__module.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.28 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.39, %507), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.output/__module.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.28, %505, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.output/__module.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.9, %input.37, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %511 : Tensor = prim::GetAttr[name="bias"](%503)
  %512 : Tensor = prim::GetAttr[name="weight"](%503)
  %513 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.15, %512), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.output/__module.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.40 : Float(17:1664, 13:128, 128:1) = aten::add(%513, %511, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.ffn.2/__module.encoder.layer.1.ffn.2.output/__module.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %515 : __torch__.torch.nn.modules.linear.___torch_mangle_26611.Linear = prim::GetAttr[name="dense"](%352)
  %516 : Tensor = prim::GetAttr[name="bias"](%515)
  %517 : Tensor = prim::GetAttr[name="weight"](%515)
  %518 : Float(128:1, 512:128) = aten::t(%517), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.29 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.40, %518), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.41 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.29, %516, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate/__module.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.42 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.41), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.intermediate # torch/nn/functional.py:1119:0
  %522 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26618.OutputBottleneck = prim::GetAttr[name="bottleneck"](%351)
  %523 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26614.NoNorm = prim::GetAttr[name="LayerNorm"](%351)
  %524 : __torch__.torch.nn.modules.linear.___torch_mangle_26613.Linear = prim::GetAttr[name="dense"](%351)
  %525 : Tensor = prim::GetAttr[name="bias"](%524)
  %526 : Tensor = prim::GetAttr[name="weight"](%524)
  %527 : Float(512:1, 128:512) = aten::t(%526), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %output.30 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.42, %527), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %layer_output.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.30, %525, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.2, %input.40, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output # transformers/modeling_mobilebert.py:405:0
  %531 : Tensor = prim::GetAttr[name="bias"](%523)
  %532 : Tensor = prim::GetAttr[name="weight"](%523)
  %533 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.16, %532), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.43 : Float(17:1664, 13:128, 128:1) = aten::add(%533, %531, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %535 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26616.NoNorm = prim::GetAttr[name="LayerNorm"](%522)
  %536 : __torch__.torch.nn.modules.linear.___torch_mangle_26615.Linear = prim::GetAttr[name="dense"](%522)
  %537 : Tensor = prim::GetAttr[name="bias"](%536)
  %538 : Tensor = prim::GetAttr[name="weight"](%536)
  %539 : Float(128:1, 512:128) = aten::t(%538), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.bottleneck/__module.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.31 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.43, %539), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.bottleneck/__module.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.44 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.31, %537, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.bottleneck/__module.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.10 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.44, %105, %102), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.bottleneck/__module.encoder.layer.1.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.17 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.10, %input.26, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %544 : Tensor = prim::GetAttr[name="bias"](%535)
  %545 : Tensor = prim::GetAttr[name="weight"](%535)
  %546 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.17, %545), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.bottleneck/__module.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.45 : Float(17:6656, 13:512, 512:1) = aten::add(%546, %544, %92), scope: __module.encoder/__module.encoder.layer.1/__module.encoder.layer.1.output/__module.encoder.layer.1.output.bottleneck/__module.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %548 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26664.MobileBertOutput = prim::GetAttr[name="output"](%149)
  %549 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26657.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%149)
  %550 : __torch__.torch.nn.modules.container.___torch_mangle_26690.ModuleList = prim::GetAttr[name="ffn"](%149)
  %551 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26689.FFNLayer = prim::GetAttr[name="2"](%550)
  %552 : __torch__.torch.nn.modules.container.___torch_mangle_26690.ModuleList = prim::GetAttr[name="ffn"](%149)
  %553 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26683.FFNLayer = prim::GetAttr[name="1"](%552)
  %554 : __torch__.torch.nn.modules.container.___torch_mangle_26690.ModuleList = prim::GetAttr[name="ffn"](%149)
  %555 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26677.FFNLayer = prim::GetAttr[name="0"](%554)
  %556 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26655.MobileBertAttention = prim::GetAttr[name="attention"](%149)
  %557 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26671.Bottleneck = prim::GetAttr[name="bottleneck"](%149)
  %558 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26670.BottleneckLayer = prim::GetAttr[name="attention"](%557)
  %559 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26667.BottleneckLayer = prim::GetAttr[name="input"](%557)
  %560 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26666.NoNorm = prim::GetAttr[name="LayerNorm"](%559)
  %561 : __torch__.torch.nn.modules.linear.___torch_mangle_26665.Linear = prim::GetAttr[name="dense"](%559)
  %562 : Tensor = prim::GetAttr[name="bias"](%561)
  %563 : Tensor = prim::GetAttr[name="weight"](%561)
  %564 : Float(512:1, 128:512) = aten::t(%563), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.input/__module.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.32 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %564), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.input/__module.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.32, %562, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.input/__module.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %567 : Tensor = prim::GetAttr[name="bias"](%560)
  %568 : Tensor = prim::GetAttr[name="weight"](%560)
  %569 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.18, %568), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.input/__module.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add(%569, %567, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.input/__module.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %571 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26669.NoNorm = prim::GetAttr[name="LayerNorm"](%558)
  %572 : __torch__.torch.nn.modules.linear.___torch_mangle_26668.Linear = prim::GetAttr[name="dense"](%558)
  %573 : Tensor = prim::GetAttr[name="bias"](%572)
  %574 : Tensor = prim::GetAttr[name="weight"](%572)
  %575 : Float(512:1, 128:512) = aten::t(%574), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.attention/__module.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.33 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %575), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.attention/__module.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.33, %573, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.attention/__module.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %578 : Tensor = prim::GetAttr[name="bias"](%571)
  %579 : Tensor = prim::GetAttr[name="weight"](%571)
  %580 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.19, %579), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.attention/__module.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.46 : Float(17:1664, 13:128, 128:1) = aten::add(%580, %578, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.bottleneck/__module.encoder.layer.2.bottleneck.attention/__module.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %582 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.46, %residual_tensor.3)
  %583 : Float(17:1664, 13:128, 128:1), %584 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%582)
  %585 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26654.MobileBertSelfOutput = prim::GetAttr[name="output"](%556)
  %586 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26651.MobileBertSelfAttention = prim::GetAttr[name="self"](%556)
  %587 : __torch__.torch.nn.modules.linear.___torch_mangle_26649.Linear = prim::GetAttr[name="value"](%586)
  %588 : __torch__.torch.nn.modules.linear.___torch_mangle_26648.Linear = prim::GetAttr[name="key"](%586)
  %589 : __torch__.torch.nn.modules.linear.___torch_mangle_26647.Linear = prim::GetAttr[name="query"](%586)
  %590 : Tensor = prim::GetAttr[name="bias"](%589)
  %591 : Tensor = prim::GetAttr[name="weight"](%589)
  %592 : Float(128:1, 128:128) = aten::t(%591), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %output.34 : Float(17:1664, 13:128, 128:1) = aten::matmul(%583, %592), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %x.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.34, %590, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.query # torch/nn/functional.py:1678:0
  %595 : Tensor = prim::GetAttr[name="bias"](%588)
  %596 : Tensor = prim::GetAttr[name="weight"](%588)
  %597 : Float(128:1, 128:128) = aten::t(%596), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %output.35 : Float(17:1664, 13:128, 128:1) = aten::matmul(%583, %597), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %x.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.35, %595, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.key # torch/nn/functional.py:1678:0
  %600 : Tensor = prim::GetAttr[name="bias"](%587)
  %601 : Tensor = prim::GetAttr[name="weight"](%587)
  %602 : Float(512:1, 128:512) = aten::t(%601), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %output.36 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %602), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %x.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.36, %600, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.value # torch/nn/functional.py:1678:0
  %605 : int = aten::size(%x.13, %93), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %606 : int = aten::size(%x.13, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %607 : int[] = prim::ListConstruct(%605, %606, %94, %95), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %x.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.13, %607), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %609 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %query_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.14, %609), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %611 : int = aten::size(%x.15, %93), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %612 : int = aten::size(%x.15, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %613 : int[] = prim::ListConstruct(%611, %612, %94, %95), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %x.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.15, %613), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %615 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %key_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.16, %615), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %617 : int = aten::size(%x.17, %93), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %618 : int = aten::size(%x.17, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %619 : int[] = prim::ListConstruct(%617, %618, %94, %95), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %x.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.17, %619), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %621 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %value_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.18, %621), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %623 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.3, %98, %99), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.3, %623), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.5, %100), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.6, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.48 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.47, %98, %101), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.48, %103, %102), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self/__module.encoder.layer.2.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.5 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.3, %value_layer.3), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:280:0
  %630 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %631 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.5, %630), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%631, %93), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %633 : int = aten::size(%context_layer.6, %93), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %634 : int = aten::size(%context_layer.6, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %635 : int[] = prim::ListConstruct(%633, %634, %104), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self
  %input.49 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.6, %635), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:283:0
  %637 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26653.NoNorm = prim::GetAttr[name="LayerNorm"](%585)
  %638 : __torch__.torch.nn.modules.linear.___torch_mangle_26652.Linear = prim::GetAttr[name="dense"](%585)
  %639 : Tensor = prim::GetAttr[name="bias"](%638)
  %640 : Tensor = prim::GetAttr[name="weight"](%638)
  %641 : Float(128:1, 128:128) = aten::t(%640), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %output.37 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.49, %641), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.37, %639, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.11, %584, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output # transformers/modeling_mobilebert.py:301:0
  %645 : Tensor = prim::GetAttr[name="bias"](%637)
  %646 : Tensor = prim::GetAttr[name="weight"](%637)
  %647 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.20, %646), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.50 : Float(17:1664, 13:128, 128:1) = aten::add(%647, %645, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.attention/__module.encoder.layer.2.attention.output/__module.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %649 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26676.FFNOutput = prim::GetAttr[name="output"](%555)
  %650 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26673.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%555)
  %651 : __torch__.torch.nn.modules.linear.___torch_mangle_26672.Linear = prim::GetAttr[name="dense"](%650)
  %652 : Tensor = prim::GetAttr[name="bias"](%651)
  %653 : Tensor = prim::GetAttr[name="weight"](%651)
  %654 : Float(128:1, 512:128) = aten::t(%653), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.intermediate/__module.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.38 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.50, %654), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.intermediate/__module.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.51 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.38, %652, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.intermediate/__module.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.52 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.51), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %658 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26675.NoNorm = prim::GetAttr[name="LayerNorm"](%649)
  %659 : __torch__.torch.nn.modules.linear.___torch_mangle_26674.Linear = prim::GetAttr[name="dense"](%649)
  %660 : Tensor = prim::GetAttr[name="bias"](%659)
  %661 : Tensor = prim::GetAttr[name="weight"](%659)
  %662 : Float(512:1, 128:512) = aten::t(%661), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.output/__module.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.39 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.52, %662), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.output/__module.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.39, %660, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.output/__module.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.12, %input.50, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %666 : Tensor = prim::GetAttr[name="bias"](%658)
  %667 : Tensor = prim::GetAttr[name="weight"](%658)
  %668 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.21, %667), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.output/__module.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.53 : Float(17:1664, 13:128, 128:1) = aten::add(%668, %666, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.0/__module.encoder.layer.2.ffn.0.output/__module.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %670 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26682.FFNOutput = prim::GetAttr[name="output"](%553)
  %671 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26679.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%553)
  %672 : __torch__.torch.nn.modules.linear.___torch_mangle_26678.Linear = prim::GetAttr[name="dense"](%671)
  %673 : Tensor = prim::GetAttr[name="bias"](%672)
  %674 : Tensor = prim::GetAttr[name="weight"](%672)
  %675 : Float(128:1, 512:128) = aten::t(%674), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.intermediate/__module.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.40 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.53, %675), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.intermediate/__module.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.54 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.40, %673, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.intermediate/__module.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.55 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.54), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %679 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26681.NoNorm = prim::GetAttr[name="LayerNorm"](%670)
  %680 : __torch__.torch.nn.modules.linear.___torch_mangle_26680.Linear = prim::GetAttr[name="dense"](%670)
  %681 : Tensor = prim::GetAttr[name="bias"](%680)
  %682 : Tensor = prim::GetAttr[name="weight"](%680)
  %683 : Float(512:1, 128:512) = aten::t(%682), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.output/__module.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.41 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.55, %683), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.output/__module.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.41, %681, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.output/__module.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.13, %input.53, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %687 : Tensor = prim::GetAttr[name="bias"](%679)
  %688 : Tensor = prim::GetAttr[name="weight"](%679)
  %689 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.22, %688), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.output/__module.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.56 : Float(17:1664, 13:128, 128:1) = aten::add(%689, %687, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.1/__module.encoder.layer.2.ffn.1.output/__module.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %691 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26688.FFNOutput = prim::GetAttr[name="output"](%551)
  %692 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26685.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%551)
  %693 : __torch__.torch.nn.modules.linear.___torch_mangle_26684.Linear = prim::GetAttr[name="dense"](%692)
  %694 : Tensor = prim::GetAttr[name="bias"](%693)
  %695 : Tensor = prim::GetAttr[name="weight"](%693)
  %696 : Float(128:1, 512:128) = aten::t(%695), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.intermediate/__module.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.42 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.56, %696), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.intermediate/__module.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.57 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.42, %694, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.intermediate/__module.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.58 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.57), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %700 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26687.NoNorm = prim::GetAttr[name="LayerNorm"](%691)
  %701 : __torch__.torch.nn.modules.linear.___torch_mangle_26686.Linear = prim::GetAttr[name="dense"](%691)
  %702 : Tensor = prim::GetAttr[name="bias"](%701)
  %703 : Tensor = prim::GetAttr[name="weight"](%701)
  %704 : Float(512:1, 128:512) = aten::t(%703), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.output/__module.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.43 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.58, %704), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.output/__module.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.43, %702, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.output/__module.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.14, %input.56, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %708 : Tensor = prim::GetAttr[name="bias"](%700)
  %709 : Tensor = prim::GetAttr[name="weight"](%700)
  %710 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.23, %709), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.output/__module.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.59 : Float(17:1664, 13:128, 128:1) = aten::add(%710, %708, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.ffn.2/__module.encoder.layer.2.ffn.2.output/__module.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %712 : __torch__.torch.nn.modules.linear.___torch_mangle_26656.Linear = prim::GetAttr[name="dense"](%549)
  %713 : Tensor = prim::GetAttr[name="bias"](%712)
  %714 : Tensor = prim::GetAttr[name="weight"](%712)
  %715 : Float(128:1, 512:128) = aten::t(%714), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate/__module.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.44 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.59, %715), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate/__module.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.60 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.44, %713, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate/__module.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.61 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.60), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.intermediate # torch/nn/functional.py:1119:0
  %719 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26663.OutputBottleneck = prim::GetAttr[name="bottleneck"](%548)
  %720 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26659.NoNorm = prim::GetAttr[name="LayerNorm"](%548)
  %721 : __torch__.torch.nn.modules.linear.___torch_mangle_26658.Linear = prim::GetAttr[name="dense"](%548)
  %722 : Tensor = prim::GetAttr[name="bias"](%721)
  %723 : Tensor = prim::GetAttr[name="weight"](%721)
  %724 : Float(512:1, 128:512) = aten::t(%723), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %output.45 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.61, %724), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %layer_output.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.45, %722, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.24 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.3, %input.59, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output # transformers/modeling_mobilebert.py:405:0
  %728 : Tensor = prim::GetAttr[name="bias"](%720)
  %729 : Tensor = prim::GetAttr[name="weight"](%720)
  %730 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.24, %729), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.62 : Float(17:1664, 13:128, 128:1) = aten::add(%730, %728, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %732 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26661.NoNorm = prim::GetAttr[name="LayerNorm"](%719)
  %733 : __torch__.torch.nn.modules.linear.___torch_mangle_26660.Linear = prim::GetAttr[name="dense"](%719)
  %734 : Tensor = prim::GetAttr[name="bias"](%733)
  %735 : Tensor = prim::GetAttr[name="weight"](%733)
  %736 : Float(128:1, 512:128) = aten::t(%735), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.bottleneck/__module.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.46 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.62, %736), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.bottleneck/__module.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.63 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.46, %734, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.bottleneck/__module.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.15 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.63, %105, %102), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.bottleneck/__module.encoder.layer.2.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.25 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.15, %input.45, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %741 : Tensor = prim::GetAttr[name="bias"](%732)
  %742 : Tensor = prim::GetAttr[name="weight"](%732)
  %743 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.25, %742), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.bottleneck/__module.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.64 : Float(17:6656, 13:512, 512:1) = aten::add(%743, %741, %92), scope: __module.encoder/__module.encoder.layer.2/__module.encoder.layer.2.output/__module.encoder.layer.2.output.bottleneck/__module.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %745 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26709.MobileBertOutput = prim::GetAttr[name="output"](%147)
  %746 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26702.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%147)
  %747 : __torch__.torch.nn.modules.container.___torch_mangle_26735.ModuleList = prim::GetAttr[name="ffn"](%147)
  %748 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26734.FFNLayer = prim::GetAttr[name="2"](%747)
  %749 : __torch__.torch.nn.modules.container.___torch_mangle_26735.ModuleList = prim::GetAttr[name="ffn"](%147)
  %750 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26728.FFNLayer = prim::GetAttr[name="1"](%749)
  %751 : __torch__.torch.nn.modules.container.___torch_mangle_26735.ModuleList = prim::GetAttr[name="ffn"](%147)
  %752 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26722.FFNLayer = prim::GetAttr[name="0"](%751)
  %753 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26700.MobileBertAttention = prim::GetAttr[name="attention"](%147)
  %754 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26716.Bottleneck = prim::GetAttr[name="bottleneck"](%147)
  %755 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26715.BottleneckLayer = prim::GetAttr[name="attention"](%754)
  %756 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26712.BottleneckLayer = prim::GetAttr[name="input"](%754)
  %757 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26711.NoNorm = prim::GetAttr[name="LayerNorm"](%756)
  %758 : __torch__.torch.nn.modules.linear.___torch_mangle_26710.Linear = prim::GetAttr[name="dense"](%756)
  %759 : Tensor = prim::GetAttr[name="bias"](%758)
  %760 : Tensor = prim::GetAttr[name="weight"](%758)
  %761 : Float(512:1, 128:512) = aten::t(%760), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.input/__module.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.47 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %761), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.input/__module.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.47, %759, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.input/__module.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %764 : Tensor = prim::GetAttr[name="bias"](%757)
  %765 : Tensor = prim::GetAttr[name="weight"](%757)
  %766 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.26, %765), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.input/__module.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%766, %764, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.input/__module.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %768 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26714.NoNorm = prim::GetAttr[name="LayerNorm"](%755)
  %769 : __torch__.torch.nn.modules.linear.___torch_mangle_26713.Linear = prim::GetAttr[name="dense"](%755)
  %770 : Tensor = prim::GetAttr[name="bias"](%769)
  %771 : Tensor = prim::GetAttr[name="weight"](%769)
  %772 : Float(512:1, 128:512) = aten::t(%771), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.attention/__module.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.48 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %772), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.attention/__module.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.48, %770, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.attention/__module.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %775 : Tensor = prim::GetAttr[name="bias"](%768)
  %776 : Tensor = prim::GetAttr[name="weight"](%768)
  %777 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.27, %776), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.attention/__module.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.65 : Float(17:1664, 13:128, 128:1) = aten::add(%777, %775, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.bottleneck/__module.encoder.layer.3.bottleneck.attention/__module.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %779 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.65, %residual_tensor.4)
  %780 : Float(17:1664, 13:128, 128:1), %781 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%779)
  %782 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26699.MobileBertSelfOutput = prim::GetAttr[name="output"](%753)
  %783 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26696.MobileBertSelfAttention = prim::GetAttr[name="self"](%753)
  %784 : __torch__.torch.nn.modules.linear.___torch_mangle_26694.Linear = prim::GetAttr[name="value"](%783)
  %785 : __torch__.torch.nn.modules.linear.___torch_mangle_26693.Linear = prim::GetAttr[name="key"](%783)
  %786 : __torch__.torch.nn.modules.linear.___torch_mangle_26692.Linear = prim::GetAttr[name="query"](%783)
  %787 : Tensor = prim::GetAttr[name="bias"](%786)
  %788 : Tensor = prim::GetAttr[name="weight"](%786)
  %789 : Float(128:1, 128:128) = aten::t(%788), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %output.49 : Float(17:1664, 13:128, 128:1) = aten::matmul(%780, %789), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %x.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.49, %787, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.query # torch/nn/functional.py:1678:0
  %792 : Tensor = prim::GetAttr[name="bias"](%785)
  %793 : Tensor = prim::GetAttr[name="weight"](%785)
  %794 : Float(128:1, 128:128) = aten::t(%793), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %output.50 : Float(17:1664, 13:128, 128:1) = aten::matmul(%780, %794), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %x.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.50, %792, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.key # torch/nn/functional.py:1678:0
  %797 : Tensor = prim::GetAttr[name="bias"](%784)
  %798 : Tensor = prim::GetAttr[name="weight"](%784)
  %799 : Float(512:1, 128:512) = aten::t(%798), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %output.51 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %799), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %x.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.51, %797, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.value # torch/nn/functional.py:1678:0
  %802 : int = aten::size(%x.19, %93), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %803 : int = aten::size(%x.19, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %804 : int[] = prim::ListConstruct(%802, %803, %94, %95), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %x.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.19, %804), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %806 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %query_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.20, %806), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %808 : int = aten::size(%x.21, %93), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %809 : int = aten::size(%x.21, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %810 : int[] = prim::ListConstruct(%808, %809, %94, %95), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %x.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.21, %810), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %812 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %key_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.22, %812), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %814 : int = aten::size(%x.23, %93), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %815 : int = aten::size(%x.23, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %816 : int[] = prim::ListConstruct(%814, %815, %94, %95), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %x.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.23, %816), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %818 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %value_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.24, %818), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %820 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.4, %98, %99), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.4, %820), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.7, %100), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.66 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.8, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.67 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.66, %98, %101), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.67, %103, %102), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self/__module.encoder.layer.3.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.7 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.4, %value_layer.4), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:280:0
  %827 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %828 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.7, %827), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%828, %93), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %830 : int = aten::size(%context_layer.8, %93), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %831 : int = aten::size(%context_layer.8, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %832 : int[] = prim::ListConstruct(%830, %831, %104), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self
  %input.68 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.8, %832), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:283:0
  %834 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26698.NoNorm = prim::GetAttr[name="LayerNorm"](%782)
  %835 : __torch__.torch.nn.modules.linear.___torch_mangle_26697.Linear = prim::GetAttr[name="dense"](%782)
  %836 : Tensor = prim::GetAttr[name="bias"](%835)
  %837 : Tensor = prim::GetAttr[name="weight"](%835)
  %838 : Float(128:1, 128:128) = aten::t(%837), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %output.52 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.68, %838), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.52, %836, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.28 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.16, %781, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output # transformers/modeling_mobilebert.py:301:0
  %842 : Tensor = prim::GetAttr[name="bias"](%834)
  %843 : Tensor = prim::GetAttr[name="weight"](%834)
  %844 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.28, %843), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.69 : Float(17:1664, 13:128, 128:1) = aten::add(%844, %842, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.attention/__module.encoder.layer.3.attention.output/__module.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %846 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26721.FFNOutput = prim::GetAttr[name="output"](%752)
  %847 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26718.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%752)
  %848 : __torch__.torch.nn.modules.linear.___torch_mangle_26717.Linear = prim::GetAttr[name="dense"](%847)
  %849 : Tensor = prim::GetAttr[name="bias"](%848)
  %850 : Tensor = prim::GetAttr[name="weight"](%848)
  %851 : Float(128:1, 512:128) = aten::t(%850), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.intermediate/__module.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.53 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.69, %851), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.intermediate/__module.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.70 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.53, %849, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.intermediate/__module.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.71 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.70), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %855 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26720.NoNorm = prim::GetAttr[name="LayerNorm"](%846)
  %856 : __torch__.torch.nn.modules.linear.___torch_mangle_26719.Linear = prim::GetAttr[name="dense"](%846)
  %857 : Tensor = prim::GetAttr[name="bias"](%856)
  %858 : Tensor = prim::GetAttr[name="weight"](%856)
  %859 : Float(512:1, 128:512) = aten::t(%858), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.output/__module.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.54 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.71, %859), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.output/__module.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.54, %857, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.output/__module.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.29 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.17, %input.69, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %863 : Tensor = prim::GetAttr[name="bias"](%855)
  %864 : Tensor = prim::GetAttr[name="weight"](%855)
  %865 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.29, %864), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.output/__module.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.72 : Float(17:1664, 13:128, 128:1) = aten::add(%865, %863, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.0/__module.encoder.layer.3.ffn.0.output/__module.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %867 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26727.FFNOutput = prim::GetAttr[name="output"](%750)
  %868 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26724.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%750)
  %869 : __torch__.torch.nn.modules.linear.___torch_mangle_26723.Linear = prim::GetAttr[name="dense"](%868)
  %870 : Tensor = prim::GetAttr[name="bias"](%869)
  %871 : Tensor = prim::GetAttr[name="weight"](%869)
  %872 : Float(128:1, 512:128) = aten::t(%871), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.intermediate/__module.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.55 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.72, %872), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.intermediate/__module.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.73 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.55, %870, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.intermediate/__module.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.74 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.73), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %876 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26726.NoNorm = prim::GetAttr[name="LayerNorm"](%867)
  %877 : __torch__.torch.nn.modules.linear.___torch_mangle_26725.Linear = prim::GetAttr[name="dense"](%867)
  %878 : Tensor = prim::GetAttr[name="bias"](%877)
  %879 : Tensor = prim::GetAttr[name="weight"](%877)
  %880 : Float(512:1, 128:512) = aten::t(%879), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.output/__module.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.56 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.74, %880), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.output/__module.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.56, %878, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.output/__module.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.30 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.18, %input.72, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %884 : Tensor = prim::GetAttr[name="bias"](%876)
  %885 : Tensor = prim::GetAttr[name="weight"](%876)
  %886 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.30, %885), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.output/__module.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.75 : Float(17:1664, 13:128, 128:1) = aten::add(%886, %884, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.1/__module.encoder.layer.3.ffn.1.output/__module.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %888 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26733.FFNOutput = prim::GetAttr[name="output"](%748)
  %889 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26730.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%748)
  %890 : __torch__.torch.nn.modules.linear.___torch_mangle_26729.Linear = prim::GetAttr[name="dense"](%889)
  %891 : Tensor = prim::GetAttr[name="bias"](%890)
  %892 : Tensor = prim::GetAttr[name="weight"](%890)
  %893 : Float(128:1, 512:128) = aten::t(%892), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.intermediate/__module.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.57 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.75, %893), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.intermediate/__module.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.76 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.57, %891, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.intermediate/__module.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.77 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.76), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %897 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26732.NoNorm = prim::GetAttr[name="LayerNorm"](%888)
  %898 : __torch__.torch.nn.modules.linear.___torch_mangle_26731.Linear = prim::GetAttr[name="dense"](%888)
  %899 : Tensor = prim::GetAttr[name="bias"](%898)
  %900 : Tensor = prim::GetAttr[name="weight"](%898)
  %901 : Float(512:1, 128:512) = aten::t(%900), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.output/__module.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.58 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.77, %901), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.output/__module.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.58, %899, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.output/__module.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.31 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.19, %input.75, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %905 : Tensor = prim::GetAttr[name="bias"](%897)
  %906 : Tensor = prim::GetAttr[name="weight"](%897)
  %907 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.31, %906), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.output/__module.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.78 : Float(17:1664, 13:128, 128:1) = aten::add(%907, %905, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.ffn.2/__module.encoder.layer.3.ffn.2.output/__module.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %909 : __torch__.torch.nn.modules.linear.___torch_mangle_26701.Linear = prim::GetAttr[name="dense"](%746)
  %910 : Tensor = prim::GetAttr[name="bias"](%909)
  %911 : Tensor = prim::GetAttr[name="weight"](%909)
  %912 : Float(128:1, 512:128) = aten::t(%911), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate/__module.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %output.59 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.78, %912), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate/__module.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %input.79 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.59, %910, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate/__module.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1678:0
  %input.80 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.79), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.intermediate # torch/nn/functional.py:1119:0
  %916 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26708.OutputBottleneck = prim::GetAttr[name="bottleneck"](%745)
  %917 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26704.NoNorm = prim::GetAttr[name="LayerNorm"](%745)
  %918 : __torch__.torch.nn.modules.linear.___torch_mangle_26703.Linear = prim::GetAttr[name="dense"](%745)
  %919 : Tensor = prim::GetAttr[name="bias"](%918)
  %920 : Tensor = prim::GetAttr[name="weight"](%918)
  %921 : Float(512:1, 128:512) = aten::t(%920), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %output.60 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.80, %921), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %layer_output.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.60, %919, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.32 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.4, %input.78, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output # transformers/modeling_mobilebert.py:405:0
  %925 : Tensor = prim::GetAttr[name="bias"](%917)
  %926 : Tensor = prim::GetAttr[name="weight"](%917)
  %927 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.32, %926), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.81 : Float(17:1664, 13:128, 128:1) = aten::add(%927, %925, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %929 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26706.NoNorm = prim::GetAttr[name="LayerNorm"](%916)
  %930 : __torch__.torch.nn.modules.linear.___torch_mangle_26705.Linear = prim::GetAttr[name="dense"](%916)
  %931 : Tensor = prim::GetAttr[name="bias"](%930)
  %932 : Tensor = prim::GetAttr[name="weight"](%930)
  %933 : Float(128:1, 512:128) = aten::t(%932), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.bottleneck/__module.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.61 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.81, %933), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.bottleneck/__module.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.82 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.61, %931, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.bottleneck/__module.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.20 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.82, %105, %102), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.bottleneck/__module.encoder.layer.3.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.33 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.20, %input.64, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %938 : Tensor = prim::GetAttr[name="bias"](%929)
  %939 : Tensor = prim::GetAttr[name="weight"](%929)
  %940 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.33, %939), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.bottleneck/__module.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.83 : Float(17:6656, 13:512, 512:1) = aten::add(%940, %938, %92), scope: __module.encoder/__module.encoder.layer.3/__module.encoder.layer.3.output/__module.encoder.layer.3.output.bottleneck/__module.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %942 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26754.MobileBertOutput = prim::GetAttr[name="output"](%145)
  %943 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26747.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%145)
  %944 : __torch__.torch.nn.modules.container.___torch_mangle_26780.ModuleList = prim::GetAttr[name="ffn"](%145)
  %945 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26779.FFNLayer = prim::GetAttr[name="2"](%944)
  %946 : __torch__.torch.nn.modules.container.___torch_mangle_26780.ModuleList = prim::GetAttr[name="ffn"](%145)
  %947 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26773.FFNLayer = prim::GetAttr[name="1"](%946)
  %948 : __torch__.torch.nn.modules.container.___torch_mangle_26780.ModuleList = prim::GetAttr[name="ffn"](%145)
  %949 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26767.FFNLayer = prim::GetAttr[name="0"](%948)
  %950 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26745.MobileBertAttention = prim::GetAttr[name="attention"](%145)
  %951 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26761.Bottleneck = prim::GetAttr[name="bottleneck"](%145)
  %952 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26760.BottleneckLayer = prim::GetAttr[name="attention"](%951)
  %953 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26757.BottleneckLayer = prim::GetAttr[name="input"](%951)
  %954 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26756.NoNorm = prim::GetAttr[name="LayerNorm"](%953)
  %955 : __torch__.torch.nn.modules.linear.___torch_mangle_26755.Linear = prim::GetAttr[name="dense"](%953)
  %956 : Tensor = prim::GetAttr[name="bias"](%955)
  %957 : Tensor = prim::GetAttr[name="weight"](%955)
  %958 : Float(512:1, 128:512) = aten::t(%957), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.input/__module.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.62 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %958), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.input/__module.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.62, %956, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.input/__module.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %961 : Tensor = prim::GetAttr[name="bias"](%954)
  %962 : Tensor = prim::GetAttr[name="weight"](%954)
  %963 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.34, %962), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.input/__module.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%963, %961, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.input/__module.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %965 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26759.NoNorm = prim::GetAttr[name="LayerNorm"](%952)
  %966 : __torch__.torch.nn.modules.linear.___torch_mangle_26758.Linear = prim::GetAttr[name="dense"](%952)
  %967 : Tensor = prim::GetAttr[name="bias"](%966)
  %968 : Tensor = prim::GetAttr[name="weight"](%966)
  %969 : Float(512:1, 128:512) = aten::t(%968), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.attention/__module.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.63 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %969), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.attention/__module.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.63, %967, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.attention/__module.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %972 : Tensor = prim::GetAttr[name="bias"](%965)
  %973 : Tensor = prim::GetAttr[name="weight"](%965)
  %974 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.35, %973), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.attention/__module.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.84 : Float(17:1664, 13:128, 128:1) = aten::add(%974, %972, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.bottleneck/__module.encoder.layer.4.bottleneck.attention/__module.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %976 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.84, %residual_tensor.5)
  %977 : Float(17:1664, 13:128, 128:1), %978 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%976)
  %979 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26744.MobileBertSelfOutput = prim::GetAttr[name="output"](%950)
  %980 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26741.MobileBertSelfAttention = prim::GetAttr[name="self"](%950)
  %981 : __torch__.torch.nn.modules.linear.___torch_mangle_26739.Linear = prim::GetAttr[name="value"](%980)
  %982 : __torch__.torch.nn.modules.linear.___torch_mangle_26738.Linear = prim::GetAttr[name="key"](%980)
  %983 : __torch__.torch.nn.modules.linear.___torch_mangle_26737.Linear = prim::GetAttr[name="query"](%980)
  %984 : Tensor = prim::GetAttr[name="bias"](%983)
  %985 : Tensor = prim::GetAttr[name="weight"](%983)
  %986 : Float(128:1, 128:128) = aten::t(%985), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %output.64 : Float(17:1664, 13:128, 128:1) = aten::matmul(%977, %986), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %x.25 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.64, %984, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.query # torch/nn/functional.py:1678:0
  %989 : Tensor = prim::GetAttr[name="bias"](%982)
  %990 : Tensor = prim::GetAttr[name="weight"](%982)
  %991 : Float(128:1, 128:128) = aten::t(%990), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %output.65 : Float(17:1664, 13:128, 128:1) = aten::matmul(%977, %991), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %x.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.65, %989, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.key # torch/nn/functional.py:1678:0
  %994 : Tensor = prim::GetAttr[name="bias"](%981)
  %995 : Tensor = prim::GetAttr[name="weight"](%981)
  %996 : Float(512:1, 128:512) = aten::t(%995), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %output.66 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %996), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %x.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.66, %994, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.value # torch/nn/functional.py:1678:0
  %999 : int = aten::size(%x.25, %93), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1000 : int = aten::size(%x.25, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1001 : int[] = prim::ListConstruct(%999, %1000, %94, %95), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %x.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.25, %1001), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %1003 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %query_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.26, %1003), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %1005 : int = aten::size(%x.27, %93), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1006 : int = aten::size(%x.27, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1007 : int[] = prim::ListConstruct(%1005, %1006, %94, %95), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %x.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.27, %1007), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %1009 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %key_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.28, %1009), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %1011 : int = aten::size(%x.29, %93), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1012 : int = aten::size(%x.29, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1013 : int[] = prim::ListConstruct(%1011, %1012, %94, %95), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %x.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.29, %1013), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %1015 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %value_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.30, %1015), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %1017 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.5, %98, %99), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.5, %1017), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.9, %100), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.85 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.10, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.86 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.85, %98, %101), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.86, %103, %102), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self/__module.encoder.layer.4.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.9 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.5, %value_layer.5), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:280:0
  %1024 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %1025 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.9, %1024), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1025, %93), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %1027 : int = aten::size(%context_layer.10, %93), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1028 : int = aten::size(%context_layer.10, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1029 : int[] = prim::ListConstruct(%1027, %1028, %104), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self
  %input.87 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.10, %1029), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:283:0
  %1031 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26743.NoNorm = prim::GetAttr[name="LayerNorm"](%979)
  %1032 : __torch__.torch.nn.modules.linear.___torch_mangle_26742.Linear = prim::GetAttr[name="dense"](%979)
  %1033 : Tensor = prim::GetAttr[name="bias"](%1032)
  %1034 : Tensor = prim::GetAttr[name="weight"](%1032)
  %1035 : Float(128:1, 128:128) = aten::t(%1034), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %output.67 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.87, %1035), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.67, %1033, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.36 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.21, %978, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output # transformers/modeling_mobilebert.py:301:0
  %1039 : Tensor = prim::GetAttr[name="bias"](%1031)
  %1040 : Tensor = prim::GetAttr[name="weight"](%1031)
  %1041 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.36, %1040), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.88 : Float(17:1664, 13:128, 128:1) = aten::add(%1041, %1039, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.attention/__module.encoder.layer.4.attention.output/__module.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1043 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26766.FFNOutput = prim::GetAttr[name="output"](%949)
  %1044 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26763.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%949)
  %1045 : __torch__.torch.nn.modules.linear.___torch_mangle_26762.Linear = prim::GetAttr[name="dense"](%1044)
  %1046 : Tensor = prim::GetAttr[name="bias"](%1045)
  %1047 : Tensor = prim::GetAttr[name="weight"](%1045)
  %1048 : Float(128:1, 512:128) = aten::t(%1047), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.intermediate/__module.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.68 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.88, %1048), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.intermediate/__module.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.89 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.68, %1046, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.intermediate/__module.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.90 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.89), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1052 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26765.NoNorm = prim::GetAttr[name="LayerNorm"](%1043)
  %1053 : __torch__.torch.nn.modules.linear.___torch_mangle_26764.Linear = prim::GetAttr[name="dense"](%1043)
  %1054 : Tensor = prim::GetAttr[name="bias"](%1053)
  %1055 : Tensor = prim::GetAttr[name="weight"](%1053)
  %1056 : Float(512:1, 128:512) = aten::t(%1055), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.output/__module.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.69 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.90, %1056), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.output/__module.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.69, %1054, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.output/__module.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.37 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.22, %input.88, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1060 : Tensor = prim::GetAttr[name="bias"](%1052)
  %1061 : Tensor = prim::GetAttr[name="weight"](%1052)
  %1062 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.37, %1061), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.output/__module.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.91 : Float(17:1664, 13:128, 128:1) = aten::add(%1062, %1060, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.0/__module.encoder.layer.4.ffn.0.output/__module.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1064 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26772.FFNOutput = prim::GetAttr[name="output"](%947)
  %1065 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26769.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%947)
  %1066 : __torch__.torch.nn.modules.linear.___torch_mangle_26768.Linear = prim::GetAttr[name="dense"](%1065)
  %1067 : Tensor = prim::GetAttr[name="bias"](%1066)
  %1068 : Tensor = prim::GetAttr[name="weight"](%1066)
  %1069 : Float(128:1, 512:128) = aten::t(%1068), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.intermediate/__module.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.70 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.91, %1069), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.intermediate/__module.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.92 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.70, %1067, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.intermediate/__module.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.93 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1073 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26771.NoNorm = prim::GetAttr[name="LayerNorm"](%1064)
  %1074 : __torch__.torch.nn.modules.linear.___torch_mangle_26770.Linear = prim::GetAttr[name="dense"](%1064)
  %1075 : Tensor = prim::GetAttr[name="bias"](%1074)
  %1076 : Tensor = prim::GetAttr[name="weight"](%1074)
  %1077 : Float(512:1, 128:512) = aten::t(%1076), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.output/__module.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.71 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.93, %1077), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.output/__module.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.71, %1075, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.output/__module.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.38 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.23, %input.91, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1081 : Tensor = prim::GetAttr[name="bias"](%1073)
  %1082 : Tensor = prim::GetAttr[name="weight"](%1073)
  %1083 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.38, %1082), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.output/__module.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.94 : Float(17:1664, 13:128, 128:1) = aten::add(%1083, %1081, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.1/__module.encoder.layer.4.ffn.1.output/__module.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1085 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26778.FFNOutput = prim::GetAttr[name="output"](%945)
  %1086 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26775.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%945)
  %1087 : __torch__.torch.nn.modules.linear.___torch_mangle_26774.Linear = prim::GetAttr[name="dense"](%1086)
  %1088 : Tensor = prim::GetAttr[name="bias"](%1087)
  %1089 : Tensor = prim::GetAttr[name="weight"](%1087)
  %1090 : Float(128:1, 512:128) = aten::t(%1089), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.intermediate/__module.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.72 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.94, %1090), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.intermediate/__module.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.95 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.72, %1088, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.intermediate/__module.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.96 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.95), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1094 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26777.NoNorm = prim::GetAttr[name="LayerNorm"](%1085)
  %1095 : __torch__.torch.nn.modules.linear.___torch_mangle_26776.Linear = prim::GetAttr[name="dense"](%1085)
  %1096 : Tensor = prim::GetAttr[name="bias"](%1095)
  %1097 : Tensor = prim::GetAttr[name="weight"](%1095)
  %1098 : Float(512:1, 128:512) = aten::t(%1097), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.output/__module.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.73 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.96, %1098), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.output/__module.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.24 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.73, %1096, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.output/__module.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.39 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.24, %input.94, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1102 : Tensor = prim::GetAttr[name="bias"](%1094)
  %1103 : Tensor = prim::GetAttr[name="weight"](%1094)
  %1104 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.39, %1103), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.output/__module.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.97 : Float(17:1664, 13:128, 128:1) = aten::add(%1104, %1102, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.ffn.2/__module.encoder.layer.4.ffn.2.output/__module.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1106 : __torch__.torch.nn.modules.linear.___torch_mangle_26746.Linear = prim::GetAttr[name="dense"](%943)
  %1107 : Tensor = prim::GetAttr[name="bias"](%1106)
  %1108 : Tensor = prim::GetAttr[name="weight"](%1106)
  %1109 : Float(128:1, 512:128) = aten::t(%1108), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate/__module.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %output.74 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.97, %1109), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate/__module.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %input.98 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.74, %1107, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate/__module.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1678:0
  %input.99 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.98), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.intermediate # torch/nn/functional.py:1119:0
  %1113 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26753.OutputBottleneck = prim::GetAttr[name="bottleneck"](%942)
  %1114 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26749.NoNorm = prim::GetAttr[name="LayerNorm"](%942)
  %1115 : __torch__.torch.nn.modules.linear.___torch_mangle_26748.Linear = prim::GetAttr[name="dense"](%942)
  %1116 : Tensor = prim::GetAttr[name="bias"](%1115)
  %1117 : Tensor = prim::GetAttr[name="weight"](%1115)
  %1118 : Float(512:1, 128:512) = aten::t(%1117), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %output.75 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.99, %1118), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %layer_output.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.75, %1116, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.40 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.5, %input.97, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output # transformers/modeling_mobilebert.py:405:0
  %1122 : Tensor = prim::GetAttr[name="bias"](%1114)
  %1123 : Tensor = prim::GetAttr[name="weight"](%1114)
  %1124 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.40, %1123), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.100 : Float(17:1664, 13:128, 128:1) = aten::add(%1124, %1122, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1126 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26751.NoNorm = prim::GetAttr[name="LayerNorm"](%1113)
  %1127 : __torch__.torch.nn.modules.linear.___torch_mangle_26750.Linear = prim::GetAttr[name="dense"](%1113)
  %1128 : Tensor = prim::GetAttr[name="bias"](%1127)
  %1129 : Tensor = prim::GetAttr[name="weight"](%1127)
  %1130 : Float(128:1, 512:128) = aten::t(%1129), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.bottleneck/__module.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.76 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.100, %1130), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.bottleneck/__module.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.101 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.76, %1128, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.bottleneck/__module.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.25 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.101, %105, %102), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.bottleneck/__module.encoder.layer.4.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.41 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.25, %input.83, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1135 : Tensor = prim::GetAttr[name="bias"](%1126)
  %1136 : Tensor = prim::GetAttr[name="weight"](%1126)
  %1137 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.41, %1136), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.bottleneck/__module.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.102 : Float(17:6656, 13:512, 512:1) = aten::add(%1137, %1135, %92), scope: __module.encoder/__module.encoder.layer.4/__module.encoder.layer.4.output/__module.encoder.layer.4.output.bottleneck/__module.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1139 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26799.MobileBertOutput = prim::GetAttr[name="output"](%143)
  %1140 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26792.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%143)
  %1141 : __torch__.torch.nn.modules.container.___torch_mangle_26825.ModuleList = prim::GetAttr[name="ffn"](%143)
  %1142 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26824.FFNLayer = prim::GetAttr[name="2"](%1141)
  %1143 : __torch__.torch.nn.modules.container.___torch_mangle_26825.ModuleList = prim::GetAttr[name="ffn"](%143)
  %1144 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26818.FFNLayer = prim::GetAttr[name="1"](%1143)
  %1145 : __torch__.torch.nn.modules.container.___torch_mangle_26825.ModuleList = prim::GetAttr[name="ffn"](%143)
  %1146 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26812.FFNLayer = prim::GetAttr[name="0"](%1145)
  %1147 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26790.MobileBertAttention = prim::GetAttr[name="attention"](%143)
  %1148 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26806.Bottleneck = prim::GetAttr[name="bottleneck"](%143)
  %1149 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26805.BottleneckLayer = prim::GetAttr[name="attention"](%1148)
  %1150 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26802.BottleneckLayer = prim::GetAttr[name="input"](%1148)
  %1151 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26801.NoNorm = prim::GetAttr[name="LayerNorm"](%1150)
  %1152 : __torch__.torch.nn.modules.linear.___torch_mangle_26800.Linear = prim::GetAttr[name="dense"](%1150)
  %1153 : Tensor = prim::GetAttr[name="bias"](%1152)
  %1154 : Tensor = prim::GetAttr[name="weight"](%1152)
  %1155 : Float(512:1, 128:512) = aten::t(%1154), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.input/__module.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.77 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1155), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.input/__module.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.77, %1153, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.input/__module.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1158 : Tensor = prim::GetAttr[name="bias"](%1151)
  %1159 : Tensor = prim::GetAttr[name="weight"](%1151)
  %1160 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.42, %1159), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.input/__module.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%1160, %1158, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.input/__module.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1162 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26804.NoNorm = prim::GetAttr[name="LayerNorm"](%1149)
  %1163 : __torch__.torch.nn.modules.linear.___torch_mangle_26803.Linear = prim::GetAttr[name="dense"](%1149)
  %1164 : Tensor = prim::GetAttr[name="bias"](%1163)
  %1165 : Tensor = prim::GetAttr[name="weight"](%1163)
  %1166 : Float(512:1, 128:512) = aten::t(%1165), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.attention/__module.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.78 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1166), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.attention/__module.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.78, %1164, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.attention/__module.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1169 : Tensor = prim::GetAttr[name="bias"](%1162)
  %1170 : Tensor = prim::GetAttr[name="weight"](%1162)
  %1171 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.43, %1170), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.attention/__module.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.103 : Float(17:1664, 13:128, 128:1) = aten::add(%1171, %1169, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.bottleneck/__module.encoder.layer.5.bottleneck.attention/__module.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1173 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.103, %residual_tensor.6)
  %1174 : Float(17:1664, 13:128, 128:1), %1175 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1173)
  %1176 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26789.MobileBertSelfOutput = prim::GetAttr[name="output"](%1147)
  %1177 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26786.MobileBertSelfAttention = prim::GetAttr[name="self"](%1147)
  %1178 : __torch__.torch.nn.modules.linear.___torch_mangle_26784.Linear = prim::GetAttr[name="value"](%1177)
  %1179 : __torch__.torch.nn.modules.linear.___torch_mangle_26783.Linear = prim::GetAttr[name="key"](%1177)
  %1180 : __torch__.torch.nn.modules.linear.___torch_mangle_26782.Linear = prim::GetAttr[name="query"](%1177)
  %1181 : Tensor = prim::GetAttr[name="bias"](%1180)
  %1182 : Tensor = prim::GetAttr[name="weight"](%1180)
  %1183 : Float(128:1, 128:128) = aten::t(%1182), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %output.79 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1174, %1183), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %x.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.79, %1181, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.query # torch/nn/functional.py:1678:0
  %1186 : Tensor = prim::GetAttr[name="bias"](%1179)
  %1187 : Tensor = prim::GetAttr[name="weight"](%1179)
  %1188 : Float(128:1, 128:128) = aten::t(%1187), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %output.80 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1174, %1188), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %x.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.80, %1186, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.key # torch/nn/functional.py:1678:0
  %1191 : Tensor = prim::GetAttr[name="bias"](%1178)
  %1192 : Tensor = prim::GetAttr[name="weight"](%1178)
  %1193 : Float(512:1, 128:512) = aten::t(%1192), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %output.81 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1193), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %x.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.81, %1191, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.value # torch/nn/functional.py:1678:0
  %1196 : int = aten::size(%x.31, %93), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1197 : int = aten::size(%x.31, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1198 : int[] = prim::ListConstruct(%1196, %1197, %94, %95), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %x.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.31, %1198), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1200 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %query_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.32, %1200), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1202 : int = aten::size(%x.33, %93), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1203 : int = aten::size(%x.33, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1204 : int[] = prim::ListConstruct(%1202, %1203, %94, %95), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %x.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.33, %1204), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1206 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %key_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.34, %1206), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1208 : int = aten::size(%x.35, %93), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1209 : int = aten::size(%x.35, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1210 : int[] = prim::ListConstruct(%1208, %1209, %94, %95), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %x.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.35, %1210), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1212 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %value_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.36, %1212), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1214 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.6, %98, %99), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.6, %1214), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.11, %100), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.104 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.12, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.105 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.104, %98, %101), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.105, %103, %102), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self/__module.encoder.layer.5.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.11 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.6, %value_layer.6), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:280:0
  %1221 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %1222 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.11, %1221), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1222, %93), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %1224 : int = aten::size(%context_layer.12, %93), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1225 : int = aten::size(%context_layer.12, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1226 : int[] = prim::ListConstruct(%1224, %1225, %104), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self
  %input.106 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.12, %1226), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:283:0
  %1228 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26788.NoNorm = prim::GetAttr[name="LayerNorm"](%1176)
  %1229 : __torch__.torch.nn.modules.linear.___torch_mangle_26787.Linear = prim::GetAttr[name="dense"](%1176)
  %1230 : Tensor = prim::GetAttr[name="bias"](%1229)
  %1231 : Tensor = prim::GetAttr[name="weight"](%1229)
  %1232 : Float(128:1, 128:128) = aten::t(%1231), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %output.82 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.106, %1232), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.82, %1230, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.44 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.26, %1175, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output # transformers/modeling_mobilebert.py:301:0
  %1236 : Tensor = prim::GetAttr[name="bias"](%1228)
  %1237 : Tensor = prim::GetAttr[name="weight"](%1228)
  %1238 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.44, %1237), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.107 : Float(17:1664, 13:128, 128:1) = aten::add(%1238, %1236, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.attention/__module.encoder.layer.5.attention.output/__module.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1240 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26811.FFNOutput = prim::GetAttr[name="output"](%1146)
  %1241 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26808.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1146)
  %1242 : __torch__.torch.nn.modules.linear.___torch_mangle_26807.Linear = prim::GetAttr[name="dense"](%1241)
  %1243 : Tensor = prim::GetAttr[name="bias"](%1242)
  %1244 : Tensor = prim::GetAttr[name="weight"](%1242)
  %1245 : Float(128:1, 512:128) = aten::t(%1244), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.intermediate/__module.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.83 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.107, %1245), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.intermediate/__module.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.108 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.83, %1243, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.intermediate/__module.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.109 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.108), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1249 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26810.NoNorm = prim::GetAttr[name="LayerNorm"](%1240)
  %1250 : __torch__.torch.nn.modules.linear.___torch_mangle_26809.Linear = prim::GetAttr[name="dense"](%1240)
  %1251 : Tensor = prim::GetAttr[name="bias"](%1250)
  %1252 : Tensor = prim::GetAttr[name="weight"](%1250)
  %1253 : Float(512:1, 128:512) = aten::t(%1252), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.output/__module.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.84 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.109, %1253), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.output/__module.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.84, %1251, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.output/__module.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.45 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.27, %input.107, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1257 : Tensor = prim::GetAttr[name="bias"](%1249)
  %1258 : Tensor = prim::GetAttr[name="weight"](%1249)
  %1259 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.45, %1258), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.output/__module.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.110 : Float(17:1664, 13:128, 128:1) = aten::add(%1259, %1257, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.0/__module.encoder.layer.5.ffn.0.output/__module.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1261 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26817.FFNOutput = prim::GetAttr[name="output"](%1144)
  %1262 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26814.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1144)
  %1263 : __torch__.torch.nn.modules.linear.___torch_mangle_26813.Linear = prim::GetAttr[name="dense"](%1262)
  %1264 : Tensor = prim::GetAttr[name="bias"](%1263)
  %1265 : Tensor = prim::GetAttr[name="weight"](%1263)
  %1266 : Float(128:1, 512:128) = aten::t(%1265), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.intermediate/__module.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.85 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.110, %1266), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.intermediate/__module.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.111 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.85, %1264, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.intermediate/__module.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.112 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.111), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1270 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26816.NoNorm = prim::GetAttr[name="LayerNorm"](%1261)
  %1271 : __torch__.torch.nn.modules.linear.___torch_mangle_26815.Linear = prim::GetAttr[name="dense"](%1261)
  %1272 : Tensor = prim::GetAttr[name="bias"](%1271)
  %1273 : Tensor = prim::GetAttr[name="weight"](%1271)
  %1274 : Float(512:1, 128:512) = aten::t(%1273), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.output/__module.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.86 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.112, %1274), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.output/__module.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.28 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.86, %1272, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.output/__module.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.46 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.28, %input.110, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1278 : Tensor = prim::GetAttr[name="bias"](%1270)
  %1279 : Tensor = prim::GetAttr[name="weight"](%1270)
  %1280 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.46, %1279), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.output/__module.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.113 : Float(17:1664, 13:128, 128:1) = aten::add(%1280, %1278, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.1/__module.encoder.layer.5.ffn.1.output/__module.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1282 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26823.FFNOutput = prim::GetAttr[name="output"](%1142)
  %1283 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26820.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1142)
  %1284 : __torch__.torch.nn.modules.linear.___torch_mangle_26819.Linear = prim::GetAttr[name="dense"](%1283)
  %1285 : Tensor = prim::GetAttr[name="bias"](%1284)
  %1286 : Tensor = prim::GetAttr[name="weight"](%1284)
  %1287 : Float(128:1, 512:128) = aten::t(%1286), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.intermediate/__module.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.87 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.113, %1287), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.intermediate/__module.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.114 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.87, %1285, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.intermediate/__module.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.115 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.114), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1291 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26822.NoNorm = prim::GetAttr[name="LayerNorm"](%1282)
  %1292 : __torch__.torch.nn.modules.linear.___torch_mangle_26821.Linear = prim::GetAttr[name="dense"](%1282)
  %1293 : Tensor = prim::GetAttr[name="bias"](%1292)
  %1294 : Tensor = prim::GetAttr[name="weight"](%1292)
  %1295 : Float(512:1, 128:512) = aten::t(%1294), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.output/__module.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.88 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.115, %1295), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.output/__module.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.88, %1293, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.output/__module.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.47 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.29, %input.113, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1299 : Tensor = prim::GetAttr[name="bias"](%1291)
  %1300 : Tensor = prim::GetAttr[name="weight"](%1291)
  %1301 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.47, %1300), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.output/__module.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.116 : Float(17:1664, 13:128, 128:1) = aten::add(%1301, %1299, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.ffn.2/__module.encoder.layer.5.ffn.2.output/__module.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1303 : __torch__.torch.nn.modules.linear.___torch_mangle_26791.Linear = prim::GetAttr[name="dense"](%1140)
  %1304 : Tensor = prim::GetAttr[name="bias"](%1303)
  %1305 : Tensor = prim::GetAttr[name="weight"](%1303)
  %1306 : Float(128:1, 512:128) = aten::t(%1305), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate/__module.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %output.89 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.116, %1306), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate/__module.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %input.117 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.89, %1304, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate/__module.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1678:0
  %input.118 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.117), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.intermediate # torch/nn/functional.py:1119:0
  %1310 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26798.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1139)
  %1311 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26794.NoNorm = prim::GetAttr[name="LayerNorm"](%1139)
  %1312 : __torch__.torch.nn.modules.linear.___torch_mangle_26793.Linear = prim::GetAttr[name="dense"](%1139)
  %1313 : Tensor = prim::GetAttr[name="bias"](%1312)
  %1314 : Tensor = prim::GetAttr[name="weight"](%1312)
  %1315 : Float(512:1, 128:512) = aten::t(%1314), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %output.90 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.118, %1315), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %layer_output.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.90, %1313, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.48 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.6, %input.116, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output # transformers/modeling_mobilebert.py:405:0
  %1319 : Tensor = prim::GetAttr[name="bias"](%1311)
  %1320 : Tensor = prim::GetAttr[name="weight"](%1311)
  %1321 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.48, %1320), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.119 : Float(17:1664, 13:128, 128:1) = aten::add(%1321, %1319, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1323 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26796.NoNorm = prim::GetAttr[name="LayerNorm"](%1310)
  %1324 : __torch__.torch.nn.modules.linear.___torch_mangle_26795.Linear = prim::GetAttr[name="dense"](%1310)
  %1325 : Tensor = prim::GetAttr[name="bias"](%1324)
  %1326 : Tensor = prim::GetAttr[name="weight"](%1324)
  %1327 : Float(128:1, 512:128) = aten::t(%1326), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.bottleneck/__module.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.91 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.119, %1327), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.bottleneck/__module.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.120 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.91, %1325, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.bottleneck/__module.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.30 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.120, %105, %102), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.bottleneck/__module.encoder.layer.5.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.49 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.30, %input.102, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1332 : Tensor = prim::GetAttr[name="bias"](%1323)
  %1333 : Tensor = prim::GetAttr[name="weight"](%1323)
  %1334 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.49, %1333), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.bottleneck/__module.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.121 : Float(17:6656, 13:512, 512:1) = aten::add(%1334, %1332, %92), scope: __module.encoder/__module.encoder.layer.5/__module.encoder.layer.5.output/__module.encoder.layer.5.output.bottleneck/__module.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1336 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26844.MobileBertOutput = prim::GetAttr[name="output"](%141)
  %1337 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26837.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%141)
  %1338 : __torch__.torch.nn.modules.container.___torch_mangle_26870.ModuleList = prim::GetAttr[name="ffn"](%141)
  %1339 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26869.FFNLayer = prim::GetAttr[name="2"](%1338)
  %1340 : __torch__.torch.nn.modules.container.___torch_mangle_26870.ModuleList = prim::GetAttr[name="ffn"](%141)
  %1341 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26863.FFNLayer = prim::GetAttr[name="1"](%1340)
  %1342 : __torch__.torch.nn.modules.container.___torch_mangle_26870.ModuleList = prim::GetAttr[name="ffn"](%141)
  %1343 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26857.FFNLayer = prim::GetAttr[name="0"](%1342)
  %1344 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26835.MobileBertAttention = prim::GetAttr[name="attention"](%141)
  %1345 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26851.Bottleneck = prim::GetAttr[name="bottleneck"](%141)
  %1346 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26850.BottleneckLayer = prim::GetAttr[name="attention"](%1345)
  %1347 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26847.BottleneckLayer = prim::GetAttr[name="input"](%1345)
  %1348 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26846.NoNorm = prim::GetAttr[name="LayerNorm"](%1347)
  %1349 : __torch__.torch.nn.modules.linear.___torch_mangle_26845.Linear = prim::GetAttr[name="dense"](%1347)
  %1350 : Tensor = prim::GetAttr[name="bias"](%1349)
  %1351 : Tensor = prim::GetAttr[name="weight"](%1349)
  %1352 : Float(512:1, 128:512) = aten::t(%1351), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.input/__module.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.92 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1352), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.input/__module.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.50 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.92, %1350, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.input/__module.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1355 : Tensor = prim::GetAttr[name="bias"](%1348)
  %1356 : Tensor = prim::GetAttr[name="weight"](%1348)
  %1357 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.50, %1356), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.input/__module.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%1357, %1355, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.input/__module.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1359 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26849.NoNorm = prim::GetAttr[name="LayerNorm"](%1346)
  %1360 : __torch__.torch.nn.modules.linear.___torch_mangle_26848.Linear = prim::GetAttr[name="dense"](%1346)
  %1361 : Tensor = prim::GetAttr[name="bias"](%1360)
  %1362 : Tensor = prim::GetAttr[name="weight"](%1360)
  %1363 : Float(512:1, 128:512) = aten::t(%1362), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.attention/__module.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.93 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1363), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.attention/__module.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.93, %1361, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.attention/__module.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1366 : Tensor = prim::GetAttr[name="bias"](%1359)
  %1367 : Tensor = prim::GetAttr[name="weight"](%1359)
  %1368 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.51, %1367), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.attention/__module.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.122 : Float(17:1664, 13:128, 128:1) = aten::add(%1368, %1366, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.bottleneck/__module.encoder.layer.6.bottleneck.attention/__module.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1370 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.122, %residual_tensor.7)
  %1371 : Float(17:1664, 13:128, 128:1), %1372 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1370)
  %1373 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26834.MobileBertSelfOutput = prim::GetAttr[name="output"](%1344)
  %1374 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26831.MobileBertSelfAttention = prim::GetAttr[name="self"](%1344)
  %1375 : __torch__.torch.nn.modules.linear.___torch_mangle_26829.Linear = prim::GetAttr[name="value"](%1374)
  %1376 : __torch__.torch.nn.modules.linear.___torch_mangle_26828.Linear = prim::GetAttr[name="key"](%1374)
  %1377 : __torch__.torch.nn.modules.linear.___torch_mangle_26827.Linear = prim::GetAttr[name="query"](%1374)
  %1378 : Tensor = prim::GetAttr[name="bias"](%1377)
  %1379 : Tensor = prim::GetAttr[name="weight"](%1377)
  %1380 : Float(128:1, 128:128) = aten::t(%1379), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %output.94 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1371, %1380), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %x.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.94, %1378, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.query # torch/nn/functional.py:1678:0
  %1383 : Tensor = prim::GetAttr[name="bias"](%1376)
  %1384 : Tensor = prim::GetAttr[name="weight"](%1376)
  %1385 : Float(128:1, 128:128) = aten::t(%1384), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %output.95 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1371, %1385), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %x.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.95, %1383, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.key # torch/nn/functional.py:1678:0
  %1388 : Tensor = prim::GetAttr[name="bias"](%1375)
  %1389 : Tensor = prim::GetAttr[name="weight"](%1375)
  %1390 : Float(512:1, 128:512) = aten::t(%1389), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %output.96 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1390), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %x.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.96, %1388, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.value # torch/nn/functional.py:1678:0
  %1393 : int = aten::size(%x.37, %93), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1394 : int = aten::size(%x.37, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1395 : int[] = prim::ListConstruct(%1393, %1394, %94, %95), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %x.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.37, %1395), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1397 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %query_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.38, %1397), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1399 : int = aten::size(%x.39, %93), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1400 : int = aten::size(%x.39, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1401 : int[] = prim::ListConstruct(%1399, %1400, %94, %95), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %x.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.39, %1401), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1403 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %key_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.40, %1403), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1405 : int = aten::size(%x.41, %93), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1406 : int = aten::size(%x.41, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1407 : int[] = prim::ListConstruct(%1405, %1406, %94, %95), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %x.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.41, %1407), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1409 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %value_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.42, %1409), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1411 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.7, %98, %99), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.7, %1411), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.13, %100), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.123 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.14, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.124 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.123, %98, %101), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.124, %103, %102), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self/__module.encoder.layer.6.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.13 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.7, %value_layer.7), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:280:0
  %1418 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %1419 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.13, %1418), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1419, %93), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %1421 : int = aten::size(%context_layer.14, %93), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1422 : int = aten::size(%context_layer.14, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1423 : int[] = prim::ListConstruct(%1421, %1422, %104), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self
  %input.125 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.14, %1423), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:283:0
  %1425 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26833.NoNorm = prim::GetAttr[name="LayerNorm"](%1373)
  %1426 : __torch__.torch.nn.modules.linear.___torch_mangle_26832.Linear = prim::GetAttr[name="dense"](%1373)
  %1427 : Tensor = prim::GetAttr[name="bias"](%1426)
  %1428 : Tensor = prim::GetAttr[name="weight"](%1426)
  %1429 : Float(128:1, 128:128) = aten::t(%1428), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %output.97 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.125, %1429), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.97, %1427, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.52 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.31, %1372, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output # transformers/modeling_mobilebert.py:301:0
  %1433 : Tensor = prim::GetAttr[name="bias"](%1425)
  %1434 : Tensor = prim::GetAttr[name="weight"](%1425)
  %1435 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.52, %1434), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.126 : Float(17:1664, 13:128, 128:1) = aten::add(%1435, %1433, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.attention/__module.encoder.layer.6.attention.output/__module.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1437 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26856.FFNOutput = prim::GetAttr[name="output"](%1343)
  %1438 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26853.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1343)
  %1439 : __torch__.torch.nn.modules.linear.___torch_mangle_26852.Linear = prim::GetAttr[name="dense"](%1438)
  %1440 : Tensor = prim::GetAttr[name="bias"](%1439)
  %1441 : Tensor = prim::GetAttr[name="weight"](%1439)
  %1442 : Float(128:1, 512:128) = aten::t(%1441), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.intermediate/__module.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.98 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.126, %1442), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.intermediate/__module.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.127 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.98, %1440, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.intermediate/__module.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.128 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.127), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1446 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26855.NoNorm = prim::GetAttr[name="LayerNorm"](%1437)
  %1447 : __torch__.torch.nn.modules.linear.___torch_mangle_26854.Linear = prim::GetAttr[name="dense"](%1437)
  %1448 : Tensor = prim::GetAttr[name="bias"](%1447)
  %1449 : Tensor = prim::GetAttr[name="weight"](%1447)
  %1450 : Float(512:1, 128:512) = aten::t(%1449), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.output/__module.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.99 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.128, %1450), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.output/__module.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.32 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.99, %1448, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.output/__module.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.53 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.32, %input.126, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1454 : Tensor = prim::GetAttr[name="bias"](%1446)
  %1455 : Tensor = prim::GetAttr[name="weight"](%1446)
  %1456 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.53, %1455), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.output/__module.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.129 : Float(17:1664, 13:128, 128:1) = aten::add(%1456, %1454, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.0/__module.encoder.layer.6.ffn.0.output/__module.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1458 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26862.FFNOutput = prim::GetAttr[name="output"](%1341)
  %1459 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26859.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1341)
  %1460 : __torch__.torch.nn.modules.linear.___torch_mangle_26858.Linear = prim::GetAttr[name="dense"](%1459)
  %1461 : Tensor = prim::GetAttr[name="bias"](%1460)
  %1462 : Tensor = prim::GetAttr[name="weight"](%1460)
  %1463 : Float(128:1, 512:128) = aten::t(%1462), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.intermediate/__module.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.100 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.129, %1463), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.intermediate/__module.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.130 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.100, %1461, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.intermediate/__module.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.131 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.130), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1467 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26861.NoNorm = prim::GetAttr[name="LayerNorm"](%1458)
  %1468 : __torch__.torch.nn.modules.linear.___torch_mangle_26860.Linear = prim::GetAttr[name="dense"](%1458)
  %1469 : Tensor = prim::GetAttr[name="bias"](%1468)
  %1470 : Tensor = prim::GetAttr[name="weight"](%1468)
  %1471 : Float(512:1, 128:512) = aten::t(%1470), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.output/__module.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.101 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.131, %1471), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.output/__module.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.101, %1469, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.output/__module.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.54 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.33, %input.129, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1475 : Tensor = prim::GetAttr[name="bias"](%1467)
  %1476 : Tensor = prim::GetAttr[name="weight"](%1467)
  %1477 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.54, %1476), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.output/__module.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.132 : Float(17:1664, 13:128, 128:1) = aten::add(%1477, %1475, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.1/__module.encoder.layer.6.ffn.1.output/__module.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1479 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26868.FFNOutput = prim::GetAttr[name="output"](%1339)
  %1480 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26865.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1339)
  %1481 : __torch__.torch.nn.modules.linear.___torch_mangle_26864.Linear = prim::GetAttr[name="dense"](%1480)
  %1482 : Tensor = prim::GetAttr[name="bias"](%1481)
  %1483 : Tensor = prim::GetAttr[name="weight"](%1481)
  %1484 : Float(128:1, 512:128) = aten::t(%1483), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.intermediate/__module.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.102 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.132, %1484), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.intermediate/__module.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.133 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.102, %1482, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.intermediate/__module.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.134 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.133), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1488 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26867.NoNorm = prim::GetAttr[name="LayerNorm"](%1479)
  %1489 : __torch__.torch.nn.modules.linear.___torch_mangle_26866.Linear = prim::GetAttr[name="dense"](%1479)
  %1490 : Tensor = prim::GetAttr[name="bias"](%1489)
  %1491 : Tensor = prim::GetAttr[name="weight"](%1489)
  %1492 : Float(512:1, 128:512) = aten::t(%1491), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.output/__module.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.103 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.134, %1492), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.output/__module.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.103, %1490, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.output/__module.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.55 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.34, %input.132, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1496 : Tensor = prim::GetAttr[name="bias"](%1488)
  %1497 : Tensor = prim::GetAttr[name="weight"](%1488)
  %1498 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.55, %1497), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.output/__module.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.135 : Float(17:1664, 13:128, 128:1) = aten::add(%1498, %1496, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.ffn.2/__module.encoder.layer.6.ffn.2.output/__module.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1500 : __torch__.torch.nn.modules.linear.___torch_mangle_26836.Linear = prim::GetAttr[name="dense"](%1337)
  %1501 : Tensor = prim::GetAttr[name="bias"](%1500)
  %1502 : Tensor = prim::GetAttr[name="weight"](%1500)
  %1503 : Float(128:1, 512:128) = aten::t(%1502), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate/__module.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %output.104 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.135, %1503), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate/__module.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %input.136 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.104, %1501, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate/__module.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1678:0
  %input.137 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.136), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.intermediate # torch/nn/functional.py:1119:0
  %1507 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26843.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1336)
  %1508 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26839.NoNorm = prim::GetAttr[name="LayerNorm"](%1336)
  %1509 : __torch__.torch.nn.modules.linear.___torch_mangle_26838.Linear = prim::GetAttr[name="dense"](%1336)
  %1510 : Tensor = prim::GetAttr[name="bias"](%1509)
  %1511 : Tensor = prim::GetAttr[name="weight"](%1509)
  %1512 : Float(512:1, 128:512) = aten::t(%1511), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %output.105 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.137, %1512), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %layer_output.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.105, %1510, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.56 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.7, %input.135, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output # transformers/modeling_mobilebert.py:405:0
  %1516 : Tensor = prim::GetAttr[name="bias"](%1508)
  %1517 : Tensor = prim::GetAttr[name="weight"](%1508)
  %1518 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.56, %1517), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.138 : Float(17:1664, 13:128, 128:1) = aten::add(%1518, %1516, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1520 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26841.NoNorm = prim::GetAttr[name="LayerNorm"](%1507)
  %1521 : __torch__.torch.nn.modules.linear.___torch_mangle_26840.Linear = prim::GetAttr[name="dense"](%1507)
  %1522 : Tensor = prim::GetAttr[name="bias"](%1521)
  %1523 : Tensor = prim::GetAttr[name="weight"](%1521)
  %1524 : Float(128:1, 512:128) = aten::t(%1523), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.bottleneck/__module.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.106 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.138, %1524), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.bottleneck/__module.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.139 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.106, %1522, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.bottleneck/__module.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.35 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.139, %105, %102), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.bottleneck/__module.encoder.layer.6.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.57 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.35, %input.121, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1529 : Tensor = prim::GetAttr[name="bias"](%1520)
  %1530 : Tensor = prim::GetAttr[name="weight"](%1520)
  %1531 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.57, %1530), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.bottleneck/__module.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.140 : Float(17:6656, 13:512, 512:1) = aten::add(%1531, %1529, %92), scope: __module.encoder/__module.encoder.layer.6/__module.encoder.layer.6.output/__module.encoder.layer.6.output.bottleneck/__module.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1533 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26889.MobileBertOutput = prim::GetAttr[name="output"](%139)
  %1534 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26882.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%139)
  %1535 : __torch__.torch.nn.modules.container.___torch_mangle_26915.ModuleList = prim::GetAttr[name="ffn"](%139)
  %1536 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26914.FFNLayer = prim::GetAttr[name="2"](%1535)
  %1537 : __torch__.torch.nn.modules.container.___torch_mangle_26915.ModuleList = prim::GetAttr[name="ffn"](%139)
  %1538 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26908.FFNLayer = prim::GetAttr[name="1"](%1537)
  %1539 : __torch__.torch.nn.modules.container.___torch_mangle_26915.ModuleList = prim::GetAttr[name="ffn"](%139)
  %1540 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26902.FFNLayer = prim::GetAttr[name="0"](%1539)
  %1541 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26880.MobileBertAttention = prim::GetAttr[name="attention"](%139)
  %1542 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26896.Bottleneck = prim::GetAttr[name="bottleneck"](%139)
  %1543 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26895.BottleneckLayer = prim::GetAttr[name="attention"](%1542)
  %1544 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26892.BottleneckLayer = prim::GetAttr[name="input"](%1542)
  %1545 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26891.NoNorm = prim::GetAttr[name="LayerNorm"](%1544)
  %1546 : __torch__.torch.nn.modules.linear.___torch_mangle_26890.Linear = prim::GetAttr[name="dense"](%1544)
  %1547 : Tensor = prim::GetAttr[name="bias"](%1546)
  %1548 : Tensor = prim::GetAttr[name="weight"](%1546)
  %1549 : Float(512:1, 128:512) = aten::t(%1548), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.input/__module.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.107 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1549), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.input/__module.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.107, %1547, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.input/__module.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1552 : Tensor = prim::GetAttr[name="bias"](%1545)
  %1553 : Tensor = prim::GetAttr[name="weight"](%1545)
  %1554 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.58, %1553), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.input/__module.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%1554, %1552, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.input/__module.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1556 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26894.NoNorm = prim::GetAttr[name="LayerNorm"](%1543)
  %1557 : __torch__.torch.nn.modules.linear.___torch_mangle_26893.Linear = prim::GetAttr[name="dense"](%1543)
  %1558 : Tensor = prim::GetAttr[name="bias"](%1557)
  %1559 : Tensor = prim::GetAttr[name="weight"](%1557)
  %1560 : Float(512:1, 128:512) = aten::t(%1559), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.attention/__module.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.108 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1560), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.attention/__module.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.108, %1558, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.attention/__module.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1563 : Tensor = prim::GetAttr[name="bias"](%1556)
  %1564 : Tensor = prim::GetAttr[name="weight"](%1556)
  %1565 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.59, %1564), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.attention/__module.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.141 : Float(17:1664, 13:128, 128:1) = aten::add(%1565, %1563, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.bottleneck/__module.encoder.layer.7.bottleneck.attention/__module.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1567 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.141, %residual_tensor.8)
  %1568 : Float(17:1664, 13:128, 128:1), %1569 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1567)
  %1570 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26879.MobileBertSelfOutput = prim::GetAttr[name="output"](%1541)
  %1571 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26876.MobileBertSelfAttention = prim::GetAttr[name="self"](%1541)
  %1572 : __torch__.torch.nn.modules.linear.___torch_mangle_26874.Linear = prim::GetAttr[name="value"](%1571)
  %1573 : __torch__.torch.nn.modules.linear.___torch_mangle_26873.Linear = prim::GetAttr[name="key"](%1571)
  %1574 : __torch__.torch.nn.modules.linear.___torch_mangle_26872.Linear = prim::GetAttr[name="query"](%1571)
  %1575 : Tensor = prim::GetAttr[name="bias"](%1574)
  %1576 : Tensor = prim::GetAttr[name="weight"](%1574)
  %1577 : Float(128:1, 128:128) = aten::t(%1576), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %output.109 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1568, %1577), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %x.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.109, %1575, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.query # torch/nn/functional.py:1678:0
  %1580 : Tensor = prim::GetAttr[name="bias"](%1573)
  %1581 : Tensor = prim::GetAttr[name="weight"](%1573)
  %1582 : Float(128:1, 128:128) = aten::t(%1581), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %output.110 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1568, %1582), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %x.45 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.110, %1580, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.key # torch/nn/functional.py:1678:0
  %1585 : Tensor = prim::GetAttr[name="bias"](%1572)
  %1586 : Tensor = prim::GetAttr[name="weight"](%1572)
  %1587 : Float(512:1, 128:512) = aten::t(%1586), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %output.111 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1587), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %x.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.111, %1585, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.value # torch/nn/functional.py:1678:0
  %1590 : int = aten::size(%x.43, %93), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1591 : int = aten::size(%x.43, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1592 : int[] = prim::ListConstruct(%1590, %1591, %94, %95), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %x.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.43, %1592), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1594 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %query_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.44, %1594), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1596 : int = aten::size(%x.45, %93), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1597 : int = aten::size(%x.45, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1598 : int[] = prim::ListConstruct(%1596, %1597, %94, %95), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %x.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.45, %1598), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1600 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %key_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.46, %1600), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1602 : int = aten::size(%x.47, %93), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1603 : int = aten::size(%x.47, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1604 : int[] = prim::ListConstruct(%1602, %1603, %94, %95), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %x.48 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.47, %1604), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1606 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %value_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.48, %1606), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1608 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.8, %98, %99), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.8, %1608), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.15, %100), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.142 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.16, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.143 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.142, %98, %101), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.143, %103, %102), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self/__module.encoder.layer.7.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.15 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.8, %value_layer.8), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:280:0
  %1615 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %1616 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.15, %1615), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1616, %93), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %1618 : int = aten::size(%context_layer.16, %93), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1619 : int = aten::size(%context_layer.16, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1620 : int[] = prim::ListConstruct(%1618, %1619, %104), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self
  %input.144 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.16, %1620), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:283:0
  %1622 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26878.NoNorm = prim::GetAttr[name="LayerNorm"](%1570)
  %1623 : __torch__.torch.nn.modules.linear.___torch_mangle_26877.Linear = prim::GetAttr[name="dense"](%1570)
  %1624 : Tensor = prim::GetAttr[name="bias"](%1623)
  %1625 : Tensor = prim::GetAttr[name="weight"](%1623)
  %1626 : Float(128:1, 128:128) = aten::t(%1625), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %output.112 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.144, %1626), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.36 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.112, %1624, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.60 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.36, %1569, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output # transformers/modeling_mobilebert.py:301:0
  %1630 : Tensor = prim::GetAttr[name="bias"](%1622)
  %1631 : Tensor = prim::GetAttr[name="weight"](%1622)
  %1632 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.60, %1631), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.145 : Float(17:1664, 13:128, 128:1) = aten::add(%1632, %1630, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.attention/__module.encoder.layer.7.attention.output/__module.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1634 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26901.FFNOutput = prim::GetAttr[name="output"](%1540)
  %1635 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26898.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1540)
  %1636 : __torch__.torch.nn.modules.linear.___torch_mangle_26897.Linear = prim::GetAttr[name="dense"](%1635)
  %1637 : Tensor = prim::GetAttr[name="bias"](%1636)
  %1638 : Tensor = prim::GetAttr[name="weight"](%1636)
  %1639 : Float(128:1, 512:128) = aten::t(%1638), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.intermediate/__module.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.113 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.145, %1639), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.intermediate/__module.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.146 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.113, %1637, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.intermediate/__module.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.147 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.146), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1643 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26900.NoNorm = prim::GetAttr[name="LayerNorm"](%1634)
  %1644 : __torch__.torch.nn.modules.linear.___torch_mangle_26899.Linear = prim::GetAttr[name="dense"](%1634)
  %1645 : Tensor = prim::GetAttr[name="bias"](%1644)
  %1646 : Tensor = prim::GetAttr[name="weight"](%1644)
  %1647 : Float(512:1, 128:512) = aten::t(%1646), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.output/__module.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.114 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.147, %1647), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.output/__module.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.114, %1645, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.output/__module.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.61 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.37, %input.145, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1651 : Tensor = prim::GetAttr[name="bias"](%1643)
  %1652 : Tensor = prim::GetAttr[name="weight"](%1643)
  %1653 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.61, %1652), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.output/__module.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.148 : Float(17:1664, 13:128, 128:1) = aten::add(%1653, %1651, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.0/__module.encoder.layer.7.ffn.0.output/__module.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1655 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26907.FFNOutput = prim::GetAttr[name="output"](%1538)
  %1656 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26904.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1538)
  %1657 : __torch__.torch.nn.modules.linear.___torch_mangle_26903.Linear = prim::GetAttr[name="dense"](%1656)
  %1658 : Tensor = prim::GetAttr[name="bias"](%1657)
  %1659 : Tensor = prim::GetAttr[name="weight"](%1657)
  %1660 : Float(128:1, 512:128) = aten::t(%1659), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.intermediate/__module.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.115 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.148, %1660), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.intermediate/__module.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.149 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.115, %1658, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.intermediate/__module.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.150 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.149), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1664 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26906.NoNorm = prim::GetAttr[name="LayerNorm"](%1655)
  %1665 : __torch__.torch.nn.modules.linear.___torch_mangle_26905.Linear = prim::GetAttr[name="dense"](%1655)
  %1666 : Tensor = prim::GetAttr[name="bias"](%1665)
  %1667 : Tensor = prim::GetAttr[name="weight"](%1665)
  %1668 : Float(512:1, 128:512) = aten::t(%1667), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.output/__module.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.116 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.150, %1668), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.output/__module.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.38 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.116, %1666, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.output/__module.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.62 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.38, %input.148, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1672 : Tensor = prim::GetAttr[name="bias"](%1664)
  %1673 : Tensor = prim::GetAttr[name="weight"](%1664)
  %1674 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.62, %1673), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.output/__module.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.151 : Float(17:1664, 13:128, 128:1) = aten::add(%1674, %1672, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.1/__module.encoder.layer.7.ffn.1.output/__module.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1676 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26913.FFNOutput = prim::GetAttr[name="output"](%1536)
  %1677 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26910.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1536)
  %1678 : __torch__.torch.nn.modules.linear.___torch_mangle_26909.Linear = prim::GetAttr[name="dense"](%1677)
  %1679 : Tensor = prim::GetAttr[name="bias"](%1678)
  %1680 : Tensor = prim::GetAttr[name="weight"](%1678)
  %1681 : Float(128:1, 512:128) = aten::t(%1680), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.intermediate/__module.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.117 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.151, %1681), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.intermediate/__module.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.152 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.117, %1679, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.intermediate/__module.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.153 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.152), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1685 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26912.NoNorm = prim::GetAttr[name="LayerNorm"](%1676)
  %1686 : __torch__.torch.nn.modules.linear.___torch_mangle_26911.Linear = prim::GetAttr[name="dense"](%1676)
  %1687 : Tensor = prim::GetAttr[name="bias"](%1686)
  %1688 : Tensor = prim::GetAttr[name="weight"](%1686)
  %1689 : Float(512:1, 128:512) = aten::t(%1688), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.output/__module.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.118 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.153, %1689), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.output/__module.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.118, %1687, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.output/__module.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.63 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.39, %input.151, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1693 : Tensor = prim::GetAttr[name="bias"](%1685)
  %1694 : Tensor = prim::GetAttr[name="weight"](%1685)
  %1695 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.63, %1694), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.output/__module.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.154 : Float(17:1664, 13:128, 128:1) = aten::add(%1695, %1693, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.ffn.2/__module.encoder.layer.7.ffn.2.output/__module.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1697 : __torch__.torch.nn.modules.linear.___torch_mangle_26881.Linear = prim::GetAttr[name="dense"](%1534)
  %1698 : Tensor = prim::GetAttr[name="bias"](%1697)
  %1699 : Tensor = prim::GetAttr[name="weight"](%1697)
  %1700 : Float(128:1, 512:128) = aten::t(%1699), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate/__module.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %output.119 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.154, %1700), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate/__module.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %input.155 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.119, %1698, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate/__module.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1678:0
  %input.156 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.155), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.intermediate # torch/nn/functional.py:1119:0
  %1704 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26888.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1533)
  %1705 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26884.NoNorm = prim::GetAttr[name="LayerNorm"](%1533)
  %1706 : __torch__.torch.nn.modules.linear.___torch_mangle_26883.Linear = prim::GetAttr[name="dense"](%1533)
  %1707 : Tensor = prim::GetAttr[name="bias"](%1706)
  %1708 : Tensor = prim::GetAttr[name="weight"](%1706)
  %1709 : Float(512:1, 128:512) = aten::t(%1708), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %output.120 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.156, %1709), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %layer_output.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.120, %1707, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.64 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.8, %input.154, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output # transformers/modeling_mobilebert.py:405:0
  %1713 : Tensor = prim::GetAttr[name="bias"](%1705)
  %1714 : Tensor = prim::GetAttr[name="weight"](%1705)
  %1715 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.64, %1714), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.157 : Float(17:1664, 13:128, 128:1) = aten::add(%1715, %1713, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1717 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26886.NoNorm = prim::GetAttr[name="LayerNorm"](%1704)
  %1718 : __torch__.torch.nn.modules.linear.___torch_mangle_26885.Linear = prim::GetAttr[name="dense"](%1704)
  %1719 : Tensor = prim::GetAttr[name="bias"](%1718)
  %1720 : Tensor = prim::GetAttr[name="weight"](%1718)
  %1721 : Float(128:1, 512:128) = aten::t(%1720), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.bottleneck/__module.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.121 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.157, %1721), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.bottleneck/__module.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.158 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.121, %1719, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.bottleneck/__module.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.40 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.158, %105, %102), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.bottleneck/__module.encoder.layer.7.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.65 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.40, %input.140, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1726 : Tensor = prim::GetAttr[name="bias"](%1717)
  %1727 : Tensor = prim::GetAttr[name="weight"](%1717)
  %1728 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.65, %1727), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.bottleneck/__module.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.159 : Float(17:6656, 13:512, 512:1) = aten::add(%1728, %1726, %92), scope: __module.encoder/__module.encoder.layer.7/__module.encoder.layer.7.output/__module.encoder.layer.7.output.bottleneck/__module.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1730 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26934.MobileBertOutput = prim::GetAttr[name="output"](%137)
  %1731 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26927.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%137)
  %1732 : __torch__.torch.nn.modules.container.___torch_mangle_26960.ModuleList = prim::GetAttr[name="ffn"](%137)
  %1733 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26959.FFNLayer = prim::GetAttr[name="2"](%1732)
  %1734 : __torch__.torch.nn.modules.container.___torch_mangle_26960.ModuleList = prim::GetAttr[name="ffn"](%137)
  %1735 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26953.FFNLayer = prim::GetAttr[name="1"](%1734)
  %1736 : __torch__.torch.nn.modules.container.___torch_mangle_26960.ModuleList = prim::GetAttr[name="ffn"](%137)
  %1737 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26947.FFNLayer = prim::GetAttr[name="0"](%1736)
  %1738 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26925.MobileBertAttention = prim::GetAttr[name="attention"](%137)
  %1739 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26941.Bottleneck = prim::GetAttr[name="bottleneck"](%137)
  %1740 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26940.BottleneckLayer = prim::GetAttr[name="attention"](%1739)
  %1741 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26937.BottleneckLayer = prim::GetAttr[name="input"](%1739)
  %1742 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26936.NoNorm = prim::GetAttr[name="LayerNorm"](%1741)
  %1743 : __torch__.torch.nn.modules.linear.___torch_mangle_26935.Linear = prim::GetAttr[name="dense"](%1741)
  %1744 : Tensor = prim::GetAttr[name="bias"](%1743)
  %1745 : Tensor = prim::GetAttr[name="weight"](%1743)
  %1746 : Float(512:1, 128:512) = aten::t(%1745), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.input/__module.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.122 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1746), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.input/__module.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.122, %1744, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.input/__module.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1749 : Tensor = prim::GetAttr[name="bias"](%1742)
  %1750 : Tensor = prim::GetAttr[name="weight"](%1742)
  %1751 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.66, %1750), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.input/__module.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.9 : Float(17:1664, 13:128, 128:1) = aten::add(%1751, %1749, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.input/__module.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1753 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26939.NoNorm = prim::GetAttr[name="LayerNorm"](%1740)
  %1754 : __torch__.torch.nn.modules.linear.___torch_mangle_26938.Linear = prim::GetAttr[name="dense"](%1740)
  %1755 : Tensor = prim::GetAttr[name="bias"](%1754)
  %1756 : Tensor = prim::GetAttr[name="weight"](%1754)
  %1757 : Float(512:1, 128:512) = aten::t(%1756), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.attention/__module.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.123 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1757), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.attention/__module.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.123, %1755, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.attention/__module.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1760 : Tensor = prim::GetAttr[name="bias"](%1753)
  %1761 : Tensor = prim::GetAttr[name="weight"](%1753)
  %1762 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.67, %1761), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.attention/__module.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.160 : Float(17:1664, 13:128, 128:1) = aten::add(%1762, %1760, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.bottleneck/__module.encoder.layer.8.bottleneck.attention/__module.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1764 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.160, %residual_tensor.9)
  %1765 : Float(17:1664, 13:128, 128:1), %1766 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1764)
  %1767 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26924.MobileBertSelfOutput = prim::GetAttr[name="output"](%1738)
  %1768 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26921.MobileBertSelfAttention = prim::GetAttr[name="self"](%1738)
  %1769 : __torch__.torch.nn.modules.linear.___torch_mangle_26919.Linear = prim::GetAttr[name="value"](%1768)
  %1770 : __torch__.torch.nn.modules.linear.___torch_mangle_26918.Linear = prim::GetAttr[name="key"](%1768)
  %1771 : __torch__.torch.nn.modules.linear.___torch_mangle_26917.Linear = prim::GetAttr[name="query"](%1768)
  %1772 : Tensor = prim::GetAttr[name="bias"](%1771)
  %1773 : Tensor = prim::GetAttr[name="weight"](%1771)
  %1774 : Float(128:1, 128:128) = aten::t(%1773), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %output.124 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1765, %1774), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %x.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.124, %1772, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.query # torch/nn/functional.py:1678:0
  %1777 : Tensor = prim::GetAttr[name="bias"](%1770)
  %1778 : Tensor = prim::GetAttr[name="weight"](%1770)
  %1779 : Float(128:1, 128:128) = aten::t(%1778), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %output.125 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1765, %1779), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %x.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.125, %1777, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.key # torch/nn/functional.py:1678:0
  %1782 : Tensor = prim::GetAttr[name="bias"](%1769)
  %1783 : Tensor = prim::GetAttr[name="weight"](%1769)
  %1784 : Float(512:1, 128:512) = aten::t(%1783), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %output.126 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1784), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %x.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.126, %1782, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.value # torch/nn/functional.py:1678:0
  %1787 : int = aten::size(%x.49, %93), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1788 : int = aten::size(%x.49, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1789 : int[] = prim::ListConstruct(%1787, %1788, %94, %95), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %x.50 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.49, %1789), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1791 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %query_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.50, %1791), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1793 : int = aten::size(%x.51, %93), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1794 : int = aten::size(%x.51, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1795 : int[] = prim::ListConstruct(%1793, %1794, %94, %95), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %x.52 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.51, %1795), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1797 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %key_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.52, %1797), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1799 : int = aten::size(%x.53, %93), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1800 : int = aten::size(%x.53, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1801 : int[] = prim::ListConstruct(%1799, %1800, %94, %95), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %x.54 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.53, %1801), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1803 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %value_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.54, %1803), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1805 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.9, %98, %99), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.9, %1805), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.17, %100), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.161 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.18, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.162 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.161, %98, %101), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.162, %103, %102), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self/__module.encoder.layer.8.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.17 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.9, %value_layer.9), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:280:0
  %1812 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %1813 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.17, %1812), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1813, %93), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %1815 : int = aten::size(%context_layer.18, %93), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1816 : int = aten::size(%context_layer.18, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1817 : int[] = prim::ListConstruct(%1815, %1816, %104), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self
  %input.163 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.18, %1817), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:283:0
  %1819 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26923.NoNorm = prim::GetAttr[name="LayerNorm"](%1767)
  %1820 : __torch__.torch.nn.modules.linear.___torch_mangle_26922.Linear = prim::GetAttr[name="dense"](%1767)
  %1821 : Tensor = prim::GetAttr[name="bias"](%1820)
  %1822 : Tensor = prim::GetAttr[name="weight"](%1820)
  %1823 : Float(128:1, 128:128) = aten::t(%1822), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %output.127 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.163, %1823), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.127, %1821, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.68 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.41, %1766, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output # transformers/modeling_mobilebert.py:301:0
  %1827 : Tensor = prim::GetAttr[name="bias"](%1819)
  %1828 : Tensor = prim::GetAttr[name="weight"](%1819)
  %1829 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.68, %1828), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.164 : Float(17:1664, 13:128, 128:1) = aten::add(%1829, %1827, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.attention/__module.encoder.layer.8.attention.output/__module.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1831 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26946.FFNOutput = prim::GetAttr[name="output"](%1737)
  %1832 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26943.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1737)
  %1833 : __torch__.torch.nn.modules.linear.___torch_mangle_26942.Linear = prim::GetAttr[name="dense"](%1832)
  %1834 : Tensor = prim::GetAttr[name="bias"](%1833)
  %1835 : Tensor = prim::GetAttr[name="weight"](%1833)
  %1836 : Float(128:1, 512:128) = aten::t(%1835), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.intermediate/__module.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.128 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.164, %1836), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.intermediate/__module.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.165 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.128, %1834, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.intermediate/__module.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.166 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.165), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1840 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26945.NoNorm = prim::GetAttr[name="LayerNorm"](%1831)
  %1841 : __torch__.torch.nn.modules.linear.___torch_mangle_26944.Linear = prim::GetAttr[name="dense"](%1831)
  %1842 : Tensor = prim::GetAttr[name="bias"](%1841)
  %1843 : Tensor = prim::GetAttr[name="weight"](%1841)
  %1844 : Float(512:1, 128:512) = aten::t(%1843), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.output/__module.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.129 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.166, %1844), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.output/__module.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.129, %1842, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.output/__module.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.69 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.42, %input.164, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1848 : Tensor = prim::GetAttr[name="bias"](%1840)
  %1849 : Tensor = prim::GetAttr[name="weight"](%1840)
  %1850 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.69, %1849), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.output/__module.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.167 : Float(17:1664, 13:128, 128:1) = aten::add(%1850, %1848, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.0/__module.encoder.layer.8.ffn.0.output/__module.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1852 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26952.FFNOutput = prim::GetAttr[name="output"](%1735)
  %1853 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26949.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1735)
  %1854 : __torch__.torch.nn.modules.linear.___torch_mangle_26948.Linear = prim::GetAttr[name="dense"](%1853)
  %1855 : Tensor = prim::GetAttr[name="bias"](%1854)
  %1856 : Tensor = prim::GetAttr[name="weight"](%1854)
  %1857 : Float(128:1, 512:128) = aten::t(%1856), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.intermediate/__module.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.130 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.167, %1857), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.intermediate/__module.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.168 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.130, %1855, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.intermediate/__module.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.169 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.168), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1861 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26951.NoNorm = prim::GetAttr[name="LayerNorm"](%1852)
  %1862 : __torch__.torch.nn.modules.linear.___torch_mangle_26950.Linear = prim::GetAttr[name="dense"](%1852)
  %1863 : Tensor = prim::GetAttr[name="bias"](%1862)
  %1864 : Tensor = prim::GetAttr[name="weight"](%1862)
  %1865 : Float(512:1, 128:512) = aten::t(%1864), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.output/__module.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.131 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.169, %1865), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.output/__module.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.131, %1863, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.output/__module.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.70 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.43, %input.167, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1869 : Tensor = prim::GetAttr[name="bias"](%1861)
  %1870 : Tensor = prim::GetAttr[name="weight"](%1861)
  %1871 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.70, %1870), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.output/__module.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.170 : Float(17:1664, 13:128, 128:1) = aten::add(%1871, %1869, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.1/__module.encoder.layer.8.ffn.1.output/__module.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1873 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26958.FFNOutput = prim::GetAttr[name="output"](%1733)
  %1874 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26955.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1733)
  %1875 : __torch__.torch.nn.modules.linear.___torch_mangle_26954.Linear = prim::GetAttr[name="dense"](%1874)
  %1876 : Tensor = prim::GetAttr[name="bias"](%1875)
  %1877 : Tensor = prim::GetAttr[name="weight"](%1875)
  %1878 : Float(128:1, 512:128) = aten::t(%1877), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.intermediate/__module.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.132 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.170, %1878), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.intermediate/__module.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.171 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.132, %1876, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.intermediate/__module.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.172 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.171), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1882 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26957.NoNorm = prim::GetAttr[name="LayerNorm"](%1873)
  %1883 : __torch__.torch.nn.modules.linear.___torch_mangle_26956.Linear = prim::GetAttr[name="dense"](%1873)
  %1884 : Tensor = prim::GetAttr[name="bias"](%1883)
  %1885 : Tensor = prim::GetAttr[name="weight"](%1883)
  %1886 : Float(512:1, 128:512) = aten::t(%1885), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.output/__module.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.133 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.172, %1886), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.output/__module.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.44 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.133, %1884, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.output/__module.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.71 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.44, %input.170, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1890 : Tensor = prim::GetAttr[name="bias"](%1882)
  %1891 : Tensor = prim::GetAttr[name="weight"](%1882)
  %1892 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.71, %1891), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.output/__module.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.173 : Float(17:1664, 13:128, 128:1) = aten::add(%1892, %1890, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.ffn.2/__module.encoder.layer.8.ffn.2.output/__module.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1894 : __torch__.torch.nn.modules.linear.___torch_mangle_26926.Linear = prim::GetAttr[name="dense"](%1731)
  %1895 : Tensor = prim::GetAttr[name="bias"](%1894)
  %1896 : Tensor = prim::GetAttr[name="weight"](%1894)
  %1897 : Float(128:1, 512:128) = aten::t(%1896), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate/__module.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %output.134 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.173, %1897), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate/__module.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %input.174 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.134, %1895, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate/__module.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1678:0
  %input.175 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.174), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.intermediate # torch/nn/functional.py:1119:0
  %1901 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26933.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1730)
  %1902 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26929.NoNorm = prim::GetAttr[name="LayerNorm"](%1730)
  %1903 : __torch__.torch.nn.modules.linear.___torch_mangle_26928.Linear = prim::GetAttr[name="dense"](%1730)
  %1904 : Tensor = prim::GetAttr[name="bias"](%1903)
  %1905 : Tensor = prim::GetAttr[name="weight"](%1903)
  %1906 : Float(512:1, 128:512) = aten::t(%1905), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %output.135 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.175, %1906), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %layer_output.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.135, %1904, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.72 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.9, %input.173, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output # transformers/modeling_mobilebert.py:405:0
  %1910 : Tensor = prim::GetAttr[name="bias"](%1902)
  %1911 : Tensor = prim::GetAttr[name="weight"](%1902)
  %1912 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.72, %1911), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.176 : Float(17:1664, 13:128, 128:1) = aten::add(%1912, %1910, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1914 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26931.NoNorm = prim::GetAttr[name="LayerNorm"](%1901)
  %1915 : __torch__.torch.nn.modules.linear.___torch_mangle_26930.Linear = prim::GetAttr[name="dense"](%1901)
  %1916 : Tensor = prim::GetAttr[name="bias"](%1915)
  %1917 : Tensor = prim::GetAttr[name="weight"](%1915)
  %1918 : Float(128:1, 512:128) = aten::t(%1917), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.bottleneck/__module.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.136 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.176, %1918), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.bottleneck/__module.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.177 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.136, %1916, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.bottleneck/__module.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.45 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.177, %105, %102), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.bottleneck/__module.encoder.layer.8.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.73 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.45, %input.159, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1923 : Tensor = prim::GetAttr[name="bias"](%1914)
  %1924 : Tensor = prim::GetAttr[name="weight"](%1914)
  %1925 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.73, %1924), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.bottleneck/__module.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.178 : Float(17:6656, 13:512, 512:1) = aten::add(%1925, %1923, %92), scope: __module.encoder/__module.encoder.layer.8/__module.encoder.layer.8.output/__module.encoder.layer.8.output.bottleneck/__module.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1927 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26979.MobileBertOutput = prim::GetAttr[name="output"](%135)
  %1928 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26972.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%135)
  %1929 : __torch__.torch.nn.modules.container.___torch_mangle_27005.ModuleList = prim::GetAttr[name="ffn"](%135)
  %1930 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27004.FFNLayer = prim::GetAttr[name="2"](%1929)
  %1931 : __torch__.torch.nn.modules.container.___torch_mangle_27005.ModuleList = prim::GetAttr[name="ffn"](%135)
  %1932 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26998.FFNLayer = prim::GetAttr[name="1"](%1931)
  %1933 : __torch__.torch.nn.modules.container.___torch_mangle_27005.ModuleList = prim::GetAttr[name="ffn"](%135)
  %1934 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26992.FFNLayer = prim::GetAttr[name="0"](%1933)
  %1935 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26970.MobileBertAttention = prim::GetAttr[name="attention"](%135)
  %1936 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26986.Bottleneck = prim::GetAttr[name="bottleneck"](%135)
  %1937 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26985.BottleneckLayer = prim::GetAttr[name="attention"](%1936)
  %1938 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26982.BottleneckLayer = prim::GetAttr[name="input"](%1936)
  %1939 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26981.NoNorm = prim::GetAttr[name="LayerNorm"](%1938)
  %1940 : __torch__.torch.nn.modules.linear.___torch_mangle_26980.Linear = prim::GetAttr[name="dense"](%1938)
  %1941 : Tensor = prim::GetAttr[name="bias"](%1940)
  %1942 : Tensor = prim::GetAttr[name="weight"](%1940)
  %1943 : Float(512:1, 128:512) = aten::t(%1942), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.input/__module.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.137 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1943), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.input/__module.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.137, %1941, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.input/__module.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1946 : Tensor = prim::GetAttr[name="bias"](%1939)
  %1947 : Tensor = prim::GetAttr[name="weight"](%1939)
  %1948 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.74, %1947), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.input/__module.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add(%1948, %1946, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.input/__module.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1950 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26984.NoNorm = prim::GetAttr[name="LayerNorm"](%1937)
  %1951 : __torch__.torch.nn.modules.linear.___torch_mangle_26983.Linear = prim::GetAttr[name="dense"](%1937)
  %1952 : Tensor = prim::GetAttr[name="bias"](%1951)
  %1953 : Tensor = prim::GetAttr[name="weight"](%1951)
  %1954 : Float(512:1, 128:512) = aten::t(%1953), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.attention/__module.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.138 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1954), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.attention/__module.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.138, %1952, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.attention/__module.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1957 : Tensor = prim::GetAttr[name="bias"](%1950)
  %1958 : Tensor = prim::GetAttr[name="weight"](%1950)
  %1959 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.75, %1958), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.attention/__module.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.179 : Float(17:1664, 13:128, 128:1) = aten::add(%1959, %1957, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.bottleneck/__module.encoder.layer.9.bottleneck.attention/__module.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1961 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.179, %residual_tensor.10)
  %1962 : Float(17:1664, 13:128, 128:1), %1963 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1961)
  %1964 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26969.MobileBertSelfOutput = prim::GetAttr[name="output"](%1935)
  %1965 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26966.MobileBertSelfAttention = prim::GetAttr[name="self"](%1935)
  %1966 : __torch__.torch.nn.modules.linear.___torch_mangle_26964.Linear = prim::GetAttr[name="value"](%1965)
  %1967 : __torch__.torch.nn.modules.linear.___torch_mangle_26963.Linear = prim::GetAttr[name="key"](%1965)
  %1968 : __torch__.torch.nn.modules.linear.___torch_mangle_26962.Linear = prim::GetAttr[name="query"](%1965)
  %1969 : Tensor = prim::GetAttr[name="bias"](%1968)
  %1970 : Tensor = prim::GetAttr[name="weight"](%1968)
  %1971 : Float(128:1, 128:128) = aten::t(%1970), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %output.139 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1962, %1971), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %x.55 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.139, %1969, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.query # torch/nn/functional.py:1678:0
  %1974 : Tensor = prim::GetAttr[name="bias"](%1967)
  %1975 : Tensor = prim::GetAttr[name="weight"](%1967)
  %1976 : Float(128:1, 128:128) = aten::t(%1975), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %output.140 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1962, %1976), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %x.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.140, %1974, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.key # torch/nn/functional.py:1678:0
  %1979 : Tensor = prim::GetAttr[name="bias"](%1966)
  %1980 : Tensor = prim::GetAttr[name="weight"](%1966)
  %1981 : Float(512:1, 128:512) = aten::t(%1980), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %output.141 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1981), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %x.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.141, %1979, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.value # torch/nn/functional.py:1678:0
  %1984 : int = aten::size(%x.55, %93), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1985 : int = aten::size(%x.55, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1986 : int[] = prim::ListConstruct(%1984, %1985, %94, %95), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %x.56 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.55, %1986), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1988 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %query_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.56, %1988), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1990 : int = aten::size(%x.57, %93), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1991 : int = aten::size(%x.57, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1992 : int[] = prim::ListConstruct(%1990, %1991, %94, %95), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %x.58 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.57, %1992), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1994 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %key_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.58, %1994), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1996 : int = aten::size(%x.59, %93), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1997 : int = aten::size(%x.59, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1998 : int[] = prim::ListConstruct(%1996, %1997, %94, %95), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %x.60 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.59, %1998), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %2000 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %value_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.60, %2000), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %2002 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.10, %98, %99), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.10, %2002), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.19, %100), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.180 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.20, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.181 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.180, %98, %101), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.181, %103, %102), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self/__module.encoder.layer.9.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.19 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.10, %value_layer.10), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:280:0
  %2009 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %2010 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.19, %2009), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2010, %93), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %2012 : int = aten::size(%context_layer.20, %93), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %2013 : int = aten::size(%context_layer.20, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %2014 : int[] = prim::ListConstruct(%2012, %2013, %104), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self
  %input.182 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.20, %2014), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:283:0
  %2016 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26968.NoNorm = prim::GetAttr[name="LayerNorm"](%1964)
  %2017 : __torch__.torch.nn.modules.linear.___torch_mangle_26967.Linear = prim::GetAttr[name="dense"](%1964)
  %2018 : Tensor = prim::GetAttr[name="bias"](%2017)
  %2019 : Tensor = prim::GetAttr[name="weight"](%2017)
  %2020 : Float(128:1, 128:128) = aten::t(%2019), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %output.142 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.182, %2020), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.46 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.142, %2018, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.76 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.46, %1963, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output # transformers/modeling_mobilebert.py:301:0
  %2024 : Tensor = prim::GetAttr[name="bias"](%2016)
  %2025 : Tensor = prim::GetAttr[name="weight"](%2016)
  %2026 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.76, %2025), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.183 : Float(17:1664, 13:128, 128:1) = aten::add(%2026, %2024, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.attention/__module.encoder.layer.9.attention.output/__module.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2028 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26991.FFNOutput = prim::GetAttr[name="output"](%1934)
  %2029 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26988.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1934)
  %2030 : __torch__.torch.nn.modules.linear.___torch_mangle_26987.Linear = prim::GetAttr[name="dense"](%2029)
  %2031 : Tensor = prim::GetAttr[name="bias"](%2030)
  %2032 : Tensor = prim::GetAttr[name="weight"](%2030)
  %2033 : Float(128:1, 512:128) = aten::t(%2032), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.intermediate/__module.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.143 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.183, %2033), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.intermediate/__module.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.184 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.143, %2031, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.intermediate/__module.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.185 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.184), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2037 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26990.NoNorm = prim::GetAttr[name="LayerNorm"](%2028)
  %2038 : __torch__.torch.nn.modules.linear.___torch_mangle_26989.Linear = prim::GetAttr[name="dense"](%2028)
  %2039 : Tensor = prim::GetAttr[name="bias"](%2038)
  %2040 : Tensor = prim::GetAttr[name="weight"](%2038)
  %2041 : Float(512:1, 128:512) = aten::t(%2040), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.output/__module.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.144 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.185, %2041), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.output/__module.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.144, %2039, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.output/__module.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.77 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.47, %input.183, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2045 : Tensor = prim::GetAttr[name="bias"](%2037)
  %2046 : Tensor = prim::GetAttr[name="weight"](%2037)
  %2047 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.77, %2046), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.output/__module.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.186 : Float(17:1664, 13:128, 128:1) = aten::add(%2047, %2045, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.0/__module.encoder.layer.9.ffn.0.output/__module.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2049 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26997.FFNOutput = prim::GetAttr[name="output"](%1932)
  %2050 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26994.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1932)
  %2051 : __torch__.torch.nn.modules.linear.___torch_mangle_26993.Linear = prim::GetAttr[name="dense"](%2050)
  %2052 : Tensor = prim::GetAttr[name="bias"](%2051)
  %2053 : Tensor = prim::GetAttr[name="weight"](%2051)
  %2054 : Float(128:1, 512:128) = aten::t(%2053), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.intermediate/__module.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.145 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.186, %2054), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.intermediate/__module.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.187 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.145, %2052, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.intermediate/__module.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.188 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.187), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2058 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26996.NoNorm = prim::GetAttr[name="LayerNorm"](%2049)
  %2059 : __torch__.torch.nn.modules.linear.___torch_mangle_26995.Linear = prim::GetAttr[name="dense"](%2049)
  %2060 : Tensor = prim::GetAttr[name="bias"](%2059)
  %2061 : Tensor = prim::GetAttr[name="weight"](%2059)
  %2062 : Float(512:1, 128:512) = aten::t(%2061), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.output/__module.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.146 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.188, %2062), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.output/__module.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.48 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.146, %2060, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.output/__module.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.78 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.48, %input.186, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2066 : Tensor = prim::GetAttr[name="bias"](%2058)
  %2067 : Tensor = prim::GetAttr[name="weight"](%2058)
  %2068 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.78, %2067), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.output/__module.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.189 : Float(17:1664, 13:128, 128:1) = aten::add(%2068, %2066, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.1/__module.encoder.layer.9.ffn.1.output/__module.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2070 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27003.FFNOutput = prim::GetAttr[name="output"](%1930)
  %2071 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27000.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1930)
  %2072 : __torch__.torch.nn.modules.linear.___torch_mangle_26999.Linear = prim::GetAttr[name="dense"](%2071)
  %2073 : Tensor = prim::GetAttr[name="bias"](%2072)
  %2074 : Tensor = prim::GetAttr[name="weight"](%2072)
  %2075 : Float(128:1, 512:128) = aten::t(%2074), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.intermediate/__module.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.147 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.189, %2075), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.intermediate/__module.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.190 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.147, %2073, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.intermediate/__module.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.191 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.190), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2079 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27002.NoNorm = prim::GetAttr[name="LayerNorm"](%2070)
  %2080 : __torch__.torch.nn.modules.linear.___torch_mangle_27001.Linear = prim::GetAttr[name="dense"](%2070)
  %2081 : Tensor = prim::GetAttr[name="bias"](%2080)
  %2082 : Tensor = prim::GetAttr[name="weight"](%2080)
  %2083 : Float(512:1, 128:512) = aten::t(%2082), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.output/__module.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.148 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.191, %2083), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.output/__module.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.148, %2081, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.output/__module.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.79 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.49, %input.189, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2087 : Tensor = prim::GetAttr[name="bias"](%2079)
  %2088 : Tensor = prim::GetAttr[name="weight"](%2079)
  %2089 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.79, %2088), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.output/__module.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.192 : Float(17:1664, 13:128, 128:1) = aten::add(%2089, %2087, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.ffn.2/__module.encoder.layer.9.ffn.2.output/__module.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2091 : __torch__.torch.nn.modules.linear.___torch_mangle_26971.Linear = prim::GetAttr[name="dense"](%1928)
  %2092 : Tensor = prim::GetAttr[name="bias"](%2091)
  %2093 : Tensor = prim::GetAttr[name="weight"](%2091)
  %2094 : Float(128:1, 512:128) = aten::t(%2093), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate/__module.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %output.149 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.192, %2094), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate/__module.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %input.193 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.149, %2092, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate/__module.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1678:0
  %input.194 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.193), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.intermediate # torch/nn/functional.py:1119:0
  %2098 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26978.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1927)
  %2099 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26974.NoNorm = prim::GetAttr[name="LayerNorm"](%1927)
  %2100 : __torch__.torch.nn.modules.linear.___torch_mangle_26973.Linear = prim::GetAttr[name="dense"](%1927)
  %2101 : Tensor = prim::GetAttr[name="bias"](%2100)
  %2102 : Tensor = prim::GetAttr[name="weight"](%2100)
  %2103 : Float(512:1, 128:512) = aten::t(%2102), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %output.150 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.194, %2103), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %layer_output.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.150, %2101, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.80 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.10, %input.192, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output # transformers/modeling_mobilebert.py:405:0
  %2107 : Tensor = prim::GetAttr[name="bias"](%2099)
  %2108 : Tensor = prim::GetAttr[name="weight"](%2099)
  %2109 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.80, %2108), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.195 : Float(17:1664, 13:128, 128:1) = aten::add(%2109, %2107, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_26976.NoNorm = prim::GetAttr[name="LayerNorm"](%2098)
  %2112 : __torch__.torch.nn.modules.linear.___torch_mangle_26975.Linear = prim::GetAttr[name="dense"](%2098)
  %2113 : Tensor = prim::GetAttr[name="bias"](%2112)
  %2114 : Tensor = prim::GetAttr[name="weight"](%2112)
  %2115 : Float(128:1, 512:128) = aten::t(%2114), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.bottleneck/__module.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.151 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.195, %2115), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.bottleneck/__module.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.196 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.151, %2113, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.bottleneck/__module.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.50 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.196, %105, %102), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.bottleneck/__module.encoder.layer.9.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.81 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.50, %input.178, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2120 : Tensor = prim::GetAttr[name="bias"](%2111)
  %2121 : Tensor = prim::GetAttr[name="weight"](%2111)
  %2122 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.81, %2121), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.bottleneck/__module.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.197 : Float(17:6656, 13:512, 512:1) = aten::add(%2122, %2120, %92), scope: __module.encoder/__module.encoder.layer.9/__module.encoder.layer.9.output/__module.encoder.layer.9.output.bottleneck/__module.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2124 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27024.MobileBertOutput = prim::GetAttr[name="output"](%133)
  %2125 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27017.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%133)
  %2126 : __torch__.torch.nn.modules.container.___torch_mangle_27050.ModuleList = prim::GetAttr[name="ffn"](%133)
  %2127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27049.FFNLayer = prim::GetAttr[name="2"](%2126)
  %2128 : __torch__.torch.nn.modules.container.___torch_mangle_27050.ModuleList = prim::GetAttr[name="ffn"](%133)
  %2129 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27043.FFNLayer = prim::GetAttr[name="1"](%2128)
  %2130 : __torch__.torch.nn.modules.container.___torch_mangle_27050.ModuleList = prim::GetAttr[name="ffn"](%133)
  %2131 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27037.FFNLayer = prim::GetAttr[name="0"](%2130)
  %2132 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27015.MobileBertAttention = prim::GetAttr[name="attention"](%133)
  %2133 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27031.Bottleneck = prim::GetAttr[name="bottleneck"](%133)
  %2134 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27030.BottleneckLayer = prim::GetAttr[name="attention"](%2133)
  %2135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27027.BottleneckLayer = prim::GetAttr[name="input"](%2133)
  %2136 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27026.NoNorm = prim::GetAttr[name="LayerNorm"](%2135)
  %2137 : __torch__.torch.nn.modules.linear.___torch_mangle_27025.Linear = prim::GetAttr[name="dense"](%2135)
  %2138 : Tensor = prim::GetAttr[name="bias"](%2137)
  %2139 : Tensor = prim::GetAttr[name="weight"](%2137)
  %2140 : Float(512:1, 128:512) = aten::t(%2139), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.input/__module.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.152 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2140), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.input/__module.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.152, %2138, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.input/__module.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2143 : Tensor = prim::GetAttr[name="bias"](%2136)
  %2144 : Tensor = prim::GetAttr[name="weight"](%2136)
  %2145 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.82, %2144), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.input/__module.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add(%2145, %2143, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.input/__module.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2147 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27029.NoNorm = prim::GetAttr[name="LayerNorm"](%2134)
  %2148 : __torch__.torch.nn.modules.linear.___torch_mangle_27028.Linear = prim::GetAttr[name="dense"](%2134)
  %2149 : Tensor = prim::GetAttr[name="bias"](%2148)
  %2150 : Tensor = prim::GetAttr[name="weight"](%2148)
  %2151 : Float(512:1, 128:512) = aten::t(%2150), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.attention/__module.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.153 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2151), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.attention/__module.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.153, %2149, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.attention/__module.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2154 : Tensor = prim::GetAttr[name="bias"](%2147)
  %2155 : Tensor = prim::GetAttr[name="weight"](%2147)
  %2156 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.83, %2155), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.attention/__module.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.198 : Float(17:1664, 13:128, 128:1) = aten::add(%2156, %2154, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.bottleneck/__module.encoder.layer.10.bottleneck.attention/__module.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2158 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.198, %residual_tensor.11)
  %2159 : Float(17:1664, 13:128, 128:1), %2160 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2158)
  %2161 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27014.MobileBertSelfOutput = prim::GetAttr[name="output"](%2132)
  %2162 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27011.MobileBertSelfAttention = prim::GetAttr[name="self"](%2132)
  %2163 : __torch__.torch.nn.modules.linear.___torch_mangle_27009.Linear = prim::GetAttr[name="value"](%2162)
  %2164 : __torch__.torch.nn.modules.linear.___torch_mangle_27008.Linear = prim::GetAttr[name="key"](%2162)
  %2165 : __torch__.torch.nn.modules.linear.___torch_mangle_27007.Linear = prim::GetAttr[name="query"](%2162)
  %2166 : Tensor = prim::GetAttr[name="bias"](%2165)
  %2167 : Tensor = prim::GetAttr[name="weight"](%2165)
  %2168 : Float(128:1, 128:128) = aten::t(%2167), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %output.154 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2159, %2168), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %x.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.154, %2166, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.query # torch/nn/functional.py:1678:0
  %2171 : Tensor = prim::GetAttr[name="bias"](%2164)
  %2172 : Tensor = prim::GetAttr[name="weight"](%2164)
  %2173 : Float(128:1, 128:128) = aten::t(%2172), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %output.155 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2159, %2173), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %x.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.155, %2171, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.key # torch/nn/functional.py:1678:0
  %2176 : Tensor = prim::GetAttr[name="bias"](%2163)
  %2177 : Tensor = prim::GetAttr[name="weight"](%2163)
  %2178 : Float(512:1, 128:512) = aten::t(%2177), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %output.156 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2178), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %x.65 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.156, %2176, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.value # torch/nn/functional.py:1678:0
  %2181 : int = aten::size(%x.61, %93), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2182 : int = aten::size(%x.61, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2183 : int[] = prim::ListConstruct(%2181, %2182, %94, %95), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %x.62 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.61, %2183), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2185 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %query_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.62, %2185), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2187 : int = aten::size(%x.63, %93), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2188 : int = aten::size(%x.63, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2189 : int[] = prim::ListConstruct(%2187, %2188, %94, %95), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %x.64 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.63, %2189), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2191 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %key_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.64, %2191), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2193 : int = aten::size(%x.65, %93), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2194 : int = aten::size(%x.65, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2195 : int[] = prim::ListConstruct(%2193, %2194, %94, %95), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %x.66 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.65, %2195), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2197 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %value_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.66, %2197), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2199 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.11, %98, %99), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.11, %2199), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.21, %100), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.199 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.22, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.200 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.199, %98, %101), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.200, %103, %102), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self/__module.encoder.layer.10.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.21 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.11, %value_layer.11), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:280:0
  %2206 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %2207 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.21, %2206), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2207, %93), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %2209 : int = aten::size(%context_layer.22, %93), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2210 : int = aten::size(%context_layer.22, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2211 : int[] = prim::ListConstruct(%2209, %2210, %104), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self
  %input.201 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.22, %2211), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:283:0
  %2213 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27013.NoNorm = prim::GetAttr[name="LayerNorm"](%2161)
  %2214 : __torch__.torch.nn.modules.linear.___torch_mangle_27012.Linear = prim::GetAttr[name="dense"](%2161)
  %2215 : Tensor = prim::GetAttr[name="bias"](%2214)
  %2216 : Tensor = prim::GetAttr[name="weight"](%2214)
  %2217 : Float(128:1, 128:128) = aten::t(%2216), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %output.157 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.201, %2217), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.157, %2215, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.84 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.51, %2160, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output # transformers/modeling_mobilebert.py:301:0
  %2221 : Tensor = prim::GetAttr[name="bias"](%2213)
  %2222 : Tensor = prim::GetAttr[name="weight"](%2213)
  %2223 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.84, %2222), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.202 : Float(17:1664, 13:128, 128:1) = aten::add(%2223, %2221, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.attention/__module.encoder.layer.10.attention.output/__module.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2225 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27036.FFNOutput = prim::GetAttr[name="output"](%2131)
  %2226 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27033.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2131)
  %2227 : __torch__.torch.nn.modules.linear.___torch_mangle_27032.Linear = prim::GetAttr[name="dense"](%2226)
  %2228 : Tensor = prim::GetAttr[name="bias"](%2227)
  %2229 : Tensor = prim::GetAttr[name="weight"](%2227)
  %2230 : Float(128:1, 512:128) = aten::t(%2229), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.intermediate/__module.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.158 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.202, %2230), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.intermediate/__module.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.203 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.158, %2228, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.intermediate/__module.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.204 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.203), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2234 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27035.NoNorm = prim::GetAttr[name="LayerNorm"](%2225)
  %2235 : __torch__.torch.nn.modules.linear.___torch_mangle_27034.Linear = prim::GetAttr[name="dense"](%2225)
  %2236 : Tensor = prim::GetAttr[name="bias"](%2235)
  %2237 : Tensor = prim::GetAttr[name="weight"](%2235)
  %2238 : Float(512:1, 128:512) = aten::t(%2237), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.output/__module.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.159 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.204, %2238), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.output/__module.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.52 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.159, %2236, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.output/__module.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.85 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.52, %input.202, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2242 : Tensor = prim::GetAttr[name="bias"](%2234)
  %2243 : Tensor = prim::GetAttr[name="weight"](%2234)
  %2244 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.85, %2243), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.output/__module.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.205 : Float(17:1664, 13:128, 128:1) = aten::add(%2244, %2242, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.0/__module.encoder.layer.10.ffn.0.output/__module.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2246 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27042.FFNOutput = prim::GetAttr[name="output"](%2129)
  %2247 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27039.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2129)
  %2248 : __torch__.torch.nn.modules.linear.___torch_mangle_27038.Linear = prim::GetAttr[name="dense"](%2247)
  %2249 : Tensor = prim::GetAttr[name="bias"](%2248)
  %2250 : Tensor = prim::GetAttr[name="weight"](%2248)
  %2251 : Float(128:1, 512:128) = aten::t(%2250), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.intermediate/__module.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.160 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.205, %2251), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.intermediate/__module.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.206 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.160, %2249, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.intermediate/__module.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.207 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.206), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2255 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27041.NoNorm = prim::GetAttr[name="LayerNorm"](%2246)
  %2256 : __torch__.torch.nn.modules.linear.___torch_mangle_27040.Linear = prim::GetAttr[name="dense"](%2246)
  %2257 : Tensor = prim::GetAttr[name="bias"](%2256)
  %2258 : Tensor = prim::GetAttr[name="weight"](%2256)
  %2259 : Float(512:1, 128:512) = aten::t(%2258), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.output/__module.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.161 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.207, %2259), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.output/__module.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.161, %2257, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.output/__module.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.86 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.53, %input.205, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2263 : Tensor = prim::GetAttr[name="bias"](%2255)
  %2264 : Tensor = prim::GetAttr[name="weight"](%2255)
  %2265 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.86, %2264), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.output/__module.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.208 : Float(17:1664, 13:128, 128:1) = aten::add(%2265, %2263, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.1/__module.encoder.layer.10.ffn.1.output/__module.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2267 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27048.FFNOutput = prim::GetAttr[name="output"](%2127)
  %2268 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27045.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2127)
  %2269 : __torch__.torch.nn.modules.linear.___torch_mangle_27044.Linear = prim::GetAttr[name="dense"](%2268)
  %2270 : Tensor = prim::GetAttr[name="bias"](%2269)
  %2271 : Tensor = prim::GetAttr[name="weight"](%2269)
  %2272 : Float(128:1, 512:128) = aten::t(%2271), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.intermediate/__module.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.162 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.208, %2272), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.intermediate/__module.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.209 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.162, %2270, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.intermediate/__module.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.210 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.209), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2276 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27047.NoNorm = prim::GetAttr[name="LayerNorm"](%2267)
  %2277 : __torch__.torch.nn.modules.linear.___torch_mangle_27046.Linear = prim::GetAttr[name="dense"](%2267)
  %2278 : Tensor = prim::GetAttr[name="bias"](%2277)
  %2279 : Tensor = prim::GetAttr[name="weight"](%2277)
  %2280 : Float(512:1, 128:512) = aten::t(%2279), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.output/__module.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.163 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.210, %2280), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.output/__module.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.54 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.163, %2278, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.output/__module.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.87 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.54, %input.208, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2284 : Tensor = prim::GetAttr[name="bias"](%2276)
  %2285 : Tensor = prim::GetAttr[name="weight"](%2276)
  %2286 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.87, %2285), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.output/__module.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.211 : Float(17:1664, 13:128, 128:1) = aten::add(%2286, %2284, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.ffn.2/__module.encoder.layer.10.ffn.2.output/__module.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2288 : __torch__.torch.nn.modules.linear.___torch_mangle_27016.Linear = prim::GetAttr[name="dense"](%2125)
  %2289 : Tensor = prim::GetAttr[name="bias"](%2288)
  %2290 : Tensor = prim::GetAttr[name="weight"](%2288)
  %2291 : Float(128:1, 512:128) = aten::t(%2290), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate/__module.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %output.164 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.211, %2291), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate/__module.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %input.212 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.164, %2289, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate/__module.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1678:0
  %input.213 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.212), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.intermediate # torch/nn/functional.py:1119:0
  %2295 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27023.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2124)
  %2296 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27019.NoNorm = prim::GetAttr[name="LayerNorm"](%2124)
  %2297 : __torch__.torch.nn.modules.linear.___torch_mangle_27018.Linear = prim::GetAttr[name="dense"](%2124)
  %2298 : Tensor = prim::GetAttr[name="bias"](%2297)
  %2299 : Tensor = prim::GetAttr[name="weight"](%2297)
  %2300 : Float(512:1, 128:512) = aten::t(%2299), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %output.165 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.213, %2300), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %layer_output.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.165, %2298, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.88 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.11, %input.211, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output # transformers/modeling_mobilebert.py:405:0
  %2304 : Tensor = prim::GetAttr[name="bias"](%2296)
  %2305 : Tensor = prim::GetAttr[name="weight"](%2296)
  %2306 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.88, %2305), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.214 : Float(17:1664, 13:128, 128:1) = aten::add(%2306, %2304, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2308 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27021.NoNorm = prim::GetAttr[name="LayerNorm"](%2295)
  %2309 : __torch__.torch.nn.modules.linear.___torch_mangle_27020.Linear = prim::GetAttr[name="dense"](%2295)
  %2310 : Tensor = prim::GetAttr[name="bias"](%2309)
  %2311 : Tensor = prim::GetAttr[name="weight"](%2309)
  %2312 : Float(128:1, 512:128) = aten::t(%2311), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.bottleneck/__module.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.166 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.214, %2312), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.bottleneck/__module.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.215 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.166, %2310, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.bottleneck/__module.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.55 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.215, %105, %102), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.bottleneck/__module.encoder.layer.10.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.89 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.55, %input.197, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2317 : Tensor = prim::GetAttr[name="bias"](%2308)
  %2318 : Tensor = prim::GetAttr[name="weight"](%2308)
  %2319 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.89, %2318), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.bottleneck/__module.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.216 : Float(17:6656, 13:512, 512:1) = aten::add(%2319, %2317, %92), scope: __module.encoder/__module.encoder.layer.10/__module.encoder.layer.10.output/__module.encoder.layer.10.output.bottleneck/__module.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2321 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27069.MobileBertOutput = prim::GetAttr[name="output"](%131)
  %2322 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27062.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%131)
  %2323 : __torch__.torch.nn.modules.container.___torch_mangle_27095.ModuleList = prim::GetAttr[name="ffn"](%131)
  %2324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27094.FFNLayer = prim::GetAttr[name="2"](%2323)
  %2325 : __torch__.torch.nn.modules.container.___torch_mangle_27095.ModuleList = prim::GetAttr[name="ffn"](%131)
  %2326 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27088.FFNLayer = prim::GetAttr[name="1"](%2325)
  %2327 : __torch__.torch.nn.modules.container.___torch_mangle_27095.ModuleList = prim::GetAttr[name="ffn"](%131)
  %2328 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27082.FFNLayer = prim::GetAttr[name="0"](%2327)
  %2329 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27060.MobileBertAttention = prim::GetAttr[name="attention"](%131)
  %2330 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27076.Bottleneck = prim::GetAttr[name="bottleneck"](%131)
  %2331 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27075.BottleneckLayer = prim::GetAttr[name="attention"](%2330)
  %2332 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27072.BottleneckLayer = prim::GetAttr[name="input"](%2330)
  %2333 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27071.NoNorm = prim::GetAttr[name="LayerNorm"](%2332)
  %2334 : __torch__.torch.nn.modules.linear.___torch_mangle_27070.Linear = prim::GetAttr[name="dense"](%2332)
  %2335 : Tensor = prim::GetAttr[name="bias"](%2334)
  %2336 : Tensor = prim::GetAttr[name="weight"](%2334)
  %2337 : Float(512:1, 128:512) = aten::t(%2336), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.input/__module.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.167 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2337), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.input/__module.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.90 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.167, %2335, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.input/__module.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2340 : Tensor = prim::GetAttr[name="bias"](%2333)
  %2341 : Tensor = prim::GetAttr[name="weight"](%2333)
  %2342 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.90, %2341), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.input/__module.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%2342, %2340, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.input/__module.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2344 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27074.NoNorm = prim::GetAttr[name="LayerNorm"](%2331)
  %2345 : __torch__.torch.nn.modules.linear.___torch_mangle_27073.Linear = prim::GetAttr[name="dense"](%2331)
  %2346 : Tensor = prim::GetAttr[name="bias"](%2345)
  %2347 : Tensor = prim::GetAttr[name="weight"](%2345)
  %2348 : Float(512:1, 128:512) = aten::t(%2347), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.attention/__module.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.168 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2348), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.attention/__module.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.168, %2346, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.attention/__module.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2351 : Tensor = prim::GetAttr[name="bias"](%2344)
  %2352 : Tensor = prim::GetAttr[name="weight"](%2344)
  %2353 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.91, %2352), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.attention/__module.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.217 : Float(17:1664, 13:128, 128:1) = aten::add(%2353, %2351, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.bottleneck/__module.encoder.layer.11.bottleneck.attention/__module.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2355 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.217, %residual_tensor.12)
  %2356 : Float(17:1664, 13:128, 128:1), %2357 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2355)
  %2358 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27059.MobileBertSelfOutput = prim::GetAttr[name="output"](%2329)
  %2359 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27056.MobileBertSelfAttention = prim::GetAttr[name="self"](%2329)
  %2360 : __torch__.torch.nn.modules.linear.___torch_mangle_27054.Linear = prim::GetAttr[name="value"](%2359)
  %2361 : __torch__.torch.nn.modules.linear.___torch_mangle_27053.Linear = prim::GetAttr[name="key"](%2359)
  %2362 : __torch__.torch.nn.modules.linear.___torch_mangle_27052.Linear = prim::GetAttr[name="query"](%2359)
  %2363 : Tensor = prim::GetAttr[name="bias"](%2362)
  %2364 : Tensor = prim::GetAttr[name="weight"](%2362)
  %2365 : Float(128:1, 128:128) = aten::t(%2364), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %output.169 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2356, %2365), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %x.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.169, %2363, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.query # torch/nn/functional.py:1678:0
  %2368 : Tensor = prim::GetAttr[name="bias"](%2361)
  %2369 : Tensor = prim::GetAttr[name="weight"](%2361)
  %2370 : Float(128:1, 128:128) = aten::t(%2369), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %output.170 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2356, %2370), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %x.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.170, %2368, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.key # torch/nn/functional.py:1678:0
  %2373 : Tensor = prim::GetAttr[name="bias"](%2360)
  %2374 : Tensor = prim::GetAttr[name="weight"](%2360)
  %2375 : Float(512:1, 128:512) = aten::t(%2374), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %output.171 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2375), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %x.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.171, %2373, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.value # torch/nn/functional.py:1678:0
  %2378 : int = aten::size(%x.67, %93), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2379 : int = aten::size(%x.67, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2380 : int[] = prim::ListConstruct(%2378, %2379, %94, %95), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %x.68 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.67, %2380), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2382 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %query_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.68, %2382), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2384 : int = aten::size(%x.69, %93), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2385 : int = aten::size(%x.69, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2386 : int[] = prim::ListConstruct(%2384, %2385, %94, %95), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %x.70 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.69, %2386), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2388 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %key_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.70, %2388), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2390 : int = aten::size(%x.71, %93), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2391 : int = aten::size(%x.71, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2392 : int[] = prim::ListConstruct(%2390, %2391, %94, %95), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %x.72 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.71, %2392), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2394 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %value_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.72, %2394), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2396 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.12, %98, %99), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.12, %2396), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.24 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.23, %100), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.218 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.24, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.219 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.218, %98, %101), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.219, %103, %102), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self/__module.encoder.layer.11.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.23 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.12, %value_layer.12), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:280:0
  %2403 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %2404 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.23, %2403), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2404, %93), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %2406 : int = aten::size(%context_layer.24, %93), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2407 : int = aten::size(%context_layer.24, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2408 : int[] = prim::ListConstruct(%2406, %2407, %104), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self
  %input.220 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.24, %2408), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:283:0
  %2410 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27058.NoNorm = prim::GetAttr[name="LayerNorm"](%2358)
  %2411 : __torch__.torch.nn.modules.linear.___torch_mangle_27057.Linear = prim::GetAttr[name="dense"](%2358)
  %2412 : Tensor = prim::GetAttr[name="bias"](%2411)
  %2413 : Tensor = prim::GetAttr[name="weight"](%2411)
  %2414 : Float(128:1, 128:128) = aten::t(%2413), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %output.172 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.220, %2414), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.56 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.172, %2412, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.92 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.56, %2357, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output # transformers/modeling_mobilebert.py:301:0
  %2418 : Tensor = prim::GetAttr[name="bias"](%2410)
  %2419 : Tensor = prim::GetAttr[name="weight"](%2410)
  %2420 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.92, %2419), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.221 : Float(17:1664, 13:128, 128:1) = aten::add(%2420, %2418, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.attention/__module.encoder.layer.11.attention.output/__module.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2422 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27081.FFNOutput = prim::GetAttr[name="output"](%2328)
  %2423 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27078.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2328)
  %2424 : __torch__.torch.nn.modules.linear.___torch_mangle_27077.Linear = prim::GetAttr[name="dense"](%2423)
  %2425 : Tensor = prim::GetAttr[name="bias"](%2424)
  %2426 : Tensor = prim::GetAttr[name="weight"](%2424)
  %2427 : Float(128:1, 512:128) = aten::t(%2426), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.intermediate/__module.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.173 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.221, %2427), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.intermediate/__module.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.222 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.173, %2425, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.intermediate/__module.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.223 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.222), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2431 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27080.NoNorm = prim::GetAttr[name="LayerNorm"](%2422)
  %2432 : __torch__.torch.nn.modules.linear.___torch_mangle_27079.Linear = prim::GetAttr[name="dense"](%2422)
  %2433 : Tensor = prim::GetAttr[name="bias"](%2432)
  %2434 : Tensor = prim::GetAttr[name="weight"](%2432)
  %2435 : Float(512:1, 128:512) = aten::t(%2434), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.output/__module.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.174 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.223, %2435), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.output/__module.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.174, %2433, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.output/__module.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.93 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.57, %input.221, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2439 : Tensor = prim::GetAttr[name="bias"](%2431)
  %2440 : Tensor = prim::GetAttr[name="weight"](%2431)
  %2441 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.93, %2440), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.output/__module.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.224 : Float(17:1664, 13:128, 128:1) = aten::add(%2441, %2439, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.0/__module.encoder.layer.11.ffn.0.output/__module.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2443 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27087.FFNOutput = prim::GetAttr[name="output"](%2326)
  %2444 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27084.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2326)
  %2445 : __torch__.torch.nn.modules.linear.___torch_mangle_27083.Linear = prim::GetAttr[name="dense"](%2444)
  %2446 : Tensor = prim::GetAttr[name="bias"](%2445)
  %2447 : Tensor = prim::GetAttr[name="weight"](%2445)
  %2448 : Float(128:1, 512:128) = aten::t(%2447), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.intermediate/__module.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.175 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.224, %2448), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.intermediate/__module.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.225 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.175, %2446, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.intermediate/__module.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.226 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.225), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2452 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27086.NoNorm = prim::GetAttr[name="LayerNorm"](%2443)
  %2453 : __torch__.torch.nn.modules.linear.___torch_mangle_27085.Linear = prim::GetAttr[name="dense"](%2443)
  %2454 : Tensor = prim::GetAttr[name="bias"](%2453)
  %2455 : Tensor = prim::GetAttr[name="weight"](%2453)
  %2456 : Float(512:1, 128:512) = aten::t(%2455), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.output/__module.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.176 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.226, %2456), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.output/__module.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.176, %2454, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.output/__module.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.94 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.58, %input.224, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2460 : Tensor = prim::GetAttr[name="bias"](%2452)
  %2461 : Tensor = prim::GetAttr[name="weight"](%2452)
  %2462 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.94, %2461), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.output/__module.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.227 : Float(17:1664, 13:128, 128:1) = aten::add(%2462, %2460, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.1/__module.encoder.layer.11.ffn.1.output/__module.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2464 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27093.FFNOutput = prim::GetAttr[name="output"](%2324)
  %2465 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27090.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2324)
  %2466 : __torch__.torch.nn.modules.linear.___torch_mangle_27089.Linear = prim::GetAttr[name="dense"](%2465)
  %2467 : Tensor = prim::GetAttr[name="bias"](%2466)
  %2468 : Tensor = prim::GetAttr[name="weight"](%2466)
  %2469 : Float(128:1, 512:128) = aten::t(%2468), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.intermediate/__module.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.177 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.227, %2469), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.intermediate/__module.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.228 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.177, %2467, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.intermediate/__module.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.229 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.228), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2473 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27092.NoNorm = prim::GetAttr[name="LayerNorm"](%2464)
  %2474 : __torch__.torch.nn.modules.linear.___torch_mangle_27091.Linear = prim::GetAttr[name="dense"](%2464)
  %2475 : Tensor = prim::GetAttr[name="bias"](%2474)
  %2476 : Tensor = prim::GetAttr[name="weight"](%2474)
  %2477 : Float(512:1, 128:512) = aten::t(%2476), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.output/__module.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.178 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.229, %2477), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.output/__module.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.178, %2475, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.output/__module.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.95 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.59, %input.227, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2481 : Tensor = prim::GetAttr[name="bias"](%2473)
  %2482 : Tensor = prim::GetAttr[name="weight"](%2473)
  %2483 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.95, %2482), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.output/__module.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.230 : Float(17:1664, 13:128, 128:1) = aten::add(%2483, %2481, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.ffn.2/__module.encoder.layer.11.ffn.2.output/__module.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2485 : __torch__.torch.nn.modules.linear.___torch_mangle_27061.Linear = prim::GetAttr[name="dense"](%2322)
  %2486 : Tensor = prim::GetAttr[name="bias"](%2485)
  %2487 : Tensor = prim::GetAttr[name="weight"](%2485)
  %2488 : Float(128:1, 512:128) = aten::t(%2487), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate/__module.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %output.179 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.230, %2488), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate/__module.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %input.231 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.179, %2486, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate/__module.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1678:0
  %input.232 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.231), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.intermediate # torch/nn/functional.py:1119:0
  %2492 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27068.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2321)
  %2493 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27064.NoNorm = prim::GetAttr[name="LayerNorm"](%2321)
  %2494 : __torch__.torch.nn.modules.linear.___torch_mangle_27063.Linear = prim::GetAttr[name="dense"](%2321)
  %2495 : Tensor = prim::GetAttr[name="bias"](%2494)
  %2496 : Tensor = prim::GetAttr[name="weight"](%2494)
  %2497 : Float(512:1, 128:512) = aten::t(%2496), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %output.180 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.232, %2497), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %layer_output.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.180, %2495, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.96 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.12, %input.230, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output # transformers/modeling_mobilebert.py:405:0
  %2501 : Tensor = prim::GetAttr[name="bias"](%2493)
  %2502 : Tensor = prim::GetAttr[name="weight"](%2493)
  %2503 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.96, %2502), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.233 : Float(17:1664, 13:128, 128:1) = aten::add(%2503, %2501, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2505 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27066.NoNorm = prim::GetAttr[name="LayerNorm"](%2492)
  %2506 : __torch__.torch.nn.modules.linear.___torch_mangle_27065.Linear = prim::GetAttr[name="dense"](%2492)
  %2507 : Tensor = prim::GetAttr[name="bias"](%2506)
  %2508 : Tensor = prim::GetAttr[name="weight"](%2506)
  %2509 : Float(128:1, 512:128) = aten::t(%2508), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.bottleneck/__module.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.181 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.233, %2509), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.bottleneck/__module.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.234 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.181, %2507, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.bottleneck/__module.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.60 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.234, %105, %102), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.bottleneck/__module.encoder.layer.11.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.97 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.60, %input.216, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2514 : Tensor = prim::GetAttr[name="bias"](%2505)
  %2515 : Tensor = prim::GetAttr[name="weight"](%2505)
  %2516 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.97, %2515), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.bottleneck/__module.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.235 : Float(17:6656, 13:512, 512:1) = aten::add(%2516, %2514, %92), scope: __module.encoder/__module.encoder.layer.11/__module.encoder.layer.11.output/__module.encoder.layer.11.output.bottleneck/__module.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2518 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27114.MobileBertOutput = prim::GetAttr[name="output"](%129)
  %2519 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27107.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%129)
  %2520 : __torch__.torch.nn.modules.container.___torch_mangle_27140.ModuleList = prim::GetAttr[name="ffn"](%129)
  %2521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27139.FFNLayer = prim::GetAttr[name="2"](%2520)
  %2522 : __torch__.torch.nn.modules.container.___torch_mangle_27140.ModuleList = prim::GetAttr[name="ffn"](%129)
  %2523 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27133.FFNLayer = prim::GetAttr[name="1"](%2522)
  %2524 : __torch__.torch.nn.modules.container.___torch_mangle_27140.ModuleList = prim::GetAttr[name="ffn"](%129)
  %2525 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27127.FFNLayer = prim::GetAttr[name="0"](%2524)
  %2526 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27105.MobileBertAttention = prim::GetAttr[name="attention"](%129)
  %2527 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27121.Bottleneck = prim::GetAttr[name="bottleneck"](%129)
  %2528 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27120.BottleneckLayer = prim::GetAttr[name="attention"](%2527)
  %2529 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27117.BottleneckLayer = prim::GetAttr[name="input"](%2527)
  %2530 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27116.NoNorm = prim::GetAttr[name="LayerNorm"](%2529)
  %2531 : __torch__.torch.nn.modules.linear.___torch_mangle_27115.Linear = prim::GetAttr[name="dense"](%2529)
  %2532 : Tensor = prim::GetAttr[name="bias"](%2531)
  %2533 : Tensor = prim::GetAttr[name="weight"](%2531)
  %2534 : Float(512:1, 128:512) = aten::t(%2533), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.input/__module.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.182 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2534), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.input/__module.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.182, %2532, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.input/__module.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2537 : Tensor = prim::GetAttr[name="bias"](%2530)
  %2538 : Tensor = prim::GetAttr[name="weight"](%2530)
  %2539 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.98, %2538), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.input/__module.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%2539, %2537, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.input/__module.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2541 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27119.NoNorm = prim::GetAttr[name="LayerNorm"](%2528)
  %2542 : __torch__.torch.nn.modules.linear.___torch_mangle_27118.Linear = prim::GetAttr[name="dense"](%2528)
  %2543 : Tensor = prim::GetAttr[name="bias"](%2542)
  %2544 : Tensor = prim::GetAttr[name="weight"](%2542)
  %2545 : Float(512:1, 128:512) = aten::t(%2544), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.attention/__module.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.183 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2545), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.attention/__module.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.183, %2543, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.attention/__module.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2548 : Tensor = prim::GetAttr[name="bias"](%2541)
  %2549 : Tensor = prim::GetAttr[name="weight"](%2541)
  %2550 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.99, %2549), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.attention/__module.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.236 : Float(17:1664, 13:128, 128:1) = aten::add(%2550, %2548, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.bottleneck/__module.encoder.layer.12.bottleneck.attention/__module.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2552 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.236, %residual_tensor.13)
  %2553 : Float(17:1664, 13:128, 128:1), %2554 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2552)
  %2555 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27104.MobileBertSelfOutput = prim::GetAttr[name="output"](%2526)
  %2556 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27101.MobileBertSelfAttention = prim::GetAttr[name="self"](%2526)
  %2557 : __torch__.torch.nn.modules.linear.___torch_mangle_27099.Linear = prim::GetAttr[name="value"](%2556)
  %2558 : __torch__.torch.nn.modules.linear.___torch_mangle_27098.Linear = prim::GetAttr[name="key"](%2556)
  %2559 : __torch__.torch.nn.modules.linear.___torch_mangle_27097.Linear = prim::GetAttr[name="query"](%2556)
  %2560 : Tensor = prim::GetAttr[name="bias"](%2559)
  %2561 : Tensor = prim::GetAttr[name="weight"](%2559)
  %2562 : Float(128:1, 128:128) = aten::t(%2561), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %output.184 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2553, %2562), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %x.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.184, %2560, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.query # torch/nn/functional.py:1678:0
  %2565 : Tensor = prim::GetAttr[name="bias"](%2558)
  %2566 : Tensor = prim::GetAttr[name="weight"](%2558)
  %2567 : Float(128:1, 128:128) = aten::t(%2566), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %output.185 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2553, %2567), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %x.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.185, %2565, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.key # torch/nn/functional.py:1678:0
  %2570 : Tensor = prim::GetAttr[name="bias"](%2557)
  %2571 : Tensor = prim::GetAttr[name="weight"](%2557)
  %2572 : Float(512:1, 128:512) = aten::t(%2571), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %output.186 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2572), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %x.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.186, %2570, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.value # torch/nn/functional.py:1678:0
  %2575 : int = aten::size(%x.73, %93), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2576 : int = aten::size(%x.73, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2577 : int[] = prim::ListConstruct(%2575, %2576, %94, %95), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self
  %x.74 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.73, %2577), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2579 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self
  %query_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.74, %2579), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2581 : int = aten::size(%x.75, %93), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2582 : int = aten::size(%x.75, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2583 : int[] = prim::ListConstruct(%2581, %2582, %94, %95), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self
  %x.76 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.75, %2583), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2585 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self
  %key_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.76, %2585), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2587 : int = aten::size(%x.77, %93), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2588 : int = aten::size(%x.77, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2589 : int[] = prim::ListConstruct(%2587, %2588, %94, %95), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self
  %x.78 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.77, %2589), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2591 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self
  %value_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.78, %2591), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2593 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.13, %98, %99), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.25 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.13, %2593), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.26 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.25, %100), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.237 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.26, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.238 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.237, %98, %101), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.238, %103, %102), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self/__module.encoder.layer.12.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.25 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.13, %value_layer.13), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:280:0
  %2600 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self
  %2601 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.25, %2600), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2601, %93), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %2603 : int = aten::size(%context_layer.26, %93), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2604 : int = aten::size(%context_layer.26, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2605 : int[] = prim::ListConstruct(%2603, %2604, %104), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self
  %input.239 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.26, %2605), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:283:0
  %2607 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27103.NoNorm = prim::GetAttr[name="LayerNorm"](%2555)
  %2608 : __torch__.torch.nn.modules.linear.___torch_mangle_27102.Linear = prim::GetAttr[name="dense"](%2555)
  %2609 : Tensor = prim::GetAttr[name="bias"](%2608)
  %2610 : Tensor = prim::GetAttr[name="weight"](%2608)
  %2611 : Float(128:1, 128:128) = aten::t(%2610), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.output/__module.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %output.187 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.239, %2611), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.output/__module.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.187, %2609, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.output/__module.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.100 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.61, %2554, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.output # transformers/modeling_mobilebert.py:301:0
  %2615 : Tensor = prim::GetAttr[name="bias"](%2607)
  %2616 : Tensor = prim::GetAttr[name="weight"](%2607)
  %2617 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.100, %2616), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.output/__module.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.240 : Float(17:1664, 13:128, 128:1) = aten::add(%2617, %2615, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.attention/__module.encoder.layer.12.attention.output/__module.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2619 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27126.FFNOutput = prim::GetAttr[name="output"](%2525)
  %2620 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27123.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2525)
  %2621 : __torch__.torch.nn.modules.linear.___torch_mangle_27122.Linear = prim::GetAttr[name="dense"](%2620)
  %2622 : Tensor = prim::GetAttr[name="bias"](%2621)
  %2623 : Tensor = prim::GetAttr[name="weight"](%2621)
  %2624 : Float(128:1, 512:128) = aten::t(%2623), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.intermediate/__module.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.188 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.240, %2624), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.intermediate/__module.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.241 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.188, %2622, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.intermediate/__module.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.242 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.241), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2628 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27125.NoNorm = prim::GetAttr[name="LayerNorm"](%2619)
  %2629 : __torch__.torch.nn.modules.linear.___torch_mangle_27124.Linear = prim::GetAttr[name="dense"](%2619)
  %2630 : Tensor = prim::GetAttr[name="bias"](%2629)
  %2631 : Tensor = prim::GetAttr[name="weight"](%2629)
  %2632 : Float(512:1, 128:512) = aten::t(%2631), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.output/__module.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.189 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.242, %2632), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.output/__module.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.62 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.189, %2630, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.output/__module.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.101 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.62, %input.240, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2636 : Tensor = prim::GetAttr[name="bias"](%2628)
  %2637 : Tensor = prim::GetAttr[name="weight"](%2628)
  %2638 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.101, %2637), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.output/__module.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.243 : Float(17:1664, 13:128, 128:1) = aten::add(%2638, %2636, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.0/__module.encoder.layer.12.ffn.0.output/__module.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2640 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27132.FFNOutput = prim::GetAttr[name="output"](%2523)
  %2641 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27129.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2523)
  %2642 : __torch__.torch.nn.modules.linear.___torch_mangle_27128.Linear = prim::GetAttr[name="dense"](%2641)
  %2643 : Tensor = prim::GetAttr[name="bias"](%2642)
  %2644 : Tensor = prim::GetAttr[name="weight"](%2642)
  %2645 : Float(128:1, 512:128) = aten::t(%2644), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.intermediate/__module.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.190 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.243, %2645), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.intermediate/__module.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.244 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.190, %2643, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.intermediate/__module.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.245 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.244), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2649 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27131.NoNorm = prim::GetAttr[name="LayerNorm"](%2640)
  %2650 : __torch__.torch.nn.modules.linear.___torch_mangle_27130.Linear = prim::GetAttr[name="dense"](%2640)
  %2651 : Tensor = prim::GetAttr[name="bias"](%2650)
  %2652 : Tensor = prim::GetAttr[name="weight"](%2650)
  %2653 : Float(512:1, 128:512) = aten::t(%2652), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.output/__module.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.191 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.245, %2653), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.output/__module.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.191, %2651, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.output/__module.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.102 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.63, %input.243, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2657 : Tensor = prim::GetAttr[name="bias"](%2649)
  %2658 : Tensor = prim::GetAttr[name="weight"](%2649)
  %2659 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.102, %2658), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.output/__module.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.246 : Float(17:1664, 13:128, 128:1) = aten::add(%2659, %2657, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.1/__module.encoder.layer.12.ffn.1.output/__module.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2661 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27138.FFNOutput = prim::GetAttr[name="output"](%2521)
  %2662 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27135.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2521)
  %2663 : __torch__.torch.nn.modules.linear.___torch_mangle_27134.Linear = prim::GetAttr[name="dense"](%2662)
  %2664 : Tensor = prim::GetAttr[name="bias"](%2663)
  %2665 : Tensor = prim::GetAttr[name="weight"](%2663)
  %2666 : Float(128:1, 512:128) = aten::t(%2665), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.intermediate/__module.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.192 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.246, %2666), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.intermediate/__module.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.247 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.192, %2664, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.intermediate/__module.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.248 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.247), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2670 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27137.NoNorm = prim::GetAttr[name="LayerNorm"](%2661)
  %2671 : __torch__.torch.nn.modules.linear.___torch_mangle_27136.Linear = prim::GetAttr[name="dense"](%2661)
  %2672 : Tensor = prim::GetAttr[name="bias"](%2671)
  %2673 : Tensor = prim::GetAttr[name="weight"](%2671)
  %2674 : Float(512:1, 128:512) = aten::t(%2673), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.output/__module.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.193 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.248, %2674), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.output/__module.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.64 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.193, %2672, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.output/__module.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.103 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.64, %input.246, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2678 : Tensor = prim::GetAttr[name="bias"](%2670)
  %2679 : Tensor = prim::GetAttr[name="weight"](%2670)
  %2680 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.103, %2679), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.output/__module.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.249 : Float(17:1664, 13:128, 128:1) = aten::add(%2680, %2678, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.ffn.2/__module.encoder.layer.12.ffn.2.output/__module.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2682 : __torch__.torch.nn.modules.linear.___torch_mangle_27106.Linear = prim::GetAttr[name="dense"](%2519)
  %2683 : Tensor = prim::GetAttr[name="bias"](%2682)
  %2684 : Tensor = prim::GetAttr[name="weight"](%2682)
  %2685 : Float(128:1, 512:128) = aten::t(%2684), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.intermediate/__module.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %output.194 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.249, %2685), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.intermediate/__module.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %input.250 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.194, %2683, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.intermediate/__module.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1678:0
  %input.251 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.250), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.intermediate # torch/nn/functional.py:1119:0
  %2689 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27113.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2518)
  %2690 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27109.NoNorm = prim::GetAttr[name="LayerNorm"](%2518)
  %2691 : __torch__.torch.nn.modules.linear.___torch_mangle_27108.Linear = prim::GetAttr[name="dense"](%2518)
  %2692 : Tensor = prim::GetAttr[name="bias"](%2691)
  %2693 : Tensor = prim::GetAttr[name="weight"](%2691)
  %2694 : Float(512:1, 128:512) = aten::t(%2693), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %output.195 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.251, %2694), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %layer_output.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.195, %2692, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.104 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.13, %input.249, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output # transformers/modeling_mobilebert.py:405:0
  %2698 : Tensor = prim::GetAttr[name="bias"](%2690)
  %2699 : Tensor = prim::GetAttr[name="weight"](%2690)
  %2700 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.104, %2699), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.252 : Float(17:1664, 13:128, 128:1) = aten::add(%2700, %2698, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2702 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27111.NoNorm = prim::GetAttr[name="LayerNorm"](%2689)
  %2703 : __torch__.torch.nn.modules.linear.___torch_mangle_27110.Linear = prim::GetAttr[name="dense"](%2689)
  %2704 : Tensor = prim::GetAttr[name="bias"](%2703)
  %2705 : Tensor = prim::GetAttr[name="weight"](%2703)
  %2706 : Float(128:1, 512:128) = aten::t(%2705), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.bottleneck/__module.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.196 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.252, %2706), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.bottleneck/__module.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.253 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.196, %2704, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.bottleneck/__module.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.65 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.253, %105, %102), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.bottleneck/__module.encoder.layer.12.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.105 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.65, %input.235, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2711 : Tensor = prim::GetAttr[name="bias"](%2702)
  %2712 : Tensor = prim::GetAttr[name="weight"](%2702)
  %2713 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.105, %2712), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.bottleneck/__module.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.254 : Float(17:6656, 13:512, 512:1) = aten::add(%2713, %2711, %92), scope: __module.encoder/__module.encoder.layer.12/__module.encoder.layer.12.output/__module.encoder.layer.12.output.bottleneck/__module.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2715 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27159.MobileBertOutput = prim::GetAttr[name="output"](%127)
  %2716 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27152.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%127)
  %2717 : __torch__.torch.nn.modules.container.___torch_mangle_27185.ModuleList = prim::GetAttr[name="ffn"](%127)
  %2718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27184.FFNLayer = prim::GetAttr[name="2"](%2717)
  %2719 : __torch__.torch.nn.modules.container.___torch_mangle_27185.ModuleList = prim::GetAttr[name="ffn"](%127)
  %2720 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27178.FFNLayer = prim::GetAttr[name="1"](%2719)
  %2721 : __torch__.torch.nn.modules.container.___torch_mangle_27185.ModuleList = prim::GetAttr[name="ffn"](%127)
  %2722 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27172.FFNLayer = prim::GetAttr[name="0"](%2721)
  %2723 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27150.MobileBertAttention = prim::GetAttr[name="attention"](%127)
  %2724 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27166.Bottleneck = prim::GetAttr[name="bottleneck"](%127)
  %2725 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27165.BottleneckLayer = prim::GetAttr[name="attention"](%2724)
  %2726 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27162.BottleneckLayer = prim::GetAttr[name="input"](%2724)
  %2727 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27161.NoNorm = prim::GetAttr[name="LayerNorm"](%2726)
  %2728 : __torch__.torch.nn.modules.linear.___torch_mangle_27160.Linear = prim::GetAttr[name="dense"](%2726)
  %2729 : Tensor = prim::GetAttr[name="bias"](%2728)
  %2730 : Tensor = prim::GetAttr[name="weight"](%2728)
  %2731 : Float(512:1, 128:512) = aten::t(%2730), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.input/__module.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.197 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2731), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.input/__module.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.197, %2729, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.input/__module.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2734 : Tensor = prim::GetAttr[name="bias"](%2727)
  %2735 : Tensor = prim::GetAttr[name="weight"](%2727)
  %2736 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.106, %2735), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.input/__module.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%2736, %2734, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.input/__module.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2738 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27164.NoNorm = prim::GetAttr[name="LayerNorm"](%2725)
  %2739 : __torch__.torch.nn.modules.linear.___torch_mangle_27163.Linear = prim::GetAttr[name="dense"](%2725)
  %2740 : Tensor = prim::GetAttr[name="bias"](%2739)
  %2741 : Tensor = prim::GetAttr[name="weight"](%2739)
  %2742 : Float(512:1, 128:512) = aten::t(%2741), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.attention/__module.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.198 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2742), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.attention/__module.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.198, %2740, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.attention/__module.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2745 : Tensor = prim::GetAttr[name="bias"](%2738)
  %2746 : Tensor = prim::GetAttr[name="weight"](%2738)
  %2747 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.107, %2746), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.attention/__module.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.255 : Float(17:1664, 13:128, 128:1) = aten::add(%2747, %2745, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.bottleneck/__module.encoder.layer.13.bottleneck.attention/__module.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2749 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.255, %residual_tensor.14)
  %2750 : Float(17:1664, 13:128, 128:1), %2751 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2749)
  %2752 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27149.MobileBertSelfOutput = prim::GetAttr[name="output"](%2723)
  %2753 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27146.MobileBertSelfAttention = prim::GetAttr[name="self"](%2723)
  %2754 : __torch__.torch.nn.modules.linear.___torch_mangle_27144.Linear = prim::GetAttr[name="value"](%2753)
  %2755 : __torch__.torch.nn.modules.linear.___torch_mangle_27143.Linear = prim::GetAttr[name="key"](%2753)
  %2756 : __torch__.torch.nn.modules.linear.___torch_mangle_27142.Linear = prim::GetAttr[name="query"](%2753)
  %2757 : Tensor = prim::GetAttr[name="bias"](%2756)
  %2758 : Tensor = prim::GetAttr[name="weight"](%2756)
  %2759 : Float(128:1, 128:128) = aten::t(%2758), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %output.199 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2750, %2759), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %x.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.199, %2757, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.query # torch/nn/functional.py:1678:0
  %2762 : Tensor = prim::GetAttr[name="bias"](%2755)
  %2763 : Tensor = prim::GetAttr[name="weight"](%2755)
  %2764 : Float(128:1, 128:128) = aten::t(%2763), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %output.200 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2750, %2764), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %x.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.200, %2762, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.key # torch/nn/functional.py:1678:0
  %2767 : Tensor = prim::GetAttr[name="bias"](%2754)
  %2768 : Tensor = prim::GetAttr[name="weight"](%2754)
  %2769 : Float(512:1, 128:512) = aten::t(%2768), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %output.201 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2769), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %x.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.201, %2767, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.value # torch/nn/functional.py:1678:0
  %2772 : int = aten::size(%x.79, %93), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2773 : int = aten::size(%x.79, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2774 : int[] = prim::ListConstruct(%2772, %2773, %94, %95), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self
  %x.80 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.79, %2774), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2776 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self
  %query_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.80, %2776), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2778 : int = aten::size(%x.81, %93), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2779 : int = aten::size(%x.81, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2780 : int[] = prim::ListConstruct(%2778, %2779, %94, %95), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self
  %x.82 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.81, %2780), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2782 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self
  %key_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.82, %2782), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2784 : int = aten::size(%x.83, %93), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2785 : int = aten::size(%x.83, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2786 : int[] = prim::ListConstruct(%2784, %2785, %94, %95), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self
  %x.84 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.83, %2786), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2788 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self
  %value_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.84, %2788), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2790 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.14, %98, %99), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.27 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.14, %2790), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.27, %100), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.256 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.28, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.257 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.256, %98, %101), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.257, %103, %102), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self/__module.encoder.layer.13.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.27 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.14, %value_layer.14), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:280:0
  %2797 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self
  %2798 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.27, %2797), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2798, %93), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %2800 : int = aten::size(%context_layer.28, %93), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2801 : int = aten::size(%context_layer.28, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2802 : int[] = prim::ListConstruct(%2800, %2801, %104), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self
  %input.258 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.28, %2802), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:283:0
  %2804 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27148.NoNorm = prim::GetAttr[name="LayerNorm"](%2752)
  %2805 : __torch__.torch.nn.modules.linear.___torch_mangle_27147.Linear = prim::GetAttr[name="dense"](%2752)
  %2806 : Tensor = prim::GetAttr[name="bias"](%2805)
  %2807 : Tensor = prim::GetAttr[name="weight"](%2805)
  %2808 : Float(128:1, 128:128) = aten::t(%2807), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.output/__module.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %output.202 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.258, %2808), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.output/__module.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.202, %2806, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.output/__module.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.108 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.66, %2751, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.output # transformers/modeling_mobilebert.py:301:0
  %2812 : Tensor = prim::GetAttr[name="bias"](%2804)
  %2813 : Tensor = prim::GetAttr[name="weight"](%2804)
  %2814 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.108, %2813), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.output/__module.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.259 : Float(17:1664, 13:128, 128:1) = aten::add(%2814, %2812, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.attention/__module.encoder.layer.13.attention.output/__module.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2816 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27171.FFNOutput = prim::GetAttr[name="output"](%2722)
  %2817 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27168.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2722)
  %2818 : __torch__.torch.nn.modules.linear.___torch_mangle_27167.Linear = prim::GetAttr[name="dense"](%2817)
  %2819 : Tensor = prim::GetAttr[name="bias"](%2818)
  %2820 : Tensor = prim::GetAttr[name="weight"](%2818)
  %2821 : Float(128:1, 512:128) = aten::t(%2820), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.intermediate/__module.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.203 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.259, %2821), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.intermediate/__module.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.260 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.203, %2819, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.intermediate/__module.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.261 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.260), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2825 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27170.NoNorm = prim::GetAttr[name="LayerNorm"](%2816)
  %2826 : __torch__.torch.nn.modules.linear.___torch_mangle_27169.Linear = prim::GetAttr[name="dense"](%2816)
  %2827 : Tensor = prim::GetAttr[name="bias"](%2826)
  %2828 : Tensor = prim::GetAttr[name="weight"](%2826)
  %2829 : Float(512:1, 128:512) = aten::t(%2828), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.output/__module.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.204 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.261, %2829), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.output/__module.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.204, %2827, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.output/__module.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.109 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.67, %input.259, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2833 : Tensor = prim::GetAttr[name="bias"](%2825)
  %2834 : Tensor = prim::GetAttr[name="weight"](%2825)
  %2835 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.109, %2834), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.output/__module.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.262 : Float(17:1664, 13:128, 128:1) = aten::add(%2835, %2833, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.0/__module.encoder.layer.13.ffn.0.output/__module.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2837 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27177.FFNOutput = prim::GetAttr[name="output"](%2720)
  %2838 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27174.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2720)
  %2839 : __torch__.torch.nn.modules.linear.___torch_mangle_27173.Linear = prim::GetAttr[name="dense"](%2838)
  %2840 : Tensor = prim::GetAttr[name="bias"](%2839)
  %2841 : Tensor = prim::GetAttr[name="weight"](%2839)
  %2842 : Float(128:1, 512:128) = aten::t(%2841), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.intermediate/__module.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.205 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.262, %2842), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.intermediate/__module.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.263 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.205, %2840, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.intermediate/__module.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.264 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.263), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2846 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27176.NoNorm = prim::GetAttr[name="LayerNorm"](%2837)
  %2847 : __torch__.torch.nn.modules.linear.___torch_mangle_27175.Linear = prim::GetAttr[name="dense"](%2837)
  %2848 : Tensor = prim::GetAttr[name="bias"](%2847)
  %2849 : Tensor = prim::GetAttr[name="weight"](%2847)
  %2850 : Float(512:1, 128:512) = aten::t(%2849), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.output/__module.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.206 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.264, %2850), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.output/__module.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.68 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.206, %2848, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.output/__module.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.110 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.68, %input.262, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2854 : Tensor = prim::GetAttr[name="bias"](%2846)
  %2855 : Tensor = prim::GetAttr[name="weight"](%2846)
  %2856 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.110, %2855), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.output/__module.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.265 : Float(17:1664, 13:128, 128:1) = aten::add(%2856, %2854, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.1/__module.encoder.layer.13.ffn.1.output/__module.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2858 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27183.FFNOutput = prim::GetAttr[name="output"](%2718)
  %2859 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27180.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2718)
  %2860 : __torch__.torch.nn.modules.linear.___torch_mangle_27179.Linear = prim::GetAttr[name="dense"](%2859)
  %2861 : Tensor = prim::GetAttr[name="bias"](%2860)
  %2862 : Tensor = prim::GetAttr[name="weight"](%2860)
  %2863 : Float(128:1, 512:128) = aten::t(%2862), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.intermediate/__module.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.207 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.265, %2863), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.intermediate/__module.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.266 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.207, %2861, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.intermediate/__module.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.267 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.266), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2867 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27182.NoNorm = prim::GetAttr[name="LayerNorm"](%2858)
  %2868 : __torch__.torch.nn.modules.linear.___torch_mangle_27181.Linear = prim::GetAttr[name="dense"](%2858)
  %2869 : Tensor = prim::GetAttr[name="bias"](%2868)
  %2870 : Tensor = prim::GetAttr[name="weight"](%2868)
  %2871 : Float(512:1, 128:512) = aten::t(%2870), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.output/__module.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.208 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.267, %2871), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.output/__module.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.208, %2869, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.output/__module.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.111 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.69, %input.265, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2875 : Tensor = prim::GetAttr[name="bias"](%2867)
  %2876 : Tensor = prim::GetAttr[name="weight"](%2867)
  %2877 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.111, %2876), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.output/__module.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.268 : Float(17:1664, 13:128, 128:1) = aten::add(%2877, %2875, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.ffn.2/__module.encoder.layer.13.ffn.2.output/__module.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2879 : __torch__.torch.nn.modules.linear.___torch_mangle_27151.Linear = prim::GetAttr[name="dense"](%2716)
  %2880 : Tensor = prim::GetAttr[name="bias"](%2879)
  %2881 : Tensor = prim::GetAttr[name="weight"](%2879)
  %2882 : Float(128:1, 512:128) = aten::t(%2881), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.intermediate/__module.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %output.209 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.268, %2882), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.intermediate/__module.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %input.269 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.209, %2880, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.intermediate/__module.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1678:0
  %input.270 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.269), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.intermediate # torch/nn/functional.py:1119:0
  %2886 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27158.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2715)
  %2887 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27154.NoNorm = prim::GetAttr[name="LayerNorm"](%2715)
  %2888 : __torch__.torch.nn.modules.linear.___torch_mangle_27153.Linear = prim::GetAttr[name="dense"](%2715)
  %2889 : Tensor = prim::GetAttr[name="bias"](%2888)
  %2890 : Tensor = prim::GetAttr[name="weight"](%2888)
  %2891 : Float(512:1, 128:512) = aten::t(%2890), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %output.210 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.270, %2891), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %layer_output.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.210, %2889, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.112 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.14, %input.268, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output # transformers/modeling_mobilebert.py:405:0
  %2895 : Tensor = prim::GetAttr[name="bias"](%2887)
  %2896 : Tensor = prim::GetAttr[name="weight"](%2887)
  %2897 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.112, %2896), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.271 : Float(17:1664, 13:128, 128:1) = aten::add(%2897, %2895, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2899 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27156.NoNorm = prim::GetAttr[name="LayerNorm"](%2886)
  %2900 : __torch__.torch.nn.modules.linear.___torch_mangle_27155.Linear = prim::GetAttr[name="dense"](%2886)
  %2901 : Tensor = prim::GetAttr[name="bias"](%2900)
  %2902 : Tensor = prim::GetAttr[name="weight"](%2900)
  %2903 : Float(128:1, 512:128) = aten::t(%2902), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.bottleneck/__module.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.211 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.271, %2903), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.bottleneck/__module.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.272 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.211, %2901, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.bottleneck/__module.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.70 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.272, %105, %102), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.bottleneck/__module.encoder.layer.13.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.113 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.70, %input.254, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2908 : Tensor = prim::GetAttr[name="bias"](%2899)
  %2909 : Tensor = prim::GetAttr[name="weight"](%2899)
  %2910 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.113, %2909), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.bottleneck/__module.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.273 : Float(17:6656, 13:512, 512:1) = aten::add(%2910, %2908, %92), scope: __module.encoder/__module.encoder.layer.13/__module.encoder.layer.13.output/__module.encoder.layer.13.output.bottleneck/__module.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2912 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27204.MobileBertOutput = prim::GetAttr[name="output"](%125)
  %2913 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27197.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%125)
  %2914 : __torch__.torch.nn.modules.container.___torch_mangle_27230.ModuleList = prim::GetAttr[name="ffn"](%125)
  %2915 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27229.FFNLayer = prim::GetAttr[name="2"](%2914)
  %2916 : __torch__.torch.nn.modules.container.___torch_mangle_27230.ModuleList = prim::GetAttr[name="ffn"](%125)
  %2917 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27223.FFNLayer = prim::GetAttr[name="1"](%2916)
  %2918 : __torch__.torch.nn.modules.container.___torch_mangle_27230.ModuleList = prim::GetAttr[name="ffn"](%125)
  %2919 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27217.FFNLayer = prim::GetAttr[name="0"](%2918)
  %2920 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27195.MobileBertAttention = prim::GetAttr[name="attention"](%125)
  %2921 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27211.Bottleneck = prim::GetAttr[name="bottleneck"](%125)
  %2922 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27210.BottleneckLayer = prim::GetAttr[name="attention"](%2921)
  %2923 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27207.BottleneckLayer = prim::GetAttr[name="input"](%2921)
  %2924 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27206.NoNorm = prim::GetAttr[name="LayerNorm"](%2923)
  %2925 : __torch__.torch.nn.modules.linear.___torch_mangle_27205.Linear = prim::GetAttr[name="dense"](%2923)
  %2926 : Tensor = prim::GetAttr[name="bias"](%2925)
  %2927 : Tensor = prim::GetAttr[name="weight"](%2925)
  %2928 : Float(512:1, 128:512) = aten::t(%2927), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.input/__module.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.212 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2928), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.input/__module.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.212, %2926, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.input/__module.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2931 : Tensor = prim::GetAttr[name="bias"](%2924)
  %2932 : Tensor = prim::GetAttr[name="weight"](%2924)
  %2933 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.114, %2932), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.input/__module.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%2933, %2931, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.input/__module.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2935 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27209.NoNorm = prim::GetAttr[name="LayerNorm"](%2922)
  %2936 : __torch__.torch.nn.modules.linear.___torch_mangle_27208.Linear = prim::GetAttr[name="dense"](%2922)
  %2937 : Tensor = prim::GetAttr[name="bias"](%2936)
  %2938 : Tensor = prim::GetAttr[name="weight"](%2936)
  %2939 : Float(512:1, 128:512) = aten::t(%2938), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.attention/__module.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.213 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2939), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.attention/__module.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.213, %2937, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.attention/__module.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2942 : Tensor = prim::GetAttr[name="bias"](%2935)
  %2943 : Tensor = prim::GetAttr[name="weight"](%2935)
  %2944 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.115, %2943), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.attention/__module.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.274 : Float(17:1664, 13:128, 128:1) = aten::add(%2944, %2942, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.bottleneck/__module.encoder.layer.14.bottleneck.attention/__module.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2946 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.274, %residual_tensor.15)
  %2947 : Float(17:1664, 13:128, 128:1), %2948 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2946)
  %2949 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27194.MobileBertSelfOutput = prim::GetAttr[name="output"](%2920)
  %2950 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27191.MobileBertSelfAttention = prim::GetAttr[name="self"](%2920)
  %2951 : __torch__.torch.nn.modules.linear.___torch_mangle_27189.Linear = prim::GetAttr[name="value"](%2950)
  %2952 : __torch__.torch.nn.modules.linear.___torch_mangle_27188.Linear = prim::GetAttr[name="key"](%2950)
  %2953 : __torch__.torch.nn.modules.linear.___torch_mangle_27187.Linear = prim::GetAttr[name="query"](%2950)
  %2954 : Tensor = prim::GetAttr[name="bias"](%2953)
  %2955 : Tensor = prim::GetAttr[name="weight"](%2953)
  %2956 : Float(128:1, 128:128) = aten::t(%2955), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %output.214 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2947, %2956), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %x.85 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.214, %2954, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.query # torch/nn/functional.py:1678:0
  %2959 : Tensor = prim::GetAttr[name="bias"](%2952)
  %2960 : Tensor = prim::GetAttr[name="weight"](%2952)
  %2961 : Float(128:1, 128:128) = aten::t(%2960), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %output.215 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2947, %2961), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %x.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.215, %2959, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.key # torch/nn/functional.py:1678:0
  %2964 : Tensor = prim::GetAttr[name="bias"](%2951)
  %2965 : Tensor = prim::GetAttr[name="weight"](%2951)
  %2966 : Float(512:1, 128:512) = aten::t(%2965), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %output.216 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2966), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %x.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.216, %2964, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.value # torch/nn/functional.py:1678:0
  %2969 : int = aten::size(%x.85, %93), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2970 : int = aten::size(%x.85, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2971 : int[] = prim::ListConstruct(%2969, %2970, %94, %95), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self
  %x.86 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.85, %2971), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2973 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self
  %query_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.86, %2973), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2975 : int = aten::size(%x.87, %93), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2976 : int = aten::size(%x.87, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2977 : int[] = prim::ListConstruct(%2975, %2976, %94, %95), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self
  %x.88 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.87, %2977), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2979 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self
  %key_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.88, %2979), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2981 : int = aten::size(%x.89, %93), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2982 : int = aten::size(%x.89, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2983 : int[] = prim::ListConstruct(%2981, %2982, %94, %95), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self
  %x.90 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.89, %2983), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2985 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self
  %value_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.90, %2985), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2987 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.15, %98, %99), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.15, %2987), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.30 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.29, %100), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.275 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.30, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.276 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.275, %98, %101), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.276, %103, %102), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self/__module.encoder.layer.14.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.29 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.15, %value_layer.15), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:280:0
  %2994 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self
  %2995 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.29, %2994), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2995, %93), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %2997 : int = aten::size(%context_layer.30, %93), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2998 : int = aten::size(%context_layer.30, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2999 : int[] = prim::ListConstruct(%2997, %2998, %104), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self
  %input.277 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.30, %2999), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:283:0
  %3001 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27193.NoNorm = prim::GetAttr[name="LayerNorm"](%2949)
  %3002 : __torch__.torch.nn.modules.linear.___torch_mangle_27192.Linear = prim::GetAttr[name="dense"](%2949)
  %3003 : Tensor = prim::GetAttr[name="bias"](%3002)
  %3004 : Tensor = prim::GetAttr[name="weight"](%3002)
  %3005 : Float(128:1, 128:128) = aten::t(%3004), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.output/__module.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %output.217 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.277, %3005), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.output/__module.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.217, %3003, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.output/__module.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.116 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.71, %2948, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.output # transformers/modeling_mobilebert.py:301:0
  %3009 : Tensor = prim::GetAttr[name="bias"](%3001)
  %3010 : Tensor = prim::GetAttr[name="weight"](%3001)
  %3011 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.116, %3010), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.output/__module.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.278 : Float(17:1664, 13:128, 128:1) = aten::add(%3011, %3009, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.attention/__module.encoder.layer.14.attention.output/__module.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3013 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27216.FFNOutput = prim::GetAttr[name="output"](%2919)
  %3014 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27213.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2919)
  %3015 : __torch__.torch.nn.modules.linear.___torch_mangle_27212.Linear = prim::GetAttr[name="dense"](%3014)
  %3016 : Tensor = prim::GetAttr[name="bias"](%3015)
  %3017 : Tensor = prim::GetAttr[name="weight"](%3015)
  %3018 : Float(128:1, 512:128) = aten::t(%3017), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.intermediate/__module.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.218 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.278, %3018), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.intermediate/__module.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.279 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.218, %3016, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.intermediate/__module.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.280 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.279), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3022 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27215.NoNorm = prim::GetAttr[name="LayerNorm"](%3013)
  %3023 : __torch__.torch.nn.modules.linear.___torch_mangle_27214.Linear = prim::GetAttr[name="dense"](%3013)
  %3024 : Tensor = prim::GetAttr[name="bias"](%3023)
  %3025 : Tensor = prim::GetAttr[name="weight"](%3023)
  %3026 : Float(512:1, 128:512) = aten::t(%3025), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.output/__module.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.219 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.280, %3026), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.output/__module.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.72 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.219, %3024, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.output/__module.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.117 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.72, %input.278, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3030 : Tensor = prim::GetAttr[name="bias"](%3022)
  %3031 : Tensor = prim::GetAttr[name="weight"](%3022)
  %3032 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.117, %3031), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.output/__module.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.281 : Float(17:1664, 13:128, 128:1) = aten::add(%3032, %3030, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.0/__module.encoder.layer.14.ffn.0.output/__module.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3034 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27222.FFNOutput = prim::GetAttr[name="output"](%2917)
  %3035 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27219.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2917)
  %3036 : __torch__.torch.nn.modules.linear.___torch_mangle_27218.Linear = prim::GetAttr[name="dense"](%3035)
  %3037 : Tensor = prim::GetAttr[name="bias"](%3036)
  %3038 : Tensor = prim::GetAttr[name="weight"](%3036)
  %3039 : Float(128:1, 512:128) = aten::t(%3038), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.intermediate/__module.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.220 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.281, %3039), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.intermediate/__module.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.282 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.220, %3037, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.intermediate/__module.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.283 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.282), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3043 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27221.NoNorm = prim::GetAttr[name="LayerNorm"](%3034)
  %3044 : __torch__.torch.nn.modules.linear.___torch_mangle_27220.Linear = prim::GetAttr[name="dense"](%3034)
  %3045 : Tensor = prim::GetAttr[name="bias"](%3044)
  %3046 : Tensor = prim::GetAttr[name="weight"](%3044)
  %3047 : Float(512:1, 128:512) = aten::t(%3046), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.output/__module.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.221 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.283, %3047), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.output/__module.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.221, %3045, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.output/__module.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.118 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.73, %input.281, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3051 : Tensor = prim::GetAttr[name="bias"](%3043)
  %3052 : Tensor = prim::GetAttr[name="weight"](%3043)
  %3053 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.118, %3052), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.output/__module.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.284 : Float(17:1664, 13:128, 128:1) = aten::add(%3053, %3051, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.1/__module.encoder.layer.14.ffn.1.output/__module.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3055 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27228.FFNOutput = prim::GetAttr[name="output"](%2915)
  %3056 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27225.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2915)
  %3057 : __torch__.torch.nn.modules.linear.___torch_mangle_27224.Linear = prim::GetAttr[name="dense"](%3056)
  %3058 : Tensor = prim::GetAttr[name="bias"](%3057)
  %3059 : Tensor = prim::GetAttr[name="weight"](%3057)
  %3060 : Float(128:1, 512:128) = aten::t(%3059), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.intermediate/__module.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.222 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.284, %3060), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.intermediate/__module.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.285 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.222, %3058, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.intermediate/__module.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.286 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.285), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3064 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27227.NoNorm = prim::GetAttr[name="LayerNorm"](%3055)
  %3065 : __torch__.torch.nn.modules.linear.___torch_mangle_27226.Linear = prim::GetAttr[name="dense"](%3055)
  %3066 : Tensor = prim::GetAttr[name="bias"](%3065)
  %3067 : Tensor = prim::GetAttr[name="weight"](%3065)
  %3068 : Float(512:1, 128:512) = aten::t(%3067), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.output/__module.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.223 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.286, %3068), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.output/__module.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.223, %3066, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.output/__module.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.119 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.74, %input.284, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3072 : Tensor = prim::GetAttr[name="bias"](%3064)
  %3073 : Tensor = prim::GetAttr[name="weight"](%3064)
  %3074 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.119, %3073), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.output/__module.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.287 : Float(17:1664, 13:128, 128:1) = aten::add(%3074, %3072, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.ffn.2/__module.encoder.layer.14.ffn.2.output/__module.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3076 : __torch__.torch.nn.modules.linear.___torch_mangle_27196.Linear = prim::GetAttr[name="dense"](%2913)
  %3077 : Tensor = prim::GetAttr[name="bias"](%3076)
  %3078 : Tensor = prim::GetAttr[name="weight"](%3076)
  %3079 : Float(128:1, 512:128) = aten::t(%3078), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.intermediate/__module.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %output.224 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.287, %3079), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.intermediate/__module.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %input.288 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.224, %3077, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.intermediate/__module.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1678:0
  %input.289 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.288), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.intermediate # torch/nn/functional.py:1119:0
  %3083 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27203.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2912)
  %3084 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27199.NoNorm = prim::GetAttr[name="LayerNorm"](%2912)
  %3085 : __torch__.torch.nn.modules.linear.___torch_mangle_27198.Linear = prim::GetAttr[name="dense"](%2912)
  %3086 : Tensor = prim::GetAttr[name="bias"](%3085)
  %3087 : Tensor = prim::GetAttr[name="weight"](%3085)
  %3088 : Float(512:1, 128:512) = aten::t(%3087), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %output.225 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.289, %3088), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %layer_output.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.225, %3086, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.120 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.15, %input.287, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output # transformers/modeling_mobilebert.py:405:0
  %3092 : Tensor = prim::GetAttr[name="bias"](%3084)
  %3093 : Tensor = prim::GetAttr[name="weight"](%3084)
  %3094 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.120, %3093), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.290 : Float(17:1664, 13:128, 128:1) = aten::add(%3094, %3092, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3096 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27201.NoNorm = prim::GetAttr[name="LayerNorm"](%3083)
  %3097 : __torch__.torch.nn.modules.linear.___torch_mangle_27200.Linear = prim::GetAttr[name="dense"](%3083)
  %3098 : Tensor = prim::GetAttr[name="bias"](%3097)
  %3099 : Tensor = prim::GetAttr[name="weight"](%3097)
  %3100 : Float(128:1, 512:128) = aten::t(%3099), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.bottleneck/__module.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.226 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.290, %3100), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.bottleneck/__module.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.291 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.226, %3098, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.bottleneck/__module.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.75 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.291, %105, %102), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.bottleneck/__module.encoder.layer.14.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.121 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.75, %input.273, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3105 : Tensor = prim::GetAttr[name="bias"](%3096)
  %3106 : Tensor = prim::GetAttr[name="weight"](%3096)
  %3107 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.121, %3106), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.bottleneck/__module.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.292 : Float(17:6656, 13:512, 512:1) = aten::add(%3107, %3105, %92), scope: __module.encoder/__module.encoder.layer.14/__module.encoder.layer.14.output/__module.encoder.layer.14.output.bottleneck/__module.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27249.MobileBertOutput = prim::GetAttr[name="output"](%123)
  %3110 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27242.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%123)
  %3111 : __torch__.torch.nn.modules.container.___torch_mangle_27275.ModuleList = prim::GetAttr[name="ffn"](%123)
  %3112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27274.FFNLayer = prim::GetAttr[name="2"](%3111)
  %3113 : __torch__.torch.nn.modules.container.___torch_mangle_27275.ModuleList = prim::GetAttr[name="ffn"](%123)
  %3114 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27268.FFNLayer = prim::GetAttr[name="1"](%3113)
  %3115 : __torch__.torch.nn.modules.container.___torch_mangle_27275.ModuleList = prim::GetAttr[name="ffn"](%123)
  %3116 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27262.FFNLayer = prim::GetAttr[name="0"](%3115)
  %3117 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27240.MobileBertAttention = prim::GetAttr[name="attention"](%123)
  %3118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27256.Bottleneck = prim::GetAttr[name="bottleneck"](%123)
  %3119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27255.BottleneckLayer = prim::GetAttr[name="attention"](%3118)
  %3120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27252.BottleneckLayer = prim::GetAttr[name="input"](%3118)
  %3121 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27251.NoNorm = prim::GetAttr[name="LayerNorm"](%3120)
  %3122 : __torch__.torch.nn.modules.linear.___torch_mangle_27250.Linear = prim::GetAttr[name="dense"](%3120)
  %3123 : Tensor = prim::GetAttr[name="bias"](%3122)
  %3124 : Tensor = prim::GetAttr[name="weight"](%3122)
  %3125 : Float(512:1, 128:512) = aten::t(%3124), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.input/__module.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.227 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3125), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.input/__module.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.122 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.227, %3123, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.input/__module.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3128 : Tensor = prim::GetAttr[name="bias"](%3121)
  %3129 : Tensor = prim::GetAttr[name="weight"](%3121)
  %3130 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.122, %3129), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.input/__module.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%3130, %3128, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.input/__module.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3132 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27254.NoNorm = prim::GetAttr[name="LayerNorm"](%3119)
  %3133 : __torch__.torch.nn.modules.linear.___torch_mangle_27253.Linear = prim::GetAttr[name="dense"](%3119)
  %3134 : Tensor = prim::GetAttr[name="bias"](%3133)
  %3135 : Tensor = prim::GetAttr[name="weight"](%3133)
  %3136 : Float(512:1, 128:512) = aten::t(%3135), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.attention/__module.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.228 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3136), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.attention/__module.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.228, %3134, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.attention/__module.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3139 : Tensor = prim::GetAttr[name="bias"](%3132)
  %3140 : Tensor = prim::GetAttr[name="weight"](%3132)
  %3141 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.123, %3140), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.attention/__module.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.293 : Float(17:1664, 13:128, 128:1) = aten::add(%3141, %3139, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.bottleneck/__module.encoder.layer.15.bottleneck.attention/__module.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3143 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.293, %residual_tensor.16)
  %3144 : Float(17:1664, 13:128, 128:1), %3145 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3143)
  %3146 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27239.MobileBertSelfOutput = prim::GetAttr[name="output"](%3117)
  %3147 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27236.MobileBertSelfAttention = prim::GetAttr[name="self"](%3117)
  %3148 : __torch__.torch.nn.modules.linear.___torch_mangle_27234.Linear = prim::GetAttr[name="value"](%3147)
  %3149 : __torch__.torch.nn.modules.linear.___torch_mangle_27233.Linear = prim::GetAttr[name="key"](%3147)
  %3150 : __torch__.torch.nn.modules.linear.___torch_mangle_27232.Linear = prim::GetAttr[name="query"](%3147)
  %3151 : Tensor = prim::GetAttr[name="bias"](%3150)
  %3152 : Tensor = prim::GetAttr[name="weight"](%3150)
  %3153 : Float(128:1, 128:128) = aten::t(%3152), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %output.229 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3144, %3153), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %x.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.229, %3151, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.query # torch/nn/functional.py:1678:0
  %3156 : Tensor = prim::GetAttr[name="bias"](%3149)
  %3157 : Tensor = prim::GetAttr[name="weight"](%3149)
  %3158 : Float(128:1, 128:128) = aten::t(%3157), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %output.230 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3144, %3158), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %x.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.230, %3156, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.key # torch/nn/functional.py:1678:0
  %3161 : Tensor = prim::GetAttr[name="bias"](%3148)
  %3162 : Tensor = prim::GetAttr[name="weight"](%3148)
  %3163 : Float(512:1, 128:512) = aten::t(%3162), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %output.231 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3163), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %x.95 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.231, %3161, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.value # torch/nn/functional.py:1678:0
  %3166 : int = aten::size(%x.91, %93), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3167 : int = aten::size(%x.91, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3168 : int[] = prim::ListConstruct(%3166, %3167, %94, %95), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self
  %x.92 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.91, %3168), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3170 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self
  %query_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.92, %3170), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3172 : int = aten::size(%x.93, %93), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3173 : int = aten::size(%x.93, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3174 : int[] = prim::ListConstruct(%3172, %3173, %94, %95), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self
  %x.94 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.93, %3174), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3176 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self
  %key_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.94, %3176), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3178 : int = aten::size(%x.95, %93), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3179 : int = aten::size(%x.95, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3180 : int[] = prim::ListConstruct(%3178, %3179, %94, %95), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self
  %x.96 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.95, %3180), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3182 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self
  %value_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.96, %3182), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3184 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.16, %98, %99), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.31 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.16, %3184), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.32 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.31, %100), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.294 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.32, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.295 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.294, %98, %101), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.295, %103, %102), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self/__module.encoder.layer.15.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.31 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.16, %value_layer.16), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:280:0
  %3191 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self
  %3192 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.31, %3191), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3192, %93), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %3194 : int = aten::size(%context_layer.32, %93), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3195 : int = aten::size(%context_layer.32, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3196 : int[] = prim::ListConstruct(%3194, %3195, %104), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self
  %input.296 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.32, %3196), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:283:0
  %3198 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27238.NoNorm = prim::GetAttr[name="LayerNorm"](%3146)
  %3199 : __torch__.torch.nn.modules.linear.___torch_mangle_27237.Linear = prim::GetAttr[name="dense"](%3146)
  %3200 : Tensor = prim::GetAttr[name="bias"](%3199)
  %3201 : Tensor = prim::GetAttr[name="weight"](%3199)
  %3202 : Float(128:1, 128:128) = aten::t(%3201), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.output/__module.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %output.232 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.296, %3202), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.output/__module.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.76 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.232, %3200, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.output/__module.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.124 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.76, %3145, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.output # transformers/modeling_mobilebert.py:301:0
  %3206 : Tensor = prim::GetAttr[name="bias"](%3198)
  %3207 : Tensor = prim::GetAttr[name="weight"](%3198)
  %3208 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.124, %3207), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.output/__module.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.297 : Float(17:1664, 13:128, 128:1) = aten::add(%3208, %3206, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.attention/__module.encoder.layer.15.attention.output/__module.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3210 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27261.FFNOutput = prim::GetAttr[name="output"](%3116)
  %3211 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27258.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3116)
  %3212 : __torch__.torch.nn.modules.linear.___torch_mangle_27257.Linear = prim::GetAttr[name="dense"](%3211)
  %3213 : Tensor = prim::GetAttr[name="bias"](%3212)
  %3214 : Tensor = prim::GetAttr[name="weight"](%3212)
  %3215 : Float(128:1, 512:128) = aten::t(%3214), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.intermediate/__module.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.233 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.297, %3215), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.intermediate/__module.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.298 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.233, %3213, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.intermediate/__module.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.299 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.298), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3219 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27260.NoNorm = prim::GetAttr[name="LayerNorm"](%3210)
  %3220 : __torch__.torch.nn.modules.linear.___torch_mangle_27259.Linear = prim::GetAttr[name="dense"](%3210)
  %3221 : Tensor = prim::GetAttr[name="bias"](%3220)
  %3222 : Tensor = prim::GetAttr[name="weight"](%3220)
  %3223 : Float(512:1, 128:512) = aten::t(%3222), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.output/__module.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.234 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.299, %3223), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.output/__module.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.234, %3221, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.output/__module.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.125 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.77, %input.297, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3227 : Tensor = prim::GetAttr[name="bias"](%3219)
  %3228 : Tensor = prim::GetAttr[name="weight"](%3219)
  %3229 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.125, %3228), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.output/__module.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.300 : Float(17:1664, 13:128, 128:1) = aten::add(%3229, %3227, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.0/__module.encoder.layer.15.ffn.0.output/__module.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3231 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27267.FFNOutput = prim::GetAttr[name="output"](%3114)
  %3232 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27264.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3114)
  %3233 : __torch__.torch.nn.modules.linear.___torch_mangle_27263.Linear = prim::GetAttr[name="dense"](%3232)
  %3234 : Tensor = prim::GetAttr[name="bias"](%3233)
  %3235 : Tensor = prim::GetAttr[name="weight"](%3233)
  %3236 : Float(128:1, 512:128) = aten::t(%3235), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.intermediate/__module.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.235 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.300, %3236), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.intermediate/__module.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.301 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.235, %3234, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.intermediate/__module.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.302 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.301), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3240 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27266.NoNorm = prim::GetAttr[name="LayerNorm"](%3231)
  %3241 : __torch__.torch.nn.modules.linear.___torch_mangle_27265.Linear = prim::GetAttr[name="dense"](%3231)
  %3242 : Tensor = prim::GetAttr[name="bias"](%3241)
  %3243 : Tensor = prim::GetAttr[name="weight"](%3241)
  %3244 : Float(512:1, 128:512) = aten::t(%3243), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.output/__module.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.236 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.302, %3244), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.output/__module.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.78 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.236, %3242, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.output/__module.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.126 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.78, %input.300, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3248 : Tensor = prim::GetAttr[name="bias"](%3240)
  %3249 : Tensor = prim::GetAttr[name="weight"](%3240)
  %3250 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.126, %3249), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.output/__module.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.303 : Float(17:1664, 13:128, 128:1) = aten::add(%3250, %3248, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.1/__module.encoder.layer.15.ffn.1.output/__module.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3252 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27273.FFNOutput = prim::GetAttr[name="output"](%3112)
  %3253 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27270.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3112)
  %3254 : __torch__.torch.nn.modules.linear.___torch_mangle_27269.Linear = prim::GetAttr[name="dense"](%3253)
  %3255 : Tensor = prim::GetAttr[name="bias"](%3254)
  %3256 : Tensor = prim::GetAttr[name="weight"](%3254)
  %3257 : Float(128:1, 512:128) = aten::t(%3256), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.intermediate/__module.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.237 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.303, %3257), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.intermediate/__module.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.304 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.237, %3255, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.intermediate/__module.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.305 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.304), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3261 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27272.NoNorm = prim::GetAttr[name="LayerNorm"](%3252)
  %3262 : __torch__.torch.nn.modules.linear.___torch_mangle_27271.Linear = prim::GetAttr[name="dense"](%3252)
  %3263 : Tensor = prim::GetAttr[name="bias"](%3262)
  %3264 : Tensor = prim::GetAttr[name="weight"](%3262)
  %3265 : Float(512:1, 128:512) = aten::t(%3264), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.output/__module.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.238 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.305, %3265), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.output/__module.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.238, %3263, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.output/__module.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.127 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.79, %input.303, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3269 : Tensor = prim::GetAttr[name="bias"](%3261)
  %3270 : Tensor = prim::GetAttr[name="weight"](%3261)
  %3271 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.127, %3270), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.output/__module.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.306 : Float(17:1664, 13:128, 128:1) = aten::add(%3271, %3269, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.ffn.2/__module.encoder.layer.15.ffn.2.output/__module.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3273 : __torch__.torch.nn.modules.linear.___torch_mangle_27241.Linear = prim::GetAttr[name="dense"](%3110)
  %3274 : Tensor = prim::GetAttr[name="bias"](%3273)
  %3275 : Tensor = prim::GetAttr[name="weight"](%3273)
  %3276 : Float(128:1, 512:128) = aten::t(%3275), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.intermediate/__module.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %output.239 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.306, %3276), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.intermediate/__module.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %input.307 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.239, %3274, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.intermediate/__module.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1678:0
  %input.308 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.307), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.intermediate # torch/nn/functional.py:1119:0
  %3280 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27248.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3109)
  %3281 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27244.NoNorm = prim::GetAttr[name="LayerNorm"](%3109)
  %3282 : __torch__.torch.nn.modules.linear.___torch_mangle_27243.Linear = prim::GetAttr[name="dense"](%3109)
  %3283 : Tensor = prim::GetAttr[name="bias"](%3282)
  %3284 : Tensor = prim::GetAttr[name="weight"](%3282)
  %3285 : Float(512:1, 128:512) = aten::t(%3284), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %output.240 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.308, %3285), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %layer_output.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.240, %3283, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.128 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.16, %input.306, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output # transformers/modeling_mobilebert.py:405:0
  %3289 : Tensor = prim::GetAttr[name="bias"](%3281)
  %3290 : Tensor = prim::GetAttr[name="weight"](%3281)
  %3291 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.128, %3290), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.309 : Float(17:1664, 13:128, 128:1) = aten::add(%3291, %3289, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3293 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27246.NoNorm = prim::GetAttr[name="LayerNorm"](%3280)
  %3294 : __torch__.torch.nn.modules.linear.___torch_mangle_27245.Linear = prim::GetAttr[name="dense"](%3280)
  %3295 : Tensor = prim::GetAttr[name="bias"](%3294)
  %3296 : Tensor = prim::GetAttr[name="weight"](%3294)
  %3297 : Float(128:1, 512:128) = aten::t(%3296), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.bottleneck/__module.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.241 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.309, %3297), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.bottleneck/__module.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.310 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.241, %3295, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.bottleneck/__module.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.80 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.310, %105, %102), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.bottleneck/__module.encoder.layer.15.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.129 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.80, %input.292, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3302 : Tensor = prim::GetAttr[name="bias"](%3293)
  %3303 : Tensor = prim::GetAttr[name="weight"](%3293)
  %3304 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.129, %3303), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.bottleneck/__module.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.311 : Float(17:6656, 13:512, 512:1) = aten::add(%3304, %3302, %92), scope: __module.encoder/__module.encoder.layer.15/__module.encoder.layer.15.output/__module.encoder.layer.15.output.bottleneck/__module.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3306 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27294.MobileBertOutput = prim::GetAttr[name="output"](%121)
  %3307 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27287.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%121)
  %3308 : __torch__.torch.nn.modules.container.___torch_mangle_27320.ModuleList = prim::GetAttr[name="ffn"](%121)
  %3309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27319.FFNLayer = prim::GetAttr[name="2"](%3308)
  %3310 : __torch__.torch.nn.modules.container.___torch_mangle_27320.ModuleList = prim::GetAttr[name="ffn"](%121)
  %3311 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27313.FFNLayer = prim::GetAttr[name="1"](%3310)
  %3312 : __torch__.torch.nn.modules.container.___torch_mangle_27320.ModuleList = prim::GetAttr[name="ffn"](%121)
  %3313 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27307.FFNLayer = prim::GetAttr[name="0"](%3312)
  %3314 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27285.MobileBertAttention = prim::GetAttr[name="attention"](%121)
  %3315 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27301.Bottleneck = prim::GetAttr[name="bottleneck"](%121)
  %3316 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27300.BottleneckLayer = prim::GetAttr[name="attention"](%3315)
  %3317 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27297.BottleneckLayer = prim::GetAttr[name="input"](%3315)
  %3318 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27296.NoNorm = prim::GetAttr[name="LayerNorm"](%3317)
  %3319 : __torch__.torch.nn.modules.linear.___torch_mangle_27295.Linear = prim::GetAttr[name="dense"](%3317)
  %3320 : Tensor = prim::GetAttr[name="bias"](%3319)
  %3321 : Tensor = prim::GetAttr[name="weight"](%3319)
  %3322 : Float(512:1, 128:512) = aten::t(%3321), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.input/__module.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.242 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3322), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.input/__module.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.130 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.242, %3320, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.input/__module.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3325 : Tensor = prim::GetAttr[name="bias"](%3318)
  %3326 : Tensor = prim::GetAttr[name="weight"](%3318)
  %3327 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.130, %3326), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.input/__module.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.17 : Float(17:1664, 13:128, 128:1) = aten::add(%3327, %3325, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.input/__module.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3329 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27299.NoNorm = prim::GetAttr[name="LayerNorm"](%3316)
  %3330 : __torch__.torch.nn.modules.linear.___torch_mangle_27298.Linear = prim::GetAttr[name="dense"](%3316)
  %3331 : Tensor = prim::GetAttr[name="bias"](%3330)
  %3332 : Tensor = prim::GetAttr[name="weight"](%3330)
  %3333 : Float(512:1, 128:512) = aten::t(%3332), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.attention/__module.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.243 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3333), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.attention/__module.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.243, %3331, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.attention/__module.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3336 : Tensor = prim::GetAttr[name="bias"](%3329)
  %3337 : Tensor = prim::GetAttr[name="weight"](%3329)
  %3338 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.131, %3337), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.attention/__module.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.312 : Float(17:1664, 13:128, 128:1) = aten::add(%3338, %3336, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.bottleneck/__module.encoder.layer.16.bottleneck.attention/__module.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3340 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.312, %residual_tensor.17)
  %3341 : Float(17:1664, 13:128, 128:1), %3342 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3340)
  %3343 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27284.MobileBertSelfOutput = prim::GetAttr[name="output"](%3314)
  %3344 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27281.MobileBertSelfAttention = prim::GetAttr[name="self"](%3314)
  %3345 : __torch__.torch.nn.modules.linear.___torch_mangle_27279.Linear = prim::GetAttr[name="value"](%3344)
  %3346 : __torch__.torch.nn.modules.linear.___torch_mangle_27278.Linear = prim::GetAttr[name="key"](%3344)
  %3347 : __torch__.torch.nn.modules.linear.___torch_mangle_27277.Linear = prim::GetAttr[name="query"](%3344)
  %3348 : Tensor = prim::GetAttr[name="bias"](%3347)
  %3349 : Tensor = prim::GetAttr[name="weight"](%3347)
  %3350 : Float(128:1, 128:128) = aten::t(%3349), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %output.244 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3341, %3350), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %x.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.244, %3348, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.query # torch/nn/functional.py:1678:0
  %3353 : Tensor = prim::GetAttr[name="bias"](%3346)
  %3354 : Tensor = prim::GetAttr[name="weight"](%3346)
  %3355 : Float(128:1, 128:128) = aten::t(%3354), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %output.245 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3341, %3355), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %x.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.245, %3353, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.key # torch/nn/functional.py:1678:0
  %3358 : Tensor = prim::GetAttr[name="bias"](%3345)
  %3359 : Tensor = prim::GetAttr[name="weight"](%3345)
  %3360 : Float(512:1, 128:512) = aten::t(%3359), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %output.246 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3360), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %x.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.246, %3358, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.value # torch/nn/functional.py:1678:0
  %3363 : int = aten::size(%x.97, %93), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3364 : int = aten::size(%x.97, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3365 : int[] = prim::ListConstruct(%3363, %3364, %94, %95), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self
  %x.98 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.97, %3365), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3367 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self
  %query_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.98, %3367), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3369 : int = aten::size(%x.99, %93), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3370 : int = aten::size(%x.99, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3371 : int[] = prim::ListConstruct(%3369, %3370, %94, %95), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self
  %x.100 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.99, %3371), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3373 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self
  %key_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.100, %3373), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3375 : int = aten::size(%x.101, %93), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3376 : int = aten::size(%x.101, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3377 : int[] = prim::ListConstruct(%3375, %3376, %94, %95), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self
  %x.102 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.101, %3377), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3379 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self
  %value_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.102, %3379), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3381 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.17, %98, %99), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.33 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.17, %3381), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.34 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.33, %100), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.313 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.34, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.314 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.313, %98, %101), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.314, %103, %102), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self/__module.encoder.layer.16.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.33 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.17, %value_layer.17), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:280:0
  %3388 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self
  %3389 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.33, %3388), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3389, %93), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %3391 : int = aten::size(%context_layer.34, %93), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3392 : int = aten::size(%context_layer.34, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3393 : int[] = prim::ListConstruct(%3391, %3392, %104), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self
  %input.315 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.34, %3393), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:283:0
  %3395 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27283.NoNorm = prim::GetAttr[name="LayerNorm"](%3343)
  %3396 : __torch__.torch.nn.modules.linear.___torch_mangle_27282.Linear = prim::GetAttr[name="dense"](%3343)
  %3397 : Tensor = prim::GetAttr[name="bias"](%3396)
  %3398 : Tensor = prim::GetAttr[name="weight"](%3396)
  %3399 : Float(128:1, 128:128) = aten::t(%3398), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.output/__module.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %output.247 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.315, %3399), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.output/__module.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.247, %3397, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.output/__module.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.132 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.81, %3342, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.output # transformers/modeling_mobilebert.py:301:0
  %3403 : Tensor = prim::GetAttr[name="bias"](%3395)
  %3404 : Tensor = prim::GetAttr[name="weight"](%3395)
  %3405 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.132, %3404), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.output/__module.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.316 : Float(17:1664, 13:128, 128:1) = aten::add(%3405, %3403, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.attention/__module.encoder.layer.16.attention.output/__module.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3407 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27306.FFNOutput = prim::GetAttr[name="output"](%3313)
  %3408 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27303.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3313)
  %3409 : __torch__.torch.nn.modules.linear.___torch_mangle_27302.Linear = prim::GetAttr[name="dense"](%3408)
  %3410 : Tensor = prim::GetAttr[name="bias"](%3409)
  %3411 : Tensor = prim::GetAttr[name="weight"](%3409)
  %3412 : Float(128:1, 512:128) = aten::t(%3411), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.intermediate/__module.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.248 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.316, %3412), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.intermediate/__module.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.317 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.248, %3410, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.intermediate/__module.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.318 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.317), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3416 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27305.NoNorm = prim::GetAttr[name="LayerNorm"](%3407)
  %3417 : __torch__.torch.nn.modules.linear.___torch_mangle_27304.Linear = prim::GetAttr[name="dense"](%3407)
  %3418 : Tensor = prim::GetAttr[name="bias"](%3417)
  %3419 : Tensor = prim::GetAttr[name="weight"](%3417)
  %3420 : Float(512:1, 128:512) = aten::t(%3419), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.output/__module.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.249 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.318, %3420), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.output/__module.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.249, %3418, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.output/__module.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.133 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.82, %input.316, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3424 : Tensor = prim::GetAttr[name="bias"](%3416)
  %3425 : Tensor = prim::GetAttr[name="weight"](%3416)
  %3426 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.133, %3425), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.output/__module.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.319 : Float(17:1664, 13:128, 128:1) = aten::add(%3426, %3424, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.0/__module.encoder.layer.16.ffn.0.output/__module.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3428 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27312.FFNOutput = prim::GetAttr[name="output"](%3311)
  %3429 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27309.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3311)
  %3430 : __torch__.torch.nn.modules.linear.___torch_mangle_27308.Linear = prim::GetAttr[name="dense"](%3429)
  %3431 : Tensor = prim::GetAttr[name="bias"](%3430)
  %3432 : Tensor = prim::GetAttr[name="weight"](%3430)
  %3433 : Float(128:1, 512:128) = aten::t(%3432), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.intermediate/__module.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.250 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.319, %3433), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.intermediate/__module.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.320 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.250, %3431, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.intermediate/__module.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.321 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.320), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3437 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27311.NoNorm = prim::GetAttr[name="LayerNorm"](%3428)
  %3438 : __torch__.torch.nn.modules.linear.___torch_mangle_27310.Linear = prim::GetAttr[name="dense"](%3428)
  %3439 : Tensor = prim::GetAttr[name="bias"](%3438)
  %3440 : Tensor = prim::GetAttr[name="weight"](%3438)
  %3441 : Float(512:1, 128:512) = aten::t(%3440), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.output/__module.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.251 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.321, %3441), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.output/__module.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.251, %3439, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.output/__module.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.134 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.83, %input.319, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3445 : Tensor = prim::GetAttr[name="bias"](%3437)
  %3446 : Tensor = prim::GetAttr[name="weight"](%3437)
  %3447 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.134, %3446), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.output/__module.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.322 : Float(17:1664, 13:128, 128:1) = aten::add(%3447, %3445, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.1/__module.encoder.layer.16.ffn.1.output/__module.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3449 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27318.FFNOutput = prim::GetAttr[name="output"](%3309)
  %3450 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27315.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3309)
  %3451 : __torch__.torch.nn.modules.linear.___torch_mangle_27314.Linear = prim::GetAttr[name="dense"](%3450)
  %3452 : Tensor = prim::GetAttr[name="bias"](%3451)
  %3453 : Tensor = prim::GetAttr[name="weight"](%3451)
  %3454 : Float(128:1, 512:128) = aten::t(%3453), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.intermediate/__module.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.252 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.322, %3454), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.intermediate/__module.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.323 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.252, %3452, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.intermediate/__module.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.324 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.323), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3458 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27317.NoNorm = prim::GetAttr[name="LayerNorm"](%3449)
  %3459 : __torch__.torch.nn.modules.linear.___torch_mangle_27316.Linear = prim::GetAttr[name="dense"](%3449)
  %3460 : Tensor = prim::GetAttr[name="bias"](%3459)
  %3461 : Tensor = prim::GetAttr[name="weight"](%3459)
  %3462 : Float(512:1, 128:512) = aten::t(%3461), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.output/__module.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.253 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.324, %3462), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.output/__module.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.84 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.253, %3460, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.output/__module.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.135 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.84, %input.322, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3466 : Tensor = prim::GetAttr[name="bias"](%3458)
  %3467 : Tensor = prim::GetAttr[name="weight"](%3458)
  %3468 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.135, %3467), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.output/__module.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.325 : Float(17:1664, 13:128, 128:1) = aten::add(%3468, %3466, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.ffn.2/__module.encoder.layer.16.ffn.2.output/__module.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3470 : __torch__.torch.nn.modules.linear.___torch_mangle_27286.Linear = prim::GetAttr[name="dense"](%3307)
  %3471 : Tensor = prim::GetAttr[name="bias"](%3470)
  %3472 : Tensor = prim::GetAttr[name="weight"](%3470)
  %3473 : Float(128:1, 512:128) = aten::t(%3472), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.intermediate/__module.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %output.254 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.325, %3473), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.intermediate/__module.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %input.326 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.254, %3471, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.intermediate/__module.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1678:0
  %input.327 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.326), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.intermediate # torch/nn/functional.py:1119:0
  %3477 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27293.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3306)
  %3478 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27289.NoNorm = prim::GetAttr[name="LayerNorm"](%3306)
  %3479 : __torch__.torch.nn.modules.linear.___torch_mangle_27288.Linear = prim::GetAttr[name="dense"](%3306)
  %3480 : Tensor = prim::GetAttr[name="bias"](%3479)
  %3481 : Tensor = prim::GetAttr[name="weight"](%3479)
  %3482 : Float(512:1, 128:512) = aten::t(%3481), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %output.255 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.327, %3482), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %layer_output.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.255, %3480, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.136 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.17, %input.325, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output # transformers/modeling_mobilebert.py:405:0
  %3486 : Tensor = prim::GetAttr[name="bias"](%3478)
  %3487 : Tensor = prim::GetAttr[name="weight"](%3478)
  %3488 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.136, %3487), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.328 : Float(17:1664, 13:128, 128:1) = aten::add(%3488, %3486, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3490 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27291.NoNorm = prim::GetAttr[name="LayerNorm"](%3477)
  %3491 : __torch__.torch.nn.modules.linear.___torch_mangle_27290.Linear = prim::GetAttr[name="dense"](%3477)
  %3492 : Tensor = prim::GetAttr[name="bias"](%3491)
  %3493 : Tensor = prim::GetAttr[name="weight"](%3491)
  %3494 : Float(128:1, 512:128) = aten::t(%3493), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.bottleneck/__module.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.256 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.328, %3494), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.bottleneck/__module.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.329 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.256, %3492, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.bottleneck/__module.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.85 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.329, %105, %102), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.bottleneck/__module.encoder.layer.16.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.137 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.85, %input.311, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3499 : Tensor = prim::GetAttr[name="bias"](%3490)
  %3500 : Tensor = prim::GetAttr[name="weight"](%3490)
  %3501 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.137, %3500), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.bottleneck/__module.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.330 : Float(17:6656, 13:512, 512:1) = aten::add(%3501, %3499, %92), scope: __module.encoder/__module.encoder.layer.16/__module.encoder.layer.16.output/__module.encoder.layer.16.output.bottleneck/__module.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3503 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27339.MobileBertOutput = prim::GetAttr[name="output"](%119)
  %3504 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27332.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%119)
  %3505 : __torch__.torch.nn.modules.container.___torch_mangle_27365.ModuleList = prim::GetAttr[name="ffn"](%119)
  %3506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27364.FFNLayer = prim::GetAttr[name="2"](%3505)
  %3507 : __torch__.torch.nn.modules.container.___torch_mangle_27365.ModuleList = prim::GetAttr[name="ffn"](%119)
  %3508 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27358.FFNLayer = prim::GetAttr[name="1"](%3507)
  %3509 : __torch__.torch.nn.modules.container.___torch_mangle_27365.ModuleList = prim::GetAttr[name="ffn"](%119)
  %3510 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27352.FFNLayer = prim::GetAttr[name="0"](%3509)
  %3511 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27330.MobileBertAttention = prim::GetAttr[name="attention"](%119)
  %3512 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27346.Bottleneck = prim::GetAttr[name="bottleneck"](%119)
  %3513 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27345.BottleneckLayer = prim::GetAttr[name="attention"](%3512)
  %3514 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27342.BottleneckLayer = prim::GetAttr[name="input"](%3512)
  %3515 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27341.NoNorm = prim::GetAttr[name="LayerNorm"](%3514)
  %3516 : __torch__.torch.nn.modules.linear.___torch_mangle_27340.Linear = prim::GetAttr[name="dense"](%3514)
  %3517 : Tensor = prim::GetAttr[name="bias"](%3516)
  %3518 : Tensor = prim::GetAttr[name="weight"](%3516)
  %3519 : Float(512:1, 128:512) = aten::t(%3518), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.input/__module.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.257 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3519), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.input/__module.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.138 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.257, %3517, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.input/__module.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3522 : Tensor = prim::GetAttr[name="bias"](%3515)
  %3523 : Tensor = prim::GetAttr[name="weight"](%3515)
  %3524 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.138, %3523), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.input/__module.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add(%3524, %3522, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.input/__module.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3526 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27344.NoNorm = prim::GetAttr[name="LayerNorm"](%3513)
  %3527 : __torch__.torch.nn.modules.linear.___torch_mangle_27343.Linear = prim::GetAttr[name="dense"](%3513)
  %3528 : Tensor = prim::GetAttr[name="bias"](%3527)
  %3529 : Tensor = prim::GetAttr[name="weight"](%3527)
  %3530 : Float(512:1, 128:512) = aten::t(%3529), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.attention/__module.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.258 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3530), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.attention/__module.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.258, %3528, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.attention/__module.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3533 : Tensor = prim::GetAttr[name="bias"](%3526)
  %3534 : Tensor = prim::GetAttr[name="weight"](%3526)
  %3535 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.139, %3534), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.attention/__module.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.331 : Float(17:1664, 13:128, 128:1) = aten::add(%3535, %3533, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.bottleneck/__module.encoder.layer.17.bottleneck.attention/__module.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3537 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.331, %residual_tensor.18)
  %3538 : Float(17:1664, 13:128, 128:1), %3539 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3537)
  %3540 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27329.MobileBertSelfOutput = prim::GetAttr[name="output"](%3511)
  %3541 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27326.MobileBertSelfAttention = prim::GetAttr[name="self"](%3511)
  %3542 : __torch__.torch.nn.modules.linear.___torch_mangle_27324.Linear = prim::GetAttr[name="value"](%3541)
  %3543 : __torch__.torch.nn.modules.linear.___torch_mangle_27323.Linear = prim::GetAttr[name="key"](%3541)
  %3544 : __torch__.torch.nn.modules.linear.___torch_mangle_27322.Linear = prim::GetAttr[name="query"](%3541)
  %3545 : Tensor = prim::GetAttr[name="bias"](%3544)
  %3546 : Tensor = prim::GetAttr[name="weight"](%3544)
  %3547 : Float(128:1, 128:128) = aten::t(%3546), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %output.259 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3538, %3547), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %x.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.259, %3545, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.query # torch/nn/functional.py:1678:0
  %3550 : Tensor = prim::GetAttr[name="bias"](%3543)
  %3551 : Tensor = prim::GetAttr[name="weight"](%3543)
  %3552 : Float(128:1, 128:128) = aten::t(%3551), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %output.260 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3538, %3552), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %x.105 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.260, %3550, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.key # torch/nn/functional.py:1678:0
  %3555 : Tensor = prim::GetAttr[name="bias"](%3542)
  %3556 : Tensor = prim::GetAttr[name="weight"](%3542)
  %3557 : Float(512:1, 128:512) = aten::t(%3556), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %output.261 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3557), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %x.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.261, %3555, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.value # torch/nn/functional.py:1678:0
  %3560 : int = aten::size(%x.103, %93), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3561 : int = aten::size(%x.103, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3562 : int[] = prim::ListConstruct(%3560, %3561, %94, %95), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self
  %x.104 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.103, %3562), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3564 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self
  %query_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.104, %3564), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3566 : int = aten::size(%x.105, %93), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3567 : int = aten::size(%x.105, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3568 : int[] = prim::ListConstruct(%3566, %3567, %94, %95), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self
  %x.106 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.105, %3568), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3570 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self
  %key_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.106, %3570), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3572 : int = aten::size(%x.107, %93), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3573 : int = aten::size(%x.107, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3574 : int[] = prim::ListConstruct(%3572, %3573, %94, %95), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self
  %x.108 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.107, %3574), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3576 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self
  %value_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.108, %3576), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3578 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.18, %98, %99), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.35 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.18, %3578), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.36 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.35, %100), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.332 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.36, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.333 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.332, %98, %101), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.333, %103, %102), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self/__module.encoder.layer.17.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.35 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.18, %value_layer.18), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:280:0
  %3585 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self
  %3586 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.35, %3585), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3586, %93), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %3588 : int = aten::size(%context_layer.36, %93), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3589 : int = aten::size(%context_layer.36, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3590 : int[] = prim::ListConstruct(%3588, %3589, %104), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self
  %input.334 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.36, %3590), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:283:0
  %3592 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27328.NoNorm = prim::GetAttr[name="LayerNorm"](%3540)
  %3593 : __torch__.torch.nn.modules.linear.___torch_mangle_27327.Linear = prim::GetAttr[name="dense"](%3540)
  %3594 : Tensor = prim::GetAttr[name="bias"](%3593)
  %3595 : Tensor = prim::GetAttr[name="weight"](%3593)
  %3596 : Float(128:1, 128:128) = aten::t(%3595), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.output/__module.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %output.262 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.334, %3596), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.output/__module.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.86 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.262, %3594, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.output/__module.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.140 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.86, %3539, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.output # transformers/modeling_mobilebert.py:301:0
  %3600 : Tensor = prim::GetAttr[name="bias"](%3592)
  %3601 : Tensor = prim::GetAttr[name="weight"](%3592)
  %3602 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.140, %3601), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.output/__module.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.335 : Float(17:1664, 13:128, 128:1) = aten::add(%3602, %3600, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.attention/__module.encoder.layer.17.attention.output/__module.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3604 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27351.FFNOutput = prim::GetAttr[name="output"](%3510)
  %3605 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27348.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3510)
  %3606 : __torch__.torch.nn.modules.linear.___torch_mangle_27347.Linear = prim::GetAttr[name="dense"](%3605)
  %3607 : Tensor = prim::GetAttr[name="bias"](%3606)
  %3608 : Tensor = prim::GetAttr[name="weight"](%3606)
  %3609 : Float(128:1, 512:128) = aten::t(%3608), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.intermediate/__module.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.263 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.335, %3609), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.intermediate/__module.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.336 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.263, %3607, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.intermediate/__module.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.337 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.336), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3613 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27350.NoNorm = prim::GetAttr[name="LayerNorm"](%3604)
  %3614 : __torch__.torch.nn.modules.linear.___torch_mangle_27349.Linear = prim::GetAttr[name="dense"](%3604)
  %3615 : Tensor = prim::GetAttr[name="bias"](%3614)
  %3616 : Tensor = prim::GetAttr[name="weight"](%3614)
  %3617 : Float(512:1, 128:512) = aten::t(%3616), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.output/__module.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.264 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.337, %3617), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.output/__module.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.264, %3615, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.output/__module.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.141 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.87, %input.335, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3621 : Tensor = prim::GetAttr[name="bias"](%3613)
  %3622 : Tensor = prim::GetAttr[name="weight"](%3613)
  %3623 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.141, %3622), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.output/__module.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.338 : Float(17:1664, 13:128, 128:1) = aten::add(%3623, %3621, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.0/__module.encoder.layer.17.ffn.0.output/__module.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3625 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27357.FFNOutput = prim::GetAttr[name="output"](%3508)
  %3626 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27354.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3508)
  %3627 : __torch__.torch.nn.modules.linear.___torch_mangle_27353.Linear = prim::GetAttr[name="dense"](%3626)
  %3628 : Tensor = prim::GetAttr[name="bias"](%3627)
  %3629 : Tensor = prim::GetAttr[name="weight"](%3627)
  %3630 : Float(128:1, 512:128) = aten::t(%3629), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.intermediate/__module.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.265 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.338, %3630), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.intermediate/__module.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.339 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.265, %3628, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.intermediate/__module.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.340 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.339), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3634 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27356.NoNorm = prim::GetAttr[name="LayerNorm"](%3625)
  %3635 : __torch__.torch.nn.modules.linear.___torch_mangle_27355.Linear = prim::GetAttr[name="dense"](%3625)
  %3636 : Tensor = prim::GetAttr[name="bias"](%3635)
  %3637 : Tensor = prim::GetAttr[name="weight"](%3635)
  %3638 : Float(512:1, 128:512) = aten::t(%3637), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.output/__module.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.266 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.340, %3638), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.output/__module.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.88 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.266, %3636, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.output/__module.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.142 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.88, %input.338, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3642 : Tensor = prim::GetAttr[name="bias"](%3634)
  %3643 : Tensor = prim::GetAttr[name="weight"](%3634)
  %3644 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.142, %3643), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.output/__module.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.341 : Float(17:1664, 13:128, 128:1) = aten::add(%3644, %3642, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.1/__module.encoder.layer.17.ffn.1.output/__module.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3646 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27363.FFNOutput = prim::GetAttr[name="output"](%3506)
  %3647 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27360.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3506)
  %3648 : __torch__.torch.nn.modules.linear.___torch_mangle_27359.Linear = prim::GetAttr[name="dense"](%3647)
  %3649 : Tensor = prim::GetAttr[name="bias"](%3648)
  %3650 : Tensor = prim::GetAttr[name="weight"](%3648)
  %3651 : Float(128:1, 512:128) = aten::t(%3650), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.intermediate/__module.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.267 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.341, %3651), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.intermediate/__module.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.342 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.267, %3649, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.intermediate/__module.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.343 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.342), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3655 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27362.NoNorm = prim::GetAttr[name="LayerNorm"](%3646)
  %3656 : __torch__.torch.nn.modules.linear.___torch_mangle_27361.Linear = prim::GetAttr[name="dense"](%3646)
  %3657 : Tensor = prim::GetAttr[name="bias"](%3656)
  %3658 : Tensor = prim::GetAttr[name="weight"](%3656)
  %3659 : Float(512:1, 128:512) = aten::t(%3658), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.output/__module.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.268 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.343, %3659), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.output/__module.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.268, %3657, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.output/__module.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.143 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.89, %input.341, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3663 : Tensor = prim::GetAttr[name="bias"](%3655)
  %3664 : Tensor = prim::GetAttr[name="weight"](%3655)
  %3665 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.143, %3664), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.output/__module.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.344 : Float(17:1664, 13:128, 128:1) = aten::add(%3665, %3663, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.ffn.2/__module.encoder.layer.17.ffn.2.output/__module.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3667 : __torch__.torch.nn.modules.linear.___torch_mangle_27331.Linear = prim::GetAttr[name="dense"](%3504)
  %3668 : Tensor = prim::GetAttr[name="bias"](%3667)
  %3669 : Tensor = prim::GetAttr[name="weight"](%3667)
  %3670 : Float(128:1, 512:128) = aten::t(%3669), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.intermediate/__module.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %output.269 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.344, %3670), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.intermediate/__module.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %input.345 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.269, %3668, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.intermediate/__module.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1678:0
  %input.346 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.345), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.intermediate # torch/nn/functional.py:1119:0
  %3674 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27338.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3503)
  %3675 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27334.NoNorm = prim::GetAttr[name="LayerNorm"](%3503)
  %3676 : __torch__.torch.nn.modules.linear.___torch_mangle_27333.Linear = prim::GetAttr[name="dense"](%3503)
  %3677 : Tensor = prim::GetAttr[name="bias"](%3676)
  %3678 : Tensor = prim::GetAttr[name="weight"](%3676)
  %3679 : Float(512:1, 128:512) = aten::t(%3678), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %output.270 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.346, %3679), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %layer_output.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.270, %3677, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.144 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.18, %input.344, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output # transformers/modeling_mobilebert.py:405:0
  %3683 : Tensor = prim::GetAttr[name="bias"](%3675)
  %3684 : Tensor = prim::GetAttr[name="weight"](%3675)
  %3685 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.144, %3684), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.347 : Float(17:1664, 13:128, 128:1) = aten::add(%3685, %3683, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3687 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27336.NoNorm = prim::GetAttr[name="LayerNorm"](%3674)
  %3688 : __torch__.torch.nn.modules.linear.___torch_mangle_27335.Linear = prim::GetAttr[name="dense"](%3674)
  %3689 : Tensor = prim::GetAttr[name="bias"](%3688)
  %3690 : Tensor = prim::GetAttr[name="weight"](%3688)
  %3691 : Float(128:1, 512:128) = aten::t(%3690), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.bottleneck/__module.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.271 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.347, %3691), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.bottleneck/__module.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.348 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.271, %3689, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.bottleneck/__module.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.90 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.348, %105, %102), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.bottleneck/__module.encoder.layer.17.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.145 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.90, %input.330, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3696 : Tensor = prim::GetAttr[name="bias"](%3687)
  %3697 : Tensor = prim::GetAttr[name="weight"](%3687)
  %3698 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.145, %3697), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.bottleneck/__module.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.349 : Float(17:6656, 13:512, 512:1) = aten::add(%3698, %3696, %92), scope: __module.encoder/__module.encoder.layer.17/__module.encoder.layer.17.output/__module.encoder.layer.17.output.bottleneck/__module.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3700 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27384.MobileBertOutput = prim::GetAttr[name="output"](%117)
  %3701 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27377.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%117)
  %3702 : __torch__.torch.nn.modules.container.___torch_mangle_27410.ModuleList = prim::GetAttr[name="ffn"](%117)
  %3703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27409.FFNLayer = prim::GetAttr[name="2"](%3702)
  %3704 : __torch__.torch.nn.modules.container.___torch_mangle_27410.ModuleList = prim::GetAttr[name="ffn"](%117)
  %3705 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27403.FFNLayer = prim::GetAttr[name="1"](%3704)
  %3706 : __torch__.torch.nn.modules.container.___torch_mangle_27410.ModuleList = prim::GetAttr[name="ffn"](%117)
  %3707 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27397.FFNLayer = prim::GetAttr[name="0"](%3706)
  %3708 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27375.MobileBertAttention = prim::GetAttr[name="attention"](%117)
  %3709 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27391.Bottleneck = prim::GetAttr[name="bottleneck"](%117)
  %3710 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27390.BottleneckLayer = prim::GetAttr[name="attention"](%3709)
  %3711 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27387.BottleneckLayer = prim::GetAttr[name="input"](%3709)
  %3712 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27386.NoNorm = prim::GetAttr[name="LayerNorm"](%3711)
  %3713 : __torch__.torch.nn.modules.linear.___torch_mangle_27385.Linear = prim::GetAttr[name="dense"](%3711)
  %3714 : Tensor = prim::GetAttr[name="bias"](%3713)
  %3715 : Tensor = prim::GetAttr[name="weight"](%3713)
  %3716 : Float(512:1, 128:512) = aten::t(%3715), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.input/__module.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.272 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3716), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.input/__module.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.146 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.272, %3714, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.input/__module.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3719 : Tensor = prim::GetAttr[name="bias"](%3712)
  %3720 : Tensor = prim::GetAttr[name="weight"](%3712)
  %3721 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.146, %3720), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.input/__module.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add(%3721, %3719, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.input/__module.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3723 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27389.NoNorm = prim::GetAttr[name="LayerNorm"](%3710)
  %3724 : __torch__.torch.nn.modules.linear.___torch_mangle_27388.Linear = prim::GetAttr[name="dense"](%3710)
  %3725 : Tensor = prim::GetAttr[name="bias"](%3724)
  %3726 : Tensor = prim::GetAttr[name="weight"](%3724)
  %3727 : Float(512:1, 128:512) = aten::t(%3726), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.attention/__module.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.273 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3727), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.attention/__module.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.147 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.273, %3725, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.attention/__module.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3730 : Tensor = prim::GetAttr[name="bias"](%3723)
  %3731 : Tensor = prim::GetAttr[name="weight"](%3723)
  %3732 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.147, %3731), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.attention/__module.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.350 : Float(17:1664, 13:128, 128:1) = aten::add(%3732, %3730, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.bottleneck/__module.encoder.layer.18.bottleneck.attention/__module.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3734 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.350, %residual_tensor.19)
  %3735 : Float(17:1664, 13:128, 128:1), %3736 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3734)
  %3737 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27374.MobileBertSelfOutput = prim::GetAttr[name="output"](%3708)
  %3738 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27371.MobileBertSelfAttention = prim::GetAttr[name="self"](%3708)
  %3739 : __torch__.torch.nn.modules.linear.___torch_mangle_27369.Linear = prim::GetAttr[name="value"](%3738)
  %3740 : __torch__.torch.nn.modules.linear.___torch_mangle_27368.Linear = prim::GetAttr[name="key"](%3738)
  %3741 : __torch__.torch.nn.modules.linear.___torch_mangle_27367.Linear = prim::GetAttr[name="query"](%3738)
  %3742 : Tensor = prim::GetAttr[name="bias"](%3741)
  %3743 : Tensor = prim::GetAttr[name="weight"](%3741)
  %3744 : Float(128:1, 128:128) = aten::t(%3743), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %output.274 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3735, %3744), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %x.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.274, %3742, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.query # torch/nn/functional.py:1678:0
  %3747 : Tensor = prim::GetAttr[name="bias"](%3740)
  %3748 : Tensor = prim::GetAttr[name="weight"](%3740)
  %3749 : Float(128:1, 128:128) = aten::t(%3748), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %output.275 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3735, %3749), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %x.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.275, %3747, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.key # torch/nn/functional.py:1678:0
  %3752 : Tensor = prim::GetAttr[name="bias"](%3739)
  %3753 : Tensor = prim::GetAttr[name="weight"](%3739)
  %3754 : Float(512:1, 128:512) = aten::t(%3753), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %output.276 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3754), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %x.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.276, %3752, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.value # torch/nn/functional.py:1678:0
  %3757 : int = aten::size(%x.109, %93), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3758 : int = aten::size(%x.109, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3759 : int[] = prim::ListConstruct(%3757, %3758, %94, %95), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self
  %x.110 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.109, %3759), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3761 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self
  %query_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.110, %3761), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3763 : int = aten::size(%x.111, %93), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3764 : int = aten::size(%x.111, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3765 : int[] = prim::ListConstruct(%3763, %3764, %94, %95), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self
  %x.112 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.111, %3765), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3767 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self
  %key_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.112, %3767), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3769 : int = aten::size(%x.113, %93), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3770 : int = aten::size(%x.113, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3771 : int[] = prim::ListConstruct(%3769, %3770, %94, %95), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self
  %x.114 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.113, %3771), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3773 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self
  %value_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.114, %3773), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3775 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.19, %98, %99), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.37 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.19, %3775), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.38 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.37, %100), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.351 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.38, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.352 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.351, %98, %101), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.352, %103, %102), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self/__module.encoder.layer.18.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.37 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.19, %value_layer.19), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:280:0
  %3782 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self
  %3783 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.37, %3782), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3783, %93), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %3785 : int = aten::size(%context_layer.38, %93), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3786 : int = aten::size(%context_layer.38, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3787 : int[] = prim::ListConstruct(%3785, %3786, %104), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self
  %input.353 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.38, %3787), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:283:0
  %3789 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27373.NoNorm = prim::GetAttr[name="LayerNorm"](%3737)
  %3790 : __torch__.torch.nn.modules.linear.___torch_mangle_27372.Linear = prim::GetAttr[name="dense"](%3737)
  %3791 : Tensor = prim::GetAttr[name="bias"](%3790)
  %3792 : Tensor = prim::GetAttr[name="weight"](%3790)
  %3793 : Float(128:1, 128:128) = aten::t(%3792), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.output/__module.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %output.277 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.353, %3793), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.output/__module.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.277, %3791, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.output/__module.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.148 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.91, %3736, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.output # transformers/modeling_mobilebert.py:301:0
  %3797 : Tensor = prim::GetAttr[name="bias"](%3789)
  %3798 : Tensor = prim::GetAttr[name="weight"](%3789)
  %3799 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.148, %3798), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.output/__module.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.354 : Float(17:1664, 13:128, 128:1) = aten::add(%3799, %3797, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.attention/__module.encoder.layer.18.attention.output/__module.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3801 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27396.FFNOutput = prim::GetAttr[name="output"](%3707)
  %3802 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27393.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3707)
  %3803 : __torch__.torch.nn.modules.linear.___torch_mangle_27392.Linear = prim::GetAttr[name="dense"](%3802)
  %3804 : Tensor = prim::GetAttr[name="bias"](%3803)
  %3805 : Tensor = prim::GetAttr[name="weight"](%3803)
  %3806 : Float(128:1, 512:128) = aten::t(%3805), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.intermediate/__module.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.278 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.354, %3806), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.intermediate/__module.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.355 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.278, %3804, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.intermediate/__module.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.356 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.355), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3810 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27395.NoNorm = prim::GetAttr[name="LayerNorm"](%3801)
  %3811 : __torch__.torch.nn.modules.linear.___torch_mangle_27394.Linear = prim::GetAttr[name="dense"](%3801)
  %3812 : Tensor = prim::GetAttr[name="bias"](%3811)
  %3813 : Tensor = prim::GetAttr[name="weight"](%3811)
  %3814 : Float(512:1, 128:512) = aten::t(%3813), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.output/__module.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.279 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.356, %3814), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.output/__module.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.92 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.279, %3812, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.output/__module.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.149 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.92, %input.354, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3818 : Tensor = prim::GetAttr[name="bias"](%3810)
  %3819 : Tensor = prim::GetAttr[name="weight"](%3810)
  %3820 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.149, %3819), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.output/__module.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.357 : Float(17:1664, 13:128, 128:1) = aten::add(%3820, %3818, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.0/__module.encoder.layer.18.ffn.0.output/__module.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3822 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27402.FFNOutput = prim::GetAttr[name="output"](%3705)
  %3823 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27399.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3705)
  %3824 : __torch__.torch.nn.modules.linear.___torch_mangle_27398.Linear = prim::GetAttr[name="dense"](%3823)
  %3825 : Tensor = prim::GetAttr[name="bias"](%3824)
  %3826 : Tensor = prim::GetAttr[name="weight"](%3824)
  %3827 : Float(128:1, 512:128) = aten::t(%3826), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.intermediate/__module.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.280 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.357, %3827), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.intermediate/__module.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.358 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.280, %3825, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.intermediate/__module.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.359 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.358), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3831 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27401.NoNorm = prim::GetAttr[name="LayerNorm"](%3822)
  %3832 : __torch__.torch.nn.modules.linear.___torch_mangle_27400.Linear = prim::GetAttr[name="dense"](%3822)
  %3833 : Tensor = prim::GetAttr[name="bias"](%3832)
  %3834 : Tensor = prim::GetAttr[name="weight"](%3832)
  %3835 : Float(512:1, 128:512) = aten::t(%3834), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.output/__module.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.281 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.359, %3835), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.output/__module.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.281, %3833, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.output/__module.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.150 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.93, %input.357, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3839 : Tensor = prim::GetAttr[name="bias"](%3831)
  %3840 : Tensor = prim::GetAttr[name="weight"](%3831)
  %3841 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.150, %3840), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.output/__module.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.360 : Float(17:1664, 13:128, 128:1) = aten::add(%3841, %3839, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.1/__module.encoder.layer.18.ffn.1.output/__module.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3843 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27408.FFNOutput = prim::GetAttr[name="output"](%3703)
  %3844 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27405.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3703)
  %3845 : __torch__.torch.nn.modules.linear.___torch_mangle_27404.Linear = prim::GetAttr[name="dense"](%3844)
  %3846 : Tensor = prim::GetAttr[name="bias"](%3845)
  %3847 : Tensor = prim::GetAttr[name="weight"](%3845)
  %3848 : Float(128:1, 512:128) = aten::t(%3847), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.intermediate/__module.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.282 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.360, %3848), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.intermediate/__module.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.361 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.282, %3846, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.intermediate/__module.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.362 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.361), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3852 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27407.NoNorm = prim::GetAttr[name="LayerNorm"](%3843)
  %3853 : __torch__.torch.nn.modules.linear.___torch_mangle_27406.Linear = prim::GetAttr[name="dense"](%3843)
  %3854 : Tensor = prim::GetAttr[name="bias"](%3853)
  %3855 : Tensor = prim::GetAttr[name="weight"](%3853)
  %3856 : Float(512:1, 128:512) = aten::t(%3855), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.output/__module.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.283 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.362, %3856), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.output/__module.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.94 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.283, %3854, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.output/__module.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.151 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.94, %input.360, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3860 : Tensor = prim::GetAttr[name="bias"](%3852)
  %3861 : Tensor = prim::GetAttr[name="weight"](%3852)
  %3862 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.151, %3861), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.output/__module.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.363 : Float(17:1664, 13:128, 128:1) = aten::add(%3862, %3860, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.ffn.2/__module.encoder.layer.18.ffn.2.output/__module.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3864 : __torch__.torch.nn.modules.linear.___torch_mangle_27376.Linear = prim::GetAttr[name="dense"](%3701)
  %3865 : Tensor = prim::GetAttr[name="bias"](%3864)
  %3866 : Tensor = prim::GetAttr[name="weight"](%3864)
  %3867 : Float(128:1, 512:128) = aten::t(%3866), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.intermediate/__module.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %output.284 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.363, %3867), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.intermediate/__module.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %input.364 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.284, %3865, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.intermediate/__module.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1678:0
  %input.365 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.364), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.intermediate # torch/nn/functional.py:1119:0
  %3871 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27383.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3700)
  %3872 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27379.NoNorm = prim::GetAttr[name="LayerNorm"](%3700)
  %3873 : __torch__.torch.nn.modules.linear.___torch_mangle_27378.Linear = prim::GetAttr[name="dense"](%3700)
  %3874 : Tensor = prim::GetAttr[name="bias"](%3873)
  %3875 : Tensor = prim::GetAttr[name="weight"](%3873)
  %3876 : Float(512:1, 128:512) = aten::t(%3875), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %output.285 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.365, %3876), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %layer_output.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.285, %3874, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.152 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.19, %input.363, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output # transformers/modeling_mobilebert.py:405:0
  %3880 : Tensor = prim::GetAttr[name="bias"](%3872)
  %3881 : Tensor = prim::GetAttr[name="weight"](%3872)
  %3882 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.152, %3881), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.366 : Float(17:1664, 13:128, 128:1) = aten::add(%3882, %3880, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3884 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27381.NoNorm = prim::GetAttr[name="LayerNorm"](%3871)
  %3885 : __torch__.torch.nn.modules.linear.___torch_mangle_27380.Linear = prim::GetAttr[name="dense"](%3871)
  %3886 : Tensor = prim::GetAttr[name="bias"](%3885)
  %3887 : Tensor = prim::GetAttr[name="weight"](%3885)
  %3888 : Float(128:1, 512:128) = aten::t(%3887), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.bottleneck/__module.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.286 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.366, %3888), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.bottleneck/__module.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.367 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.286, %3886, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.bottleneck/__module.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.95 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.367, %105, %102), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.bottleneck/__module.encoder.layer.18.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.153 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.95, %input.349, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3893 : Tensor = prim::GetAttr[name="bias"](%3884)
  %3894 : Tensor = prim::GetAttr[name="weight"](%3884)
  %3895 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.153, %3894), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.bottleneck/__module.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.368 : Float(17:6656, 13:512, 512:1) = aten::add(%3895, %3893, %92), scope: __module.encoder/__module.encoder.layer.18/__module.encoder.layer.18.output/__module.encoder.layer.18.output.bottleneck/__module.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3897 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27429.MobileBertOutput = prim::GetAttr[name="output"](%115)
  %3898 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27422.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%115)
  %3899 : __torch__.torch.nn.modules.container.___torch_mangle_27455.ModuleList = prim::GetAttr[name="ffn"](%115)
  %3900 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27454.FFNLayer = prim::GetAttr[name="2"](%3899)
  %3901 : __torch__.torch.nn.modules.container.___torch_mangle_27455.ModuleList = prim::GetAttr[name="ffn"](%115)
  %3902 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27448.FFNLayer = prim::GetAttr[name="1"](%3901)
  %3903 : __torch__.torch.nn.modules.container.___torch_mangle_27455.ModuleList = prim::GetAttr[name="ffn"](%115)
  %3904 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27442.FFNLayer = prim::GetAttr[name="0"](%3903)
  %3905 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27420.MobileBertAttention = prim::GetAttr[name="attention"](%115)
  %3906 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27436.Bottleneck = prim::GetAttr[name="bottleneck"](%115)
  %3907 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27435.BottleneckLayer = prim::GetAttr[name="attention"](%3906)
  %3908 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27432.BottleneckLayer = prim::GetAttr[name="input"](%3906)
  %3909 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27431.NoNorm = prim::GetAttr[name="LayerNorm"](%3908)
  %3910 : __torch__.torch.nn.modules.linear.___torch_mangle_27430.Linear = prim::GetAttr[name="dense"](%3908)
  %3911 : Tensor = prim::GetAttr[name="bias"](%3910)
  %3912 : Tensor = prim::GetAttr[name="weight"](%3910)
  %3913 : Float(512:1, 128:512) = aten::t(%3912), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.input/__module.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.287 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3913), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.input/__module.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.154 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.287, %3911, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.input/__module.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3916 : Tensor = prim::GetAttr[name="bias"](%3909)
  %3917 : Tensor = prim::GetAttr[name="weight"](%3909)
  %3918 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.154, %3917), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.input/__module.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%3918, %3916, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.input/__module.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3920 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27434.NoNorm = prim::GetAttr[name="LayerNorm"](%3907)
  %3921 : __torch__.torch.nn.modules.linear.___torch_mangle_27433.Linear = prim::GetAttr[name="dense"](%3907)
  %3922 : Tensor = prim::GetAttr[name="bias"](%3921)
  %3923 : Tensor = prim::GetAttr[name="weight"](%3921)
  %3924 : Float(512:1, 128:512) = aten::t(%3923), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.attention/__module.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.288 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3924), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.attention/__module.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.155 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.288, %3922, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.attention/__module.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3927 : Tensor = prim::GetAttr[name="bias"](%3920)
  %3928 : Tensor = prim::GetAttr[name="weight"](%3920)
  %3929 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.155, %3928), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.attention/__module.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.369 : Float(17:1664, 13:128, 128:1) = aten::add(%3929, %3927, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.bottleneck/__module.encoder.layer.19.bottleneck.attention/__module.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3931 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.369, %residual_tensor.20)
  %3932 : Float(17:1664, 13:128, 128:1), %3933 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3931)
  %3934 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27419.MobileBertSelfOutput = prim::GetAttr[name="output"](%3905)
  %3935 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27416.MobileBertSelfAttention = prim::GetAttr[name="self"](%3905)
  %3936 : __torch__.torch.nn.modules.linear.___torch_mangle_27414.Linear = prim::GetAttr[name="value"](%3935)
  %3937 : __torch__.torch.nn.modules.linear.___torch_mangle_27413.Linear = prim::GetAttr[name="key"](%3935)
  %3938 : __torch__.torch.nn.modules.linear.___torch_mangle_27412.Linear = prim::GetAttr[name="query"](%3935)
  %3939 : Tensor = prim::GetAttr[name="bias"](%3938)
  %3940 : Tensor = prim::GetAttr[name="weight"](%3938)
  %3941 : Float(128:1, 128:128) = aten::t(%3940), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %output.289 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3932, %3941), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %x.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.289, %3939, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.query # torch/nn/functional.py:1678:0
  %3944 : Tensor = prim::GetAttr[name="bias"](%3937)
  %3945 : Tensor = prim::GetAttr[name="weight"](%3937)
  %3946 : Float(128:1, 128:128) = aten::t(%3945), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %output.290 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3932, %3946), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %x.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.290, %3944, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.key # torch/nn/functional.py:1678:0
  %3949 : Tensor = prim::GetAttr[name="bias"](%3936)
  %3950 : Tensor = prim::GetAttr[name="weight"](%3936)
  %3951 : Float(512:1, 128:512) = aten::t(%3950), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %output.291 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3951), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %x.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.291, %3949, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.value # torch/nn/functional.py:1678:0
  %3954 : int = aten::size(%x.115, %93), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3955 : int = aten::size(%x.115, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3956 : int[] = prim::ListConstruct(%3954, %3955, %94, %95), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self
  %x.116 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.115, %3956), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3958 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self
  %query_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.116, %3958), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3960 : int = aten::size(%x.117, %93), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3961 : int = aten::size(%x.117, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3962 : int[] = prim::ListConstruct(%3960, %3961, %94, %95), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self
  %x.118 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.117, %3962), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3964 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self
  %key_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.118, %3964), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3966 : int = aten::size(%x.119, %93), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3967 : int = aten::size(%x.119, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3968 : int[] = prim::ListConstruct(%3966, %3967, %94, %95), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self
  %x.120 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.119, %3968), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3970 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self
  %value_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.120, %3970), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3972 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.20, %98, %99), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.39 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.20, %3972), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.40 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.39, %100), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.370 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.40, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.371 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.370, %98, %101), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.371, %103, %102), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self/__module.encoder.layer.19.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.39 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.20, %value_layer.20), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:280:0
  %3979 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self
  %3980 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.39, %3979), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3980, %93), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %3982 : int = aten::size(%context_layer.40, %93), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3983 : int = aten::size(%context_layer.40, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3984 : int[] = prim::ListConstruct(%3982, %3983, %104), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self
  %input.372 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.40, %3984), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:283:0
  %3986 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27418.NoNorm = prim::GetAttr[name="LayerNorm"](%3934)
  %3987 : __torch__.torch.nn.modules.linear.___torch_mangle_27417.Linear = prim::GetAttr[name="dense"](%3934)
  %3988 : Tensor = prim::GetAttr[name="bias"](%3987)
  %3989 : Tensor = prim::GetAttr[name="weight"](%3987)
  %3990 : Float(128:1, 128:128) = aten::t(%3989), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.output/__module.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %output.292 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.372, %3990), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.output/__module.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.96 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.292, %3988, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.output/__module.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.156 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.96, %3933, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.output # transformers/modeling_mobilebert.py:301:0
  %3994 : Tensor = prim::GetAttr[name="bias"](%3986)
  %3995 : Tensor = prim::GetAttr[name="weight"](%3986)
  %3996 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.156, %3995), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.output/__module.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.373 : Float(17:1664, 13:128, 128:1) = aten::add(%3996, %3994, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.attention/__module.encoder.layer.19.attention.output/__module.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3998 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27441.FFNOutput = prim::GetAttr[name="output"](%3904)
  %3999 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27438.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3904)
  %4000 : __torch__.torch.nn.modules.linear.___torch_mangle_27437.Linear = prim::GetAttr[name="dense"](%3999)
  %4001 : Tensor = prim::GetAttr[name="bias"](%4000)
  %4002 : Tensor = prim::GetAttr[name="weight"](%4000)
  %4003 : Float(128:1, 512:128) = aten::t(%4002), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.intermediate/__module.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.293 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.373, %4003), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.intermediate/__module.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.374 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.293, %4001, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.intermediate/__module.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.375 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.374), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4007 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27440.NoNorm = prim::GetAttr[name="LayerNorm"](%3998)
  %4008 : __torch__.torch.nn.modules.linear.___torch_mangle_27439.Linear = prim::GetAttr[name="dense"](%3998)
  %4009 : Tensor = prim::GetAttr[name="bias"](%4008)
  %4010 : Tensor = prim::GetAttr[name="weight"](%4008)
  %4011 : Float(512:1, 128:512) = aten::t(%4010), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.output/__module.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.294 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.375, %4011), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.output/__module.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.294, %4009, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.output/__module.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.157 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.97, %input.373, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4015 : Tensor = prim::GetAttr[name="bias"](%4007)
  %4016 : Tensor = prim::GetAttr[name="weight"](%4007)
  %4017 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.157, %4016), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.output/__module.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.376 : Float(17:1664, 13:128, 128:1) = aten::add(%4017, %4015, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.0/__module.encoder.layer.19.ffn.0.output/__module.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4019 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27447.FFNOutput = prim::GetAttr[name="output"](%3902)
  %4020 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27444.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3902)
  %4021 : __torch__.torch.nn.modules.linear.___torch_mangle_27443.Linear = prim::GetAttr[name="dense"](%4020)
  %4022 : Tensor = prim::GetAttr[name="bias"](%4021)
  %4023 : Tensor = prim::GetAttr[name="weight"](%4021)
  %4024 : Float(128:1, 512:128) = aten::t(%4023), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.intermediate/__module.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.295 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.376, %4024), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.intermediate/__module.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.377 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.295, %4022, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.intermediate/__module.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.378 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.377), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4028 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27446.NoNorm = prim::GetAttr[name="LayerNorm"](%4019)
  %4029 : __torch__.torch.nn.modules.linear.___torch_mangle_27445.Linear = prim::GetAttr[name="dense"](%4019)
  %4030 : Tensor = prim::GetAttr[name="bias"](%4029)
  %4031 : Tensor = prim::GetAttr[name="weight"](%4029)
  %4032 : Float(512:1, 128:512) = aten::t(%4031), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.output/__module.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.296 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.378, %4032), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.output/__module.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.296, %4030, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.output/__module.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.158 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.98, %input.376, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4036 : Tensor = prim::GetAttr[name="bias"](%4028)
  %4037 : Tensor = prim::GetAttr[name="weight"](%4028)
  %4038 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.158, %4037), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.output/__module.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.379 : Float(17:1664, 13:128, 128:1) = aten::add(%4038, %4036, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.1/__module.encoder.layer.19.ffn.1.output/__module.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4040 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27453.FFNOutput = prim::GetAttr[name="output"](%3900)
  %4041 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27450.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3900)
  %4042 : __torch__.torch.nn.modules.linear.___torch_mangle_27449.Linear = prim::GetAttr[name="dense"](%4041)
  %4043 : Tensor = prim::GetAttr[name="bias"](%4042)
  %4044 : Tensor = prim::GetAttr[name="weight"](%4042)
  %4045 : Float(128:1, 512:128) = aten::t(%4044), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.intermediate/__module.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.297 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.379, %4045), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.intermediate/__module.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.380 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.297, %4043, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.intermediate/__module.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.381 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.380), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4049 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27452.NoNorm = prim::GetAttr[name="LayerNorm"](%4040)
  %4050 : __torch__.torch.nn.modules.linear.___torch_mangle_27451.Linear = prim::GetAttr[name="dense"](%4040)
  %4051 : Tensor = prim::GetAttr[name="bias"](%4050)
  %4052 : Tensor = prim::GetAttr[name="weight"](%4050)
  %4053 : Float(512:1, 128:512) = aten::t(%4052), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.output/__module.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.298 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.381, %4053), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.output/__module.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.298, %4051, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.output/__module.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.159 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.99, %input.379, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4057 : Tensor = prim::GetAttr[name="bias"](%4049)
  %4058 : Tensor = prim::GetAttr[name="weight"](%4049)
  %4059 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.159, %4058), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.output/__module.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.382 : Float(17:1664, 13:128, 128:1) = aten::add(%4059, %4057, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.ffn.2/__module.encoder.layer.19.ffn.2.output/__module.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4061 : __torch__.torch.nn.modules.linear.___torch_mangle_27421.Linear = prim::GetAttr[name="dense"](%3898)
  %4062 : Tensor = prim::GetAttr[name="bias"](%4061)
  %4063 : Tensor = prim::GetAttr[name="weight"](%4061)
  %4064 : Float(128:1, 512:128) = aten::t(%4063), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.intermediate/__module.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %output.299 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.382, %4064), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.intermediate/__module.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %input.383 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.299, %4062, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.intermediate/__module.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1678:0
  %input.384 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.383), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.intermediate # torch/nn/functional.py:1119:0
  %4068 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27428.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3897)
  %4069 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27424.NoNorm = prim::GetAttr[name="LayerNorm"](%3897)
  %4070 : __torch__.torch.nn.modules.linear.___torch_mangle_27423.Linear = prim::GetAttr[name="dense"](%3897)
  %4071 : Tensor = prim::GetAttr[name="bias"](%4070)
  %4072 : Tensor = prim::GetAttr[name="weight"](%4070)
  %4073 : Float(512:1, 128:512) = aten::t(%4072), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %output.300 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.384, %4073), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %layer_output.20 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.300, %4071, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.160 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.20, %input.382, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output # transformers/modeling_mobilebert.py:405:0
  %4077 : Tensor = prim::GetAttr[name="bias"](%4069)
  %4078 : Tensor = prim::GetAttr[name="weight"](%4069)
  %4079 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.160, %4078), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.385 : Float(17:1664, 13:128, 128:1) = aten::add(%4079, %4077, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4081 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27426.NoNorm = prim::GetAttr[name="LayerNorm"](%4068)
  %4082 : __torch__.torch.nn.modules.linear.___torch_mangle_27425.Linear = prim::GetAttr[name="dense"](%4068)
  %4083 : Tensor = prim::GetAttr[name="bias"](%4082)
  %4084 : Tensor = prim::GetAttr[name="weight"](%4082)
  %4085 : Float(128:1, 512:128) = aten::t(%4084), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.bottleneck/__module.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.301 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.385, %4085), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.bottleneck/__module.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.386 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.301, %4083, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.bottleneck/__module.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.100 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.386, %105, %102), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.bottleneck/__module.encoder.layer.19.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.161 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.100, %input.368, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4090 : Tensor = prim::GetAttr[name="bias"](%4081)
  %4091 : Tensor = prim::GetAttr[name="weight"](%4081)
  %4092 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.161, %4091), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.bottleneck/__module.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.387 : Float(17:6656, 13:512, 512:1) = aten::add(%4092, %4090, %92), scope: __module.encoder/__module.encoder.layer.19/__module.encoder.layer.19.output/__module.encoder.layer.19.output.bottleneck/__module.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4094 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27474.MobileBertOutput = prim::GetAttr[name="output"](%113)
  %4095 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27467.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%113)
  %4096 : __torch__.torch.nn.modules.container.___torch_mangle_27500.ModuleList = prim::GetAttr[name="ffn"](%113)
  %4097 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27499.FFNLayer = prim::GetAttr[name="2"](%4096)
  %4098 : __torch__.torch.nn.modules.container.___torch_mangle_27500.ModuleList = prim::GetAttr[name="ffn"](%113)
  %4099 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27493.FFNLayer = prim::GetAttr[name="1"](%4098)
  %4100 : __torch__.torch.nn.modules.container.___torch_mangle_27500.ModuleList = prim::GetAttr[name="ffn"](%113)
  %4101 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27487.FFNLayer = prim::GetAttr[name="0"](%4100)
  %4102 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27465.MobileBertAttention = prim::GetAttr[name="attention"](%113)
  %4103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27481.Bottleneck = prim::GetAttr[name="bottleneck"](%113)
  %4104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27480.BottleneckLayer = prim::GetAttr[name="attention"](%4103)
  %4105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27477.BottleneckLayer = prim::GetAttr[name="input"](%4103)
  %4106 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27476.NoNorm = prim::GetAttr[name="LayerNorm"](%4105)
  %4107 : __torch__.torch.nn.modules.linear.___torch_mangle_27475.Linear = prim::GetAttr[name="dense"](%4105)
  %4108 : Tensor = prim::GetAttr[name="bias"](%4107)
  %4109 : Tensor = prim::GetAttr[name="weight"](%4107)
  %4110 : Float(512:1, 128:512) = aten::t(%4109), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.input/__module.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.302 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4110), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.input/__module.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.162 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.302, %4108, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.input/__module.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4113 : Tensor = prim::GetAttr[name="bias"](%4106)
  %4114 : Tensor = prim::GetAttr[name="weight"](%4106)
  %4115 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.162, %4114), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.input/__module.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%4115, %4113, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.input/__module.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4117 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27479.NoNorm = prim::GetAttr[name="LayerNorm"](%4104)
  %4118 : __torch__.torch.nn.modules.linear.___torch_mangle_27478.Linear = prim::GetAttr[name="dense"](%4104)
  %4119 : Tensor = prim::GetAttr[name="bias"](%4118)
  %4120 : Tensor = prim::GetAttr[name="weight"](%4118)
  %4121 : Float(512:1, 128:512) = aten::t(%4120), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.attention/__module.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.303 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4121), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.attention/__module.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.163 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.303, %4119, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.attention/__module.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4124 : Tensor = prim::GetAttr[name="bias"](%4117)
  %4125 : Tensor = prim::GetAttr[name="weight"](%4117)
  %4126 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.163, %4125), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.attention/__module.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.388 : Float(17:1664, 13:128, 128:1) = aten::add(%4126, %4124, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.bottleneck/__module.encoder.layer.20.bottleneck.attention/__module.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4128 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.388, %residual_tensor.21)
  %4129 : Float(17:1664, 13:128, 128:1), %4130 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4128)
  %4131 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27464.MobileBertSelfOutput = prim::GetAttr[name="output"](%4102)
  %4132 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27461.MobileBertSelfAttention = prim::GetAttr[name="self"](%4102)
  %4133 : __torch__.torch.nn.modules.linear.___torch_mangle_27459.Linear = prim::GetAttr[name="value"](%4132)
  %4134 : __torch__.torch.nn.modules.linear.___torch_mangle_27458.Linear = prim::GetAttr[name="key"](%4132)
  %4135 : __torch__.torch.nn.modules.linear.___torch_mangle_27457.Linear = prim::GetAttr[name="query"](%4132)
  %4136 : Tensor = prim::GetAttr[name="bias"](%4135)
  %4137 : Tensor = prim::GetAttr[name="weight"](%4135)
  %4138 : Float(128:1, 128:128) = aten::t(%4137), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %output.304 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4129, %4138), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %x.121 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.304, %4136, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.query # torch/nn/functional.py:1678:0
  %4141 : Tensor = prim::GetAttr[name="bias"](%4134)
  %4142 : Tensor = prim::GetAttr[name="weight"](%4134)
  %4143 : Float(128:1, 128:128) = aten::t(%4142), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %output.305 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4129, %4143), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %x.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.305, %4141, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.key # torch/nn/functional.py:1678:0
  %4146 : Tensor = prim::GetAttr[name="bias"](%4133)
  %4147 : Tensor = prim::GetAttr[name="weight"](%4133)
  %4148 : Float(512:1, 128:512) = aten::t(%4147), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %output.306 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4148), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %x.125 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.306, %4146, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.value # torch/nn/functional.py:1678:0
  %4151 : int = aten::size(%x.121, %93), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4152 : int = aten::size(%x.121, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4153 : int[] = prim::ListConstruct(%4151, %4152, %94, %95), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self
  %x.122 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.121, %4153), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4155 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self
  %query_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.122, %4155), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4157 : int = aten::size(%x.123, %93), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4158 : int = aten::size(%x.123, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4159 : int[] = prim::ListConstruct(%4157, %4158, %94, %95), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self
  %x.124 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.123, %4159), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4161 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self
  %key_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.124, %4161), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4163 : int = aten::size(%x.125, %93), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4164 : int = aten::size(%x.125, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4165 : int[] = prim::ListConstruct(%4163, %4164, %94, %95), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self
  %x.126 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.125, %4165), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4167 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self
  %value_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.126, %4167), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4169 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.21, %98, %99), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.41 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.21, %4169), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.42 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.41, %100), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.389 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.42, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.390 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.389, %98, %101), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.390, %103, %102), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self/__module.encoder.layer.20.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.41 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.21, %value_layer.21), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:280:0
  %4176 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self
  %4177 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.41, %4176), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4177, %93), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %4179 : int = aten::size(%context_layer.42, %93), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4180 : int = aten::size(%context_layer.42, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4181 : int[] = prim::ListConstruct(%4179, %4180, %104), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self
  %input.391 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.42, %4181), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:283:0
  %4183 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27463.NoNorm = prim::GetAttr[name="LayerNorm"](%4131)
  %4184 : __torch__.torch.nn.modules.linear.___torch_mangle_27462.Linear = prim::GetAttr[name="dense"](%4131)
  %4185 : Tensor = prim::GetAttr[name="bias"](%4184)
  %4186 : Tensor = prim::GetAttr[name="weight"](%4184)
  %4187 : Float(128:1, 128:128) = aten::t(%4186), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.output/__module.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %output.307 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.391, %4187), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.output/__module.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.307, %4185, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.output/__module.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.164 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.101, %4130, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.output # transformers/modeling_mobilebert.py:301:0
  %4191 : Tensor = prim::GetAttr[name="bias"](%4183)
  %4192 : Tensor = prim::GetAttr[name="weight"](%4183)
  %4193 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.164, %4192), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.output/__module.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.392 : Float(17:1664, 13:128, 128:1) = aten::add(%4193, %4191, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.attention/__module.encoder.layer.20.attention.output/__module.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4195 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27486.FFNOutput = prim::GetAttr[name="output"](%4101)
  %4196 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27483.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4101)
  %4197 : __torch__.torch.nn.modules.linear.___torch_mangle_27482.Linear = prim::GetAttr[name="dense"](%4196)
  %4198 : Tensor = prim::GetAttr[name="bias"](%4197)
  %4199 : Tensor = prim::GetAttr[name="weight"](%4197)
  %4200 : Float(128:1, 512:128) = aten::t(%4199), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.intermediate/__module.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.308 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.392, %4200), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.intermediate/__module.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.393 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.308, %4198, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.intermediate/__module.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.394 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.393), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4204 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27485.NoNorm = prim::GetAttr[name="LayerNorm"](%4195)
  %4205 : __torch__.torch.nn.modules.linear.___torch_mangle_27484.Linear = prim::GetAttr[name="dense"](%4195)
  %4206 : Tensor = prim::GetAttr[name="bias"](%4205)
  %4207 : Tensor = prim::GetAttr[name="weight"](%4205)
  %4208 : Float(512:1, 128:512) = aten::t(%4207), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.output/__module.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.309 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.394, %4208), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.output/__module.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.102 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.309, %4206, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.output/__module.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.165 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.102, %input.392, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4212 : Tensor = prim::GetAttr[name="bias"](%4204)
  %4213 : Tensor = prim::GetAttr[name="weight"](%4204)
  %4214 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.165, %4213), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.output/__module.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.395 : Float(17:1664, 13:128, 128:1) = aten::add(%4214, %4212, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.0/__module.encoder.layer.20.ffn.0.output/__module.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4216 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27492.FFNOutput = prim::GetAttr[name="output"](%4099)
  %4217 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27489.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4099)
  %4218 : __torch__.torch.nn.modules.linear.___torch_mangle_27488.Linear = prim::GetAttr[name="dense"](%4217)
  %4219 : Tensor = prim::GetAttr[name="bias"](%4218)
  %4220 : Tensor = prim::GetAttr[name="weight"](%4218)
  %4221 : Float(128:1, 512:128) = aten::t(%4220), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.intermediate/__module.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.310 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.395, %4221), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.intermediate/__module.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.396 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.310, %4219, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.intermediate/__module.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.397 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.396), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4225 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27491.NoNorm = prim::GetAttr[name="LayerNorm"](%4216)
  %4226 : __torch__.torch.nn.modules.linear.___torch_mangle_27490.Linear = prim::GetAttr[name="dense"](%4216)
  %4227 : Tensor = prim::GetAttr[name="bias"](%4226)
  %4228 : Tensor = prim::GetAttr[name="weight"](%4226)
  %4229 : Float(512:1, 128:512) = aten::t(%4228), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.output/__module.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.311 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.397, %4229), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.output/__module.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.311, %4227, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.output/__module.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.166 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.103, %input.395, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4233 : Tensor = prim::GetAttr[name="bias"](%4225)
  %4234 : Tensor = prim::GetAttr[name="weight"](%4225)
  %4235 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.166, %4234), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.output/__module.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.398 : Float(17:1664, 13:128, 128:1) = aten::add(%4235, %4233, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.1/__module.encoder.layer.20.ffn.1.output/__module.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4237 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27498.FFNOutput = prim::GetAttr[name="output"](%4097)
  %4238 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27495.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4097)
  %4239 : __torch__.torch.nn.modules.linear.___torch_mangle_27494.Linear = prim::GetAttr[name="dense"](%4238)
  %4240 : Tensor = prim::GetAttr[name="bias"](%4239)
  %4241 : Tensor = prim::GetAttr[name="weight"](%4239)
  %4242 : Float(128:1, 512:128) = aten::t(%4241), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.intermediate/__module.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.312 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.398, %4242), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.intermediate/__module.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.399 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.312, %4240, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.intermediate/__module.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.400 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.399), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4246 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27497.NoNorm = prim::GetAttr[name="LayerNorm"](%4237)
  %4247 : __torch__.torch.nn.modules.linear.___torch_mangle_27496.Linear = prim::GetAttr[name="dense"](%4237)
  %4248 : Tensor = prim::GetAttr[name="bias"](%4247)
  %4249 : Tensor = prim::GetAttr[name="weight"](%4247)
  %4250 : Float(512:1, 128:512) = aten::t(%4249), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.output/__module.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.313 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.400, %4250), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.output/__module.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.104 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.313, %4248, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.output/__module.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.167 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.104, %input.398, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4254 : Tensor = prim::GetAttr[name="bias"](%4246)
  %4255 : Tensor = prim::GetAttr[name="weight"](%4246)
  %4256 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.167, %4255), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.output/__module.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.401 : Float(17:1664, 13:128, 128:1) = aten::add(%4256, %4254, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.ffn.2/__module.encoder.layer.20.ffn.2.output/__module.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4258 : __torch__.torch.nn.modules.linear.___torch_mangle_27466.Linear = prim::GetAttr[name="dense"](%4095)
  %4259 : Tensor = prim::GetAttr[name="bias"](%4258)
  %4260 : Tensor = prim::GetAttr[name="weight"](%4258)
  %4261 : Float(128:1, 512:128) = aten::t(%4260), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.intermediate/__module.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %output.314 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.401, %4261), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.intermediate/__module.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %input.402 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.314, %4259, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.intermediate/__module.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1678:0
  %input.403 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.402), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.intermediate # torch/nn/functional.py:1119:0
  %4265 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27473.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4094)
  %4266 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27469.NoNorm = prim::GetAttr[name="LayerNorm"](%4094)
  %4267 : __torch__.torch.nn.modules.linear.___torch_mangle_27468.Linear = prim::GetAttr[name="dense"](%4094)
  %4268 : Tensor = prim::GetAttr[name="bias"](%4267)
  %4269 : Tensor = prim::GetAttr[name="weight"](%4267)
  %4270 : Float(512:1, 128:512) = aten::t(%4269), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %output.315 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.403, %4270), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %layer_output.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.315, %4268, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.168 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.21, %input.401, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output # transformers/modeling_mobilebert.py:405:0
  %4274 : Tensor = prim::GetAttr[name="bias"](%4266)
  %4275 : Tensor = prim::GetAttr[name="weight"](%4266)
  %4276 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.168, %4275), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.404 : Float(17:1664, 13:128, 128:1) = aten::add(%4276, %4274, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4278 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27471.NoNorm = prim::GetAttr[name="LayerNorm"](%4265)
  %4279 : __torch__.torch.nn.modules.linear.___torch_mangle_27470.Linear = prim::GetAttr[name="dense"](%4265)
  %4280 : Tensor = prim::GetAttr[name="bias"](%4279)
  %4281 : Tensor = prim::GetAttr[name="weight"](%4279)
  %4282 : Float(128:1, 512:128) = aten::t(%4281), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.bottleneck/__module.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.316 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.404, %4282), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.bottleneck/__module.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.405 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.316, %4280, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.bottleneck/__module.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.105 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.405, %105, %102), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.bottleneck/__module.encoder.layer.20.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.169 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.105, %input.387, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4287 : Tensor = prim::GetAttr[name="bias"](%4278)
  %4288 : Tensor = prim::GetAttr[name="weight"](%4278)
  %4289 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.169, %4288), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.bottleneck/__module.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.406 : Float(17:6656, 13:512, 512:1) = aten::add(%4289, %4287, %92), scope: __module.encoder/__module.encoder.layer.20/__module.encoder.layer.20.output/__module.encoder.layer.20.output.bottleneck/__module.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4291 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27519.MobileBertOutput = prim::GetAttr[name="output"](%111)
  %4292 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27512.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%111)
  %4293 : __torch__.torch.nn.modules.container.___torch_mangle_27545.ModuleList = prim::GetAttr[name="ffn"](%111)
  %4294 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27544.FFNLayer = prim::GetAttr[name="2"](%4293)
  %4295 : __torch__.torch.nn.modules.container.___torch_mangle_27545.ModuleList = prim::GetAttr[name="ffn"](%111)
  %4296 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27538.FFNLayer = prim::GetAttr[name="1"](%4295)
  %4297 : __torch__.torch.nn.modules.container.___torch_mangle_27545.ModuleList = prim::GetAttr[name="ffn"](%111)
  %4298 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27532.FFNLayer = prim::GetAttr[name="0"](%4297)
  %4299 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27510.MobileBertAttention = prim::GetAttr[name="attention"](%111)
  %4300 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27526.Bottleneck = prim::GetAttr[name="bottleneck"](%111)
  %4301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27525.BottleneckLayer = prim::GetAttr[name="attention"](%4300)
  %4302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27522.BottleneckLayer = prim::GetAttr[name="input"](%4300)
  %4303 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27521.NoNorm = prim::GetAttr[name="LayerNorm"](%4302)
  %4304 : __torch__.torch.nn.modules.linear.___torch_mangle_27520.Linear = prim::GetAttr[name="dense"](%4302)
  %4305 : Tensor = prim::GetAttr[name="bias"](%4304)
  %4306 : Tensor = prim::GetAttr[name="weight"](%4304)
  %4307 : Float(512:1, 128:512) = aten::t(%4306), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.input/__module.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.317 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4307), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.input/__module.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.170 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.317, %4305, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.input/__module.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4310 : Tensor = prim::GetAttr[name="bias"](%4303)
  %4311 : Tensor = prim::GetAttr[name="weight"](%4303)
  %4312 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.170, %4311), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.input/__module.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%4312, %4310, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.input/__module.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4314 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27524.NoNorm = prim::GetAttr[name="LayerNorm"](%4301)
  %4315 : __torch__.torch.nn.modules.linear.___torch_mangle_27523.Linear = prim::GetAttr[name="dense"](%4301)
  %4316 : Tensor = prim::GetAttr[name="bias"](%4315)
  %4317 : Tensor = prim::GetAttr[name="weight"](%4315)
  %4318 : Float(512:1, 128:512) = aten::t(%4317), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.attention/__module.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.318 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4318), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.attention/__module.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.171 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.318, %4316, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.attention/__module.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4321 : Tensor = prim::GetAttr[name="bias"](%4314)
  %4322 : Tensor = prim::GetAttr[name="weight"](%4314)
  %4323 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.171, %4322), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.attention/__module.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.407 : Float(17:1664, 13:128, 128:1) = aten::add(%4323, %4321, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.bottleneck/__module.encoder.layer.21.bottleneck.attention/__module.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4325 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.407, %residual_tensor.22)
  %4326 : Float(17:1664, 13:128, 128:1), %4327 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4325)
  %4328 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27509.MobileBertSelfOutput = prim::GetAttr[name="output"](%4299)
  %4329 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27506.MobileBertSelfAttention = prim::GetAttr[name="self"](%4299)
  %4330 : __torch__.torch.nn.modules.linear.___torch_mangle_27504.Linear = prim::GetAttr[name="value"](%4329)
  %4331 : __torch__.torch.nn.modules.linear.___torch_mangle_27503.Linear = prim::GetAttr[name="key"](%4329)
  %4332 : __torch__.torch.nn.modules.linear.___torch_mangle_27502.Linear = prim::GetAttr[name="query"](%4329)
  %4333 : Tensor = prim::GetAttr[name="bias"](%4332)
  %4334 : Tensor = prim::GetAttr[name="weight"](%4332)
  %4335 : Float(128:1, 128:128) = aten::t(%4334), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %output.319 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4326, %4335), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %x.127 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.319, %4333, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.query # torch/nn/functional.py:1678:0
  %4338 : Tensor = prim::GetAttr[name="bias"](%4331)
  %4339 : Tensor = prim::GetAttr[name="weight"](%4331)
  %4340 : Float(128:1, 128:128) = aten::t(%4339), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %output.320 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4326, %4340), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %x.129 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.320, %4338, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.key # torch/nn/functional.py:1678:0
  %4343 : Tensor = prim::GetAttr[name="bias"](%4330)
  %4344 : Tensor = prim::GetAttr[name="weight"](%4330)
  %4345 : Float(512:1, 128:512) = aten::t(%4344), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %output.321 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4345), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %x.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.321, %4343, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.value # torch/nn/functional.py:1678:0
  %4348 : int = aten::size(%x.127, %93), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4349 : int = aten::size(%x.127, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4350 : int[] = prim::ListConstruct(%4348, %4349, %94, %95), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self
  %x.128 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.127, %4350), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4352 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self
  %query_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.128, %4352), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4354 : int = aten::size(%x.129, %93), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4355 : int = aten::size(%x.129, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4356 : int[] = prim::ListConstruct(%4354, %4355, %94, %95), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self
  %x.130 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.129, %4356), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4358 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self
  %key_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.130, %4358), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4360 : int = aten::size(%x.131, %93), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4361 : int = aten::size(%x.131, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4362 : int[] = prim::ListConstruct(%4360, %4361, %94, %95), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self
  %x.132 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.131, %4362), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4364 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self
  %value_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.132, %4364), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4366 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.22, %98, %99), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.43 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.22, %4366), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.44 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.43, %100), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.408 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.44, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.409 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.408, %98, %101), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.409, %103, %102), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self/__module.encoder.layer.21.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.43 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.22, %value_layer.22), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:280:0
  %4373 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self
  %4374 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.43, %4373), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4374, %93), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %4376 : int = aten::size(%context_layer.44, %93), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4377 : int = aten::size(%context_layer.44, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4378 : int[] = prim::ListConstruct(%4376, %4377, %104), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self
  %input.410 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.44, %4378), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:283:0
  %4380 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27508.NoNorm = prim::GetAttr[name="LayerNorm"](%4328)
  %4381 : __torch__.torch.nn.modules.linear.___torch_mangle_27507.Linear = prim::GetAttr[name="dense"](%4328)
  %4382 : Tensor = prim::GetAttr[name="bias"](%4381)
  %4383 : Tensor = prim::GetAttr[name="weight"](%4381)
  %4384 : Float(128:1, 128:128) = aten::t(%4383), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.output/__module.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %output.322 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.410, %4384), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.output/__module.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.322, %4382, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.output/__module.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.172 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.106, %4327, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.output # transformers/modeling_mobilebert.py:301:0
  %4388 : Tensor = prim::GetAttr[name="bias"](%4380)
  %4389 : Tensor = prim::GetAttr[name="weight"](%4380)
  %4390 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.172, %4389), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.output/__module.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.411 : Float(17:1664, 13:128, 128:1) = aten::add(%4390, %4388, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.attention/__module.encoder.layer.21.attention.output/__module.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4392 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27531.FFNOutput = prim::GetAttr[name="output"](%4298)
  %4393 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27528.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4298)
  %4394 : __torch__.torch.nn.modules.linear.___torch_mangle_27527.Linear = prim::GetAttr[name="dense"](%4393)
  %4395 : Tensor = prim::GetAttr[name="bias"](%4394)
  %4396 : Tensor = prim::GetAttr[name="weight"](%4394)
  %4397 : Float(128:1, 512:128) = aten::t(%4396), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.intermediate/__module.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.323 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.411, %4397), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.intermediate/__module.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.412 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.323, %4395, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.intermediate/__module.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.413 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.412), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4401 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27530.NoNorm = prim::GetAttr[name="LayerNorm"](%4392)
  %4402 : __torch__.torch.nn.modules.linear.___torch_mangle_27529.Linear = prim::GetAttr[name="dense"](%4392)
  %4403 : Tensor = prim::GetAttr[name="bias"](%4402)
  %4404 : Tensor = prim::GetAttr[name="weight"](%4402)
  %4405 : Float(512:1, 128:512) = aten::t(%4404), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.output/__module.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.324 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.413, %4405), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.output/__module.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.324, %4403, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.output/__module.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.173 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.107, %input.411, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4409 : Tensor = prim::GetAttr[name="bias"](%4401)
  %4410 : Tensor = prim::GetAttr[name="weight"](%4401)
  %4411 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.173, %4410), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.output/__module.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.414 : Float(17:1664, 13:128, 128:1) = aten::add(%4411, %4409, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.0/__module.encoder.layer.21.ffn.0.output/__module.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4413 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27537.FFNOutput = prim::GetAttr[name="output"](%4296)
  %4414 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27534.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4296)
  %4415 : __torch__.torch.nn.modules.linear.___torch_mangle_27533.Linear = prim::GetAttr[name="dense"](%4414)
  %4416 : Tensor = prim::GetAttr[name="bias"](%4415)
  %4417 : Tensor = prim::GetAttr[name="weight"](%4415)
  %4418 : Float(128:1, 512:128) = aten::t(%4417), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.intermediate/__module.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.325 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.414, %4418), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.intermediate/__module.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.415 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.325, %4416, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.intermediate/__module.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.416 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.415), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4422 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27536.NoNorm = prim::GetAttr[name="LayerNorm"](%4413)
  %4423 : __torch__.torch.nn.modules.linear.___torch_mangle_27535.Linear = prim::GetAttr[name="dense"](%4413)
  %4424 : Tensor = prim::GetAttr[name="bias"](%4423)
  %4425 : Tensor = prim::GetAttr[name="weight"](%4423)
  %4426 : Float(512:1, 128:512) = aten::t(%4425), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.output/__module.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.326 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.416, %4426), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.output/__module.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.108 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.326, %4424, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.output/__module.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.174 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.108, %input.414, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4430 : Tensor = prim::GetAttr[name="bias"](%4422)
  %4431 : Tensor = prim::GetAttr[name="weight"](%4422)
  %4432 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.174, %4431), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.output/__module.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.417 : Float(17:1664, 13:128, 128:1) = aten::add(%4432, %4430, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.1/__module.encoder.layer.21.ffn.1.output/__module.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4434 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27543.FFNOutput = prim::GetAttr[name="output"](%4294)
  %4435 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27540.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4294)
  %4436 : __torch__.torch.nn.modules.linear.___torch_mangle_27539.Linear = prim::GetAttr[name="dense"](%4435)
  %4437 : Tensor = prim::GetAttr[name="bias"](%4436)
  %4438 : Tensor = prim::GetAttr[name="weight"](%4436)
  %4439 : Float(128:1, 512:128) = aten::t(%4438), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.intermediate/__module.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.327 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.417, %4439), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.intermediate/__module.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.418 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.327, %4437, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.intermediate/__module.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.419 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.418), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4443 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27542.NoNorm = prim::GetAttr[name="LayerNorm"](%4434)
  %4444 : __torch__.torch.nn.modules.linear.___torch_mangle_27541.Linear = prim::GetAttr[name="dense"](%4434)
  %4445 : Tensor = prim::GetAttr[name="bias"](%4444)
  %4446 : Tensor = prim::GetAttr[name="weight"](%4444)
  %4447 : Float(512:1, 128:512) = aten::t(%4446), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.output/__module.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.328 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.419, %4447), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.output/__module.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.328, %4445, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.output/__module.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.175 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.109, %input.417, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4451 : Tensor = prim::GetAttr[name="bias"](%4443)
  %4452 : Tensor = prim::GetAttr[name="weight"](%4443)
  %4453 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.175, %4452), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.output/__module.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.420 : Float(17:1664, 13:128, 128:1) = aten::add(%4453, %4451, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.ffn.2/__module.encoder.layer.21.ffn.2.output/__module.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4455 : __torch__.torch.nn.modules.linear.___torch_mangle_27511.Linear = prim::GetAttr[name="dense"](%4292)
  %4456 : Tensor = prim::GetAttr[name="bias"](%4455)
  %4457 : Tensor = prim::GetAttr[name="weight"](%4455)
  %4458 : Float(128:1, 512:128) = aten::t(%4457), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.intermediate/__module.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %output.329 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.420, %4458), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.intermediate/__module.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %input.421 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.329, %4456, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.intermediate/__module.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1678:0
  %input.422 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.421), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.intermediate # torch/nn/functional.py:1119:0
  %4462 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27518.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4291)
  %4463 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27514.NoNorm = prim::GetAttr[name="LayerNorm"](%4291)
  %4464 : __torch__.torch.nn.modules.linear.___torch_mangle_27513.Linear = prim::GetAttr[name="dense"](%4291)
  %4465 : Tensor = prim::GetAttr[name="bias"](%4464)
  %4466 : Tensor = prim::GetAttr[name="weight"](%4464)
  %4467 : Float(512:1, 128:512) = aten::t(%4466), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %output.330 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.422, %4467), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %layer_output.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.330, %4465, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.176 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.22, %input.420, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output # transformers/modeling_mobilebert.py:405:0
  %4471 : Tensor = prim::GetAttr[name="bias"](%4463)
  %4472 : Tensor = prim::GetAttr[name="weight"](%4463)
  %4473 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.176, %4472), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.423 : Float(17:1664, 13:128, 128:1) = aten::add(%4473, %4471, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4475 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27516.NoNorm = prim::GetAttr[name="LayerNorm"](%4462)
  %4476 : __torch__.torch.nn.modules.linear.___torch_mangle_27515.Linear = prim::GetAttr[name="dense"](%4462)
  %4477 : Tensor = prim::GetAttr[name="bias"](%4476)
  %4478 : Tensor = prim::GetAttr[name="weight"](%4476)
  %4479 : Float(128:1, 512:128) = aten::t(%4478), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.bottleneck/__module.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.331 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.423, %4479), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.bottleneck/__module.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.424 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.331, %4477, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.bottleneck/__module.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.110 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.424, %105, %102), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.bottleneck/__module.encoder.layer.21.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.177 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.110, %input.406, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4484 : Tensor = prim::GetAttr[name="bias"](%4475)
  %4485 : Tensor = prim::GetAttr[name="weight"](%4475)
  %4486 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.177, %4485), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.bottleneck/__module.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.425 : Float(17:6656, 13:512, 512:1) = aten::add(%4486, %4484, %92), scope: __module.encoder/__module.encoder.layer.21/__module.encoder.layer.21.output/__module.encoder.layer.21.output.bottleneck/__module.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4488 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27564.MobileBertOutput = prim::GetAttr[name="output"](%109)
  %4489 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27557.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%109)
  %4490 : __torch__.torch.nn.modules.container.___torch_mangle_27590.ModuleList = prim::GetAttr[name="ffn"](%109)
  %4491 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27589.FFNLayer = prim::GetAttr[name="2"](%4490)
  %4492 : __torch__.torch.nn.modules.container.___torch_mangle_27590.ModuleList = prim::GetAttr[name="ffn"](%109)
  %4493 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27583.FFNLayer = prim::GetAttr[name="1"](%4492)
  %4494 : __torch__.torch.nn.modules.container.___torch_mangle_27590.ModuleList = prim::GetAttr[name="ffn"](%109)
  %4495 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27577.FFNLayer = prim::GetAttr[name="0"](%4494)
  %4496 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27555.MobileBertAttention = prim::GetAttr[name="attention"](%109)
  %4497 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27571.Bottleneck = prim::GetAttr[name="bottleneck"](%109)
  %4498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27570.BottleneckLayer = prim::GetAttr[name="attention"](%4497)
  %4499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27567.BottleneckLayer = prim::GetAttr[name="input"](%4497)
  %4500 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27566.NoNorm = prim::GetAttr[name="LayerNorm"](%4499)
  %4501 : __torch__.torch.nn.modules.linear.___torch_mangle_27565.Linear = prim::GetAttr[name="dense"](%4499)
  %4502 : Tensor = prim::GetAttr[name="bias"](%4501)
  %4503 : Tensor = prim::GetAttr[name="weight"](%4501)
  %4504 : Float(512:1, 128:512) = aten::t(%4503), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.input/__module.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.332 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4504), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.input/__module.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.178 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.332, %4502, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.input/__module.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4507 : Tensor = prim::GetAttr[name="bias"](%4500)
  %4508 : Tensor = prim::GetAttr[name="weight"](%4500)
  %4509 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.178, %4508), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.input/__module.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%4509, %4507, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.input/__module.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4511 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27569.NoNorm = prim::GetAttr[name="LayerNorm"](%4498)
  %4512 : __torch__.torch.nn.modules.linear.___torch_mangle_27568.Linear = prim::GetAttr[name="dense"](%4498)
  %4513 : Tensor = prim::GetAttr[name="bias"](%4512)
  %4514 : Tensor = prim::GetAttr[name="weight"](%4512)
  %4515 : Float(512:1, 128:512) = aten::t(%4514), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.attention/__module.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.333 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4515), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.attention/__module.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.179 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.333, %4513, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.attention/__module.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4518 : Tensor = prim::GetAttr[name="bias"](%4511)
  %4519 : Tensor = prim::GetAttr[name="weight"](%4511)
  %4520 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.179, %4519), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.attention/__module.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.426 : Float(17:1664, 13:128, 128:1) = aten::add(%4520, %4518, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.bottleneck/__module.encoder.layer.22.bottleneck.attention/__module.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4522 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.426, %residual_tensor.23)
  %4523 : Float(17:1664, 13:128, 128:1), %4524 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4522)
  %4525 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27554.MobileBertSelfOutput = prim::GetAttr[name="output"](%4496)
  %4526 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27551.MobileBertSelfAttention = prim::GetAttr[name="self"](%4496)
  %4527 : __torch__.torch.nn.modules.linear.___torch_mangle_27549.Linear = prim::GetAttr[name="value"](%4526)
  %4528 : __torch__.torch.nn.modules.linear.___torch_mangle_27548.Linear = prim::GetAttr[name="key"](%4526)
  %4529 : __torch__.torch.nn.modules.linear.___torch_mangle_27547.Linear = prim::GetAttr[name="query"](%4526)
  %4530 : Tensor = prim::GetAttr[name="bias"](%4529)
  %4531 : Tensor = prim::GetAttr[name="weight"](%4529)
  %4532 : Float(128:1, 128:128) = aten::t(%4531), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %output.334 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4523, %4532), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %x.133 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.334, %4530, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.query # torch/nn/functional.py:1678:0
  %4535 : Tensor = prim::GetAttr[name="bias"](%4528)
  %4536 : Tensor = prim::GetAttr[name="weight"](%4528)
  %4537 : Float(128:1, 128:128) = aten::t(%4536), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %output.335 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4523, %4537), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %x.135 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.335, %4535, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.key # torch/nn/functional.py:1678:0
  %4540 : Tensor = prim::GetAttr[name="bias"](%4527)
  %4541 : Tensor = prim::GetAttr[name="weight"](%4527)
  %4542 : Float(512:1, 128:512) = aten::t(%4541), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %output.336 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4542), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %x.137 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.336, %4540, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.value # torch/nn/functional.py:1678:0
  %4545 : int = aten::size(%x.133, %93), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4546 : int = aten::size(%x.133, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4547 : int[] = prim::ListConstruct(%4545, %4546, %94, %95), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self
  %x.134 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.133, %4547), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4549 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self
  %query_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.134, %4549), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4551 : int = aten::size(%x.135, %93), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4552 : int = aten::size(%x.135, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4553 : int[] = prim::ListConstruct(%4551, %4552, %94, %95), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self
  %x.136 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.135, %4553), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4555 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self
  %key_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.136, %4555), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4557 : int = aten::size(%x.137, %93), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4558 : int = aten::size(%x.137, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4559 : int[] = prim::ListConstruct(%4557, %4558, %94, %95), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self
  %x.138 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.137, %4559), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4561 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self
  %value_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.138, %4561), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4563 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.23, %98, %99), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.45 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.23, %4563), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.46 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.45, %100), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.427 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.46, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.428 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.427, %98, %101), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.428, %103, %102), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self/__module.encoder.layer.22.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.45 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.23, %value_layer.23), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:280:0
  %4570 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self
  %4571 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.45, %4570), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4571, %93), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %4573 : int = aten::size(%context_layer.46, %93), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4574 : int = aten::size(%context_layer.46, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4575 : int[] = prim::ListConstruct(%4573, %4574, %104), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self
  %input.429 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.46, %4575), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:283:0
  %4577 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27553.NoNorm = prim::GetAttr[name="LayerNorm"](%4525)
  %4578 : __torch__.torch.nn.modules.linear.___torch_mangle_27552.Linear = prim::GetAttr[name="dense"](%4525)
  %4579 : Tensor = prim::GetAttr[name="bias"](%4578)
  %4580 : Tensor = prim::GetAttr[name="weight"](%4578)
  %4581 : Float(128:1, 128:128) = aten::t(%4580), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.output/__module.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %output.337 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.429, %4581), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.output/__module.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.337, %4579, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.output/__module.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.180 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.111, %4524, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.output # transformers/modeling_mobilebert.py:301:0
  %4585 : Tensor = prim::GetAttr[name="bias"](%4577)
  %4586 : Tensor = prim::GetAttr[name="weight"](%4577)
  %4587 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.180, %4586), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.output/__module.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.430 : Float(17:1664, 13:128, 128:1) = aten::add(%4587, %4585, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.attention/__module.encoder.layer.22.attention.output/__module.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4589 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27576.FFNOutput = prim::GetAttr[name="output"](%4495)
  %4590 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27573.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4495)
  %4591 : __torch__.torch.nn.modules.linear.___torch_mangle_27572.Linear = prim::GetAttr[name="dense"](%4590)
  %4592 : Tensor = prim::GetAttr[name="bias"](%4591)
  %4593 : Tensor = prim::GetAttr[name="weight"](%4591)
  %4594 : Float(128:1, 512:128) = aten::t(%4593), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.intermediate/__module.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.338 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.430, %4594), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.intermediate/__module.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.431 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.338, %4592, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.intermediate/__module.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.432 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.431), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4598 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27575.NoNorm = prim::GetAttr[name="LayerNorm"](%4589)
  %4599 : __torch__.torch.nn.modules.linear.___torch_mangle_27574.Linear = prim::GetAttr[name="dense"](%4589)
  %4600 : Tensor = prim::GetAttr[name="bias"](%4599)
  %4601 : Tensor = prim::GetAttr[name="weight"](%4599)
  %4602 : Float(512:1, 128:512) = aten::t(%4601), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.output/__module.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.339 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.432, %4602), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.output/__module.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.112 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.339, %4600, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.output/__module.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.181 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.112, %input.430, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4606 : Tensor = prim::GetAttr[name="bias"](%4598)
  %4607 : Tensor = prim::GetAttr[name="weight"](%4598)
  %4608 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.181, %4607), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.output/__module.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.433 : Float(17:1664, 13:128, 128:1) = aten::add(%4608, %4606, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.0/__module.encoder.layer.22.ffn.0.output/__module.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4610 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27582.FFNOutput = prim::GetAttr[name="output"](%4493)
  %4611 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27579.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4493)
  %4612 : __torch__.torch.nn.modules.linear.___torch_mangle_27578.Linear = prim::GetAttr[name="dense"](%4611)
  %4613 : Tensor = prim::GetAttr[name="bias"](%4612)
  %4614 : Tensor = prim::GetAttr[name="weight"](%4612)
  %4615 : Float(128:1, 512:128) = aten::t(%4614), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.intermediate/__module.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.340 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.433, %4615), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.intermediate/__module.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.434 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.340, %4613, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.intermediate/__module.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.435 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.434), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4619 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27581.NoNorm = prim::GetAttr[name="LayerNorm"](%4610)
  %4620 : __torch__.torch.nn.modules.linear.___torch_mangle_27580.Linear = prim::GetAttr[name="dense"](%4610)
  %4621 : Tensor = prim::GetAttr[name="bias"](%4620)
  %4622 : Tensor = prim::GetAttr[name="weight"](%4620)
  %4623 : Float(512:1, 128:512) = aten::t(%4622), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.output/__module.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.341 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.435, %4623), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.output/__module.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.341, %4621, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.output/__module.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.182 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.113, %input.433, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4627 : Tensor = prim::GetAttr[name="bias"](%4619)
  %4628 : Tensor = prim::GetAttr[name="weight"](%4619)
  %4629 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.182, %4628), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.output/__module.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.436 : Float(17:1664, 13:128, 128:1) = aten::add(%4629, %4627, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.1/__module.encoder.layer.22.ffn.1.output/__module.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4631 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27588.FFNOutput = prim::GetAttr[name="output"](%4491)
  %4632 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27585.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4491)
  %4633 : __torch__.torch.nn.modules.linear.___torch_mangle_27584.Linear = prim::GetAttr[name="dense"](%4632)
  %4634 : Tensor = prim::GetAttr[name="bias"](%4633)
  %4635 : Tensor = prim::GetAttr[name="weight"](%4633)
  %4636 : Float(128:1, 512:128) = aten::t(%4635), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.intermediate/__module.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.342 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.436, %4636), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.intermediate/__module.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.437 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.342, %4634, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.intermediate/__module.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.438 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.437), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4640 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27587.NoNorm = prim::GetAttr[name="LayerNorm"](%4631)
  %4641 : __torch__.torch.nn.modules.linear.___torch_mangle_27586.Linear = prim::GetAttr[name="dense"](%4631)
  %4642 : Tensor = prim::GetAttr[name="bias"](%4641)
  %4643 : Tensor = prim::GetAttr[name="weight"](%4641)
  %4644 : Float(512:1, 128:512) = aten::t(%4643), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.output/__module.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.343 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.438, %4644), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.output/__module.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.343, %4642, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.output/__module.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.183 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.114, %input.436, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4648 : Tensor = prim::GetAttr[name="bias"](%4640)
  %4649 : Tensor = prim::GetAttr[name="weight"](%4640)
  %4650 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.183, %4649), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.output/__module.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.439 : Float(17:1664, 13:128, 128:1) = aten::add(%4650, %4648, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.ffn.2/__module.encoder.layer.22.ffn.2.output/__module.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4652 : __torch__.torch.nn.modules.linear.___torch_mangle_27556.Linear = prim::GetAttr[name="dense"](%4489)
  %4653 : Tensor = prim::GetAttr[name="bias"](%4652)
  %4654 : Tensor = prim::GetAttr[name="weight"](%4652)
  %4655 : Float(128:1, 512:128) = aten::t(%4654), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.intermediate/__module.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %output.344 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.439, %4655), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.intermediate/__module.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %input.440 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.344, %4653, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.intermediate/__module.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1678:0
  %input.441 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.440), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.intermediate # torch/nn/functional.py:1119:0
  %4659 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27563.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4488)
  %4660 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27559.NoNorm = prim::GetAttr[name="LayerNorm"](%4488)
  %4661 : __torch__.torch.nn.modules.linear.___torch_mangle_27558.Linear = prim::GetAttr[name="dense"](%4488)
  %4662 : Tensor = prim::GetAttr[name="bias"](%4661)
  %4663 : Tensor = prim::GetAttr[name="weight"](%4661)
  %4664 : Float(512:1, 128:512) = aten::t(%4663), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %output.345 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.441, %4664), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %layer_output.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.345, %4662, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.184 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.23, %input.439, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output # transformers/modeling_mobilebert.py:405:0
  %4668 : Tensor = prim::GetAttr[name="bias"](%4660)
  %4669 : Tensor = prim::GetAttr[name="weight"](%4660)
  %4670 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.184, %4669), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.442 : Float(17:1664, 13:128, 128:1) = aten::add(%4670, %4668, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4672 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27561.NoNorm = prim::GetAttr[name="LayerNorm"](%4659)
  %4673 : __torch__.torch.nn.modules.linear.___torch_mangle_27560.Linear = prim::GetAttr[name="dense"](%4659)
  %4674 : Tensor = prim::GetAttr[name="bias"](%4673)
  %4675 : Tensor = prim::GetAttr[name="weight"](%4673)
  %4676 : Float(128:1, 512:128) = aten::t(%4675), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.bottleneck/__module.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.346 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.442, %4676), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.bottleneck/__module.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.443 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.346, %4674, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.bottleneck/__module.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.115 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.443, %105, %102), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.bottleneck/__module.encoder.layer.22.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.185 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.115, %input.425, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4681 : Tensor = prim::GetAttr[name="bias"](%4672)
  %4682 : Tensor = prim::GetAttr[name="weight"](%4672)
  %4683 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.185, %4682), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.bottleneck/__module.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.444 : Float(17:6656, 13:512, 512:1) = aten::add(%4683, %4681, %92), scope: __module.encoder/__module.encoder.layer.22/__module.encoder.layer.22.output/__module.encoder.layer.22.output.bottleneck/__module.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4685 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27609.MobileBertOutput = prim::GetAttr[name="output"](%107)
  %4686 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27602.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%107)
  %4687 : __torch__.torch.nn.modules.container.___torch_mangle_27635.ModuleList = prim::GetAttr[name="ffn"](%107)
  %4688 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27634.FFNLayer = prim::GetAttr[name="2"](%4687)
  %4689 : __torch__.torch.nn.modules.container.___torch_mangle_27635.ModuleList = prim::GetAttr[name="ffn"](%107)
  %4690 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27628.FFNLayer = prim::GetAttr[name="1"](%4689)
  %4691 : __torch__.torch.nn.modules.container.___torch_mangle_27635.ModuleList = prim::GetAttr[name="ffn"](%107)
  %4692 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27622.FFNLayer = prim::GetAttr[name="0"](%4691)
  %4693 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27600.MobileBertAttention = prim::GetAttr[name="attention"](%107)
  %4694 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27616.Bottleneck = prim::GetAttr[name="bottleneck"](%107)
  %4695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27615.BottleneckLayer = prim::GetAttr[name="attention"](%4694)
  %4696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27612.BottleneckLayer = prim::GetAttr[name="input"](%4694)
  %4697 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27611.NoNorm = prim::GetAttr[name="LayerNorm"](%4696)
  %4698 : __torch__.torch.nn.modules.linear.___torch_mangle_27610.Linear = prim::GetAttr[name="dense"](%4696)
  %4699 : Tensor = prim::GetAttr[name="bias"](%4698)
  %4700 : Tensor = prim::GetAttr[name="weight"](%4698)
  %4701 : Float(512:1, 128:512) = aten::t(%4700), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.input/__module.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.347 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4701), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.input/__module.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.186 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.347, %4699, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.input/__module.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4704 : Tensor = prim::GetAttr[name="bias"](%4697)
  %4705 : Tensor = prim::GetAttr[name="weight"](%4697)
  %4706 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.186, %4705), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.input/__module.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor : Float(17:1664, 13:128, 128:1) = aten::add(%4706, %4704, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.input/__module.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4708 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27614.NoNorm = prim::GetAttr[name="LayerNorm"](%4695)
  %4709 : __torch__.torch.nn.modules.linear.___torch_mangle_27613.Linear = prim::GetAttr[name="dense"](%4695)
  %4710 : Tensor = prim::GetAttr[name="bias"](%4709)
  %4711 : Tensor = prim::GetAttr[name="weight"](%4709)
  %4712 : Float(512:1, 128:512) = aten::t(%4711), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.attention/__module.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.348 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4712), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.attention/__module.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.187 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.348, %4710, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.attention/__module.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4715 : Tensor = prim::GetAttr[name="bias"](%4708)
  %4716 : Tensor = prim::GetAttr[name="weight"](%4708)
  %4717 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.187, %4716), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.attention/__module.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.445 : Float(17:1664, 13:128, 128:1) = aten::add(%4717, %4715, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.bottleneck/__module.encoder.layer.23.bottleneck.attention/__module.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4719 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.445, %residual_tensor)
  %4720 : Float(17:1664, 13:128, 128:1), %4721 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4719)
  %4722 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27599.MobileBertSelfOutput = prim::GetAttr[name="output"](%4693)
  %4723 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27596.MobileBertSelfAttention = prim::GetAttr[name="self"](%4693)
  %4724 : __torch__.torch.nn.modules.linear.___torch_mangle_27594.Linear = prim::GetAttr[name="value"](%4723)
  %4725 : __torch__.torch.nn.modules.linear.___torch_mangle_27593.Linear = prim::GetAttr[name="key"](%4723)
  %4726 : __torch__.torch.nn.modules.linear.___torch_mangle_27592.Linear = prim::GetAttr[name="query"](%4723)
  %4727 : Tensor = prim::GetAttr[name="bias"](%4726)
  %4728 : Tensor = prim::GetAttr[name="weight"](%4726)
  %4729 : Float(128:1, 128:128) = aten::t(%4728), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %output.349 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4720, %4729), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %x.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.349, %4727, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.query # torch/nn/functional.py:1678:0
  %4732 : Tensor = prim::GetAttr[name="bias"](%4725)
  %4733 : Tensor = prim::GetAttr[name="weight"](%4725)
  %4734 : Float(128:1, 128:128) = aten::t(%4733), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %output.350 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4720, %4734), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %x.141 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.350, %4732, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.key # torch/nn/functional.py:1678:0
  %4737 : Tensor = prim::GetAttr[name="bias"](%4724)
  %4738 : Tensor = prim::GetAttr[name="weight"](%4724)
  %4739 : Float(512:1, 128:512) = aten::t(%4738), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %output.351 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4739), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %x.143 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.351, %4737, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.value # torch/nn/functional.py:1678:0
  %4742 : int = aten::size(%x.139, %93), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4743 : int = aten::size(%x.139, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4744 : int[] = prim::ListConstruct(%4742, %4743, %94, %95), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self
  %x.140 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.139, %4744), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4746 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self
  %query_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.140, %4746), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4748 : int = aten::size(%x.141, %93), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4749 : int = aten::size(%x.141, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4750 : int[] = prim::ListConstruct(%4748, %4749, %94, %95), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self
  %x.142 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.141, %4750), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4752 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self
  %key_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.142, %4752), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4754 : int = aten::size(%x.143, %93), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4755 : int = aten::size(%x.143, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4756 : int[] = prim::ListConstruct(%4754, %4755, %94, %95), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self
  %x : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.143, %4756), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4758 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self
  %value_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x, %4758), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4760 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer, %98, %99), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer, %4760), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.47, %100), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.446 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores, %attention_mask, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.447 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.446, %98, %101), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # torch/nn/functional.py:1498:0
  %attention_probs : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.447, %103, %102), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self/__module.encoder.layer.23.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.47 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:280:0
  %4767 : int[] = prim::ListConstruct(%93, %96, %92, %97), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self
  %4768 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.47, %4767), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4768, %93), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %4770 : int = aten::size(%context_layer, %93), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4771 : int = aten::size(%context_layer, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4772 : int[] = prim::ListConstruct(%4770, %4771, %104), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self
  %input.448 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer, %4772), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:283:0
  %4774 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27598.NoNorm = prim::GetAttr[name="LayerNorm"](%4722)
  %4775 : __torch__.torch.nn.modules.linear.___torch_mangle_27597.Linear = prim::GetAttr[name="dense"](%4722)
  %4776 : Tensor = prim::GetAttr[name="bias"](%4775)
  %4777 : Tensor = prim::GetAttr[name="weight"](%4775)
  %4778 : Float(128:1, 128:128) = aten::t(%4777), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.output/__module.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %output.352 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.448, %4778), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.output/__module.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.116 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.352, %4776, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.output/__module.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.188 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.116, %4721, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.output # transformers/modeling_mobilebert.py:301:0
  %4782 : Tensor = prim::GetAttr[name="bias"](%4774)
  %4783 : Tensor = prim::GetAttr[name="weight"](%4774)
  %4784 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.188, %4783), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.output/__module.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.449 : Float(17:1664, 13:128, 128:1) = aten::add(%4784, %4782, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.attention/__module.encoder.layer.23.attention.output/__module.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4786 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27621.FFNOutput = prim::GetAttr[name="output"](%4692)
  %4787 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27618.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4692)
  %4788 : __torch__.torch.nn.modules.linear.___torch_mangle_27617.Linear = prim::GetAttr[name="dense"](%4787)
  %4789 : Tensor = prim::GetAttr[name="bias"](%4788)
  %4790 : Tensor = prim::GetAttr[name="weight"](%4788)
  %4791 : Float(128:1, 512:128) = aten::t(%4790), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.intermediate/__module.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.353 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.449, %4791), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.intermediate/__module.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.450 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.353, %4789, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.intermediate/__module.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.451 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.450), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4795 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27620.NoNorm = prim::GetAttr[name="LayerNorm"](%4786)
  %4796 : __torch__.torch.nn.modules.linear.___torch_mangle_27619.Linear = prim::GetAttr[name="dense"](%4786)
  %4797 : Tensor = prim::GetAttr[name="bias"](%4796)
  %4798 : Tensor = prim::GetAttr[name="weight"](%4796)
  %4799 : Float(512:1, 128:512) = aten::t(%4798), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.output/__module.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.354 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.451, %4799), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.output/__module.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.354, %4797, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.output/__module.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.189 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.117, %input.449, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4803 : Tensor = prim::GetAttr[name="bias"](%4795)
  %4804 : Tensor = prim::GetAttr[name="weight"](%4795)
  %4805 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.189, %4804), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.output/__module.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.452 : Float(17:1664, 13:128, 128:1) = aten::add(%4805, %4803, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.0/__module.encoder.layer.23.ffn.0.output/__module.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4807 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27627.FFNOutput = prim::GetAttr[name="output"](%4690)
  %4808 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27624.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4690)
  %4809 : __torch__.torch.nn.modules.linear.___torch_mangle_27623.Linear = prim::GetAttr[name="dense"](%4808)
  %4810 : Tensor = prim::GetAttr[name="bias"](%4809)
  %4811 : Tensor = prim::GetAttr[name="weight"](%4809)
  %4812 : Float(128:1, 512:128) = aten::t(%4811), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.intermediate/__module.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.355 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.452, %4812), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.intermediate/__module.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.453 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.355, %4810, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.intermediate/__module.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.454 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.453), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4816 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27626.NoNorm = prim::GetAttr[name="LayerNorm"](%4807)
  %4817 : __torch__.torch.nn.modules.linear.___torch_mangle_27625.Linear = prim::GetAttr[name="dense"](%4807)
  %4818 : Tensor = prim::GetAttr[name="bias"](%4817)
  %4819 : Tensor = prim::GetAttr[name="weight"](%4817)
  %4820 : Float(512:1, 128:512) = aten::t(%4819), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.output/__module.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.356 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.454, %4820), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.output/__module.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.118 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.356, %4818, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.output/__module.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.190 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.118, %input.452, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4824 : Tensor = prim::GetAttr[name="bias"](%4816)
  %4825 : Tensor = prim::GetAttr[name="weight"](%4816)
  %4826 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.190, %4825), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.output/__module.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.455 : Float(17:1664, 13:128, 128:1) = aten::add(%4826, %4824, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.1/__module.encoder.layer.23.ffn.1.output/__module.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4828 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27633.FFNOutput = prim::GetAttr[name="output"](%4688)
  %4829 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27630.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4688)
  %4830 : __torch__.torch.nn.modules.linear.___torch_mangle_27629.Linear = prim::GetAttr[name="dense"](%4829)
  %4831 : Tensor = prim::GetAttr[name="bias"](%4830)
  %4832 : Tensor = prim::GetAttr[name="weight"](%4830)
  %4833 : Float(128:1, 512:128) = aten::t(%4832), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.intermediate/__module.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.357 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.455, %4833), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.intermediate/__module.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.456 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.357, %4831, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.intermediate/__module.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.457 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.456), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4837 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27632.NoNorm = prim::GetAttr[name="LayerNorm"](%4828)
  %4838 : __torch__.torch.nn.modules.linear.___torch_mangle_27631.Linear = prim::GetAttr[name="dense"](%4828)
  %4839 : Tensor = prim::GetAttr[name="bias"](%4838)
  %4840 : Tensor = prim::GetAttr[name="weight"](%4838)
  %4841 : Float(512:1, 128:512) = aten::t(%4840), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.output/__module.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.358 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.457, %4841), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.output/__module.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.358, %4839, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.output/__module.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.191 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.119, %input.455, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4845 : Tensor = prim::GetAttr[name="bias"](%4837)
  %4846 : Tensor = prim::GetAttr[name="weight"](%4837)
  %4847 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.191, %4846), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.output/__module.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.458 : Float(17:1664, 13:128, 128:1) = aten::add(%4847, %4845, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.ffn.2/__module.encoder.layer.23.ffn.2.output/__module.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4849 : __torch__.torch.nn.modules.linear.___torch_mangle_27601.Linear = prim::GetAttr[name="dense"](%4686)
  %4850 : Tensor = prim::GetAttr[name="bias"](%4849)
  %4851 : Tensor = prim::GetAttr[name="weight"](%4849)
  %4852 : Float(128:1, 512:128) = aten::t(%4851), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.intermediate/__module.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %output.359 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.458, %4852), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.intermediate/__module.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %input.459 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.359, %4850, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.intermediate/__module.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1678:0
  %input.460 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.459), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.intermediate # torch/nn/functional.py:1119:0
  %4856 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27608.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4685)
  %4857 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27604.NoNorm = prim::GetAttr[name="LayerNorm"](%4685)
  %4858 : __torch__.torch.nn.modules.linear.___torch_mangle_27603.Linear = prim::GetAttr[name="dense"](%4685)
  %4859 : Tensor = prim::GetAttr[name="bias"](%4858)
  %4860 : Tensor = prim::GetAttr[name="weight"](%4858)
  %4861 : Float(512:1, 128:512) = aten::t(%4860), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %output.360 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.460, %4861), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %layer_output : Float(17:1664, 13:128, 128:1) = aten::add_(%output.360, %4859, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.192 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output, %input.458, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output # transformers/modeling_mobilebert.py:405:0
  %4865 : Tensor = prim::GetAttr[name="bias"](%4857)
  %4866 : Tensor = prim::GetAttr[name="weight"](%4857)
  %4867 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.192, %4866), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.461 : Float(17:1664, 13:128, 128:1) = aten::add(%4867, %4865, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4869 : __torch__.transformers.modeling_mobilebert.___torch_mangle_27606.NoNorm = prim::GetAttr[name="LayerNorm"](%4856)
  %4870 : __torch__.torch.nn.modules.linear.___torch_mangle_27605.Linear = prim::GetAttr[name="dense"](%4856)
  %4871 : Tensor = prim::GetAttr[name="bias"](%4870)
  %4872 : Tensor = prim::GetAttr[name="weight"](%4870)
  %4873 : Float(128:1, 512:128) = aten::t(%4872), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.bottleneck/__module.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.461, %4873), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.bottleneck/__module.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.462 : Float(17:6656, 13:512, 512:1) = aten::add_(%output, %4871, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.bottleneck/__module.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.462, %105, %102), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.bottleneck/__module.encoder.layer.23.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs, %input.444, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4878 : Tensor = prim::GetAttr[name="bias"](%4869)
  %4879 : Tensor = prim::GetAttr[name="weight"](%4869)
  %4880 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor, %4879), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.bottleneck/__module.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %hidden_states : Float(17:6656, 13:512, 512:1) = aten::add(%4880, %4878, %92), scope: __module.encoder/__module.encoder.layer.23/__module.encoder.layer.23.output/__module.encoder.layer.23.output.bottleneck/__module.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4882 : int = prim::Constant[value=1](), scope: __module.pooler # transformers/modeling_mobilebert.py:603:0
  %4883 : int = prim::Constant[value=9223372036854775807](), scope: __module.pooler # transformers/modeling_mobilebert.py:603:0
  %4884 : int = prim::Constant[value=0](), scope: __module.pooler # transformers/modeling_mobilebert.py:603:0
  %4885 : __torch__.torch.nn.modules.linear.___torch_mangle_27639.Linear = prim::GetAttr[name="dense"](%3)
  %4886 : Float(17:6656, 13:512, 512:1) = aten::slice(%hidden_states, %4884, %4884, %4883, %4882), scope: __module.pooler # transformers/modeling_mobilebert.py:603:0
  %input : Float(17:6656, 512:1) = aten::select(%4886, %4882, %4884), scope: __module.pooler # transformers/modeling_mobilebert.py:603:0
  %4888 : Tensor = prim::GetAttr[name="bias"](%4885)
  %4889 : Tensor = prim::GetAttr[name="weight"](%4885)
  %4890 : Float(512:1, 512:512) = aten::t(%4889), scope: __module.pooler/__module.pooler.dense # torch/nn/functional.py:1674:0
  %pooled_output : Float(17:512, 512:1) = aten::addmm(%4888, %input, %4890, %4882, %4882), scope: __module.pooler/__module.pooler.dense # torch/nn/functional.py:1674:0
  %4892 : Float(17:512, 512:1) = aten::tanh(%pooled_output), scope: __module.pooler # transformers/modeling_mobilebert.py:608:0
  %47 : (Float(17:6656, 13:512, 512:1), Float(17:512, 512:1)) = prim::TupleConstruct(%hidden_states, %4892)
  return (%47)
