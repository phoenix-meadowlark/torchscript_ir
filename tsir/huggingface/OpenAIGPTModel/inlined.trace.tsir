graph(%self.1 : __torch__.transformers.modeling_openai.___torch_mangle_29334.OpenAIGPTModel,
      %input_ids : Long(17:13, 13:1),
      %attention_mask.1 : Long(17:13, 13:1)):
  %3 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %4 : __torch__.transformers.modeling_openai.___torch_mangle_29332.Block = prim::GetAttr[name="11"](%3)
  %5 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %6 : __torch__.transformers.modeling_openai.___torch_mangle_29320.Block = prim::GetAttr[name="10"](%5)
  %7 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %8 : __torch__.transformers.modeling_openai.___torch_mangle_29308.Block = prim::GetAttr[name="9"](%7)
  %9 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %10 : __torch__.transformers.modeling_openai.___torch_mangle_29296.Block = prim::GetAttr[name="8"](%9)
  %11 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %12 : __torch__.transformers.modeling_openai.___torch_mangle_29284.Block = prim::GetAttr[name="7"](%11)
  %13 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %14 : __torch__.transformers.modeling_openai.___torch_mangle_29272.Block = prim::GetAttr[name="6"](%13)
  %15 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %16 : __torch__.transformers.modeling_openai.___torch_mangle_29260.Block = prim::GetAttr[name="5"](%15)
  %17 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %18 : __torch__.transformers.modeling_openai.___torch_mangle_29248.Block = prim::GetAttr[name="4"](%17)
  %19 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %20 : __torch__.transformers.modeling_openai.___torch_mangle_29236.Block = prim::GetAttr[name="3"](%19)
  %21 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %22 : __torch__.transformers.modeling_openai.___torch_mangle_29224.Block = prim::GetAttr[name="2"](%21)
  %23 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %24 : __torch__.transformers.modeling_openai.___torch_mangle_29212.Block = prim::GetAttr[name="1"](%23)
  %25 : __torch__.torch.nn.modules.container.___torch_mangle_29333.ModuleList = prim::GetAttr[name="h"](%self.1)
  %26 : __torch__.transformers.modeling_openai.___torch_mangle_29200.Block = prim::GetAttr[name="0"](%25)
  %27 : __torch__.torch.nn.modules.dropout.___torch_mangle_29188.Dropout = prim::GetAttr[name="drop"](%self.1)
  %28 : __torch__.torch.nn.modules.sparse.___torch_mangle_29187.Embedding = prim::GetAttr[name="positions_embed"](%self.1)
  %29 : __torch__.torch.nn.modules.sparse.___torch_mangle_29186.Embedding = prim::GetAttr[name="tokens_embed"](%self.1)
  %30 : Tensor = prim::GetAttr[name="position_ids"](%self.1)
  %31 : int = prim::Constant[value=0]() # transformers/modeling_openai.py:458:0
  %32 : int = aten::size(%input_ids, %31) # transformers/modeling_openai.py:458:0
  %33 : Long() = prim::NumToTensor(%32)
  %34 : int = aten::Int(%33)
  %35 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:458:0
  %36 : int = aten::size(%input_ids, %35) # transformers/modeling_openai.py:458:0
  %37 : Long() = prim::NumToTensor(%36)
  %38 : int = aten::Int(%37)
  %39 : int = aten::Int(%37)
  %40 : int = aten::Int(%37)
  %41 : int = prim::Constant[value=-1]() # transformers/modeling_openai.py:459:0
  %42 : int[] = prim::ListConstruct(%41, %40)
  %input.1 : Long(17:13, 13:1) = aten::view(%input_ids, %42) # transformers/modeling_openai.py:459:0
  %44 : int = prim::Constant[value=0]() # transformers/modeling_openai.py:467:0
  %45 : Long(1:512, 512:1) = aten::unsqueeze(%30, %44) # transformers/modeling_openai.py:467:0
  %46 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:467:0
  %47 : int = prim::Constant[value=0]() # transformers/modeling_openai.py:467:0
  %48 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:467:0
  %input.2 : Long(1:512, 13:1) = aten::slice(%45, %46, %47, %39, %48) # transformers/modeling_openai.py:467:0
  %50 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:476:0
  %51 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%attention_mask.1, %50) # transformers/modeling_openai.py:476:0
  %52 : int = prim::Constant[value=2]() # transformers/modeling_openai.py:476:0
  %attention_mask.2 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%51, %52) # transformers/modeling_openai.py:476:0
  %54 : int = prim::Constant[value=6]() # transformers/modeling_openai.py:483:0
  %55 : bool = prim::Constant[value=0]() # transformers/modeling_openai.py:483:0
  %56 : bool = prim::Constant[value=0]() # transformers/modeling_openai.py:483:0
  %57 : None = prim::Constant()
  %58 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%attention_mask.2, %54, %55, %56, %57) # transformers/modeling_openai.py:483:0
  %59 : float = prim::Constant[value=1.]() # torch/tensor.py:396:0
  %60 : int = prim::Constant[value=1]() # torch/tensor.py:396:0
  %61 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%58, %59, %60) # torch/tensor.py:396:0
  %62 : Double() = prim::Constant[value={-10000}]() # transformers/modeling_openai.py:484:0
  %attention_mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%61, %62) # transformers/modeling_openai.py:484:0
  %91 : bool = prim::Constant[value=0](), scope: __module.tokens_embed # torch/nn/functional.py:1814:0
  %92 : int = prim::Constant[value=-1](), scope: __module.tokens_embed # torch/nn/functional.py:1814:0
  %93 : Tensor = prim::GetAttr[name="weight"](%29)
  %inputs_embeds : Float(17:9984, 13:768, 768:1) = aten::embedding(%93, %input.1, %92, %91, %91), scope: __module.tokens_embed # torch/nn/functional.py:1814:0
  %95 : bool = prim::Constant[value=0](), scope: __module.positions_embed # torch/nn/functional.py:1814:0
  %96 : int = prim::Constant[value=-1](), scope: __module.positions_embed # torch/nn/functional.py:1814:0
  %97 : Tensor = prim::GetAttr[name="weight"](%28)
  %position_embeds : Float(1:9984, 13:768, 768:1) = aten::embedding(%97, %input.2, %96, %95, %95), scope: __module.positions_embed # torch/nn/functional.py:1814:0
  %66 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:497:0
  %67 : Float(17:9984, 13:768, 768:1) = aten::add(%inputs_embeds, %position_embeds, %66) # transformers/modeling_openai.py:497:0
  %68 : Long() = prim::Constant[value={0}]() # transformers/modeling_openai.py:497:0
  %69 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:497:0
  %input.3 : Float(17:9984, 13:768, 768:1) = aten::add(%67, %68, %69) # transformers/modeling_openai.py:497:0
  %99 : bool = prim::Constant[value=0](), scope: __module.drop # torch/nn/functional.py:973:0
  %100 : float = prim::Constant[value=0.10000000000000001](), scope: __module.drop # torch/nn/functional.py:973:0
  %hidden_states.1 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.3, %100, %99), scope: __module.drop # torch/nn/functional.py:973:0
  %72 : int = prim::Constant[value=-1]() # transformers/modeling_openai.py:500:0
  %73 : int = aten::size(%hidden_states.1, %72) # transformers/modeling_openai.py:500:0
  %74 : Long() = prim::NumToTensor(%73)
  %75 : int = aten::Int(%74)
  %102 : int = prim::Constant[value=3072](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %103 : Double() = prim::Constant[value={0.5}](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %104 : float = prim::Constant[value=3.](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %105 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %106 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %107 : Double() = prim::Constant[value={1}](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %108 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.0/__module.h.0.ln_1 # torch/nn/functional.py:2048:0
  %109 : bool = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.ln_1 # torch/nn/functional.py:2048:0
  %110 : int = prim::Constant[value=2304](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1095:0
  %111 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
  %112 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1093:0
  %113 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1093:0
  %114 : int = prim::Constant[value=768](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:371:0
  %115 : int = prim::Constant[value=2](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:371:0
  %116 : Long() = prim::Constant[value={12}](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
  %117 : int = prim::Constant[value=12](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
  %118 : int = prim::Constant[value=3](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
  %119 : Double() = prim::Constant[value={8}](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:180:0
  %120 : int = prim::Constant[value=-2](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
  %121 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
  %122 : Double() = prim::Constant[value={-10000}](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:184:0
  %123 : None = prim::Constant(), scope: __module.h.0/__module.h.0.attn
  %124 : bool = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.attn_dropout # torch/nn/functional.py:973:0
  %125 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.attn_dropout # torch/nn/functional.py:973:0
  %126 : __torch__.torch.nn.modules.normalization.___torch_mangle_29199.LayerNorm = prim::GetAttr[name="ln_2"](%26)
  %127 : __torch__.transformers.modeling_openai.___torch_mangle_29198.MLP = prim::GetAttr[name="mlp"](%26)
  %128 : __torch__.torch.nn.modules.normalization.___torch_mangle_29194.LayerNorm = prim::GetAttr[name="ln_1"](%26)
  %129 : __torch__.transformers.modeling_openai.___torch_mangle_29193.Attention = prim::GetAttr[name="attn"](%26)
  %130 : __torch__.transformers.modeling_utils.___torch_mangle_29190.Conv1D = prim::GetAttr[name="c_proj"](%129)
  %131 : Tensor = prim::GetAttr[name="bias"](%129)
  %132 : __torch__.transformers.modeling_utils.___torch_mangle_29189.Conv1D = prim::GetAttr[name="c_attn"](%129)
  %133 : Tensor = prim::GetAttr[name="weight"](%132)
  %134 : Tensor = prim::GetAttr[name="bias"](%132)
  %135 : int = aten::size(%hidden_states.1, %113), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1093:0
  %136 : int = aten::size(%hidden_states.1, %112), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1093:0
  %137 : int = aten::size(%hidden_states.1, %111), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
  %138 : int[] = prim::ListConstruct(%111, %137), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
  %139 : Float(221:768, 768:1) = aten::view(%hidden_states.1, %138), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.1 : Float(221:2304, 2304:1) = aten::addmm(%134, %139, %133, %112, %112), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
  %141 : int[] = prim::ListConstruct(%135, %136, %110), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
  %142 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.1, %141), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1095:0
  %143 : Tensor[] = aten::split(%142, %114, %115), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:371:0
  %x.2 : Float(17:29952, 13:2304, 768:1), %x.4 : Float(17:29952, 13:2304, 768:1), %x.6 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%143), scope: __module.h.0/__module.h.0.attn
  %147 : int = aten::size(%x.2, %113), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
  %148 : int = aten::size(%x.2, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
  %149 : int = aten::size(%x.2, %111), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
  %150 : Long() = prim::NumToTensor(%149), scope: __module.h.0/__module.h.0.attn
  %151 : Long() = aten::floor_divide(%150, %116), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
  %152 : int = aten::Int(%151), scope: __module.h.0/__module.h.0.attn
  %153 : int[] = prim::ListConstruct(%147, %148, %117, %152), scope: __module.h.0/__module.h.0.attn
  %x.3 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.2, %153), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
  %155 : int[] = prim::ListConstruct(%113, %115, %112, %118), scope: __module.h.0/__module.h.0.attn
  %q.1 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.3, %155), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
  %157 : int = aten::size(%x.4, %113), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
  %158 : int = aten::size(%x.4, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
  %159 : int = aten::size(%x.4, %111), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
  %160 : Long() = prim::NumToTensor(%159), scope: __module.h.0/__module.h.0.attn
  %161 : Long() = aten::floor_divide(%160, %116), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
  %162 : int = aten::Int(%161), scope: __module.h.0/__module.h.0.attn
  %163 : int[] = prim::ListConstruct(%157, %158, %117, %162), scope: __module.h.0/__module.h.0.attn
  %x.5 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.4, %163), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
  %165 : int[] = prim::ListConstruct(%113, %115, %118, %112), scope: __module.h.0/__module.h.0.attn
  %k.1 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.5, %165), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:211:0
  %167 : int = aten::size(%x.6, %113), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
  %168 : int = aten::size(%x.6, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
  %169 : int = aten::size(%x.6, %111), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
  %170 : Long() = prim::NumToTensor(%169), scope: __module.h.0/__module.h.0.attn
  %171 : Long() = aten::floor_divide(%170, %116), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
  %172 : int = aten::Int(%171), scope: __module.h.0/__module.h.0.attn
  %173 : int[] = prim::ListConstruct(%167, %168, %117, %172), scope: __module.h.0/__module.h.0.attn
  %x.7 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.6, %173), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
  %175 : int[] = prim::ListConstruct(%113, %115, %112, %118), scope: __module.h.0/__module.h.0.attn
  %v.1 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.7, %175), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
  %w.1 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.1, %k.1), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:178:0
  %w.2 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.1, %119), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:180:0
  %179 : int = aten::size(%w.2, %120), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
  %180 : int = aten::size(%w.2, %111), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
  %181 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%131, %113, %113, %121, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
  %182 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%181, %112, %113, %121, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
  %183 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%182, %115, %113, %179, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
  %b.1 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%183, %118, %113, %180, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
  %185 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.2, %b.1), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:184:0
  %186 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.1, %112, %112), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:396:0
  %187 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%186, %122), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:184:0
  %w.3 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%185, %187, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:184:0
  %input.4 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.3, %attention_mask, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:188:0
  %input.5 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.4, %111, %123), scope: __module.h.0/__module.h.0.attn # torch/nn/functional.py:1498:0
  %w.4 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.5, %125, %124), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.8 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.4, %v.1), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:197:0
  %193 : int[] = prim::ListConstruct(%113, %115, %112, %118), scope: __module.h.0/__module.h.0.attn
  %194 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.8, %193), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:203:0
  %x.9 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%194, %113), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:203:0
  %196 : int = aten::size(%x.9, %113), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
  %197 : int = aten::size(%x.9, %112), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
  %198 : int = aten::size(%x.9, %120), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
  %199 : Long() = prim::NumToTensor(%198), scope: __module.h.0/__module.h.0.attn
  %200 : int = aten::size(%x.9, %111), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
  %201 : Long() = prim::NumToTensor(%200), scope: __module.h.0/__module.h.0.attn
  %202 : Long() = aten::mul(%199, %201), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
  %203 : int = aten::Int(%202), scope: __module.h.0/__module.h.0.attn
  %204 : int[] = prim::ListConstruct(%196, %197, %203), scope: __module.h.0/__module.h.0.attn
  %x.10 : Float(17:9984, 13:768, 768:1) = aten::view(%x.9, %204), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:205:0
  %206 : Tensor = prim::GetAttr[name="weight"](%130)
  %207 : Tensor = prim::GetAttr[name="bias"](%130)
  %208 : int = aten::size(%x.10, %113), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1093:0
  %209 : int = aten::size(%x.10, %112), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1093:0
  %210 : int = aten::size(%x.10, %111), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
  %211 : int[] = prim::ListConstruct(%111, %210), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
  %212 : Float(221:768, 768:1) = aten::view(%x.10, %211), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.11 : Float(221:768, 768:1) = aten::addmm(%207, %212, %206, %112, %112), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
  %214 : int[] = prim::ListConstruct(%208, %209, %114), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
  %input.6 : Float(17:9984, 13:768, 768:1) = aten::view(%x.11, %214), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.1 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.6, %125, %124), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.7 : Float(17:9984, 13:768, 768:1) = aten::add(%hidden_states.1, %a.1, %112), scope: __module.h.0 # transformers/modeling_openai.py:266:0
  %218 : Tensor = prim::GetAttr[name="bias"](%128)
  %219 : Tensor = prim::GetAttr[name="weight"](%128)
  %220 : int[] = prim::ListConstruct(%114), scope: __module.h.0/__module.h.0.ln_1
  %x.12 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.7, %220, %219, %218, %108, %109), scope: __module.h.0/__module.h.0.ln_1 # torch/nn/functional.py:2048:0
  %222 : __torch__.transformers.modeling_utils.___torch_mangle_29196.Conv1D = prim::GetAttr[name="c_proj"](%127)
  %223 : __torch__.transformers.modeling_utils.___torch_mangle_29195.Conv1D = prim::GetAttr[name="c_fc"](%127)
  %224 : Tensor = prim::GetAttr[name="weight"](%223)
  %225 : Tensor = prim::GetAttr[name="bias"](%223)
  %226 : int = aten::size(%x.12, %113), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %227 : int = aten::size(%x.12, %112), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %228 : int = aten::size(%x.12, %111), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %229 : int[] = prim::ListConstruct(%111, %228), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
  %230 : Float(221:768, 768:1) = aten::view(%x.12, %229), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.13 : Float(221:3072, 3072:1) = aten::addmm(%225, %230, %224, %112, %112), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %232 : int[] = prim::ListConstruct(%226, %227, %102), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
  %x.14 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.13, %232), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %234 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.14, %103), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %235 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.14, %104), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %236 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%235, %105), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %237 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.14, %236, %112), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %238 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%237, %106), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %239 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%238), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %240 : Float(17:39936, 13:3072, 3072:1) = aten::add(%239, %107, %112), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %x.15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%234, %240), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
  %242 : Tensor = prim::GetAttr[name="weight"](%222)
  %243 : Tensor = prim::GetAttr[name="bias"](%222)
  %244 : int = aten::size(%x.15, %113), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %245 : int = aten::size(%x.15, %112), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %246 : int = aten::size(%x.15, %111), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %247 : int[] = prim::ListConstruct(%111, %246), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
  %248 : Float(221:3072, 3072:1) = aten::view(%x.15, %247), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.16 : Float(221:768, 768:1) = aten::addmm(%243, %248, %242, %112, %112), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %250 : int[] = prim::ListConstruct(%244, %245, %114), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
  %input.8 : Float(17:9984, 13:768, 768:1) = aten::view(%x.16, %250), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.1 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.8, %125, %124), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.dropout # torch/nn/functional.py:973:0
  %input.9 : Float(17:9984, 13:768, 768:1) = aten::add(%x.12, %m.1, %112), scope: __module.h.0 # transformers/modeling_openai.py:268:0
  %254 : Tensor = prim::GetAttr[name="bias"](%126)
  %255 : Tensor = prim::GetAttr[name="weight"](%126)
  %256 : int[] = prim::ListConstruct(%114), scope: __module.h.0/__module.h.0.ln_2
  %x.17 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.9, %256, %255, %254, %108, %109), scope: __module.h.0/__module.h.0.ln_2 # torch/nn/functional.py:2048:0
  %258 : int = prim::Constant[value=3072](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %259 : Double() = prim::Constant[value={0.5}](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %260 : float = prim::Constant[value=3.](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %261 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %262 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %263 : Double() = prim::Constant[value={1}](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %264 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.1/__module.h.1.ln_1 # torch/nn/functional.py:2048:0
  %265 : bool = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.ln_1 # torch/nn/functional.py:2048:0
  %266 : int = prim::Constant[value=2304](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1095:0
  %267 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
  %268 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1093:0
  %269 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1093:0
  %270 : int = prim::Constant[value=768](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:371:0
  %271 : int = prim::Constant[value=2](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:371:0
  %272 : Long() = prim::Constant[value={12}](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
  %273 : int = prim::Constant[value=12](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
  %274 : int = prim::Constant[value=3](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
  %275 : Double() = prim::Constant[value={8}](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:180:0
  %276 : int = prim::Constant[value=-2](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
  %277 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
  %278 : Double() = prim::Constant[value={-10000}](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:184:0
  %279 : None = prim::Constant(), scope: __module.h.1/__module.h.1.attn
  %280 : bool = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.attn_dropout # torch/nn/functional.py:973:0
  %281 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.attn_dropout # torch/nn/functional.py:973:0
  %282 : __torch__.torch.nn.modules.normalization.___torch_mangle_29211.LayerNorm = prim::GetAttr[name="ln_2"](%24)
  %283 : __torch__.transformers.modeling_openai.___torch_mangle_29210.MLP = prim::GetAttr[name="mlp"](%24)
  %284 : __torch__.torch.nn.modules.normalization.___torch_mangle_29206.LayerNorm = prim::GetAttr[name="ln_1"](%24)
  %285 : __torch__.transformers.modeling_openai.___torch_mangle_29205.Attention = prim::GetAttr[name="attn"](%24)
  %286 : __torch__.transformers.modeling_utils.___torch_mangle_29202.Conv1D = prim::GetAttr[name="c_proj"](%285)
  %287 : Tensor = prim::GetAttr[name="bias"](%285)
  %288 : __torch__.transformers.modeling_utils.___torch_mangle_29201.Conv1D = prim::GetAttr[name="c_attn"](%285)
  %289 : Tensor = prim::GetAttr[name="weight"](%288)
  %290 : Tensor = prim::GetAttr[name="bias"](%288)
  %291 : int = aten::size(%x.17, %269), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1093:0
  %292 : int = aten::size(%x.17, %268), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1093:0
  %293 : int = aten::size(%x.17, %267), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
  %294 : int[] = prim::ListConstruct(%267, %293), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
  %295 : Float(221:768, 768:1) = aten::view(%x.17, %294), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.18 : Float(221:2304, 2304:1) = aten::addmm(%290, %295, %289, %268, %268), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
  %297 : int[] = prim::ListConstruct(%291, %292, %266), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
  %298 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.18, %297), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1095:0
  %299 : Tensor[] = aten::split(%298, %270, %271), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:371:0
  %x.19 : Float(17:29952, 13:2304, 768:1), %x.21 : Float(17:29952, 13:2304, 768:1), %x.23 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%299), scope: __module.h.1/__module.h.1.attn
  %303 : int = aten::size(%x.19, %269), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
  %304 : int = aten::size(%x.19, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
  %305 : int = aten::size(%x.19, %267), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
  %306 : Long() = prim::NumToTensor(%305), scope: __module.h.1/__module.h.1.attn
  %307 : Long() = aten::floor_divide(%306, %272), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
  %308 : int = aten::Int(%307), scope: __module.h.1/__module.h.1.attn
  %309 : int[] = prim::ListConstruct(%303, %304, %273, %308), scope: __module.h.1/__module.h.1.attn
  %x.20 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.19, %309), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
  %311 : int[] = prim::ListConstruct(%269, %271, %268, %274), scope: __module.h.1/__module.h.1.attn
  %q.2 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.20, %311), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
  %313 : int = aten::size(%x.21, %269), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
  %314 : int = aten::size(%x.21, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
  %315 : int = aten::size(%x.21, %267), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
  %316 : Long() = prim::NumToTensor(%315), scope: __module.h.1/__module.h.1.attn
  %317 : Long() = aten::floor_divide(%316, %272), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
  %318 : int = aten::Int(%317), scope: __module.h.1/__module.h.1.attn
  %319 : int[] = prim::ListConstruct(%313, %314, %273, %318), scope: __module.h.1/__module.h.1.attn
  %x.22 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.21, %319), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
  %321 : int[] = prim::ListConstruct(%269, %271, %274, %268), scope: __module.h.1/__module.h.1.attn
  %k.2 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.22, %321), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:211:0
  %323 : int = aten::size(%x.23, %269), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
  %324 : int = aten::size(%x.23, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
  %325 : int = aten::size(%x.23, %267), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
  %326 : Long() = prim::NumToTensor(%325), scope: __module.h.1/__module.h.1.attn
  %327 : Long() = aten::floor_divide(%326, %272), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
  %328 : int = aten::Int(%327), scope: __module.h.1/__module.h.1.attn
  %329 : int[] = prim::ListConstruct(%323, %324, %273, %328), scope: __module.h.1/__module.h.1.attn
  %x.24 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.23, %329), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
  %331 : int[] = prim::ListConstruct(%269, %271, %268, %274), scope: __module.h.1/__module.h.1.attn
  %v.2 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.24, %331), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
  %w.5 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.2, %k.2), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:178:0
  %w.6 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.5, %275), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:180:0
  %335 : int = aten::size(%w.6, %276), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
  %336 : int = aten::size(%w.6, %267), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
  %337 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%287, %269, %269, %277, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
  %338 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%337, %268, %269, %277, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
  %339 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%338, %271, %269, %335, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
  %b.2 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%339, %274, %269, %336, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
  %341 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.6, %b.2), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:184:0
  %342 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.2, %268, %268), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:396:0
  %343 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%342, %278), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:184:0
  %w.7 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%341, %343, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:184:0
  %input.10 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.7, %attention_mask, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:188:0
  %input.11 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.10, %267, %279), scope: __module.h.1/__module.h.1.attn # torch/nn/functional.py:1498:0
  %w.8 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.11, %281, %280), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.25 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.8, %v.2), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:197:0
  %349 : int[] = prim::ListConstruct(%269, %271, %268, %274), scope: __module.h.1/__module.h.1.attn
  %350 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.25, %349), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:203:0
  %x.26 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%350, %269), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:203:0
  %352 : int = aten::size(%x.26, %269), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
  %353 : int = aten::size(%x.26, %268), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
  %354 : int = aten::size(%x.26, %276), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
  %355 : Long() = prim::NumToTensor(%354), scope: __module.h.1/__module.h.1.attn
  %356 : int = aten::size(%x.26, %267), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
  %357 : Long() = prim::NumToTensor(%356), scope: __module.h.1/__module.h.1.attn
  %358 : Long() = aten::mul(%355, %357), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
  %359 : int = aten::Int(%358), scope: __module.h.1/__module.h.1.attn
  %360 : int[] = prim::ListConstruct(%352, %353, %359), scope: __module.h.1/__module.h.1.attn
  %x.27 : Float(17:9984, 13:768, 768:1) = aten::view(%x.26, %360), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:205:0
  %362 : Tensor = prim::GetAttr[name="weight"](%286)
  %363 : Tensor = prim::GetAttr[name="bias"](%286)
  %364 : int = aten::size(%x.27, %269), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1093:0
  %365 : int = aten::size(%x.27, %268), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1093:0
  %366 : int = aten::size(%x.27, %267), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
  %367 : int[] = prim::ListConstruct(%267, %366), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
  %368 : Float(221:768, 768:1) = aten::view(%x.27, %367), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.28 : Float(221:768, 768:1) = aten::addmm(%363, %368, %362, %268, %268), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
  %370 : int[] = prim::ListConstruct(%364, %365, %270), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
  %input.12 : Float(17:9984, 13:768, 768:1) = aten::view(%x.28, %370), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.2 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.12, %281, %280), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.13 : Float(17:9984, 13:768, 768:1) = aten::add(%x.17, %a.2, %268), scope: __module.h.1 # transformers/modeling_openai.py:266:0
  %374 : Tensor = prim::GetAttr[name="bias"](%284)
  %375 : Tensor = prim::GetAttr[name="weight"](%284)
  %376 : int[] = prim::ListConstruct(%270), scope: __module.h.1/__module.h.1.ln_1
  %x.29 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.13, %376, %375, %374, %264, %265), scope: __module.h.1/__module.h.1.ln_1 # torch/nn/functional.py:2048:0
  %378 : __torch__.transformers.modeling_utils.___torch_mangle_29208.Conv1D = prim::GetAttr[name="c_proj"](%283)
  %379 : __torch__.transformers.modeling_utils.___torch_mangle_29207.Conv1D = prim::GetAttr[name="c_fc"](%283)
  %380 : Tensor = prim::GetAttr[name="weight"](%379)
  %381 : Tensor = prim::GetAttr[name="bias"](%379)
  %382 : int = aten::size(%x.29, %269), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %383 : int = aten::size(%x.29, %268), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %384 : int = aten::size(%x.29, %267), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %385 : int[] = prim::ListConstruct(%267, %384), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
  %386 : Float(221:768, 768:1) = aten::view(%x.29, %385), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.30 : Float(221:3072, 3072:1) = aten::addmm(%381, %386, %380, %268, %268), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %388 : int[] = prim::ListConstruct(%382, %383, %258), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
  %x.31 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.30, %388), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %390 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.31, %259), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %391 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.31, %260), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %392 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%391, %261), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %393 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.31, %392, %268), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %394 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%393, %262), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %395 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%394), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %396 : Float(17:39936, 13:3072, 3072:1) = aten::add(%395, %263, %268), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %x.32 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%390, %396), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
  %398 : Tensor = prim::GetAttr[name="weight"](%378)
  %399 : Tensor = prim::GetAttr[name="bias"](%378)
  %400 : int = aten::size(%x.32, %269), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %401 : int = aten::size(%x.32, %268), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %402 : int = aten::size(%x.32, %267), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %403 : int[] = prim::ListConstruct(%267, %402), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
  %404 : Float(221:3072, 3072:1) = aten::view(%x.32, %403), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.33 : Float(221:768, 768:1) = aten::addmm(%399, %404, %398, %268, %268), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %406 : int[] = prim::ListConstruct(%400, %401, %270), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
  %input.14 : Float(17:9984, 13:768, 768:1) = aten::view(%x.33, %406), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.2 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.14, %281, %280), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.dropout # torch/nn/functional.py:973:0
  %input.15 : Float(17:9984, 13:768, 768:1) = aten::add(%x.29, %m.2, %268), scope: __module.h.1 # transformers/modeling_openai.py:268:0
  %410 : Tensor = prim::GetAttr[name="bias"](%282)
  %411 : Tensor = prim::GetAttr[name="weight"](%282)
  %412 : int[] = prim::ListConstruct(%270), scope: __module.h.1/__module.h.1.ln_2
  %x.34 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.15, %412, %411, %410, %264, %265), scope: __module.h.1/__module.h.1.ln_2 # torch/nn/functional.py:2048:0
  %414 : int = prim::Constant[value=3072](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %415 : Double() = prim::Constant[value={0.5}](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %416 : float = prim::Constant[value=3.](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %417 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %418 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %419 : Double() = prim::Constant[value={1}](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %420 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.2/__module.h.2.ln_1 # torch/nn/functional.py:2048:0
  %421 : bool = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.ln_1 # torch/nn/functional.py:2048:0
  %422 : int = prim::Constant[value=2304](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1095:0
  %423 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
  %424 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1093:0
  %425 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1093:0
  %426 : int = prim::Constant[value=768](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:371:0
  %427 : int = prim::Constant[value=2](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:371:0
  %428 : Long() = prim::Constant[value={12}](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
  %429 : int = prim::Constant[value=12](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
  %430 : int = prim::Constant[value=3](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
  %431 : Double() = prim::Constant[value={8}](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:180:0
  %432 : int = prim::Constant[value=-2](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
  %433 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
  %434 : Double() = prim::Constant[value={-10000}](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:184:0
  %435 : None = prim::Constant(), scope: __module.h.2/__module.h.2.attn
  %436 : bool = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.attn_dropout # torch/nn/functional.py:973:0
  %437 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.attn_dropout # torch/nn/functional.py:973:0
  %438 : __torch__.torch.nn.modules.normalization.___torch_mangle_29223.LayerNorm = prim::GetAttr[name="ln_2"](%22)
  %439 : __torch__.transformers.modeling_openai.___torch_mangle_29222.MLP = prim::GetAttr[name="mlp"](%22)
  %440 : __torch__.torch.nn.modules.normalization.___torch_mangle_29218.LayerNorm = prim::GetAttr[name="ln_1"](%22)
  %441 : __torch__.transformers.modeling_openai.___torch_mangle_29217.Attention = prim::GetAttr[name="attn"](%22)
  %442 : __torch__.transformers.modeling_utils.___torch_mangle_29214.Conv1D = prim::GetAttr[name="c_proj"](%441)
  %443 : Tensor = prim::GetAttr[name="bias"](%441)
  %444 : __torch__.transformers.modeling_utils.___torch_mangle_29213.Conv1D = prim::GetAttr[name="c_attn"](%441)
  %445 : Tensor = prim::GetAttr[name="weight"](%444)
  %446 : Tensor = prim::GetAttr[name="bias"](%444)
  %447 : int = aten::size(%x.34, %425), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1093:0
  %448 : int = aten::size(%x.34, %424), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1093:0
  %449 : int = aten::size(%x.34, %423), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
  %450 : int[] = prim::ListConstruct(%423, %449), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
  %451 : Float(221:768, 768:1) = aten::view(%x.34, %450), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.35 : Float(221:2304, 2304:1) = aten::addmm(%446, %451, %445, %424, %424), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
  %453 : int[] = prim::ListConstruct(%447, %448, %422), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
  %454 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.35, %453), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1095:0
  %455 : Tensor[] = aten::split(%454, %426, %427), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:371:0
  %x.36 : Float(17:29952, 13:2304, 768:1), %x.38 : Float(17:29952, 13:2304, 768:1), %x.40 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%455), scope: __module.h.2/__module.h.2.attn
  %459 : int = aten::size(%x.36, %425), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
  %460 : int = aten::size(%x.36, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
  %461 : int = aten::size(%x.36, %423), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
  %462 : Long() = prim::NumToTensor(%461), scope: __module.h.2/__module.h.2.attn
  %463 : Long() = aten::floor_divide(%462, %428), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
  %464 : int = aten::Int(%463), scope: __module.h.2/__module.h.2.attn
  %465 : int[] = prim::ListConstruct(%459, %460, %429, %464), scope: __module.h.2/__module.h.2.attn
  %x.37 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.36, %465), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
  %467 : int[] = prim::ListConstruct(%425, %427, %424, %430), scope: __module.h.2/__module.h.2.attn
  %q.3 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.37, %467), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
  %469 : int = aten::size(%x.38, %425), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
  %470 : int = aten::size(%x.38, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
  %471 : int = aten::size(%x.38, %423), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
  %472 : Long() = prim::NumToTensor(%471), scope: __module.h.2/__module.h.2.attn
  %473 : Long() = aten::floor_divide(%472, %428), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
  %474 : int = aten::Int(%473), scope: __module.h.2/__module.h.2.attn
  %475 : int[] = prim::ListConstruct(%469, %470, %429, %474), scope: __module.h.2/__module.h.2.attn
  %x.39 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.38, %475), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
  %477 : int[] = prim::ListConstruct(%425, %427, %430, %424), scope: __module.h.2/__module.h.2.attn
  %k.3 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.39, %477), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:211:0
  %479 : int = aten::size(%x.40, %425), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
  %480 : int = aten::size(%x.40, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
  %481 : int = aten::size(%x.40, %423), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
  %482 : Long() = prim::NumToTensor(%481), scope: __module.h.2/__module.h.2.attn
  %483 : Long() = aten::floor_divide(%482, %428), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
  %484 : int = aten::Int(%483), scope: __module.h.2/__module.h.2.attn
  %485 : int[] = prim::ListConstruct(%479, %480, %429, %484), scope: __module.h.2/__module.h.2.attn
  %x.41 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.40, %485), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
  %487 : int[] = prim::ListConstruct(%425, %427, %424, %430), scope: __module.h.2/__module.h.2.attn
  %v.3 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.41, %487), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
  %w.9 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.3, %k.3), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:178:0
  %w.10 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.9, %431), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:180:0
  %491 : int = aten::size(%w.10, %432), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
  %492 : int = aten::size(%w.10, %423), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
  %493 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%443, %425, %425, %433, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
  %494 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%493, %424, %425, %433, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
  %495 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%494, %427, %425, %491, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
  %b.3 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%495, %430, %425, %492, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
  %497 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.10, %b.3), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:184:0
  %498 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.3, %424, %424), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:396:0
  %499 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%498, %434), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:184:0
  %w.11 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%497, %499, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:184:0
  %input.16 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.11, %attention_mask, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:188:0
  %input.17 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.16, %423, %435), scope: __module.h.2/__module.h.2.attn # torch/nn/functional.py:1498:0
  %w.12 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.17, %437, %436), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.42 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.12, %v.3), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:197:0
  %505 : int[] = prim::ListConstruct(%425, %427, %424, %430), scope: __module.h.2/__module.h.2.attn
  %506 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.42, %505), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:203:0
  %x.43 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%506, %425), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:203:0
  %508 : int = aten::size(%x.43, %425), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
  %509 : int = aten::size(%x.43, %424), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
  %510 : int = aten::size(%x.43, %432), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
  %511 : Long() = prim::NumToTensor(%510), scope: __module.h.2/__module.h.2.attn
  %512 : int = aten::size(%x.43, %423), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
  %513 : Long() = prim::NumToTensor(%512), scope: __module.h.2/__module.h.2.attn
  %514 : Long() = aten::mul(%511, %513), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
  %515 : int = aten::Int(%514), scope: __module.h.2/__module.h.2.attn
  %516 : int[] = prim::ListConstruct(%508, %509, %515), scope: __module.h.2/__module.h.2.attn
  %x.44 : Float(17:9984, 13:768, 768:1) = aten::view(%x.43, %516), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:205:0
  %518 : Tensor = prim::GetAttr[name="weight"](%442)
  %519 : Tensor = prim::GetAttr[name="bias"](%442)
  %520 : int = aten::size(%x.44, %425), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1093:0
  %521 : int = aten::size(%x.44, %424), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1093:0
  %522 : int = aten::size(%x.44, %423), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
  %523 : int[] = prim::ListConstruct(%423, %522), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
  %524 : Float(221:768, 768:1) = aten::view(%x.44, %523), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.45 : Float(221:768, 768:1) = aten::addmm(%519, %524, %518, %424, %424), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
  %526 : int[] = prim::ListConstruct(%520, %521, %426), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
  %input.18 : Float(17:9984, 13:768, 768:1) = aten::view(%x.45, %526), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.3 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.18, %437, %436), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.19 : Float(17:9984, 13:768, 768:1) = aten::add(%x.34, %a.3, %424), scope: __module.h.2 # transformers/modeling_openai.py:266:0
  %530 : Tensor = prim::GetAttr[name="bias"](%440)
  %531 : Tensor = prim::GetAttr[name="weight"](%440)
  %532 : int[] = prim::ListConstruct(%426), scope: __module.h.2/__module.h.2.ln_1
  %x.46 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.19, %532, %531, %530, %420, %421), scope: __module.h.2/__module.h.2.ln_1 # torch/nn/functional.py:2048:0
  %534 : __torch__.transformers.modeling_utils.___torch_mangle_29220.Conv1D = prim::GetAttr[name="c_proj"](%439)
  %535 : __torch__.transformers.modeling_utils.___torch_mangle_29219.Conv1D = prim::GetAttr[name="c_fc"](%439)
  %536 : Tensor = prim::GetAttr[name="weight"](%535)
  %537 : Tensor = prim::GetAttr[name="bias"](%535)
  %538 : int = aten::size(%x.46, %425), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %539 : int = aten::size(%x.46, %424), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %540 : int = aten::size(%x.46, %423), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %541 : int[] = prim::ListConstruct(%423, %540), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
  %542 : Float(221:768, 768:1) = aten::view(%x.46, %541), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.47 : Float(221:3072, 3072:1) = aten::addmm(%537, %542, %536, %424, %424), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %544 : int[] = prim::ListConstruct(%538, %539, %414), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
  %x.48 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.47, %544), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %546 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.48, %415), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %547 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.48, %416), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %548 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%547, %417), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %549 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.48, %548, %424), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %550 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%549, %418), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %551 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%550), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %552 : Float(17:39936, 13:3072, 3072:1) = aten::add(%551, %419, %424), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %x.49 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%546, %552), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
  %554 : Tensor = prim::GetAttr[name="weight"](%534)
  %555 : Tensor = prim::GetAttr[name="bias"](%534)
  %556 : int = aten::size(%x.49, %425), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %557 : int = aten::size(%x.49, %424), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %558 : int = aten::size(%x.49, %423), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %559 : int[] = prim::ListConstruct(%423, %558), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
  %560 : Float(221:3072, 3072:1) = aten::view(%x.49, %559), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.50 : Float(221:768, 768:1) = aten::addmm(%555, %560, %554, %424, %424), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %562 : int[] = prim::ListConstruct(%556, %557, %426), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
  %input.20 : Float(17:9984, 13:768, 768:1) = aten::view(%x.50, %562), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.3 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.20, %437, %436), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.dropout # torch/nn/functional.py:973:0
  %input.21 : Float(17:9984, 13:768, 768:1) = aten::add(%x.46, %m.3, %424), scope: __module.h.2 # transformers/modeling_openai.py:268:0
  %566 : Tensor = prim::GetAttr[name="bias"](%438)
  %567 : Tensor = prim::GetAttr[name="weight"](%438)
  %568 : int[] = prim::ListConstruct(%426), scope: __module.h.2/__module.h.2.ln_2
  %x.51 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.21, %568, %567, %566, %420, %421), scope: __module.h.2/__module.h.2.ln_2 # torch/nn/functional.py:2048:0
  %570 : int = prim::Constant[value=3072](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %571 : Double() = prim::Constant[value={0.5}](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %572 : float = prim::Constant[value=3.](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %573 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %574 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %575 : Double() = prim::Constant[value={1}](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %576 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.3/__module.h.3.ln_1 # torch/nn/functional.py:2048:0
  %577 : bool = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.ln_1 # torch/nn/functional.py:2048:0
  %578 : int = prim::Constant[value=2304](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1095:0
  %579 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
  %580 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1093:0
  %581 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1093:0
  %582 : int = prim::Constant[value=768](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:371:0
  %583 : int = prim::Constant[value=2](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:371:0
  %584 : Long() = prim::Constant[value={12}](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
  %585 : int = prim::Constant[value=12](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
  %586 : int = prim::Constant[value=3](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
  %587 : Double() = prim::Constant[value={8}](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:180:0
  %588 : int = prim::Constant[value=-2](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
  %589 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
  %590 : Double() = prim::Constant[value={-10000}](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:184:0
  %591 : None = prim::Constant(), scope: __module.h.3/__module.h.3.attn
  %592 : bool = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.attn_dropout # torch/nn/functional.py:973:0
  %593 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.attn_dropout # torch/nn/functional.py:973:0
  %594 : __torch__.torch.nn.modules.normalization.___torch_mangle_29235.LayerNorm = prim::GetAttr[name="ln_2"](%20)
  %595 : __torch__.transformers.modeling_openai.___torch_mangle_29234.MLP = prim::GetAttr[name="mlp"](%20)
  %596 : __torch__.torch.nn.modules.normalization.___torch_mangle_29230.LayerNorm = prim::GetAttr[name="ln_1"](%20)
  %597 : __torch__.transformers.modeling_openai.___torch_mangle_29229.Attention = prim::GetAttr[name="attn"](%20)
  %598 : __torch__.transformers.modeling_utils.___torch_mangle_29226.Conv1D = prim::GetAttr[name="c_proj"](%597)
  %599 : Tensor = prim::GetAttr[name="bias"](%597)
  %600 : __torch__.transformers.modeling_utils.___torch_mangle_29225.Conv1D = prim::GetAttr[name="c_attn"](%597)
  %601 : Tensor = prim::GetAttr[name="weight"](%600)
  %602 : Tensor = prim::GetAttr[name="bias"](%600)
  %603 : int = aten::size(%x.51, %581), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1093:0
  %604 : int = aten::size(%x.51, %580), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1093:0
  %605 : int = aten::size(%x.51, %579), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
  %606 : int[] = prim::ListConstruct(%579, %605), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
  %607 : Float(221:768, 768:1) = aten::view(%x.51, %606), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.52 : Float(221:2304, 2304:1) = aten::addmm(%602, %607, %601, %580, %580), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
  %609 : int[] = prim::ListConstruct(%603, %604, %578), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
  %610 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.52, %609), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1095:0
  %611 : Tensor[] = aten::split(%610, %582, %583), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:371:0
  %x.53 : Float(17:29952, 13:2304, 768:1), %x.55 : Float(17:29952, 13:2304, 768:1), %x.57 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%611), scope: __module.h.3/__module.h.3.attn
  %615 : int = aten::size(%x.53, %581), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
  %616 : int = aten::size(%x.53, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
  %617 : int = aten::size(%x.53, %579), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
  %618 : Long() = prim::NumToTensor(%617), scope: __module.h.3/__module.h.3.attn
  %619 : Long() = aten::floor_divide(%618, %584), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
  %620 : int = aten::Int(%619), scope: __module.h.3/__module.h.3.attn
  %621 : int[] = prim::ListConstruct(%615, %616, %585, %620), scope: __module.h.3/__module.h.3.attn
  %x.54 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.53, %621), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
  %623 : int[] = prim::ListConstruct(%581, %583, %580, %586), scope: __module.h.3/__module.h.3.attn
  %q.4 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.54, %623), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
  %625 : int = aten::size(%x.55, %581), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
  %626 : int = aten::size(%x.55, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
  %627 : int = aten::size(%x.55, %579), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
  %628 : Long() = prim::NumToTensor(%627), scope: __module.h.3/__module.h.3.attn
  %629 : Long() = aten::floor_divide(%628, %584), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
  %630 : int = aten::Int(%629), scope: __module.h.3/__module.h.3.attn
  %631 : int[] = prim::ListConstruct(%625, %626, %585, %630), scope: __module.h.3/__module.h.3.attn
  %x.56 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.55, %631), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
  %633 : int[] = prim::ListConstruct(%581, %583, %586, %580), scope: __module.h.3/__module.h.3.attn
  %k.4 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.56, %633), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:211:0
  %635 : int = aten::size(%x.57, %581), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
  %636 : int = aten::size(%x.57, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
  %637 : int = aten::size(%x.57, %579), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
  %638 : Long() = prim::NumToTensor(%637), scope: __module.h.3/__module.h.3.attn
  %639 : Long() = aten::floor_divide(%638, %584), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
  %640 : int = aten::Int(%639), scope: __module.h.3/__module.h.3.attn
  %641 : int[] = prim::ListConstruct(%635, %636, %585, %640), scope: __module.h.3/__module.h.3.attn
  %x.58 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.57, %641), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
  %643 : int[] = prim::ListConstruct(%581, %583, %580, %586), scope: __module.h.3/__module.h.3.attn
  %v.4 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.58, %643), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
  %w.13 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.4, %k.4), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:178:0
  %w.14 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.13, %587), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:180:0
  %647 : int = aten::size(%w.14, %588), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
  %648 : int = aten::size(%w.14, %579), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
  %649 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%599, %581, %581, %589, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
  %650 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%649, %580, %581, %589, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
  %651 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%650, %583, %581, %647, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
  %b.4 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%651, %586, %581, %648, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
  %653 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.14, %b.4), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:184:0
  %654 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.4, %580, %580), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:396:0
  %655 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%654, %590), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:184:0
  %w.15 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%653, %655, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:184:0
  %input.22 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.15, %attention_mask, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:188:0
  %input.23 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.22, %579, %591), scope: __module.h.3/__module.h.3.attn # torch/nn/functional.py:1498:0
  %w.16 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.23, %593, %592), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.59 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.16, %v.4), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:197:0
  %661 : int[] = prim::ListConstruct(%581, %583, %580, %586), scope: __module.h.3/__module.h.3.attn
  %662 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.59, %661), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:203:0
  %x.60 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%662, %581), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:203:0
  %664 : int = aten::size(%x.60, %581), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
  %665 : int = aten::size(%x.60, %580), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
  %666 : int = aten::size(%x.60, %588), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
  %667 : Long() = prim::NumToTensor(%666), scope: __module.h.3/__module.h.3.attn
  %668 : int = aten::size(%x.60, %579), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
  %669 : Long() = prim::NumToTensor(%668), scope: __module.h.3/__module.h.3.attn
  %670 : Long() = aten::mul(%667, %669), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
  %671 : int = aten::Int(%670), scope: __module.h.3/__module.h.3.attn
  %672 : int[] = prim::ListConstruct(%664, %665, %671), scope: __module.h.3/__module.h.3.attn
  %x.61 : Float(17:9984, 13:768, 768:1) = aten::view(%x.60, %672), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:205:0
  %674 : Tensor = prim::GetAttr[name="weight"](%598)
  %675 : Tensor = prim::GetAttr[name="bias"](%598)
  %676 : int = aten::size(%x.61, %581), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1093:0
  %677 : int = aten::size(%x.61, %580), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1093:0
  %678 : int = aten::size(%x.61, %579), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
  %679 : int[] = prim::ListConstruct(%579, %678), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
  %680 : Float(221:768, 768:1) = aten::view(%x.61, %679), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.62 : Float(221:768, 768:1) = aten::addmm(%675, %680, %674, %580, %580), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
  %682 : int[] = prim::ListConstruct(%676, %677, %582), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
  %input.24 : Float(17:9984, 13:768, 768:1) = aten::view(%x.62, %682), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.4 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.24, %593, %592), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.25 : Float(17:9984, 13:768, 768:1) = aten::add(%x.51, %a.4, %580), scope: __module.h.3 # transformers/modeling_openai.py:266:0
  %686 : Tensor = prim::GetAttr[name="bias"](%596)
  %687 : Tensor = prim::GetAttr[name="weight"](%596)
  %688 : int[] = prim::ListConstruct(%582), scope: __module.h.3/__module.h.3.ln_1
  %x.63 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.25, %688, %687, %686, %576, %577), scope: __module.h.3/__module.h.3.ln_1 # torch/nn/functional.py:2048:0
  %690 : __torch__.transformers.modeling_utils.___torch_mangle_29232.Conv1D = prim::GetAttr[name="c_proj"](%595)
  %691 : __torch__.transformers.modeling_utils.___torch_mangle_29231.Conv1D = prim::GetAttr[name="c_fc"](%595)
  %692 : Tensor = prim::GetAttr[name="weight"](%691)
  %693 : Tensor = prim::GetAttr[name="bias"](%691)
  %694 : int = aten::size(%x.63, %581), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %695 : int = aten::size(%x.63, %580), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %696 : int = aten::size(%x.63, %579), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %697 : int[] = prim::ListConstruct(%579, %696), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
  %698 : Float(221:768, 768:1) = aten::view(%x.63, %697), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.64 : Float(221:3072, 3072:1) = aten::addmm(%693, %698, %692, %580, %580), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %700 : int[] = prim::ListConstruct(%694, %695, %570), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
  %x.65 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.64, %700), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %702 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.65, %571), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %703 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.65, %572), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %704 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%703, %573), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %705 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.65, %704, %580), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %706 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%705, %574), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %707 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%706), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %708 : Float(17:39936, 13:3072, 3072:1) = aten::add(%707, %575, %580), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %x.66 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%702, %708), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
  %710 : Tensor = prim::GetAttr[name="weight"](%690)
  %711 : Tensor = prim::GetAttr[name="bias"](%690)
  %712 : int = aten::size(%x.66, %581), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %713 : int = aten::size(%x.66, %580), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %714 : int = aten::size(%x.66, %579), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %715 : int[] = prim::ListConstruct(%579, %714), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
  %716 : Float(221:3072, 3072:1) = aten::view(%x.66, %715), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.67 : Float(221:768, 768:1) = aten::addmm(%711, %716, %710, %580, %580), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %718 : int[] = prim::ListConstruct(%712, %713, %582), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
  %input.26 : Float(17:9984, 13:768, 768:1) = aten::view(%x.67, %718), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.4 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.26, %593, %592), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.dropout # torch/nn/functional.py:973:0
  %input.27 : Float(17:9984, 13:768, 768:1) = aten::add(%x.63, %m.4, %580), scope: __module.h.3 # transformers/modeling_openai.py:268:0
  %722 : Tensor = prim::GetAttr[name="bias"](%594)
  %723 : Tensor = prim::GetAttr[name="weight"](%594)
  %724 : int[] = prim::ListConstruct(%582), scope: __module.h.3/__module.h.3.ln_2
  %x.68 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.27, %724, %723, %722, %576, %577), scope: __module.h.3/__module.h.3.ln_2 # torch/nn/functional.py:2048:0
  %726 : int = prim::Constant[value=3072](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %727 : Double() = prim::Constant[value={0.5}](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %728 : float = prim::Constant[value=3.](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %729 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %730 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %731 : Double() = prim::Constant[value={1}](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %732 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.4/__module.h.4.ln_1 # torch/nn/functional.py:2048:0
  %733 : bool = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.ln_1 # torch/nn/functional.py:2048:0
  %734 : int = prim::Constant[value=2304](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1095:0
  %735 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
  %736 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1093:0
  %737 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1093:0
  %738 : int = prim::Constant[value=768](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:371:0
  %739 : int = prim::Constant[value=2](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:371:0
  %740 : Long() = prim::Constant[value={12}](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
  %741 : int = prim::Constant[value=12](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
  %742 : int = prim::Constant[value=3](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
  %743 : Double() = prim::Constant[value={8}](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:180:0
  %744 : int = prim::Constant[value=-2](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
  %745 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
  %746 : Double() = prim::Constant[value={-10000}](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:184:0
  %747 : None = prim::Constant(), scope: __module.h.4/__module.h.4.attn
  %748 : bool = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.attn_dropout # torch/nn/functional.py:973:0
  %749 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.attn_dropout # torch/nn/functional.py:973:0
  %750 : __torch__.torch.nn.modules.normalization.___torch_mangle_29247.LayerNorm = prim::GetAttr[name="ln_2"](%18)
  %751 : __torch__.transformers.modeling_openai.___torch_mangle_29246.MLP = prim::GetAttr[name="mlp"](%18)
  %752 : __torch__.torch.nn.modules.normalization.___torch_mangle_29242.LayerNorm = prim::GetAttr[name="ln_1"](%18)
  %753 : __torch__.transformers.modeling_openai.___torch_mangle_29241.Attention = prim::GetAttr[name="attn"](%18)
  %754 : __torch__.transformers.modeling_utils.___torch_mangle_29238.Conv1D = prim::GetAttr[name="c_proj"](%753)
  %755 : Tensor = prim::GetAttr[name="bias"](%753)
  %756 : __torch__.transformers.modeling_utils.___torch_mangle_29237.Conv1D = prim::GetAttr[name="c_attn"](%753)
  %757 : Tensor = prim::GetAttr[name="weight"](%756)
  %758 : Tensor = prim::GetAttr[name="bias"](%756)
  %759 : int = aten::size(%x.68, %737), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1093:0
  %760 : int = aten::size(%x.68, %736), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1093:0
  %761 : int = aten::size(%x.68, %735), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
  %762 : int[] = prim::ListConstruct(%735, %761), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
  %763 : Float(221:768, 768:1) = aten::view(%x.68, %762), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.69 : Float(221:2304, 2304:1) = aten::addmm(%758, %763, %757, %736, %736), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
  %765 : int[] = prim::ListConstruct(%759, %760, %734), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
  %766 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.69, %765), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1095:0
  %767 : Tensor[] = aten::split(%766, %738, %739), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:371:0
  %x.70 : Float(17:29952, 13:2304, 768:1), %x.72 : Float(17:29952, 13:2304, 768:1), %x.74 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%767), scope: __module.h.4/__module.h.4.attn
  %771 : int = aten::size(%x.70, %737), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
  %772 : int = aten::size(%x.70, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
  %773 : int = aten::size(%x.70, %735), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
  %774 : Long() = prim::NumToTensor(%773), scope: __module.h.4/__module.h.4.attn
  %775 : Long() = aten::floor_divide(%774, %740), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
  %776 : int = aten::Int(%775), scope: __module.h.4/__module.h.4.attn
  %777 : int[] = prim::ListConstruct(%771, %772, %741, %776), scope: __module.h.4/__module.h.4.attn
  %x.71 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.70, %777), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
  %779 : int[] = prim::ListConstruct(%737, %739, %736, %742), scope: __module.h.4/__module.h.4.attn
  %q.5 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.71, %779), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
  %781 : int = aten::size(%x.72, %737), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
  %782 : int = aten::size(%x.72, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
  %783 : int = aten::size(%x.72, %735), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
  %784 : Long() = prim::NumToTensor(%783), scope: __module.h.4/__module.h.4.attn
  %785 : Long() = aten::floor_divide(%784, %740), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
  %786 : int = aten::Int(%785), scope: __module.h.4/__module.h.4.attn
  %787 : int[] = prim::ListConstruct(%781, %782, %741, %786), scope: __module.h.4/__module.h.4.attn
  %x.73 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.72, %787), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
  %789 : int[] = prim::ListConstruct(%737, %739, %742, %736), scope: __module.h.4/__module.h.4.attn
  %k.5 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.73, %789), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:211:0
  %791 : int = aten::size(%x.74, %737), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
  %792 : int = aten::size(%x.74, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
  %793 : int = aten::size(%x.74, %735), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
  %794 : Long() = prim::NumToTensor(%793), scope: __module.h.4/__module.h.4.attn
  %795 : Long() = aten::floor_divide(%794, %740), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
  %796 : int = aten::Int(%795), scope: __module.h.4/__module.h.4.attn
  %797 : int[] = prim::ListConstruct(%791, %792, %741, %796), scope: __module.h.4/__module.h.4.attn
  %x.75 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.74, %797), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
  %799 : int[] = prim::ListConstruct(%737, %739, %736, %742), scope: __module.h.4/__module.h.4.attn
  %v.5 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.75, %799), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
  %w.17 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.5, %k.5), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:178:0
  %w.18 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.17, %743), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:180:0
  %803 : int = aten::size(%w.18, %744), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
  %804 : int = aten::size(%w.18, %735), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
  %805 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%755, %737, %737, %745, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
  %806 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%805, %736, %737, %745, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
  %807 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%806, %739, %737, %803, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
  %b.5 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%807, %742, %737, %804, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
  %809 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.18, %b.5), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:184:0
  %810 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.5, %736, %736), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:396:0
  %811 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%810, %746), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:184:0
  %w.19 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%809, %811, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:184:0
  %input.28 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.19, %attention_mask, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:188:0
  %input.29 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.28, %735, %747), scope: __module.h.4/__module.h.4.attn # torch/nn/functional.py:1498:0
  %w.20 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.29, %749, %748), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.76 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.20, %v.5), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:197:0
  %817 : int[] = prim::ListConstruct(%737, %739, %736, %742), scope: __module.h.4/__module.h.4.attn
  %818 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.76, %817), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:203:0
  %x.77 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%818, %737), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:203:0
  %820 : int = aten::size(%x.77, %737), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
  %821 : int = aten::size(%x.77, %736), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
  %822 : int = aten::size(%x.77, %744), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
  %823 : Long() = prim::NumToTensor(%822), scope: __module.h.4/__module.h.4.attn
  %824 : int = aten::size(%x.77, %735), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
  %825 : Long() = prim::NumToTensor(%824), scope: __module.h.4/__module.h.4.attn
  %826 : Long() = aten::mul(%823, %825), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
  %827 : int = aten::Int(%826), scope: __module.h.4/__module.h.4.attn
  %828 : int[] = prim::ListConstruct(%820, %821, %827), scope: __module.h.4/__module.h.4.attn
  %x.78 : Float(17:9984, 13:768, 768:1) = aten::view(%x.77, %828), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:205:0
  %830 : Tensor = prim::GetAttr[name="weight"](%754)
  %831 : Tensor = prim::GetAttr[name="bias"](%754)
  %832 : int = aten::size(%x.78, %737), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1093:0
  %833 : int = aten::size(%x.78, %736), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1093:0
  %834 : int = aten::size(%x.78, %735), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
  %835 : int[] = prim::ListConstruct(%735, %834), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
  %836 : Float(221:768, 768:1) = aten::view(%x.78, %835), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.79 : Float(221:768, 768:1) = aten::addmm(%831, %836, %830, %736, %736), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
  %838 : int[] = prim::ListConstruct(%832, %833, %738), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
  %input.30 : Float(17:9984, 13:768, 768:1) = aten::view(%x.79, %838), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.5 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.30, %749, %748), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.31 : Float(17:9984, 13:768, 768:1) = aten::add(%x.68, %a.5, %736), scope: __module.h.4 # transformers/modeling_openai.py:266:0
  %842 : Tensor = prim::GetAttr[name="bias"](%752)
  %843 : Tensor = prim::GetAttr[name="weight"](%752)
  %844 : int[] = prim::ListConstruct(%738), scope: __module.h.4/__module.h.4.ln_1
  %x.80 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.31, %844, %843, %842, %732, %733), scope: __module.h.4/__module.h.4.ln_1 # torch/nn/functional.py:2048:0
  %846 : __torch__.transformers.modeling_utils.___torch_mangle_29244.Conv1D = prim::GetAttr[name="c_proj"](%751)
  %847 : __torch__.transformers.modeling_utils.___torch_mangle_29243.Conv1D = prim::GetAttr[name="c_fc"](%751)
  %848 : Tensor = prim::GetAttr[name="weight"](%847)
  %849 : Tensor = prim::GetAttr[name="bias"](%847)
  %850 : int = aten::size(%x.80, %737), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %851 : int = aten::size(%x.80, %736), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %852 : int = aten::size(%x.80, %735), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %853 : int[] = prim::ListConstruct(%735, %852), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
  %854 : Float(221:768, 768:1) = aten::view(%x.80, %853), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.81 : Float(221:3072, 3072:1) = aten::addmm(%849, %854, %848, %736, %736), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %856 : int[] = prim::ListConstruct(%850, %851, %726), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
  %x.82 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.81, %856), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %858 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.82, %727), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %859 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.82, %728), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %860 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%859, %729), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %861 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.82, %860, %736), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %862 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%861, %730), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %863 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%862), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %864 : Float(17:39936, 13:3072, 3072:1) = aten::add(%863, %731, %736), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %x.83 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%858, %864), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
  %866 : Tensor = prim::GetAttr[name="weight"](%846)
  %867 : Tensor = prim::GetAttr[name="bias"](%846)
  %868 : int = aten::size(%x.83, %737), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %869 : int = aten::size(%x.83, %736), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %870 : int = aten::size(%x.83, %735), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %871 : int[] = prim::ListConstruct(%735, %870), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
  %872 : Float(221:3072, 3072:1) = aten::view(%x.83, %871), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.84 : Float(221:768, 768:1) = aten::addmm(%867, %872, %866, %736, %736), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %874 : int[] = prim::ListConstruct(%868, %869, %738), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
  %input.32 : Float(17:9984, 13:768, 768:1) = aten::view(%x.84, %874), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.5 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.32, %749, %748), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.dropout # torch/nn/functional.py:973:0
  %input.33 : Float(17:9984, 13:768, 768:1) = aten::add(%x.80, %m.5, %736), scope: __module.h.4 # transformers/modeling_openai.py:268:0
  %878 : Tensor = prim::GetAttr[name="bias"](%750)
  %879 : Tensor = prim::GetAttr[name="weight"](%750)
  %880 : int[] = prim::ListConstruct(%738), scope: __module.h.4/__module.h.4.ln_2
  %x.85 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.33, %880, %879, %878, %732, %733), scope: __module.h.4/__module.h.4.ln_2 # torch/nn/functional.py:2048:0
  %882 : int = prim::Constant[value=3072](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %883 : Double() = prim::Constant[value={0.5}](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %884 : float = prim::Constant[value=3.](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %885 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %886 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %887 : Double() = prim::Constant[value={1}](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %888 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.5/__module.h.5.ln_1 # torch/nn/functional.py:2048:0
  %889 : bool = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.ln_1 # torch/nn/functional.py:2048:0
  %890 : int = prim::Constant[value=2304](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1095:0
  %891 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
  %892 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1093:0
  %893 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1093:0
  %894 : int = prim::Constant[value=768](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:371:0
  %895 : int = prim::Constant[value=2](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:371:0
  %896 : Long() = prim::Constant[value={12}](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
  %897 : int = prim::Constant[value=12](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
  %898 : int = prim::Constant[value=3](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
  %899 : Double() = prim::Constant[value={8}](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:180:0
  %900 : int = prim::Constant[value=-2](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
  %901 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
  %902 : Double() = prim::Constant[value={-10000}](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:184:0
  %903 : None = prim::Constant(), scope: __module.h.5/__module.h.5.attn
  %904 : bool = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.attn_dropout # torch/nn/functional.py:973:0
  %905 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.attn_dropout # torch/nn/functional.py:973:0
  %906 : __torch__.torch.nn.modules.normalization.___torch_mangle_29259.LayerNorm = prim::GetAttr[name="ln_2"](%16)
  %907 : __torch__.transformers.modeling_openai.___torch_mangle_29258.MLP = prim::GetAttr[name="mlp"](%16)
  %908 : __torch__.torch.nn.modules.normalization.___torch_mangle_29254.LayerNorm = prim::GetAttr[name="ln_1"](%16)
  %909 : __torch__.transformers.modeling_openai.___torch_mangle_29253.Attention = prim::GetAttr[name="attn"](%16)
  %910 : __torch__.transformers.modeling_utils.___torch_mangle_29250.Conv1D = prim::GetAttr[name="c_proj"](%909)
  %911 : Tensor = prim::GetAttr[name="bias"](%909)
  %912 : __torch__.transformers.modeling_utils.___torch_mangle_29249.Conv1D = prim::GetAttr[name="c_attn"](%909)
  %913 : Tensor = prim::GetAttr[name="weight"](%912)
  %914 : Tensor = prim::GetAttr[name="bias"](%912)
  %915 : int = aten::size(%x.85, %893), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1093:0
  %916 : int = aten::size(%x.85, %892), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1093:0
  %917 : int = aten::size(%x.85, %891), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
  %918 : int[] = prim::ListConstruct(%891, %917), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
  %919 : Float(221:768, 768:1) = aten::view(%x.85, %918), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.86 : Float(221:2304, 2304:1) = aten::addmm(%914, %919, %913, %892, %892), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
  %921 : int[] = prim::ListConstruct(%915, %916, %890), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
  %922 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.86, %921), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1095:0
  %923 : Tensor[] = aten::split(%922, %894, %895), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:371:0
  %x.87 : Float(17:29952, 13:2304, 768:1), %x.89 : Float(17:29952, 13:2304, 768:1), %x.91 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%923), scope: __module.h.5/__module.h.5.attn
  %927 : int = aten::size(%x.87, %893), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
  %928 : int = aten::size(%x.87, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
  %929 : int = aten::size(%x.87, %891), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
  %930 : Long() = prim::NumToTensor(%929), scope: __module.h.5/__module.h.5.attn
  %931 : Long() = aten::floor_divide(%930, %896), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
  %932 : int = aten::Int(%931), scope: __module.h.5/__module.h.5.attn
  %933 : int[] = prim::ListConstruct(%927, %928, %897, %932), scope: __module.h.5/__module.h.5.attn
  %x.88 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.87, %933), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
  %935 : int[] = prim::ListConstruct(%893, %895, %892, %898), scope: __module.h.5/__module.h.5.attn
  %q.6 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.88, %935), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
  %937 : int = aten::size(%x.89, %893), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
  %938 : int = aten::size(%x.89, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
  %939 : int = aten::size(%x.89, %891), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
  %940 : Long() = prim::NumToTensor(%939), scope: __module.h.5/__module.h.5.attn
  %941 : Long() = aten::floor_divide(%940, %896), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
  %942 : int = aten::Int(%941), scope: __module.h.5/__module.h.5.attn
  %943 : int[] = prim::ListConstruct(%937, %938, %897, %942), scope: __module.h.5/__module.h.5.attn
  %x.90 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.89, %943), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
  %945 : int[] = prim::ListConstruct(%893, %895, %898, %892), scope: __module.h.5/__module.h.5.attn
  %k.6 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.90, %945), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:211:0
  %947 : int = aten::size(%x.91, %893), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
  %948 : int = aten::size(%x.91, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
  %949 : int = aten::size(%x.91, %891), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
  %950 : Long() = prim::NumToTensor(%949), scope: __module.h.5/__module.h.5.attn
  %951 : Long() = aten::floor_divide(%950, %896), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
  %952 : int = aten::Int(%951), scope: __module.h.5/__module.h.5.attn
  %953 : int[] = prim::ListConstruct(%947, %948, %897, %952), scope: __module.h.5/__module.h.5.attn
  %x.92 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.91, %953), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
  %955 : int[] = prim::ListConstruct(%893, %895, %892, %898), scope: __module.h.5/__module.h.5.attn
  %v.6 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.92, %955), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
  %w.21 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.6, %k.6), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:178:0
  %w.22 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.21, %899), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:180:0
  %959 : int = aten::size(%w.22, %900), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
  %960 : int = aten::size(%w.22, %891), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
  %961 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%911, %893, %893, %901, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
  %962 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%961, %892, %893, %901, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
  %963 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%962, %895, %893, %959, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
  %b.6 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%963, %898, %893, %960, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
  %965 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.22, %b.6), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:184:0
  %966 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.6, %892, %892), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:396:0
  %967 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%966, %902), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:184:0
  %w.23 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%965, %967, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:184:0
  %input.34 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.23, %attention_mask, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:188:0
  %input.35 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.34, %891, %903), scope: __module.h.5/__module.h.5.attn # torch/nn/functional.py:1498:0
  %w.24 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.35, %905, %904), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.93 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.24, %v.6), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:197:0
  %973 : int[] = prim::ListConstruct(%893, %895, %892, %898), scope: __module.h.5/__module.h.5.attn
  %974 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.93, %973), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:203:0
  %x.94 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%974, %893), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:203:0
  %976 : int = aten::size(%x.94, %893), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
  %977 : int = aten::size(%x.94, %892), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
  %978 : int = aten::size(%x.94, %900), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
  %979 : Long() = prim::NumToTensor(%978), scope: __module.h.5/__module.h.5.attn
  %980 : int = aten::size(%x.94, %891), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
  %981 : Long() = prim::NumToTensor(%980), scope: __module.h.5/__module.h.5.attn
  %982 : Long() = aten::mul(%979, %981), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
  %983 : int = aten::Int(%982), scope: __module.h.5/__module.h.5.attn
  %984 : int[] = prim::ListConstruct(%976, %977, %983), scope: __module.h.5/__module.h.5.attn
  %x.95 : Float(17:9984, 13:768, 768:1) = aten::view(%x.94, %984), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:205:0
  %986 : Tensor = prim::GetAttr[name="weight"](%910)
  %987 : Tensor = prim::GetAttr[name="bias"](%910)
  %988 : int = aten::size(%x.95, %893), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1093:0
  %989 : int = aten::size(%x.95, %892), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1093:0
  %990 : int = aten::size(%x.95, %891), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
  %991 : int[] = prim::ListConstruct(%891, %990), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
  %992 : Float(221:768, 768:1) = aten::view(%x.95, %991), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.96 : Float(221:768, 768:1) = aten::addmm(%987, %992, %986, %892, %892), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
  %994 : int[] = prim::ListConstruct(%988, %989, %894), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
  %input.36 : Float(17:9984, 13:768, 768:1) = aten::view(%x.96, %994), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.6 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.36, %905, %904), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.37 : Float(17:9984, 13:768, 768:1) = aten::add(%x.85, %a.6, %892), scope: __module.h.5 # transformers/modeling_openai.py:266:0
  %998 : Tensor = prim::GetAttr[name="bias"](%908)
  %999 : Tensor = prim::GetAttr[name="weight"](%908)
  %1000 : int[] = prim::ListConstruct(%894), scope: __module.h.5/__module.h.5.ln_1
  %x.97 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.37, %1000, %999, %998, %888, %889), scope: __module.h.5/__module.h.5.ln_1 # torch/nn/functional.py:2048:0
  %1002 : __torch__.transformers.modeling_utils.___torch_mangle_29256.Conv1D = prim::GetAttr[name="c_proj"](%907)
  %1003 : __torch__.transformers.modeling_utils.___torch_mangle_29255.Conv1D = prim::GetAttr[name="c_fc"](%907)
  %1004 : Tensor = prim::GetAttr[name="weight"](%1003)
  %1005 : Tensor = prim::GetAttr[name="bias"](%1003)
  %1006 : int = aten::size(%x.97, %893), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1007 : int = aten::size(%x.97, %892), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1008 : int = aten::size(%x.97, %891), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1009 : int[] = prim::ListConstruct(%891, %1008), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
  %1010 : Float(221:768, 768:1) = aten::view(%x.97, %1009), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.98 : Float(221:3072, 3072:1) = aten::addmm(%1005, %1010, %1004, %892, %892), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1012 : int[] = prim::ListConstruct(%1006, %1007, %882), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
  %x.99 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.98, %1012), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1014 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.99, %883), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %1015 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.99, %884), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %1016 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1015, %885), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %1017 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.99, %1016, %892), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %1018 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1017, %886), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %1019 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%1018), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %1020 : Float(17:39936, 13:3072, 3072:1) = aten::add(%1019, %887, %892), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %x.100 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1014, %1020), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
  %1022 : Tensor = prim::GetAttr[name="weight"](%1002)
  %1023 : Tensor = prim::GetAttr[name="bias"](%1002)
  %1024 : int = aten::size(%x.100, %893), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1025 : int = aten::size(%x.100, %892), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1026 : int = aten::size(%x.100, %891), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1027 : int[] = prim::ListConstruct(%891, %1026), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
  %1028 : Float(221:3072, 3072:1) = aten::view(%x.100, %1027), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.101 : Float(221:768, 768:1) = aten::addmm(%1023, %1028, %1022, %892, %892), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1030 : int[] = prim::ListConstruct(%1024, %1025, %894), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
  %input.38 : Float(17:9984, 13:768, 768:1) = aten::view(%x.101, %1030), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.6 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.38, %905, %904), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.dropout # torch/nn/functional.py:973:0
  %input.39 : Float(17:9984, 13:768, 768:1) = aten::add(%x.97, %m.6, %892), scope: __module.h.5 # transformers/modeling_openai.py:268:0
  %1034 : Tensor = prim::GetAttr[name="bias"](%906)
  %1035 : Tensor = prim::GetAttr[name="weight"](%906)
  %1036 : int[] = prim::ListConstruct(%894), scope: __module.h.5/__module.h.5.ln_2
  %x.102 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.39, %1036, %1035, %1034, %888, %889), scope: __module.h.5/__module.h.5.ln_2 # torch/nn/functional.py:2048:0
  %1038 : int = prim::Constant[value=3072](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1039 : Double() = prim::Constant[value={0.5}](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1040 : float = prim::Constant[value=3.](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1041 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1042 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1043 : Double() = prim::Constant[value={1}](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1044 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.6/__module.h.6.ln_1 # torch/nn/functional.py:2048:0
  %1045 : bool = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.ln_1 # torch/nn/functional.py:2048:0
  %1046 : int = prim::Constant[value=2304](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1047 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1048 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1049 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1050 : int = prim::Constant[value=768](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:371:0
  %1051 : int = prim::Constant[value=2](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:371:0
  %1052 : Long() = prim::Constant[value={12}](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
  %1053 : int = prim::Constant[value=12](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
  %1054 : int = prim::Constant[value=3](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
  %1055 : Double() = prim::Constant[value={8}](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:180:0
  %1056 : int = prim::Constant[value=-2](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
  %1057 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
  %1058 : Double() = prim::Constant[value={-10000}](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:184:0
  %1059 : None = prim::Constant(), scope: __module.h.6/__module.h.6.attn
  %1060 : bool = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.attn_dropout # torch/nn/functional.py:973:0
  %1061 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.attn_dropout # torch/nn/functional.py:973:0
  %1062 : __torch__.torch.nn.modules.normalization.___torch_mangle_29271.LayerNorm = prim::GetAttr[name="ln_2"](%14)
  %1063 : __torch__.transformers.modeling_openai.___torch_mangle_29270.MLP = prim::GetAttr[name="mlp"](%14)
  %1064 : __torch__.torch.nn.modules.normalization.___torch_mangle_29266.LayerNorm = prim::GetAttr[name="ln_1"](%14)
  %1065 : __torch__.transformers.modeling_openai.___torch_mangle_29265.Attention = prim::GetAttr[name="attn"](%14)
  %1066 : __torch__.transformers.modeling_utils.___torch_mangle_29262.Conv1D = prim::GetAttr[name="c_proj"](%1065)
  %1067 : Tensor = prim::GetAttr[name="bias"](%1065)
  %1068 : __torch__.transformers.modeling_utils.___torch_mangle_29261.Conv1D = prim::GetAttr[name="c_attn"](%1065)
  %1069 : Tensor = prim::GetAttr[name="weight"](%1068)
  %1070 : Tensor = prim::GetAttr[name="bias"](%1068)
  %1071 : int = aten::size(%x.102, %1049), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1072 : int = aten::size(%x.102, %1048), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1073 : int = aten::size(%x.102, %1047), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1074 : int[] = prim::ListConstruct(%1047, %1073), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
  %1075 : Float(221:768, 768:1) = aten::view(%x.102, %1074), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.103 : Float(221:2304, 2304:1) = aten::addmm(%1070, %1075, %1069, %1048, %1048), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1077 : int[] = prim::ListConstruct(%1071, %1072, %1046), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
  %1078 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.103, %1077), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1079 : Tensor[] = aten::split(%1078, %1050, %1051), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:371:0
  %x.104 : Float(17:29952, 13:2304, 768:1), %x.106 : Float(17:29952, 13:2304, 768:1), %x.108 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%1079), scope: __module.h.6/__module.h.6.attn
  %1083 : int = aten::size(%x.104, %1049), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
  %1084 : int = aten::size(%x.104, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
  %1085 : int = aten::size(%x.104, %1047), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
  %1086 : Long() = prim::NumToTensor(%1085), scope: __module.h.6/__module.h.6.attn
  %1087 : Long() = aten::floor_divide(%1086, %1052), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
  %1088 : int = aten::Int(%1087), scope: __module.h.6/__module.h.6.attn
  %1089 : int[] = prim::ListConstruct(%1083, %1084, %1053, %1088), scope: __module.h.6/__module.h.6.attn
  %x.105 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.104, %1089), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
  %1091 : int[] = prim::ListConstruct(%1049, %1051, %1048, %1054), scope: __module.h.6/__module.h.6.attn
  %q.7 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.105, %1091), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
  %1093 : int = aten::size(%x.106, %1049), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
  %1094 : int = aten::size(%x.106, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
  %1095 : int = aten::size(%x.106, %1047), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
  %1096 : Long() = prim::NumToTensor(%1095), scope: __module.h.6/__module.h.6.attn
  %1097 : Long() = aten::floor_divide(%1096, %1052), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
  %1098 : int = aten::Int(%1097), scope: __module.h.6/__module.h.6.attn
  %1099 : int[] = prim::ListConstruct(%1093, %1094, %1053, %1098), scope: __module.h.6/__module.h.6.attn
  %x.107 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.106, %1099), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
  %1101 : int[] = prim::ListConstruct(%1049, %1051, %1054, %1048), scope: __module.h.6/__module.h.6.attn
  %k.7 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.107, %1101), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:211:0
  %1103 : int = aten::size(%x.108, %1049), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
  %1104 : int = aten::size(%x.108, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
  %1105 : int = aten::size(%x.108, %1047), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
  %1106 : Long() = prim::NumToTensor(%1105), scope: __module.h.6/__module.h.6.attn
  %1107 : Long() = aten::floor_divide(%1106, %1052), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
  %1108 : int = aten::Int(%1107), scope: __module.h.6/__module.h.6.attn
  %1109 : int[] = prim::ListConstruct(%1103, %1104, %1053, %1108), scope: __module.h.6/__module.h.6.attn
  %x.109 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.108, %1109), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
  %1111 : int[] = prim::ListConstruct(%1049, %1051, %1048, %1054), scope: __module.h.6/__module.h.6.attn
  %v.7 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.109, %1111), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
  %w.25 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.7, %k.7), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:178:0
  %w.26 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.25, %1055), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:180:0
  %1115 : int = aten::size(%w.26, %1056), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
  %1116 : int = aten::size(%w.26, %1047), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
  %1117 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1067, %1049, %1049, %1057, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
  %1118 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1117, %1048, %1049, %1057, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
  %1119 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%1118, %1051, %1049, %1115, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
  %b.7 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%1119, %1054, %1049, %1116, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
  %1121 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.26, %b.7), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:184:0
  %1122 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.7, %1048, %1048), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:396:0
  %1123 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%1122, %1058), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:184:0
  %w.27 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%1121, %1123, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:184:0
  %input.40 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.27, %attention_mask, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:188:0
  %input.41 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.40, %1047, %1059), scope: __module.h.6/__module.h.6.attn # torch/nn/functional.py:1498:0
  %w.28 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.41, %1061, %1060), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.110 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.28, %v.7), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:197:0
  %1129 : int[] = prim::ListConstruct(%1049, %1051, %1048, %1054), scope: __module.h.6/__module.h.6.attn
  %1130 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.110, %1129), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:203:0
  %x.111 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%1130, %1049), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:203:0
  %1132 : int = aten::size(%x.111, %1049), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
  %1133 : int = aten::size(%x.111, %1048), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
  %1134 : int = aten::size(%x.111, %1056), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
  %1135 : Long() = prim::NumToTensor(%1134), scope: __module.h.6/__module.h.6.attn
  %1136 : int = aten::size(%x.111, %1047), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
  %1137 : Long() = prim::NumToTensor(%1136), scope: __module.h.6/__module.h.6.attn
  %1138 : Long() = aten::mul(%1135, %1137), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
  %1139 : int = aten::Int(%1138), scope: __module.h.6/__module.h.6.attn
  %1140 : int[] = prim::ListConstruct(%1132, %1133, %1139), scope: __module.h.6/__module.h.6.attn
  %x.112 : Float(17:9984, 13:768, 768:1) = aten::view(%x.111, %1140), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:205:0
  %1142 : Tensor = prim::GetAttr[name="weight"](%1066)
  %1143 : Tensor = prim::GetAttr[name="bias"](%1066)
  %1144 : int = aten::size(%x.112, %1049), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1145 : int = aten::size(%x.112, %1048), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1146 : int = aten::size(%x.112, %1047), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1147 : int[] = prim::ListConstruct(%1047, %1146), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
  %1148 : Float(221:768, 768:1) = aten::view(%x.112, %1147), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.113 : Float(221:768, 768:1) = aten::addmm(%1143, %1148, %1142, %1048, %1048), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1150 : int[] = prim::ListConstruct(%1144, %1145, %1050), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
  %input.42 : Float(17:9984, 13:768, 768:1) = aten::view(%x.113, %1150), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.7 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.42, %1061, %1060), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.43 : Float(17:9984, 13:768, 768:1) = aten::add(%x.102, %a.7, %1048), scope: __module.h.6 # transformers/modeling_openai.py:266:0
  %1154 : Tensor = prim::GetAttr[name="bias"](%1064)
  %1155 : Tensor = prim::GetAttr[name="weight"](%1064)
  %1156 : int[] = prim::ListConstruct(%1050), scope: __module.h.6/__module.h.6.ln_1
  %x.114 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.43, %1156, %1155, %1154, %1044, %1045), scope: __module.h.6/__module.h.6.ln_1 # torch/nn/functional.py:2048:0
  %1158 : __torch__.transformers.modeling_utils.___torch_mangle_29268.Conv1D = prim::GetAttr[name="c_proj"](%1063)
  %1159 : __torch__.transformers.modeling_utils.___torch_mangle_29267.Conv1D = prim::GetAttr[name="c_fc"](%1063)
  %1160 : Tensor = prim::GetAttr[name="weight"](%1159)
  %1161 : Tensor = prim::GetAttr[name="bias"](%1159)
  %1162 : int = aten::size(%x.114, %1049), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1163 : int = aten::size(%x.114, %1048), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1164 : int = aten::size(%x.114, %1047), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1165 : int[] = prim::ListConstruct(%1047, %1164), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
  %1166 : Float(221:768, 768:1) = aten::view(%x.114, %1165), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.115 : Float(221:3072, 3072:1) = aten::addmm(%1161, %1166, %1160, %1048, %1048), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1168 : int[] = prim::ListConstruct(%1162, %1163, %1038), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
  %x.116 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.115, %1168), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1170 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.116, %1039), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1171 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.116, %1040), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1172 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1171, %1041), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1173 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.116, %1172, %1048), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1174 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1173, %1042), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1175 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%1174), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1176 : Float(17:39936, 13:3072, 3072:1) = aten::add(%1175, %1043, %1048), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %x.117 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1170, %1176), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
  %1178 : Tensor = prim::GetAttr[name="weight"](%1158)
  %1179 : Tensor = prim::GetAttr[name="bias"](%1158)
  %1180 : int = aten::size(%x.117, %1049), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1181 : int = aten::size(%x.117, %1048), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1182 : int = aten::size(%x.117, %1047), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1183 : int[] = prim::ListConstruct(%1047, %1182), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
  %1184 : Float(221:3072, 3072:1) = aten::view(%x.117, %1183), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.118 : Float(221:768, 768:1) = aten::addmm(%1179, %1184, %1178, %1048, %1048), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1186 : int[] = prim::ListConstruct(%1180, %1181, %1050), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
  %input.44 : Float(17:9984, 13:768, 768:1) = aten::view(%x.118, %1186), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.7 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.44, %1061, %1060), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.dropout # torch/nn/functional.py:973:0
  %input.45 : Float(17:9984, 13:768, 768:1) = aten::add(%x.114, %m.7, %1048), scope: __module.h.6 # transformers/modeling_openai.py:268:0
  %1190 : Tensor = prim::GetAttr[name="bias"](%1062)
  %1191 : Tensor = prim::GetAttr[name="weight"](%1062)
  %1192 : int[] = prim::ListConstruct(%1050), scope: __module.h.6/__module.h.6.ln_2
  %x.119 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.45, %1192, %1191, %1190, %1044, %1045), scope: __module.h.6/__module.h.6.ln_2 # torch/nn/functional.py:2048:0
  %1194 : int = prim::Constant[value=3072](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1195 : Double() = prim::Constant[value={0.5}](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1196 : float = prim::Constant[value=3.](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1197 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1198 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1199 : Double() = prim::Constant[value={1}](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1200 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.7/__module.h.7.ln_1 # torch/nn/functional.py:2048:0
  %1201 : bool = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.ln_1 # torch/nn/functional.py:2048:0
  %1202 : int = prim::Constant[value=2304](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1203 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1204 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1205 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1206 : int = prim::Constant[value=768](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:371:0
  %1207 : int = prim::Constant[value=2](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:371:0
  %1208 : Long() = prim::Constant[value={12}](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
  %1209 : int = prim::Constant[value=12](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
  %1210 : int = prim::Constant[value=3](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
  %1211 : Double() = prim::Constant[value={8}](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:180:0
  %1212 : int = prim::Constant[value=-2](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
  %1213 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
  %1214 : Double() = prim::Constant[value={-10000}](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:184:0
  %1215 : None = prim::Constant(), scope: __module.h.7/__module.h.7.attn
  %1216 : bool = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.attn_dropout # torch/nn/functional.py:973:0
  %1217 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.attn_dropout # torch/nn/functional.py:973:0
  %1218 : __torch__.torch.nn.modules.normalization.___torch_mangle_29283.LayerNorm = prim::GetAttr[name="ln_2"](%12)
  %1219 : __torch__.transformers.modeling_openai.___torch_mangle_29282.MLP = prim::GetAttr[name="mlp"](%12)
  %1220 : __torch__.torch.nn.modules.normalization.___torch_mangle_29278.LayerNorm = prim::GetAttr[name="ln_1"](%12)
  %1221 : __torch__.transformers.modeling_openai.___torch_mangle_29277.Attention = prim::GetAttr[name="attn"](%12)
  %1222 : __torch__.transformers.modeling_utils.___torch_mangle_29274.Conv1D = prim::GetAttr[name="c_proj"](%1221)
  %1223 : Tensor = prim::GetAttr[name="bias"](%1221)
  %1224 : __torch__.transformers.modeling_utils.___torch_mangle_29273.Conv1D = prim::GetAttr[name="c_attn"](%1221)
  %1225 : Tensor = prim::GetAttr[name="weight"](%1224)
  %1226 : Tensor = prim::GetAttr[name="bias"](%1224)
  %1227 : int = aten::size(%x.119, %1205), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1228 : int = aten::size(%x.119, %1204), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1229 : int = aten::size(%x.119, %1203), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1230 : int[] = prim::ListConstruct(%1203, %1229), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
  %1231 : Float(221:768, 768:1) = aten::view(%x.119, %1230), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.120 : Float(221:2304, 2304:1) = aten::addmm(%1226, %1231, %1225, %1204, %1204), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1233 : int[] = prim::ListConstruct(%1227, %1228, %1202), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
  %1234 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.120, %1233), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1235 : Tensor[] = aten::split(%1234, %1206, %1207), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:371:0
  %x.121 : Float(17:29952, 13:2304, 768:1), %x.123 : Float(17:29952, 13:2304, 768:1), %x.125 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%1235), scope: __module.h.7/__module.h.7.attn
  %1239 : int = aten::size(%x.121, %1205), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
  %1240 : int = aten::size(%x.121, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
  %1241 : int = aten::size(%x.121, %1203), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
  %1242 : Long() = prim::NumToTensor(%1241), scope: __module.h.7/__module.h.7.attn
  %1243 : Long() = aten::floor_divide(%1242, %1208), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
  %1244 : int = aten::Int(%1243), scope: __module.h.7/__module.h.7.attn
  %1245 : int[] = prim::ListConstruct(%1239, %1240, %1209, %1244), scope: __module.h.7/__module.h.7.attn
  %x.122 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.121, %1245), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
  %1247 : int[] = prim::ListConstruct(%1205, %1207, %1204, %1210), scope: __module.h.7/__module.h.7.attn
  %q.8 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.122, %1247), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
  %1249 : int = aten::size(%x.123, %1205), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
  %1250 : int = aten::size(%x.123, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
  %1251 : int = aten::size(%x.123, %1203), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
  %1252 : Long() = prim::NumToTensor(%1251), scope: __module.h.7/__module.h.7.attn
  %1253 : Long() = aten::floor_divide(%1252, %1208), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
  %1254 : int = aten::Int(%1253), scope: __module.h.7/__module.h.7.attn
  %1255 : int[] = prim::ListConstruct(%1249, %1250, %1209, %1254), scope: __module.h.7/__module.h.7.attn
  %x.124 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.123, %1255), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
  %1257 : int[] = prim::ListConstruct(%1205, %1207, %1210, %1204), scope: __module.h.7/__module.h.7.attn
  %k.8 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.124, %1257), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:211:0
  %1259 : int = aten::size(%x.125, %1205), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
  %1260 : int = aten::size(%x.125, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
  %1261 : int = aten::size(%x.125, %1203), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
  %1262 : Long() = prim::NumToTensor(%1261), scope: __module.h.7/__module.h.7.attn
  %1263 : Long() = aten::floor_divide(%1262, %1208), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
  %1264 : int = aten::Int(%1263), scope: __module.h.7/__module.h.7.attn
  %1265 : int[] = prim::ListConstruct(%1259, %1260, %1209, %1264), scope: __module.h.7/__module.h.7.attn
  %x.126 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.125, %1265), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
  %1267 : int[] = prim::ListConstruct(%1205, %1207, %1204, %1210), scope: __module.h.7/__module.h.7.attn
  %v.8 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.126, %1267), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
  %w.29 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.8, %k.8), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:178:0
  %w.30 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.29, %1211), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:180:0
  %1271 : int = aten::size(%w.30, %1212), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
  %1272 : int = aten::size(%w.30, %1203), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
  %1273 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1223, %1205, %1205, %1213, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
  %1274 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1273, %1204, %1205, %1213, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
  %1275 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%1274, %1207, %1205, %1271, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
  %b.8 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%1275, %1210, %1205, %1272, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
  %1277 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.30, %b.8), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:184:0
  %1278 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.8, %1204, %1204), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:396:0
  %1279 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%1278, %1214), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:184:0
  %w.31 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%1277, %1279, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:184:0
  %input.46 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.31, %attention_mask, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:188:0
  %input.47 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.46, %1203, %1215), scope: __module.h.7/__module.h.7.attn # torch/nn/functional.py:1498:0
  %w.32 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.47, %1217, %1216), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.127 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.32, %v.8), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:197:0
  %1285 : int[] = prim::ListConstruct(%1205, %1207, %1204, %1210), scope: __module.h.7/__module.h.7.attn
  %1286 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.127, %1285), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:203:0
  %x.128 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%1286, %1205), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:203:0
  %1288 : int = aten::size(%x.128, %1205), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
  %1289 : int = aten::size(%x.128, %1204), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
  %1290 : int = aten::size(%x.128, %1212), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
  %1291 : Long() = prim::NumToTensor(%1290), scope: __module.h.7/__module.h.7.attn
  %1292 : int = aten::size(%x.128, %1203), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
  %1293 : Long() = prim::NumToTensor(%1292), scope: __module.h.7/__module.h.7.attn
  %1294 : Long() = aten::mul(%1291, %1293), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
  %1295 : int = aten::Int(%1294), scope: __module.h.7/__module.h.7.attn
  %1296 : int[] = prim::ListConstruct(%1288, %1289, %1295), scope: __module.h.7/__module.h.7.attn
  %x.129 : Float(17:9984, 13:768, 768:1) = aten::view(%x.128, %1296), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:205:0
  %1298 : Tensor = prim::GetAttr[name="weight"](%1222)
  %1299 : Tensor = prim::GetAttr[name="bias"](%1222)
  %1300 : int = aten::size(%x.129, %1205), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1301 : int = aten::size(%x.129, %1204), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1302 : int = aten::size(%x.129, %1203), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1303 : int[] = prim::ListConstruct(%1203, %1302), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
  %1304 : Float(221:768, 768:1) = aten::view(%x.129, %1303), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.130 : Float(221:768, 768:1) = aten::addmm(%1299, %1304, %1298, %1204, %1204), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1306 : int[] = prim::ListConstruct(%1300, %1301, %1206), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
  %input.48 : Float(17:9984, 13:768, 768:1) = aten::view(%x.130, %1306), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.8 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.48, %1217, %1216), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.49 : Float(17:9984, 13:768, 768:1) = aten::add(%x.119, %a.8, %1204), scope: __module.h.7 # transformers/modeling_openai.py:266:0
  %1310 : Tensor = prim::GetAttr[name="bias"](%1220)
  %1311 : Tensor = prim::GetAttr[name="weight"](%1220)
  %1312 : int[] = prim::ListConstruct(%1206), scope: __module.h.7/__module.h.7.ln_1
  %x.131 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.49, %1312, %1311, %1310, %1200, %1201), scope: __module.h.7/__module.h.7.ln_1 # torch/nn/functional.py:2048:0
  %1314 : __torch__.transformers.modeling_utils.___torch_mangle_29280.Conv1D = prim::GetAttr[name="c_proj"](%1219)
  %1315 : __torch__.transformers.modeling_utils.___torch_mangle_29279.Conv1D = prim::GetAttr[name="c_fc"](%1219)
  %1316 : Tensor = prim::GetAttr[name="weight"](%1315)
  %1317 : Tensor = prim::GetAttr[name="bias"](%1315)
  %1318 : int = aten::size(%x.131, %1205), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1319 : int = aten::size(%x.131, %1204), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1320 : int = aten::size(%x.131, %1203), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1321 : int[] = prim::ListConstruct(%1203, %1320), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
  %1322 : Float(221:768, 768:1) = aten::view(%x.131, %1321), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.132 : Float(221:3072, 3072:1) = aten::addmm(%1317, %1322, %1316, %1204, %1204), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1324 : int[] = prim::ListConstruct(%1318, %1319, %1194), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
  %x.133 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.132, %1324), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1326 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.133, %1195), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1327 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.133, %1196), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1328 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1327, %1197), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1329 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.133, %1328, %1204), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1330 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1329, %1198), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1331 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%1330), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1332 : Float(17:39936, 13:3072, 3072:1) = aten::add(%1331, %1199, %1204), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %x.134 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1326, %1332), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
  %1334 : Tensor = prim::GetAttr[name="weight"](%1314)
  %1335 : Tensor = prim::GetAttr[name="bias"](%1314)
  %1336 : int = aten::size(%x.134, %1205), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1337 : int = aten::size(%x.134, %1204), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1338 : int = aten::size(%x.134, %1203), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1339 : int[] = prim::ListConstruct(%1203, %1338), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
  %1340 : Float(221:3072, 3072:1) = aten::view(%x.134, %1339), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.135 : Float(221:768, 768:1) = aten::addmm(%1335, %1340, %1334, %1204, %1204), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1342 : int[] = prim::ListConstruct(%1336, %1337, %1206), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
  %input.50 : Float(17:9984, 13:768, 768:1) = aten::view(%x.135, %1342), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.8 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.50, %1217, %1216), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.dropout # torch/nn/functional.py:973:0
  %input.51 : Float(17:9984, 13:768, 768:1) = aten::add(%x.131, %m.8, %1204), scope: __module.h.7 # transformers/modeling_openai.py:268:0
  %1346 : Tensor = prim::GetAttr[name="bias"](%1218)
  %1347 : Tensor = prim::GetAttr[name="weight"](%1218)
  %1348 : int[] = prim::ListConstruct(%1206), scope: __module.h.7/__module.h.7.ln_2
  %x.136 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.51, %1348, %1347, %1346, %1200, %1201), scope: __module.h.7/__module.h.7.ln_2 # torch/nn/functional.py:2048:0
  %1350 : int = prim::Constant[value=3072](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1351 : Double() = prim::Constant[value={0.5}](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1352 : float = prim::Constant[value=3.](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1353 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1354 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1355 : Double() = prim::Constant[value={1}](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1356 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.8/__module.h.8.ln_1 # torch/nn/functional.py:2048:0
  %1357 : bool = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.ln_1 # torch/nn/functional.py:2048:0
  %1358 : int = prim::Constant[value=2304](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1359 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1360 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1361 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1362 : int = prim::Constant[value=768](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:371:0
  %1363 : int = prim::Constant[value=2](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:371:0
  %1364 : Long() = prim::Constant[value={12}](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
  %1365 : int = prim::Constant[value=12](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
  %1366 : int = prim::Constant[value=3](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
  %1367 : Double() = prim::Constant[value={8}](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:180:0
  %1368 : int = prim::Constant[value=-2](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
  %1369 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
  %1370 : Double() = prim::Constant[value={-10000}](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:184:0
  %1371 : None = prim::Constant(), scope: __module.h.8/__module.h.8.attn
  %1372 : bool = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.attn_dropout # torch/nn/functional.py:973:0
  %1373 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.attn_dropout # torch/nn/functional.py:973:0
  %1374 : __torch__.torch.nn.modules.normalization.___torch_mangle_29295.LayerNorm = prim::GetAttr[name="ln_2"](%10)
  %1375 : __torch__.transformers.modeling_openai.___torch_mangle_29294.MLP = prim::GetAttr[name="mlp"](%10)
  %1376 : __torch__.torch.nn.modules.normalization.___torch_mangle_29290.LayerNorm = prim::GetAttr[name="ln_1"](%10)
  %1377 : __torch__.transformers.modeling_openai.___torch_mangle_29289.Attention = prim::GetAttr[name="attn"](%10)
  %1378 : __torch__.transformers.modeling_utils.___torch_mangle_29286.Conv1D = prim::GetAttr[name="c_proj"](%1377)
  %1379 : Tensor = prim::GetAttr[name="bias"](%1377)
  %1380 : __torch__.transformers.modeling_utils.___torch_mangle_29285.Conv1D = prim::GetAttr[name="c_attn"](%1377)
  %1381 : Tensor = prim::GetAttr[name="weight"](%1380)
  %1382 : Tensor = prim::GetAttr[name="bias"](%1380)
  %1383 : int = aten::size(%x.136, %1361), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1384 : int = aten::size(%x.136, %1360), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1385 : int = aten::size(%x.136, %1359), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1386 : int[] = prim::ListConstruct(%1359, %1385), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
  %1387 : Float(221:768, 768:1) = aten::view(%x.136, %1386), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.137 : Float(221:2304, 2304:1) = aten::addmm(%1382, %1387, %1381, %1360, %1360), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1389 : int[] = prim::ListConstruct(%1383, %1384, %1358), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
  %1390 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.137, %1389), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1391 : Tensor[] = aten::split(%1390, %1362, %1363), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:371:0
  %x.138 : Float(17:29952, 13:2304, 768:1), %x.140 : Float(17:29952, 13:2304, 768:1), %x.142 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%1391), scope: __module.h.8/__module.h.8.attn
  %1395 : int = aten::size(%x.138, %1361), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
  %1396 : int = aten::size(%x.138, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
  %1397 : int = aten::size(%x.138, %1359), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
  %1398 : Long() = prim::NumToTensor(%1397), scope: __module.h.8/__module.h.8.attn
  %1399 : Long() = aten::floor_divide(%1398, %1364), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
  %1400 : int = aten::Int(%1399), scope: __module.h.8/__module.h.8.attn
  %1401 : int[] = prim::ListConstruct(%1395, %1396, %1365, %1400), scope: __module.h.8/__module.h.8.attn
  %x.139 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.138, %1401), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
  %1403 : int[] = prim::ListConstruct(%1361, %1363, %1360, %1366), scope: __module.h.8/__module.h.8.attn
  %q.9 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.139, %1403), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
  %1405 : int = aten::size(%x.140, %1361), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
  %1406 : int = aten::size(%x.140, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
  %1407 : int = aten::size(%x.140, %1359), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
  %1408 : Long() = prim::NumToTensor(%1407), scope: __module.h.8/__module.h.8.attn
  %1409 : Long() = aten::floor_divide(%1408, %1364), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
  %1410 : int = aten::Int(%1409), scope: __module.h.8/__module.h.8.attn
  %1411 : int[] = prim::ListConstruct(%1405, %1406, %1365, %1410), scope: __module.h.8/__module.h.8.attn
  %x.141 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.140, %1411), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
  %1413 : int[] = prim::ListConstruct(%1361, %1363, %1366, %1360), scope: __module.h.8/__module.h.8.attn
  %k.9 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.141, %1413), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:211:0
  %1415 : int = aten::size(%x.142, %1361), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
  %1416 : int = aten::size(%x.142, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
  %1417 : int = aten::size(%x.142, %1359), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
  %1418 : Long() = prim::NumToTensor(%1417), scope: __module.h.8/__module.h.8.attn
  %1419 : Long() = aten::floor_divide(%1418, %1364), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
  %1420 : int = aten::Int(%1419), scope: __module.h.8/__module.h.8.attn
  %1421 : int[] = prim::ListConstruct(%1415, %1416, %1365, %1420), scope: __module.h.8/__module.h.8.attn
  %x.143 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.142, %1421), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
  %1423 : int[] = prim::ListConstruct(%1361, %1363, %1360, %1366), scope: __module.h.8/__module.h.8.attn
  %v.9 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.143, %1423), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
  %w.33 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.9, %k.9), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:178:0
  %w.34 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.33, %1367), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:180:0
  %1427 : int = aten::size(%w.34, %1368), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
  %1428 : int = aten::size(%w.34, %1359), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
  %1429 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1379, %1361, %1361, %1369, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
  %1430 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1429, %1360, %1361, %1369, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
  %1431 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%1430, %1363, %1361, %1427, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
  %b.9 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%1431, %1366, %1361, %1428, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
  %1433 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.34, %b.9), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:184:0
  %1434 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.9, %1360, %1360), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:396:0
  %1435 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%1434, %1370), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:184:0
  %w.35 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%1433, %1435, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:184:0
  %input.52 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.35, %attention_mask, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:188:0
  %input.53 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.52, %1359, %1371), scope: __module.h.8/__module.h.8.attn # torch/nn/functional.py:1498:0
  %w.36 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.53, %1373, %1372), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.144 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.36, %v.9), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:197:0
  %1441 : int[] = prim::ListConstruct(%1361, %1363, %1360, %1366), scope: __module.h.8/__module.h.8.attn
  %1442 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.144, %1441), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:203:0
  %x.145 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%1442, %1361), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:203:0
  %1444 : int = aten::size(%x.145, %1361), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
  %1445 : int = aten::size(%x.145, %1360), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
  %1446 : int = aten::size(%x.145, %1368), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
  %1447 : Long() = prim::NumToTensor(%1446), scope: __module.h.8/__module.h.8.attn
  %1448 : int = aten::size(%x.145, %1359), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
  %1449 : Long() = prim::NumToTensor(%1448), scope: __module.h.8/__module.h.8.attn
  %1450 : Long() = aten::mul(%1447, %1449), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
  %1451 : int = aten::Int(%1450), scope: __module.h.8/__module.h.8.attn
  %1452 : int[] = prim::ListConstruct(%1444, %1445, %1451), scope: __module.h.8/__module.h.8.attn
  %x.146 : Float(17:9984, 13:768, 768:1) = aten::view(%x.145, %1452), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:205:0
  %1454 : Tensor = prim::GetAttr[name="weight"](%1378)
  %1455 : Tensor = prim::GetAttr[name="bias"](%1378)
  %1456 : int = aten::size(%x.146, %1361), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1457 : int = aten::size(%x.146, %1360), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1458 : int = aten::size(%x.146, %1359), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1459 : int[] = prim::ListConstruct(%1359, %1458), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
  %1460 : Float(221:768, 768:1) = aten::view(%x.146, %1459), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.147 : Float(221:768, 768:1) = aten::addmm(%1455, %1460, %1454, %1360, %1360), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1462 : int[] = prim::ListConstruct(%1456, %1457, %1362), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
  %input.54 : Float(17:9984, 13:768, 768:1) = aten::view(%x.147, %1462), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.9 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.54, %1373, %1372), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.55 : Float(17:9984, 13:768, 768:1) = aten::add(%x.136, %a.9, %1360), scope: __module.h.8 # transformers/modeling_openai.py:266:0
  %1466 : Tensor = prim::GetAttr[name="bias"](%1376)
  %1467 : Tensor = prim::GetAttr[name="weight"](%1376)
  %1468 : int[] = prim::ListConstruct(%1362), scope: __module.h.8/__module.h.8.ln_1
  %x.148 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.55, %1468, %1467, %1466, %1356, %1357), scope: __module.h.8/__module.h.8.ln_1 # torch/nn/functional.py:2048:0
  %1470 : __torch__.transformers.modeling_utils.___torch_mangle_29292.Conv1D = prim::GetAttr[name="c_proj"](%1375)
  %1471 : __torch__.transformers.modeling_utils.___torch_mangle_29291.Conv1D = prim::GetAttr[name="c_fc"](%1375)
  %1472 : Tensor = prim::GetAttr[name="weight"](%1471)
  %1473 : Tensor = prim::GetAttr[name="bias"](%1471)
  %1474 : int = aten::size(%x.148, %1361), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1475 : int = aten::size(%x.148, %1360), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1476 : int = aten::size(%x.148, %1359), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1477 : int[] = prim::ListConstruct(%1359, %1476), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
  %1478 : Float(221:768, 768:1) = aten::view(%x.148, %1477), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.149 : Float(221:3072, 3072:1) = aten::addmm(%1473, %1478, %1472, %1360, %1360), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1480 : int[] = prim::ListConstruct(%1474, %1475, %1350), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
  %x.150 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.149, %1480), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1482 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.150, %1351), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1483 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.150, %1352), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1484 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1483, %1353), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1485 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.150, %1484, %1360), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1486 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1485, %1354), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1487 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%1486), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1488 : Float(17:39936, 13:3072, 3072:1) = aten::add(%1487, %1355, %1360), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %x.151 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1482, %1488), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
  %1490 : Tensor = prim::GetAttr[name="weight"](%1470)
  %1491 : Tensor = prim::GetAttr[name="bias"](%1470)
  %1492 : int = aten::size(%x.151, %1361), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1493 : int = aten::size(%x.151, %1360), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1494 : int = aten::size(%x.151, %1359), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1495 : int[] = prim::ListConstruct(%1359, %1494), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
  %1496 : Float(221:3072, 3072:1) = aten::view(%x.151, %1495), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.152 : Float(221:768, 768:1) = aten::addmm(%1491, %1496, %1490, %1360, %1360), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1498 : int[] = prim::ListConstruct(%1492, %1493, %1362), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
  %input.56 : Float(17:9984, 13:768, 768:1) = aten::view(%x.152, %1498), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.9 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.56, %1373, %1372), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.dropout # torch/nn/functional.py:973:0
  %input.57 : Float(17:9984, 13:768, 768:1) = aten::add(%x.148, %m.9, %1360), scope: __module.h.8 # transformers/modeling_openai.py:268:0
  %1502 : Tensor = prim::GetAttr[name="bias"](%1374)
  %1503 : Tensor = prim::GetAttr[name="weight"](%1374)
  %1504 : int[] = prim::ListConstruct(%1362), scope: __module.h.8/__module.h.8.ln_2
  %x.153 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.57, %1504, %1503, %1502, %1356, %1357), scope: __module.h.8/__module.h.8.ln_2 # torch/nn/functional.py:2048:0
  %1506 : int = prim::Constant[value=3072](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1507 : Double() = prim::Constant[value={0.5}](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1508 : float = prim::Constant[value=3.](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1509 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1510 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1511 : Double() = prim::Constant[value={1}](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1512 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.9/__module.h.9.ln_1 # torch/nn/functional.py:2048:0
  %1513 : bool = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.ln_1 # torch/nn/functional.py:2048:0
  %1514 : int = prim::Constant[value=2304](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1515 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1516 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1517 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1518 : int = prim::Constant[value=768](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:371:0
  %1519 : int = prim::Constant[value=2](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:371:0
  %1520 : Long() = prim::Constant[value={12}](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
  %1521 : int = prim::Constant[value=12](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
  %1522 : int = prim::Constant[value=3](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
  %1523 : Double() = prim::Constant[value={8}](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:180:0
  %1524 : int = prim::Constant[value=-2](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
  %1525 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
  %1526 : Double() = prim::Constant[value={-10000}](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:184:0
  %1527 : None = prim::Constant(), scope: __module.h.9/__module.h.9.attn
  %1528 : bool = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.attn_dropout # torch/nn/functional.py:973:0
  %1529 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.attn_dropout # torch/nn/functional.py:973:0
  %1530 : __torch__.torch.nn.modules.normalization.___torch_mangle_29307.LayerNorm = prim::GetAttr[name="ln_2"](%8)
  %1531 : __torch__.transformers.modeling_openai.___torch_mangle_29306.MLP = prim::GetAttr[name="mlp"](%8)
  %1532 : __torch__.torch.nn.modules.normalization.___torch_mangle_29302.LayerNorm = prim::GetAttr[name="ln_1"](%8)
  %1533 : __torch__.transformers.modeling_openai.___torch_mangle_29301.Attention = prim::GetAttr[name="attn"](%8)
  %1534 : __torch__.transformers.modeling_utils.___torch_mangle_29298.Conv1D = prim::GetAttr[name="c_proj"](%1533)
  %1535 : Tensor = prim::GetAttr[name="bias"](%1533)
  %1536 : __torch__.transformers.modeling_utils.___torch_mangle_29297.Conv1D = prim::GetAttr[name="c_attn"](%1533)
  %1537 : Tensor = prim::GetAttr[name="weight"](%1536)
  %1538 : Tensor = prim::GetAttr[name="bias"](%1536)
  %1539 : int = aten::size(%x.153, %1517), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1540 : int = aten::size(%x.153, %1516), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1541 : int = aten::size(%x.153, %1515), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1542 : int[] = prim::ListConstruct(%1515, %1541), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
  %1543 : Float(221:768, 768:1) = aten::view(%x.153, %1542), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.154 : Float(221:2304, 2304:1) = aten::addmm(%1538, %1543, %1537, %1516, %1516), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1545 : int[] = prim::ListConstruct(%1539, %1540, %1514), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
  %1546 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.154, %1545), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1547 : Tensor[] = aten::split(%1546, %1518, %1519), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:371:0
  %x.155 : Float(17:29952, 13:2304, 768:1), %x.157 : Float(17:29952, 13:2304, 768:1), %x.159 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%1547), scope: __module.h.9/__module.h.9.attn
  %1551 : int = aten::size(%x.155, %1517), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
  %1552 : int = aten::size(%x.155, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
  %1553 : int = aten::size(%x.155, %1515), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
  %1554 : Long() = prim::NumToTensor(%1553), scope: __module.h.9/__module.h.9.attn
  %1555 : Long() = aten::floor_divide(%1554, %1520), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
  %1556 : int = aten::Int(%1555), scope: __module.h.9/__module.h.9.attn
  %1557 : int[] = prim::ListConstruct(%1551, %1552, %1521, %1556), scope: __module.h.9/__module.h.9.attn
  %x.156 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.155, %1557), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
  %1559 : int[] = prim::ListConstruct(%1517, %1519, %1516, %1522), scope: __module.h.9/__module.h.9.attn
  %q.10 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.156, %1559), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
  %1561 : int = aten::size(%x.157, %1517), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
  %1562 : int = aten::size(%x.157, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
  %1563 : int = aten::size(%x.157, %1515), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
  %1564 : Long() = prim::NumToTensor(%1563), scope: __module.h.9/__module.h.9.attn
  %1565 : Long() = aten::floor_divide(%1564, %1520), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
  %1566 : int = aten::Int(%1565), scope: __module.h.9/__module.h.9.attn
  %1567 : int[] = prim::ListConstruct(%1561, %1562, %1521, %1566), scope: __module.h.9/__module.h.9.attn
  %x.158 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.157, %1567), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
  %1569 : int[] = prim::ListConstruct(%1517, %1519, %1522, %1516), scope: __module.h.9/__module.h.9.attn
  %k.10 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.158, %1569), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:211:0
  %1571 : int = aten::size(%x.159, %1517), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
  %1572 : int = aten::size(%x.159, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
  %1573 : int = aten::size(%x.159, %1515), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
  %1574 : Long() = prim::NumToTensor(%1573), scope: __module.h.9/__module.h.9.attn
  %1575 : Long() = aten::floor_divide(%1574, %1520), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
  %1576 : int = aten::Int(%1575), scope: __module.h.9/__module.h.9.attn
  %1577 : int[] = prim::ListConstruct(%1571, %1572, %1521, %1576), scope: __module.h.9/__module.h.9.attn
  %x.160 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.159, %1577), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
  %1579 : int[] = prim::ListConstruct(%1517, %1519, %1516, %1522), scope: __module.h.9/__module.h.9.attn
  %v.10 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.160, %1579), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
  %w.37 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.10, %k.10), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:178:0
  %w.38 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.37, %1523), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:180:0
  %1583 : int = aten::size(%w.38, %1524), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
  %1584 : int = aten::size(%w.38, %1515), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
  %1585 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1535, %1517, %1517, %1525, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
  %1586 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1585, %1516, %1517, %1525, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
  %1587 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%1586, %1519, %1517, %1583, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
  %b.10 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%1587, %1522, %1517, %1584, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
  %1589 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.38, %b.10), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:184:0
  %1590 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.10, %1516, %1516), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:396:0
  %1591 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%1590, %1526), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:184:0
  %w.39 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%1589, %1591, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:184:0
  %input.58 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.39, %attention_mask, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:188:0
  %input.59 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.58, %1515, %1527), scope: __module.h.9/__module.h.9.attn # torch/nn/functional.py:1498:0
  %w.40 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.59, %1529, %1528), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.161 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.40, %v.10), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:197:0
  %1597 : int[] = prim::ListConstruct(%1517, %1519, %1516, %1522), scope: __module.h.9/__module.h.9.attn
  %1598 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.161, %1597), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:203:0
  %x.162 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%1598, %1517), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:203:0
  %1600 : int = aten::size(%x.162, %1517), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
  %1601 : int = aten::size(%x.162, %1516), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
  %1602 : int = aten::size(%x.162, %1524), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
  %1603 : Long() = prim::NumToTensor(%1602), scope: __module.h.9/__module.h.9.attn
  %1604 : int = aten::size(%x.162, %1515), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
  %1605 : Long() = prim::NumToTensor(%1604), scope: __module.h.9/__module.h.9.attn
  %1606 : Long() = aten::mul(%1603, %1605), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
  %1607 : int = aten::Int(%1606), scope: __module.h.9/__module.h.9.attn
  %1608 : int[] = prim::ListConstruct(%1600, %1601, %1607), scope: __module.h.9/__module.h.9.attn
  %x.163 : Float(17:9984, 13:768, 768:1) = aten::view(%x.162, %1608), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:205:0
  %1610 : Tensor = prim::GetAttr[name="weight"](%1534)
  %1611 : Tensor = prim::GetAttr[name="bias"](%1534)
  %1612 : int = aten::size(%x.163, %1517), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1613 : int = aten::size(%x.163, %1516), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1614 : int = aten::size(%x.163, %1515), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1615 : int[] = prim::ListConstruct(%1515, %1614), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
  %1616 : Float(221:768, 768:1) = aten::view(%x.163, %1615), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.164 : Float(221:768, 768:1) = aten::addmm(%1611, %1616, %1610, %1516, %1516), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1618 : int[] = prim::ListConstruct(%1612, %1613, %1518), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
  %input.60 : Float(17:9984, 13:768, 768:1) = aten::view(%x.164, %1618), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.10 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.60, %1529, %1528), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.61 : Float(17:9984, 13:768, 768:1) = aten::add(%x.153, %a.10, %1516), scope: __module.h.9 # transformers/modeling_openai.py:266:0
  %1622 : Tensor = prim::GetAttr[name="bias"](%1532)
  %1623 : Tensor = prim::GetAttr[name="weight"](%1532)
  %1624 : int[] = prim::ListConstruct(%1518), scope: __module.h.9/__module.h.9.ln_1
  %x.165 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.61, %1624, %1623, %1622, %1512, %1513), scope: __module.h.9/__module.h.9.ln_1 # torch/nn/functional.py:2048:0
  %1626 : __torch__.transformers.modeling_utils.___torch_mangle_29304.Conv1D = prim::GetAttr[name="c_proj"](%1531)
  %1627 : __torch__.transformers.modeling_utils.___torch_mangle_29303.Conv1D = prim::GetAttr[name="c_fc"](%1531)
  %1628 : Tensor = prim::GetAttr[name="weight"](%1627)
  %1629 : Tensor = prim::GetAttr[name="bias"](%1627)
  %1630 : int = aten::size(%x.165, %1517), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1631 : int = aten::size(%x.165, %1516), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1632 : int = aten::size(%x.165, %1515), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1633 : int[] = prim::ListConstruct(%1515, %1632), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
  %1634 : Float(221:768, 768:1) = aten::view(%x.165, %1633), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.166 : Float(221:3072, 3072:1) = aten::addmm(%1629, %1634, %1628, %1516, %1516), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1636 : int[] = prim::ListConstruct(%1630, %1631, %1506), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
  %x.167 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.166, %1636), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1638 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.167, %1507), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1639 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.167, %1508), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1640 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1639, %1509), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1641 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.167, %1640, %1516), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1642 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1641, %1510), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1643 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%1642), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1644 : Float(17:39936, 13:3072, 3072:1) = aten::add(%1643, %1511, %1516), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %x.168 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1638, %1644), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
  %1646 : Tensor = prim::GetAttr[name="weight"](%1626)
  %1647 : Tensor = prim::GetAttr[name="bias"](%1626)
  %1648 : int = aten::size(%x.168, %1517), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1649 : int = aten::size(%x.168, %1516), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1650 : int = aten::size(%x.168, %1515), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1651 : int[] = prim::ListConstruct(%1515, %1650), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
  %1652 : Float(221:3072, 3072:1) = aten::view(%x.168, %1651), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.169 : Float(221:768, 768:1) = aten::addmm(%1647, %1652, %1646, %1516, %1516), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1654 : int[] = prim::ListConstruct(%1648, %1649, %1518), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
  %input.62 : Float(17:9984, 13:768, 768:1) = aten::view(%x.169, %1654), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.10 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.62, %1529, %1528), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.dropout # torch/nn/functional.py:973:0
  %input.63 : Float(17:9984, 13:768, 768:1) = aten::add(%x.165, %m.10, %1516), scope: __module.h.9 # transformers/modeling_openai.py:268:0
  %1658 : Tensor = prim::GetAttr[name="bias"](%1530)
  %1659 : Tensor = prim::GetAttr[name="weight"](%1530)
  %1660 : int[] = prim::ListConstruct(%1518), scope: __module.h.9/__module.h.9.ln_2
  %x.170 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.63, %1660, %1659, %1658, %1512, %1513), scope: __module.h.9/__module.h.9.ln_2 # torch/nn/functional.py:2048:0
  %1662 : int = prim::Constant[value=3072](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1663 : Double() = prim::Constant[value={0.5}](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1664 : float = prim::Constant[value=3.](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1665 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1666 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1667 : Double() = prim::Constant[value={1}](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1668 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.10/__module.h.10.ln_1 # torch/nn/functional.py:2048:0
  %1669 : bool = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.ln_1 # torch/nn/functional.py:2048:0
  %1670 : int = prim::Constant[value=2304](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1671 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1672 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1673 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1674 : int = prim::Constant[value=768](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:371:0
  %1675 : int = prim::Constant[value=2](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:371:0
  %1676 : Long() = prim::Constant[value={12}](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
  %1677 : int = prim::Constant[value=12](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
  %1678 : int = prim::Constant[value=3](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
  %1679 : Double() = prim::Constant[value={8}](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:180:0
  %1680 : int = prim::Constant[value=-2](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
  %1681 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
  %1682 : Double() = prim::Constant[value={-10000}](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:184:0
  %1683 : None = prim::Constant(), scope: __module.h.10/__module.h.10.attn
  %1684 : bool = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.attn_dropout # torch/nn/functional.py:973:0
  %1685 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.attn_dropout # torch/nn/functional.py:973:0
  %1686 : __torch__.torch.nn.modules.normalization.___torch_mangle_29319.LayerNorm = prim::GetAttr[name="ln_2"](%6)
  %1687 : __torch__.transformers.modeling_openai.___torch_mangle_29318.MLP = prim::GetAttr[name="mlp"](%6)
  %1688 : __torch__.torch.nn.modules.normalization.___torch_mangle_29314.LayerNorm = prim::GetAttr[name="ln_1"](%6)
  %1689 : __torch__.transformers.modeling_openai.___torch_mangle_29313.Attention = prim::GetAttr[name="attn"](%6)
  %1690 : __torch__.transformers.modeling_utils.___torch_mangle_29310.Conv1D = prim::GetAttr[name="c_proj"](%1689)
  %1691 : Tensor = prim::GetAttr[name="bias"](%1689)
  %1692 : __torch__.transformers.modeling_utils.___torch_mangle_29309.Conv1D = prim::GetAttr[name="c_attn"](%1689)
  %1693 : Tensor = prim::GetAttr[name="weight"](%1692)
  %1694 : Tensor = prim::GetAttr[name="bias"](%1692)
  %1695 : int = aten::size(%x.170, %1673), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1696 : int = aten::size(%x.170, %1672), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1697 : int = aten::size(%x.170, %1671), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1698 : int[] = prim::ListConstruct(%1671, %1697), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
  %1699 : Float(221:768, 768:1) = aten::view(%x.170, %1698), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.171 : Float(221:2304, 2304:1) = aten::addmm(%1694, %1699, %1693, %1672, %1672), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1701 : int[] = prim::ListConstruct(%1695, %1696, %1670), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
  %1702 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.171, %1701), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1703 : Tensor[] = aten::split(%1702, %1674, %1675), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:371:0
  %x.172 : Float(17:29952, 13:2304, 768:1), %x.174 : Float(17:29952, 13:2304, 768:1), %x.176 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%1703), scope: __module.h.10/__module.h.10.attn
  %1707 : int = aten::size(%x.172, %1673), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
  %1708 : int = aten::size(%x.172, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
  %1709 : int = aten::size(%x.172, %1671), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
  %1710 : Long() = prim::NumToTensor(%1709), scope: __module.h.10/__module.h.10.attn
  %1711 : Long() = aten::floor_divide(%1710, %1676), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
  %1712 : int = aten::Int(%1711), scope: __module.h.10/__module.h.10.attn
  %1713 : int[] = prim::ListConstruct(%1707, %1708, %1677, %1712), scope: __module.h.10/__module.h.10.attn
  %x.173 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.172, %1713), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
  %1715 : int[] = prim::ListConstruct(%1673, %1675, %1672, %1678), scope: __module.h.10/__module.h.10.attn
  %q.11 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.173, %1715), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
  %1717 : int = aten::size(%x.174, %1673), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
  %1718 : int = aten::size(%x.174, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
  %1719 : int = aten::size(%x.174, %1671), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
  %1720 : Long() = prim::NumToTensor(%1719), scope: __module.h.10/__module.h.10.attn
  %1721 : Long() = aten::floor_divide(%1720, %1676), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
  %1722 : int = aten::Int(%1721), scope: __module.h.10/__module.h.10.attn
  %1723 : int[] = prim::ListConstruct(%1717, %1718, %1677, %1722), scope: __module.h.10/__module.h.10.attn
  %x.175 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.174, %1723), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
  %1725 : int[] = prim::ListConstruct(%1673, %1675, %1678, %1672), scope: __module.h.10/__module.h.10.attn
  %k.11 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.175, %1725), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:211:0
  %1727 : int = aten::size(%x.176, %1673), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
  %1728 : int = aten::size(%x.176, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
  %1729 : int = aten::size(%x.176, %1671), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
  %1730 : Long() = prim::NumToTensor(%1729), scope: __module.h.10/__module.h.10.attn
  %1731 : Long() = aten::floor_divide(%1730, %1676), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
  %1732 : int = aten::Int(%1731), scope: __module.h.10/__module.h.10.attn
  %1733 : int[] = prim::ListConstruct(%1727, %1728, %1677, %1732), scope: __module.h.10/__module.h.10.attn
  %x.177 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.176, %1733), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
  %1735 : int[] = prim::ListConstruct(%1673, %1675, %1672, %1678), scope: __module.h.10/__module.h.10.attn
  %v.11 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.177, %1735), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
  %w.41 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.11, %k.11), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:178:0
  %w.42 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.41, %1679), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:180:0
  %1739 : int = aten::size(%w.42, %1680), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
  %1740 : int = aten::size(%w.42, %1671), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
  %1741 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1691, %1673, %1673, %1681, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
  %1742 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1741, %1672, %1673, %1681, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
  %1743 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%1742, %1675, %1673, %1739, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
  %b.11 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%1743, %1678, %1673, %1740, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
  %1745 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.42, %b.11), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:184:0
  %1746 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.11, %1672, %1672), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:396:0
  %1747 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%1746, %1682), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:184:0
  %w.43 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%1745, %1747, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:184:0
  %input.64 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.43, %attention_mask, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:188:0
  %input.65 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.64, %1671, %1683), scope: __module.h.10/__module.h.10.attn # torch/nn/functional.py:1498:0
  %w.44 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.65, %1685, %1684), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.178 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w.44, %v.11), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:197:0
  %1753 : int[] = prim::ListConstruct(%1673, %1675, %1672, %1678), scope: __module.h.10/__module.h.10.attn
  %1754 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.178, %1753), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:203:0
  %x.179 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%1754, %1673), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:203:0
  %1756 : int = aten::size(%x.179, %1673), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
  %1757 : int = aten::size(%x.179, %1672), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
  %1758 : int = aten::size(%x.179, %1680), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
  %1759 : Long() = prim::NumToTensor(%1758), scope: __module.h.10/__module.h.10.attn
  %1760 : int = aten::size(%x.179, %1671), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
  %1761 : Long() = prim::NumToTensor(%1760), scope: __module.h.10/__module.h.10.attn
  %1762 : Long() = aten::mul(%1759, %1761), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
  %1763 : int = aten::Int(%1762), scope: __module.h.10/__module.h.10.attn
  %1764 : int[] = prim::ListConstruct(%1756, %1757, %1763), scope: __module.h.10/__module.h.10.attn
  %x.180 : Float(17:9984, 13:768, 768:1) = aten::view(%x.179, %1764), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:205:0
  %1766 : Tensor = prim::GetAttr[name="weight"](%1690)
  %1767 : Tensor = prim::GetAttr[name="bias"](%1690)
  %1768 : int = aten::size(%x.180, %1673), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1769 : int = aten::size(%x.180, %1672), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1770 : int = aten::size(%x.180, %1671), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1771 : int[] = prim::ListConstruct(%1671, %1770), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
  %1772 : Float(221:768, 768:1) = aten::view(%x.180, %1771), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.181 : Float(221:768, 768:1) = aten::addmm(%1767, %1772, %1766, %1672, %1672), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1774 : int[] = prim::ListConstruct(%1768, %1769, %1674), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
  %input.66 : Float(17:9984, 13:768, 768:1) = aten::view(%x.181, %1774), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a.11 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.66, %1685, %1684), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.67 : Float(17:9984, 13:768, 768:1) = aten::add(%x.170, %a.11, %1672), scope: __module.h.10 # transformers/modeling_openai.py:266:0
  %1778 : Tensor = prim::GetAttr[name="bias"](%1688)
  %1779 : Tensor = prim::GetAttr[name="weight"](%1688)
  %1780 : int[] = prim::ListConstruct(%1674), scope: __module.h.10/__module.h.10.ln_1
  %x.182 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.67, %1780, %1779, %1778, %1668, %1669), scope: __module.h.10/__module.h.10.ln_1 # torch/nn/functional.py:2048:0
  %1782 : __torch__.transformers.modeling_utils.___torch_mangle_29316.Conv1D = prim::GetAttr[name="c_proj"](%1687)
  %1783 : __torch__.transformers.modeling_utils.___torch_mangle_29315.Conv1D = prim::GetAttr[name="c_fc"](%1687)
  %1784 : Tensor = prim::GetAttr[name="weight"](%1783)
  %1785 : Tensor = prim::GetAttr[name="bias"](%1783)
  %1786 : int = aten::size(%x.182, %1673), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1787 : int = aten::size(%x.182, %1672), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1788 : int = aten::size(%x.182, %1671), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1789 : int[] = prim::ListConstruct(%1671, %1788), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
  %1790 : Float(221:768, 768:1) = aten::view(%x.182, %1789), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.183 : Float(221:3072, 3072:1) = aten::addmm(%1785, %1790, %1784, %1672, %1672), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1792 : int[] = prim::ListConstruct(%1786, %1787, %1662), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
  %x.184 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.183, %1792), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1794 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.184, %1663), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1795 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.184, %1664), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1796 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1795, %1665), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1797 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.184, %1796, %1672), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1798 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1797, %1666), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1799 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%1798), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1800 : Float(17:39936, 13:3072, 3072:1) = aten::add(%1799, %1667, %1672), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %x.185 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1794, %1800), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
  %1802 : Tensor = prim::GetAttr[name="weight"](%1782)
  %1803 : Tensor = prim::GetAttr[name="bias"](%1782)
  %1804 : int = aten::size(%x.185, %1673), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1805 : int = aten::size(%x.185, %1672), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1806 : int = aten::size(%x.185, %1671), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1807 : int[] = prim::ListConstruct(%1671, %1806), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
  %1808 : Float(221:3072, 3072:1) = aten::view(%x.185, %1807), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x.186 : Float(221:768, 768:1) = aten::addmm(%1803, %1808, %1802, %1672, %1672), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1810 : int[] = prim::ListConstruct(%1804, %1805, %1674), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
  %input.68 : Float(17:9984, 13:768, 768:1) = aten::view(%x.186, %1810), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m.11 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.68, %1685, %1684), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.dropout # torch/nn/functional.py:973:0
  %input.69 : Float(17:9984, 13:768, 768:1) = aten::add(%x.182, %m.11, %1672), scope: __module.h.10 # transformers/modeling_openai.py:268:0
  %1814 : Tensor = prim::GetAttr[name="bias"](%1686)
  %1815 : Tensor = prim::GetAttr[name="weight"](%1686)
  %1816 : int[] = prim::ListConstruct(%1674), scope: __module.h.10/__module.h.10.ln_2
  %x.187 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.69, %1816, %1815, %1814, %1668, %1669), scope: __module.h.10/__module.h.10.ln_2 # torch/nn/functional.py:2048:0
  %1818 : int = prim::Constant[value=3072](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1819 : Double() = prim::Constant[value={0.5}](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1820 : float = prim::Constant[value=3.](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1821 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1822 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1823 : Double() = prim::Constant[value={1}](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1824 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.11/__module.h.11.ln_1 # torch/nn/functional.py:2048:0
  %1825 : bool = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.ln_1 # torch/nn/functional.py:2048:0
  %1826 : int = prim::Constant[value=2304](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1827 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1828 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1829 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1830 : int = prim::Constant[value=768](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:371:0
  %1831 : int = prim::Constant[value=2](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:371:0
  %1832 : Long() = prim::Constant[value={12}](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
  %1833 : int = prim::Constant[value=12](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
  %1834 : int = prim::Constant[value=3](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
  %1835 : Double() = prim::Constant[value={8}](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:180:0
  %1836 : int = prim::Constant[value=-2](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
  %1837 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
  %1838 : Double() = prim::Constant[value={-10000}](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:184:0
  %1839 : None = prim::Constant(), scope: __module.h.11/__module.h.11.attn
  %1840 : bool = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.attn_dropout # torch/nn/functional.py:973:0
  %1841 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.attn_dropout # torch/nn/functional.py:973:0
  %1842 : __torch__.torch.nn.modules.normalization.___torch_mangle_29331.LayerNorm = prim::GetAttr[name="ln_2"](%4)
  %1843 : __torch__.transformers.modeling_openai.___torch_mangle_29330.MLP = prim::GetAttr[name="mlp"](%4)
  %1844 : __torch__.torch.nn.modules.normalization.___torch_mangle_29326.LayerNorm = prim::GetAttr[name="ln_1"](%4)
  %1845 : __torch__.transformers.modeling_openai.___torch_mangle_29325.Attention = prim::GetAttr[name="attn"](%4)
  %1846 : __torch__.transformers.modeling_utils.___torch_mangle_29322.Conv1D = prim::GetAttr[name="c_proj"](%1845)
  %1847 : Tensor = prim::GetAttr[name="bias"](%1845)
  %1848 : __torch__.transformers.modeling_utils.___torch_mangle_29321.Conv1D = prim::GetAttr[name="c_attn"](%1845)
  %1849 : Tensor = prim::GetAttr[name="weight"](%1848)
  %1850 : Tensor = prim::GetAttr[name="bias"](%1848)
  %1851 : int = aten::size(%x.187, %1829), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1852 : int = aten::size(%x.187, %1828), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1093:0
  %1853 : int = aten::size(%x.187, %1827), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1854 : int[] = prim::ListConstruct(%1827, %1853), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
  %1855 : Float(221:768, 768:1) = aten::view(%x.187, %1854), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
  %x.188 : Float(221:2304, 2304:1) = aten::addmm(%1850, %1855, %1849, %1828, %1828), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
  %1857 : int[] = prim::ListConstruct(%1851, %1852, %1826), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
  %1858 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.188, %1857), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1095:0
  %1859 : Tensor[] = aten::split(%1858, %1830, %1831), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:371:0
  %x.189 : Float(17:29952, 13:2304, 768:1), %x.191 : Float(17:29952, 13:2304, 768:1), %x.193 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%1859), scope: __module.h.11/__module.h.11.attn
  %1863 : int = aten::size(%x.189, %1829), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
  %1864 : int = aten::size(%x.189, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
  %1865 : int = aten::size(%x.189, %1827), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
  %1866 : Long() = prim::NumToTensor(%1865), scope: __module.h.11/__module.h.11.attn
  %1867 : Long() = aten::floor_divide(%1866, %1832), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
  %1868 : int = aten::Int(%1867), scope: __module.h.11/__module.h.11.attn
  %1869 : int[] = prim::ListConstruct(%1863, %1864, %1833, %1868), scope: __module.h.11/__module.h.11.attn
  %x.190 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.189, %1869), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
  %1871 : int[] = prim::ListConstruct(%1829, %1831, %1828, %1834), scope: __module.h.11/__module.h.11.attn
  %q : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.190, %1871), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
  %1873 : int = aten::size(%x.191, %1829), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
  %1874 : int = aten::size(%x.191, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
  %1875 : int = aten::size(%x.191, %1827), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
  %1876 : Long() = prim::NumToTensor(%1875), scope: __module.h.11/__module.h.11.attn
  %1877 : Long() = aten::floor_divide(%1876, %1832), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
  %1878 : int = aten::Int(%1877), scope: __module.h.11/__module.h.11.attn
  %1879 : int[] = prim::ListConstruct(%1873, %1874, %1833, %1878), scope: __module.h.11/__module.h.11.attn
  %x.192 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.191, %1879), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
  %1881 : int[] = prim::ListConstruct(%1829, %1831, %1834, %1828), scope: __module.h.11/__module.h.11.attn
  %k : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.192, %1881), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:211:0
  %1883 : int = aten::size(%x.193, %1829), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
  %1884 : int = aten::size(%x.193, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
  %1885 : int = aten::size(%x.193, %1827), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
  %1886 : Long() = prim::NumToTensor(%1885), scope: __module.h.11/__module.h.11.attn
  %1887 : Long() = aten::floor_divide(%1886, %1832), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
  %1888 : int = aten::Int(%1887), scope: __module.h.11/__module.h.11.attn
  %1889 : int[] = prim::ListConstruct(%1883, %1884, %1833, %1888), scope: __module.h.11/__module.h.11.attn
  %x.194 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.193, %1889), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
  %1891 : int[] = prim::ListConstruct(%1829, %1831, %1828, %1834), scope: __module.h.11/__module.h.11.attn
  %v : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.194, %1891), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
  %w.45 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q, %k), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:178:0
  %w.46 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.45, %1835), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:180:0
  %1895 : int = aten::size(%w.46, %1836), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
  %1896 : int = aten::size(%w.46, %1827), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
  %1897 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1847, %1829, %1829, %1837, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
  %1898 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%1897, %1828, %1829, %1837, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
  %1899 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%1898, %1831, %1829, %1895, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
  %b : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%1899, %1834, %1829, %1896, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
  %1901 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.46, %b), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:184:0
  %1902 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b, %1828, %1828), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:396:0
  %1903 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%1902, %1838), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:184:0
  %w.47 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%1901, %1903, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:184:0
  %input.70 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.47, %attention_mask, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:188:0
  %input.71 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.70, %1827, %1839), scope: __module.h.11/__module.h.11.attn # torch/nn/functional.py:1498:0
  %w : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.71, %1841, %1840), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.attn_dropout # torch/nn/functional.py:973:0
  %x.195 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%w, %v), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:197:0
  %1909 : int[] = prim::ListConstruct(%1829, %1831, %1828, %1834), scope: __module.h.11/__module.h.11.attn
  %1910 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.195, %1909), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:203:0
  %x.196 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%1910, %1829), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:203:0
  %1912 : int = aten::size(%x.196, %1829), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
  %1913 : int = aten::size(%x.196, %1828), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
  %1914 : int = aten::size(%x.196, %1836), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
  %1915 : Long() = prim::NumToTensor(%1914), scope: __module.h.11/__module.h.11.attn
  %1916 : int = aten::size(%x.196, %1827), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
  %1917 : Long() = prim::NumToTensor(%1916), scope: __module.h.11/__module.h.11.attn
  %1918 : Long() = aten::mul(%1915, %1917), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
  %1919 : int = aten::Int(%1918), scope: __module.h.11/__module.h.11.attn
  %1920 : int[] = prim::ListConstruct(%1912, %1913, %1919), scope: __module.h.11/__module.h.11.attn
  %x.197 : Float(17:9984, 13:768, 768:1) = aten::view(%x.196, %1920), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:205:0
  %1922 : Tensor = prim::GetAttr[name="weight"](%1846)
  %1923 : Tensor = prim::GetAttr[name="bias"](%1846)
  %1924 : int = aten::size(%x.197, %1829), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1925 : int = aten::size(%x.197, %1828), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1093:0
  %1926 : int = aten::size(%x.197, %1827), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1927 : int[] = prim::ListConstruct(%1827, %1926), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
  %1928 : Float(221:768, 768:1) = aten::view(%x.197, %1927), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
  %x.198 : Float(221:768, 768:1) = aten::addmm(%1923, %1928, %1922, %1828, %1828), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
  %1930 : int[] = prim::ListConstruct(%1924, %1925, %1830), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
  %input.72 : Float(17:9984, 13:768, 768:1) = aten::view(%x.198, %1930), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1095:0
  %a : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.72, %1841, %1840), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.resid_dropout # torch/nn/functional.py:973:0
  %input.73 : Float(17:9984, 13:768, 768:1) = aten::add(%x.187, %a, %1828), scope: __module.h.11 # transformers/modeling_openai.py:266:0
  %1934 : Tensor = prim::GetAttr[name="bias"](%1844)
  %1935 : Tensor = prim::GetAttr[name="weight"](%1844)
  %1936 : int[] = prim::ListConstruct(%1830), scope: __module.h.11/__module.h.11.ln_1
  %x.199 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.73, %1936, %1935, %1934, %1824, %1825), scope: __module.h.11/__module.h.11.ln_1 # torch/nn/functional.py:2048:0
  %1938 : __torch__.transformers.modeling_utils.___torch_mangle_29328.Conv1D = prim::GetAttr[name="c_proj"](%1843)
  %1939 : __torch__.transformers.modeling_utils.___torch_mangle_29327.Conv1D = prim::GetAttr[name="c_fc"](%1843)
  %1940 : Tensor = prim::GetAttr[name="weight"](%1939)
  %1941 : Tensor = prim::GetAttr[name="bias"](%1939)
  %1942 : int = aten::size(%x.199, %1829), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1943 : int = aten::size(%x.199, %1828), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1093:0
  %1944 : int = aten::size(%x.199, %1827), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1945 : int[] = prim::ListConstruct(%1827, %1944), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
  %1946 : Float(221:768, 768:1) = aten::view(%x.199, %1945), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %x.200 : Float(221:3072, 3072:1) = aten::addmm(%1941, %1946, %1940, %1828, %1828), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
  %1948 : int[] = prim::ListConstruct(%1942, %1943, %1818), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
  %x.201 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.200, %1948), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1095:0
  %1950 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%x.201, %1819), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1951 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%x.201, %1820), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1952 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1951, %1821), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1953 : Float(17:39936, 13:3072, 3072:1) = aten::add(%x.201, %1952, %1828), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1954 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1953, %1822), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1955 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%1954), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1956 : Float(17:39936, 13:3072, 3072:1) = aten::add(%1955, %1823, %1828), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %x.202 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%1950, %1956), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
  %1958 : Tensor = prim::GetAttr[name="weight"](%1938)
  %1959 : Tensor = prim::GetAttr[name="bias"](%1938)
  %1960 : int = aten::size(%x.202, %1829), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1961 : int = aten::size(%x.202, %1828), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1093:0
  %1962 : int = aten::size(%x.202, %1827), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1963 : int[] = prim::ListConstruct(%1827, %1962), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
  %1964 : Float(221:3072, 3072:1) = aten::view(%x.202, %1963), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %x : Float(221:768, 768:1) = aten::addmm(%1959, %1964, %1958, %1828, %1828), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
  %1966 : int[] = prim::ListConstruct(%1960, %1961, %1830), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
  %input.74 : Float(17:9984, 13:768, 768:1) = aten::view(%x, %1966), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1095:0
  %m : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.74, %1841, %1840), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.dropout # torch/nn/functional.py:973:0
  %input : Float(17:9984, 13:768, 768:1) = aten::add(%x.199, %m, %1828), scope: __module.h.11 # transformers/modeling_openai.py:268:0
  %1970 : Tensor = prim::GetAttr[name="bias"](%1842)
  %1971 : Tensor = prim::GetAttr[name="weight"](%1842)
  %1972 : int[] = prim::ListConstruct(%1830), scope: __module.h.11/__module.h.11.ln_2
  %hidden_states : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input, %1972, %1971, %1970, %1824, %1825), scope: __module.h.11/__module.h.11.ln_2 # torch/nn/functional.py:2048:0
  %88 : int[] = prim::ListConstruct(%34, %38, %75)
  %89 : Float(17:9984, 13:768, 768:1) = aten::view(%hidden_states, %88) # transformers/modeling_openai.py:513:0
  %90 : (Float(17:9984, 13:768, 768:1)) = prim::TupleConstruct(%89)
  return (%90)
