OpenAIGPTModel(
  (tokens_embed): Embedding(40478, 768)
  (positions_embed): Embedding(512, 768)
  (drop): Dropout(p=0.1, inplace=False)
  (h): ModuleList(
    (0): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (1): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (2): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (3): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (4): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (5): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (6): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (7): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (8): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (9): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (10): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
    (11): Block(
      (attn): Attention(
        (c_attn): Conv1D()
        (c_proj): Conv1D()
        (attn_dropout): Dropout(p=0.1, inplace=False)
        (resid_dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
      (mlp): MLP(
        (c_fc): Conv1D()
        (c_proj): Conv1D()
        (dropout): Dropout(p=0.1, inplace=False)
      )
      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
    )
  )
)

OpenAIGPTModel._actual_script_module
OpenAIGPTModel.forward
  graph(%self.1 : __torch__.transformers.modeling_openai.OpenAIGPTModel,
        %input_ids : Long(17:13, 13:1),
        %attention_mask.1 : Long(17:13, 13:1)):
    %4530 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4531 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="11"](%4530)
    %4504 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4505 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="10"](%4504)
    %4478 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4479 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="9"](%4478)
    %4452 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4453 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="8"](%4452)
    %4426 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4427 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="7"](%4426)
    %4400 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4401 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="6"](%4400)
    %4374 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4375 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="5"](%4374)
    %4348 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4349 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="4"](%4348)
    %4322 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4323 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="3"](%4322)
    %4296 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4297 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="2"](%4296)
    %4270 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4271 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="1"](%4270)
    %4244 : __torch__.torch.nn.modules.container.ModuleList = prim::GetAttr[name="h"](%self.1)
    %4245 : __torch__.transformers.modeling_openai.Block = prim::GetAttr[name="0"](%4244)
    %4219 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="drop"](%self.1)
    %4218 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name="positions_embed"](%self.1)
    %4216 : __torch__.torch.nn.modules.sparse.Embedding = prim::GetAttr[name="tokens_embed"](%self.1)
    %4214 : Tensor = prim::GetAttr[name="position_ids"](%self.1)
    %459 : int = prim::Constant[value=0]() # transformers/modeling_openai.py:458:0
    %460 : int = aten::size(%input_ids, %459) # transformers/modeling_openai.py:458:0
    %461 : Long() = prim::NumToTensor(%460)
    %4061 : int = aten::Int(%461)
    %462 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:458:0
    %463 : int = aten::size(%input_ids, %462) # transformers/modeling_openai.py:458:0
    %464 : Long() = prim::NumToTensor(%463)
    %4062 : int = aten::Int(%464)
    %471 : int = aten::Int(%464)
    %465 : int = aten::Int(%464)
    %466 : int = prim::Constant[value=-1]() # transformers/modeling_openai.py:459:0
    %467 : int[] = prim::ListConstruct(%466, %465)
    %input.1 : Long(17:13, 13:1) = aten::view(%input_ids, %467) # transformers/modeling_openai.py:459:0
    %469 : int = prim::Constant[value=0]() # transformers/modeling_openai.py:467:0
    %470 : Long(1:512, 512:1) = aten::unsqueeze(%4214, %469) # transformers/modeling_openai.py:467:0
    %472 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:467:0
    %473 : int = prim::Constant[value=0]() # transformers/modeling_openai.py:467:0
    %474 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:467:0
    %input.2 : Long(1:512, 13:1) = aten::slice(%470, %472, %473, %471, %474) # transformers/modeling_openai.py:467:0
    %476 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:476:0
    %477 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%attention_mask.1, %476) # transformers/modeling_openai.py:476:0
    %478 : int = prim::Constant[value=2]() # transformers/modeling_openai.py:476:0
    %attention_mask.2 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%477, %478) # transformers/modeling_openai.py:476:0
    %480 : int = prim::Constant[value=6]() # transformers/modeling_openai.py:483:0
    %481 : bool = prim::Constant[value=0]() # transformers/modeling_openai.py:483:0
    %482 : bool = prim::Constant[value=0]() # transformers/modeling_openai.py:483:0
    %483 : None = prim::Constant()
    %484 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%attention_mask.2, %480, %481, %482, %483) # transformers/modeling_openai.py:483:0
    %485 : float = prim::Constant[value=1.]() # torch/tensor.py:396:0
    %486 : int = prim::Constant[value=1]() # torch/tensor.py:396:0
    %487 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%484, %485, %486) # torch/tensor.py:396:0
    %488 : Double() = prim::Constant[value={-10000}]() # transformers/modeling_openai.py:484:0
    %attention_mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%487, %488) # transformers/modeling_openai.py:484:0
    %4679 : Tensor = prim::CallMethod[name="forward"](%4216, %input.1)
    %4680 : Tensor = prim::CallMethod[name="forward"](%4218, %input.2)
    %498 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:497:0
    %499 : Float(17:9984, 13:768, 768:1) = aten::add(%4679, %4680, %498) # transformers/modeling_openai.py:497:0
    %500 : Long() = prim::Constant[value={0}]() # transformers/modeling_openai.py:497:0
    %501 : int = prim::Constant[value=1]() # transformers/modeling_openai.py:497:0
    %input.3 : Float(17:9984, 13:768, 768:1) = aten::add(%499, %500, %501) # transformers/modeling_openai.py:497:0
    %4681 : Tensor = prim::CallMethod[name="forward"](%4219, %input.3)
    %506 : int = prim::Constant[value=-1]() # transformers/modeling_openai.py:500:0
    %507 : int = aten::size(%4681, %506) # transformers/modeling_openai.py:500:0
    %508 : Long() = prim::NumToTensor(%507)
    %4063 : int = aten::Int(%508)
    %4682 : Tensor = prim::CallMethod[name="forward"](%4245, %4681, %attention_mask)
    %4683 : Tensor = prim::CallMethod[name="forward"](%4271, %4682, %attention_mask)
    %4684 : Tensor = prim::CallMethod[name="forward"](%4297, %4683, %attention_mask)
    %4685 : Tensor = prim::CallMethod[name="forward"](%4323, %4684, %attention_mask)
    %4686 : Tensor = prim::CallMethod[name="forward"](%4349, %4685, %attention_mask)
    %4687 : Tensor = prim::CallMethod[name="forward"](%4375, %4686, %attention_mask)
    %4688 : Tensor = prim::CallMethod[name="forward"](%4401, %4687, %attention_mask)
    %4689 : Tensor = prim::CallMethod[name="forward"](%4427, %4688, %attention_mask)
    %4690 : Tensor = prim::CallMethod[name="forward"](%4453, %4689, %attention_mask)
    %4691 : Tensor = prim::CallMethod[name="forward"](%4479, %4690, %attention_mask)
    %4692 : Tensor = prim::CallMethod[name="forward"](%4505, %4691, %attention_mask)
    %4693 : Tensor = prim::CallMethod[name="forward"](%4531, %4692, %attention_mask)
    %4064 : int[] = prim::ListConstruct(%4061, %4062, %4063)
    %4065 : Float(17:9984, 13:768, 768:1) = aten::view(%4693, %4064) # transformers/modeling_openai.py:513:0
    %4066 : (Float(17:9984, 13:768, 768:1)) = prim::TupleConstruct(%4065)
    return (%4066)

OpenAIGPTModel.drop
Dropout._actual_script_module
  graph(%self.4 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.3 : Float(17:9984, 13:768, 768:1)):
    %1 : float = prim::Constant[value=0.10000000000000001](), scope: __module.drop # torch/nn/functional.py:973:0
    %2 : bool = prim::Constant[value=0](), scope: __module.drop # torch/nn/functional.py:973:0
    %hidden_states.1 : Float(17:9984, 13:768, 768:1) = aten::dropout(%input.3, %1, %2), scope: __module.drop # torch/nn/functional.py:973:0
    return (%hidden_states.1)

OpenAIGPTModel.positions_embed
Embedding._actual_script_module
  graph(%self.3 : __torch__.torch.nn.modules.sparse.Embedding,
        %input.2 : Long(1:512, 13:1)):
    %1 : Tensor = prim::GetAttr[name="weight"](%self.3)
    %2 : int = prim::Constant[value=-1](), scope: __module.positions_embed # torch/nn/functional.py:1814:0
    %3 : bool = prim::Constant[value=0](), scope: __module.positions_embed # torch/nn/functional.py:1814:0
    %4 : bool = prim::Constant[value=0](), scope: __module.positions_embed # torch/nn/functional.py:1814:0
    %position_embeds : Float(1:9984, 13:768, 768:1) = aten::embedding(%1, %input.2, %2, %3, %4), scope: __module.positions_embed # torch/nn/functional.py:1814:0
    return (%position_embeds)

OpenAIGPTModel.tokens_embed
Embedding._actual_script_module
  graph(%self.2 : __torch__.torch.nn.modules.sparse.Embedding,
        %input.1 : Long(17:13, 13:1)):
    %1 : Tensor = prim::GetAttr[name="weight"](%self.2)
    %2 : int = prim::Constant[value=-1](), scope: __module.tokens_embed # torch/nn/functional.py:1814:0
    %3 : bool = prim::Constant[value=0](), scope: __module.tokens_embed # torch/nn/functional.py:1814:0
    %4 : bool = prim::Constant[value=0](), scope: __module.tokens_embed # torch/nn/functional.py:1814:0
    %inputs_embeds : Float(17:9984, 13:768, 768:1) = aten::embedding(%1, %input.1, %2, %3, %4), scope: __module.tokens_embed # torch/nn/functional.py:1814:0
    return (%inputs_embeds)

ModuleList.*
  module had no methods with graph attrs.

Block._actual_script_module
  graph(%self.5 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.5)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.5)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.5)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.5)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.0 # transformers/modeling_openai.py:266:0
    %input.7 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.0 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.7)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.0 # transformers/modeling_openai.py:268:0
    %input.9 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.0 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.9)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.6 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.6)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.6)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.6)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.6)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.6)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:371:0
    %x.2 : Float(17:29952, 13:2304, 768:1), %x.4 : Float(17:29952, 13:2304, 768:1), %x.6 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.0/__module.h.0.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.2, %15), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.0/__module.h.0.attn
    %18 : int = aten::Int(%17), scope: __module.h.0/__module.h.0.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.2, %19), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.0/__module.h.0.attn
    %22 : int = aten::Int(%21), scope: __module.h.0/__module.h.0.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.2, %26), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.0/__module.h.0.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.0/__module.h.0.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.0/__module.h.0.attn
    %x.3 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.2, %33), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.0/__module.h.0.attn
    %q.1 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.3, %39), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.4, %41), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.0/__module.h.0.attn
    %44 : int = aten::Int(%43), scope: __module.h.0/__module.h.0.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.4, %45), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.0/__module.h.0.attn
    %48 : int = aten::Int(%47), scope: __module.h.0/__module.h.0.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.4, %52), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.0/__module.h.0.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.0/__module.h.0.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.0/__module.h.0.attn
    %x.5 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.4, %59), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.0/__module.h.0.attn
    %k.1 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.5, %65), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.6, %67), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.0/__module.h.0.attn
    %70 : int = aten::Int(%69), scope: __module.h.0/__module.h.0.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.6, %71), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.0/__module.h.0.attn
    %74 : int = aten::Int(%73), scope: __module.h.0/__module.h.0.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.6, %78), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.0/__module.h.0.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.0/__module.h.0.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.0/__module.h.0.attn
    %x.7 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.6, %85), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.0/__module.h.0.attn
    %v.1 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.7, %91), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:213:0
    %w.1 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.1, %k.1), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:180:0
    %w.2 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.1, %97), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.2, %99), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.0/__module.h.0.attn
    %102 : int = aten::Int(%101), scope: __module.h.0/__module.h.0.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.2, %103), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.0/__module.h.0.attn
    %106 : int = aten::Int(%105), scope: __module.h.0/__module.h.0.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %b.1 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.2, %b.1), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.1, %126, %127), scope: __module.h.0/__module.h.0.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:184:0
    %w.3 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:188:0
    %input.4 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.3, %attention_mask, %133), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.0/__module.h.0.attn
    %input.5 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.4, %135, %136), scope: __module.h.0/__module.h.0.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.5)
    %x.8 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.1), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.0/__module.h.0.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.8, %144), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:203:0
    %x.9 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.9, %148), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.0/__module.h.0.attn
    %151 : int = aten::Int(%150), scope: __module.h.0/__module.h.0.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.9, %152), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.0/__module.h.0.attn
    %155 : int = aten::Int(%154), scope: __module.h.0/__module.h.0.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.9, %162), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.0/__module.h.0.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.9, %165), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.0/__module.h.0.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.0/__module.h.0.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.0/__module.h.0.attn
    %x.10 : Float(17:9984, 13:768, 768:1) = aten::view(%x.9, %170), scope: __module.h.0/__module.h.0.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.10)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.11 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.7 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.11)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.11)
    %4 : int = prim::Constant[value=768](), scope: __module.h.0/__module.h.0.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.0/__module.h.0.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.0/__module.h.0.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.ln_1 # torch/nn/functional.py:2048:0
    %x.12 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.7, %5, %3, %2, %6, %7), scope: __module.h.0/__module.h.0.ln_1 # torch/nn/functional.py:2048:0
    return (%x.12)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.16 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.9 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.16)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.16)
    %4 : int = prim::Constant[value=768](), scope: __module.h.0/__module.h.0.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.0/__module.h.0.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.0/__module.h.0.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.ln_2 # torch/nn/functional.py:2048:0
    %x.17 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.9, %5, %3, %2, %6, %7), scope: __module.h.0/__module.h.0.ln_2 # torch/nn/functional.py:2048:0
    return (%x.17)

Block.mlp
MLP._actual_script_module
  graph(%self.12 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.12)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.12)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.12)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %x.15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.0/__module.h.0.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.15)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.8 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.5 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.4 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.5, %2, %3), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.4)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.7 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.7)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.7)
    %4 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.1 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.1, %26), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.9 : __torch__.transformers.modeling_utils.Conv1D,
        %x.10 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.9)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.9)
    %4 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.10, %4), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.10, %8), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.10, %15), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.10, %20), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.11 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj
    %input.6 : Float(17:9984, 13:768, 768:1) = aten::view(%x.11, %26), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.6)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.10 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.1 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.0/__module.h.0.attn/__module.h.0.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.1)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.13 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.13)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.13)
    %4 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.13 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc
    %x.14 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.13, %26), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.14)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.14 : __torch__.transformers.modeling_utils.Conv1D,
        %x.15 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.14)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.14)
    %4 : int = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.15, %4), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.15, %8), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.15, %15), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.15, %20), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.16 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj
    %input.8 : Float(17:9984, 13:768, 768:1) = aten::view(%x.16, %26), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.8)

MLP.dropout
Dropout._actual_script_module
  graph(%self.15 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.dropout # torch/nn/functional.py:973:0
    %m.1 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.0/__module.h.0.mlp/__module.h.0.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.1)

Block._actual_script_module
  graph(%self.17 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.17)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.17)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.17)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.17)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.1 # transformers/modeling_openai.py:266:0
    %input.13 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.1 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.13)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.1 # transformers/modeling_openai.py:268:0
    %input.15 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.1 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.15)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.18 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.18)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.18)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.18)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.18)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.18)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:371:0
    %x.19 : Float(17:29952, 13:2304, 768:1), %x.21 : Float(17:29952, 13:2304, 768:1), %x.23 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.1/__module.h.1.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.19, %15), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.1/__module.h.1.attn
    %18 : int = aten::Int(%17), scope: __module.h.1/__module.h.1.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.19, %19), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.1/__module.h.1.attn
    %22 : int = aten::Int(%21), scope: __module.h.1/__module.h.1.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.19, %26), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.1/__module.h.1.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.1/__module.h.1.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.1/__module.h.1.attn
    %x.20 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.19, %33), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.1/__module.h.1.attn
    %q.2 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.20, %39), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.21, %41), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.1/__module.h.1.attn
    %44 : int = aten::Int(%43), scope: __module.h.1/__module.h.1.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.21, %45), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.1/__module.h.1.attn
    %48 : int = aten::Int(%47), scope: __module.h.1/__module.h.1.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.21, %52), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.1/__module.h.1.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.1/__module.h.1.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.1/__module.h.1.attn
    %x.22 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.21, %59), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.1/__module.h.1.attn
    %k.2 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.22, %65), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.23, %67), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.1/__module.h.1.attn
    %70 : int = aten::Int(%69), scope: __module.h.1/__module.h.1.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.23, %71), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.1/__module.h.1.attn
    %74 : int = aten::Int(%73), scope: __module.h.1/__module.h.1.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.23, %78), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.1/__module.h.1.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.1/__module.h.1.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.1/__module.h.1.attn
    %x.24 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.23, %85), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.1/__module.h.1.attn
    %v.2 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.24, %91), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:213:0
    %w.5 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.2, %k.2), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:180:0
    %w.6 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.5, %97), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.6, %99), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.1/__module.h.1.attn
    %102 : int = aten::Int(%101), scope: __module.h.1/__module.h.1.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.6, %103), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.1/__module.h.1.attn
    %106 : int = aten::Int(%105), scope: __module.h.1/__module.h.1.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %b.2 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.6, %b.2), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.2, %126, %127), scope: __module.h.1/__module.h.1.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:184:0
    %w.7 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:188:0
    %input.10 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.7, %attention_mask, %133), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.1/__module.h.1.attn
    %input.11 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.10, %135, %136), scope: __module.h.1/__module.h.1.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.11)
    %x.25 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.2), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.1/__module.h.1.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.25, %144), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:203:0
    %x.26 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.26, %148), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.1/__module.h.1.attn
    %151 : int = aten::Int(%150), scope: __module.h.1/__module.h.1.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.26, %152), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.1/__module.h.1.attn
    %155 : int = aten::Int(%154), scope: __module.h.1/__module.h.1.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.26, %162), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.1/__module.h.1.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.26, %165), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.1/__module.h.1.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.1/__module.h.1.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.1/__module.h.1.attn
    %x.27 : Float(17:9984, 13:768, 768:1) = aten::view(%x.26, %170), scope: __module.h.1/__module.h.1.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.27)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.23 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.13 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.23)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.23)
    %4 : int = prim::Constant[value=768](), scope: __module.h.1/__module.h.1.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.1/__module.h.1.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.1/__module.h.1.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.ln_1 # torch/nn/functional.py:2048:0
    %x.29 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.13, %5, %3, %2, %6, %7), scope: __module.h.1/__module.h.1.ln_1 # torch/nn/functional.py:2048:0
    return (%x.29)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.28 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.15 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.28)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.28)
    %4 : int = prim::Constant[value=768](), scope: __module.h.1/__module.h.1.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.1/__module.h.1.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.1/__module.h.1.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.ln_2 # torch/nn/functional.py:2048:0
    %x.34 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.15, %5, %3, %2, %6, %7), scope: __module.h.1/__module.h.1.ln_2 # torch/nn/functional.py:2048:0
    return (%x.34)

Block.mlp
MLP._actual_script_module
  graph(%self.24 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.24)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.24)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.24)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %x.32 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.1/__module.h.1.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.32)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.20 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.11 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.8 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.11, %2, %3), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.8)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.19 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.19)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.19)
    %4 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.18 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.18, %26), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.21 : __torch__.transformers.modeling_utils.Conv1D,
        %x.27 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.21)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.21)
    %4 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.27, %4), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.27, %8), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.27, %15), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.27, %20), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.28 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj
    %input.12 : Float(17:9984, 13:768, 768:1) = aten::view(%x.28, %26), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.12)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.22 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.2 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.1/__module.h.1.attn/__module.h.1.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.2)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.25 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.25)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.25)
    %4 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.30 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc
    %x.31 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.30, %26), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.31)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.26 : __torch__.transformers.modeling_utils.Conv1D,
        %x.32 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.26)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.26)
    %4 : int = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.32, %4), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.32, %8), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.32, %15), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.32, %20), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.33 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj
    %input.14 : Float(17:9984, 13:768, 768:1) = aten::view(%x.33, %26), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.14)

MLP.dropout
Dropout._actual_script_module
  graph(%self.27 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.dropout # torch/nn/functional.py:973:0
    %m.2 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.1/__module.h.1.mlp/__module.h.1.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.2)

Block._actual_script_module
  graph(%self.29 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.29)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.29)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.29)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.29)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.2 # transformers/modeling_openai.py:266:0
    %input.19 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.2 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.19)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.2 # transformers/modeling_openai.py:268:0
    %input.21 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.2 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.21)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.30 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.30)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.30)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.30)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.30)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.30)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:371:0
    %x.36 : Float(17:29952, 13:2304, 768:1), %x.38 : Float(17:29952, 13:2304, 768:1), %x.40 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.2/__module.h.2.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.36, %15), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.2/__module.h.2.attn
    %18 : int = aten::Int(%17), scope: __module.h.2/__module.h.2.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.36, %19), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.2/__module.h.2.attn
    %22 : int = aten::Int(%21), scope: __module.h.2/__module.h.2.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.36, %26), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.2/__module.h.2.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.2/__module.h.2.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.2/__module.h.2.attn
    %x.37 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.36, %33), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.2/__module.h.2.attn
    %q.3 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.37, %39), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.38, %41), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.2/__module.h.2.attn
    %44 : int = aten::Int(%43), scope: __module.h.2/__module.h.2.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.38, %45), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.2/__module.h.2.attn
    %48 : int = aten::Int(%47), scope: __module.h.2/__module.h.2.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.38, %52), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.2/__module.h.2.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.2/__module.h.2.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.2/__module.h.2.attn
    %x.39 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.38, %59), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.2/__module.h.2.attn
    %k.3 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.39, %65), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.40, %67), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.2/__module.h.2.attn
    %70 : int = aten::Int(%69), scope: __module.h.2/__module.h.2.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.40, %71), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.2/__module.h.2.attn
    %74 : int = aten::Int(%73), scope: __module.h.2/__module.h.2.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.40, %78), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.2/__module.h.2.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.2/__module.h.2.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.2/__module.h.2.attn
    %x.41 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.40, %85), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.2/__module.h.2.attn
    %v.3 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.41, %91), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:213:0
    %w.9 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.3, %k.3), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:180:0
    %w.10 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.9, %97), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.10, %99), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.2/__module.h.2.attn
    %102 : int = aten::Int(%101), scope: __module.h.2/__module.h.2.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.10, %103), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.2/__module.h.2.attn
    %106 : int = aten::Int(%105), scope: __module.h.2/__module.h.2.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %b.3 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.10, %b.3), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.3, %126, %127), scope: __module.h.2/__module.h.2.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:184:0
    %w.11 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:188:0
    %input.16 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.11, %attention_mask, %133), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.2/__module.h.2.attn
    %input.17 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.16, %135, %136), scope: __module.h.2/__module.h.2.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.17)
    %x.42 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.3), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.2/__module.h.2.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.42, %144), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:203:0
    %x.43 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.43, %148), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.2/__module.h.2.attn
    %151 : int = aten::Int(%150), scope: __module.h.2/__module.h.2.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.43, %152), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.2/__module.h.2.attn
    %155 : int = aten::Int(%154), scope: __module.h.2/__module.h.2.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.43, %162), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.2/__module.h.2.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.43, %165), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.2/__module.h.2.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.2/__module.h.2.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.2/__module.h.2.attn
    %x.44 : Float(17:9984, 13:768, 768:1) = aten::view(%x.43, %170), scope: __module.h.2/__module.h.2.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.44)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.35 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.19 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.35)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.35)
    %4 : int = prim::Constant[value=768](), scope: __module.h.2/__module.h.2.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.2/__module.h.2.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.2/__module.h.2.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.ln_1 # torch/nn/functional.py:2048:0
    %x.46 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.19, %5, %3, %2, %6, %7), scope: __module.h.2/__module.h.2.ln_1 # torch/nn/functional.py:2048:0
    return (%x.46)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.40 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.21 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.40)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.40)
    %4 : int = prim::Constant[value=768](), scope: __module.h.2/__module.h.2.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.2/__module.h.2.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.2/__module.h.2.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.ln_2 # torch/nn/functional.py:2048:0
    %x.51 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.21, %5, %3, %2, %6, %7), scope: __module.h.2/__module.h.2.ln_2 # torch/nn/functional.py:2048:0
    return (%x.51)

Block.mlp
MLP._actual_script_module
  graph(%self.36 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.36)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.36)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.36)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %x.49 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.2/__module.h.2.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.49)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.32 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.17 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.12 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.17, %2, %3), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.12)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.31 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.31)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.31)
    %4 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.35 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.35, %26), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.33 : __torch__.transformers.modeling_utils.Conv1D,
        %x.44 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.33)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.33)
    %4 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.44, %4), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.44, %8), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.44, %15), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.44, %20), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.45 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj
    %input.18 : Float(17:9984, 13:768, 768:1) = aten::view(%x.45, %26), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.18)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.34 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.3 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.2/__module.h.2.attn/__module.h.2.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.3)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.37 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.37)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.37)
    %4 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.47 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc
    %x.48 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.47, %26), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.48)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.38 : __torch__.transformers.modeling_utils.Conv1D,
        %x.49 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.38)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.38)
    %4 : int = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.49, %4), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.49, %8), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.49, %15), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.49, %20), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.50 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj
    %input.20 : Float(17:9984, 13:768, 768:1) = aten::view(%x.50, %26), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.20)

MLP.dropout
Dropout._actual_script_module
  graph(%self.39 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.dropout # torch/nn/functional.py:973:0
    %m.3 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.2/__module.h.2.mlp/__module.h.2.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.3)

Block._actual_script_module
  graph(%self.41 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.41)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.41)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.41)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.41)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.3 # transformers/modeling_openai.py:266:0
    %input.25 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.3 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.25)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.3 # transformers/modeling_openai.py:268:0
    %input.27 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.3 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.27)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.42 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.42)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.42)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.42)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.42)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.42)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:371:0
    %x.53 : Float(17:29952, 13:2304, 768:1), %x.55 : Float(17:29952, 13:2304, 768:1), %x.57 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.3/__module.h.3.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.53, %15), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.3/__module.h.3.attn
    %18 : int = aten::Int(%17), scope: __module.h.3/__module.h.3.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.53, %19), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.3/__module.h.3.attn
    %22 : int = aten::Int(%21), scope: __module.h.3/__module.h.3.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.53, %26), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.3/__module.h.3.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.3/__module.h.3.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.3/__module.h.3.attn
    %x.54 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.53, %33), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.3/__module.h.3.attn
    %q.4 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.54, %39), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.55, %41), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.3/__module.h.3.attn
    %44 : int = aten::Int(%43), scope: __module.h.3/__module.h.3.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.55, %45), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.3/__module.h.3.attn
    %48 : int = aten::Int(%47), scope: __module.h.3/__module.h.3.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.55, %52), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.3/__module.h.3.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.3/__module.h.3.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.3/__module.h.3.attn
    %x.56 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.55, %59), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.3/__module.h.3.attn
    %k.4 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.56, %65), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.57, %67), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.3/__module.h.3.attn
    %70 : int = aten::Int(%69), scope: __module.h.3/__module.h.3.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.57, %71), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.3/__module.h.3.attn
    %74 : int = aten::Int(%73), scope: __module.h.3/__module.h.3.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.57, %78), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.3/__module.h.3.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.3/__module.h.3.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.3/__module.h.3.attn
    %x.58 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.57, %85), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.3/__module.h.3.attn
    %v.4 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.58, %91), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:213:0
    %w.13 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.4, %k.4), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:180:0
    %w.14 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.13, %97), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.14, %99), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.3/__module.h.3.attn
    %102 : int = aten::Int(%101), scope: __module.h.3/__module.h.3.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.14, %103), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.3/__module.h.3.attn
    %106 : int = aten::Int(%105), scope: __module.h.3/__module.h.3.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %b.4 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.14, %b.4), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.4, %126, %127), scope: __module.h.3/__module.h.3.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:184:0
    %w.15 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:188:0
    %input.22 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.15, %attention_mask, %133), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.3/__module.h.3.attn
    %input.23 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.22, %135, %136), scope: __module.h.3/__module.h.3.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.23)
    %x.59 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.4), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.3/__module.h.3.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.59, %144), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:203:0
    %x.60 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.60, %148), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.3/__module.h.3.attn
    %151 : int = aten::Int(%150), scope: __module.h.3/__module.h.3.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.60, %152), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.3/__module.h.3.attn
    %155 : int = aten::Int(%154), scope: __module.h.3/__module.h.3.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.60, %162), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.3/__module.h.3.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.60, %165), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.3/__module.h.3.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.3/__module.h.3.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.3/__module.h.3.attn
    %x.61 : Float(17:9984, 13:768, 768:1) = aten::view(%x.60, %170), scope: __module.h.3/__module.h.3.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.61)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.47 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.25 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.47)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.47)
    %4 : int = prim::Constant[value=768](), scope: __module.h.3/__module.h.3.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.3/__module.h.3.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.3/__module.h.3.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.ln_1 # torch/nn/functional.py:2048:0
    %x.63 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.25, %5, %3, %2, %6, %7), scope: __module.h.3/__module.h.3.ln_1 # torch/nn/functional.py:2048:0
    return (%x.63)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.52 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.27 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.52)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.52)
    %4 : int = prim::Constant[value=768](), scope: __module.h.3/__module.h.3.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.3/__module.h.3.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.3/__module.h.3.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.ln_2 # torch/nn/functional.py:2048:0
    %x.68 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.27, %5, %3, %2, %6, %7), scope: __module.h.3/__module.h.3.ln_2 # torch/nn/functional.py:2048:0
    return (%x.68)

Block.mlp
MLP._actual_script_module
  graph(%self.48 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.48)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.48)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.48)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %x.66 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.3/__module.h.3.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.66)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.44 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.23 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.16 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.23, %2, %3), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.16)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.43 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.43)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.43)
    %4 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.52 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.52, %26), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.45 : __torch__.transformers.modeling_utils.Conv1D,
        %x.61 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.45)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.45)
    %4 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.61, %4), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.61, %8), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.61, %15), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.61, %20), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.62 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj
    %input.24 : Float(17:9984, 13:768, 768:1) = aten::view(%x.62, %26), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.24)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.46 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.4 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.3/__module.h.3.attn/__module.h.3.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.4)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.49 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.49)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.49)
    %4 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.64 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc
    %x.65 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.64, %26), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.65)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.50 : __torch__.transformers.modeling_utils.Conv1D,
        %x.66 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.50)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.50)
    %4 : int = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.66, %4), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.66, %8), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.66, %15), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.66, %20), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.67 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj
    %input.26 : Float(17:9984, 13:768, 768:1) = aten::view(%x.67, %26), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.26)

MLP.dropout
Dropout._actual_script_module
  graph(%self.51 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.dropout # torch/nn/functional.py:973:0
    %m.4 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.3/__module.h.3.mlp/__module.h.3.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.4)

Block._actual_script_module
  graph(%self.53 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.53)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.53)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.53)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.53)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.4 # transformers/modeling_openai.py:266:0
    %input.31 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.4 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.31)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.4 # transformers/modeling_openai.py:268:0
    %input.33 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.4 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.33)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.54 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.54)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.54)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.54)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.54)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.54)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:371:0
    %x.70 : Float(17:29952, 13:2304, 768:1), %x.72 : Float(17:29952, 13:2304, 768:1), %x.74 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.4/__module.h.4.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.70, %15), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.4/__module.h.4.attn
    %18 : int = aten::Int(%17), scope: __module.h.4/__module.h.4.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.70, %19), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.4/__module.h.4.attn
    %22 : int = aten::Int(%21), scope: __module.h.4/__module.h.4.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.70, %26), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.4/__module.h.4.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.4/__module.h.4.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.4/__module.h.4.attn
    %x.71 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.70, %33), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.4/__module.h.4.attn
    %q.5 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.71, %39), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.72, %41), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.4/__module.h.4.attn
    %44 : int = aten::Int(%43), scope: __module.h.4/__module.h.4.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.72, %45), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.4/__module.h.4.attn
    %48 : int = aten::Int(%47), scope: __module.h.4/__module.h.4.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.72, %52), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.4/__module.h.4.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.4/__module.h.4.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.4/__module.h.4.attn
    %x.73 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.72, %59), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.4/__module.h.4.attn
    %k.5 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.73, %65), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.74, %67), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.4/__module.h.4.attn
    %70 : int = aten::Int(%69), scope: __module.h.4/__module.h.4.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.74, %71), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.4/__module.h.4.attn
    %74 : int = aten::Int(%73), scope: __module.h.4/__module.h.4.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.74, %78), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.4/__module.h.4.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.4/__module.h.4.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.4/__module.h.4.attn
    %x.75 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.74, %85), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.4/__module.h.4.attn
    %v.5 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.75, %91), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:213:0
    %w.17 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.5, %k.5), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:180:0
    %w.18 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.17, %97), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.18, %99), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.4/__module.h.4.attn
    %102 : int = aten::Int(%101), scope: __module.h.4/__module.h.4.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.18, %103), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.4/__module.h.4.attn
    %106 : int = aten::Int(%105), scope: __module.h.4/__module.h.4.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %b.5 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.18, %b.5), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.5, %126, %127), scope: __module.h.4/__module.h.4.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:184:0
    %w.19 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:188:0
    %input.28 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.19, %attention_mask, %133), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.4/__module.h.4.attn
    %input.29 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.28, %135, %136), scope: __module.h.4/__module.h.4.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.29)
    %x.76 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.5), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.4/__module.h.4.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.76, %144), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:203:0
    %x.77 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.77, %148), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.4/__module.h.4.attn
    %151 : int = aten::Int(%150), scope: __module.h.4/__module.h.4.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.77, %152), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.4/__module.h.4.attn
    %155 : int = aten::Int(%154), scope: __module.h.4/__module.h.4.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.77, %162), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.4/__module.h.4.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.77, %165), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.4/__module.h.4.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.4/__module.h.4.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.4/__module.h.4.attn
    %x.78 : Float(17:9984, 13:768, 768:1) = aten::view(%x.77, %170), scope: __module.h.4/__module.h.4.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.78)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.59 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.31 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.59)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.59)
    %4 : int = prim::Constant[value=768](), scope: __module.h.4/__module.h.4.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.4/__module.h.4.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.4/__module.h.4.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.ln_1 # torch/nn/functional.py:2048:0
    %x.80 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.31, %5, %3, %2, %6, %7), scope: __module.h.4/__module.h.4.ln_1 # torch/nn/functional.py:2048:0
    return (%x.80)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.64 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.33 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.64)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.64)
    %4 : int = prim::Constant[value=768](), scope: __module.h.4/__module.h.4.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.4/__module.h.4.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.4/__module.h.4.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.ln_2 # torch/nn/functional.py:2048:0
    %x.85 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.33, %5, %3, %2, %6, %7), scope: __module.h.4/__module.h.4.ln_2 # torch/nn/functional.py:2048:0
    return (%x.85)

Block.mlp
MLP._actual_script_module
  graph(%self.60 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.60)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.60)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.60)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %x.83 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.4/__module.h.4.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.83)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.56 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.29 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.20 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.29, %2, %3), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.20)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.55 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.55)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.55)
    %4 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.69 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.69, %26), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.57 : __torch__.transformers.modeling_utils.Conv1D,
        %x.78 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.57)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.57)
    %4 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.78, %4), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.78, %8), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.78, %15), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.78, %20), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.79 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj
    %input.30 : Float(17:9984, 13:768, 768:1) = aten::view(%x.79, %26), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.30)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.58 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.5 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.4/__module.h.4.attn/__module.h.4.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.5)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.61 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.61)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.61)
    %4 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.81 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc
    %x.82 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.81, %26), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.82)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.62 : __torch__.transformers.modeling_utils.Conv1D,
        %x.83 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.62)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.62)
    %4 : int = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.83, %4), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.83, %8), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.83, %15), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.83, %20), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.84 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj
    %input.32 : Float(17:9984, 13:768, 768:1) = aten::view(%x.84, %26), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.32)

MLP.dropout
Dropout._actual_script_module
  graph(%self.63 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.dropout # torch/nn/functional.py:973:0
    %m.5 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.4/__module.h.4.mlp/__module.h.4.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.5)

Block._actual_script_module
  graph(%self.65 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.65)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.65)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.65)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.65)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.5 # transformers/modeling_openai.py:266:0
    %input.37 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.5 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.37)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.5 # transformers/modeling_openai.py:268:0
    %input.39 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.5 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.39)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.66 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.66)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.66)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.66)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.66)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.66)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:371:0
    %x.87 : Float(17:29952, 13:2304, 768:1), %x.89 : Float(17:29952, 13:2304, 768:1), %x.91 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.5/__module.h.5.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.87, %15), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.5/__module.h.5.attn
    %18 : int = aten::Int(%17), scope: __module.h.5/__module.h.5.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.87, %19), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.5/__module.h.5.attn
    %22 : int = aten::Int(%21), scope: __module.h.5/__module.h.5.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.87, %26), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.5/__module.h.5.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.5/__module.h.5.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.5/__module.h.5.attn
    %x.88 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.87, %33), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.5/__module.h.5.attn
    %q.6 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.88, %39), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.89, %41), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.5/__module.h.5.attn
    %44 : int = aten::Int(%43), scope: __module.h.5/__module.h.5.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.89, %45), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.5/__module.h.5.attn
    %48 : int = aten::Int(%47), scope: __module.h.5/__module.h.5.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.89, %52), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.5/__module.h.5.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.5/__module.h.5.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.5/__module.h.5.attn
    %x.90 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.89, %59), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.5/__module.h.5.attn
    %k.6 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.90, %65), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.91, %67), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.5/__module.h.5.attn
    %70 : int = aten::Int(%69), scope: __module.h.5/__module.h.5.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.91, %71), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.5/__module.h.5.attn
    %74 : int = aten::Int(%73), scope: __module.h.5/__module.h.5.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.91, %78), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.5/__module.h.5.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.5/__module.h.5.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.5/__module.h.5.attn
    %x.92 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.91, %85), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.5/__module.h.5.attn
    %v.6 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.92, %91), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:213:0
    %w.21 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.6, %k.6), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:180:0
    %w.22 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.21, %97), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.22, %99), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.5/__module.h.5.attn
    %102 : int = aten::Int(%101), scope: __module.h.5/__module.h.5.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.22, %103), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.5/__module.h.5.attn
    %106 : int = aten::Int(%105), scope: __module.h.5/__module.h.5.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %b.6 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.22, %b.6), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.6, %126, %127), scope: __module.h.5/__module.h.5.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:184:0
    %w.23 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:188:0
    %input.34 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.23, %attention_mask, %133), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.5/__module.h.5.attn
    %input.35 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.34, %135, %136), scope: __module.h.5/__module.h.5.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.35)
    %x.93 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.6), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.5/__module.h.5.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.93, %144), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:203:0
    %x.94 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.94, %148), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.5/__module.h.5.attn
    %151 : int = aten::Int(%150), scope: __module.h.5/__module.h.5.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.94, %152), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.5/__module.h.5.attn
    %155 : int = aten::Int(%154), scope: __module.h.5/__module.h.5.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.94, %162), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.5/__module.h.5.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.94, %165), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.5/__module.h.5.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.5/__module.h.5.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.5/__module.h.5.attn
    %x.95 : Float(17:9984, 13:768, 768:1) = aten::view(%x.94, %170), scope: __module.h.5/__module.h.5.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.95)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.71 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.37 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.71)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.71)
    %4 : int = prim::Constant[value=768](), scope: __module.h.5/__module.h.5.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.5/__module.h.5.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.5/__module.h.5.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.ln_1 # torch/nn/functional.py:2048:0
    %x.97 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.37, %5, %3, %2, %6, %7), scope: __module.h.5/__module.h.5.ln_1 # torch/nn/functional.py:2048:0
    return (%x.97)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.76 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.39 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.76)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.76)
    %4 : int = prim::Constant[value=768](), scope: __module.h.5/__module.h.5.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.5/__module.h.5.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.5/__module.h.5.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.ln_2 # torch/nn/functional.py:2048:0
    %x.102 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.39, %5, %3, %2, %6, %7), scope: __module.h.5/__module.h.5.ln_2 # torch/nn/functional.py:2048:0
    return (%x.102)

Block.mlp
MLP._actual_script_module
  graph(%self.72 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.72)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.72)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.72)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %x.100 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.5/__module.h.5.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.100)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.68 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.35 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.24 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.35, %2, %3), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.24)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.67 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.67)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.67)
    %4 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.86 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.86, %26), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.69 : __torch__.transformers.modeling_utils.Conv1D,
        %x.95 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.69)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.69)
    %4 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.95, %4), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.95, %8), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.95, %15), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.95, %20), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.96 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj
    %input.36 : Float(17:9984, 13:768, 768:1) = aten::view(%x.96, %26), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.36)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.70 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.6 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.5/__module.h.5.attn/__module.h.5.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.6)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.73 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.73)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.73)
    %4 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.98 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc
    %x.99 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.98, %26), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.99)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.74 : __torch__.transformers.modeling_utils.Conv1D,
        %x.100 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.74)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.74)
    %4 : int = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.100, %4), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.100, %8), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.100, %15), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.100, %20), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.101 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj
    %input.38 : Float(17:9984, 13:768, 768:1) = aten::view(%x.101, %26), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.38)

MLP.dropout
Dropout._actual_script_module
  graph(%self.75 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.dropout # torch/nn/functional.py:973:0
    %m.6 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.5/__module.h.5.mlp/__module.h.5.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.6)

Block._actual_script_module
  graph(%self.77 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.77)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.77)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.77)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.77)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.6 # transformers/modeling_openai.py:266:0
    %input.43 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.6 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.43)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.6 # transformers/modeling_openai.py:268:0
    %input.45 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.6 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.45)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.78 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.78)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.78)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.78)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.78)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.78)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:371:0
    %x.104 : Float(17:29952, 13:2304, 768:1), %x.106 : Float(17:29952, 13:2304, 768:1), %x.108 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.6/__module.h.6.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.104, %15), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.6/__module.h.6.attn
    %18 : int = aten::Int(%17), scope: __module.h.6/__module.h.6.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.104, %19), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.6/__module.h.6.attn
    %22 : int = aten::Int(%21), scope: __module.h.6/__module.h.6.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.104, %26), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.6/__module.h.6.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.6/__module.h.6.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.6/__module.h.6.attn
    %x.105 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.104, %33), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.6/__module.h.6.attn
    %q.7 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.105, %39), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.106, %41), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.6/__module.h.6.attn
    %44 : int = aten::Int(%43), scope: __module.h.6/__module.h.6.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.106, %45), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.6/__module.h.6.attn
    %48 : int = aten::Int(%47), scope: __module.h.6/__module.h.6.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.106, %52), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.6/__module.h.6.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.6/__module.h.6.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.6/__module.h.6.attn
    %x.107 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.106, %59), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.6/__module.h.6.attn
    %k.7 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.107, %65), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.108, %67), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.6/__module.h.6.attn
    %70 : int = aten::Int(%69), scope: __module.h.6/__module.h.6.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.108, %71), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.6/__module.h.6.attn
    %74 : int = aten::Int(%73), scope: __module.h.6/__module.h.6.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.108, %78), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.6/__module.h.6.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.6/__module.h.6.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.6/__module.h.6.attn
    %x.109 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.108, %85), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.6/__module.h.6.attn
    %v.7 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.109, %91), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:213:0
    %w.25 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.7, %k.7), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:180:0
    %w.26 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.25, %97), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.26, %99), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.6/__module.h.6.attn
    %102 : int = aten::Int(%101), scope: __module.h.6/__module.h.6.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.26, %103), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.6/__module.h.6.attn
    %106 : int = aten::Int(%105), scope: __module.h.6/__module.h.6.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %b.7 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.26, %b.7), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.7, %126, %127), scope: __module.h.6/__module.h.6.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:184:0
    %w.27 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:188:0
    %input.40 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.27, %attention_mask, %133), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.6/__module.h.6.attn
    %input.41 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.40, %135, %136), scope: __module.h.6/__module.h.6.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.41)
    %x.110 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.7), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.6/__module.h.6.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.110, %144), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:203:0
    %x.111 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.111, %148), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.6/__module.h.6.attn
    %151 : int = aten::Int(%150), scope: __module.h.6/__module.h.6.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.111, %152), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.6/__module.h.6.attn
    %155 : int = aten::Int(%154), scope: __module.h.6/__module.h.6.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.111, %162), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.6/__module.h.6.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.111, %165), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.6/__module.h.6.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.6/__module.h.6.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.6/__module.h.6.attn
    %x.112 : Float(17:9984, 13:768, 768:1) = aten::view(%x.111, %170), scope: __module.h.6/__module.h.6.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.112)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.83 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.43 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.83)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.83)
    %4 : int = prim::Constant[value=768](), scope: __module.h.6/__module.h.6.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.6/__module.h.6.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.6/__module.h.6.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.ln_1 # torch/nn/functional.py:2048:0
    %x.114 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.43, %5, %3, %2, %6, %7), scope: __module.h.6/__module.h.6.ln_1 # torch/nn/functional.py:2048:0
    return (%x.114)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.88 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.45 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.88)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.88)
    %4 : int = prim::Constant[value=768](), scope: __module.h.6/__module.h.6.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.6/__module.h.6.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.6/__module.h.6.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.ln_2 # torch/nn/functional.py:2048:0
    %x.119 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.45, %5, %3, %2, %6, %7), scope: __module.h.6/__module.h.6.ln_2 # torch/nn/functional.py:2048:0
    return (%x.119)

Block.mlp
MLP._actual_script_module
  graph(%self.84 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.84)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.84)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.84)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %x.117 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.6/__module.h.6.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.117)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.80 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.41 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.28 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.41, %2, %3), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.28)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.79 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.79)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.79)
    %4 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.103 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.103, %26), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.81 : __torch__.transformers.modeling_utils.Conv1D,
        %x.112 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.81)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.81)
    %4 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.112, %4), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.112, %8), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.112, %15), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.112, %20), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.113 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj
    %input.42 : Float(17:9984, 13:768, 768:1) = aten::view(%x.113, %26), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.42)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.82 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.7 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.6/__module.h.6.attn/__module.h.6.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.7)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.85 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.85)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.85)
    %4 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.115 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc
    %x.116 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.115, %26), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.116)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.86 : __torch__.transformers.modeling_utils.Conv1D,
        %x.117 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.86)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.86)
    %4 : int = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.117, %4), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.117, %8), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.117, %15), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.117, %20), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.118 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj
    %input.44 : Float(17:9984, 13:768, 768:1) = aten::view(%x.118, %26), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.44)

MLP.dropout
Dropout._actual_script_module
  graph(%self.87 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.dropout # torch/nn/functional.py:973:0
    %m.7 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.6/__module.h.6.mlp/__module.h.6.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.7)

Block._actual_script_module
  graph(%self.89 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.89)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.89)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.89)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.89)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.7 # transformers/modeling_openai.py:266:0
    %input.49 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.7 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.49)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.7 # transformers/modeling_openai.py:268:0
    %input.51 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.7 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.51)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.90 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.90)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.90)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.90)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.90)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.90)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:371:0
    %x.121 : Float(17:29952, 13:2304, 768:1), %x.123 : Float(17:29952, 13:2304, 768:1), %x.125 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.7/__module.h.7.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.121, %15), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.7/__module.h.7.attn
    %18 : int = aten::Int(%17), scope: __module.h.7/__module.h.7.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.121, %19), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.7/__module.h.7.attn
    %22 : int = aten::Int(%21), scope: __module.h.7/__module.h.7.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.121, %26), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.7/__module.h.7.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.7/__module.h.7.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.7/__module.h.7.attn
    %x.122 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.121, %33), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.7/__module.h.7.attn
    %q.8 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.122, %39), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.123, %41), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.7/__module.h.7.attn
    %44 : int = aten::Int(%43), scope: __module.h.7/__module.h.7.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.123, %45), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.7/__module.h.7.attn
    %48 : int = aten::Int(%47), scope: __module.h.7/__module.h.7.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.123, %52), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.7/__module.h.7.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.7/__module.h.7.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.7/__module.h.7.attn
    %x.124 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.123, %59), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.7/__module.h.7.attn
    %k.8 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.124, %65), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.125, %67), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.7/__module.h.7.attn
    %70 : int = aten::Int(%69), scope: __module.h.7/__module.h.7.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.125, %71), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.7/__module.h.7.attn
    %74 : int = aten::Int(%73), scope: __module.h.7/__module.h.7.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.125, %78), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.7/__module.h.7.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.7/__module.h.7.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.7/__module.h.7.attn
    %x.126 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.125, %85), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.7/__module.h.7.attn
    %v.8 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.126, %91), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:213:0
    %w.29 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.8, %k.8), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:180:0
    %w.30 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.29, %97), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.30, %99), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.7/__module.h.7.attn
    %102 : int = aten::Int(%101), scope: __module.h.7/__module.h.7.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.30, %103), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.7/__module.h.7.attn
    %106 : int = aten::Int(%105), scope: __module.h.7/__module.h.7.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %b.8 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.30, %b.8), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.8, %126, %127), scope: __module.h.7/__module.h.7.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:184:0
    %w.31 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:188:0
    %input.46 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.31, %attention_mask, %133), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.7/__module.h.7.attn
    %input.47 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.46, %135, %136), scope: __module.h.7/__module.h.7.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.47)
    %x.127 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.8), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.7/__module.h.7.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.127, %144), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:203:0
    %x.128 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.128, %148), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.7/__module.h.7.attn
    %151 : int = aten::Int(%150), scope: __module.h.7/__module.h.7.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.128, %152), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.7/__module.h.7.attn
    %155 : int = aten::Int(%154), scope: __module.h.7/__module.h.7.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.128, %162), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.7/__module.h.7.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.128, %165), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.7/__module.h.7.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.7/__module.h.7.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.7/__module.h.7.attn
    %x.129 : Float(17:9984, 13:768, 768:1) = aten::view(%x.128, %170), scope: __module.h.7/__module.h.7.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.129)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.95 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.49 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.95)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.95)
    %4 : int = prim::Constant[value=768](), scope: __module.h.7/__module.h.7.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.7/__module.h.7.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.7/__module.h.7.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.ln_1 # torch/nn/functional.py:2048:0
    %x.131 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.49, %5, %3, %2, %6, %7), scope: __module.h.7/__module.h.7.ln_1 # torch/nn/functional.py:2048:0
    return (%x.131)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.100 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.51 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.100)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.100)
    %4 : int = prim::Constant[value=768](), scope: __module.h.7/__module.h.7.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.7/__module.h.7.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.7/__module.h.7.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.ln_2 # torch/nn/functional.py:2048:0
    %x.136 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.51, %5, %3, %2, %6, %7), scope: __module.h.7/__module.h.7.ln_2 # torch/nn/functional.py:2048:0
    return (%x.136)

Block.mlp
MLP._actual_script_module
  graph(%self.96 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.96)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.96)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.96)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %x.134 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.7/__module.h.7.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.134)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.92 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.47 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.32 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.47, %2, %3), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.32)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.91 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.91)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.91)
    %4 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.120 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.120, %26), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.93 : __torch__.transformers.modeling_utils.Conv1D,
        %x.129 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.93)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.93)
    %4 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.129, %4), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.129, %8), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.129, %15), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.129, %20), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.130 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj
    %input.48 : Float(17:9984, 13:768, 768:1) = aten::view(%x.130, %26), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.48)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.94 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.8 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.7/__module.h.7.attn/__module.h.7.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.8)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.97 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.97)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.97)
    %4 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.132 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc
    %x.133 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.132, %26), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.133)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.98 : __torch__.transformers.modeling_utils.Conv1D,
        %x.134 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.98)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.98)
    %4 : int = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.134, %4), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.134, %8), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.134, %15), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.134, %20), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.135 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj
    %input.50 : Float(17:9984, 13:768, 768:1) = aten::view(%x.135, %26), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.50)

MLP.dropout
Dropout._actual_script_module
  graph(%self.99 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.dropout # torch/nn/functional.py:973:0
    %m.8 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.7/__module.h.7.mlp/__module.h.7.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.8)

Block._actual_script_module
  graph(%self.101 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.101)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.101)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.101)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.101)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.8 # transformers/modeling_openai.py:266:0
    %input.55 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.8 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.55)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.8 # transformers/modeling_openai.py:268:0
    %input.57 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.8 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.57)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.102 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.102)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.102)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.102)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.102)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.102)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:371:0
    %x.138 : Float(17:29952, 13:2304, 768:1), %x.140 : Float(17:29952, 13:2304, 768:1), %x.142 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.8/__module.h.8.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.138, %15), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.8/__module.h.8.attn
    %18 : int = aten::Int(%17), scope: __module.h.8/__module.h.8.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.138, %19), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.8/__module.h.8.attn
    %22 : int = aten::Int(%21), scope: __module.h.8/__module.h.8.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.138, %26), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.8/__module.h.8.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.8/__module.h.8.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.8/__module.h.8.attn
    %x.139 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.138, %33), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.8/__module.h.8.attn
    %q.9 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.139, %39), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.140, %41), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.8/__module.h.8.attn
    %44 : int = aten::Int(%43), scope: __module.h.8/__module.h.8.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.140, %45), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.8/__module.h.8.attn
    %48 : int = aten::Int(%47), scope: __module.h.8/__module.h.8.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.140, %52), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.8/__module.h.8.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.8/__module.h.8.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.8/__module.h.8.attn
    %x.141 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.140, %59), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.8/__module.h.8.attn
    %k.9 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.141, %65), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.142, %67), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.8/__module.h.8.attn
    %70 : int = aten::Int(%69), scope: __module.h.8/__module.h.8.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.142, %71), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.8/__module.h.8.attn
    %74 : int = aten::Int(%73), scope: __module.h.8/__module.h.8.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.142, %78), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.8/__module.h.8.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.8/__module.h.8.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.8/__module.h.8.attn
    %x.143 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.142, %85), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.8/__module.h.8.attn
    %v.9 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.143, %91), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:213:0
    %w.33 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.9, %k.9), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:180:0
    %w.34 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.33, %97), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.34, %99), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.8/__module.h.8.attn
    %102 : int = aten::Int(%101), scope: __module.h.8/__module.h.8.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.34, %103), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.8/__module.h.8.attn
    %106 : int = aten::Int(%105), scope: __module.h.8/__module.h.8.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %b.9 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.34, %b.9), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.9, %126, %127), scope: __module.h.8/__module.h.8.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:184:0
    %w.35 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:188:0
    %input.52 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.35, %attention_mask, %133), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.8/__module.h.8.attn
    %input.53 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.52, %135, %136), scope: __module.h.8/__module.h.8.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.53)
    %x.144 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.9), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.8/__module.h.8.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.144, %144), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:203:0
    %x.145 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.145, %148), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.8/__module.h.8.attn
    %151 : int = aten::Int(%150), scope: __module.h.8/__module.h.8.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.145, %152), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.8/__module.h.8.attn
    %155 : int = aten::Int(%154), scope: __module.h.8/__module.h.8.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.145, %162), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.8/__module.h.8.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.145, %165), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.8/__module.h.8.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.8/__module.h.8.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.8/__module.h.8.attn
    %x.146 : Float(17:9984, 13:768, 768:1) = aten::view(%x.145, %170), scope: __module.h.8/__module.h.8.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.146)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.107 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.55 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.107)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.107)
    %4 : int = prim::Constant[value=768](), scope: __module.h.8/__module.h.8.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.8/__module.h.8.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.8/__module.h.8.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.ln_1 # torch/nn/functional.py:2048:0
    %x.148 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.55, %5, %3, %2, %6, %7), scope: __module.h.8/__module.h.8.ln_1 # torch/nn/functional.py:2048:0
    return (%x.148)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.112 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.57 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.112)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.112)
    %4 : int = prim::Constant[value=768](), scope: __module.h.8/__module.h.8.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.8/__module.h.8.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.8/__module.h.8.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.ln_2 # torch/nn/functional.py:2048:0
    %x.153 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.57, %5, %3, %2, %6, %7), scope: __module.h.8/__module.h.8.ln_2 # torch/nn/functional.py:2048:0
    return (%x.153)

Block.mlp
MLP._actual_script_module
  graph(%self.108 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.108)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.108)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.108)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %x.151 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.8/__module.h.8.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.151)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.104 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.53 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.36 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.53, %2, %3), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.36)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.103 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.103)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.103)
    %4 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.137 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.137, %26), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.105 : __torch__.transformers.modeling_utils.Conv1D,
        %x.146 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.105)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.105)
    %4 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.146, %4), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.146, %8), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.146, %15), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.146, %20), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.147 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj
    %input.54 : Float(17:9984, 13:768, 768:1) = aten::view(%x.147, %26), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.54)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.106 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.9 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.8/__module.h.8.attn/__module.h.8.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.9)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.109 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.109)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.109)
    %4 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.149 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc
    %x.150 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.149, %26), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.150)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.110 : __torch__.transformers.modeling_utils.Conv1D,
        %x.151 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.110)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.110)
    %4 : int = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.151, %4), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.151, %8), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.151, %15), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.151, %20), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.152 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj
    %input.56 : Float(17:9984, 13:768, 768:1) = aten::view(%x.152, %26), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.56)

MLP.dropout
Dropout._actual_script_module
  graph(%self.111 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.dropout # torch/nn/functional.py:973:0
    %m.9 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.8/__module.h.8.mlp/__module.h.8.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.9)

Block._actual_script_module
  graph(%self.113 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.113)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.113)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.113)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.113)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.9 # transformers/modeling_openai.py:266:0
    %input.61 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.9 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.61)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.9 # transformers/modeling_openai.py:268:0
    %input.63 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.9 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.63)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.114 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.114)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.114)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.114)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.114)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.114)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:371:0
    %x.155 : Float(17:29952, 13:2304, 768:1), %x.157 : Float(17:29952, 13:2304, 768:1), %x.159 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.9/__module.h.9.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.155, %15), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.9/__module.h.9.attn
    %18 : int = aten::Int(%17), scope: __module.h.9/__module.h.9.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.155, %19), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.9/__module.h.9.attn
    %22 : int = aten::Int(%21), scope: __module.h.9/__module.h.9.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.155, %26), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.9/__module.h.9.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.9/__module.h.9.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.9/__module.h.9.attn
    %x.156 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.155, %33), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.9/__module.h.9.attn
    %q.10 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.156, %39), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.157, %41), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.9/__module.h.9.attn
    %44 : int = aten::Int(%43), scope: __module.h.9/__module.h.9.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.157, %45), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.9/__module.h.9.attn
    %48 : int = aten::Int(%47), scope: __module.h.9/__module.h.9.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.157, %52), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.9/__module.h.9.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.9/__module.h.9.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.9/__module.h.9.attn
    %x.158 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.157, %59), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.9/__module.h.9.attn
    %k.10 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.158, %65), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.159, %67), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.9/__module.h.9.attn
    %70 : int = aten::Int(%69), scope: __module.h.9/__module.h.9.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.159, %71), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.9/__module.h.9.attn
    %74 : int = aten::Int(%73), scope: __module.h.9/__module.h.9.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.159, %78), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.9/__module.h.9.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.9/__module.h.9.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.9/__module.h.9.attn
    %x.160 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.159, %85), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.9/__module.h.9.attn
    %v.10 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.160, %91), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:213:0
    %w.37 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.10, %k.10), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:180:0
    %w.38 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.37, %97), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.38, %99), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.9/__module.h.9.attn
    %102 : int = aten::Int(%101), scope: __module.h.9/__module.h.9.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.38, %103), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.9/__module.h.9.attn
    %106 : int = aten::Int(%105), scope: __module.h.9/__module.h.9.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %b.10 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.38, %b.10), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.10, %126, %127), scope: __module.h.9/__module.h.9.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:184:0
    %w.39 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:188:0
    %input.58 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.39, %attention_mask, %133), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.9/__module.h.9.attn
    %input.59 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.58, %135, %136), scope: __module.h.9/__module.h.9.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.59)
    %x.161 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.10), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.9/__module.h.9.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.161, %144), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:203:0
    %x.162 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.162, %148), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.9/__module.h.9.attn
    %151 : int = aten::Int(%150), scope: __module.h.9/__module.h.9.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.162, %152), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.9/__module.h.9.attn
    %155 : int = aten::Int(%154), scope: __module.h.9/__module.h.9.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.162, %162), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.9/__module.h.9.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.162, %165), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.9/__module.h.9.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.9/__module.h.9.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.9/__module.h.9.attn
    %x.163 : Float(17:9984, 13:768, 768:1) = aten::view(%x.162, %170), scope: __module.h.9/__module.h.9.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.163)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.119 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.61 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.119)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.119)
    %4 : int = prim::Constant[value=768](), scope: __module.h.9/__module.h.9.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.9/__module.h.9.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.9/__module.h.9.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.ln_1 # torch/nn/functional.py:2048:0
    %x.165 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.61, %5, %3, %2, %6, %7), scope: __module.h.9/__module.h.9.ln_1 # torch/nn/functional.py:2048:0
    return (%x.165)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.124 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.63 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.124)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.124)
    %4 : int = prim::Constant[value=768](), scope: __module.h.9/__module.h.9.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.9/__module.h.9.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.9/__module.h.9.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.ln_2 # torch/nn/functional.py:2048:0
    %x.170 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.63, %5, %3, %2, %6, %7), scope: __module.h.9/__module.h.9.ln_2 # torch/nn/functional.py:2048:0
    return (%x.170)

Block.mlp
MLP._actual_script_module
  graph(%self.120 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.120)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.120)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.120)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %x.168 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.9/__module.h.9.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.168)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.116 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.59 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.40 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.59, %2, %3), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.40)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.115 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.115)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.115)
    %4 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.154 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.154, %26), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.117 : __torch__.transformers.modeling_utils.Conv1D,
        %x.163 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.117)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.117)
    %4 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.163, %4), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.163, %8), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.163, %15), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.163, %20), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.164 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj
    %input.60 : Float(17:9984, 13:768, 768:1) = aten::view(%x.164, %26), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.60)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.118 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.10 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.9/__module.h.9.attn/__module.h.9.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.10)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.121 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.121)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.121)
    %4 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.166 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc
    %x.167 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.166, %26), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.167)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.122 : __torch__.transformers.modeling_utils.Conv1D,
        %x.168 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.122)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.122)
    %4 : int = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.168, %4), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.168, %8), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.168, %15), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.168, %20), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.169 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj
    %input.62 : Float(17:9984, 13:768, 768:1) = aten::view(%x.169, %26), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.62)

MLP.dropout
Dropout._actual_script_module
  graph(%self.123 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.dropout # torch/nn/functional.py:973:0
    %m.10 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.9/__module.h.9.mlp/__module.h.9.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.10)

Block._actual_script_module
  graph(%self.125 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.125)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.125)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.125)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.125)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.10 # transformers/modeling_openai.py:266:0
    %input.67 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.10 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.67)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.10 # transformers/modeling_openai.py:268:0
    %input.69 : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.10 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input.69)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.126 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.126)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.126)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.126)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.126)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.126)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:371:0
    %x.172 : Float(17:29952, 13:2304, 768:1), %x.174 : Float(17:29952, 13:2304, 768:1), %x.176 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.10/__module.h.10.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.172, %15), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.10/__module.h.10.attn
    %18 : int = aten::Int(%17), scope: __module.h.10/__module.h.10.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.172, %19), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.10/__module.h.10.attn
    %22 : int = aten::Int(%21), scope: __module.h.10/__module.h.10.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.172, %26), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.10/__module.h.10.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.10/__module.h.10.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.10/__module.h.10.attn
    %x.173 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.172, %33), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.10/__module.h.10.attn
    %q.11 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.173, %39), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.174, %41), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.10/__module.h.10.attn
    %44 : int = aten::Int(%43), scope: __module.h.10/__module.h.10.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.174, %45), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.10/__module.h.10.attn
    %48 : int = aten::Int(%47), scope: __module.h.10/__module.h.10.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.174, %52), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.10/__module.h.10.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.10/__module.h.10.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.10/__module.h.10.attn
    %x.175 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.174, %59), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.10/__module.h.10.attn
    %k.11 : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.175, %65), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.176, %67), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.10/__module.h.10.attn
    %70 : int = aten::Int(%69), scope: __module.h.10/__module.h.10.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.176, %71), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.10/__module.h.10.attn
    %74 : int = aten::Int(%73), scope: __module.h.10/__module.h.10.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.176, %78), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.10/__module.h.10.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.10/__module.h.10.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.10/__module.h.10.attn
    %x.177 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.176, %85), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.10/__module.h.10.attn
    %v.11 : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.177, %91), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:213:0
    %w.41 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q.11, %k.11), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:180:0
    %w.42 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.41, %97), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.42, %99), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.10/__module.h.10.attn
    %102 : int = aten::Int(%101), scope: __module.h.10/__module.h.10.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.42, %103), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.10/__module.h.10.attn
    %106 : int = aten::Int(%105), scope: __module.h.10/__module.h.10.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %b.11 : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.42, %b.11), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b.11, %126, %127), scope: __module.h.10/__module.h.10.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:184:0
    %w.43 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:188:0
    %input.64 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.43, %attention_mask, %133), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.10/__module.h.10.attn
    %input.65 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.64, %135, %136), scope: __module.h.10/__module.h.10.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.65)
    %x.178 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v.11), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.10/__module.h.10.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.178, %144), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:203:0
    %x.179 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.179, %148), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.10/__module.h.10.attn
    %151 : int = aten::Int(%150), scope: __module.h.10/__module.h.10.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.179, %152), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.10/__module.h.10.attn
    %155 : int = aten::Int(%154), scope: __module.h.10/__module.h.10.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.179, %162), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.10/__module.h.10.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.179, %165), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.10/__module.h.10.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.10/__module.h.10.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.10/__module.h.10.attn
    %x.180 : Float(17:9984, 13:768, 768:1) = aten::view(%x.179, %170), scope: __module.h.10/__module.h.10.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.180)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.131 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.67 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.131)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.131)
    %4 : int = prim::Constant[value=768](), scope: __module.h.10/__module.h.10.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.10/__module.h.10.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.10/__module.h.10.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.ln_1 # torch/nn/functional.py:2048:0
    %x.182 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.67, %5, %3, %2, %6, %7), scope: __module.h.10/__module.h.10.ln_1 # torch/nn/functional.py:2048:0
    return (%x.182)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self.136 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.69 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.136)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.136)
    %4 : int = prim::Constant[value=768](), scope: __module.h.10/__module.h.10.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.10/__module.h.10.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.10/__module.h.10.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.ln_2 # torch/nn/functional.py:2048:0
    %x.187 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.69, %5, %3, %2, %6, %7), scope: __module.h.10/__module.h.10.ln_2 # torch/nn/functional.py:2048:0
    return (%x.187)

Block.mlp
MLP._actual_script_module
  graph(%self.132 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.132)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.132)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.132)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %x.185 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.10/__module.h.10.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.185)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.128 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.65 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.attn_dropout # torch/nn/functional.py:973:0
    %w.44 : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.65, %2, %3), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w.44)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.127 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.127)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.127)
    %4 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.171 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.171, %26), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.129 : __torch__.transformers.modeling_utils.Conv1D,
        %x.180 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.129)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.129)
    %4 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.180, %4), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.180, %8), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.180, %15), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.180, %20), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.181 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj
    %input.66 : Float(17:9984, 13:768, 768:1) = aten::view(%x.181, %26), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.66)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.130 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.resid_dropout # torch/nn/functional.py:973:0
    %a.11 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.10/__module.h.10.attn/__module.h.10.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a.11)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.133 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.133)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.133)
    %4 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.183 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc
    %x.184 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.183, %26), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.184)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.134 : __torch__.transformers.modeling_utils.Conv1D,
        %x.185 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.134)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.134)
    %4 : int = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.185, %4), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.185, %8), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.185, %15), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.185, %20), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x.186 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj
    %input.68 : Float(17:9984, 13:768, 768:1) = aten::view(%x.186, %26), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.68)

MLP.dropout
Dropout._actual_script_module
  graph(%self.135 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.dropout # torch/nn/functional.py:973:0
    %m.11 : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.10/__module.h.10.mlp/__module.h.10.mlp.dropout # torch/nn/functional.py:973:0
    return (%m.11)

Block._actual_script_module
  graph(%self.137 : __torch__.transformers.modeling_openai.Block,
        %6 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %1 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_2"](%self.137)
    %2 : __torch__.transformers.modeling_openai.MLP = prim::GetAttr[name="mlp"](%self.137)
    %3 : __torch__.torch.nn.modules.normalization.LayerNorm = prim::GetAttr[name="ln_1"](%self.137)
    %4 : __torch__.transformers.modeling_openai.Attention = prim::GetAttr[name="attn"](%self.137)
    %15 : Tensor = prim::CallMethod[name="forward"](%4, %6, %attention_mask)
    %8 : int = prim::Constant[value=1](), scope: __module.h.11 # transformers/modeling_openai.py:266:0
    %input.73 : Float(17:9984, 13:768, 768:1) = aten::add(%6, %15, %8), scope: __module.h.11 # transformers/modeling_openai.py:266:0
    %16 : Tensor = prim::CallMethod[name="forward"](%3, %input.73)
    %17 : Tensor = prim::CallMethod[name="forward"](%2, %16)
    %12 : int = prim::Constant[value=1](), scope: __module.h.11 # transformers/modeling_openai.py:268:0
    %input : Float(17:9984, 13:768, 768:1) = aten::add(%16, %17, %12), scope: __module.h.11 # transformers/modeling_openai.py:268:0
    %18 : Tensor = prim::CallMethod[name="forward"](%1, %input)
    return (%18)

Block.attn
Attention._actual_script_module
  graph(%self.138 : __torch__.transformers.modeling_openai.Attention,
        %1 : Float(17:9984, 13:768, 768:1),
        %attention_mask : Float(17:13, 1:13, 1:13, 13:1)):
    %3 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="resid_dropout"](%self.138)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.138)
    %5 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="attn_dropout"](%self.138)
    %6 : Tensor = prim::GetAttr[name="bias"](%self.138)
    %7 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_attn"](%self.138)
    %174 : Tensor = prim::CallMethod[name="forward"](%7, %1)
    %9 : int = prim::Constant[value=768](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:371:0
    %10 : int = prim::Constant[value=2](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:371:0
    %11 : Tensor[] = aten::split(%174, %9, %10), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:371:0
    %x.189 : Float(17:29952, 13:2304, 768:1), %x.191 : Float(17:29952, 13:2304, 768:1), %x.193 : Float(17:29952, 13:2304, 768:1) = prim::ListUnpack(%11), scope: __module.h.11/__module.h.11.attn
    %15 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %16 : int = aten::size(%x.189, %15), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.11/__module.h.11.attn
    %18 : int = aten::Int(%17), scope: __module.h.11/__module.h.11.attn
    %19 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %20 : int = aten::size(%x.189, %19), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %21 : Long() = prim::NumToTensor(%20), scope: __module.h.11/__module.h.11.attn
    %22 : int = aten::Int(%21), scope: __module.h.11/__module.h.11.attn
    %26 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %27 : int = aten::size(%x.189, %26), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %28 : Long() = prim::NumToTensor(%27), scope: __module.h.11/__module.h.11.attn
    %29 : Long() = prim::Constant[value={12}](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
    %30 : Long() = aten::floor_divide(%28, %29), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
    %31 : int = aten::Int(%30), scope: __module.h.11/__module.h.11.attn
    %32 : int = prim::Constant[value=12](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
    %33 : int[] = prim::ListConstruct(%18, %22, %32, %31), scope: __module.h.11/__module.h.11.attn
    %x.190 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.189, %33), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
    %35 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %36 : int = prim::Constant[value=2](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %37 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %38 : int = prim::Constant[value=3](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %39 : int[] = prim::ListConstruct(%35, %36, %37, %38), scope: __module.h.11/__module.h.11.attn
    %q : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.190, %39), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %41 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %42 : int = aten::size(%x.191, %41), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %43 : Long() = prim::NumToTensor(%42), scope: __module.h.11/__module.h.11.attn
    %44 : int = aten::Int(%43), scope: __module.h.11/__module.h.11.attn
    %45 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %46 : int = aten::size(%x.191, %45), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %47 : Long() = prim::NumToTensor(%46), scope: __module.h.11/__module.h.11.attn
    %48 : int = aten::Int(%47), scope: __module.h.11/__module.h.11.attn
    %52 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %53 : int = aten::size(%x.191, %52), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %54 : Long() = prim::NumToTensor(%53), scope: __module.h.11/__module.h.11.attn
    %55 : Long() = prim::Constant[value={12}](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
    %56 : Long() = aten::floor_divide(%54, %55), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
    %57 : int = aten::Int(%56), scope: __module.h.11/__module.h.11.attn
    %58 : int = prim::Constant[value=12](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
    %59 : int[] = prim::ListConstruct(%44, %48, %58, %57), scope: __module.h.11/__module.h.11.attn
    %x.192 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.191, %59), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
    %61 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:211:0
    %62 : int = prim::Constant[value=2](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:211:0
    %63 : int = prim::Constant[value=3](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:211:0
    %64 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:211:0
    %65 : int[] = prim::ListConstruct(%61, %62, %63, %64), scope: __module.h.11/__module.h.11.attn
    %k : Float(17:29952, 12:64, 64:1, 13:2304) = aten::permute(%x.192, %65), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:211:0
    %67 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %68 : int = aten::size(%x.193, %67), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %69 : Long() = prim::NumToTensor(%68), scope: __module.h.11/__module.h.11.attn
    %70 : int = aten::Int(%69), scope: __module.h.11/__module.h.11.attn
    %71 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %72 : int = aten::size(%x.193, %71), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %73 : Long() = prim::NumToTensor(%72), scope: __module.h.11/__module.h.11.attn
    %74 : int = aten::Int(%73), scope: __module.h.11/__module.h.11.attn
    %78 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %79 : int = aten::size(%x.193, %78), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:208:0
    %80 : Long() = prim::NumToTensor(%79), scope: __module.h.11/__module.h.11.attn
    %81 : Long() = prim::Constant[value={12}](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
    %82 : Long() = aten::floor_divide(%80, %81), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:424:0
    %83 : int = aten::Int(%82), scope: __module.h.11/__module.h.11.attn
    %84 : int = prim::Constant[value=12](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
    %85 : int[] = prim::ListConstruct(%70, %74, %84, %83), scope: __module.h.11/__module.h.11.attn
    %x.194 : Float(17:29952, 13:2304, 12:64, 64:1) = aten::view(%x.193, %85), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:209:0
    %87 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %88 : int = prim::Constant[value=2](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %89 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %90 : int = prim::Constant[value=3](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %91 : int[] = prim::ListConstruct(%87, %88, %89, %90), scope: __module.h.11/__module.h.11.attn
    %v : Float(17:29952, 12:64, 13:2304, 64:1) = aten::permute(%x.194, %91), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:213:0
    %w.45 : Float(17:2028, 12:169, 13:13, 13:1) = aten::matmul(%q, %k), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:178:0
    %97 : Double() = prim::Constant[value={8}](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:180:0
    %w.46 : Float(17:2028, 12:169, 13:13, 13:1) = aten::div(%w.45, %97), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:180:0
    %99 : int = prim::Constant[value=-2](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %100 : int = aten::size(%w.46, %99), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %101 : Long() = prim::NumToTensor(%100), scope: __module.h.11/__module.h.11.attn
    %102 : int = aten::Int(%101), scope: __module.h.11/__module.h.11.attn
    %103 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %104 : int = aten::size(%w.46, %103), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %105 : Long() = prim::NumToTensor(%104), scope: __module.h.11/__module.h.11.attn
    %106 : int = aten::Int(%105), scope: __module.h.11/__module.h.11.attn
    %107 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %108 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %109 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %110 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %111 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%6, %107, %108, %109, %110), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %112 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %113 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %114 : int = prim::Constant[value=9223372036854775807](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %115 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %116 : Float(1:262144, 1:262144, 512:512, 512:1) = aten::slice(%111, %112, %113, %114, %115), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %117 : int = prim::Constant[value=2](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %118 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %119 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %120 : Float(1:262144, 1:262144, 13:512, 512:1) = aten::slice(%116, %117, %118, %102, %119), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %121 : int = prim::Constant[value=3](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %122 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %123 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %b : Float(1:262144, 1:262144, 13:512, 13:1) = aten::slice(%120, %121, %122, %106, %123), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:183:0
    %125 : Float(17:2028, 12:169, 13:13, 13:1) = aten::mul(%w.46, %b), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:184:0
    %126 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:396:0
    %127 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:396:0
    %128 : Float(1:169, 1:169, 13:13, 13:1) = aten::rsub(%b, %126, %127), scope: __module.h.11/__module.h.11.attn # torch/tensor.py:396:0
    %129 : Double() = prim::Constant[value={-10000}](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:184:0
    %130 : Float(1:169, 1:169, 13:13, 13:1) = aten::mul(%128, %129), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:184:0
    %131 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:184:0
    %w.47 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%125, %130, %131), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:184:0
    %133 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:188:0
    %input.70 : Float(17:2028, 12:169, 13:13, 13:1) = aten::add(%w.47, %attention_mask, %133), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:188:0
    %135 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn # torch/nn/functional.py:1498:0
    %136 : None = prim::Constant(), scope: __module.h.11/__module.h.11.attn
    %input.71 : Float(17:2028, 12:169, 13:13, 13:1) = aten::softmax(%input.70, %135, %136), scope: __module.h.11/__module.h.11.attn # torch/nn/functional.py:1498:0
    %175 : Tensor = prim::CallMethod[name="forward"](%5, %input.71)
    %x.195 : Float(17:9984, 12:832, 13:64, 64:1) = aten::matmul(%175, %v), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:197:0
    %140 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:203:0
    %141 : int = prim::Constant[value=2](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:203:0
    %142 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:203:0
    %143 : int = prim::Constant[value=3](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:203:0
    %144 : int[] = prim::ListConstruct(%140, %141, %142, %143), scope: __module.h.11/__module.h.11.attn
    %145 : Float(17:9984, 13:64, 12:832, 64:1) = aten::permute(%x.195, %144), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:203:0
    %146 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:203:0
    %x.196 : Float(17:9984, 13:768, 12:64, 64:1) = aten::contiguous(%145, %146), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:203:0
    %148 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
    %149 : int = aten::size(%x.196, %148), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
    %150 : Long() = prim::NumToTensor(%149), scope: __module.h.11/__module.h.11.attn
    %151 : int = aten::Int(%150), scope: __module.h.11/__module.h.11.attn
    %152 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
    %153 : int = aten::size(%x.196, %152), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
    %154 : Long() = prim::NumToTensor(%153), scope: __module.h.11/__module.h.11.attn
    %155 : int = aten::Int(%154), scope: __module.h.11/__module.h.11.attn
    %162 : int = prim::Constant[value=-2](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
    %163 : int = aten::size(%x.196, %162), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
    %164 : Long() = prim::NumToTensor(%163), scope: __module.h.11/__module.h.11.attn
    %165 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
    %166 : int = aten::size(%x.196, %165), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
    %167 : Long() = prim::NumToTensor(%166), scope: __module.h.11/__module.h.11.attn
    %168 : Long() = aten::mul(%164, %167), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:204:0
    %169 : int = aten::Int(%168), scope: __module.h.11/__module.h.11.attn
    %170 : int[] = prim::ListConstruct(%151, %155, %169), scope: __module.h.11/__module.h.11.attn
    %x.197 : Float(17:9984, 13:768, 768:1) = aten::view(%x.196, %170), scope: __module.h.11/__module.h.11.attn # transformers/modeling_openai.py:205:0
    %176 : Tensor = prim::CallMethod[name="forward"](%4, %x.197)
    %177 : Tensor = prim::CallMethod[name="forward"](%3, %176)
    return (%177)

Block.ln_1
LayerNorm._actual_script_module
  graph(%self.143 : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input.73 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self.143)
    %3 : Tensor = prim::GetAttr[name="weight"](%self.143)
    %4 : int = prim::Constant[value=768](), scope: __module.h.11/__module.h.11.ln_1 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.11/__module.h.11.ln_1
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.11/__module.h.11.ln_1 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.ln_1 # torch/nn/functional.py:2048:0
    %x.199 : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input.73, %5, %3, %2, %6, %7), scope: __module.h.11/__module.h.11.ln_1 # torch/nn/functional.py:2048:0
    return (%x.199)

Block.ln_2
LayerNorm._actual_script_module
  graph(%self : __torch__.torch.nn.modules.normalization.LayerNorm,
        %input : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="bias"](%self)
    %3 : Tensor = prim::GetAttr[name="weight"](%self)
    %4 : int = prim::Constant[value=768](), scope: __module.h.11/__module.h.11.ln_2 # torch/nn/functional.py:2048:0
    %5 : int[] = prim::ListConstruct(%4), scope: __module.h.11/__module.h.11.ln_2
    %6 : float = prim::Constant[value=1.0000000000000001e-05](), scope: __module.h.11/__module.h.11.ln_2 # torch/nn/functional.py:2048:0
    %7 : bool = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.ln_2 # torch/nn/functional.py:2048:0
    %hidden_states : Float(17:9984, 13:768, 768:1) = aten::layer_norm(%input, %5, %3, %2, %6, %7), scope: __module.h.11/__module.h.11.ln_2 # torch/nn/functional.py:2048:0
    return (%hidden_states)

Block.mlp
MLP._actual_script_module
  graph(%self.144 : __torch__.transformers.modeling_openai.MLP,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : __torch__.torch.nn.modules.dropout.Dropout = prim::GetAttr[name="dropout"](%self.144)
    %3 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_proj"](%self.144)
    %4 : __torch__.transformers.modeling_utils.Conv1D = prim::GetAttr[name="c_fc"](%self.144)
    %23 : Tensor = prim::CallMethod[name="forward"](%4, %1)
    %6 : Double() = prim::Constant[value={0.5}](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %7 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%23, %6), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %8 : float = prim::Constant[value=3.](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %9 : Float(17:39936, 13:3072, 3072:1) = aten::pow(%23, %8), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %10 : Double() = prim::Constant[value={0.044715}](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %11 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%9, %10), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %12 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %13 : Float(17:39936, 13:3072, 3072:1) = aten::add(%23, %11, %12), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %14 : Double() = prim::Constant[value={0.797885}](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %15 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%13, %14), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %16 : Float(17:39936, 13:3072, 3072:1) = aten::tanh(%15), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %17 : Double() = prim::Constant[value={1}](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %18 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %19 : Float(17:39936, 13:3072, 3072:1) = aten::add(%16, %17, %18), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %x.202 : Float(17:39936, 13:3072, 3072:1) = aten::mul(%7, %19), scope: __module.h.11/__module.h.11.mlp # transformers/activations.py:30:0
    %24 : Tensor = prim::CallMethod[name="forward"](%3, %x.202)
    %25 : Tensor = prim::CallMethod[name="forward"](%2, %24)
    return (%25)

Attention.attn_dropout
Dropout._actual_script_module
  graph(%self.140 : __torch__.torch.nn.modules.dropout.Dropout,
        %input.71 : Float(17:2028, 12:169, 13:13, 13:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.attn_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.attn_dropout # torch/nn/functional.py:973:0
    %w : Float(17:2028, 12:169, 13:13, 13:1) = aten::dropout(%input.71, %2, %3), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.attn_dropout # torch/nn/functional.py:973:0
    return (%w)

Attention.c_attn
Conv1D._actual_script_module
  graph(%self.139 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.139)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.139)
    %4 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
    %7 : int = aten::Int(%6), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
    %8 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
    %11 : int = aten::Int(%10), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
    %15 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
    %18 : int = aten::Int(%17), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
    %19 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
    %x.188 : Float(221:2304, 2304:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=2304](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn
    %27 : Float(17:29952, 13:2304, 2304:1) = aten::view(%x.188, %26), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_attn # transformers/modeling_utils.py:1095:0
    return (%27)

Attention.c_proj
Conv1D._actual_script_module
  graph(%self.141 : __torch__.transformers.modeling_utils.Conv1D,
        %x.197 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.141)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.141)
    %4 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.197, %4), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.197, %8), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.197, %15), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
    %21 : Float(221:768, 768:1) = aten::view(%x.197, %20), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
    %x.198 : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj
    %input.72 : Float(17:9984, 13:768, 768:1) = aten::view(%x.198, %26), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.72)

Attention.resid_dropout
Dropout._actual_script_module
  graph(%self.142 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.resid_dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.resid_dropout # torch/nn/functional.py:973:0
    %a : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.11/__module.h.11.attn/__module.h.11.attn.resid_dropout # torch/nn/functional.py:973:0
    return (%a)

MLP.c_fc
Conv1D._actual_script_module
  graph(%self.145 : __torch__.transformers.modeling_utils.Conv1D,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.145)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.145)
    %4 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%1, %4), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
    %7 : int = aten::Int(%6), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
    %8 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%1, %8), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
    %11 : int = aten::Int(%10), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
    %15 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%1, %15), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
    %18 : int = aten::Int(%17), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
    %19 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
    %21 : Float(221:768, 768:1) = aten::view(%1, %20), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %x.200 : Float(221:3072, 3072:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=3072](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc
    %x.201 : Float(17:39936, 13:3072, 3072:1) = aten::view(%x.200, %26), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_fc # transformers/modeling_utils.py:1095:0
    return (%x.201)

MLP.c_proj
Conv1D._actual_script_module
  graph(%self.146 : __torch__.transformers.modeling_utils.Conv1D,
        %x.202 : Float(17:39936, 13:3072, 3072:1)):
    %2 : Tensor = prim::GetAttr[name="weight"](%self.146)
    %3 : Tensor = prim::GetAttr[name="bias"](%self.146)
    %4 : int = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %5 : int = aten::size(%x.202, %4), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %6 : Long() = prim::NumToTensor(%5), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
    %7 : int = aten::Int(%6), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
    %8 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %9 : int = aten::size(%x.202, %8), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1093:0
    %10 : Long() = prim::NumToTensor(%9), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
    %11 : int = aten::Int(%10), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
    %15 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %16 : int = aten::size(%x.202, %15), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %17 : Long() = prim::NumToTensor(%16), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
    %18 : int = aten::Int(%17), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
    %19 : int = prim::Constant[value=-1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %20 : int[] = prim::ListConstruct(%19, %18), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
    %21 : Float(221:3072, 3072:1) = aten::view(%x.202, %20), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %22 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %23 : int = prim::Constant[value=1](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %x : Float(221:768, 768:1) = aten::addmm(%3, %21, %2, %22, %23), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1094:0
    %25 : int = prim::Constant[value=768](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1095:0
    %26 : int[] = prim::ListConstruct(%7, %11, %25), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj
    %input.74 : Float(17:9984, 13:768, 768:1) = aten::view(%x, %26), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.c_proj # transformers/modeling_utils.py:1095:0
    return (%input.74)

MLP.dropout
Dropout._actual_script_module
  graph(%self.147 : __torch__.torch.nn.modules.dropout.Dropout,
        %1 : Float(17:9984, 13:768, 768:1)):
    %2 : float = prim::Constant[value=0.10000000000000001](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.dropout # torch/nn/functional.py:973:0
    %3 : bool = prim::Constant[value=0](), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.dropout # torch/nn/functional.py:973:0
    %m : Float(17:9984, 13:768, 768:1) = aten::dropout(%1, %2, %3), scope: __module.h.11/__module.h.11.mlp/__module.h.11.mlp.dropout # torch/nn/functional.py:973:0
    return (%m)

