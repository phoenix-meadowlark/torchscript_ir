graph(%self.1 : __torch__.transformers.modeling_mobilebert.MobileBertForPreTraining,
      %input_ids : Long(17:13, 13:1),
      %attention_mask.1 : Long(17:13, 13:1)):
  %3 : __torch__.transformers.modeling_mobilebert.MobileBertPreTrainingHeads = prim::GetAttr[name="cls"](%self.1)
  %4 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18884.MobileBertModel = prim::GetAttr[name="mobilebert"](%self.1)
  %12 : int = prim::Constant[value=128](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %13 : float = prim::Constant[value=0.10000000000000001](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %14 : Double() = prim::Constant[value={5.65685}](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %15 : int = prim::Constant[value=-2](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %16 : int = prim::Constant[value=32](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %17 : int = prim::Constant[value=-1](), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %18 : float = prim::Constant[value=0.](), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %19 : Double() = prim::Constant[value={-10000}](), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %20 : float = prim::Constant[value=1.](), scope: __module.mobilebert # torch/tensor.py:396:0
  %21 : None = prim::Constant(), scope: __module.mobilebert
  %22 : int = prim::Constant[value=6](), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %23 : int = prim::Constant[value=3](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %24 : int = prim::Constant[value=2](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %25 : int = prim::Constant[value=9223372036854775807](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %26 : bool = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %27 : Device = prim::Constant[value="cpu"](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %28 : int = prim::Constant[value=4](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %29 : int = prim::Constant[value=1](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %30 : int = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %31 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18883.MobileBertPooler = prim::GetAttr[name="pooler"](%4)
  %32 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18881.MobileBertEncoder = prim::GetAttr[name="encoder"](%4)
  %33 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17799.MobileBertEmbeddings = prim::GetAttr[name="embeddings"](%4)
  %34 : int = aten::size(%input_ids, %30), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %35 : int = aten::size(%input_ids, %29), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %36 : int[] = prim::ListConstruct(%34, %35), scope: __module.mobilebert
  %input.5 : Long(17:13, 13:1) = aten::zeros(%36, %28, %30, %27, %26), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %38 : Long(17:13, 13:1) = aten::slice(%attention_mask.1, %30, %30, %25, %29), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %39 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%38, %29), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %40 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%39, %24), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %extended_attention_mask : Long(17:13, 1:13, 1:13, 13:1) = aten::slice(%40, %23, %30, %25, %29), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %42 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%extended_attention_mask, %22, %26, %26, %21), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %43 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%42, %20, %29), scope: __module.mobilebert # torch/tensor.py:396:0
  %attention_mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%43, %19), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %45 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17797.NoNorm = prim::GetAttr[name="LayerNorm"](%33)
  %46 : __torch__.torch.nn.modules.sparse.___torch_mangle_17795.Embedding = prim::GetAttr[name="token_type_embeddings"](%33)
  %47 : __torch__.torch.nn.modules.sparse.___torch_mangle_17794.Embedding = prim::GetAttr[name="position_embeddings"](%33)
  %48 : __torch__.torch.nn.modules.linear.___torch_mangle_17796.Linear = prim::GetAttr[name="embedding_transformation"](%33)
  %49 : __torch__.torch.nn.modules.sparse.___torch_mangle_17793.Embedding = prim::GetAttr[name="word_embeddings"](%33)
  %50 : Tensor = prim::GetAttr[name="position_ids"](%33)
  %51 : int = aten::size(%input_ids, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:185:0
  %52 : Long(1:512, 512:1) = aten::slice(%50, %30, %30, %25, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %input.4 : Long(1:512, 13:1) = aten::slice(%52, %29, %30, %51, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %54 : Tensor = prim::GetAttr[name="weight"](%49)
  %inputs_embeds.1 : Float(17:1664, 13:128, 128:1) = aten::embedding(%54, %input_ids, %30, %26, %26), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %56 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %30, %30, %25, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %input.1 : Float(17:1664, 12:128, 128:1) = aten::slice(%56, %29, %29, %25, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %58 : int[] = prim::ListConstruct(%30, %30, %30, %29, %30, %30), scope: __module.mobilebert/__module.mobilebert.embeddings
  %59 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.1, %58, %30), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %60 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %30, %30, %25, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %input.2 : Float(17:1664, 12:128, 128:1) = aten::slice(%60, %29, %30, %17, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %62 : int[] = prim::ListConstruct(%30, %30, %29, %30, %30, %30), scope: __module.mobilebert/__module.mobilebert.embeddings
  %63 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.2, %62, %30), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %64 : Tensor[] = prim::ListConstruct(%59, %inputs_embeds.1, %63), scope: __module.mobilebert/__module.mobilebert.embeddings
  %input.3 : Float(17:4992, 13:384, 384:1) = aten::cat(%64, %24), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:207:0
  %66 : Tensor = prim::GetAttr[name="bias"](%48)
  %67 : Tensor = prim::GetAttr[name="weight"](%48)
  %68 : Float(384:1, 512:384) = aten::t(%67), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %output.1 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.3, %68), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %inputs_embeds : Float(17:6656, 13:512, 512:1) = aten::add_(%output.1, %66, %29), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1678:0
  %71 : Tensor = prim::GetAttr[name="weight"](%47)
  %position_embeddings : Float(1:6656, 13:512, 512:1) = aten::embedding(%71, %input.4, %17, %26, %26), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %73 : Tensor = prim::GetAttr[name="weight"](%46)
  %token_type_embeddings : Float(17:6656, 13:512, 512:1) = aten::embedding(%73, %input.5, %17, %26, %26), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %75 : Float(17:6656, 13:512, 512:1) = aten::add(%inputs_embeds, %position_embeddings, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %input_tensor.1 : Float(17:6656, 13:512, 512:1) = aten::add(%75, %token_type_embeddings, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %77 : Tensor = prim::GetAttr[name="bias"](%45)
  %78 : Tensor = prim::GetAttr[name="weight"](%45)
  %79 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.1, %78), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.6 : Float(17:6656, 13:512, 512:1) = aten::add(%79, %77, %29), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.7 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.6, %18, %26), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %82 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %83 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18879.MobileBertLayer = prim::GetAttr[name="23"](%82)
  %84 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %85 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18834.MobileBertLayer = prim::GetAttr[name="22"](%84)
  %86 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %87 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18789.MobileBertLayer = prim::GetAttr[name="21"](%86)
  %88 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %89 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18744.MobileBertLayer = prim::GetAttr[name="20"](%88)
  %90 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %91 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18699.MobileBertLayer = prim::GetAttr[name="19"](%90)
  %92 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %93 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18654.MobileBertLayer = prim::GetAttr[name="18"](%92)
  %94 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %95 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18609.MobileBertLayer = prim::GetAttr[name="17"](%94)
  %96 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %97 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18564.MobileBertLayer = prim::GetAttr[name="16"](%96)
  %98 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %99 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18519.MobileBertLayer = prim::GetAttr[name="15"](%98)
  %100 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %101 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18474.MobileBertLayer = prim::GetAttr[name="14"](%100)
  %102 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18429.MobileBertLayer = prim::GetAttr[name="13"](%102)
  %104 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18384.MobileBertLayer = prim::GetAttr[name="12"](%104)
  %106 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18339.MobileBertLayer = prim::GetAttr[name="11"](%106)
  %108 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18294.MobileBertLayer = prim::GetAttr[name="10"](%108)
  %110 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18249.MobileBertLayer = prim::GetAttr[name="9"](%110)
  %112 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %113 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18204.MobileBertLayer = prim::GetAttr[name="8"](%112)
  %114 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %115 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18159.MobileBertLayer = prim::GetAttr[name="7"](%114)
  %116 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %117 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18114.MobileBertLayer = prim::GetAttr[name="6"](%116)
  %118 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18069.MobileBertLayer = prim::GetAttr[name="5"](%118)
  %120 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %121 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18024.MobileBertLayer = prim::GetAttr[name="4"](%120)
  %122 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %123 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17979.MobileBertLayer = prim::GetAttr[name="3"](%122)
  %124 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %125 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17934.MobileBertLayer = prim::GetAttr[name="2"](%124)
  %126 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17889.MobileBertLayer = prim::GetAttr[name="1"](%126)
  %128 : __torch__.torch.nn.modules.container.___torch_mangle_18880.ModuleList = prim::GetAttr[name="layer"](%32)
  %129 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17844.MobileBertLayer = prim::GetAttr[name="0"](%128)
  %130 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17817.MobileBertOutput = prim::GetAttr[name="output"](%129)
  %131 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17810.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%129)
  %132 : __torch__.torch.nn.modules.container.___torch_mangle_17843.ModuleList = prim::GetAttr[name="ffn"](%129)
  %133 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17842.FFNLayer = prim::GetAttr[name="2"](%132)
  %134 : __torch__.torch.nn.modules.container.___torch_mangle_17843.ModuleList = prim::GetAttr[name="ffn"](%129)
  %135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17836.FFNLayer = prim::GetAttr[name="1"](%134)
  %136 : __torch__.torch.nn.modules.container.___torch_mangle_17843.ModuleList = prim::GetAttr[name="ffn"](%129)
  %137 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17830.FFNLayer = prim::GetAttr[name="0"](%136)
  %138 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17808.MobileBertAttention = prim::GetAttr[name="attention"](%129)
  %139 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17824.Bottleneck = prim::GetAttr[name="bottleneck"](%129)
  %140 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17823.BottleneckLayer = prim::GetAttr[name="attention"](%139)
  %141 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17820.BottleneckLayer = prim::GetAttr[name="input"](%139)
  %142 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17819.NoNorm = prim::GetAttr[name="LayerNorm"](%141)
  %143 : __torch__.torch.nn.modules.linear.___torch_mangle_17818.Linear = prim::GetAttr[name="dense"](%141)
  %144 : Tensor = prim::GetAttr[name="bias"](%143)
  %145 : Tensor = prim::GetAttr[name="weight"](%143)
  %146 : Float(512:1, 128:512) = aten::t(%145), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.2 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.2, %144, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %149 : Tensor = prim::GetAttr[name="bias"](%142)
  %150 : Tensor = prim::GetAttr[name="weight"](%142)
  %151 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.2, %150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.1 : Float(17:1664, 13:128, 128:1) = aten::add(%151, %149, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %153 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17822.NoNorm = prim::GetAttr[name="LayerNorm"](%140)
  %154 : __torch__.torch.nn.modules.linear.___torch_mangle_17821.Linear = prim::GetAttr[name="dense"](%140)
  %155 : Tensor = prim::GetAttr[name="bias"](%154)
  %156 : Tensor = prim::GetAttr[name="weight"](%154)
  %157 : Float(512:1, 128:512) = aten::t(%156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.3 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %157), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.3, %155, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %160 : Tensor = prim::GetAttr[name="bias"](%153)
  %161 : Tensor = prim::GetAttr[name="weight"](%153)
  %162 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.3, %161), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.8 : Float(17:1664, 13:128, 128:1) = aten::add(%162, %160, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %164 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.8, %residual_tensor.1)
  %165 : Float(17:1664, 13:128, 128:1), %166 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%164)
  %167 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17807.MobileBertSelfOutput = prim::GetAttr[name="output"](%138)
  %168 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17804.MobileBertSelfAttention = prim::GetAttr[name="self"](%138)
  %169 : __torch__.torch.nn.modules.linear.___torch_mangle_17802.Linear = prim::GetAttr[name="value"](%168)
  %170 : __torch__.torch.nn.modules.linear.___torch_mangle_17801.Linear = prim::GetAttr[name="key"](%168)
  %171 : __torch__.torch.nn.modules.linear.___torch_mangle_17800.Linear = prim::GetAttr[name="query"](%168)
  %172 : Tensor = prim::GetAttr[name="bias"](%171)
  %173 : Tensor = prim::GetAttr[name="weight"](%171)
  %174 : Float(128:1, 128:128) = aten::t(%173), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %output.4 : Float(17:1664, 13:128, 128:1) = aten::matmul(%165, %174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %x.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.4, %172, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %177 : Tensor = prim::GetAttr[name="bias"](%170)
  %178 : Tensor = prim::GetAttr[name="weight"](%170)
  %179 : Float(128:1, 128:128) = aten::t(%178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %output.5 : Float(17:1664, 13:128, 128:1) = aten::matmul(%165, %179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %x.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.5, %177, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1678:0
  %182 : Tensor = prim::GetAttr[name="bias"](%169)
  %183 : Tensor = prim::GetAttr[name="weight"](%169)
  %184 : Float(512:1, 128:512) = aten::t(%183), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %output.6 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %x.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.6, %182, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1678:0
  %187 : int = aten::size(%x.1, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %188 : int = aten::size(%x.1, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %189 : int[] = prim::ListConstruct(%187, %188, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.1, %189), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %191 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %query_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.2, %191), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %193 : int = aten::size(%x.3, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %194 : int = aten::size(%x.3, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %195 : int[] = prim::ListConstruct(%193, %194, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.3, %195), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %197 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %key_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.4, %197), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %199 : int = aten::size(%x.5, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %200 : int = aten::size(%x.5, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %201 : int[] = prim::ListConstruct(%199, %200, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.5, %201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %203 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %value_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.6, %203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %205 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.1, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.1, %205), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.1, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.2, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.9, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.10, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.1 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:280:0
  %212 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %213 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.1, %212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%213, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %215 : int = aten::size(%context_layer.2, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %216 : int = aten::size(%context_layer.2, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %217 : int[] = prim::ListConstruct(%215, %216, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %input.11 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.2, %217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %219 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17806.NoNorm = prim::GetAttr[name="LayerNorm"](%167)
  %220 : __torch__.torch.nn.modules.linear.___torch_mangle_17805.Linear = prim::GetAttr[name="dense"](%167)
  %221 : Tensor = prim::GetAttr[name="bias"](%220)
  %222 : Tensor = prim::GetAttr[name="weight"](%220)
  %223 : Float(128:1, 128:128) = aten::t(%222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %output.7 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.11, %223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.7, %221, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.1, %166, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output # transformers/modeling_mobilebert.py:301:0
  %227 : Tensor = prim::GetAttr[name="bias"](%219)
  %228 : Tensor = prim::GetAttr[name="weight"](%219)
  %229 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.4, %228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.12 : Float(17:1664, 13:128, 128:1) = aten::add(%229, %227, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %231 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17829.FFNOutput = prim::GetAttr[name="output"](%137)
  %232 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17826.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%137)
  %233 : __torch__.torch.nn.modules.linear.___torch_mangle_17825.Linear = prim::GetAttr[name="dense"](%232)
  %234 : Tensor = prim::GetAttr[name="bias"](%233)
  %235 : Tensor = prim::GetAttr[name="weight"](%233)
  %236 : Float(128:1, 512:128) = aten::t(%235), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.8 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.12, %236), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.13 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.8, %234, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.14 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %240 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17828.NoNorm = prim::GetAttr[name="LayerNorm"](%231)
  %241 : __torch__.torch.nn.modules.linear.___torch_mangle_17827.Linear = prim::GetAttr[name="dense"](%231)
  %242 : Tensor = prim::GetAttr[name="bias"](%241)
  %243 : Tensor = prim::GetAttr[name="weight"](%241)
  %244 : Float(512:1, 128:512) = aten::t(%243), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.9 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.14, %244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.9, %242, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.2, %input.12, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %248 : Tensor = prim::GetAttr[name="bias"](%240)
  %249 : Tensor = prim::GetAttr[name="weight"](%240)
  %250 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.5, %249), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.15 : Float(17:1664, 13:128, 128:1) = aten::add(%250, %248, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %252 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17835.FFNOutput = prim::GetAttr[name="output"](%135)
  %253 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17832.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%135)
  %254 : __torch__.torch.nn.modules.linear.___torch_mangle_17831.Linear = prim::GetAttr[name="dense"](%253)
  %255 : Tensor = prim::GetAttr[name="bias"](%254)
  %256 : Tensor = prim::GetAttr[name="weight"](%254)
  %257 : Float(128:1, 512:128) = aten::t(%256), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.10 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.15, %257), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.16 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.10, %255, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.17 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %261 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17834.NoNorm = prim::GetAttr[name="LayerNorm"](%252)
  %262 : __torch__.torch.nn.modules.linear.___torch_mangle_17833.Linear = prim::GetAttr[name="dense"](%252)
  %263 : Tensor = prim::GetAttr[name="bias"](%262)
  %264 : Tensor = prim::GetAttr[name="weight"](%262)
  %265 : Float(512:1, 128:512) = aten::t(%264), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.11 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.17, %265), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.11, %263, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.3, %input.15, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %269 : Tensor = prim::GetAttr[name="bias"](%261)
  %270 : Tensor = prim::GetAttr[name="weight"](%261)
  %271 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.6, %270), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.18 : Float(17:1664, 13:128, 128:1) = aten::add(%271, %269, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %273 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17841.FFNOutput = prim::GetAttr[name="output"](%133)
  %274 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17838.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%133)
  %275 : __torch__.torch.nn.modules.linear.___torch_mangle_17837.Linear = prim::GetAttr[name="dense"](%274)
  %276 : Tensor = prim::GetAttr[name="bias"](%275)
  %277 : Tensor = prim::GetAttr[name="weight"](%275)
  %278 : Float(128:1, 512:128) = aten::t(%277), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.12 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.18, %278), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.19 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.12, %276, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.20 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %282 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17840.NoNorm = prim::GetAttr[name="LayerNorm"](%273)
  %283 : __torch__.torch.nn.modules.linear.___torch_mangle_17839.Linear = prim::GetAttr[name="dense"](%273)
  %284 : Tensor = prim::GetAttr[name="bias"](%283)
  %285 : Tensor = prim::GetAttr[name="weight"](%283)
  %286 : Float(512:1, 128:512) = aten::t(%285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.13 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.20, %286), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.13, %284, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.4, %input.18, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %290 : Tensor = prim::GetAttr[name="bias"](%282)
  %291 : Tensor = prim::GetAttr[name="weight"](%282)
  %292 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.7, %291), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.21 : Float(17:1664, 13:128, 128:1) = aten::add(%292, %290, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %294 : __torch__.torch.nn.modules.linear.___torch_mangle_17809.Linear = prim::GetAttr[name="dense"](%131)
  %295 : Tensor = prim::GetAttr[name="bias"](%294)
  %296 : Tensor = prim::GetAttr[name="weight"](%294)
  %297 : Float(128:1, 512:128) = aten::t(%296), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.14 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.21, %297), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.22 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.14, %295, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.23 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate # torch/nn/functional.py:1119:0
  %301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17816.OutputBottleneck = prim::GetAttr[name="bottleneck"](%130)
  %302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17812.NoNorm = prim::GetAttr[name="LayerNorm"](%130)
  %303 : __torch__.torch.nn.modules.linear.___torch_mangle_17811.Linear = prim::GetAttr[name="dense"](%130)
  %304 : Tensor = prim::GetAttr[name="bias"](%303)
  %305 : Tensor = prim::GetAttr[name="weight"](%303)
  %306 : Float(512:1, 128:512) = aten::t(%305), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %output.15 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.23, %306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %layer_output.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.15, %304, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.1, %input.21, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output # transformers/modeling_mobilebert.py:405:0
  %310 : Tensor = prim::GetAttr[name="bias"](%302)
  %311 : Tensor = prim::GetAttr[name="weight"](%302)
  %312 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.8, %311), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.24 : Float(17:1664, 13:128, 128:1) = aten::add(%312, %310, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %314 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17814.NoNorm = prim::GetAttr[name="LayerNorm"](%301)
  %315 : __torch__.torch.nn.modules.linear.___torch_mangle_17813.Linear = prim::GetAttr[name="dense"](%301)
  %316 : Tensor = prim::GetAttr[name="bias"](%315)
  %317 : Tensor = prim::GetAttr[name="weight"](%315)
  %318 : Float(128:1, 512:128) = aten::t(%317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.16 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.24, %318), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.25 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.16, %316, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.5 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.25, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.9 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.5, %input.7, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %323 : Tensor = prim::GetAttr[name="bias"](%314)
  %324 : Tensor = prim::GetAttr[name="weight"](%314)
  %325 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.9, %324), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.26 : Float(17:6656, 13:512, 512:1) = aten::add(%325, %323, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %327 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17862.MobileBertOutput = prim::GetAttr[name="output"](%127)
  %328 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17855.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%127)
  %329 : __torch__.torch.nn.modules.container.___torch_mangle_17888.ModuleList = prim::GetAttr[name="ffn"](%127)
  %330 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17887.FFNLayer = prim::GetAttr[name="2"](%329)
  %331 : __torch__.torch.nn.modules.container.___torch_mangle_17888.ModuleList = prim::GetAttr[name="ffn"](%127)
  %332 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17881.FFNLayer = prim::GetAttr[name="1"](%331)
  %333 : __torch__.torch.nn.modules.container.___torch_mangle_17888.ModuleList = prim::GetAttr[name="ffn"](%127)
  %334 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17875.FFNLayer = prim::GetAttr[name="0"](%333)
  %335 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17853.MobileBertAttention = prim::GetAttr[name="attention"](%127)
  %336 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17869.Bottleneck = prim::GetAttr[name="bottleneck"](%127)
  %337 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17868.BottleneckLayer = prim::GetAttr[name="attention"](%336)
  %338 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17865.BottleneckLayer = prim::GetAttr[name="input"](%336)
  %339 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17864.NoNorm = prim::GetAttr[name="LayerNorm"](%338)
  %340 : __torch__.torch.nn.modules.linear.___torch_mangle_17863.Linear = prim::GetAttr[name="dense"](%338)
  %341 : Tensor = prim::GetAttr[name="bias"](%340)
  %342 : Tensor = prim::GetAttr[name="weight"](%340)
  %343 : Float(512:1, 128:512) = aten::t(%342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.17 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %343), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.17, %341, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %346 : Tensor = prim::GetAttr[name="bias"](%339)
  %347 : Tensor = prim::GetAttr[name="weight"](%339)
  %348 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.10, %347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add(%348, %346, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %350 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17867.NoNorm = prim::GetAttr[name="LayerNorm"](%337)
  %351 : __torch__.torch.nn.modules.linear.___torch_mangle_17866.Linear = prim::GetAttr[name="dense"](%337)
  %352 : Tensor = prim::GetAttr[name="bias"](%351)
  %353 : Tensor = prim::GetAttr[name="weight"](%351)
  %354 : Float(512:1, 128:512) = aten::t(%353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.18 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %354), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.18, %352, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %357 : Tensor = prim::GetAttr[name="bias"](%350)
  %358 : Tensor = prim::GetAttr[name="weight"](%350)
  %359 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.11, %358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.27 : Float(17:1664, 13:128, 128:1) = aten::add(%359, %357, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %361 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.27, %residual_tensor.2)
  %362 : Float(17:1664, 13:128, 128:1), %363 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%361)
  %364 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17852.MobileBertSelfOutput = prim::GetAttr[name="output"](%335)
  %365 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17849.MobileBertSelfAttention = prim::GetAttr[name="self"](%335)
  %366 : __torch__.torch.nn.modules.linear.___torch_mangle_17847.Linear = prim::GetAttr[name="value"](%365)
  %367 : __torch__.torch.nn.modules.linear.___torch_mangle_17846.Linear = prim::GetAttr[name="key"](%365)
  %368 : __torch__.torch.nn.modules.linear.___torch_mangle_17845.Linear = prim::GetAttr[name="query"](%365)
  %369 : Tensor = prim::GetAttr[name="bias"](%368)
  %370 : Tensor = prim::GetAttr[name="weight"](%368)
  %371 : Float(128:1, 128:128) = aten::t(%370), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %output.19 : Float(17:1664, 13:128, 128:1) = aten::matmul(%362, %371), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %x.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.19, %369, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1678:0
  %374 : Tensor = prim::GetAttr[name="bias"](%367)
  %375 : Tensor = prim::GetAttr[name="weight"](%367)
  %376 : Float(128:1, 128:128) = aten::t(%375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %output.20 : Float(17:1664, 13:128, 128:1) = aten::matmul(%362, %376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %x.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.20, %374, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1678:0
  %379 : Tensor = prim::GetAttr[name="bias"](%366)
  %380 : Tensor = prim::GetAttr[name="weight"](%366)
  %381 : Float(512:1, 128:512) = aten::t(%380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %output.21 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %381), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %x.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.21, %379, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1678:0
  %384 : int = aten::size(%x.7, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %385 : int = aten::size(%x.7, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %386 : int[] = prim::ListConstruct(%384, %385, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.7, %386), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %388 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %query_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.8, %388), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %390 : int = aten::size(%x.9, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %391 : int = aten::size(%x.9, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %392 : int[] = prim::ListConstruct(%390, %391, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.9, %392), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %394 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %key_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.10, %394), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %396 : int = aten::size(%x.11, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %397 : int = aten::size(%x.11, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %398 : int[] = prim::ListConstruct(%396, %397, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.11, %398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %400 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %value_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.12, %400), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %402 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.2, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.2, %402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.3, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.4, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.28, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.29, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.3 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.2, %value_layer.2), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:280:0
  %409 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %410 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.3, %409), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%410, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %412 : int = aten::size(%context_layer.4, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %413 : int = aten::size(%context_layer.4, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %414 : int[] = prim::ListConstruct(%412, %413, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %input.30 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.4, %414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:283:0
  %416 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17851.NoNorm = prim::GetAttr[name="LayerNorm"](%364)
  %417 : __torch__.torch.nn.modules.linear.___torch_mangle_17850.Linear = prim::GetAttr[name="dense"](%364)
  %418 : Tensor = prim::GetAttr[name="bias"](%417)
  %419 : Tensor = prim::GetAttr[name="weight"](%417)
  %420 : Float(128:1, 128:128) = aten::t(%419), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %output.22 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.30, %420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.22, %418, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.6, %363, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output # transformers/modeling_mobilebert.py:301:0
  %424 : Tensor = prim::GetAttr[name="bias"](%416)
  %425 : Tensor = prim::GetAttr[name="weight"](%416)
  %426 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.12, %425), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.31 : Float(17:1664, 13:128, 128:1) = aten::add(%426, %424, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %428 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17874.FFNOutput = prim::GetAttr[name="output"](%334)
  %429 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17871.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%334)
  %430 : __torch__.torch.nn.modules.linear.___torch_mangle_17870.Linear = prim::GetAttr[name="dense"](%429)
  %431 : Tensor = prim::GetAttr[name="bias"](%430)
  %432 : Tensor = prim::GetAttr[name="weight"](%430)
  %433 : Float(128:1, 512:128) = aten::t(%432), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.23 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.31, %433), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.32 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.23, %431, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.33 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.32), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %437 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17873.NoNorm = prim::GetAttr[name="LayerNorm"](%428)
  %438 : __torch__.torch.nn.modules.linear.___torch_mangle_17872.Linear = prim::GetAttr[name="dense"](%428)
  %439 : Tensor = prim::GetAttr[name="bias"](%438)
  %440 : Tensor = prim::GetAttr[name="weight"](%438)
  %441 : Float(512:1, 128:512) = aten::t(%440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.24 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.33, %441), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.24, %439, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.7, %input.31, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %445 : Tensor = prim::GetAttr[name="bias"](%437)
  %446 : Tensor = prim::GetAttr[name="weight"](%437)
  %447 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.13, %446), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.34 : Float(17:1664, 13:128, 128:1) = aten::add(%447, %445, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %449 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17880.FFNOutput = prim::GetAttr[name="output"](%332)
  %450 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17877.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%332)
  %451 : __torch__.torch.nn.modules.linear.___torch_mangle_17876.Linear = prim::GetAttr[name="dense"](%450)
  %452 : Tensor = prim::GetAttr[name="bias"](%451)
  %453 : Tensor = prim::GetAttr[name="weight"](%451)
  %454 : Float(128:1, 512:128) = aten::t(%453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.25 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.34, %454), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.35 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.25, %452, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.36 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %458 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17879.NoNorm = prim::GetAttr[name="LayerNorm"](%449)
  %459 : __torch__.torch.nn.modules.linear.___torch_mangle_17878.Linear = prim::GetAttr[name="dense"](%449)
  %460 : Tensor = prim::GetAttr[name="bias"](%459)
  %461 : Tensor = prim::GetAttr[name="weight"](%459)
  %462 : Float(512:1, 128:512) = aten::t(%461), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.26 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.36, %462), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.26, %460, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.8, %input.34, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %466 : Tensor = prim::GetAttr[name="bias"](%458)
  %467 : Tensor = prim::GetAttr[name="weight"](%458)
  %468 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.14, %467), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.37 : Float(17:1664, 13:128, 128:1) = aten::add(%468, %466, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %470 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17886.FFNOutput = prim::GetAttr[name="output"](%330)
  %471 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17883.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%330)
  %472 : __torch__.torch.nn.modules.linear.___torch_mangle_17882.Linear = prim::GetAttr[name="dense"](%471)
  %473 : Tensor = prim::GetAttr[name="bias"](%472)
  %474 : Tensor = prim::GetAttr[name="weight"](%472)
  %475 : Float(128:1, 512:128) = aten::t(%474), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.27 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.37, %475), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.38 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.27, %473, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.39 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.38), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %479 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17885.NoNorm = prim::GetAttr[name="LayerNorm"](%470)
  %480 : __torch__.torch.nn.modules.linear.___torch_mangle_17884.Linear = prim::GetAttr[name="dense"](%470)
  %481 : Tensor = prim::GetAttr[name="bias"](%480)
  %482 : Tensor = prim::GetAttr[name="weight"](%480)
  %483 : Float(512:1, 128:512) = aten::t(%482), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.28 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.39, %483), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.28, %481, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.9, %input.37, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %487 : Tensor = prim::GetAttr[name="bias"](%479)
  %488 : Tensor = prim::GetAttr[name="weight"](%479)
  %489 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.15, %488), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.40 : Float(17:1664, 13:128, 128:1) = aten::add(%489, %487, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %491 : __torch__.torch.nn.modules.linear.___torch_mangle_17854.Linear = prim::GetAttr[name="dense"](%328)
  %492 : Tensor = prim::GetAttr[name="bias"](%491)
  %493 : Tensor = prim::GetAttr[name="weight"](%491)
  %494 : Float(128:1, 512:128) = aten::t(%493), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.29 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.40, %494), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.41 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.29, %492, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.42 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.41), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate # torch/nn/functional.py:1119:0
  %498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17861.OutputBottleneck = prim::GetAttr[name="bottleneck"](%327)
  %499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17857.NoNorm = prim::GetAttr[name="LayerNorm"](%327)
  %500 : __torch__.torch.nn.modules.linear.___torch_mangle_17856.Linear = prim::GetAttr[name="dense"](%327)
  %501 : Tensor = prim::GetAttr[name="bias"](%500)
  %502 : Tensor = prim::GetAttr[name="weight"](%500)
  %503 : Float(512:1, 128:512) = aten::t(%502), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %output.30 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.42, %503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %layer_output.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.30, %501, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.2, %input.40, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output # transformers/modeling_mobilebert.py:405:0
  %507 : Tensor = prim::GetAttr[name="bias"](%499)
  %508 : Tensor = prim::GetAttr[name="weight"](%499)
  %509 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.16, %508), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.43 : Float(17:1664, 13:128, 128:1) = aten::add(%509, %507, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %511 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17859.NoNorm = prim::GetAttr[name="LayerNorm"](%498)
  %512 : __torch__.torch.nn.modules.linear.___torch_mangle_17858.Linear = prim::GetAttr[name="dense"](%498)
  %513 : Tensor = prim::GetAttr[name="bias"](%512)
  %514 : Tensor = prim::GetAttr[name="weight"](%512)
  %515 : Float(128:1, 512:128) = aten::t(%514), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.31 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.43, %515), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.44 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.31, %513, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.10 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.44, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.17 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.10, %input.26, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %520 : Tensor = prim::GetAttr[name="bias"](%511)
  %521 : Tensor = prim::GetAttr[name="weight"](%511)
  %522 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.17, %521), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.45 : Float(17:6656, 13:512, 512:1) = aten::add(%522, %520, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %524 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17907.MobileBertOutput = prim::GetAttr[name="output"](%125)
  %525 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17900.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%125)
  %526 : __torch__.torch.nn.modules.container.___torch_mangle_17933.ModuleList = prim::GetAttr[name="ffn"](%125)
  %527 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17932.FFNLayer = prim::GetAttr[name="2"](%526)
  %528 : __torch__.torch.nn.modules.container.___torch_mangle_17933.ModuleList = prim::GetAttr[name="ffn"](%125)
  %529 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17926.FFNLayer = prim::GetAttr[name="1"](%528)
  %530 : __torch__.torch.nn.modules.container.___torch_mangle_17933.ModuleList = prim::GetAttr[name="ffn"](%125)
  %531 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17920.FFNLayer = prim::GetAttr[name="0"](%530)
  %532 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17898.MobileBertAttention = prim::GetAttr[name="attention"](%125)
  %533 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17914.Bottleneck = prim::GetAttr[name="bottleneck"](%125)
  %534 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17913.BottleneckLayer = prim::GetAttr[name="attention"](%533)
  %535 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17910.BottleneckLayer = prim::GetAttr[name="input"](%533)
  %536 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17909.NoNorm = prim::GetAttr[name="LayerNorm"](%535)
  %537 : __torch__.torch.nn.modules.linear.___torch_mangle_17908.Linear = prim::GetAttr[name="dense"](%535)
  %538 : Tensor = prim::GetAttr[name="bias"](%537)
  %539 : Tensor = prim::GetAttr[name="weight"](%537)
  %540 : Float(512:1, 128:512) = aten::t(%539), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.32 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %540), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.32, %538, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %543 : Tensor = prim::GetAttr[name="bias"](%536)
  %544 : Tensor = prim::GetAttr[name="weight"](%536)
  %545 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.18, %544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add(%545, %543, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %547 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17912.NoNorm = prim::GetAttr[name="LayerNorm"](%534)
  %548 : __torch__.torch.nn.modules.linear.___torch_mangle_17911.Linear = prim::GetAttr[name="dense"](%534)
  %549 : Tensor = prim::GetAttr[name="bias"](%548)
  %550 : Tensor = prim::GetAttr[name="weight"](%548)
  %551 : Float(512:1, 128:512) = aten::t(%550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.33 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %551), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.33, %549, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %554 : Tensor = prim::GetAttr[name="bias"](%547)
  %555 : Tensor = prim::GetAttr[name="weight"](%547)
  %556 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.19, %555), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.46 : Float(17:1664, 13:128, 128:1) = aten::add(%556, %554, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %558 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.46, %residual_tensor.3)
  %559 : Float(17:1664, 13:128, 128:1), %560 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%558)
  %561 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17897.MobileBertSelfOutput = prim::GetAttr[name="output"](%532)
  %562 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17894.MobileBertSelfAttention = prim::GetAttr[name="self"](%532)
  %563 : __torch__.torch.nn.modules.linear.___torch_mangle_17892.Linear = prim::GetAttr[name="value"](%562)
  %564 : __torch__.torch.nn.modules.linear.___torch_mangle_17891.Linear = prim::GetAttr[name="key"](%562)
  %565 : __torch__.torch.nn.modules.linear.___torch_mangle_17890.Linear = prim::GetAttr[name="query"](%562)
  %566 : Tensor = prim::GetAttr[name="bias"](%565)
  %567 : Tensor = prim::GetAttr[name="weight"](%565)
  %568 : Float(128:1, 128:128) = aten::t(%567), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %output.34 : Float(17:1664, 13:128, 128:1) = aten::matmul(%559, %568), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %x.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.34, %566, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1678:0
  %571 : Tensor = prim::GetAttr[name="bias"](%564)
  %572 : Tensor = prim::GetAttr[name="weight"](%564)
  %573 : Float(128:1, 128:128) = aten::t(%572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %output.35 : Float(17:1664, 13:128, 128:1) = aten::matmul(%559, %573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %x.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.35, %571, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1678:0
  %576 : Tensor = prim::GetAttr[name="bias"](%563)
  %577 : Tensor = prim::GetAttr[name="weight"](%563)
  %578 : Float(512:1, 128:512) = aten::t(%577), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %output.36 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %578), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %x.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.36, %576, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1678:0
  %581 : int = aten::size(%x.13, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %582 : int = aten::size(%x.13, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %583 : int[] = prim::ListConstruct(%581, %582, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.13, %583), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %585 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %query_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.14, %585), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %587 : int = aten::size(%x.15, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %588 : int = aten::size(%x.15, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %589 : int[] = prim::ListConstruct(%587, %588, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.15, %589), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %591 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %key_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.16, %591), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %593 : int = aten::size(%x.17, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %594 : int = aten::size(%x.17, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %595 : int[] = prim::ListConstruct(%593, %594, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.17, %595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %597 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %value_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.18, %597), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %599 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.3, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.3, %599), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.5, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.6, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.48 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.47, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.48, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.5 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.3, %value_layer.3), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:280:0
  %606 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %607 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.5, %606), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%607, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %609 : int = aten::size(%context_layer.6, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %610 : int = aten::size(%context_layer.6, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %611 : int[] = prim::ListConstruct(%609, %610, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %input.49 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.6, %611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:283:0
  %613 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17896.NoNorm = prim::GetAttr[name="LayerNorm"](%561)
  %614 : __torch__.torch.nn.modules.linear.___torch_mangle_17895.Linear = prim::GetAttr[name="dense"](%561)
  %615 : Tensor = prim::GetAttr[name="bias"](%614)
  %616 : Tensor = prim::GetAttr[name="weight"](%614)
  %617 : Float(128:1, 128:128) = aten::t(%616), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %output.37 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.49, %617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.37, %615, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.11, %560, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output # transformers/modeling_mobilebert.py:301:0
  %621 : Tensor = prim::GetAttr[name="bias"](%613)
  %622 : Tensor = prim::GetAttr[name="weight"](%613)
  %623 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.20, %622), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.50 : Float(17:1664, 13:128, 128:1) = aten::add(%623, %621, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %625 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17919.FFNOutput = prim::GetAttr[name="output"](%531)
  %626 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17916.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%531)
  %627 : __torch__.torch.nn.modules.linear.___torch_mangle_17915.Linear = prim::GetAttr[name="dense"](%626)
  %628 : Tensor = prim::GetAttr[name="bias"](%627)
  %629 : Tensor = prim::GetAttr[name="weight"](%627)
  %630 : Float(128:1, 512:128) = aten::t(%629), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.38 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.50, %630), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.51 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.38, %628, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.52 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.51), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %634 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17918.NoNorm = prim::GetAttr[name="LayerNorm"](%625)
  %635 : __torch__.torch.nn.modules.linear.___torch_mangle_17917.Linear = prim::GetAttr[name="dense"](%625)
  %636 : Tensor = prim::GetAttr[name="bias"](%635)
  %637 : Tensor = prim::GetAttr[name="weight"](%635)
  %638 : Float(512:1, 128:512) = aten::t(%637), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.39 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.52, %638), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.39, %636, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.12, %input.50, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %642 : Tensor = prim::GetAttr[name="bias"](%634)
  %643 : Tensor = prim::GetAttr[name="weight"](%634)
  %644 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.21, %643), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.53 : Float(17:1664, 13:128, 128:1) = aten::add(%644, %642, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %646 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17925.FFNOutput = prim::GetAttr[name="output"](%529)
  %647 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17922.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%529)
  %648 : __torch__.torch.nn.modules.linear.___torch_mangle_17921.Linear = prim::GetAttr[name="dense"](%647)
  %649 : Tensor = prim::GetAttr[name="bias"](%648)
  %650 : Tensor = prim::GetAttr[name="weight"](%648)
  %651 : Float(128:1, 512:128) = aten::t(%650), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.40 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.53, %651), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.54 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.40, %649, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.55 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.54), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %655 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17924.NoNorm = prim::GetAttr[name="LayerNorm"](%646)
  %656 : __torch__.torch.nn.modules.linear.___torch_mangle_17923.Linear = prim::GetAttr[name="dense"](%646)
  %657 : Tensor = prim::GetAttr[name="bias"](%656)
  %658 : Tensor = prim::GetAttr[name="weight"](%656)
  %659 : Float(512:1, 128:512) = aten::t(%658), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.41 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.55, %659), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.41, %657, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.13, %input.53, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %663 : Tensor = prim::GetAttr[name="bias"](%655)
  %664 : Tensor = prim::GetAttr[name="weight"](%655)
  %665 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.22, %664), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.56 : Float(17:1664, 13:128, 128:1) = aten::add(%665, %663, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %667 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17931.FFNOutput = prim::GetAttr[name="output"](%527)
  %668 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17928.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%527)
  %669 : __torch__.torch.nn.modules.linear.___torch_mangle_17927.Linear = prim::GetAttr[name="dense"](%668)
  %670 : Tensor = prim::GetAttr[name="bias"](%669)
  %671 : Tensor = prim::GetAttr[name="weight"](%669)
  %672 : Float(128:1, 512:128) = aten::t(%671), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.42 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.56, %672), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.57 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.42, %670, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.58 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.57), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %676 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17930.NoNorm = prim::GetAttr[name="LayerNorm"](%667)
  %677 : __torch__.torch.nn.modules.linear.___torch_mangle_17929.Linear = prim::GetAttr[name="dense"](%667)
  %678 : Tensor = prim::GetAttr[name="bias"](%677)
  %679 : Tensor = prim::GetAttr[name="weight"](%677)
  %680 : Float(512:1, 128:512) = aten::t(%679), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.43 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.58, %680), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.43, %678, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.14, %input.56, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %684 : Tensor = prim::GetAttr[name="bias"](%676)
  %685 : Tensor = prim::GetAttr[name="weight"](%676)
  %686 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.23, %685), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.59 : Float(17:1664, 13:128, 128:1) = aten::add(%686, %684, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %688 : __torch__.torch.nn.modules.linear.___torch_mangle_17899.Linear = prim::GetAttr[name="dense"](%525)
  %689 : Tensor = prim::GetAttr[name="bias"](%688)
  %690 : Tensor = prim::GetAttr[name="weight"](%688)
  %691 : Float(128:1, 512:128) = aten::t(%690), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.44 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.59, %691), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.60 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.44, %689, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.61 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.60), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate # torch/nn/functional.py:1119:0
  %695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17906.OutputBottleneck = prim::GetAttr[name="bottleneck"](%524)
  %696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17902.NoNorm = prim::GetAttr[name="LayerNorm"](%524)
  %697 : __torch__.torch.nn.modules.linear.___torch_mangle_17901.Linear = prim::GetAttr[name="dense"](%524)
  %698 : Tensor = prim::GetAttr[name="bias"](%697)
  %699 : Tensor = prim::GetAttr[name="weight"](%697)
  %700 : Float(512:1, 128:512) = aten::t(%699), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %output.45 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.61, %700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %layer_output.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.45, %698, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.24 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.3, %input.59, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output # transformers/modeling_mobilebert.py:405:0
  %704 : Tensor = prim::GetAttr[name="bias"](%696)
  %705 : Tensor = prim::GetAttr[name="weight"](%696)
  %706 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.24, %705), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.62 : Float(17:1664, 13:128, 128:1) = aten::add(%706, %704, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %708 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17904.NoNorm = prim::GetAttr[name="LayerNorm"](%695)
  %709 : __torch__.torch.nn.modules.linear.___torch_mangle_17903.Linear = prim::GetAttr[name="dense"](%695)
  %710 : Tensor = prim::GetAttr[name="bias"](%709)
  %711 : Tensor = prim::GetAttr[name="weight"](%709)
  %712 : Float(128:1, 512:128) = aten::t(%711), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.46 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.62, %712), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.63 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.46, %710, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.15 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.63, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.25 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.15, %input.45, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %717 : Tensor = prim::GetAttr[name="bias"](%708)
  %718 : Tensor = prim::GetAttr[name="weight"](%708)
  %719 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.25, %718), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.64 : Float(17:6656, 13:512, 512:1) = aten::add(%719, %717, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %721 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17952.MobileBertOutput = prim::GetAttr[name="output"](%123)
  %722 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17945.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%123)
  %723 : __torch__.torch.nn.modules.container.___torch_mangle_17978.ModuleList = prim::GetAttr[name="ffn"](%123)
  %724 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17977.FFNLayer = prim::GetAttr[name="2"](%723)
  %725 : __torch__.torch.nn.modules.container.___torch_mangle_17978.ModuleList = prim::GetAttr[name="ffn"](%123)
  %726 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17971.FFNLayer = prim::GetAttr[name="1"](%725)
  %727 : __torch__.torch.nn.modules.container.___torch_mangle_17978.ModuleList = prim::GetAttr[name="ffn"](%123)
  %728 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17965.FFNLayer = prim::GetAttr[name="0"](%727)
  %729 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17943.MobileBertAttention = prim::GetAttr[name="attention"](%123)
  %730 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17959.Bottleneck = prim::GetAttr[name="bottleneck"](%123)
  %731 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17958.BottleneckLayer = prim::GetAttr[name="attention"](%730)
  %732 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17955.BottleneckLayer = prim::GetAttr[name="input"](%730)
  %733 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17954.NoNorm = prim::GetAttr[name="LayerNorm"](%732)
  %734 : __torch__.torch.nn.modules.linear.___torch_mangle_17953.Linear = prim::GetAttr[name="dense"](%732)
  %735 : Tensor = prim::GetAttr[name="bias"](%734)
  %736 : Tensor = prim::GetAttr[name="weight"](%734)
  %737 : Float(512:1, 128:512) = aten::t(%736), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.47 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %737), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.47, %735, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %740 : Tensor = prim::GetAttr[name="bias"](%733)
  %741 : Tensor = prim::GetAttr[name="weight"](%733)
  %742 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.26, %741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%742, %740, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %744 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17957.NoNorm = prim::GetAttr[name="LayerNorm"](%731)
  %745 : __torch__.torch.nn.modules.linear.___torch_mangle_17956.Linear = prim::GetAttr[name="dense"](%731)
  %746 : Tensor = prim::GetAttr[name="bias"](%745)
  %747 : Tensor = prim::GetAttr[name="weight"](%745)
  %748 : Float(512:1, 128:512) = aten::t(%747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.48 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %748), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.48, %746, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %751 : Tensor = prim::GetAttr[name="bias"](%744)
  %752 : Tensor = prim::GetAttr[name="weight"](%744)
  %753 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.27, %752), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.65 : Float(17:1664, 13:128, 128:1) = aten::add(%753, %751, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %755 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.65, %residual_tensor.4)
  %756 : Float(17:1664, 13:128, 128:1), %757 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%755)
  %758 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17942.MobileBertSelfOutput = prim::GetAttr[name="output"](%729)
  %759 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17939.MobileBertSelfAttention = prim::GetAttr[name="self"](%729)
  %760 : __torch__.torch.nn.modules.linear.___torch_mangle_17937.Linear = prim::GetAttr[name="value"](%759)
  %761 : __torch__.torch.nn.modules.linear.___torch_mangle_17936.Linear = prim::GetAttr[name="key"](%759)
  %762 : __torch__.torch.nn.modules.linear.___torch_mangle_17935.Linear = prim::GetAttr[name="query"](%759)
  %763 : Tensor = prim::GetAttr[name="bias"](%762)
  %764 : Tensor = prim::GetAttr[name="weight"](%762)
  %765 : Float(128:1, 128:128) = aten::t(%764), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %output.49 : Float(17:1664, 13:128, 128:1) = aten::matmul(%756, %765), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %x.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.49, %763, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1678:0
  %768 : Tensor = prim::GetAttr[name="bias"](%761)
  %769 : Tensor = prim::GetAttr[name="weight"](%761)
  %770 : Float(128:1, 128:128) = aten::t(%769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %output.50 : Float(17:1664, 13:128, 128:1) = aten::matmul(%756, %770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %x.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.50, %768, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1678:0
  %773 : Tensor = prim::GetAttr[name="bias"](%760)
  %774 : Tensor = prim::GetAttr[name="weight"](%760)
  %775 : Float(512:1, 128:512) = aten::t(%774), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %output.51 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %775), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %x.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.51, %773, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1678:0
  %778 : int = aten::size(%x.19, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %779 : int = aten::size(%x.19, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %780 : int[] = prim::ListConstruct(%778, %779, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.19, %780), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %782 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %query_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.20, %782), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %784 : int = aten::size(%x.21, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %785 : int = aten::size(%x.21, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %786 : int[] = prim::ListConstruct(%784, %785, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.21, %786), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %788 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %key_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.22, %788), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %790 : int = aten::size(%x.23, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %791 : int = aten::size(%x.23, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %792 : int[] = prim::ListConstruct(%790, %791, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.23, %792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %794 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %value_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.24, %794), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %796 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.4, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.4, %796), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.7, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.66 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.8, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.67 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.66, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.67, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.7 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.4, %value_layer.4), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:280:0
  %803 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %804 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.7, %803), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%804, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %806 : int = aten::size(%context_layer.8, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %807 : int = aten::size(%context_layer.8, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %808 : int[] = prim::ListConstruct(%806, %807, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %input.68 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.8, %808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:283:0
  %810 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17941.NoNorm = prim::GetAttr[name="LayerNorm"](%758)
  %811 : __torch__.torch.nn.modules.linear.___torch_mangle_17940.Linear = prim::GetAttr[name="dense"](%758)
  %812 : Tensor = prim::GetAttr[name="bias"](%811)
  %813 : Tensor = prim::GetAttr[name="weight"](%811)
  %814 : Float(128:1, 128:128) = aten::t(%813), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %output.52 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.68, %814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.52, %812, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.28 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.16, %757, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output # transformers/modeling_mobilebert.py:301:0
  %818 : Tensor = prim::GetAttr[name="bias"](%810)
  %819 : Tensor = prim::GetAttr[name="weight"](%810)
  %820 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.28, %819), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.69 : Float(17:1664, 13:128, 128:1) = aten::add(%820, %818, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %822 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17964.FFNOutput = prim::GetAttr[name="output"](%728)
  %823 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17961.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%728)
  %824 : __torch__.torch.nn.modules.linear.___torch_mangle_17960.Linear = prim::GetAttr[name="dense"](%823)
  %825 : Tensor = prim::GetAttr[name="bias"](%824)
  %826 : Tensor = prim::GetAttr[name="weight"](%824)
  %827 : Float(128:1, 512:128) = aten::t(%826), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.53 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.69, %827), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.70 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.53, %825, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.71 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.70), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %831 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17963.NoNorm = prim::GetAttr[name="LayerNorm"](%822)
  %832 : __torch__.torch.nn.modules.linear.___torch_mangle_17962.Linear = prim::GetAttr[name="dense"](%822)
  %833 : Tensor = prim::GetAttr[name="bias"](%832)
  %834 : Tensor = prim::GetAttr[name="weight"](%832)
  %835 : Float(512:1, 128:512) = aten::t(%834), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.54 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.71, %835), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.54, %833, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.29 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.17, %input.69, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %839 : Tensor = prim::GetAttr[name="bias"](%831)
  %840 : Tensor = prim::GetAttr[name="weight"](%831)
  %841 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.29, %840), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.72 : Float(17:1664, 13:128, 128:1) = aten::add(%841, %839, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %843 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17970.FFNOutput = prim::GetAttr[name="output"](%726)
  %844 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17967.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%726)
  %845 : __torch__.torch.nn.modules.linear.___torch_mangle_17966.Linear = prim::GetAttr[name="dense"](%844)
  %846 : Tensor = prim::GetAttr[name="bias"](%845)
  %847 : Tensor = prim::GetAttr[name="weight"](%845)
  %848 : Float(128:1, 512:128) = aten::t(%847), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.55 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.72, %848), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.73 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.55, %846, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.74 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.73), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %852 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17969.NoNorm = prim::GetAttr[name="LayerNorm"](%843)
  %853 : __torch__.torch.nn.modules.linear.___torch_mangle_17968.Linear = prim::GetAttr[name="dense"](%843)
  %854 : Tensor = prim::GetAttr[name="bias"](%853)
  %855 : Tensor = prim::GetAttr[name="weight"](%853)
  %856 : Float(512:1, 128:512) = aten::t(%855), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.56 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.74, %856), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.56, %854, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.30 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.18, %input.72, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %860 : Tensor = prim::GetAttr[name="bias"](%852)
  %861 : Tensor = prim::GetAttr[name="weight"](%852)
  %862 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.30, %861), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.75 : Float(17:1664, 13:128, 128:1) = aten::add(%862, %860, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %864 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17976.FFNOutput = prim::GetAttr[name="output"](%724)
  %865 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17973.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%724)
  %866 : __torch__.torch.nn.modules.linear.___torch_mangle_17972.Linear = prim::GetAttr[name="dense"](%865)
  %867 : Tensor = prim::GetAttr[name="bias"](%866)
  %868 : Tensor = prim::GetAttr[name="weight"](%866)
  %869 : Float(128:1, 512:128) = aten::t(%868), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.57 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.75, %869), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.76 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.57, %867, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.77 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.76), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %873 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17975.NoNorm = prim::GetAttr[name="LayerNorm"](%864)
  %874 : __torch__.torch.nn.modules.linear.___torch_mangle_17974.Linear = prim::GetAttr[name="dense"](%864)
  %875 : Tensor = prim::GetAttr[name="bias"](%874)
  %876 : Tensor = prim::GetAttr[name="weight"](%874)
  %877 : Float(512:1, 128:512) = aten::t(%876), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.58 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.77, %877), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.58, %875, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.31 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.19, %input.75, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %881 : Tensor = prim::GetAttr[name="bias"](%873)
  %882 : Tensor = prim::GetAttr[name="weight"](%873)
  %883 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.31, %882), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.78 : Float(17:1664, 13:128, 128:1) = aten::add(%883, %881, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %885 : __torch__.torch.nn.modules.linear.___torch_mangle_17944.Linear = prim::GetAttr[name="dense"](%722)
  %886 : Tensor = prim::GetAttr[name="bias"](%885)
  %887 : Tensor = prim::GetAttr[name="weight"](%885)
  %888 : Float(128:1, 512:128) = aten::t(%887), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %output.59 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.78, %888), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %input.79 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.59, %886, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1678:0
  %input.80 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.79), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate # torch/nn/functional.py:1119:0
  %892 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17951.OutputBottleneck = prim::GetAttr[name="bottleneck"](%721)
  %893 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17947.NoNorm = prim::GetAttr[name="LayerNorm"](%721)
  %894 : __torch__.torch.nn.modules.linear.___torch_mangle_17946.Linear = prim::GetAttr[name="dense"](%721)
  %895 : Tensor = prim::GetAttr[name="bias"](%894)
  %896 : Tensor = prim::GetAttr[name="weight"](%894)
  %897 : Float(512:1, 128:512) = aten::t(%896), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %output.60 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.80, %897), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %layer_output.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.60, %895, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.32 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.4, %input.78, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output # transformers/modeling_mobilebert.py:405:0
  %901 : Tensor = prim::GetAttr[name="bias"](%893)
  %902 : Tensor = prim::GetAttr[name="weight"](%893)
  %903 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.32, %902), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.81 : Float(17:1664, 13:128, 128:1) = aten::add(%903, %901, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %905 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17949.NoNorm = prim::GetAttr[name="LayerNorm"](%892)
  %906 : __torch__.torch.nn.modules.linear.___torch_mangle_17948.Linear = prim::GetAttr[name="dense"](%892)
  %907 : Tensor = prim::GetAttr[name="bias"](%906)
  %908 : Tensor = prim::GetAttr[name="weight"](%906)
  %909 : Float(128:1, 512:128) = aten::t(%908), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.61 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.81, %909), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.82 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.61, %907, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.20 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.82, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.33 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.20, %input.64, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %914 : Tensor = prim::GetAttr[name="bias"](%905)
  %915 : Tensor = prim::GetAttr[name="weight"](%905)
  %916 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.33, %915), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.83 : Float(17:6656, 13:512, 512:1) = aten::add(%916, %914, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %918 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17997.MobileBertOutput = prim::GetAttr[name="output"](%121)
  %919 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17990.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%121)
  %920 : __torch__.torch.nn.modules.container.___torch_mangle_18023.ModuleList = prim::GetAttr[name="ffn"](%121)
  %921 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18022.FFNLayer = prim::GetAttr[name="2"](%920)
  %922 : __torch__.torch.nn.modules.container.___torch_mangle_18023.ModuleList = prim::GetAttr[name="ffn"](%121)
  %923 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18016.FFNLayer = prim::GetAttr[name="1"](%922)
  %924 : __torch__.torch.nn.modules.container.___torch_mangle_18023.ModuleList = prim::GetAttr[name="ffn"](%121)
  %925 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18010.FFNLayer = prim::GetAttr[name="0"](%924)
  %926 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17988.MobileBertAttention = prim::GetAttr[name="attention"](%121)
  %927 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18004.Bottleneck = prim::GetAttr[name="bottleneck"](%121)
  %928 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18003.BottleneckLayer = prim::GetAttr[name="attention"](%927)
  %929 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18000.BottleneckLayer = prim::GetAttr[name="input"](%927)
  %930 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17999.NoNorm = prim::GetAttr[name="LayerNorm"](%929)
  %931 : __torch__.torch.nn.modules.linear.___torch_mangle_17998.Linear = prim::GetAttr[name="dense"](%929)
  %932 : Tensor = prim::GetAttr[name="bias"](%931)
  %933 : Tensor = prim::GetAttr[name="weight"](%931)
  %934 : Float(512:1, 128:512) = aten::t(%933), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.62 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %934), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.62, %932, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %937 : Tensor = prim::GetAttr[name="bias"](%930)
  %938 : Tensor = prim::GetAttr[name="weight"](%930)
  %939 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.34, %938), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%939, %937, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %941 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18002.NoNorm = prim::GetAttr[name="LayerNorm"](%928)
  %942 : __torch__.torch.nn.modules.linear.___torch_mangle_18001.Linear = prim::GetAttr[name="dense"](%928)
  %943 : Tensor = prim::GetAttr[name="bias"](%942)
  %944 : Tensor = prim::GetAttr[name="weight"](%942)
  %945 : Float(512:1, 128:512) = aten::t(%944), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.63 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %945), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.63, %943, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %948 : Tensor = prim::GetAttr[name="bias"](%941)
  %949 : Tensor = prim::GetAttr[name="weight"](%941)
  %950 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.35, %949), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.84 : Float(17:1664, 13:128, 128:1) = aten::add(%950, %948, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %952 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.84, %residual_tensor.5)
  %953 : Float(17:1664, 13:128, 128:1), %954 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%952)
  %955 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17987.MobileBertSelfOutput = prim::GetAttr[name="output"](%926)
  %956 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17984.MobileBertSelfAttention = prim::GetAttr[name="self"](%926)
  %957 : __torch__.torch.nn.modules.linear.___torch_mangle_17982.Linear = prim::GetAttr[name="value"](%956)
  %958 : __torch__.torch.nn.modules.linear.___torch_mangle_17981.Linear = prim::GetAttr[name="key"](%956)
  %959 : __torch__.torch.nn.modules.linear.___torch_mangle_17980.Linear = prim::GetAttr[name="query"](%956)
  %960 : Tensor = prim::GetAttr[name="bias"](%959)
  %961 : Tensor = prim::GetAttr[name="weight"](%959)
  %962 : Float(128:1, 128:128) = aten::t(%961), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %output.64 : Float(17:1664, 13:128, 128:1) = aten::matmul(%953, %962), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %x.25 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.64, %960, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1678:0
  %965 : Tensor = prim::GetAttr[name="bias"](%958)
  %966 : Tensor = prim::GetAttr[name="weight"](%958)
  %967 : Float(128:1, 128:128) = aten::t(%966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %output.65 : Float(17:1664, 13:128, 128:1) = aten::matmul(%953, %967), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %x.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.65, %965, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1678:0
  %970 : Tensor = prim::GetAttr[name="bias"](%957)
  %971 : Tensor = prim::GetAttr[name="weight"](%957)
  %972 : Float(512:1, 128:512) = aten::t(%971), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %output.66 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %972), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %x.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.66, %970, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1678:0
  %975 : int = aten::size(%x.25, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %976 : int = aten::size(%x.25, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %977 : int[] = prim::ListConstruct(%975, %976, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.25, %977), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %979 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %query_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.26, %979), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %981 : int = aten::size(%x.27, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %982 : int = aten::size(%x.27, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %983 : int[] = prim::ListConstruct(%981, %982, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.27, %983), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %985 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %key_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.28, %985), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %987 : int = aten::size(%x.29, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %988 : int = aten::size(%x.29, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %989 : int[] = prim::ListConstruct(%987, %988, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.29, %989), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %991 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %value_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.30, %991), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %993 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.5, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.5, %993), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.9, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.85 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.10, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.86 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.85, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.86, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.9 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.5, %value_layer.5), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:280:0
  %1000 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %1001 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.9, %1000), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1001, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %1003 : int = aten::size(%context_layer.10, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1004 : int = aten::size(%context_layer.10, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1005 : int[] = prim::ListConstruct(%1003, %1004, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %input.87 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.10, %1005), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:283:0
  %1007 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17986.NoNorm = prim::GetAttr[name="LayerNorm"](%955)
  %1008 : __torch__.torch.nn.modules.linear.___torch_mangle_17985.Linear = prim::GetAttr[name="dense"](%955)
  %1009 : Tensor = prim::GetAttr[name="bias"](%1008)
  %1010 : Tensor = prim::GetAttr[name="weight"](%1008)
  %1011 : Float(128:1, 128:128) = aten::t(%1010), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %output.67 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.87, %1011), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.67, %1009, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.36 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.21, %954, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output # transformers/modeling_mobilebert.py:301:0
  %1015 : Tensor = prim::GetAttr[name="bias"](%1007)
  %1016 : Tensor = prim::GetAttr[name="weight"](%1007)
  %1017 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.36, %1016), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.88 : Float(17:1664, 13:128, 128:1) = aten::add(%1017, %1015, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1019 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18009.FFNOutput = prim::GetAttr[name="output"](%925)
  %1020 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18006.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%925)
  %1021 : __torch__.torch.nn.modules.linear.___torch_mangle_18005.Linear = prim::GetAttr[name="dense"](%1020)
  %1022 : Tensor = prim::GetAttr[name="bias"](%1021)
  %1023 : Tensor = prim::GetAttr[name="weight"](%1021)
  %1024 : Float(128:1, 512:128) = aten::t(%1023), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.68 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.88, %1024), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.89 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.68, %1022, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.90 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.89), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1028 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18008.NoNorm = prim::GetAttr[name="LayerNorm"](%1019)
  %1029 : __torch__.torch.nn.modules.linear.___torch_mangle_18007.Linear = prim::GetAttr[name="dense"](%1019)
  %1030 : Tensor = prim::GetAttr[name="bias"](%1029)
  %1031 : Tensor = prim::GetAttr[name="weight"](%1029)
  %1032 : Float(512:1, 128:512) = aten::t(%1031), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.69 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.90, %1032), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.69, %1030, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.37 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.22, %input.88, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1036 : Tensor = prim::GetAttr[name="bias"](%1028)
  %1037 : Tensor = prim::GetAttr[name="weight"](%1028)
  %1038 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.37, %1037), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.91 : Float(17:1664, 13:128, 128:1) = aten::add(%1038, %1036, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1040 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18015.FFNOutput = prim::GetAttr[name="output"](%923)
  %1041 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18012.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%923)
  %1042 : __torch__.torch.nn.modules.linear.___torch_mangle_18011.Linear = prim::GetAttr[name="dense"](%1041)
  %1043 : Tensor = prim::GetAttr[name="bias"](%1042)
  %1044 : Tensor = prim::GetAttr[name="weight"](%1042)
  %1045 : Float(128:1, 512:128) = aten::t(%1044), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.70 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.91, %1045), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.92 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.70, %1043, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.93 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.92), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1049 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18014.NoNorm = prim::GetAttr[name="LayerNorm"](%1040)
  %1050 : __torch__.torch.nn.modules.linear.___torch_mangle_18013.Linear = prim::GetAttr[name="dense"](%1040)
  %1051 : Tensor = prim::GetAttr[name="bias"](%1050)
  %1052 : Tensor = prim::GetAttr[name="weight"](%1050)
  %1053 : Float(512:1, 128:512) = aten::t(%1052), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.71 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.93, %1053), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.71, %1051, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.38 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.23, %input.91, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1057 : Tensor = prim::GetAttr[name="bias"](%1049)
  %1058 : Tensor = prim::GetAttr[name="weight"](%1049)
  %1059 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.38, %1058), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.94 : Float(17:1664, 13:128, 128:1) = aten::add(%1059, %1057, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1061 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18021.FFNOutput = prim::GetAttr[name="output"](%921)
  %1062 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18018.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%921)
  %1063 : __torch__.torch.nn.modules.linear.___torch_mangle_18017.Linear = prim::GetAttr[name="dense"](%1062)
  %1064 : Tensor = prim::GetAttr[name="bias"](%1063)
  %1065 : Tensor = prim::GetAttr[name="weight"](%1063)
  %1066 : Float(128:1, 512:128) = aten::t(%1065), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.72 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.94, %1066), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.95 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.72, %1064, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.96 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.95), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1070 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18020.NoNorm = prim::GetAttr[name="LayerNorm"](%1061)
  %1071 : __torch__.torch.nn.modules.linear.___torch_mangle_18019.Linear = prim::GetAttr[name="dense"](%1061)
  %1072 : Tensor = prim::GetAttr[name="bias"](%1071)
  %1073 : Tensor = prim::GetAttr[name="weight"](%1071)
  %1074 : Float(512:1, 128:512) = aten::t(%1073), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.73 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.96, %1074), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.24 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.73, %1072, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.39 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.24, %input.94, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1078 : Tensor = prim::GetAttr[name="bias"](%1070)
  %1079 : Tensor = prim::GetAttr[name="weight"](%1070)
  %1080 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.39, %1079), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.97 : Float(17:1664, 13:128, 128:1) = aten::add(%1080, %1078, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1082 : __torch__.torch.nn.modules.linear.___torch_mangle_17989.Linear = prim::GetAttr[name="dense"](%919)
  %1083 : Tensor = prim::GetAttr[name="bias"](%1082)
  %1084 : Tensor = prim::GetAttr[name="weight"](%1082)
  %1085 : Float(128:1, 512:128) = aten::t(%1084), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %output.74 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.97, %1085), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %input.98 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.74, %1083, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1678:0
  %input.99 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.98), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate # torch/nn/functional.py:1119:0
  %1089 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17996.OutputBottleneck = prim::GetAttr[name="bottleneck"](%918)
  %1090 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17992.NoNorm = prim::GetAttr[name="LayerNorm"](%918)
  %1091 : __torch__.torch.nn.modules.linear.___torch_mangle_17991.Linear = prim::GetAttr[name="dense"](%918)
  %1092 : Tensor = prim::GetAttr[name="bias"](%1091)
  %1093 : Tensor = prim::GetAttr[name="weight"](%1091)
  %1094 : Float(512:1, 128:512) = aten::t(%1093), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %output.75 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.99, %1094), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %layer_output.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.75, %1092, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.40 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.5, %input.97, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output # transformers/modeling_mobilebert.py:405:0
  %1098 : Tensor = prim::GetAttr[name="bias"](%1090)
  %1099 : Tensor = prim::GetAttr[name="weight"](%1090)
  %1100 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.40, %1099), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.100 : Float(17:1664, 13:128, 128:1) = aten::add(%1100, %1098, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1102 : __torch__.transformers.modeling_mobilebert.___torch_mangle_17994.NoNorm = prim::GetAttr[name="LayerNorm"](%1089)
  %1103 : __torch__.torch.nn.modules.linear.___torch_mangle_17993.Linear = prim::GetAttr[name="dense"](%1089)
  %1104 : Tensor = prim::GetAttr[name="bias"](%1103)
  %1105 : Tensor = prim::GetAttr[name="weight"](%1103)
  %1106 : Float(128:1, 512:128) = aten::t(%1105), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.76 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.100, %1106), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.101 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.76, %1104, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.25 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.101, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.41 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.25, %input.83, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1111 : Tensor = prim::GetAttr[name="bias"](%1102)
  %1112 : Tensor = prim::GetAttr[name="weight"](%1102)
  %1113 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.41, %1112), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.102 : Float(17:6656, 13:512, 512:1) = aten::add(%1113, %1111, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1115 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18042.MobileBertOutput = prim::GetAttr[name="output"](%119)
  %1116 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18035.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%119)
  %1117 : __torch__.torch.nn.modules.container.___torch_mangle_18068.ModuleList = prim::GetAttr[name="ffn"](%119)
  %1118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18067.FFNLayer = prim::GetAttr[name="2"](%1117)
  %1119 : __torch__.torch.nn.modules.container.___torch_mangle_18068.ModuleList = prim::GetAttr[name="ffn"](%119)
  %1120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18061.FFNLayer = prim::GetAttr[name="1"](%1119)
  %1121 : __torch__.torch.nn.modules.container.___torch_mangle_18068.ModuleList = prim::GetAttr[name="ffn"](%119)
  %1122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18055.FFNLayer = prim::GetAttr[name="0"](%1121)
  %1123 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18033.MobileBertAttention = prim::GetAttr[name="attention"](%119)
  %1124 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18049.Bottleneck = prim::GetAttr[name="bottleneck"](%119)
  %1125 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18048.BottleneckLayer = prim::GetAttr[name="attention"](%1124)
  %1126 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18045.BottleneckLayer = prim::GetAttr[name="input"](%1124)
  %1127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18044.NoNorm = prim::GetAttr[name="LayerNorm"](%1126)
  %1128 : __torch__.torch.nn.modules.linear.___torch_mangle_18043.Linear = prim::GetAttr[name="dense"](%1126)
  %1129 : Tensor = prim::GetAttr[name="bias"](%1128)
  %1130 : Tensor = prim::GetAttr[name="weight"](%1128)
  %1131 : Float(512:1, 128:512) = aten::t(%1130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.77 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1131), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.77, %1129, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1134 : Tensor = prim::GetAttr[name="bias"](%1127)
  %1135 : Tensor = prim::GetAttr[name="weight"](%1127)
  %1136 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.42, %1135), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%1136, %1134, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1138 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18047.NoNorm = prim::GetAttr[name="LayerNorm"](%1125)
  %1139 : __torch__.torch.nn.modules.linear.___torch_mangle_18046.Linear = prim::GetAttr[name="dense"](%1125)
  %1140 : Tensor = prim::GetAttr[name="bias"](%1139)
  %1141 : Tensor = prim::GetAttr[name="weight"](%1139)
  %1142 : Float(512:1, 128:512) = aten::t(%1141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.78 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1142), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.78, %1140, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1145 : Tensor = prim::GetAttr[name="bias"](%1138)
  %1146 : Tensor = prim::GetAttr[name="weight"](%1138)
  %1147 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.43, %1146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.103 : Float(17:1664, 13:128, 128:1) = aten::add(%1147, %1145, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1149 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.103, %residual_tensor.6)
  %1150 : Float(17:1664, 13:128, 128:1), %1151 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1149)
  %1152 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18032.MobileBertSelfOutput = prim::GetAttr[name="output"](%1123)
  %1153 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18029.MobileBertSelfAttention = prim::GetAttr[name="self"](%1123)
  %1154 : __torch__.torch.nn.modules.linear.___torch_mangle_18027.Linear = prim::GetAttr[name="value"](%1153)
  %1155 : __torch__.torch.nn.modules.linear.___torch_mangle_18026.Linear = prim::GetAttr[name="key"](%1153)
  %1156 : __torch__.torch.nn.modules.linear.___torch_mangle_18025.Linear = prim::GetAttr[name="query"](%1153)
  %1157 : Tensor = prim::GetAttr[name="bias"](%1156)
  %1158 : Tensor = prim::GetAttr[name="weight"](%1156)
  %1159 : Float(128:1, 128:128) = aten::t(%1158), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %output.79 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1150, %1159), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %x.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.79, %1157, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1678:0
  %1162 : Tensor = prim::GetAttr[name="bias"](%1155)
  %1163 : Tensor = prim::GetAttr[name="weight"](%1155)
  %1164 : Float(128:1, 128:128) = aten::t(%1163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %output.80 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1150, %1164), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %x.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.80, %1162, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1678:0
  %1167 : Tensor = prim::GetAttr[name="bias"](%1154)
  %1168 : Tensor = prim::GetAttr[name="weight"](%1154)
  %1169 : Float(512:1, 128:512) = aten::t(%1168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %output.81 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1169), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %x.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.81, %1167, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1678:0
  %1172 : int = aten::size(%x.31, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1173 : int = aten::size(%x.31, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1174 : int[] = prim::ListConstruct(%1172, %1173, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.31, %1174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1176 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %query_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.32, %1176), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1178 : int = aten::size(%x.33, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1179 : int = aten::size(%x.33, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1180 : int[] = prim::ListConstruct(%1178, %1179, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.33, %1180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1182 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %key_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.34, %1182), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1184 : int = aten::size(%x.35, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1185 : int = aten::size(%x.35, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1186 : int[] = prim::ListConstruct(%1184, %1185, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.35, %1186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1188 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %value_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.36, %1188), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1190 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.6, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.6, %1190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.11, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.104 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.12, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.105 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.104, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.105, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.11 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.6, %value_layer.6), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:280:0
  %1197 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %1198 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.11, %1197), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1198, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %1200 : int = aten::size(%context_layer.12, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1201 : int = aten::size(%context_layer.12, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1202 : int[] = prim::ListConstruct(%1200, %1201, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %input.106 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.12, %1202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:283:0
  %1204 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18031.NoNorm = prim::GetAttr[name="LayerNorm"](%1152)
  %1205 : __torch__.torch.nn.modules.linear.___torch_mangle_18030.Linear = prim::GetAttr[name="dense"](%1152)
  %1206 : Tensor = prim::GetAttr[name="bias"](%1205)
  %1207 : Tensor = prim::GetAttr[name="weight"](%1205)
  %1208 : Float(128:1, 128:128) = aten::t(%1207), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %output.82 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.106, %1208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.82, %1206, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.44 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.26, %1151, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output # transformers/modeling_mobilebert.py:301:0
  %1212 : Tensor = prim::GetAttr[name="bias"](%1204)
  %1213 : Tensor = prim::GetAttr[name="weight"](%1204)
  %1214 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.44, %1213), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.107 : Float(17:1664, 13:128, 128:1) = aten::add(%1214, %1212, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1216 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18054.FFNOutput = prim::GetAttr[name="output"](%1122)
  %1217 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18051.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1122)
  %1218 : __torch__.torch.nn.modules.linear.___torch_mangle_18050.Linear = prim::GetAttr[name="dense"](%1217)
  %1219 : Tensor = prim::GetAttr[name="bias"](%1218)
  %1220 : Tensor = prim::GetAttr[name="weight"](%1218)
  %1221 : Float(128:1, 512:128) = aten::t(%1220), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.83 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.107, %1221), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.108 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.83, %1219, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.109 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1225 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18053.NoNorm = prim::GetAttr[name="LayerNorm"](%1216)
  %1226 : __torch__.torch.nn.modules.linear.___torch_mangle_18052.Linear = prim::GetAttr[name="dense"](%1216)
  %1227 : Tensor = prim::GetAttr[name="bias"](%1226)
  %1228 : Tensor = prim::GetAttr[name="weight"](%1226)
  %1229 : Float(512:1, 128:512) = aten::t(%1228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.84 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.109, %1229), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.84, %1227, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.45 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.27, %input.107, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1233 : Tensor = prim::GetAttr[name="bias"](%1225)
  %1234 : Tensor = prim::GetAttr[name="weight"](%1225)
  %1235 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.45, %1234), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.110 : Float(17:1664, 13:128, 128:1) = aten::add(%1235, %1233, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1237 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18060.FFNOutput = prim::GetAttr[name="output"](%1120)
  %1238 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18057.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1120)
  %1239 : __torch__.torch.nn.modules.linear.___torch_mangle_18056.Linear = prim::GetAttr[name="dense"](%1238)
  %1240 : Tensor = prim::GetAttr[name="bias"](%1239)
  %1241 : Tensor = prim::GetAttr[name="weight"](%1239)
  %1242 : Float(128:1, 512:128) = aten::t(%1241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.85 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.110, %1242), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.111 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.85, %1240, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.112 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1246 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18059.NoNorm = prim::GetAttr[name="LayerNorm"](%1237)
  %1247 : __torch__.torch.nn.modules.linear.___torch_mangle_18058.Linear = prim::GetAttr[name="dense"](%1237)
  %1248 : Tensor = prim::GetAttr[name="bias"](%1247)
  %1249 : Tensor = prim::GetAttr[name="weight"](%1247)
  %1250 : Float(512:1, 128:512) = aten::t(%1249), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.86 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.112, %1250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.28 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.86, %1248, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.46 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.28, %input.110, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1254 : Tensor = prim::GetAttr[name="bias"](%1246)
  %1255 : Tensor = prim::GetAttr[name="weight"](%1246)
  %1256 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.46, %1255), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.113 : Float(17:1664, 13:128, 128:1) = aten::add(%1256, %1254, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1258 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18066.FFNOutput = prim::GetAttr[name="output"](%1118)
  %1259 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18063.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1118)
  %1260 : __torch__.torch.nn.modules.linear.___torch_mangle_18062.Linear = prim::GetAttr[name="dense"](%1259)
  %1261 : Tensor = prim::GetAttr[name="bias"](%1260)
  %1262 : Tensor = prim::GetAttr[name="weight"](%1260)
  %1263 : Float(128:1, 512:128) = aten::t(%1262), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.87 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.113, %1263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.114 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.87, %1261, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.115 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.114), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1267 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18065.NoNorm = prim::GetAttr[name="LayerNorm"](%1258)
  %1268 : __torch__.torch.nn.modules.linear.___torch_mangle_18064.Linear = prim::GetAttr[name="dense"](%1258)
  %1269 : Tensor = prim::GetAttr[name="bias"](%1268)
  %1270 : Tensor = prim::GetAttr[name="weight"](%1268)
  %1271 : Float(512:1, 128:512) = aten::t(%1270), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.88 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.115, %1271), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.88, %1269, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.47 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.29, %input.113, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1275 : Tensor = prim::GetAttr[name="bias"](%1267)
  %1276 : Tensor = prim::GetAttr[name="weight"](%1267)
  %1277 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.47, %1276), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.116 : Float(17:1664, 13:128, 128:1) = aten::add(%1277, %1275, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1279 : __torch__.torch.nn.modules.linear.___torch_mangle_18034.Linear = prim::GetAttr[name="dense"](%1116)
  %1280 : Tensor = prim::GetAttr[name="bias"](%1279)
  %1281 : Tensor = prim::GetAttr[name="weight"](%1279)
  %1282 : Float(128:1, 512:128) = aten::t(%1281), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %output.89 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.116, %1282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %input.117 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.89, %1280, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1678:0
  %input.118 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.117), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate # torch/nn/functional.py:1119:0
  %1286 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18041.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1115)
  %1287 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18037.NoNorm = prim::GetAttr[name="LayerNorm"](%1115)
  %1288 : __torch__.torch.nn.modules.linear.___torch_mangle_18036.Linear = prim::GetAttr[name="dense"](%1115)
  %1289 : Tensor = prim::GetAttr[name="bias"](%1288)
  %1290 : Tensor = prim::GetAttr[name="weight"](%1288)
  %1291 : Float(512:1, 128:512) = aten::t(%1290), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %output.90 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.118, %1291), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %layer_output.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.90, %1289, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.48 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.6, %input.116, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output # transformers/modeling_mobilebert.py:405:0
  %1295 : Tensor = prim::GetAttr[name="bias"](%1287)
  %1296 : Tensor = prim::GetAttr[name="weight"](%1287)
  %1297 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.48, %1296), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.119 : Float(17:1664, 13:128, 128:1) = aten::add(%1297, %1295, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1299 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18039.NoNorm = prim::GetAttr[name="LayerNorm"](%1286)
  %1300 : __torch__.torch.nn.modules.linear.___torch_mangle_18038.Linear = prim::GetAttr[name="dense"](%1286)
  %1301 : Tensor = prim::GetAttr[name="bias"](%1300)
  %1302 : Tensor = prim::GetAttr[name="weight"](%1300)
  %1303 : Float(128:1, 512:128) = aten::t(%1302), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.91 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.119, %1303), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.120 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.91, %1301, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.30 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.120, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.49 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.30, %input.102, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1308 : Tensor = prim::GetAttr[name="bias"](%1299)
  %1309 : Tensor = prim::GetAttr[name="weight"](%1299)
  %1310 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.49, %1309), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.121 : Float(17:6656, 13:512, 512:1) = aten::add(%1310, %1308, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1312 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18087.MobileBertOutput = prim::GetAttr[name="output"](%117)
  %1313 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18080.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%117)
  %1314 : __torch__.torch.nn.modules.container.___torch_mangle_18113.ModuleList = prim::GetAttr[name="ffn"](%117)
  %1315 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18112.FFNLayer = prim::GetAttr[name="2"](%1314)
  %1316 : __torch__.torch.nn.modules.container.___torch_mangle_18113.ModuleList = prim::GetAttr[name="ffn"](%117)
  %1317 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18106.FFNLayer = prim::GetAttr[name="1"](%1316)
  %1318 : __torch__.torch.nn.modules.container.___torch_mangle_18113.ModuleList = prim::GetAttr[name="ffn"](%117)
  %1319 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18100.FFNLayer = prim::GetAttr[name="0"](%1318)
  %1320 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18078.MobileBertAttention = prim::GetAttr[name="attention"](%117)
  %1321 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18094.Bottleneck = prim::GetAttr[name="bottleneck"](%117)
  %1322 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18093.BottleneckLayer = prim::GetAttr[name="attention"](%1321)
  %1323 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18090.BottleneckLayer = prim::GetAttr[name="input"](%1321)
  %1324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18089.NoNorm = prim::GetAttr[name="LayerNorm"](%1323)
  %1325 : __torch__.torch.nn.modules.linear.___torch_mangle_18088.Linear = prim::GetAttr[name="dense"](%1323)
  %1326 : Tensor = prim::GetAttr[name="bias"](%1325)
  %1327 : Tensor = prim::GetAttr[name="weight"](%1325)
  %1328 : Float(512:1, 128:512) = aten::t(%1327), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.92 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.50 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.92, %1326, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1331 : Tensor = prim::GetAttr[name="bias"](%1324)
  %1332 : Tensor = prim::GetAttr[name="weight"](%1324)
  %1333 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.50, %1332), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%1333, %1331, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1335 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18092.NoNorm = prim::GetAttr[name="LayerNorm"](%1322)
  %1336 : __torch__.torch.nn.modules.linear.___torch_mangle_18091.Linear = prim::GetAttr[name="dense"](%1322)
  %1337 : Tensor = prim::GetAttr[name="bias"](%1336)
  %1338 : Tensor = prim::GetAttr[name="weight"](%1336)
  %1339 : Float(512:1, 128:512) = aten::t(%1338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.93 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.93, %1337, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1342 : Tensor = prim::GetAttr[name="bias"](%1335)
  %1343 : Tensor = prim::GetAttr[name="weight"](%1335)
  %1344 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.51, %1343), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.122 : Float(17:1664, 13:128, 128:1) = aten::add(%1344, %1342, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1346 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.122, %residual_tensor.7)
  %1347 : Float(17:1664, 13:128, 128:1), %1348 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1346)
  %1349 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18077.MobileBertSelfOutput = prim::GetAttr[name="output"](%1320)
  %1350 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18074.MobileBertSelfAttention = prim::GetAttr[name="self"](%1320)
  %1351 : __torch__.torch.nn.modules.linear.___torch_mangle_18072.Linear = prim::GetAttr[name="value"](%1350)
  %1352 : __torch__.torch.nn.modules.linear.___torch_mangle_18071.Linear = prim::GetAttr[name="key"](%1350)
  %1353 : __torch__.torch.nn.modules.linear.___torch_mangle_18070.Linear = prim::GetAttr[name="query"](%1350)
  %1354 : Tensor = prim::GetAttr[name="bias"](%1353)
  %1355 : Tensor = prim::GetAttr[name="weight"](%1353)
  %1356 : Float(128:1, 128:128) = aten::t(%1355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %output.94 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1347, %1356), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %x.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.94, %1354, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1678:0
  %1359 : Tensor = prim::GetAttr[name="bias"](%1352)
  %1360 : Tensor = prim::GetAttr[name="weight"](%1352)
  %1361 : Float(128:1, 128:128) = aten::t(%1360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %output.95 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1347, %1361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %x.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.95, %1359, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1678:0
  %1364 : Tensor = prim::GetAttr[name="bias"](%1351)
  %1365 : Tensor = prim::GetAttr[name="weight"](%1351)
  %1366 : Float(512:1, 128:512) = aten::t(%1365), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %output.96 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1366), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %x.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.96, %1364, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1678:0
  %1369 : int = aten::size(%x.37, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1370 : int = aten::size(%x.37, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1371 : int[] = prim::ListConstruct(%1369, %1370, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.37, %1371), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1373 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %query_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.38, %1373), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1375 : int = aten::size(%x.39, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1376 : int = aten::size(%x.39, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1377 : int[] = prim::ListConstruct(%1375, %1376, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.39, %1377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1379 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %key_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.40, %1379), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1381 : int = aten::size(%x.41, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1382 : int = aten::size(%x.41, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1383 : int[] = prim::ListConstruct(%1381, %1382, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.41, %1383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1385 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %value_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.42, %1385), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1387 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.7, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.7, %1387), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.13, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.123 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.14, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.124 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.123, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.124, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.13 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.7, %value_layer.7), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:280:0
  %1394 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %1395 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.13, %1394), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1395, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %1397 : int = aten::size(%context_layer.14, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1398 : int = aten::size(%context_layer.14, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1399 : int[] = prim::ListConstruct(%1397, %1398, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %input.125 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.14, %1399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:283:0
  %1401 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18076.NoNorm = prim::GetAttr[name="LayerNorm"](%1349)
  %1402 : __torch__.torch.nn.modules.linear.___torch_mangle_18075.Linear = prim::GetAttr[name="dense"](%1349)
  %1403 : Tensor = prim::GetAttr[name="bias"](%1402)
  %1404 : Tensor = prim::GetAttr[name="weight"](%1402)
  %1405 : Float(128:1, 128:128) = aten::t(%1404), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %output.97 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.125, %1405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.97, %1403, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.52 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.31, %1348, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output # transformers/modeling_mobilebert.py:301:0
  %1409 : Tensor = prim::GetAttr[name="bias"](%1401)
  %1410 : Tensor = prim::GetAttr[name="weight"](%1401)
  %1411 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.52, %1410), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.126 : Float(17:1664, 13:128, 128:1) = aten::add(%1411, %1409, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1413 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18099.FFNOutput = prim::GetAttr[name="output"](%1319)
  %1414 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18096.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1319)
  %1415 : __torch__.torch.nn.modules.linear.___torch_mangle_18095.Linear = prim::GetAttr[name="dense"](%1414)
  %1416 : Tensor = prim::GetAttr[name="bias"](%1415)
  %1417 : Tensor = prim::GetAttr[name="weight"](%1415)
  %1418 : Float(128:1, 512:128) = aten::t(%1417), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.98 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.126, %1418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.127 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.98, %1416, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.128 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1422 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18098.NoNorm = prim::GetAttr[name="LayerNorm"](%1413)
  %1423 : __torch__.torch.nn.modules.linear.___torch_mangle_18097.Linear = prim::GetAttr[name="dense"](%1413)
  %1424 : Tensor = prim::GetAttr[name="bias"](%1423)
  %1425 : Tensor = prim::GetAttr[name="weight"](%1423)
  %1426 : Float(512:1, 128:512) = aten::t(%1425), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.99 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.128, %1426), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.32 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.99, %1424, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.53 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.32, %input.126, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1430 : Tensor = prim::GetAttr[name="bias"](%1422)
  %1431 : Tensor = prim::GetAttr[name="weight"](%1422)
  %1432 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.53, %1431), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.129 : Float(17:1664, 13:128, 128:1) = aten::add(%1432, %1430, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1434 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18105.FFNOutput = prim::GetAttr[name="output"](%1317)
  %1435 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18102.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1317)
  %1436 : __torch__.torch.nn.modules.linear.___torch_mangle_18101.Linear = prim::GetAttr[name="dense"](%1435)
  %1437 : Tensor = prim::GetAttr[name="bias"](%1436)
  %1438 : Tensor = prim::GetAttr[name="weight"](%1436)
  %1439 : Float(128:1, 512:128) = aten::t(%1438), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.100 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.129, %1439), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.130 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.100, %1437, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.131 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1443 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18104.NoNorm = prim::GetAttr[name="LayerNorm"](%1434)
  %1444 : __torch__.torch.nn.modules.linear.___torch_mangle_18103.Linear = prim::GetAttr[name="dense"](%1434)
  %1445 : Tensor = prim::GetAttr[name="bias"](%1444)
  %1446 : Tensor = prim::GetAttr[name="weight"](%1444)
  %1447 : Float(512:1, 128:512) = aten::t(%1446), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.101 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.131, %1447), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.101, %1445, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.54 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.33, %input.129, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1451 : Tensor = prim::GetAttr[name="bias"](%1443)
  %1452 : Tensor = prim::GetAttr[name="weight"](%1443)
  %1453 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.54, %1452), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.132 : Float(17:1664, 13:128, 128:1) = aten::add(%1453, %1451, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1455 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18111.FFNOutput = prim::GetAttr[name="output"](%1315)
  %1456 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18108.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1315)
  %1457 : __torch__.torch.nn.modules.linear.___torch_mangle_18107.Linear = prim::GetAttr[name="dense"](%1456)
  %1458 : Tensor = prim::GetAttr[name="bias"](%1457)
  %1459 : Tensor = prim::GetAttr[name="weight"](%1457)
  %1460 : Float(128:1, 512:128) = aten::t(%1459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.102 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.132, %1460), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.133 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.102, %1458, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.134 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1464 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18110.NoNorm = prim::GetAttr[name="LayerNorm"](%1455)
  %1465 : __torch__.torch.nn.modules.linear.___torch_mangle_18109.Linear = prim::GetAttr[name="dense"](%1455)
  %1466 : Tensor = prim::GetAttr[name="bias"](%1465)
  %1467 : Tensor = prim::GetAttr[name="weight"](%1465)
  %1468 : Float(512:1, 128:512) = aten::t(%1467), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.103 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.134, %1468), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.103, %1466, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.55 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.34, %input.132, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1472 : Tensor = prim::GetAttr[name="bias"](%1464)
  %1473 : Tensor = prim::GetAttr[name="weight"](%1464)
  %1474 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.55, %1473), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.135 : Float(17:1664, 13:128, 128:1) = aten::add(%1474, %1472, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1476 : __torch__.torch.nn.modules.linear.___torch_mangle_18079.Linear = prim::GetAttr[name="dense"](%1313)
  %1477 : Tensor = prim::GetAttr[name="bias"](%1476)
  %1478 : Tensor = prim::GetAttr[name="weight"](%1476)
  %1479 : Float(128:1, 512:128) = aten::t(%1478), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %output.104 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.135, %1479), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %input.136 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.104, %1477, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1678:0
  %input.137 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.136), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate # torch/nn/functional.py:1119:0
  %1483 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18086.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1312)
  %1484 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18082.NoNorm = prim::GetAttr[name="LayerNorm"](%1312)
  %1485 : __torch__.torch.nn.modules.linear.___torch_mangle_18081.Linear = prim::GetAttr[name="dense"](%1312)
  %1486 : Tensor = prim::GetAttr[name="bias"](%1485)
  %1487 : Tensor = prim::GetAttr[name="weight"](%1485)
  %1488 : Float(512:1, 128:512) = aten::t(%1487), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %output.105 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.137, %1488), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %layer_output.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.105, %1486, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.56 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.7, %input.135, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output # transformers/modeling_mobilebert.py:405:0
  %1492 : Tensor = prim::GetAttr[name="bias"](%1484)
  %1493 : Tensor = prim::GetAttr[name="weight"](%1484)
  %1494 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.56, %1493), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.138 : Float(17:1664, 13:128, 128:1) = aten::add(%1494, %1492, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1496 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18084.NoNorm = prim::GetAttr[name="LayerNorm"](%1483)
  %1497 : __torch__.torch.nn.modules.linear.___torch_mangle_18083.Linear = prim::GetAttr[name="dense"](%1483)
  %1498 : Tensor = prim::GetAttr[name="bias"](%1497)
  %1499 : Tensor = prim::GetAttr[name="weight"](%1497)
  %1500 : Float(128:1, 512:128) = aten::t(%1499), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.106 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.138, %1500), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.139 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.106, %1498, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.35 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.139, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.57 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.35, %input.121, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1505 : Tensor = prim::GetAttr[name="bias"](%1496)
  %1506 : Tensor = prim::GetAttr[name="weight"](%1496)
  %1507 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.57, %1506), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.140 : Float(17:6656, 13:512, 512:1) = aten::add(%1507, %1505, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1509 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18132.MobileBertOutput = prim::GetAttr[name="output"](%115)
  %1510 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18125.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%115)
  %1511 : __torch__.torch.nn.modules.container.___torch_mangle_18158.ModuleList = prim::GetAttr[name="ffn"](%115)
  %1512 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18157.FFNLayer = prim::GetAttr[name="2"](%1511)
  %1513 : __torch__.torch.nn.modules.container.___torch_mangle_18158.ModuleList = prim::GetAttr[name="ffn"](%115)
  %1514 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18151.FFNLayer = prim::GetAttr[name="1"](%1513)
  %1515 : __torch__.torch.nn.modules.container.___torch_mangle_18158.ModuleList = prim::GetAttr[name="ffn"](%115)
  %1516 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18145.FFNLayer = prim::GetAttr[name="0"](%1515)
  %1517 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18123.MobileBertAttention = prim::GetAttr[name="attention"](%115)
  %1518 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18139.Bottleneck = prim::GetAttr[name="bottleneck"](%115)
  %1519 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18138.BottleneckLayer = prim::GetAttr[name="attention"](%1518)
  %1520 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18135.BottleneckLayer = prim::GetAttr[name="input"](%1518)
  %1521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18134.NoNorm = prim::GetAttr[name="LayerNorm"](%1520)
  %1522 : __torch__.torch.nn.modules.linear.___torch_mangle_18133.Linear = prim::GetAttr[name="dense"](%1520)
  %1523 : Tensor = prim::GetAttr[name="bias"](%1522)
  %1524 : Tensor = prim::GetAttr[name="weight"](%1522)
  %1525 : Float(512:1, 128:512) = aten::t(%1524), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.107 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.107, %1523, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1528 : Tensor = prim::GetAttr[name="bias"](%1521)
  %1529 : Tensor = prim::GetAttr[name="weight"](%1521)
  %1530 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.58, %1529), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%1530, %1528, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1532 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18137.NoNorm = prim::GetAttr[name="LayerNorm"](%1519)
  %1533 : __torch__.torch.nn.modules.linear.___torch_mangle_18136.Linear = prim::GetAttr[name="dense"](%1519)
  %1534 : Tensor = prim::GetAttr[name="bias"](%1533)
  %1535 : Tensor = prim::GetAttr[name="weight"](%1533)
  %1536 : Float(512:1, 128:512) = aten::t(%1535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.108 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1536), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.108, %1534, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1539 : Tensor = prim::GetAttr[name="bias"](%1532)
  %1540 : Tensor = prim::GetAttr[name="weight"](%1532)
  %1541 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.59, %1540), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.141 : Float(17:1664, 13:128, 128:1) = aten::add(%1541, %1539, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1543 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.141, %residual_tensor.8)
  %1544 : Float(17:1664, 13:128, 128:1), %1545 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1543)
  %1546 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18122.MobileBertSelfOutput = prim::GetAttr[name="output"](%1517)
  %1547 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18119.MobileBertSelfAttention = prim::GetAttr[name="self"](%1517)
  %1548 : __torch__.torch.nn.modules.linear.___torch_mangle_18117.Linear = prim::GetAttr[name="value"](%1547)
  %1549 : __torch__.torch.nn.modules.linear.___torch_mangle_18116.Linear = prim::GetAttr[name="key"](%1547)
  %1550 : __torch__.torch.nn.modules.linear.___torch_mangle_18115.Linear = prim::GetAttr[name="query"](%1547)
  %1551 : Tensor = prim::GetAttr[name="bias"](%1550)
  %1552 : Tensor = prim::GetAttr[name="weight"](%1550)
  %1553 : Float(128:1, 128:128) = aten::t(%1552), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %output.109 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1544, %1553), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %x.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.109, %1551, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1678:0
  %1556 : Tensor = prim::GetAttr[name="bias"](%1549)
  %1557 : Tensor = prim::GetAttr[name="weight"](%1549)
  %1558 : Float(128:1, 128:128) = aten::t(%1557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %output.110 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1544, %1558), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %x.45 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.110, %1556, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1678:0
  %1561 : Tensor = prim::GetAttr[name="bias"](%1548)
  %1562 : Tensor = prim::GetAttr[name="weight"](%1548)
  %1563 : Float(512:1, 128:512) = aten::t(%1562), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %output.111 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1563), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %x.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.111, %1561, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1678:0
  %1566 : int = aten::size(%x.43, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1567 : int = aten::size(%x.43, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1568 : int[] = prim::ListConstruct(%1566, %1567, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.43, %1568), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1570 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %query_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.44, %1570), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1572 : int = aten::size(%x.45, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1573 : int = aten::size(%x.45, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1574 : int[] = prim::ListConstruct(%1572, %1573, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.45, %1574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1576 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %key_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.46, %1576), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1578 : int = aten::size(%x.47, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1579 : int = aten::size(%x.47, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1580 : int[] = prim::ListConstruct(%1578, %1579, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.48 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.47, %1580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1582 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %value_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.48, %1582), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1584 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.8, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.8, %1584), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.15, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.142 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.16, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.143 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.142, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.143, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.15 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.8, %value_layer.8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:280:0
  %1591 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %1592 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.15, %1591), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1592, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %1594 : int = aten::size(%context_layer.16, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1595 : int = aten::size(%context_layer.16, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1596 : int[] = prim::ListConstruct(%1594, %1595, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %input.144 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.16, %1596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:283:0
  %1598 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18121.NoNorm = prim::GetAttr[name="LayerNorm"](%1546)
  %1599 : __torch__.torch.nn.modules.linear.___torch_mangle_18120.Linear = prim::GetAttr[name="dense"](%1546)
  %1600 : Tensor = prim::GetAttr[name="bias"](%1599)
  %1601 : Tensor = prim::GetAttr[name="weight"](%1599)
  %1602 : Float(128:1, 128:128) = aten::t(%1601), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %output.112 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.144, %1602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.36 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.112, %1600, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.60 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.36, %1545, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output # transformers/modeling_mobilebert.py:301:0
  %1606 : Tensor = prim::GetAttr[name="bias"](%1598)
  %1607 : Tensor = prim::GetAttr[name="weight"](%1598)
  %1608 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.60, %1607), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.145 : Float(17:1664, 13:128, 128:1) = aten::add(%1608, %1606, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1610 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18144.FFNOutput = prim::GetAttr[name="output"](%1516)
  %1611 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18141.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1516)
  %1612 : __torch__.torch.nn.modules.linear.___torch_mangle_18140.Linear = prim::GetAttr[name="dense"](%1611)
  %1613 : Tensor = prim::GetAttr[name="bias"](%1612)
  %1614 : Tensor = prim::GetAttr[name="weight"](%1612)
  %1615 : Float(128:1, 512:128) = aten::t(%1614), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.113 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.145, %1615), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.146 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.113, %1613, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.147 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1619 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18143.NoNorm = prim::GetAttr[name="LayerNorm"](%1610)
  %1620 : __torch__.torch.nn.modules.linear.___torch_mangle_18142.Linear = prim::GetAttr[name="dense"](%1610)
  %1621 : Tensor = prim::GetAttr[name="bias"](%1620)
  %1622 : Tensor = prim::GetAttr[name="weight"](%1620)
  %1623 : Float(512:1, 128:512) = aten::t(%1622), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.114 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.147, %1623), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.114, %1621, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.61 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.37, %input.145, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1627 : Tensor = prim::GetAttr[name="bias"](%1619)
  %1628 : Tensor = prim::GetAttr[name="weight"](%1619)
  %1629 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.61, %1628), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.148 : Float(17:1664, 13:128, 128:1) = aten::add(%1629, %1627, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1631 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18150.FFNOutput = prim::GetAttr[name="output"](%1514)
  %1632 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18147.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1514)
  %1633 : __torch__.torch.nn.modules.linear.___torch_mangle_18146.Linear = prim::GetAttr[name="dense"](%1632)
  %1634 : Tensor = prim::GetAttr[name="bias"](%1633)
  %1635 : Tensor = prim::GetAttr[name="weight"](%1633)
  %1636 : Float(128:1, 512:128) = aten::t(%1635), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.115 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.148, %1636), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.149 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.115, %1634, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.150 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1640 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18149.NoNorm = prim::GetAttr[name="LayerNorm"](%1631)
  %1641 : __torch__.torch.nn.modules.linear.___torch_mangle_18148.Linear = prim::GetAttr[name="dense"](%1631)
  %1642 : Tensor = prim::GetAttr[name="bias"](%1641)
  %1643 : Tensor = prim::GetAttr[name="weight"](%1641)
  %1644 : Float(512:1, 128:512) = aten::t(%1643), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.116 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.150, %1644), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.38 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.116, %1642, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.62 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.38, %input.148, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1648 : Tensor = prim::GetAttr[name="bias"](%1640)
  %1649 : Tensor = prim::GetAttr[name="weight"](%1640)
  %1650 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.62, %1649), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.151 : Float(17:1664, 13:128, 128:1) = aten::add(%1650, %1648, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1652 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18156.FFNOutput = prim::GetAttr[name="output"](%1512)
  %1653 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18153.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1512)
  %1654 : __torch__.torch.nn.modules.linear.___torch_mangle_18152.Linear = prim::GetAttr[name="dense"](%1653)
  %1655 : Tensor = prim::GetAttr[name="bias"](%1654)
  %1656 : Tensor = prim::GetAttr[name="weight"](%1654)
  %1657 : Float(128:1, 512:128) = aten::t(%1656), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.117 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.151, %1657), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.152 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.117, %1655, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.153 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1661 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18155.NoNorm = prim::GetAttr[name="LayerNorm"](%1652)
  %1662 : __torch__.torch.nn.modules.linear.___torch_mangle_18154.Linear = prim::GetAttr[name="dense"](%1652)
  %1663 : Tensor = prim::GetAttr[name="bias"](%1662)
  %1664 : Tensor = prim::GetAttr[name="weight"](%1662)
  %1665 : Float(512:1, 128:512) = aten::t(%1664), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.118 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.153, %1665), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.118, %1663, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.63 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.39, %input.151, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1669 : Tensor = prim::GetAttr[name="bias"](%1661)
  %1670 : Tensor = prim::GetAttr[name="weight"](%1661)
  %1671 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.63, %1670), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.154 : Float(17:1664, 13:128, 128:1) = aten::add(%1671, %1669, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1673 : __torch__.torch.nn.modules.linear.___torch_mangle_18124.Linear = prim::GetAttr[name="dense"](%1510)
  %1674 : Tensor = prim::GetAttr[name="bias"](%1673)
  %1675 : Tensor = prim::GetAttr[name="weight"](%1673)
  %1676 : Float(128:1, 512:128) = aten::t(%1675), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %output.119 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.154, %1676), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %input.155 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.119, %1674, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1678:0
  %input.156 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate # torch/nn/functional.py:1119:0
  %1680 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18131.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1509)
  %1681 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18127.NoNorm = prim::GetAttr[name="LayerNorm"](%1509)
  %1682 : __torch__.torch.nn.modules.linear.___torch_mangle_18126.Linear = prim::GetAttr[name="dense"](%1509)
  %1683 : Tensor = prim::GetAttr[name="bias"](%1682)
  %1684 : Tensor = prim::GetAttr[name="weight"](%1682)
  %1685 : Float(512:1, 128:512) = aten::t(%1684), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %output.120 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.156, %1685), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %layer_output.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.120, %1683, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.64 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.8, %input.154, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output # transformers/modeling_mobilebert.py:405:0
  %1689 : Tensor = prim::GetAttr[name="bias"](%1681)
  %1690 : Tensor = prim::GetAttr[name="weight"](%1681)
  %1691 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.64, %1690), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.157 : Float(17:1664, 13:128, 128:1) = aten::add(%1691, %1689, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1693 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18129.NoNorm = prim::GetAttr[name="LayerNorm"](%1680)
  %1694 : __torch__.torch.nn.modules.linear.___torch_mangle_18128.Linear = prim::GetAttr[name="dense"](%1680)
  %1695 : Tensor = prim::GetAttr[name="bias"](%1694)
  %1696 : Tensor = prim::GetAttr[name="weight"](%1694)
  %1697 : Float(128:1, 512:128) = aten::t(%1696), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.121 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.157, %1697), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.158 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.121, %1695, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.40 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.158, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.65 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.40, %input.140, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1702 : Tensor = prim::GetAttr[name="bias"](%1693)
  %1703 : Tensor = prim::GetAttr[name="weight"](%1693)
  %1704 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.65, %1703), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.159 : Float(17:6656, 13:512, 512:1) = aten::add(%1704, %1702, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1706 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18177.MobileBertOutput = prim::GetAttr[name="output"](%113)
  %1707 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18170.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%113)
  %1708 : __torch__.torch.nn.modules.container.___torch_mangle_18203.ModuleList = prim::GetAttr[name="ffn"](%113)
  %1709 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18202.FFNLayer = prim::GetAttr[name="2"](%1708)
  %1710 : __torch__.torch.nn.modules.container.___torch_mangle_18203.ModuleList = prim::GetAttr[name="ffn"](%113)
  %1711 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18196.FFNLayer = prim::GetAttr[name="1"](%1710)
  %1712 : __torch__.torch.nn.modules.container.___torch_mangle_18203.ModuleList = prim::GetAttr[name="ffn"](%113)
  %1713 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18190.FFNLayer = prim::GetAttr[name="0"](%1712)
  %1714 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18168.MobileBertAttention = prim::GetAttr[name="attention"](%113)
  %1715 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18184.Bottleneck = prim::GetAttr[name="bottleneck"](%113)
  %1716 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18183.BottleneckLayer = prim::GetAttr[name="attention"](%1715)
  %1717 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18180.BottleneckLayer = prim::GetAttr[name="input"](%1715)
  %1718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18179.NoNorm = prim::GetAttr[name="LayerNorm"](%1717)
  %1719 : __torch__.torch.nn.modules.linear.___torch_mangle_18178.Linear = prim::GetAttr[name="dense"](%1717)
  %1720 : Tensor = prim::GetAttr[name="bias"](%1719)
  %1721 : Tensor = prim::GetAttr[name="weight"](%1719)
  %1722 : Float(512:1, 128:512) = aten::t(%1721), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.122 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.122, %1720, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1725 : Tensor = prim::GetAttr[name="bias"](%1718)
  %1726 : Tensor = prim::GetAttr[name="weight"](%1718)
  %1727 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.66, %1726), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.9 : Float(17:1664, 13:128, 128:1) = aten::add(%1727, %1725, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1729 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18182.NoNorm = prim::GetAttr[name="LayerNorm"](%1716)
  %1730 : __torch__.torch.nn.modules.linear.___torch_mangle_18181.Linear = prim::GetAttr[name="dense"](%1716)
  %1731 : Tensor = prim::GetAttr[name="bias"](%1730)
  %1732 : Tensor = prim::GetAttr[name="weight"](%1730)
  %1733 : Float(512:1, 128:512) = aten::t(%1732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.123 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1733), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.123, %1731, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1736 : Tensor = prim::GetAttr[name="bias"](%1729)
  %1737 : Tensor = prim::GetAttr[name="weight"](%1729)
  %1738 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.67, %1737), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.160 : Float(17:1664, 13:128, 128:1) = aten::add(%1738, %1736, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1740 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.160, %residual_tensor.9)
  %1741 : Float(17:1664, 13:128, 128:1), %1742 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1740)
  %1743 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18167.MobileBertSelfOutput = prim::GetAttr[name="output"](%1714)
  %1744 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18164.MobileBertSelfAttention = prim::GetAttr[name="self"](%1714)
  %1745 : __torch__.torch.nn.modules.linear.___torch_mangle_18162.Linear = prim::GetAttr[name="value"](%1744)
  %1746 : __torch__.torch.nn.modules.linear.___torch_mangle_18161.Linear = prim::GetAttr[name="key"](%1744)
  %1747 : __torch__.torch.nn.modules.linear.___torch_mangle_18160.Linear = prim::GetAttr[name="query"](%1744)
  %1748 : Tensor = prim::GetAttr[name="bias"](%1747)
  %1749 : Tensor = prim::GetAttr[name="weight"](%1747)
  %1750 : Float(128:1, 128:128) = aten::t(%1749), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %output.124 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1741, %1750), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %x.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.124, %1748, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1678:0
  %1753 : Tensor = prim::GetAttr[name="bias"](%1746)
  %1754 : Tensor = prim::GetAttr[name="weight"](%1746)
  %1755 : Float(128:1, 128:128) = aten::t(%1754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %output.125 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1741, %1755), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %x.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.125, %1753, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1678:0
  %1758 : Tensor = prim::GetAttr[name="bias"](%1745)
  %1759 : Tensor = prim::GetAttr[name="weight"](%1745)
  %1760 : Float(512:1, 128:512) = aten::t(%1759), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %output.126 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1760), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %x.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.126, %1758, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1678:0
  %1763 : int = aten::size(%x.49, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1764 : int = aten::size(%x.49, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1765 : int[] = prim::ListConstruct(%1763, %1764, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.50 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.49, %1765), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1767 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %query_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.50, %1767), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1769 : int = aten::size(%x.51, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1770 : int = aten::size(%x.51, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1771 : int[] = prim::ListConstruct(%1769, %1770, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.52 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.51, %1771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1773 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %key_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.52, %1773), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1775 : int = aten::size(%x.53, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1776 : int = aten::size(%x.53, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1777 : int[] = prim::ListConstruct(%1775, %1776, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.54 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.53, %1777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1779 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %value_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.54, %1779), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1781 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.9, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.9, %1781), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.17, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.161 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.18, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.162 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.161, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.162, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.17 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.9, %value_layer.9), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:280:0
  %1788 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %1789 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.17, %1788), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1789, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %1791 : int = aten::size(%context_layer.18, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1792 : int = aten::size(%context_layer.18, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1793 : int[] = prim::ListConstruct(%1791, %1792, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %input.163 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.18, %1793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:283:0
  %1795 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18166.NoNorm = prim::GetAttr[name="LayerNorm"](%1743)
  %1796 : __torch__.torch.nn.modules.linear.___torch_mangle_18165.Linear = prim::GetAttr[name="dense"](%1743)
  %1797 : Tensor = prim::GetAttr[name="bias"](%1796)
  %1798 : Tensor = prim::GetAttr[name="weight"](%1796)
  %1799 : Float(128:1, 128:128) = aten::t(%1798), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %output.127 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.163, %1799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.127, %1797, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.68 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.41, %1742, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output # transformers/modeling_mobilebert.py:301:0
  %1803 : Tensor = prim::GetAttr[name="bias"](%1795)
  %1804 : Tensor = prim::GetAttr[name="weight"](%1795)
  %1805 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.68, %1804), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.164 : Float(17:1664, 13:128, 128:1) = aten::add(%1805, %1803, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1807 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18189.FFNOutput = prim::GetAttr[name="output"](%1713)
  %1808 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18186.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1713)
  %1809 : __torch__.torch.nn.modules.linear.___torch_mangle_18185.Linear = prim::GetAttr[name="dense"](%1808)
  %1810 : Tensor = prim::GetAttr[name="bias"](%1809)
  %1811 : Tensor = prim::GetAttr[name="weight"](%1809)
  %1812 : Float(128:1, 512:128) = aten::t(%1811), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.128 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.164, %1812), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.165 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.128, %1810, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.166 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1816 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18188.NoNorm = prim::GetAttr[name="LayerNorm"](%1807)
  %1817 : __torch__.torch.nn.modules.linear.___torch_mangle_18187.Linear = prim::GetAttr[name="dense"](%1807)
  %1818 : Tensor = prim::GetAttr[name="bias"](%1817)
  %1819 : Tensor = prim::GetAttr[name="weight"](%1817)
  %1820 : Float(512:1, 128:512) = aten::t(%1819), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.129 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.166, %1820), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.129, %1818, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.69 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.42, %input.164, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1824 : Tensor = prim::GetAttr[name="bias"](%1816)
  %1825 : Tensor = prim::GetAttr[name="weight"](%1816)
  %1826 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.69, %1825), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.167 : Float(17:1664, 13:128, 128:1) = aten::add(%1826, %1824, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1828 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18195.FFNOutput = prim::GetAttr[name="output"](%1711)
  %1829 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18192.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1711)
  %1830 : __torch__.torch.nn.modules.linear.___torch_mangle_18191.Linear = prim::GetAttr[name="dense"](%1829)
  %1831 : Tensor = prim::GetAttr[name="bias"](%1830)
  %1832 : Tensor = prim::GetAttr[name="weight"](%1830)
  %1833 : Float(128:1, 512:128) = aten::t(%1832), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.130 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.167, %1833), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.168 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.130, %1831, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.169 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1837 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18194.NoNorm = prim::GetAttr[name="LayerNorm"](%1828)
  %1838 : __torch__.torch.nn.modules.linear.___torch_mangle_18193.Linear = prim::GetAttr[name="dense"](%1828)
  %1839 : Tensor = prim::GetAttr[name="bias"](%1838)
  %1840 : Tensor = prim::GetAttr[name="weight"](%1838)
  %1841 : Float(512:1, 128:512) = aten::t(%1840), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.131 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.169, %1841), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.131, %1839, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.70 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.43, %input.167, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1845 : Tensor = prim::GetAttr[name="bias"](%1837)
  %1846 : Tensor = prim::GetAttr[name="weight"](%1837)
  %1847 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.70, %1846), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.170 : Float(17:1664, 13:128, 128:1) = aten::add(%1847, %1845, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1849 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18201.FFNOutput = prim::GetAttr[name="output"](%1709)
  %1850 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18198.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1709)
  %1851 : __torch__.torch.nn.modules.linear.___torch_mangle_18197.Linear = prim::GetAttr[name="dense"](%1850)
  %1852 : Tensor = prim::GetAttr[name="bias"](%1851)
  %1853 : Tensor = prim::GetAttr[name="weight"](%1851)
  %1854 : Float(128:1, 512:128) = aten::t(%1853), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.132 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.170, %1854), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.171 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.132, %1852, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.172 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1858 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18200.NoNorm = prim::GetAttr[name="LayerNorm"](%1849)
  %1859 : __torch__.torch.nn.modules.linear.___torch_mangle_18199.Linear = prim::GetAttr[name="dense"](%1849)
  %1860 : Tensor = prim::GetAttr[name="bias"](%1859)
  %1861 : Tensor = prim::GetAttr[name="weight"](%1859)
  %1862 : Float(512:1, 128:512) = aten::t(%1861), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.133 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.172, %1862), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.44 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.133, %1860, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.71 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.44, %input.170, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1866 : Tensor = prim::GetAttr[name="bias"](%1858)
  %1867 : Tensor = prim::GetAttr[name="weight"](%1858)
  %1868 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.71, %1867), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.173 : Float(17:1664, 13:128, 128:1) = aten::add(%1868, %1866, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1870 : __torch__.torch.nn.modules.linear.___torch_mangle_18169.Linear = prim::GetAttr[name="dense"](%1707)
  %1871 : Tensor = prim::GetAttr[name="bias"](%1870)
  %1872 : Tensor = prim::GetAttr[name="weight"](%1870)
  %1873 : Float(128:1, 512:128) = aten::t(%1872), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %output.134 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.173, %1873), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %input.174 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.134, %1871, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1678:0
  %input.175 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate # torch/nn/functional.py:1119:0
  %1877 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18176.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1706)
  %1878 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18172.NoNorm = prim::GetAttr[name="LayerNorm"](%1706)
  %1879 : __torch__.torch.nn.modules.linear.___torch_mangle_18171.Linear = prim::GetAttr[name="dense"](%1706)
  %1880 : Tensor = prim::GetAttr[name="bias"](%1879)
  %1881 : Tensor = prim::GetAttr[name="weight"](%1879)
  %1882 : Float(512:1, 128:512) = aten::t(%1881), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %output.135 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.175, %1882), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %layer_output.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.135, %1880, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.72 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.9, %input.173, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output # transformers/modeling_mobilebert.py:405:0
  %1886 : Tensor = prim::GetAttr[name="bias"](%1878)
  %1887 : Tensor = prim::GetAttr[name="weight"](%1878)
  %1888 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.72, %1887), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.176 : Float(17:1664, 13:128, 128:1) = aten::add(%1888, %1886, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1890 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18174.NoNorm = prim::GetAttr[name="LayerNorm"](%1877)
  %1891 : __torch__.torch.nn.modules.linear.___torch_mangle_18173.Linear = prim::GetAttr[name="dense"](%1877)
  %1892 : Tensor = prim::GetAttr[name="bias"](%1891)
  %1893 : Tensor = prim::GetAttr[name="weight"](%1891)
  %1894 : Float(128:1, 512:128) = aten::t(%1893), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.136 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.176, %1894), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.177 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.136, %1892, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.45 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.177, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.73 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.45, %input.159, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1899 : Tensor = prim::GetAttr[name="bias"](%1890)
  %1900 : Tensor = prim::GetAttr[name="weight"](%1890)
  %1901 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.73, %1900), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.178 : Float(17:6656, 13:512, 512:1) = aten::add(%1901, %1899, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1903 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18222.MobileBertOutput = prim::GetAttr[name="output"](%111)
  %1904 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18215.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%111)
  %1905 : __torch__.torch.nn.modules.container.___torch_mangle_18248.ModuleList = prim::GetAttr[name="ffn"](%111)
  %1906 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18247.FFNLayer = prim::GetAttr[name="2"](%1905)
  %1907 : __torch__.torch.nn.modules.container.___torch_mangle_18248.ModuleList = prim::GetAttr[name="ffn"](%111)
  %1908 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18241.FFNLayer = prim::GetAttr[name="1"](%1907)
  %1909 : __torch__.torch.nn.modules.container.___torch_mangle_18248.ModuleList = prim::GetAttr[name="ffn"](%111)
  %1910 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18235.FFNLayer = prim::GetAttr[name="0"](%1909)
  %1911 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18213.MobileBertAttention = prim::GetAttr[name="attention"](%111)
  %1912 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18229.Bottleneck = prim::GetAttr[name="bottleneck"](%111)
  %1913 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18228.BottleneckLayer = prim::GetAttr[name="attention"](%1912)
  %1914 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18225.BottleneckLayer = prim::GetAttr[name="input"](%1912)
  %1915 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18224.NoNorm = prim::GetAttr[name="LayerNorm"](%1914)
  %1916 : __torch__.torch.nn.modules.linear.___torch_mangle_18223.Linear = prim::GetAttr[name="dense"](%1914)
  %1917 : Tensor = prim::GetAttr[name="bias"](%1916)
  %1918 : Tensor = prim::GetAttr[name="weight"](%1916)
  %1919 : Float(512:1, 128:512) = aten::t(%1918), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.137 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1919), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.137, %1917, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1922 : Tensor = prim::GetAttr[name="bias"](%1915)
  %1923 : Tensor = prim::GetAttr[name="weight"](%1915)
  %1924 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.74, %1923), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add(%1924, %1922, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1926 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18227.NoNorm = prim::GetAttr[name="LayerNorm"](%1913)
  %1927 : __torch__.torch.nn.modules.linear.___torch_mangle_18226.Linear = prim::GetAttr[name="dense"](%1913)
  %1928 : Tensor = prim::GetAttr[name="bias"](%1927)
  %1929 : Tensor = prim::GetAttr[name="weight"](%1927)
  %1930 : Float(512:1, 128:512) = aten::t(%1929), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.138 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1930), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.138, %1928, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1933 : Tensor = prim::GetAttr[name="bias"](%1926)
  %1934 : Tensor = prim::GetAttr[name="weight"](%1926)
  %1935 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.75, %1934), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.179 : Float(17:1664, 13:128, 128:1) = aten::add(%1935, %1933, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1937 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.179, %residual_tensor.10)
  %1938 : Float(17:1664, 13:128, 128:1), %1939 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1937)
  %1940 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18212.MobileBertSelfOutput = prim::GetAttr[name="output"](%1911)
  %1941 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18209.MobileBertSelfAttention = prim::GetAttr[name="self"](%1911)
  %1942 : __torch__.torch.nn.modules.linear.___torch_mangle_18207.Linear = prim::GetAttr[name="value"](%1941)
  %1943 : __torch__.torch.nn.modules.linear.___torch_mangle_18206.Linear = prim::GetAttr[name="key"](%1941)
  %1944 : __torch__.torch.nn.modules.linear.___torch_mangle_18205.Linear = prim::GetAttr[name="query"](%1941)
  %1945 : Tensor = prim::GetAttr[name="bias"](%1944)
  %1946 : Tensor = prim::GetAttr[name="weight"](%1944)
  %1947 : Float(128:1, 128:128) = aten::t(%1946), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %output.139 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1938, %1947), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %x.55 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.139, %1945, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1678:0
  %1950 : Tensor = prim::GetAttr[name="bias"](%1943)
  %1951 : Tensor = prim::GetAttr[name="weight"](%1943)
  %1952 : Float(128:1, 128:128) = aten::t(%1951), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %output.140 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1938, %1952), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %x.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.140, %1950, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1678:0
  %1955 : Tensor = prim::GetAttr[name="bias"](%1942)
  %1956 : Tensor = prim::GetAttr[name="weight"](%1942)
  %1957 : Float(512:1, 128:512) = aten::t(%1956), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %output.141 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1957), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %x.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.141, %1955, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1678:0
  %1960 : int = aten::size(%x.55, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1961 : int = aten::size(%x.55, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1962 : int[] = prim::ListConstruct(%1960, %1961, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.56 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.55, %1962), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1964 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %query_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.56, %1964), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1966 : int = aten::size(%x.57, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1967 : int = aten::size(%x.57, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1968 : int[] = prim::ListConstruct(%1966, %1967, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.58 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.57, %1968), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1970 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %key_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.58, %1970), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1972 : int = aten::size(%x.59, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1973 : int = aten::size(%x.59, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1974 : int[] = prim::ListConstruct(%1972, %1973, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.60 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.59, %1974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1976 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %value_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.60, %1976), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1978 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.10, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.10, %1978), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.19, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.180 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.20, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.181 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.180, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.181, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.19 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.10, %value_layer.10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:280:0
  %1985 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %1986 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.19, %1985), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1986, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %1988 : int = aten::size(%context_layer.20, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1989 : int = aten::size(%context_layer.20, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1990 : int[] = prim::ListConstruct(%1988, %1989, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %input.182 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.20, %1990), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:283:0
  %1992 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18211.NoNorm = prim::GetAttr[name="LayerNorm"](%1940)
  %1993 : __torch__.torch.nn.modules.linear.___torch_mangle_18210.Linear = prim::GetAttr[name="dense"](%1940)
  %1994 : Tensor = prim::GetAttr[name="bias"](%1993)
  %1995 : Tensor = prim::GetAttr[name="weight"](%1993)
  %1996 : Float(128:1, 128:128) = aten::t(%1995), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %output.142 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.182, %1996), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.46 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.142, %1994, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.76 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.46, %1939, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output # transformers/modeling_mobilebert.py:301:0
  %2000 : Tensor = prim::GetAttr[name="bias"](%1992)
  %2001 : Tensor = prim::GetAttr[name="weight"](%1992)
  %2002 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.76, %2001), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.183 : Float(17:1664, 13:128, 128:1) = aten::add(%2002, %2000, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2004 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18234.FFNOutput = prim::GetAttr[name="output"](%1910)
  %2005 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18231.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1910)
  %2006 : __torch__.torch.nn.modules.linear.___torch_mangle_18230.Linear = prim::GetAttr[name="dense"](%2005)
  %2007 : Tensor = prim::GetAttr[name="bias"](%2006)
  %2008 : Tensor = prim::GetAttr[name="weight"](%2006)
  %2009 : Float(128:1, 512:128) = aten::t(%2008), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.143 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.183, %2009), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.184 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.143, %2007, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.185 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2013 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18233.NoNorm = prim::GetAttr[name="LayerNorm"](%2004)
  %2014 : __torch__.torch.nn.modules.linear.___torch_mangle_18232.Linear = prim::GetAttr[name="dense"](%2004)
  %2015 : Tensor = prim::GetAttr[name="bias"](%2014)
  %2016 : Tensor = prim::GetAttr[name="weight"](%2014)
  %2017 : Float(512:1, 128:512) = aten::t(%2016), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.144 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.185, %2017), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.144, %2015, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.77 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.47, %input.183, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2021 : Tensor = prim::GetAttr[name="bias"](%2013)
  %2022 : Tensor = prim::GetAttr[name="weight"](%2013)
  %2023 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.77, %2022), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.186 : Float(17:1664, 13:128, 128:1) = aten::add(%2023, %2021, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2025 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18240.FFNOutput = prim::GetAttr[name="output"](%1908)
  %2026 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18237.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1908)
  %2027 : __torch__.torch.nn.modules.linear.___torch_mangle_18236.Linear = prim::GetAttr[name="dense"](%2026)
  %2028 : Tensor = prim::GetAttr[name="bias"](%2027)
  %2029 : Tensor = prim::GetAttr[name="weight"](%2027)
  %2030 : Float(128:1, 512:128) = aten::t(%2029), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.145 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.186, %2030), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.187 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.145, %2028, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.188 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2034 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18239.NoNorm = prim::GetAttr[name="LayerNorm"](%2025)
  %2035 : __torch__.torch.nn.modules.linear.___torch_mangle_18238.Linear = prim::GetAttr[name="dense"](%2025)
  %2036 : Tensor = prim::GetAttr[name="bias"](%2035)
  %2037 : Tensor = prim::GetAttr[name="weight"](%2035)
  %2038 : Float(512:1, 128:512) = aten::t(%2037), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.146 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.188, %2038), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.48 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.146, %2036, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.78 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.48, %input.186, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2042 : Tensor = prim::GetAttr[name="bias"](%2034)
  %2043 : Tensor = prim::GetAttr[name="weight"](%2034)
  %2044 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.78, %2043), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.189 : Float(17:1664, 13:128, 128:1) = aten::add(%2044, %2042, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2046 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18246.FFNOutput = prim::GetAttr[name="output"](%1906)
  %2047 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18243.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1906)
  %2048 : __torch__.torch.nn.modules.linear.___torch_mangle_18242.Linear = prim::GetAttr[name="dense"](%2047)
  %2049 : Tensor = prim::GetAttr[name="bias"](%2048)
  %2050 : Tensor = prim::GetAttr[name="weight"](%2048)
  %2051 : Float(128:1, 512:128) = aten::t(%2050), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.147 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.189, %2051), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.190 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.147, %2049, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.191 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2055 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18245.NoNorm = prim::GetAttr[name="LayerNorm"](%2046)
  %2056 : __torch__.torch.nn.modules.linear.___torch_mangle_18244.Linear = prim::GetAttr[name="dense"](%2046)
  %2057 : Tensor = prim::GetAttr[name="bias"](%2056)
  %2058 : Tensor = prim::GetAttr[name="weight"](%2056)
  %2059 : Float(512:1, 128:512) = aten::t(%2058), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.148 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.191, %2059), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.148, %2057, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.79 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.49, %input.189, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2063 : Tensor = prim::GetAttr[name="bias"](%2055)
  %2064 : Tensor = prim::GetAttr[name="weight"](%2055)
  %2065 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.79, %2064), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.192 : Float(17:1664, 13:128, 128:1) = aten::add(%2065, %2063, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2067 : __torch__.torch.nn.modules.linear.___torch_mangle_18214.Linear = prim::GetAttr[name="dense"](%1904)
  %2068 : Tensor = prim::GetAttr[name="bias"](%2067)
  %2069 : Tensor = prim::GetAttr[name="weight"](%2067)
  %2070 : Float(128:1, 512:128) = aten::t(%2069), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %output.149 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.192, %2070), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %input.193 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.149, %2068, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1678:0
  %input.194 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate # torch/nn/functional.py:1119:0
  %2074 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18221.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1903)
  %2075 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18217.NoNorm = prim::GetAttr[name="LayerNorm"](%1903)
  %2076 : __torch__.torch.nn.modules.linear.___torch_mangle_18216.Linear = prim::GetAttr[name="dense"](%1903)
  %2077 : Tensor = prim::GetAttr[name="bias"](%2076)
  %2078 : Tensor = prim::GetAttr[name="weight"](%2076)
  %2079 : Float(512:1, 128:512) = aten::t(%2078), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %output.150 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.194, %2079), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %layer_output.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.150, %2077, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.80 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.10, %input.192, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output # transformers/modeling_mobilebert.py:405:0
  %2083 : Tensor = prim::GetAttr[name="bias"](%2075)
  %2084 : Tensor = prim::GetAttr[name="weight"](%2075)
  %2085 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.80, %2084), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.195 : Float(17:1664, 13:128, 128:1) = aten::add(%2085, %2083, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2087 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18219.NoNorm = prim::GetAttr[name="LayerNorm"](%2074)
  %2088 : __torch__.torch.nn.modules.linear.___torch_mangle_18218.Linear = prim::GetAttr[name="dense"](%2074)
  %2089 : Tensor = prim::GetAttr[name="bias"](%2088)
  %2090 : Tensor = prim::GetAttr[name="weight"](%2088)
  %2091 : Float(128:1, 512:128) = aten::t(%2090), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.151 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.195, %2091), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.196 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.151, %2089, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.50 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.196, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.81 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.50, %input.178, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2096 : Tensor = prim::GetAttr[name="bias"](%2087)
  %2097 : Tensor = prim::GetAttr[name="weight"](%2087)
  %2098 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.81, %2097), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.197 : Float(17:6656, 13:512, 512:1) = aten::add(%2098, %2096, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2100 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18267.MobileBertOutput = prim::GetAttr[name="output"](%109)
  %2101 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18260.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%109)
  %2102 : __torch__.torch.nn.modules.container.___torch_mangle_18293.ModuleList = prim::GetAttr[name="ffn"](%109)
  %2103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18292.FFNLayer = prim::GetAttr[name="2"](%2102)
  %2104 : __torch__.torch.nn.modules.container.___torch_mangle_18293.ModuleList = prim::GetAttr[name="ffn"](%109)
  %2105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18286.FFNLayer = prim::GetAttr[name="1"](%2104)
  %2106 : __torch__.torch.nn.modules.container.___torch_mangle_18293.ModuleList = prim::GetAttr[name="ffn"](%109)
  %2107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18280.FFNLayer = prim::GetAttr[name="0"](%2106)
  %2108 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18258.MobileBertAttention = prim::GetAttr[name="attention"](%109)
  %2109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18274.Bottleneck = prim::GetAttr[name="bottleneck"](%109)
  %2110 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18273.BottleneckLayer = prim::GetAttr[name="attention"](%2109)
  %2111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18270.BottleneckLayer = prim::GetAttr[name="input"](%2109)
  %2112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18269.NoNorm = prim::GetAttr[name="LayerNorm"](%2111)
  %2113 : __torch__.torch.nn.modules.linear.___torch_mangle_18268.Linear = prim::GetAttr[name="dense"](%2111)
  %2114 : Tensor = prim::GetAttr[name="bias"](%2113)
  %2115 : Tensor = prim::GetAttr[name="weight"](%2113)
  %2116 : Float(512:1, 128:512) = aten::t(%2115), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.152 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2116), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.152, %2114, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2119 : Tensor = prim::GetAttr[name="bias"](%2112)
  %2120 : Tensor = prim::GetAttr[name="weight"](%2112)
  %2121 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.82, %2120), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add(%2121, %2119, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2123 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18272.NoNorm = prim::GetAttr[name="LayerNorm"](%2110)
  %2124 : __torch__.torch.nn.modules.linear.___torch_mangle_18271.Linear = prim::GetAttr[name="dense"](%2110)
  %2125 : Tensor = prim::GetAttr[name="bias"](%2124)
  %2126 : Tensor = prim::GetAttr[name="weight"](%2124)
  %2127 : Float(512:1, 128:512) = aten::t(%2126), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.153 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.153, %2125, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2130 : Tensor = prim::GetAttr[name="bias"](%2123)
  %2131 : Tensor = prim::GetAttr[name="weight"](%2123)
  %2132 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.83, %2131), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.198 : Float(17:1664, 13:128, 128:1) = aten::add(%2132, %2130, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2134 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.198, %residual_tensor.11)
  %2135 : Float(17:1664, 13:128, 128:1), %2136 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2134)
  %2137 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18257.MobileBertSelfOutput = prim::GetAttr[name="output"](%2108)
  %2138 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18254.MobileBertSelfAttention = prim::GetAttr[name="self"](%2108)
  %2139 : __torch__.torch.nn.modules.linear.___torch_mangle_18252.Linear = prim::GetAttr[name="value"](%2138)
  %2140 : __torch__.torch.nn.modules.linear.___torch_mangle_18251.Linear = prim::GetAttr[name="key"](%2138)
  %2141 : __torch__.torch.nn.modules.linear.___torch_mangle_18250.Linear = prim::GetAttr[name="query"](%2138)
  %2142 : Tensor = prim::GetAttr[name="bias"](%2141)
  %2143 : Tensor = prim::GetAttr[name="weight"](%2141)
  %2144 : Float(128:1, 128:128) = aten::t(%2143), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %output.154 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2135, %2144), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %x.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.154, %2142, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1678:0
  %2147 : Tensor = prim::GetAttr[name="bias"](%2140)
  %2148 : Tensor = prim::GetAttr[name="weight"](%2140)
  %2149 : Float(128:1, 128:128) = aten::t(%2148), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %output.155 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2135, %2149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %x.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.155, %2147, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1678:0
  %2152 : Tensor = prim::GetAttr[name="bias"](%2139)
  %2153 : Tensor = prim::GetAttr[name="weight"](%2139)
  %2154 : Float(512:1, 128:512) = aten::t(%2153), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %output.156 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %x.65 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.156, %2152, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1678:0
  %2157 : int = aten::size(%x.61, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2158 : int = aten::size(%x.61, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2159 : int[] = prim::ListConstruct(%2157, %2158, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.62 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.61, %2159), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2161 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %query_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.62, %2161), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2163 : int = aten::size(%x.63, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2164 : int = aten::size(%x.63, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2165 : int[] = prim::ListConstruct(%2163, %2164, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.64 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.63, %2165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2167 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %key_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.64, %2167), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2169 : int = aten::size(%x.65, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2170 : int = aten::size(%x.65, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2171 : int[] = prim::ListConstruct(%2169, %2170, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.66 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.65, %2171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2173 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %value_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.66, %2173), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2175 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.11, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.11, %2175), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.21, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.199 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.22, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.200 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.199, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.200, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.21 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.11, %value_layer.11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:280:0
  %2182 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %2183 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.21, %2182), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2183, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %2185 : int = aten::size(%context_layer.22, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2186 : int = aten::size(%context_layer.22, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2187 : int[] = prim::ListConstruct(%2185, %2186, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %input.201 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.22, %2187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:283:0
  %2189 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18256.NoNorm = prim::GetAttr[name="LayerNorm"](%2137)
  %2190 : __torch__.torch.nn.modules.linear.___torch_mangle_18255.Linear = prim::GetAttr[name="dense"](%2137)
  %2191 : Tensor = prim::GetAttr[name="bias"](%2190)
  %2192 : Tensor = prim::GetAttr[name="weight"](%2190)
  %2193 : Float(128:1, 128:128) = aten::t(%2192), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %output.157 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.201, %2193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.157, %2191, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.84 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.51, %2136, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output # transformers/modeling_mobilebert.py:301:0
  %2197 : Tensor = prim::GetAttr[name="bias"](%2189)
  %2198 : Tensor = prim::GetAttr[name="weight"](%2189)
  %2199 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.84, %2198), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.202 : Float(17:1664, 13:128, 128:1) = aten::add(%2199, %2197, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2201 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18279.FFNOutput = prim::GetAttr[name="output"](%2107)
  %2202 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18276.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2107)
  %2203 : __torch__.torch.nn.modules.linear.___torch_mangle_18275.Linear = prim::GetAttr[name="dense"](%2202)
  %2204 : Tensor = prim::GetAttr[name="bias"](%2203)
  %2205 : Tensor = prim::GetAttr[name="weight"](%2203)
  %2206 : Float(128:1, 512:128) = aten::t(%2205), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.158 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.202, %2206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.203 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.158, %2204, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.204 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2210 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18278.NoNorm = prim::GetAttr[name="LayerNorm"](%2201)
  %2211 : __torch__.torch.nn.modules.linear.___torch_mangle_18277.Linear = prim::GetAttr[name="dense"](%2201)
  %2212 : Tensor = prim::GetAttr[name="bias"](%2211)
  %2213 : Tensor = prim::GetAttr[name="weight"](%2211)
  %2214 : Float(512:1, 128:512) = aten::t(%2213), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.159 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.204, %2214), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.52 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.159, %2212, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.85 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.52, %input.202, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2218 : Tensor = prim::GetAttr[name="bias"](%2210)
  %2219 : Tensor = prim::GetAttr[name="weight"](%2210)
  %2220 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.85, %2219), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.205 : Float(17:1664, 13:128, 128:1) = aten::add(%2220, %2218, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2222 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18285.FFNOutput = prim::GetAttr[name="output"](%2105)
  %2223 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18282.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2105)
  %2224 : __torch__.torch.nn.modules.linear.___torch_mangle_18281.Linear = prim::GetAttr[name="dense"](%2223)
  %2225 : Tensor = prim::GetAttr[name="bias"](%2224)
  %2226 : Tensor = prim::GetAttr[name="weight"](%2224)
  %2227 : Float(128:1, 512:128) = aten::t(%2226), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.160 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.205, %2227), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.206 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.160, %2225, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.207 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2231 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18284.NoNorm = prim::GetAttr[name="LayerNorm"](%2222)
  %2232 : __torch__.torch.nn.modules.linear.___torch_mangle_18283.Linear = prim::GetAttr[name="dense"](%2222)
  %2233 : Tensor = prim::GetAttr[name="bias"](%2232)
  %2234 : Tensor = prim::GetAttr[name="weight"](%2232)
  %2235 : Float(512:1, 128:512) = aten::t(%2234), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.161 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.207, %2235), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.161, %2233, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.86 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.53, %input.205, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2239 : Tensor = prim::GetAttr[name="bias"](%2231)
  %2240 : Tensor = prim::GetAttr[name="weight"](%2231)
  %2241 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.86, %2240), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.208 : Float(17:1664, 13:128, 128:1) = aten::add(%2241, %2239, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2243 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18291.FFNOutput = prim::GetAttr[name="output"](%2103)
  %2244 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18288.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2103)
  %2245 : __torch__.torch.nn.modules.linear.___torch_mangle_18287.Linear = prim::GetAttr[name="dense"](%2244)
  %2246 : Tensor = prim::GetAttr[name="bias"](%2245)
  %2247 : Tensor = prim::GetAttr[name="weight"](%2245)
  %2248 : Float(128:1, 512:128) = aten::t(%2247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.162 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.208, %2248), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.209 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.162, %2246, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.210 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2252 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18290.NoNorm = prim::GetAttr[name="LayerNorm"](%2243)
  %2253 : __torch__.torch.nn.modules.linear.___torch_mangle_18289.Linear = prim::GetAttr[name="dense"](%2243)
  %2254 : Tensor = prim::GetAttr[name="bias"](%2253)
  %2255 : Tensor = prim::GetAttr[name="weight"](%2253)
  %2256 : Float(512:1, 128:512) = aten::t(%2255), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.163 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.210, %2256), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.54 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.163, %2254, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.87 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.54, %input.208, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2260 : Tensor = prim::GetAttr[name="bias"](%2252)
  %2261 : Tensor = prim::GetAttr[name="weight"](%2252)
  %2262 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.87, %2261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.211 : Float(17:1664, 13:128, 128:1) = aten::add(%2262, %2260, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2264 : __torch__.torch.nn.modules.linear.___torch_mangle_18259.Linear = prim::GetAttr[name="dense"](%2101)
  %2265 : Tensor = prim::GetAttr[name="bias"](%2264)
  %2266 : Tensor = prim::GetAttr[name="weight"](%2264)
  %2267 : Float(128:1, 512:128) = aten::t(%2266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %output.164 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.211, %2267), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %input.212 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.164, %2265, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1678:0
  %input.213 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate # torch/nn/functional.py:1119:0
  %2271 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18266.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2100)
  %2272 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18262.NoNorm = prim::GetAttr[name="LayerNorm"](%2100)
  %2273 : __torch__.torch.nn.modules.linear.___torch_mangle_18261.Linear = prim::GetAttr[name="dense"](%2100)
  %2274 : Tensor = prim::GetAttr[name="bias"](%2273)
  %2275 : Tensor = prim::GetAttr[name="weight"](%2273)
  %2276 : Float(512:1, 128:512) = aten::t(%2275), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %output.165 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.213, %2276), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %layer_output.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.165, %2274, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.88 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.11, %input.211, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output # transformers/modeling_mobilebert.py:405:0
  %2280 : Tensor = prim::GetAttr[name="bias"](%2272)
  %2281 : Tensor = prim::GetAttr[name="weight"](%2272)
  %2282 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.88, %2281), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.214 : Float(17:1664, 13:128, 128:1) = aten::add(%2282, %2280, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2284 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18264.NoNorm = prim::GetAttr[name="LayerNorm"](%2271)
  %2285 : __torch__.torch.nn.modules.linear.___torch_mangle_18263.Linear = prim::GetAttr[name="dense"](%2271)
  %2286 : Tensor = prim::GetAttr[name="bias"](%2285)
  %2287 : Tensor = prim::GetAttr[name="weight"](%2285)
  %2288 : Float(128:1, 512:128) = aten::t(%2287), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.166 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.214, %2288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.215 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.166, %2286, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.55 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.215, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.89 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.55, %input.197, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2293 : Tensor = prim::GetAttr[name="bias"](%2284)
  %2294 : Tensor = prim::GetAttr[name="weight"](%2284)
  %2295 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.89, %2294), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.216 : Float(17:6656, 13:512, 512:1) = aten::add(%2295, %2293, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2297 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18312.MobileBertOutput = prim::GetAttr[name="output"](%107)
  %2298 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18305.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%107)
  %2299 : __torch__.torch.nn.modules.container.___torch_mangle_18338.ModuleList = prim::GetAttr[name="ffn"](%107)
  %2300 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18337.FFNLayer = prim::GetAttr[name="2"](%2299)
  %2301 : __torch__.torch.nn.modules.container.___torch_mangle_18338.ModuleList = prim::GetAttr[name="ffn"](%107)
  %2302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18331.FFNLayer = prim::GetAttr[name="1"](%2301)
  %2303 : __torch__.torch.nn.modules.container.___torch_mangle_18338.ModuleList = prim::GetAttr[name="ffn"](%107)
  %2304 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18325.FFNLayer = prim::GetAttr[name="0"](%2303)
  %2305 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18303.MobileBertAttention = prim::GetAttr[name="attention"](%107)
  %2306 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18319.Bottleneck = prim::GetAttr[name="bottleneck"](%107)
  %2307 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18318.BottleneckLayer = prim::GetAttr[name="attention"](%2306)
  %2308 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18315.BottleneckLayer = prim::GetAttr[name="input"](%2306)
  %2309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18314.NoNorm = prim::GetAttr[name="LayerNorm"](%2308)
  %2310 : __torch__.torch.nn.modules.linear.___torch_mangle_18313.Linear = prim::GetAttr[name="dense"](%2308)
  %2311 : Tensor = prim::GetAttr[name="bias"](%2310)
  %2312 : Tensor = prim::GetAttr[name="weight"](%2310)
  %2313 : Float(512:1, 128:512) = aten::t(%2312), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.167 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.90 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.167, %2311, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2316 : Tensor = prim::GetAttr[name="bias"](%2309)
  %2317 : Tensor = prim::GetAttr[name="weight"](%2309)
  %2318 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.90, %2317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%2318, %2316, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2320 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18317.NoNorm = prim::GetAttr[name="LayerNorm"](%2307)
  %2321 : __torch__.torch.nn.modules.linear.___torch_mangle_18316.Linear = prim::GetAttr[name="dense"](%2307)
  %2322 : Tensor = prim::GetAttr[name="bias"](%2321)
  %2323 : Tensor = prim::GetAttr[name="weight"](%2321)
  %2324 : Float(512:1, 128:512) = aten::t(%2323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.168 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2324), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.168, %2322, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2327 : Tensor = prim::GetAttr[name="bias"](%2320)
  %2328 : Tensor = prim::GetAttr[name="weight"](%2320)
  %2329 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.91, %2328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.217 : Float(17:1664, 13:128, 128:1) = aten::add(%2329, %2327, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2331 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.217, %residual_tensor.12)
  %2332 : Float(17:1664, 13:128, 128:1), %2333 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2331)
  %2334 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18302.MobileBertSelfOutput = prim::GetAttr[name="output"](%2305)
  %2335 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18299.MobileBertSelfAttention = prim::GetAttr[name="self"](%2305)
  %2336 : __torch__.torch.nn.modules.linear.___torch_mangle_18297.Linear = prim::GetAttr[name="value"](%2335)
  %2337 : __torch__.torch.nn.modules.linear.___torch_mangle_18296.Linear = prim::GetAttr[name="key"](%2335)
  %2338 : __torch__.torch.nn.modules.linear.___torch_mangle_18295.Linear = prim::GetAttr[name="query"](%2335)
  %2339 : Tensor = prim::GetAttr[name="bias"](%2338)
  %2340 : Tensor = prim::GetAttr[name="weight"](%2338)
  %2341 : Float(128:1, 128:128) = aten::t(%2340), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %output.169 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2332, %2341), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %x.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.169, %2339, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1678:0
  %2344 : Tensor = prim::GetAttr[name="bias"](%2337)
  %2345 : Tensor = prim::GetAttr[name="weight"](%2337)
  %2346 : Float(128:1, 128:128) = aten::t(%2345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %output.170 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2332, %2346), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %x.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.170, %2344, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1678:0
  %2349 : Tensor = prim::GetAttr[name="bias"](%2336)
  %2350 : Tensor = prim::GetAttr[name="weight"](%2336)
  %2351 : Float(512:1, 128:512) = aten::t(%2350), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %output.171 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %x.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.171, %2349, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1678:0
  %2354 : int = aten::size(%x.67, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2355 : int = aten::size(%x.67, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2356 : int[] = prim::ListConstruct(%2354, %2355, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.68 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.67, %2356), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2358 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %query_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.68, %2358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2360 : int = aten::size(%x.69, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2361 : int = aten::size(%x.69, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2362 : int[] = prim::ListConstruct(%2360, %2361, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.70 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.69, %2362), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2364 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %key_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.70, %2364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2366 : int = aten::size(%x.71, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2367 : int = aten::size(%x.71, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2368 : int[] = prim::ListConstruct(%2366, %2367, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.72 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.71, %2368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2370 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %value_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.72, %2370), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2372 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.12, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.12, %2372), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.24 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.23, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.218 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.24, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.219 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.218, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.219, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.23 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.12, %value_layer.12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:280:0
  %2379 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %2380 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.23, %2379), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2380, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %2382 : int = aten::size(%context_layer.24, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2383 : int = aten::size(%context_layer.24, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2384 : int[] = prim::ListConstruct(%2382, %2383, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %input.220 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.24, %2384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:283:0
  %2386 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18301.NoNorm = prim::GetAttr[name="LayerNorm"](%2334)
  %2387 : __torch__.torch.nn.modules.linear.___torch_mangle_18300.Linear = prim::GetAttr[name="dense"](%2334)
  %2388 : Tensor = prim::GetAttr[name="bias"](%2387)
  %2389 : Tensor = prim::GetAttr[name="weight"](%2387)
  %2390 : Float(128:1, 128:128) = aten::t(%2389), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %output.172 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.220, %2390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.56 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.172, %2388, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.92 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.56, %2333, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output # transformers/modeling_mobilebert.py:301:0
  %2394 : Tensor = prim::GetAttr[name="bias"](%2386)
  %2395 : Tensor = prim::GetAttr[name="weight"](%2386)
  %2396 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.92, %2395), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.221 : Float(17:1664, 13:128, 128:1) = aten::add(%2396, %2394, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2398 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18324.FFNOutput = prim::GetAttr[name="output"](%2304)
  %2399 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18321.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2304)
  %2400 : __torch__.torch.nn.modules.linear.___torch_mangle_18320.Linear = prim::GetAttr[name="dense"](%2399)
  %2401 : Tensor = prim::GetAttr[name="bias"](%2400)
  %2402 : Tensor = prim::GetAttr[name="weight"](%2400)
  %2403 : Float(128:1, 512:128) = aten::t(%2402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.173 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.221, %2403), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.222 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.173, %2401, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.223 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2407 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18323.NoNorm = prim::GetAttr[name="LayerNorm"](%2398)
  %2408 : __torch__.torch.nn.modules.linear.___torch_mangle_18322.Linear = prim::GetAttr[name="dense"](%2398)
  %2409 : Tensor = prim::GetAttr[name="bias"](%2408)
  %2410 : Tensor = prim::GetAttr[name="weight"](%2408)
  %2411 : Float(512:1, 128:512) = aten::t(%2410), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.174 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.223, %2411), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.174, %2409, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.93 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.57, %input.221, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2415 : Tensor = prim::GetAttr[name="bias"](%2407)
  %2416 : Tensor = prim::GetAttr[name="weight"](%2407)
  %2417 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.93, %2416), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.224 : Float(17:1664, 13:128, 128:1) = aten::add(%2417, %2415, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2419 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18330.FFNOutput = prim::GetAttr[name="output"](%2302)
  %2420 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18327.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2302)
  %2421 : __torch__.torch.nn.modules.linear.___torch_mangle_18326.Linear = prim::GetAttr[name="dense"](%2420)
  %2422 : Tensor = prim::GetAttr[name="bias"](%2421)
  %2423 : Tensor = prim::GetAttr[name="weight"](%2421)
  %2424 : Float(128:1, 512:128) = aten::t(%2423), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.175 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.224, %2424), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.225 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.175, %2422, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.226 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2428 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18329.NoNorm = prim::GetAttr[name="LayerNorm"](%2419)
  %2429 : __torch__.torch.nn.modules.linear.___torch_mangle_18328.Linear = prim::GetAttr[name="dense"](%2419)
  %2430 : Tensor = prim::GetAttr[name="bias"](%2429)
  %2431 : Tensor = prim::GetAttr[name="weight"](%2429)
  %2432 : Float(512:1, 128:512) = aten::t(%2431), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.176 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.226, %2432), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.176, %2430, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.94 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.58, %input.224, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2436 : Tensor = prim::GetAttr[name="bias"](%2428)
  %2437 : Tensor = prim::GetAttr[name="weight"](%2428)
  %2438 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.94, %2437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.227 : Float(17:1664, 13:128, 128:1) = aten::add(%2438, %2436, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2440 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18336.FFNOutput = prim::GetAttr[name="output"](%2300)
  %2441 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18333.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2300)
  %2442 : __torch__.torch.nn.modules.linear.___torch_mangle_18332.Linear = prim::GetAttr[name="dense"](%2441)
  %2443 : Tensor = prim::GetAttr[name="bias"](%2442)
  %2444 : Tensor = prim::GetAttr[name="weight"](%2442)
  %2445 : Float(128:1, 512:128) = aten::t(%2444), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.177 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.227, %2445), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.228 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.177, %2443, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.229 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2449 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18335.NoNorm = prim::GetAttr[name="LayerNorm"](%2440)
  %2450 : __torch__.torch.nn.modules.linear.___torch_mangle_18334.Linear = prim::GetAttr[name="dense"](%2440)
  %2451 : Tensor = prim::GetAttr[name="bias"](%2450)
  %2452 : Tensor = prim::GetAttr[name="weight"](%2450)
  %2453 : Float(512:1, 128:512) = aten::t(%2452), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.178 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.229, %2453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.178, %2451, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.95 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.59, %input.227, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2457 : Tensor = prim::GetAttr[name="bias"](%2449)
  %2458 : Tensor = prim::GetAttr[name="weight"](%2449)
  %2459 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.95, %2458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.230 : Float(17:1664, 13:128, 128:1) = aten::add(%2459, %2457, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2461 : __torch__.torch.nn.modules.linear.___torch_mangle_18304.Linear = prim::GetAttr[name="dense"](%2298)
  %2462 : Tensor = prim::GetAttr[name="bias"](%2461)
  %2463 : Tensor = prim::GetAttr[name="weight"](%2461)
  %2464 : Float(128:1, 512:128) = aten::t(%2463), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %output.179 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.230, %2464), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %input.231 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.179, %2462, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1678:0
  %input.232 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate # torch/nn/functional.py:1119:0
  %2468 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18311.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2297)
  %2469 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18307.NoNorm = prim::GetAttr[name="LayerNorm"](%2297)
  %2470 : __torch__.torch.nn.modules.linear.___torch_mangle_18306.Linear = prim::GetAttr[name="dense"](%2297)
  %2471 : Tensor = prim::GetAttr[name="bias"](%2470)
  %2472 : Tensor = prim::GetAttr[name="weight"](%2470)
  %2473 : Float(512:1, 128:512) = aten::t(%2472), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %output.180 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.232, %2473), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %layer_output.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.180, %2471, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.96 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.12, %input.230, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output # transformers/modeling_mobilebert.py:405:0
  %2477 : Tensor = prim::GetAttr[name="bias"](%2469)
  %2478 : Tensor = prim::GetAttr[name="weight"](%2469)
  %2479 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.96, %2478), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.233 : Float(17:1664, 13:128, 128:1) = aten::add(%2479, %2477, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2481 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18309.NoNorm = prim::GetAttr[name="LayerNorm"](%2468)
  %2482 : __torch__.torch.nn.modules.linear.___torch_mangle_18308.Linear = prim::GetAttr[name="dense"](%2468)
  %2483 : Tensor = prim::GetAttr[name="bias"](%2482)
  %2484 : Tensor = prim::GetAttr[name="weight"](%2482)
  %2485 : Float(128:1, 512:128) = aten::t(%2484), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.181 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.233, %2485), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.234 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.181, %2483, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.60 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.234, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.97 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.60, %input.216, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2490 : Tensor = prim::GetAttr[name="bias"](%2481)
  %2491 : Tensor = prim::GetAttr[name="weight"](%2481)
  %2492 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.97, %2491), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.235 : Float(17:6656, 13:512, 512:1) = aten::add(%2492, %2490, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2494 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18357.MobileBertOutput = prim::GetAttr[name="output"](%105)
  %2495 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18350.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%105)
  %2496 : __torch__.torch.nn.modules.container.___torch_mangle_18383.ModuleList = prim::GetAttr[name="ffn"](%105)
  %2497 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18382.FFNLayer = prim::GetAttr[name="2"](%2496)
  %2498 : __torch__.torch.nn.modules.container.___torch_mangle_18383.ModuleList = prim::GetAttr[name="ffn"](%105)
  %2499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18376.FFNLayer = prim::GetAttr[name="1"](%2498)
  %2500 : __torch__.torch.nn.modules.container.___torch_mangle_18383.ModuleList = prim::GetAttr[name="ffn"](%105)
  %2501 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18370.FFNLayer = prim::GetAttr[name="0"](%2500)
  %2502 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18348.MobileBertAttention = prim::GetAttr[name="attention"](%105)
  %2503 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18364.Bottleneck = prim::GetAttr[name="bottleneck"](%105)
  %2504 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18363.BottleneckLayer = prim::GetAttr[name="attention"](%2503)
  %2505 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18360.BottleneckLayer = prim::GetAttr[name="input"](%2503)
  %2506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18359.NoNorm = prim::GetAttr[name="LayerNorm"](%2505)
  %2507 : __torch__.torch.nn.modules.linear.___torch_mangle_18358.Linear = prim::GetAttr[name="dense"](%2505)
  %2508 : Tensor = prim::GetAttr[name="bias"](%2507)
  %2509 : Tensor = prim::GetAttr[name="weight"](%2507)
  %2510 : Float(512:1, 128:512) = aten::t(%2509), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.182 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.182, %2508, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2513 : Tensor = prim::GetAttr[name="bias"](%2506)
  %2514 : Tensor = prim::GetAttr[name="weight"](%2506)
  %2515 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.98, %2514), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%2515, %2513, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2517 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18362.NoNorm = prim::GetAttr[name="LayerNorm"](%2504)
  %2518 : __torch__.torch.nn.modules.linear.___torch_mangle_18361.Linear = prim::GetAttr[name="dense"](%2504)
  %2519 : Tensor = prim::GetAttr[name="bias"](%2518)
  %2520 : Tensor = prim::GetAttr[name="weight"](%2518)
  %2521 : Float(512:1, 128:512) = aten::t(%2520), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.183 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2521), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.183, %2519, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2524 : Tensor = prim::GetAttr[name="bias"](%2517)
  %2525 : Tensor = prim::GetAttr[name="weight"](%2517)
  %2526 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.99, %2525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.236 : Float(17:1664, 13:128, 128:1) = aten::add(%2526, %2524, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2528 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.236, %residual_tensor.13)
  %2529 : Float(17:1664, 13:128, 128:1), %2530 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2528)
  %2531 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18347.MobileBertSelfOutput = prim::GetAttr[name="output"](%2502)
  %2532 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18344.MobileBertSelfAttention = prim::GetAttr[name="self"](%2502)
  %2533 : __torch__.torch.nn.modules.linear.___torch_mangle_18342.Linear = prim::GetAttr[name="value"](%2532)
  %2534 : __torch__.torch.nn.modules.linear.___torch_mangle_18341.Linear = prim::GetAttr[name="key"](%2532)
  %2535 : __torch__.torch.nn.modules.linear.___torch_mangle_18340.Linear = prim::GetAttr[name="query"](%2532)
  %2536 : Tensor = prim::GetAttr[name="bias"](%2535)
  %2537 : Tensor = prim::GetAttr[name="weight"](%2535)
  %2538 : Float(128:1, 128:128) = aten::t(%2537), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %output.184 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2529, %2538), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %x.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.184, %2536, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1678:0
  %2541 : Tensor = prim::GetAttr[name="bias"](%2534)
  %2542 : Tensor = prim::GetAttr[name="weight"](%2534)
  %2543 : Float(128:1, 128:128) = aten::t(%2542), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %output.185 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2529, %2543), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %x.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.185, %2541, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1678:0
  %2546 : Tensor = prim::GetAttr[name="bias"](%2533)
  %2547 : Tensor = prim::GetAttr[name="weight"](%2533)
  %2548 : Float(512:1, 128:512) = aten::t(%2547), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %output.186 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %x.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.186, %2546, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1678:0
  %2551 : int = aten::size(%x.73, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2552 : int = aten::size(%x.73, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2553 : int[] = prim::ListConstruct(%2551, %2552, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.74 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.73, %2553), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2555 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %query_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.74, %2555), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2557 : int = aten::size(%x.75, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2558 : int = aten::size(%x.75, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2559 : int[] = prim::ListConstruct(%2557, %2558, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.76 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.75, %2559), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2561 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %key_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.76, %2561), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2563 : int = aten::size(%x.77, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2564 : int = aten::size(%x.77, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2565 : int[] = prim::ListConstruct(%2563, %2564, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.78 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.77, %2565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2567 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %value_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.78, %2567), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2569 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.13, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.25 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.13, %2569), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.26 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.25, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.237 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.26, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.238 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.237, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.238, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.25 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.13, %value_layer.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:280:0
  %2576 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %2577 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.25, %2576), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2577, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %2579 : int = aten::size(%context_layer.26, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2580 : int = aten::size(%context_layer.26, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2581 : int[] = prim::ListConstruct(%2579, %2580, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %input.239 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.26, %2581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:283:0
  %2583 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18346.NoNorm = prim::GetAttr[name="LayerNorm"](%2531)
  %2584 : __torch__.torch.nn.modules.linear.___torch_mangle_18345.Linear = prim::GetAttr[name="dense"](%2531)
  %2585 : Tensor = prim::GetAttr[name="bias"](%2584)
  %2586 : Tensor = prim::GetAttr[name="weight"](%2584)
  %2587 : Float(128:1, 128:128) = aten::t(%2586), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %output.187 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.239, %2587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.187, %2585, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.100 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.61, %2530, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output # transformers/modeling_mobilebert.py:301:0
  %2591 : Tensor = prim::GetAttr[name="bias"](%2583)
  %2592 : Tensor = prim::GetAttr[name="weight"](%2583)
  %2593 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.100, %2592), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.240 : Float(17:1664, 13:128, 128:1) = aten::add(%2593, %2591, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2595 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18369.FFNOutput = prim::GetAttr[name="output"](%2501)
  %2596 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18366.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2501)
  %2597 : __torch__.torch.nn.modules.linear.___torch_mangle_18365.Linear = prim::GetAttr[name="dense"](%2596)
  %2598 : Tensor = prim::GetAttr[name="bias"](%2597)
  %2599 : Tensor = prim::GetAttr[name="weight"](%2597)
  %2600 : Float(128:1, 512:128) = aten::t(%2599), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.188 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.240, %2600), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.241 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.188, %2598, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.242 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2604 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18368.NoNorm = prim::GetAttr[name="LayerNorm"](%2595)
  %2605 : __torch__.torch.nn.modules.linear.___torch_mangle_18367.Linear = prim::GetAttr[name="dense"](%2595)
  %2606 : Tensor = prim::GetAttr[name="bias"](%2605)
  %2607 : Tensor = prim::GetAttr[name="weight"](%2605)
  %2608 : Float(512:1, 128:512) = aten::t(%2607), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.189 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.242, %2608), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.62 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.189, %2606, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.101 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.62, %input.240, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2612 : Tensor = prim::GetAttr[name="bias"](%2604)
  %2613 : Tensor = prim::GetAttr[name="weight"](%2604)
  %2614 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.101, %2613), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.243 : Float(17:1664, 13:128, 128:1) = aten::add(%2614, %2612, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2616 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18375.FFNOutput = prim::GetAttr[name="output"](%2499)
  %2617 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18372.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2499)
  %2618 : __torch__.torch.nn.modules.linear.___torch_mangle_18371.Linear = prim::GetAttr[name="dense"](%2617)
  %2619 : Tensor = prim::GetAttr[name="bias"](%2618)
  %2620 : Tensor = prim::GetAttr[name="weight"](%2618)
  %2621 : Float(128:1, 512:128) = aten::t(%2620), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.190 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.243, %2621), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.244 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.190, %2619, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.245 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2625 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18374.NoNorm = prim::GetAttr[name="LayerNorm"](%2616)
  %2626 : __torch__.torch.nn.modules.linear.___torch_mangle_18373.Linear = prim::GetAttr[name="dense"](%2616)
  %2627 : Tensor = prim::GetAttr[name="bias"](%2626)
  %2628 : Tensor = prim::GetAttr[name="weight"](%2626)
  %2629 : Float(512:1, 128:512) = aten::t(%2628), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.191 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.245, %2629), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.191, %2627, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.102 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.63, %input.243, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2633 : Tensor = prim::GetAttr[name="bias"](%2625)
  %2634 : Tensor = prim::GetAttr[name="weight"](%2625)
  %2635 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.102, %2634), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.246 : Float(17:1664, 13:128, 128:1) = aten::add(%2635, %2633, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2637 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18381.FFNOutput = prim::GetAttr[name="output"](%2497)
  %2638 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18378.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2497)
  %2639 : __torch__.torch.nn.modules.linear.___torch_mangle_18377.Linear = prim::GetAttr[name="dense"](%2638)
  %2640 : Tensor = prim::GetAttr[name="bias"](%2639)
  %2641 : Tensor = prim::GetAttr[name="weight"](%2639)
  %2642 : Float(128:1, 512:128) = aten::t(%2641), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.192 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.246, %2642), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.247 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.192, %2640, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.248 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2646 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18380.NoNorm = prim::GetAttr[name="LayerNorm"](%2637)
  %2647 : __torch__.torch.nn.modules.linear.___torch_mangle_18379.Linear = prim::GetAttr[name="dense"](%2637)
  %2648 : Tensor = prim::GetAttr[name="bias"](%2647)
  %2649 : Tensor = prim::GetAttr[name="weight"](%2647)
  %2650 : Float(512:1, 128:512) = aten::t(%2649), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.193 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.248, %2650), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.64 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.193, %2648, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.103 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.64, %input.246, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2654 : Tensor = prim::GetAttr[name="bias"](%2646)
  %2655 : Tensor = prim::GetAttr[name="weight"](%2646)
  %2656 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.103, %2655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.249 : Float(17:1664, 13:128, 128:1) = aten::add(%2656, %2654, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2658 : __torch__.torch.nn.modules.linear.___torch_mangle_18349.Linear = prim::GetAttr[name="dense"](%2495)
  %2659 : Tensor = prim::GetAttr[name="bias"](%2658)
  %2660 : Tensor = prim::GetAttr[name="weight"](%2658)
  %2661 : Float(128:1, 512:128) = aten::t(%2660), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %output.194 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.249, %2661), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %input.250 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.194, %2659, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1678:0
  %input.251 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate # torch/nn/functional.py:1119:0
  %2665 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18356.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2494)
  %2666 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18352.NoNorm = prim::GetAttr[name="LayerNorm"](%2494)
  %2667 : __torch__.torch.nn.modules.linear.___torch_mangle_18351.Linear = prim::GetAttr[name="dense"](%2494)
  %2668 : Tensor = prim::GetAttr[name="bias"](%2667)
  %2669 : Tensor = prim::GetAttr[name="weight"](%2667)
  %2670 : Float(512:1, 128:512) = aten::t(%2669), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %output.195 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.251, %2670), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %layer_output.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.195, %2668, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.104 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.13, %input.249, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output # transformers/modeling_mobilebert.py:405:0
  %2674 : Tensor = prim::GetAttr[name="bias"](%2666)
  %2675 : Tensor = prim::GetAttr[name="weight"](%2666)
  %2676 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.104, %2675), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.252 : Float(17:1664, 13:128, 128:1) = aten::add(%2676, %2674, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2678 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18354.NoNorm = prim::GetAttr[name="LayerNorm"](%2665)
  %2679 : __torch__.torch.nn.modules.linear.___torch_mangle_18353.Linear = prim::GetAttr[name="dense"](%2665)
  %2680 : Tensor = prim::GetAttr[name="bias"](%2679)
  %2681 : Tensor = prim::GetAttr[name="weight"](%2679)
  %2682 : Float(128:1, 512:128) = aten::t(%2681), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.196 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.252, %2682), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.253 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.196, %2680, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.65 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.253, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.105 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.65, %input.235, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2687 : Tensor = prim::GetAttr[name="bias"](%2678)
  %2688 : Tensor = prim::GetAttr[name="weight"](%2678)
  %2689 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.105, %2688), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.254 : Float(17:6656, 13:512, 512:1) = aten::add(%2689, %2687, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2691 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18402.MobileBertOutput = prim::GetAttr[name="output"](%103)
  %2692 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18395.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%103)
  %2693 : __torch__.torch.nn.modules.container.___torch_mangle_18428.ModuleList = prim::GetAttr[name="ffn"](%103)
  %2694 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18427.FFNLayer = prim::GetAttr[name="2"](%2693)
  %2695 : __torch__.torch.nn.modules.container.___torch_mangle_18428.ModuleList = prim::GetAttr[name="ffn"](%103)
  %2696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18421.FFNLayer = prim::GetAttr[name="1"](%2695)
  %2697 : __torch__.torch.nn.modules.container.___torch_mangle_18428.ModuleList = prim::GetAttr[name="ffn"](%103)
  %2698 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18415.FFNLayer = prim::GetAttr[name="0"](%2697)
  %2699 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18393.MobileBertAttention = prim::GetAttr[name="attention"](%103)
  %2700 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18409.Bottleneck = prim::GetAttr[name="bottleneck"](%103)
  %2701 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18408.BottleneckLayer = prim::GetAttr[name="attention"](%2700)
  %2702 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18405.BottleneckLayer = prim::GetAttr[name="input"](%2700)
  %2703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18404.NoNorm = prim::GetAttr[name="LayerNorm"](%2702)
  %2704 : __torch__.torch.nn.modules.linear.___torch_mangle_18403.Linear = prim::GetAttr[name="dense"](%2702)
  %2705 : Tensor = prim::GetAttr[name="bias"](%2704)
  %2706 : Tensor = prim::GetAttr[name="weight"](%2704)
  %2707 : Float(512:1, 128:512) = aten::t(%2706), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.197 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.197, %2705, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2710 : Tensor = prim::GetAttr[name="bias"](%2703)
  %2711 : Tensor = prim::GetAttr[name="weight"](%2703)
  %2712 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.106, %2711), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%2712, %2710, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2714 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18407.NoNorm = prim::GetAttr[name="LayerNorm"](%2701)
  %2715 : __torch__.torch.nn.modules.linear.___torch_mangle_18406.Linear = prim::GetAttr[name="dense"](%2701)
  %2716 : Tensor = prim::GetAttr[name="bias"](%2715)
  %2717 : Tensor = prim::GetAttr[name="weight"](%2715)
  %2718 : Float(512:1, 128:512) = aten::t(%2717), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.198 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2718), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.198, %2716, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2721 : Tensor = prim::GetAttr[name="bias"](%2714)
  %2722 : Tensor = prim::GetAttr[name="weight"](%2714)
  %2723 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.107, %2722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.255 : Float(17:1664, 13:128, 128:1) = aten::add(%2723, %2721, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2725 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.255, %residual_tensor.14)
  %2726 : Float(17:1664, 13:128, 128:1), %2727 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2725)
  %2728 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18392.MobileBertSelfOutput = prim::GetAttr[name="output"](%2699)
  %2729 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18389.MobileBertSelfAttention = prim::GetAttr[name="self"](%2699)
  %2730 : __torch__.torch.nn.modules.linear.___torch_mangle_18387.Linear = prim::GetAttr[name="value"](%2729)
  %2731 : __torch__.torch.nn.modules.linear.___torch_mangle_18386.Linear = prim::GetAttr[name="key"](%2729)
  %2732 : __torch__.torch.nn.modules.linear.___torch_mangle_18385.Linear = prim::GetAttr[name="query"](%2729)
  %2733 : Tensor = prim::GetAttr[name="bias"](%2732)
  %2734 : Tensor = prim::GetAttr[name="weight"](%2732)
  %2735 : Float(128:1, 128:128) = aten::t(%2734), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %output.199 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2726, %2735), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %x.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.199, %2733, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1678:0
  %2738 : Tensor = prim::GetAttr[name="bias"](%2731)
  %2739 : Tensor = prim::GetAttr[name="weight"](%2731)
  %2740 : Float(128:1, 128:128) = aten::t(%2739), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %output.200 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2726, %2740), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %x.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.200, %2738, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1678:0
  %2743 : Tensor = prim::GetAttr[name="bias"](%2730)
  %2744 : Tensor = prim::GetAttr[name="weight"](%2730)
  %2745 : Float(512:1, 128:512) = aten::t(%2744), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %output.201 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %x.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.201, %2743, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1678:0
  %2748 : int = aten::size(%x.79, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2749 : int = aten::size(%x.79, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2750 : int[] = prim::ListConstruct(%2748, %2749, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.80 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.79, %2750), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2752 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %query_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.80, %2752), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2754 : int = aten::size(%x.81, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2755 : int = aten::size(%x.81, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2756 : int[] = prim::ListConstruct(%2754, %2755, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.82 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.81, %2756), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2758 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %key_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.82, %2758), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2760 : int = aten::size(%x.83, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2761 : int = aten::size(%x.83, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2762 : int[] = prim::ListConstruct(%2760, %2761, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.84 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.83, %2762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2764 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %value_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.84, %2764), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2766 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.14, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.27 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.14, %2766), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.27, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.256 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.28, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.257 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.256, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.257, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.27 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.14, %value_layer.14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:280:0
  %2773 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %2774 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.27, %2773), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2774, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %2776 : int = aten::size(%context_layer.28, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2777 : int = aten::size(%context_layer.28, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2778 : int[] = prim::ListConstruct(%2776, %2777, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %input.258 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.28, %2778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:283:0
  %2780 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18391.NoNorm = prim::GetAttr[name="LayerNorm"](%2728)
  %2781 : __torch__.torch.nn.modules.linear.___torch_mangle_18390.Linear = prim::GetAttr[name="dense"](%2728)
  %2782 : Tensor = prim::GetAttr[name="bias"](%2781)
  %2783 : Tensor = prim::GetAttr[name="weight"](%2781)
  %2784 : Float(128:1, 128:128) = aten::t(%2783), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %output.202 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.258, %2784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.202, %2782, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.108 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.66, %2727, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output # transformers/modeling_mobilebert.py:301:0
  %2788 : Tensor = prim::GetAttr[name="bias"](%2780)
  %2789 : Tensor = prim::GetAttr[name="weight"](%2780)
  %2790 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.108, %2789), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.259 : Float(17:1664, 13:128, 128:1) = aten::add(%2790, %2788, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2792 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18414.FFNOutput = prim::GetAttr[name="output"](%2698)
  %2793 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18411.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2698)
  %2794 : __torch__.torch.nn.modules.linear.___torch_mangle_18410.Linear = prim::GetAttr[name="dense"](%2793)
  %2795 : Tensor = prim::GetAttr[name="bias"](%2794)
  %2796 : Tensor = prim::GetAttr[name="weight"](%2794)
  %2797 : Float(128:1, 512:128) = aten::t(%2796), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.203 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.259, %2797), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.260 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.203, %2795, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.261 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2801 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18413.NoNorm = prim::GetAttr[name="LayerNorm"](%2792)
  %2802 : __torch__.torch.nn.modules.linear.___torch_mangle_18412.Linear = prim::GetAttr[name="dense"](%2792)
  %2803 : Tensor = prim::GetAttr[name="bias"](%2802)
  %2804 : Tensor = prim::GetAttr[name="weight"](%2802)
  %2805 : Float(512:1, 128:512) = aten::t(%2804), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.204 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.261, %2805), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.204, %2803, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.109 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.67, %input.259, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2809 : Tensor = prim::GetAttr[name="bias"](%2801)
  %2810 : Tensor = prim::GetAttr[name="weight"](%2801)
  %2811 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.109, %2810), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.262 : Float(17:1664, 13:128, 128:1) = aten::add(%2811, %2809, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2813 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18420.FFNOutput = prim::GetAttr[name="output"](%2696)
  %2814 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18417.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2696)
  %2815 : __torch__.torch.nn.modules.linear.___torch_mangle_18416.Linear = prim::GetAttr[name="dense"](%2814)
  %2816 : Tensor = prim::GetAttr[name="bias"](%2815)
  %2817 : Tensor = prim::GetAttr[name="weight"](%2815)
  %2818 : Float(128:1, 512:128) = aten::t(%2817), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.205 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.262, %2818), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.263 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.205, %2816, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.264 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2822 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18419.NoNorm = prim::GetAttr[name="LayerNorm"](%2813)
  %2823 : __torch__.torch.nn.modules.linear.___torch_mangle_18418.Linear = prim::GetAttr[name="dense"](%2813)
  %2824 : Tensor = prim::GetAttr[name="bias"](%2823)
  %2825 : Tensor = prim::GetAttr[name="weight"](%2823)
  %2826 : Float(512:1, 128:512) = aten::t(%2825), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.206 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.264, %2826), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.68 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.206, %2824, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.110 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.68, %input.262, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2830 : Tensor = prim::GetAttr[name="bias"](%2822)
  %2831 : Tensor = prim::GetAttr[name="weight"](%2822)
  %2832 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.110, %2831), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.265 : Float(17:1664, 13:128, 128:1) = aten::add(%2832, %2830, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2834 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18426.FFNOutput = prim::GetAttr[name="output"](%2694)
  %2835 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18423.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2694)
  %2836 : __torch__.torch.nn.modules.linear.___torch_mangle_18422.Linear = prim::GetAttr[name="dense"](%2835)
  %2837 : Tensor = prim::GetAttr[name="bias"](%2836)
  %2838 : Tensor = prim::GetAttr[name="weight"](%2836)
  %2839 : Float(128:1, 512:128) = aten::t(%2838), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.207 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.265, %2839), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.266 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.207, %2837, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.267 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2843 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18425.NoNorm = prim::GetAttr[name="LayerNorm"](%2834)
  %2844 : __torch__.torch.nn.modules.linear.___torch_mangle_18424.Linear = prim::GetAttr[name="dense"](%2834)
  %2845 : Tensor = prim::GetAttr[name="bias"](%2844)
  %2846 : Tensor = prim::GetAttr[name="weight"](%2844)
  %2847 : Float(512:1, 128:512) = aten::t(%2846), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.208 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.267, %2847), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.208, %2845, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.111 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.69, %input.265, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2851 : Tensor = prim::GetAttr[name="bias"](%2843)
  %2852 : Tensor = prim::GetAttr[name="weight"](%2843)
  %2853 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.111, %2852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.268 : Float(17:1664, 13:128, 128:1) = aten::add(%2853, %2851, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2855 : __torch__.torch.nn.modules.linear.___torch_mangle_18394.Linear = prim::GetAttr[name="dense"](%2692)
  %2856 : Tensor = prim::GetAttr[name="bias"](%2855)
  %2857 : Tensor = prim::GetAttr[name="weight"](%2855)
  %2858 : Float(128:1, 512:128) = aten::t(%2857), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %output.209 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.268, %2858), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %input.269 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.209, %2856, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1678:0
  %input.270 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate # torch/nn/functional.py:1119:0
  %2862 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18401.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2691)
  %2863 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18397.NoNorm = prim::GetAttr[name="LayerNorm"](%2691)
  %2864 : __torch__.torch.nn.modules.linear.___torch_mangle_18396.Linear = prim::GetAttr[name="dense"](%2691)
  %2865 : Tensor = prim::GetAttr[name="bias"](%2864)
  %2866 : Tensor = prim::GetAttr[name="weight"](%2864)
  %2867 : Float(512:1, 128:512) = aten::t(%2866), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %output.210 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.270, %2867), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %layer_output.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.210, %2865, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.112 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.14, %input.268, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output # transformers/modeling_mobilebert.py:405:0
  %2871 : Tensor = prim::GetAttr[name="bias"](%2863)
  %2872 : Tensor = prim::GetAttr[name="weight"](%2863)
  %2873 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.112, %2872), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.271 : Float(17:1664, 13:128, 128:1) = aten::add(%2873, %2871, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2875 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18399.NoNorm = prim::GetAttr[name="LayerNorm"](%2862)
  %2876 : __torch__.torch.nn.modules.linear.___torch_mangle_18398.Linear = prim::GetAttr[name="dense"](%2862)
  %2877 : Tensor = prim::GetAttr[name="bias"](%2876)
  %2878 : Tensor = prim::GetAttr[name="weight"](%2876)
  %2879 : Float(128:1, 512:128) = aten::t(%2878), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.211 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.271, %2879), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.272 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.211, %2877, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.70 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.272, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.113 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.70, %input.254, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2884 : Tensor = prim::GetAttr[name="bias"](%2875)
  %2885 : Tensor = prim::GetAttr[name="weight"](%2875)
  %2886 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.113, %2885), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.273 : Float(17:6656, 13:512, 512:1) = aten::add(%2886, %2884, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2888 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18447.MobileBertOutput = prim::GetAttr[name="output"](%101)
  %2889 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18440.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%101)
  %2890 : __torch__.torch.nn.modules.container.___torch_mangle_18473.ModuleList = prim::GetAttr[name="ffn"](%101)
  %2891 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18472.FFNLayer = prim::GetAttr[name="2"](%2890)
  %2892 : __torch__.torch.nn.modules.container.___torch_mangle_18473.ModuleList = prim::GetAttr[name="ffn"](%101)
  %2893 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18466.FFNLayer = prim::GetAttr[name="1"](%2892)
  %2894 : __torch__.torch.nn.modules.container.___torch_mangle_18473.ModuleList = prim::GetAttr[name="ffn"](%101)
  %2895 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18460.FFNLayer = prim::GetAttr[name="0"](%2894)
  %2896 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18438.MobileBertAttention = prim::GetAttr[name="attention"](%101)
  %2897 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18454.Bottleneck = prim::GetAttr[name="bottleneck"](%101)
  %2898 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18453.BottleneckLayer = prim::GetAttr[name="attention"](%2897)
  %2899 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18450.BottleneckLayer = prim::GetAttr[name="input"](%2897)
  %2900 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18449.NoNorm = prim::GetAttr[name="LayerNorm"](%2899)
  %2901 : __torch__.torch.nn.modules.linear.___torch_mangle_18448.Linear = prim::GetAttr[name="dense"](%2899)
  %2902 : Tensor = prim::GetAttr[name="bias"](%2901)
  %2903 : Tensor = prim::GetAttr[name="weight"](%2901)
  %2904 : Float(512:1, 128:512) = aten::t(%2903), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.212 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2904), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.212, %2902, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2907 : Tensor = prim::GetAttr[name="bias"](%2900)
  %2908 : Tensor = prim::GetAttr[name="weight"](%2900)
  %2909 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.114, %2908), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%2909, %2907, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2911 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18452.NoNorm = prim::GetAttr[name="LayerNorm"](%2898)
  %2912 : __torch__.torch.nn.modules.linear.___torch_mangle_18451.Linear = prim::GetAttr[name="dense"](%2898)
  %2913 : Tensor = prim::GetAttr[name="bias"](%2912)
  %2914 : Tensor = prim::GetAttr[name="weight"](%2912)
  %2915 : Float(512:1, 128:512) = aten::t(%2914), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.213 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2915), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.213, %2913, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2918 : Tensor = prim::GetAttr[name="bias"](%2911)
  %2919 : Tensor = prim::GetAttr[name="weight"](%2911)
  %2920 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.115, %2919), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.274 : Float(17:1664, 13:128, 128:1) = aten::add(%2920, %2918, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2922 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.274, %residual_tensor.15)
  %2923 : Float(17:1664, 13:128, 128:1), %2924 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2922)
  %2925 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18437.MobileBertSelfOutput = prim::GetAttr[name="output"](%2896)
  %2926 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18434.MobileBertSelfAttention = prim::GetAttr[name="self"](%2896)
  %2927 : __torch__.torch.nn.modules.linear.___torch_mangle_18432.Linear = prim::GetAttr[name="value"](%2926)
  %2928 : __torch__.torch.nn.modules.linear.___torch_mangle_18431.Linear = prim::GetAttr[name="key"](%2926)
  %2929 : __torch__.torch.nn.modules.linear.___torch_mangle_18430.Linear = prim::GetAttr[name="query"](%2926)
  %2930 : Tensor = prim::GetAttr[name="bias"](%2929)
  %2931 : Tensor = prim::GetAttr[name="weight"](%2929)
  %2932 : Float(128:1, 128:128) = aten::t(%2931), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %output.214 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2923, %2932), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %x.85 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.214, %2930, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1678:0
  %2935 : Tensor = prim::GetAttr[name="bias"](%2928)
  %2936 : Tensor = prim::GetAttr[name="weight"](%2928)
  %2937 : Float(128:1, 128:128) = aten::t(%2936), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %output.215 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2923, %2937), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %x.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.215, %2935, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1678:0
  %2940 : Tensor = prim::GetAttr[name="bias"](%2927)
  %2941 : Tensor = prim::GetAttr[name="weight"](%2927)
  %2942 : Float(512:1, 128:512) = aten::t(%2941), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %output.216 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2942), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %x.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.216, %2940, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1678:0
  %2945 : int = aten::size(%x.85, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2946 : int = aten::size(%x.85, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2947 : int[] = prim::ListConstruct(%2945, %2946, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.86 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.85, %2947), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2949 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %query_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.86, %2949), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2951 : int = aten::size(%x.87, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2952 : int = aten::size(%x.87, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2953 : int[] = prim::ListConstruct(%2951, %2952, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.88 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.87, %2953), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2955 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %key_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.88, %2955), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2957 : int = aten::size(%x.89, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2958 : int = aten::size(%x.89, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2959 : int[] = prim::ListConstruct(%2957, %2958, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.90 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.89, %2959), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2961 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %value_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.90, %2961), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2963 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.15, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.15, %2963), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.30 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.29, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.275 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.30, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.276 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.275, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.276, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.29 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.15, %value_layer.15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:280:0
  %2970 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %2971 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.29, %2970), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2971, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %2973 : int = aten::size(%context_layer.30, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2974 : int = aten::size(%context_layer.30, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2975 : int[] = prim::ListConstruct(%2973, %2974, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %input.277 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.30, %2975), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:283:0
  %2977 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18436.NoNorm = prim::GetAttr[name="LayerNorm"](%2925)
  %2978 : __torch__.torch.nn.modules.linear.___torch_mangle_18435.Linear = prim::GetAttr[name="dense"](%2925)
  %2979 : Tensor = prim::GetAttr[name="bias"](%2978)
  %2980 : Tensor = prim::GetAttr[name="weight"](%2978)
  %2981 : Float(128:1, 128:128) = aten::t(%2980), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %output.217 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.277, %2981), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.217, %2979, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.116 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.71, %2924, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output # transformers/modeling_mobilebert.py:301:0
  %2985 : Tensor = prim::GetAttr[name="bias"](%2977)
  %2986 : Tensor = prim::GetAttr[name="weight"](%2977)
  %2987 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.116, %2986), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.278 : Float(17:1664, 13:128, 128:1) = aten::add(%2987, %2985, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2989 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18459.FFNOutput = prim::GetAttr[name="output"](%2895)
  %2990 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18456.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2895)
  %2991 : __torch__.torch.nn.modules.linear.___torch_mangle_18455.Linear = prim::GetAttr[name="dense"](%2990)
  %2992 : Tensor = prim::GetAttr[name="bias"](%2991)
  %2993 : Tensor = prim::GetAttr[name="weight"](%2991)
  %2994 : Float(128:1, 512:128) = aten::t(%2993), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.218 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.278, %2994), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.279 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.218, %2992, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.280 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2998 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18458.NoNorm = prim::GetAttr[name="LayerNorm"](%2989)
  %2999 : __torch__.torch.nn.modules.linear.___torch_mangle_18457.Linear = prim::GetAttr[name="dense"](%2989)
  %3000 : Tensor = prim::GetAttr[name="bias"](%2999)
  %3001 : Tensor = prim::GetAttr[name="weight"](%2999)
  %3002 : Float(512:1, 128:512) = aten::t(%3001), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.219 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.280, %3002), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.72 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.219, %3000, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.117 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.72, %input.278, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3006 : Tensor = prim::GetAttr[name="bias"](%2998)
  %3007 : Tensor = prim::GetAttr[name="weight"](%2998)
  %3008 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.117, %3007), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.281 : Float(17:1664, 13:128, 128:1) = aten::add(%3008, %3006, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3010 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18465.FFNOutput = prim::GetAttr[name="output"](%2893)
  %3011 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18462.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2893)
  %3012 : __torch__.torch.nn.modules.linear.___torch_mangle_18461.Linear = prim::GetAttr[name="dense"](%3011)
  %3013 : Tensor = prim::GetAttr[name="bias"](%3012)
  %3014 : Tensor = prim::GetAttr[name="weight"](%3012)
  %3015 : Float(128:1, 512:128) = aten::t(%3014), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.220 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.281, %3015), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.282 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.220, %3013, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.283 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3019 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18464.NoNorm = prim::GetAttr[name="LayerNorm"](%3010)
  %3020 : __torch__.torch.nn.modules.linear.___torch_mangle_18463.Linear = prim::GetAttr[name="dense"](%3010)
  %3021 : Tensor = prim::GetAttr[name="bias"](%3020)
  %3022 : Tensor = prim::GetAttr[name="weight"](%3020)
  %3023 : Float(512:1, 128:512) = aten::t(%3022), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.221 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.283, %3023), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.221, %3021, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.118 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.73, %input.281, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3027 : Tensor = prim::GetAttr[name="bias"](%3019)
  %3028 : Tensor = prim::GetAttr[name="weight"](%3019)
  %3029 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.118, %3028), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.284 : Float(17:1664, 13:128, 128:1) = aten::add(%3029, %3027, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3031 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18471.FFNOutput = prim::GetAttr[name="output"](%2891)
  %3032 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18468.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2891)
  %3033 : __torch__.torch.nn.modules.linear.___torch_mangle_18467.Linear = prim::GetAttr[name="dense"](%3032)
  %3034 : Tensor = prim::GetAttr[name="bias"](%3033)
  %3035 : Tensor = prim::GetAttr[name="weight"](%3033)
  %3036 : Float(128:1, 512:128) = aten::t(%3035), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.222 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.284, %3036), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.285 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.222, %3034, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.286 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3040 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18470.NoNorm = prim::GetAttr[name="LayerNorm"](%3031)
  %3041 : __torch__.torch.nn.modules.linear.___torch_mangle_18469.Linear = prim::GetAttr[name="dense"](%3031)
  %3042 : Tensor = prim::GetAttr[name="bias"](%3041)
  %3043 : Tensor = prim::GetAttr[name="weight"](%3041)
  %3044 : Float(512:1, 128:512) = aten::t(%3043), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.223 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.286, %3044), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.223, %3042, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.119 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.74, %input.284, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3048 : Tensor = prim::GetAttr[name="bias"](%3040)
  %3049 : Tensor = prim::GetAttr[name="weight"](%3040)
  %3050 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.119, %3049), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.287 : Float(17:1664, 13:128, 128:1) = aten::add(%3050, %3048, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3052 : __torch__.torch.nn.modules.linear.___torch_mangle_18439.Linear = prim::GetAttr[name="dense"](%2889)
  %3053 : Tensor = prim::GetAttr[name="bias"](%3052)
  %3054 : Tensor = prim::GetAttr[name="weight"](%3052)
  %3055 : Float(128:1, 512:128) = aten::t(%3054), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %output.224 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.287, %3055), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %input.288 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.224, %3053, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1678:0
  %input.289 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate # torch/nn/functional.py:1119:0
  %3059 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18446.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2888)
  %3060 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18442.NoNorm = prim::GetAttr[name="LayerNorm"](%2888)
  %3061 : __torch__.torch.nn.modules.linear.___torch_mangle_18441.Linear = prim::GetAttr[name="dense"](%2888)
  %3062 : Tensor = prim::GetAttr[name="bias"](%3061)
  %3063 : Tensor = prim::GetAttr[name="weight"](%3061)
  %3064 : Float(512:1, 128:512) = aten::t(%3063), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %output.225 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.289, %3064), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %layer_output.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.225, %3062, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.120 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.15, %input.287, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output # transformers/modeling_mobilebert.py:405:0
  %3068 : Tensor = prim::GetAttr[name="bias"](%3060)
  %3069 : Tensor = prim::GetAttr[name="weight"](%3060)
  %3070 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.120, %3069), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.290 : Float(17:1664, 13:128, 128:1) = aten::add(%3070, %3068, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3072 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18444.NoNorm = prim::GetAttr[name="LayerNorm"](%3059)
  %3073 : __torch__.torch.nn.modules.linear.___torch_mangle_18443.Linear = prim::GetAttr[name="dense"](%3059)
  %3074 : Tensor = prim::GetAttr[name="bias"](%3073)
  %3075 : Tensor = prim::GetAttr[name="weight"](%3073)
  %3076 : Float(128:1, 512:128) = aten::t(%3075), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.226 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.290, %3076), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.291 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.226, %3074, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.75 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.291, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.121 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.75, %input.273, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3081 : Tensor = prim::GetAttr[name="bias"](%3072)
  %3082 : Tensor = prim::GetAttr[name="weight"](%3072)
  %3083 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.121, %3082), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.292 : Float(17:6656, 13:512, 512:1) = aten::add(%3083, %3081, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3085 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18492.MobileBertOutput = prim::GetAttr[name="output"](%99)
  %3086 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18485.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%99)
  %3087 : __torch__.torch.nn.modules.container.___torch_mangle_18518.ModuleList = prim::GetAttr[name="ffn"](%99)
  %3088 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18517.FFNLayer = prim::GetAttr[name="2"](%3087)
  %3089 : __torch__.torch.nn.modules.container.___torch_mangle_18518.ModuleList = prim::GetAttr[name="ffn"](%99)
  %3090 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18511.FFNLayer = prim::GetAttr[name="1"](%3089)
  %3091 : __torch__.torch.nn.modules.container.___torch_mangle_18518.ModuleList = prim::GetAttr[name="ffn"](%99)
  %3092 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18505.FFNLayer = prim::GetAttr[name="0"](%3091)
  %3093 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18483.MobileBertAttention = prim::GetAttr[name="attention"](%99)
  %3094 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18499.Bottleneck = prim::GetAttr[name="bottleneck"](%99)
  %3095 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18498.BottleneckLayer = prim::GetAttr[name="attention"](%3094)
  %3096 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18495.BottleneckLayer = prim::GetAttr[name="input"](%3094)
  %3097 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18494.NoNorm = prim::GetAttr[name="LayerNorm"](%3096)
  %3098 : __torch__.torch.nn.modules.linear.___torch_mangle_18493.Linear = prim::GetAttr[name="dense"](%3096)
  %3099 : Tensor = prim::GetAttr[name="bias"](%3098)
  %3100 : Tensor = prim::GetAttr[name="weight"](%3098)
  %3101 : Float(512:1, 128:512) = aten::t(%3100), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.227 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3101), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.122 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.227, %3099, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3104 : Tensor = prim::GetAttr[name="bias"](%3097)
  %3105 : Tensor = prim::GetAttr[name="weight"](%3097)
  %3106 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.122, %3105), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%3106, %3104, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3108 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18497.NoNorm = prim::GetAttr[name="LayerNorm"](%3095)
  %3109 : __torch__.torch.nn.modules.linear.___torch_mangle_18496.Linear = prim::GetAttr[name="dense"](%3095)
  %3110 : Tensor = prim::GetAttr[name="bias"](%3109)
  %3111 : Tensor = prim::GetAttr[name="weight"](%3109)
  %3112 : Float(512:1, 128:512) = aten::t(%3111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.228 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3112), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.228, %3110, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3115 : Tensor = prim::GetAttr[name="bias"](%3108)
  %3116 : Tensor = prim::GetAttr[name="weight"](%3108)
  %3117 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.123, %3116), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.293 : Float(17:1664, 13:128, 128:1) = aten::add(%3117, %3115, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3119 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.293, %residual_tensor.16)
  %3120 : Float(17:1664, 13:128, 128:1), %3121 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3119)
  %3122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18482.MobileBertSelfOutput = prim::GetAttr[name="output"](%3093)
  %3123 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18479.MobileBertSelfAttention = prim::GetAttr[name="self"](%3093)
  %3124 : __torch__.torch.nn.modules.linear.___torch_mangle_18477.Linear = prim::GetAttr[name="value"](%3123)
  %3125 : __torch__.torch.nn.modules.linear.___torch_mangle_18476.Linear = prim::GetAttr[name="key"](%3123)
  %3126 : __torch__.torch.nn.modules.linear.___torch_mangle_18475.Linear = prim::GetAttr[name="query"](%3123)
  %3127 : Tensor = prim::GetAttr[name="bias"](%3126)
  %3128 : Tensor = prim::GetAttr[name="weight"](%3126)
  %3129 : Float(128:1, 128:128) = aten::t(%3128), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %output.229 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3120, %3129), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %x.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.229, %3127, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1678:0
  %3132 : Tensor = prim::GetAttr[name="bias"](%3125)
  %3133 : Tensor = prim::GetAttr[name="weight"](%3125)
  %3134 : Float(128:1, 128:128) = aten::t(%3133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %output.230 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3120, %3134), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %x.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.230, %3132, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1678:0
  %3137 : Tensor = prim::GetAttr[name="bias"](%3124)
  %3138 : Tensor = prim::GetAttr[name="weight"](%3124)
  %3139 : Float(512:1, 128:512) = aten::t(%3138), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %output.231 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3139), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %x.95 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.231, %3137, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1678:0
  %3142 : int = aten::size(%x.91, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3143 : int = aten::size(%x.91, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3144 : int[] = prim::ListConstruct(%3142, %3143, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.92 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.91, %3144), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3146 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %query_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.92, %3146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3148 : int = aten::size(%x.93, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3149 : int = aten::size(%x.93, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3150 : int[] = prim::ListConstruct(%3148, %3149, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.94 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.93, %3150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3152 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %key_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.94, %3152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3154 : int = aten::size(%x.95, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3155 : int = aten::size(%x.95, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3156 : int[] = prim::ListConstruct(%3154, %3155, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.96 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.95, %3156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3158 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %value_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.96, %3158), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3160 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.16, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.31 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.16, %3160), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.32 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.31, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.294 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.32, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.295 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.294, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.295, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.31 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.16, %value_layer.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:280:0
  %3167 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %3168 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.31, %3167), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3168, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %3170 : int = aten::size(%context_layer.32, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3171 : int = aten::size(%context_layer.32, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3172 : int[] = prim::ListConstruct(%3170, %3171, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %input.296 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.32, %3172), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:283:0
  %3174 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18481.NoNorm = prim::GetAttr[name="LayerNorm"](%3122)
  %3175 : __torch__.torch.nn.modules.linear.___torch_mangle_18480.Linear = prim::GetAttr[name="dense"](%3122)
  %3176 : Tensor = prim::GetAttr[name="bias"](%3175)
  %3177 : Tensor = prim::GetAttr[name="weight"](%3175)
  %3178 : Float(128:1, 128:128) = aten::t(%3177), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %output.232 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.296, %3178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.76 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.232, %3176, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.124 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.76, %3121, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output # transformers/modeling_mobilebert.py:301:0
  %3182 : Tensor = prim::GetAttr[name="bias"](%3174)
  %3183 : Tensor = prim::GetAttr[name="weight"](%3174)
  %3184 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.124, %3183), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.297 : Float(17:1664, 13:128, 128:1) = aten::add(%3184, %3182, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3186 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18504.FFNOutput = prim::GetAttr[name="output"](%3092)
  %3187 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18501.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3092)
  %3188 : __torch__.torch.nn.modules.linear.___torch_mangle_18500.Linear = prim::GetAttr[name="dense"](%3187)
  %3189 : Tensor = prim::GetAttr[name="bias"](%3188)
  %3190 : Tensor = prim::GetAttr[name="weight"](%3188)
  %3191 : Float(128:1, 512:128) = aten::t(%3190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.233 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.297, %3191), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.298 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.233, %3189, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.299 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3195 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18503.NoNorm = prim::GetAttr[name="LayerNorm"](%3186)
  %3196 : __torch__.torch.nn.modules.linear.___torch_mangle_18502.Linear = prim::GetAttr[name="dense"](%3186)
  %3197 : Tensor = prim::GetAttr[name="bias"](%3196)
  %3198 : Tensor = prim::GetAttr[name="weight"](%3196)
  %3199 : Float(512:1, 128:512) = aten::t(%3198), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.234 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.299, %3199), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.234, %3197, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.125 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.77, %input.297, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3203 : Tensor = prim::GetAttr[name="bias"](%3195)
  %3204 : Tensor = prim::GetAttr[name="weight"](%3195)
  %3205 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.125, %3204), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.300 : Float(17:1664, 13:128, 128:1) = aten::add(%3205, %3203, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3207 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18510.FFNOutput = prim::GetAttr[name="output"](%3090)
  %3208 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18507.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3090)
  %3209 : __torch__.torch.nn.modules.linear.___torch_mangle_18506.Linear = prim::GetAttr[name="dense"](%3208)
  %3210 : Tensor = prim::GetAttr[name="bias"](%3209)
  %3211 : Tensor = prim::GetAttr[name="weight"](%3209)
  %3212 : Float(128:1, 512:128) = aten::t(%3211), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.235 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.300, %3212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.301 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.235, %3210, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.302 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3216 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18509.NoNorm = prim::GetAttr[name="LayerNorm"](%3207)
  %3217 : __torch__.torch.nn.modules.linear.___torch_mangle_18508.Linear = prim::GetAttr[name="dense"](%3207)
  %3218 : Tensor = prim::GetAttr[name="bias"](%3217)
  %3219 : Tensor = prim::GetAttr[name="weight"](%3217)
  %3220 : Float(512:1, 128:512) = aten::t(%3219), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.236 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.302, %3220), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.78 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.236, %3218, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.126 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.78, %input.300, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3224 : Tensor = prim::GetAttr[name="bias"](%3216)
  %3225 : Tensor = prim::GetAttr[name="weight"](%3216)
  %3226 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.126, %3225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.303 : Float(17:1664, 13:128, 128:1) = aten::add(%3226, %3224, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3228 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18516.FFNOutput = prim::GetAttr[name="output"](%3088)
  %3229 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18513.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3088)
  %3230 : __torch__.torch.nn.modules.linear.___torch_mangle_18512.Linear = prim::GetAttr[name="dense"](%3229)
  %3231 : Tensor = prim::GetAttr[name="bias"](%3230)
  %3232 : Tensor = prim::GetAttr[name="weight"](%3230)
  %3233 : Float(128:1, 512:128) = aten::t(%3232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.237 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.303, %3233), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.304 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.237, %3231, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.305 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3237 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18515.NoNorm = prim::GetAttr[name="LayerNorm"](%3228)
  %3238 : __torch__.torch.nn.modules.linear.___torch_mangle_18514.Linear = prim::GetAttr[name="dense"](%3228)
  %3239 : Tensor = prim::GetAttr[name="bias"](%3238)
  %3240 : Tensor = prim::GetAttr[name="weight"](%3238)
  %3241 : Float(512:1, 128:512) = aten::t(%3240), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.238 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.305, %3241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.238, %3239, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.127 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.79, %input.303, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3245 : Tensor = prim::GetAttr[name="bias"](%3237)
  %3246 : Tensor = prim::GetAttr[name="weight"](%3237)
  %3247 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.127, %3246), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.306 : Float(17:1664, 13:128, 128:1) = aten::add(%3247, %3245, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3249 : __torch__.torch.nn.modules.linear.___torch_mangle_18484.Linear = prim::GetAttr[name="dense"](%3086)
  %3250 : Tensor = prim::GetAttr[name="bias"](%3249)
  %3251 : Tensor = prim::GetAttr[name="weight"](%3249)
  %3252 : Float(128:1, 512:128) = aten::t(%3251), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %output.239 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.306, %3252), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %input.307 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.239, %3250, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1678:0
  %input.308 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate # torch/nn/functional.py:1119:0
  %3256 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18491.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3085)
  %3257 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18487.NoNorm = prim::GetAttr[name="LayerNorm"](%3085)
  %3258 : __torch__.torch.nn.modules.linear.___torch_mangle_18486.Linear = prim::GetAttr[name="dense"](%3085)
  %3259 : Tensor = prim::GetAttr[name="bias"](%3258)
  %3260 : Tensor = prim::GetAttr[name="weight"](%3258)
  %3261 : Float(512:1, 128:512) = aten::t(%3260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %output.240 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.308, %3261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %layer_output.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.240, %3259, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.128 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.16, %input.306, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output # transformers/modeling_mobilebert.py:405:0
  %3265 : Tensor = prim::GetAttr[name="bias"](%3257)
  %3266 : Tensor = prim::GetAttr[name="weight"](%3257)
  %3267 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.128, %3266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.309 : Float(17:1664, 13:128, 128:1) = aten::add(%3267, %3265, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3269 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18489.NoNorm = prim::GetAttr[name="LayerNorm"](%3256)
  %3270 : __torch__.torch.nn.modules.linear.___torch_mangle_18488.Linear = prim::GetAttr[name="dense"](%3256)
  %3271 : Tensor = prim::GetAttr[name="bias"](%3270)
  %3272 : Tensor = prim::GetAttr[name="weight"](%3270)
  %3273 : Float(128:1, 512:128) = aten::t(%3272), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.241 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.309, %3273), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.310 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.241, %3271, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.80 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.310, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.129 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.80, %input.292, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3278 : Tensor = prim::GetAttr[name="bias"](%3269)
  %3279 : Tensor = prim::GetAttr[name="weight"](%3269)
  %3280 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.129, %3279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.311 : Float(17:6656, 13:512, 512:1) = aten::add(%3280, %3278, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3282 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18537.MobileBertOutput = prim::GetAttr[name="output"](%97)
  %3283 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18530.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%97)
  %3284 : __torch__.torch.nn.modules.container.___torch_mangle_18563.ModuleList = prim::GetAttr[name="ffn"](%97)
  %3285 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18562.FFNLayer = prim::GetAttr[name="2"](%3284)
  %3286 : __torch__.torch.nn.modules.container.___torch_mangle_18563.ModuleList = prim::GetAttr[name="ffn"](%97)
  %3287 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18556.FFNLayer = prim::GetAttr[name="1"](%3286)
  %3288 : __torch__.torch.nn.modules.container.___torch_mangle_18563.ModuleList = prim::GetAttr[name="ffn"](%97)
  %3289 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18550.FFNLayer = prim::GetAttr[name="0"](%3288)
  %3290 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18528.MobileBertAttention = prim::GetAttr[name="attention"](%97)
  %3291 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18544.Bottleneck = prim::GetAttr[name="bottleneck"](%97)
  %3292 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18543.BottleneckLayer = prim::GetAttr[name="attention"](%3291)
  %3293 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18540.BottleneckLayer = prim::GetAttr[name="input"](%3291)
  %3294 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18539.NoNorm = prim::GetAttr[name="LayerNorm"](%3293)
  %3295 : __torch__.torch.nn.modules.linear.___torch_mangle_18538.Linear = prim::GetAttr[name="dense"](%3293)
  %3296 : Tensor = prim::GetAttr[name="bias"](%3295)
  %3297 : Tensor = prim::GetAttr[name="weight"](%3295)
  %3298 : Float(512:1, 128:512) = aten::t(%3297), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.242 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.130 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.242, %3296, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3301 : Tensor = prim::GetAttr[name="bias"](%3294)
  %3302 : Tensor = prim::GetAttr[name="weight"](%3294)
  %3303 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.130, %3302), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.17 : Float(17:1664, 13:128, 128:1) = aten::add(%3303, %3301, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3305 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18542.NoNorm = prim::GetAttr[name="LayerNorm"](%3292)
  %3306 : __torch__.torch.nn.modules.linear.___torch_mangle_18541.Linear = prim::GetAttr[name="dense"](%3292)
  %3307 : Tensor = prim::GetAttr[name="bias"](%3306)
  %3308 : Tensor = prim::GetAttr[name="weight"](%3306)
  %3309 : Float(512:1, 128:512) = aten::t(%3308), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.243 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3309), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.243, %3307, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3312 : Tensor = prim::GetAttr[name="bias"](%3305)
  %3313 : Tensor = prim::GetAttr[name="weight"](%3305)
  %3314 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.131, %3313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.312 : Float(17:1664, 13:128, 128:1) = aten::add(%3314, %3312, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3316 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.312, %residual_tensor.17)
  %3317 : Float(17:1664, 13:128, 128:1), %3318 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3316)
  %3319 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18527.MobileBertSelfOutput = prim::GetAttr[name="output"](%3290)
  %3320 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18524.MobileBertSelfAttention = prim::GetAttr[name="self"](%3290)
  %3321 : __torch__.torch.nn.modules.linear.___torch_mangle_18522.Linear = prim::GetAttr[name="value"](%3320)
  %3322 : __torch__.torch.nn.modules.linear.___torch_mangle_18521.Linear = prim::GetAttr[name="key"](%3320)
  %3323 : __torch__.torch.nn.modules.linear.___torch_mangle_18520.Linear = prim::GetAttr[name="query"](%3320)
  %3324 : Tensor = prim::GetAttr[name="bias"](%3323)
  %3325 : Tensor = prim::GetAttr[name="weight"](%3323)
  %3326 : Float(128:1, 128:128) = aten::t(%3325), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %output.244 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3317, %3326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %x.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.244, %3324, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1678:0
  %3329 : Tensor = prim::GetAttr[name="bias"](%3322)
  %3330 : Tensor = prim::GetAttr[name="weight"](%3322)
  %3331 : Float(128:1, 128:128) = aten::t(%3330), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %output.245 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3317, %3331), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %x.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.245, %3329, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1678:0
  %3334 : Tensor = prim::GetAttr[name="bias"](%3321)
  %3335 : Tensor = prim::GetAttr[name="weight"](%3321)
  %3336 : Float(512:1, 128:512) = aten::t(%3335), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %output.246 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %x.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.246, %3334, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1678:0
  %3339 : int = aten::size(%x.97, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3340 : int = aten::size(%x.97, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3341 : int[] = prim::ListConstruct(%3339, %3340, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.98 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.97, %3341), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3343 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %query_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.98, %3343), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3345 : int = aten::size(%x.99, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3346 : int = aten::size(%x.99, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3347 : int[] = prim::ListConstruct(%3345, %3346, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.100 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.99, %3347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3349 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %key_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.100, %3349), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3351 : int = aten::size(%x.101, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3352 : int = aten::size(%x.101, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3353 : int[] = prim::ListConstruct(%3351, %3352, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.102 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.101, %3353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3355 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %value_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.102, %3355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3357 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.17, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.33 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.17, %3357), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.34 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.33, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.313 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.34, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.314 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.313, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.314, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.33 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.17, %value_layer.17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:280:0
  %3364 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %3365 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.33, %3364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3365, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %3367 : int = aten::size(%context_layer.34, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3368 : int = aten::size(%context_layer.34, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3369 : int[] = prim::ListConstruct(%3367, %3368, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %input.315 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.34, %3369), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:283:0
  %3371 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18526.NoNorm = prim::GetAttr[name="LayerNorm"](%3319)
  %3372 : __torch__.torch.nn.modules.linear.___torch_mangle_18525.Linear = prim::GetAttr[name="dense"](%3319)
  %3373 : Tensor = prim::GetAttr[name="bias"](%3372)
  %3374 : Tensor = prim::GetAttr[name="weight"](%3372)
  %3375 : Float(128:1, 128:128) = aten::t(%3374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %output.247 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.315, %3375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.247, %3373, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.132 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.81, %3318, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output # transformers/modeling_mobilebert.py:301:0
  %3379 : Tensor = prim::GetAttr[name="bias"](%3371)
  %3380 : Tensor = prim::GetAttr[name="weight"](%3371)
  %3381 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.132, %3380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.316 : Float(17:1664, 13:128, 128:1) = aten::add(%3381, %3379, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3383 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18549.FFNOutput = prim::GetAttr[name="output"](%3289)
  %3384 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18546.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3289)
  %3385 : __torch__.torch.nn.modules.linear.___torch_mangle_18545.Linear = prim::GetAttr[name="dense"](%3384)
  %3386 : Tensor = prim::GetAttr[name="bias"](%3385)
  %3387 : Tensor = prim::GetAttr[name="weight"](%3385)
  %3388 : Float(128:1, 512:128) = aten::t(%3387), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.248 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.316, %3388), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.317 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.248, %3386, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.318 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3392 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18548.NoNorm = prim::GetAttr[name="LayerNorm"](%3383)
  %3393 : __torch__.torch.nn.modules.linear.___torch_mangle_18547.Linear = prim::GetAttr[name="dense"](%3383)
  %3394 : Tensor = prim::GetAttr[name="bias"](%3393)
  %3395 : Tensor = prim::GetAttr[name="weight"](%3393)
  %3396 : Float(512:1, 128:512) = aten::t(%3395), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.249 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.318, %3396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.249, %3394, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.133 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.82, %input.316, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3400 : Tensor = prim::GetAttr[name="bias"](%3392)
  %3401 : Tensor = prim::GetAttr[name="weight"](%3392)
  %3402 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.133, %3401), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.319 : Float(17:1664, 13:128, 128:1) = aten::add(%3402, %3400, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3404 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18555.FFNOutput = prim::GetAttr[name="output"](%3287)
  %3405 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18552.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3287)
  %3406 : __torch__.torch.nn.modules.linear.___torch_mangle_18551.Linear = prim::GetAttr[name="dense"](%3405)
  %3407 : Tensor = prim::GetAttr[name="bias"](%3406)
  %3408 : Tensor = prim::GetAttr[name="weight"](%3406)
  %3409 : Float(128:1, 512:128) = aten::t(%3408), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.250 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.319, %3409), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.320 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.250, %3407, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.321 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3413 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18554.NoNorm = prim::GetAttr[name="LayerNorm"](%3404)
  %3414 : __torch__.torch.nn.modules.linear.___torch_mangle_18553.Linear = prim::GetAttr[name="dense"](%3404)
  %3415 : Tensor = prim::GetAttr[name="bias"](%3414)
  %3416 : Tensor = prim::GetAttr[name="weight"](%3414)
  %3417 : Float(512:1, 128:512) = aten::t(%3416), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.251 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.321, %3417), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.251, %3415, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.134 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.83, %input.319, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3421 : Tensor = prim::GetAttr[name="bias"](%3413)
  %3422 : Tensor = prim::GetAttr[name="weight"](%3413)
  %3423 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.134, %3422), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.322 : Float(17:1664, 13:128, 128:1) = aten::add(%3423, %3421, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3425 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18561.FFNOutput = prim::GetAttr[name="output"](%3285)
  %3426 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18558.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3285)
  %3427 : __torch__.torch.nn.modules.linear.___torch_mangle_18557.Linear = prim::GetAttr[name="dense"](%3426)
  %3428 : Tensor = prim::GetAttr[name="bias"](%3427)
  %3429 : Tensor = prim::GetAttr[name="weight"](%3427)
  %3430 : Float(128:1, 512:128) = aten::t(%3429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.252 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.322, %3430), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.323 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.252, %3428, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.324 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3434 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18560.NoNorm = prim::GetAttr[name="LayerNorm"](%3425)
  %3435 : __torch__.torch.nn.modules.linear.___torch_mangle_18559.Linear = prim::GetAttr[name="dense"](%3425)
  %3436 : Tensor = prim::GetAttr[name="bias"](%3435)
  %3437 : Tensor = prim::GetAttr[name="weight"](%3435)
  %3438 : Float(512:1, 128:512) = aten::t(%3437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.253 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.324, %3438), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.84 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.253, %3436, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.135 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.84, %input.322, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3442 : Tensor = prim::GetAttr[name="bias"](%3434)
  %3443 : Tensor = prim::GetAttr[name="weight"](%3434)
  %3444 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.135, %3443), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.325 : Float(17:1664, 13:128, 128:1) = aten::add(%3444, %3442, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3446 : __torch__.torch.nn.modules.linear.___torch_mangle_18529.Linear = prim::GetAttr[name="dense"](%3283)
  %3447 : Tensor = prim::GetAttr[name="bias"](%3446)
  %3448 : Tensor = prim::GetAttr[name="weight"](%3446)
  %3449 : Float(128:1, 512:128) = aten::t(%3448), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %output.254 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.325, %3449), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %input.326 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.254, %3447, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1678:0
  %input.327 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate # torch/nn/functional.py:1119:0
  %3453 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18536.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3282)
  %3454 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18532.NoNorm = prim::GetAttr[name="LayerNorm"](%3282)
  %3455 : __torch__.torch.nn.modules.linear.___torch_mangle_18531.Linear = prim::GetAttr[name="dense"](%3282)
  %3456 : Tensor = prim::GetAttr[name="bias"](%3455)
  %3457 : Tensor = prim::GetAttr[name="weight"](%3455)
  %3458 : Float(512:1, 128:512) = aten::t(%3457), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %output.255 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.327, %3458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %layer_output.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.255, %3456, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.136 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.17, %input.325, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output # transformers/modeling_mobilebert.py:405:0
  %3462 : Tensor = prim::GetAttr[name="bias"](%3454)
  %3463 : Tensor = prim::GetAttr[name="weight"](%3454)
  %3464 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.136, %3463), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.328 : Float(17:1664, 13:128, 128:1) = aten::add(%3464, %3462, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3466 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18534.NoNorm = prim::GetAttr[name="LayerNorm"](%3453)
  %3467 : __torch__.torch.nn.modules.linear.___torch_mangle_18533.Linear = prim::GetAttr[name="dense"](%3453)
  %3468 : Tensor = prim::GetAttr[name="bias"](%3467)
  %3469 : Tensor = prim::GetAttr[name="weight"](%3467)
  %3470 : Float(128:1, 512:128) = aten::t(%3469), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.256 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.328, %3470), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.329 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.256, %3468, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.85 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.329, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.137 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.85, %input.311, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3475 : Tensor = prim::GetAttr[name="bias"](%3466)
  %3476 : Tensor = prim::GetAttr[name="weight"](%3466)
  %3477 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.137, %3476), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.330 : Float(17:6656, 13:512, 512:1) = aten::add(%3477, %3475, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3479 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18582.MobileBertOutput = prim::GetAttr[name="output"](%95)
  %3480 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18575.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%95)
  %3481 : __torch__.torch.nn.modules.container.___torch_mangle_18608.ModuleList = prim::GetAttr[name="ffn"](%95)
  %3482 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18607.FFNLayer = prim::GetAttr[name="2"](%3481)
  %3483 : __torch__.torch.nn.modules.container.___torch_mangle_18608.ModuleList = prim::GetAttr[name="ffn"](%95)
  %3484 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18601.FFNLayer = prim::GetAttr[name="1"](%3483)
  %3485 : __torch__.torch.nn.modules.container.___torch_mangle_18608.ModuleList = prim::GetAttr[name="ffn"](%95)
  %3486 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18595.FFNLayer = prim::GetAttr[name="0"](%3485)
  %3487 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18573.MobileBertAttention = prim::GetAttr[name="attention"](%95)
  %3488 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18589.Bottleneck = prim::GetAttr[name="bottleneck"](%95)
  %3489 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18588.BottleneckLayer = prim::GetAttr[name="attention"](%3488)
  %3490 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18585.BottleneckLayer = prim::GetAttr[name="input"](%3488)
  %3491 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18584.NoNorm = prim::GetAttr[name="LayerNorm"](%3490)
  %3492 : __torch__.torch.nn.modules.linear.___torch_mangle_18583.Linear = prim::GetAttr[name="dense"](%3490)
  %3493 : Tensor = prim::GetAttr[name="bias"](%3492)
  %3494 : Tensor = prim::GetAttr[name="weight"](%3492)
  %3495 : Float(512:1, 128:512) = aten::t(%3494), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.257 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3495), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.138 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.257, %3493, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3498 : Tensor = prim::GetAttr[name="bias"](%3491)
  %3499 : Tensor = prim::GetAttr[name="weight"](%3491)
  %3500 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.138, %3499), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add(%3500, %3498, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3502 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18587.NoNorm = prim::GetAttr[name="LayerNorm"](%3489)
  %3503 : __torch__.torch.nn.modules.linear.___torch_mangle_18586.Linear = prim::GetAttr[name="dense"](%3489)
  %3504 : Tensor = prim::GetAttr[name="bias"](%3503)
  %3505 : Tensor = prim::GetAttr[name="weight"](%3503)
  %3506 : Float(512:1, 128:512) = aten::t(%3505), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.258 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3506), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.258, %3504, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3509 : Tensor = prim::GetAttr[name="bias"](%3502)
  %3510 : Tensor = prim::GetAttr[name="weight"](%3502)
  %3511 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.139, %3510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.331 : Float(17:1664, 13:128, 128:1) = aten::add(%3511, %3509, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3513 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.331, %residual_tensor.18)
  %3514 : Float(17:1664, 13:128, 128:1), %3515 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3513)
  %3516 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18572.MobileBertSelfOutput = prim::GetAttr[name="output"](%3487)
  %3517 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18569.MobileBertSelfAttention = prim::GetAttr[name="self"](%3487)
  %3518 : __torch__.torch.nn.modules.linear.___torch_mangle_18567.Linear = prim::GetAttr[name="value"](%3517)
  %3519 : __torch__.torch.nn.modules.linear.___torch_mangle_18566.Linear = prim::GetAttr[name="key"](%3517)
  %3520 : __torch__.torch.nn.modules.linear.___torch_mangle_18565.Linear = prim::GetAttr[name="query"](%3517)
  %3521 : Tensor = prim::GetAttr[name="bias"](%3520)
  %3522 : Tensor = prim::GetAttr[name="weight"](%3520)
  %3523 : Float(128:1, 128:128) = aten::t(%3522), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %output.259 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3514, %3523), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %x.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.259, %3521, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1678:0
  %3526 : Tensor = prim::GetAttr[name="bias"](%3519)
  %3527 : Tensor = prim::GetAttr[name="weight"](%3519)
  %3528 : Float(128:1, 128:128) = aten::t(%3527), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %output.260 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3514, %3528), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %x.105 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.260, %3526, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1678:0
  %3531 : Tensor = prim::GetAttr[name="bias"](%3518)
  %3532 : Tensor = prim::GetAttr[name="weight"](%3518)
  %3533 : Float(512:1, 128:512) = aten::t(%3532), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %output.261 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %x.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.261, %3531, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1678:0
  %3536 : int = aten::size(%x.103, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3537 : int = aten::size(%x.103, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3538 : int[] = prim::ListConstruct(%3536, %3537, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.104 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.103, %3538), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3540 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %query_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.104, %3540), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3542 : int = aten::size(%x.105, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3543 : int = aten::size(%x.105, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3544 : int[] = prim::ListConstruct(%3542, %3543, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.106 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.105, %3544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3546 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %key_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.106, %3546), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3548 : int = aten::size(%x.107, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3549 : int = aten::size(%x.107, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3550 : int[] = prim::ListConstruct(%3548, %3549, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.108 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.107, %3550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3552 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %value_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.108, %3552), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3554 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.18, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.35 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.18, %3554), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.36 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.35, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.332 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.36, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.333 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.332, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.333, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.35 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.18, %value_layer.18), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:280:0
  %3561 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %3562 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.35, %3561), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3562, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %3564 : int = aten::size(%context_layer.36, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3565 : int = aten::size(%context_layer.36, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3566 : int[] = prim::ListConstruct(%3564, %3565, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %input.334 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.36, %3566), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:283:0
  %3568 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18571.NoNorm = prim::GetAttr[name="LayerNorm"](%3516)
  %3569 : __torch__.torch.nn.modules.linear.___torch_mangle_18570.Linear = prim::GetAttr[name="dense"](%3516)
  %3570 : Tensor = prim::GetAttr[name="bias"](%3569)
  %3571 : Tensor = prim::GetAttr[name="weight"](%3569)
  %3572 : Float(128:1, 128:128) = aten::t(%3571), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %output.262 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.334, %3572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.86 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.262, %3570, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.140 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.86, %3515, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output # transformers/modeling_mobilebert.py:301:0
  %3576 : Tensor = prim::GetAttr[name="bias"](%3568)
  %3577 : Tensor = prim::GetAttr[name="weight"](%3568)
  %3578 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.140, %3577), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.335 : Float(17:1664, 13:128, 128:1) = aten::add(%3578, %3576, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3580 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18594.FFNOutput = prim::GetAttr[name="output"](%3486)
  %3581 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18591.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3486)
  %3582 : __torch__.torch.nn.modules.linear.___torch_mangle_18590.Linear = prim::GetAttr[name="dense"](%3581)
  %3583 : Tensor = prim::GetAttr[name="bias"](%3582)
  %3584 : Tensor = prim::GetAttr[name="weight"](%3582)
  %3585 : Float(128:1, 512:128) = aten::t(%3584), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.263 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.335, %3585), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.336 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.263, %3583, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.337 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3589 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18593.NoNorm = prim::GetAttr[name="LayerNorm"](%3580)
  %3590 : __torch__.torch.nn.modules.linear.___torch_mangle_18592.Linear = prim::GetAttr[name="dense"](%3580)
  %3591 : Tensor = prim::GetAttr[name="bias"](%3590)
  %3592 : Tensor = prim::GetAttr[name="weight"](%3590)
  %3593 : Float(512:1, 128:512) = aten::t(%3592), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.264 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.337, %3593), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.264, %3591, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.141 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.87, %input.335, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3597 : Tensor = prim::GetAttr[name="bias"](%3589)
  %3598 : Tensor = prim::GetAttr[name="weight"](%3589)
  %3599 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.141, %3598), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.338 : Float(17:1664, 13:128, 128:1) = aten::add(%3599, %3597, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3601 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18600.FFNOutput = prim::GetAttr[name="output"](%3484)
  %3602 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18597.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3484)
  %3603 : __torch__.torch.nn.modules.linear.___torch_mangle_18596.Linear = prim::GetAttr[name="dense"](%3602)
  %3604 : Tensor = prim::GetAttr[name="bias"](%3603)
  %3605 : Tensor = prim::GetAttr[name="weight"](%3603)
  %3606 : Float(128:1, 512:128) = aten::t(%3605), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.265 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.338, %3606), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.339 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.265, %3604, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.340 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3610 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18599.NoNorm = prim::GetAttr[name="LayerNorm"](%3601)
  %3611 : __torch__.torch.nn.modules.linear.___torch_mangle_18598.Linear = prim::GetAttr[name="dense"](%3601)
  %3612 : Tensor = prim::GetAttr[name="bias"](%3611)
  %3613 : Tensor = prim::GetAttr[name="weight"](%3611)
  %3614 : Float(512:1, 128:512) = aten::t(%3613), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.266 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.340, %3614), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.88 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.266, %3612, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.142 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.88, %input.338, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3618 : Tensor = prim::GetAttr[name="bias"](%3610)
  %3619 : Tensor = prim::GetAttr[name="weight"](%3610)
  %3620 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.142, %3619), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.341 : Float(17:1664, 13:128, 128:1) = aten::add(%3620, %3618, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3622 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18606.FFNOutput = prim::GetAttr[name="output"](%3482)
  %3623 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18603.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3482)
  %3624 : __torch__.torch.nn.modules.linear.___torch_mangle_18602.Linear = prim::GetAttr[name="dense"](%3623)
  %3625 : Tensor = prim::GetAttr[name="bias"](%3624)
  %3626 : Tensor = prim::GetAttr[name="weight"](%3624)
  %3627 : Float(128:1, 512:128) = aten::t(%3626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.267 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.341, %3627), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.342 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.267, %3625, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.343 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3631 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18605.NoNorm = prim::GetAttr[name="LayerNorm"](%3622)
  %3632 : __torch__.torch.nn.modules.linear.___torch_mangle_18604.Linear = prim::GetAttr[name="dense"](%3622)
  %3633 : Tensor = prim::GetAttr[name="bias"](%3632)
  %3634 : Tensor = prim::GetAttr[name="weight"](%3632)
  %3635 : Float(512:1, 128:512) = aten::t(%3634), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.268 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.343, %3635), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.268, %3633, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.143 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.89, %input.341, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3639 : Tensor = prim::GetAttr[name="bias"](%3631)
  %3640 : Tensor = prim::GetAttr[name="weight"](%3631)
  %3641 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.143, %3640), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.344 : Float(17:1664, 13:128, 128:1) = aten::add(%3641, %3639, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3643 : __torch__.torch.nn.modules.linear.___torch_mangle_18574.Linear = prim::GetAttr[name="dense"](%3480)
  %3644 : Tensor = prim::GetAttr[name="bias"](%3643)
  %3645 : Tensor = prim::GetAttr[name="weight"](%3643)
  %3646 : Float(128:1, 512:128) = aten::t(%3645), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %output.269 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.344, %3646), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %input.345 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.269, %3644, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1678:0
  %input.346 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate # torch/nn/functional.py:1119:0
  %3650 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18581.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3479)
  %3651 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18577.NoNorm = prim::GetAttr[name="LayerNorm"](%3479)
  %3652 : __torch__.torch.nn.modules.linear.___torch_mangle_18576.Linear = prim::GetAttr[name="dense"](%3479)
  %3653 : Tensor = prim::GetAttr[name="bias"](%3652)
  %3654 : Tensor = prim::GetAttr[name="weight"](%3652)
  %3655 : Float(512:1, 128:512) = aten::t(%3654), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %output.270 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.346, %3655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %layer_output.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.270, %3653, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.144 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.18, %input.344, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output # transformers/modeling_mobilebert.py:405:0
  %3659 : Tensor = prim::GetAttr[name="bias"](%3651)
  %3660 : Tensor = prim::GetAttr[name="weight"](%3651)
  %3661 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.144, %3660), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.347 : Float(17:1664, 13:128, 128:1) = aten::add(%3661, %3659, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3663 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18579.NoNorm = prim::GetAttr[name="LayerNorm"](%3650)
  %3664 : __torch__.torch.nn.modules.linear.___torch_mangle_18578.Linear = prim::GetAttr[name="dense"](%3650)
  %3665 : Tensor = prim::GetAttr[name="bias"](%3664)
  %3666 : Tensor = prim::GetAttr[name="weight"](%3664)
  %3667 : Float(128:1, 512:128) = aten::t(%3666), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.271 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.347, %3667), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.348 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.271, %3665, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.90 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.348, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.145 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.90, %input.330, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3672 : Tensor = prim::GetAttr[name="bias"](%3663)
  %3673 : Tensor = prim::GetAttr[name="weight"](%3663)
  %3674 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.145, %3673), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.349 : Float(17:6656, 13:512, 512:1) = aten::add(%3674, %3672, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3676 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18627.MobileBertOutput = prim::GetAttr[name="output"](%93)
  %3677 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18620.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%93)
  %3678 : __torch__.torch.nn.modules.container.___torch_mangle_18653.ModuleList = prim::GetAttr[name="ffn"](%93)
  %3679 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18652.FFNLayer = prim::GetAttr[name="2"](%3678)
  %3680 : __torch__.torch.nn.modules.container.___torch_mangle_18653.ModuleList = prim::GetAttr[name="ffn"](%93)
  %3681 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18646.FFNLayer = prim::GetAttr[name="1"](%3680)
  %3682 : __torch__.torch.nn.modules.container.___torch_mangle_18653.ModuleList = prim::GetAttr[name="ffn"](%93)
  %3683 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18640.FFNLayer = prim::GetAttr[name="0"](%3682)
  %3684 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18618.MobileBertAttention = prim::GetAttr[name="attention"](%93)
  %3685 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18634.Bottleneck = prim::GetAttr[name="bottleneck"](%93)
  %3686 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18633.BottleneckLayer = prim::GetAttr[name="attention"](%3685)
  %3687 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18630.BottleneckLayer = prim::GetAttr[name="input"](%3685)
  %3688 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18629.NoNorm = prim::GetAttr[name="LayerNorm"](%3687)
  %3689 : __torch__.torch.nn.modules.linear.___torch_mangle_18628.Linear = prim::GetAttr[name="dense"](%3687)
  %3690 : Tensor = prim::GetAttr[name="bias"](%3689)
  %3691 : Tensor = prim::GetAttr[name="weight"](%3689)
  %3692 : Float(512:1, 128:512) = aten::t(%3691), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.272 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3692), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.146 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.272, %3690, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3695 : Tensor = prim::GetAttr[name="bias"](%3688)
  %3696 : Tensor = prim::GetAttr[name="weight"](%3688)
  %3697 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.146, %3696), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add(%3697, %3695, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3699 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18632.NoNorm = prim::GetAttr[name="LayerNorm"](%3686)
  %3700 : __torch__.torch.nn.modules.linear.___torch_mangle_18631.Linear = prim::GetAttr[name="dense"](%3686)
  %3701 : Tensor = prim::GetAttr[name="bias"](%3700)
  %3702 : Tensor = prim::GetAttr[name="weight"](%3700)
  %3703 : Float(512:1, 128:512) = aten::t(%3702), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.273 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3703), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.147 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.273, %3701, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3706 : Tensor = prim::GetAttr[name="bias"](%3699)
  %3707 : Tensor = prim::GetAttr[name="weight"](%3699)
  %3708 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.147, %3707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.350 : Float(17:1664, 13:128, 128:1) = aten::add(%3708, %3706, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3710 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.350, %residual_tensor.19)
  %3711 : Float(17:1664, 13:128, 128:1), %3712 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3710)
  %3713 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18617.MobileBertSelfOutput = prim::GetAttr[name="output"](%3684)
  %3714 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18614.MobileBertSelfAttention = prim::GetAttr[name="self"](%3684)
  %3715 : __torch__.torch.nn.modules.linear.___torch_mangle_18612.Linear = prim::GetAttr[name="value"](%3714)
  %3716 : __torch__.torch.nn.modules.linear.___torch_mangle_18611.Linear = prim::GetAttr[name="key"](%3714)
  %3717 : __torch__.torch.nn.modules.linear.___torch_mangle_18610.Linear = prim::GetAttr[name="query"](%3714)
  %3718 : Tensor = prim::GetAttr[name="bias"](%3717)
  %3719 : Tensor = prim::GetAttr[name="weight"](%3717)
  %3720 : Float(128:1, 128:128) = aten::t(%3719), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %output.274 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3711, %3720), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %x.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.274, %3718, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1678:0
  %3723 : Tensor = prim::GetAttr[name="bias"](%3716)
  %3724 : Tensor = prim::GetAttr[name="weight"](%3716)
  %3725 : Float(128:1, 128:128) = aten::t(%3724), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %output.275 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3711, %3725), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %x.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.275, %3723, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1678:0
  %3728 : Tensor = prim::GetAttr[name="bias"](%3715)
  %3729 : Tensor = prim::GetAttr[name="weight"](%3715)
  %3730 : Float(512:1, 128:512) = aten::t(%3729), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %output.276 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %x.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.276, %3728, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1678:0
  %3733 : int = aten::size(%x.109, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3734 : int = aten::size(%x.109, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3735 : int[] = prim::ListConstruct(%3733, %3734, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.110 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.109, %3735), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3737 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %query_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.110, %3737), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3739 : int = aten::size(%x.111, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3740 : int = aten::size(%x.111, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3741 : int[] = prim::ListConstruct(%3739, %3740, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.112 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.111, %3741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3743 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %key_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.112, %3743), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3745 : int = aten::size(%x.113, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3746 : int = aten::size(%x.113, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3747 : int[] = prim::ListConstruct(%3745, %3746, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.114 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.113, %3747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3749 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %value_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.114, %3749), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3751 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.19, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.37 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.19, %3751), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.38 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.37, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.351 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.38, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.352 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.351, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.352, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.37 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.19, %value_layer.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:280:0
  %3758 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %3759 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.37, %3758), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3759, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %3761 : int = aten::size(%context_layer.38, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3762 : int = aten::size(%context_layer.38, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3763 : int[] = prim::ListConstruct(%3761, %3762, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %input.353 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.38, %3763), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:283:0
  %3765 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18616.NoNorm = prim::GetAttr[name="LayerNorm"](%3713)
  %3766 : __torch__.torch.nn.modules.linear.___torch_mangle_18615.Linear = prim::GetAttr[name="dense"](%3713)
  %3767 : Tensor = prim::GetAttr[name="bias"](%3766)
  %3768 : Tensor = prim::GetAttr[name="weight"](%3766)
  %3769 : Float(128:1, 128:128) = aten::t(%3768), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %output.277 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.353, %3769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.277, %3767, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.148 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.91, %3712, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output # transformers/modeling_mobilebert.py:301:0
  %3773 : Tensor = prim::GetAttr[name="bias"](%3765)
  %3774 : Tensor = prim::GetAttr[name="weight"](%3765)
  %3775 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.148, %3774), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.354 : Float(17:1664, 13:128, 128:1) = aten::add(%3775, %3773, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3777 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18639.FFNOutput = prim::GetAttr[name="output"](%3683)
  %3778 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18636.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3683)
  %3779 : __torch__.torch.nn.modules.linear.___torch_mangle_18635.Linear = prim::GetAttr[name="dense"](%3778)
  %3780 : Tensor = prim::GetAttr[name="bias"](%3779)
  %3781 : Tensor = prim::GetAttr[name="weight"](%3779)
  %3782 : Float(128:1, 512:128) = aten::t(%3781), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.278 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.354, %3782), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.355 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.278, %3780, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.356 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3786 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18638.NoNorm = prim::GetAttr[name="LayerNorm"](%3777)
  %3787 : __torch__.torch.nn.modules.linear.___torch_mangle_18637.Linear = prim::GetAttr[name="dense"](%3777)
  %3788 : Tensor = prim::GetAttr[name="bias"](%3787)
  %3789 : Tensor = prim::GetAttr[name="weight"](%3787)
  %3790 : Float(512:1, 128:512) = aten::t(%3789), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.279 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.356, %3790), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.92 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.279, %3788, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.149 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.92, %input.354, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3794 : Tensor = prim::GetAttr[name="bias"](%3786)
  %3795 : Tensor = prim::GetAttr[name="weight"](%3786)
  %3796 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.149, %3795), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.357 : Float(17:1664, 13:128, 128:1) = aten::add(%3796, %3794, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3798 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18645.FFNOutput = prim::GetAttr[name="output"](%3681)
  %3799 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18642.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3681)
  %3800 : __torch__.torch.nn.modules.linear.___torch_mangle_18641.Linear = prim::GetAttr[name="dense"](%3799)
  %3801 : Tensor = prim::GetAttr[name="bias"](%3800)
  %3802 : Tensor = prim::GetAttr[name="weight"](%3800)
  %3803 : Float(128:1, 512:128) = aten::t(%3802), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.280 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.357, %3803), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.358 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.280, %3801, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.359 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3807 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18644.NoNorm = prim::GetAttr[name="LayerNorm"](%3798)
  %3808 : __torch__.torch.nn.modules.linear.___torch_mangle_18643.Linear = prim::GetAttr[name="dense"](%3798)
  %3809 : Tensor = prim::GetAttr[name="bias"](%3808)
  %3810 : Tensor = prim::GetAttr[name="weight"](%3808)
  %3811 : Float(512:1, 128:512) = aten::t(%3810), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.281 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.359, %3811), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.281, %3809, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.150 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.93, %input.357, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3815 : Tensor = prim::GetAttr[name="bias"](%3807)
  %3816 : Tensor = prim::GetAttr[name="weight"](%3807)
  %3817 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.150, %3816), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.360 : Float(17:1664, 13:128, 128:1) = aten::add(%3817, %3815, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3819 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18651.FFNOutput = prim::GetAttr[name="output"](%3679)
  %3820 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18648.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3679)
  %3821 : __torch__.torch.nn.modules.linear.___torch_mangle_18647.Linear = prim::GetAttr[name="dense"](%3820)
  %3822 : Tensor = prim::GetAttr[name="bias"](%3821)
  %3823 : Tensor = prim::GetAttr[name="weight"](%3821)
  %3824 : Float(128:1, 512:128) = aten::t(%3823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.282 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.360, %3824), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.361 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.282, %3822, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.362 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3828 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18650.NoNorm = prim::GetAttr[name="LayerNorm"](%3819)
  %3829 : __torch__.torch.nn.modules.linear.___torch_mangle_18649.Linear = prim::GetAttr[name="dense"](%3819)
  %3830 : Tensor = prim::GetAttr[name="bias"](%3829)
  %3831 : Tensor = prim::GetAttr[name="weight"](%3829)
  %3832 : Float(512:1, 128:512) = aten::t(%3831), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.283 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.362, %3832), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.94 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.283, %3830, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.151 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.94, %input.360, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3836 : Tensor = prim::GetAttr[name="bias"](%3828)
  %3837 : Tensor = prim::GetAttr[name="weight"](%3828)
  %3838 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.151, %3837), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.363 : Float(17:1664, 13:128, 128:1) = aten::add(%3838, %3836, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3840 : __torch__.torch.nn.modules.linear.___torch_mangle_18619.Linear = prim::GetAttr[name="dense"](%3677)
  %3841 : Tensor = prim::GetAttr[name="bias"](%3840)
  %3842 : Tensor = prim::GetAttr[name="weight"](%3840)
  %3843 : Float(128:1, 512:128) = aten::t(%3842), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %output.284 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.363, %3843), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %input.364 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.284, %3841, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1678:0
  %input.365 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate # torch/nn/functional.py:1119:0
  %3847 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18626.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3676)
  %3848 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18622.NoNorm = prim::GetAttr[name="LayerNorm"](%3676)
  %3849 : __torch__.torch.nn.modules.linear.___torch_mangle_18621.Linear = prim::GetAttr[name="dense"](%3676)
  %3850 : Tensor = prim::GetAttr[name="bias"](%3849)
  %3851 : Tensor = prim::GetAttr[name="weight"](%3849)
  %3852 : Float(512:1, 128:512) = aten::t(%3851), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %output.285 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.365, %3852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %layer_output.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.285, %3850, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.152 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.19, %input.363, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output # transformers/modeling_mobilebert.py:405:0
  %3856 : Tensor = prim::GetAttr[name="bias"](%3848)
  %3857 : Tensor = prim::GetAttr[name="weight"](%3848)
  %3858 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.152, %3857), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.366 : Float(17:1664, 13:128, 128:1) = aten::add(%3858, %3856, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3860 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18624.NoNorm = prim::GetAttr[name="LayerNorm"](%3847)
  %3861 : __torch__.torch.nn.modules.linear.___torch_mangle_18623.Linear = prim::GetAttr[name="dense"](%3847)
  %3862 : Tensor = prim::GetAttr[name="bias"](%3861)
  %3863 : Tensor = prim::GetAttr[name="weight"](%3861)
  %3864 : Float(128:1, 512:128) = aten::t(%3863), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.286 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.366, %3864), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.367 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.286, %3862, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.95 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.367, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.153 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.95, %input.349, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3869 : Tensor = prim::GetAttr[name="bias"](%3860)
  %3870 : Tensor = prim::GetAttr[name="weight"](%3860)
  %3871 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.153, %3870), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.368 : Float(17:6656, 13:512, 512:1) = aten::add(%3871, %3869, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3873 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18672.MobileBertOutput = prim::GetAttr[name="output"](%91)
  %3874 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18665.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%91)
  %3875 : __torch__.torch.nn.modules.container.___torch_mangle_18698.ModuleList = prim::GetAttr[name="ffn"](%91)
  %3876 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18697.FFNLayer = prim::GetAttr[name="2"](%3875)
  %3877 : __torch__.torch.nn.modules.container.___torch_mangle_18698.ModuleList = prim::GetAttr[name="ffn"](%91)
  %3878 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18691.FFNLayer = prim::GetAttr[name="1"](%3877)
  %3879 : __torch__.torch.nn.modules.container.___torch_mangle_18698.ModuleList = prim::GetAttr[name="ffn"](%91)
  %3880 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18685.FFNLayer = prim::GetAttr[name="0"](%3879)
  %3881 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18663.MobileBertAttention = prim::GetAttr[name="attention"](%91)
  %3882 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18679.Bottleneck = prim::GetAttr[name="bottleneck"](%91)
  %3883 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18678.BottleneckLayer = prim::GetAttr[name="attention"](%3882)
  %3884 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18675.BottleneckLayer = prim::GetAttr[name="input"](%3882)
  %3885 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18674.NoNorm = prim::GetAttr[name="LayerNorm"](%3884)
  %3886 : __torch__.torch.nn.modules.linear.___torch_mangle_18673.Linear = prim::GetAttr[name="dense"](%3884)
  %3887 : Tensor = prim::GetAttr[name="bias"](%3886)
  %3888 : Tensor = prim::GetAttr[name="weight"](%3886)
  %3889 : Float(512:1, 128:512) = aten::t(%3888), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.287 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3889), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.154 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.287, %3887, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3892 : Tensor = prim::GetAttr[name="bias"](%3885)
  %3893 : Tensor = prim::GetAttr[name="weight"](%3885)
  %3894 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.154, %3893), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%3894, %3892, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3896 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18677.NoNorm = prim::GetAttr[name="LayerNorm"](%3883)
  %3897 : __torch__.torch.nn.modules.linear.___torch_mangle_18676.Linear = prim::GetAttr[name="dense"](%3883)
  %3898 : Tensor = prim::GetAttr[name="bias"](%3897)
  %3899 : Tensor = prim::GetAttr[name="weight"](%3897)
  %3900 : Float(512:1, 128:512) = aten::t(%3899), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.288 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3900), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.155 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.288, %3898, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3903 : Tensor = prim::GetAttr[name="bias"](%3896)
  %3904 : Tensor = prim::GetAttr[name="weight"](%3896)
  %3905 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.155, %3904), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.369 : Float(17:1664, 13:128, 128:1) = aten::add(%3905, %3903, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3907 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.369, %residual_tensor.20)
  %3908 : Float(17:1664, 13:128, 128:1), %3909 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3907)
  %3910 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18662.MobileBertSelfOutput = prim::GetAttr[name="output"](%3881)
  %3911 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18659.MobileBertSelfAttention = prim::GetAttr[name="self"](%3881)
  %3912 : __torch__.torch.nn.modules.linear.___torch_mangle_18657.Linear = prim::GetAttr[name="value"](%3911)
  %3913 : __torch__.torch.nn.modules.linear.___torch_mangle_18656.Linear = prim::GetAttr[name="key"](%3911)
  %3914 : __torch__.torch.nn.modules.linear.___torch_mangle_18655.Linear = prim::GetAttr[name="query"](%3911)
  %3915 : Tensor = prim::GetAttr[name="bias"](%3914)
  %3916 : Tensor = prim::GetAttr[name="weight"](%3914)
  %3917 : Float(128:1, 128:128) = aten::t(%3916), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %output.289 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3908, %3917), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %x.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.289, %3915, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1678:0
  %3920 : Tensor = prim::GetAttr[name="bias"](%3913)
  %3921 : Tensor = prim::GetAttr[name="weight"](%3913)
  %3922 : Float(128:1, 128:128) = aten::t(%3921), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %output.290 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3908, %3922), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %x.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.290, %3920, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1678:0
  %3925 : Tensor = prim::GetAttr[name="bias"](%3912)
  %3926 : Tensor = prim::GetAttr[name="weight"](%3912)
  %3927 : Float(512:1, 128:512) = aten::t(%3926), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %output.291 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3927), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %x.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.291, %3925, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1678:0
  %3930 : int = aten::size(%x.115, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3931 : int = aten::size(%x.115, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3932 : int[] = prim::ListConstruct(%3930, %3931, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.116 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.115, %3932), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3934 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %query_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.116, %3934), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3936 : int = aten::size(%x.117, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3937 : int = aten::size(%x.117, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3938 : int[] = prim::ListConstruct(%3936, %3937, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.118 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.117, %3938), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3940 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %key_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.118, %3940), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3942 : int = aten::size(%x.119, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3943 : int = aten::size(%x.119, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3944 : int[] = prim::ListConstruct(%3942, %3943, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.120 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.119, %3944), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3946 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %value_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.120, %3946), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3948 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.20, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.39 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.20, %3948), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.40 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.39, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.370 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.40, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.371 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.370, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.371, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.39 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.20, %value_layer.20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:280:0
  %3955 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %3956 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.39, %3955), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3956, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %3958 : int = aten::size(%context_layer.40, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3959 : int = aten::size(%context_layer.40, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3960 : int[] = prim::ListConstruct(%3958, %3959, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %input.372 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.40, %3960), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:283:0
  %3962 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18661.NoNorm = prim::GetAttr[name="LayerNorm"](%3910)
  %3963 : __torch__.torch.nn.modules.linear.___torch_mangle_18660.Linear = prim::GetAttr[name="dense"](%3910)
  %3964 : Tensor = prim::GetAttr[name="bias"](%3963)
  %3965 : Tensor = prim::GetAttr[name="weight"](%3963)
  %3966 : Float(128:1, 128:128) = aten::t(%3965), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %output.292 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.372, %3966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.96 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.292, %3964, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.156 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.96, %3909, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output # transformers/modeling_mobilebert.py:301:0
  %3970 : Tensor = prim::GetAttr[name="bias"](%3962)
  %3971 : Tensor = prim::GetAttr[name="weight"](%3962)
  %3972 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.156, %3971), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.373 : Float(17:1664, 13:128, 128:1) = aten::add(%3972, %3970, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3974 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18684.FFNOutput = prim::GetAttr[name="output"](%3880)
  %3975 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18681.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3880)
  %3976 : __torch__.torch.nn.modules.linear.___torch_mangle_18680.Linear = prim::GetAttr[name="dense"](%3975)
  %3977 : Tensor = prim::GetAttr[name="bias"](%3976)
  %3978 : Tensor = prim::GetAttr[name="weight"](%3976)
  %3979 : Float(128:1, 512:128) = aten::t(%3978), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.293 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.373, %3979), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.374 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.293, %3977, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.375 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3983 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18683.NoNorm = prim::GetAttr[name="LayerNorm"](%3974)
  %3984 : __torch__.torch.nn.modules.linear.___torch_mangle_18682.Linear = prim::GetAttr[name="dense"](%3974)
  %3985 : Tensor = prim::GetAttr[name="bias"](%3984)
  %3986 : Tensor = prim::GetAttr[name="weight"](%3984)
  %3987 : Float(512:1, 128:512) = aten::t(%3986), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.294 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.375, %3987), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.294, %3985, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.157 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.97, %input.373, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3991 : Tensor = prim::GetAttr[name="bias"](%3983)
  %3992 : Tensor = prim::GetAttr[name="weight"](%3983)
  %3993 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.157, %3992), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.376 : Float(17:1664, 13:128, 128:1) = aten::add(%3993, %3991, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3995 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18690.FFNOutput = prim::GetAttr[name="output"](%3878)
  %3996 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18687.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3878)
  %3997 : __torch__.torch.nn.modules.linear.___torch_mangle_18686.Linear = prim::GetAttr[name="dense"](%3996)
  %3998 : Tensor = prim::GetAttr[name="bias"](%3997)
  %3999 : Tensor = prim::GetAttr[name="weight"](%3997)
  %4000 : Float(128:1, 512:128) = aten::t(%3999), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.295 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.376, %4000), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.377 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.295, %3998, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.378 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4004 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18689.NoNorm = prim::GetAttr[name="LayerNorm"](%3995)
  %4005 : __torch__.torch.nn.modules.linear.___torch_mangle_18688.Linear = prim::GetAttr[name="dense"](%3995)
  %4006 : Tensor = prim::GetAttr[name="bias"](%4005)
  %4007 : Tensor = prim::GetAttr[name="weight"](%4005)
  %4008 : Float(512:1, 128:512) = aten::t(%4007), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.296 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.378, %4008), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.296, %4006, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.158 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.98, %input.376, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4012 : Tensor = prim::GetAttr[name="bias"](%4004)
  %4013 : Tensor = prim::GetAttr[name="weight"](%4004)
  %4014 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.158, %4013), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.379 : Float(17:1664, 13:128, 128:1) = aten::add(%4014, %4012, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4016 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18696.FFNOutput = prim::GetAttr[name="output"](%3876)
  %4017 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18693.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3876)
  %4018 : __torch__.torch.nn.modules.linear.___torch_mangle_18692.Linear = prim::GetAttr[name="dense"](%4017)
  %4019 : Tensor = prim::GetAttr[name="bias"](%4018)
  %4020 : Tensor = prim::GetAttr[name="weight"](%4018)
  %4021 : Float(128:1, 512:128) = aten::t(%4020), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.297 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.379, %4021), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.380 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.297, %4019, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.381 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4025 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18695.NoNorm = prim::GetAttr[name="LayerNorm"](%4016)
  %4026 : __torch__.torch.nn.modules.linear.___torch_mangle_18694.Linear = prim::GetAttr[name="dense"](%4016)
  %4027 : Tensor = prim::GetAttr[name="bias"](%4026)
  %4028 : Tensor = prim::GetAttr[name="weight"](%4026)
  %4029 : Float(512:1, 128:512) = aten::t(%4028), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.298 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.381, %4029), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.298, %4027, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.159 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.99, %input.379, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4033 : Tensor = prim::GetAttr[name="bias"](%4025)
  %4034 : Tensor = prim::GetAttr[name="weight"](%4025)
  %4035 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.159, %4034), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.382 : Float(17:1664, 13:128, 128:1) = aten::add(%4035, %4033, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4037 : __torch__.torch.nn.modules.linear.___torch_mangle_18664.Linear = prim::GetAttr[name="dense"](%3874)
  %4038 : Tensor = prim::GetAttr[name="bias"](%4037)
  %4039 : Tensor = prim::GetAttr[name="weight"](%4037)
  %4040 : Float(128:1, 512:128) = aten::t(%4039), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %output.299 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.382, %4040), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %input.383 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.299, %4038, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1678:0
  %input.384 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate # torch/nn/functional.py:1119:0
  %4044 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18671.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3873)
  %4045 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18667.NoNorm = prim::GetAttr[name="LayerNorm"](%3873)
  %4046 : __torch__.torch.nn.modules.linear.___torch_mangle_18666.Linear = prim::GetAttr[name="dense"](%3873)
  %4047 : Tensor = prim::GetAttr[name="bias"](%4046)
  %4048 : Tensor = prim::GetAttr[name="weight"](%4046)
  %4049 : Float(512:1, 128:512) = aten::t(%4048), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %output.300 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.384, %4049), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %layer_output.20 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.300, %4047, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.160 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.20, %input.382, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output # transformers/modeling_mobilebert.py:405:0
  %4053 : Tensor = prim::GetAttr[name="bias"](%4045)
  %4054 : Tensor = prim::GetAttr[name="weight"](%4045)
  %4055 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.160, %4054), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.385 : Float(17:1664, 13:128, 128:1) = aten::add(%4055, %4053, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4057 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18669.NoNorm = prim::GetAttr[name="LayerNorm"](%4044)
  %4058 : __torch__.torch.nn.modules.linear.___torch_mangle_18668.Linear = prim::GetAttr[name="dense"](%4044)
  %4059 : Tensor = prim::GetAttr[name="bias"](%4058)
  %4060 : Tensor = prim::GetAttr[name="weight"](%4058)
  %4061 : Float(128:1, 512:128) = aten::t(%4060), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.301 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.385, %4061), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.386 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.301, %4059, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.100 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.386, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.161 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.100, %input.368, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4066 : Tensor = prim::GetAttr[name="bias"](%4057)
  %4067 : Tensor = prim::GetAttr[name="weight"](%4057)
  %4068 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.161, %4067), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.387 : Float(17:6656, 13:512, 512:1) = aten::add(%4068, %4066, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4070 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18717.MobileBertOutput = prim::GetAttr[name="output"](%89)
  %4071 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18710.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%89)
  %4072 : __torch__.torch.nn.modules.container.___torch_mangle_18743.ModuleList = prim::GetAttr[name="ffn"](%89)
  %4073 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18742.FFNLayer = prim::GetAttr[name="2"](%4072)
  %4074 : __torch__.torch.nn.modules.container.___torch_mangle_18743.ModuleList = prim::GetAttr[name="ffn"](%89)
  %4075 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18736.FFNLayer = prim::GetAttr[name="1"](%4074)
  %4076 : __torch__.torch.nn.modules.container.___torch_mangle_18743.ModuleList = prim::GetAttr[name="ffn"](%89)
  %4077 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18730.FFNLayer = prim::GetAttr[name="0"](%4076)
  %4078 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18708.MobileBertAttention = prim::GetAttr[name="attention"](%89)
  %4079 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18724.Bottleneck = prim::GetAttr[name="bottleneck"](%89)
  %4080 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18723.BottleneckLayer = prim::GetAttr[name="attention"](%4079)
  %4081 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18720.BottleneckLayer = prim::GetAttr[name="input"](%4079)
  %4082 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18719.NoNorm = prim::GetAttr[name="LayerNorm"](%4081)
  %4083 : __torch__.torch.nn.modules.linear.___torch_mangle_18718.Linear = prim::GetAttr[name="dense"](%4081)
  %4084 : Tensor = prim::GetAttr[name="bias"](%4083)
  %4085 : Tensor = prim::GetAttr[name="weight"](%4083)
  %4086 : Float(512:1, 128:512) = aten::t(%4085), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.302 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4086), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.162 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.302, %4084, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4089 : Tensor = prim::GetAttr[name="bias"](%4082)
  %4090 : Tensor = prim::GetAttr[name="weight"](%4082)
  %4091 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.162, %4090), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%4091, %4089, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4093 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18722.NoNorm = prim::GetAttr[name="LayerNorm"](%4080)
  %4094 : __torch__.torch.nn.modules.linear.___torch_mangle_18721.Linear = prim::GetAttr[name="dense"](%4080)
  %4095 : Tensor = prim::GetAttr[name="bias"](%4094)
  %4096 : Tensor = prim::GetAttr[name="weight"](%4094)
  %4097 : Float(512:1, 128:512) = aten::t(%4096), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.303 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4097), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.163 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.303, %4095, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4100 : Tensor = prim::GetAttr[name="bias"](%4093)
  %4101 : Tensor = prim::GetAttr[name="weight"](%4093)
  %4102 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.163, %4101), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.388 : Float(17:1664, 13:128, 128:1) = aten::add(%4102, %4100, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4104 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.388, %residual_tensor.21)
  %4105 : Float(17:1664, 13:128, 128:1), %4106 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4104)
  %4107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18707.MobileBertSelfOutput = prim::GetAttr[name="output"](%4078)
  %4108 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18704.MobileBertSelfAttention = prim::GetAttr[name="self"](%4078)
  %4109 : __torch__.torch.nn.modules.linear.___torch_mangle_18702.Linear = prim::GetAttr[name="value"](%4108)
  %4110 : __torch__.torch.nn.modules.linear.___torch_mangle_18701.Linear = prim::GetAttr[name="key"](%4108)
  %4111 : __torch__.torch.nn.modules.linear.___torch_mangle_18700.Linear = prim::GetAttr[name="query"](%4108)
  %4112 : Tensor = prim::GetAttr[name="bias"](%4111)
  %4113 : Tensor = prim::GetAttr[name="weight"](%4111)
  %4114 : Float(128:1, 128:128) = aten::t(%4113), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %output.304 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4105, %4114), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %x.121 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.304, %4112, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1678:0
  %4117 : Tensor = prim::GetAttr[name="bias"](%4110)
  %4118 : Tensor = prim::GetAttr[name="weight"](%4110)
  %4119 : Float(128:1, 128:128) = aten::t(%4118), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %output.305 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4105, %4119), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %x.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.305, %4117, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1678:0
  %4122 : Tensor = prim::GetAttr[name="bias"](%4109)
  %4123 : Tensor = prim::GetAttr[name="weight"](%4109)
  %4124 : Float(512:1, 128:512) = aten::t(%4123), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %output.306 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4124), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %x.125 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.306, %4122, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1678:0
  %4127 : int = aten::size(%x.121, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4128 : int = aten::size(%x.121, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4129 : int[] = prim::ListConstruct(%4127, %4128, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.122 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.121, %4129), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4131 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %query_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.122, %4131), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4133 : int = aten::size(%x.123, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4134 : int = aten::size(%x.123, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4135 : int[] = prim::ListConstruct(%4133, %4134, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.124 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.123, %4135), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4137 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %key_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.124, %4137), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4139 : int = aten::size(%x.125, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4140 : int = aten::size(%x.125, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4141 : int[] = prim::ListConstruct(%4139, %4140, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.126 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.125, %4141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4143 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %value_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.126, %4143), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4145 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.21, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.41 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.21, %4145), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.42 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.41, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.389 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.42, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.390 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.389, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.390, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.41 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.21, %value_layer.21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:280:0
  %4152 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %4153 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.41, %4152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4153, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %4155 : int = aten::size(%context_layer.42, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4156 : int = aten::size(%context_layer.42, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4157 : int[] = prim::ListConstruct(%4155, %4156, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %input.391 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.42, %4157), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:283:0
  %4159 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18706.NoNorm = prim::GetAttr[name="LayerNorm"](%4107)
  %4160 : __torch__.torch.nn.modules.linear.___torch_mangle_18705.Linear = prim::GetAttr[name="dense"](%4107)
  %4161 : Tensor = prim::GetAttr[name="bias"](%4160)
  %4162 : Tensor = prim::GetAttr[name="weight"](%4160)
  %4163 : Float(128:1, 128:128) = aten::t(%4162), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %output.307 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.391, %4163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.307, %4161, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.164 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.101, %4106, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output # transformers/modeling_mobilebert.py:301:0
  %4167 : Tensor = prim::GetAttr[name="bias"](%4159)
  %4168 : Tensor = prim::GetAttr[name="weight"](%4159)
  %4169 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.164, %4168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.392 : Float(17:1664, 13:128, 128:1) = aten::add(%4169, %4167, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4171 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18729.FFNOutput = prim::GetAttr[name="output"](%4077)
  %4172 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18726.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4077)
  %4173 : __torch__.torch.nn.modules.linear.___torch_mangle_18725.Linear = prim::GetAttr[name="dense"](%4172)
  %4174 : Tensor = prim::GetAttr[name="bias"](%4173)
  %4175 : Tensor = prim::GetAttr[name="weight"](%4173)
  %4176 : Float(128:1, 512:128) = aten::t(%4175), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.308 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.392, %4176), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.393 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.308, %4174, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.394 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4180 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18728.NoNorm = prim::GetAttr[name="LayerNorm"](%4171)
  %4181 : __torch__.torch.nn.modules.linear.___torch_mangle_18727.Linear = prim::GetAttr[name="dense"](%4171)
  %4182 : Tensor = prim::GetAttr[name="bias"](%4181)
  %4183 : Tensor = prim::GetAttr[name="weight"](%4181)
  %4184 : Float(512:1, 128:512) = aten::t(%4183), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.309 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.394, %4184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.102 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.309, %4182, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.165 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.102, %input.392, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4188 : Tensor = prim::GetAttr[name="bias"](%4180)
  %4189 : Tensor = prim::GetAttr[name="weight"](%4180)
  %4190 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.165, %4189), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.395 : Float(17:1664, 13:128, 128:1) = aten::add(%4190, %4188, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4192 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18735.FFNOutput = prim::GetAttr[name="output"](%4075)
  %4193 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18732.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4075)
  %4194 : __torch__.torch.nn.modules.linear.___torch_mangle_18731.Linear = prim::GetAttr[name="dense"](%4193)
  %4195 : Tensor = prim::GetAttr[name="bias"](%4194)
  %4196 : Tensor = prim::GetAttr[name="weight"](%4194)
  %4197 : Float(128:1, 512:128) = aten::t(%4196), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.310 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.395, %4197), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.396 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.310, %4195, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.397 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4201 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18734.NoNorm = prim::GetAttr[name="LayerNorm"](%4192)
  %4202 : __torch__.torch.nn.modules.linear.___torch_mangle_18733.Linear = prim::GetAttr[name="dense"](%4192)
  %4203 : Tensor = prim::GetAttr[name="bias"](%4202)
  %4204 : Tensor = prim::GetAttr[name="weight"](%4202)
  %4205 : Float(512:1, 128:512) = aten::t(%4204), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.311 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.397, %4205), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.311, %4203, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.166 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.103, %input.395, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4209 : Tensor = prim::GetAttr[name="bias"](%4201)
  %4210 : Tensor = prim::GetAttr[name="weight"](%4201)
  %4211 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.166, %4210), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.398 : Float(17:1664, 13:128, 128:1) = aten::add(%4211, %4209, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4213 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18741.FFNOutput = prim::GetAttr[name="output"](%4073)
  %4214 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18738.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4073)
  %4215 : __torch__.torch.nn.modules.linear.___torch_mangle_18737.Linear = prim::GetAttr[name="dense"](%4214)
  %4216 : Tensor = prim::GetAttr[name="bias"](%4215)
  %4217 : Tensor = prim::GetAttr[name="weight"](%4215)
  %4218 : Float(128:1, 512:128) = aten::t(%4217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.312 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.398, %4218), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.399 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.312, %4216, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.400 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4222 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18740.NoNorm = prim::GetAttr[name="LayerNorm"](%4213)
  %4223 : __torch__.torch.nn.modules.linear.___torch_mangle_18739.Linear = prim::GetAttr[name="dense"](%4213)
  %4224 : Tensor = prim::GetAttr[name="bias"](%4223)
  %4225 : Tensor = prim::GetAttr[name="weight"](%4223)
  %4226 : Float(512:1, 128:512) = aten::t(%4225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.313 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.400, %4226), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.104 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.313, %4224, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.167 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.104, %input.398, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4230 : Tensor = prim::GetAttr[name="bias"](%4222)
  %4231 : Tensor = prim::GetAttr[name="weight"](%4222)
  %4232 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.167, %4231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.401 : Float(17:1664, 13:128, 128:1) = aten::add(%4232, %4230, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4234 : __torch__.torch.nn.modules.linear.___torch_mangle_18709.Linear = prim::GetAttr[name="dense"](%4071)
  %4235 : Tensor = prim::GetAttr[name="bias"](%4234)
  %4236 : Tensor = prim::GetAttr[name="weight"](%4234)
  %4237 : Float(128:1, 512:128) = aten::t(%4236), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %output.314 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.401, %4237), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %input.402 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.314, %4235, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1678:0
  %input.403 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate # torch/nn/functional.py:1119:0
  %4241 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18716.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4070)
  %4242 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18712.NoNorm = prim::GetAttr[name="LayerNorm"](%4070)
  %4243 : __torch__.torch.nn.modules.linear.___torch_mangle_18711.Linear = prim::GetAttr[name="dense"](%4070)
  %4244 : Tensor = prim::GetAttr[name="bias"](%4243)
  %4245 : Tensor = prim::GetAttr[name="weight"](%4243)
  %4246 : Float(512:1, 128:512) = aten::t(%4245), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %output.315 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.403, %4246), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %layer_output.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.315, %4244, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.168 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.21, %input.401, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output # transformers/modeling_mobilebert.py:405:0
  %4250 : Tensor = prim::GetAttr[name="bias"](%4242)
  %4251 : Tensor = prim::GetAttr[name="weight"](%4242)
  %4252 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.168, %4251), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.404 : Float(17:1664, 13:128, 128:1) = aten::add(%4252, %4250, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4254 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18714.NoNorm = prim::GetAttr[name="LayerNorm"](%4241)
  %4255 : __torch__.torch.nn.modules.linear.___torch_mangle_18713.Linear = prim::GetAttr[name="dense"](%4241)
  %4256 : Tensor = prim::GetAttr[name="bias"](%4255)
  %4257 : Tensor = prim::GetAttr[name="weight"](%4255)
  %4258 : Float(128:1, 512:128) = aten::t(%4257), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.316 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.404, %4258), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.405 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.316, %4256, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.105 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.405, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.169 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.105, %input.387, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4263 : Tensor = prim::GetAttr[name="bias"](%4254)
  %4264 : Tensor = prim::GetAttr[name="weight"](%4254)
  %4265 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.169, %4264), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.406 : Float(17:6656, 13:512, 512:1) = aten::add(%4265, %4263, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4267 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18762.MobileBertOutput = prim::GetAttr[name="output"](%87)
  %4268 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18755.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%87)
  %4269 : __torch__.torch.nn.modules.container.___torch_mangle_18788.ModuleList = prim::GetAttr[name="ffn"](%87)
  %4270 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18787.FFNLayer = prim::GetAttr[name="2"](%4269)
  %4271 : __torch__.torch.nn.modules.container.___torch_mangle_18788.ModuleList = prim::GetAttr[name="ffn"](%87)
  %4272 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18781.FFNLayer = prim::GetAttr[name="1"](%4271)
  %4273 : __torch__.torch.nn.modules.container.___torch_mangle_18788.ModuleList = prim::GetAttr[name="ffn"](%87)
  %4274 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18775.FFNLayer = prim::GetAttr[name="0"](%4273)
  %4275 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18753.MobileBertAttention = prim::GetAttr[name="attention"](%87)
  %4276 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18769.Bottleneck = prim::GetAttr[name="bottleneck"](%87)
  %4277 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18768.BottleneckLayer = prim::GetAttr[name="attention"](%4276)
  %4278 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18765.BottleneckLayer = prim::GetAttr[name="input"](%4276)
  %4279 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18764.NoNorm = prim::GetAttr[name="LayerNorm"](%4278)
  %4280 : __torch__.torch.nn.modules.linear.___torch_mangle_18763.Linear = prim::GetAttr[name="dense"](%4278)
  %4281 : Tensor = prim::GetAttr[name="bias"](%4280)
  %4282 : Tensor = prim::GetAttr[name="weight"](%4280)
  %4283 : Float(512:1, 128:512) = aten::t(%4282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.317 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4283), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.170 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.317, %4281, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4286 : Tensor = prim::GetAttr[name="bias"](%4279)
  %4287 : Tensor = prim::GetAttr[name="weight"](%4279)
  %4288 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.170, %4287), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%4288, %4286, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4290 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18767.NoNorm = prim::GetAttr[name="LayerNorm"](%4277)
  %4291 : __torch__.torch.nn.modules.linear.___torch_mangle_18766.Linear = prim::GetAttr[name="dense"](%4277)
  %4292 : Tensor = prim::GetAttr[name="bias"](%4291)
  %4293 : Tensor = prim::GetAttr[name="weight"](%4291)
  %4294 : Float(512:1, 128:512) = aten::t(%4293), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.318 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4294), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.171 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.318, %4292, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4297 : Tensor = prim::GetAttr[name="bias"](%4290)
  %4298 : Tensor = prim::GetAttr[name="weight"](%4290)
  %4299 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.171, %4298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.407 : Float(17:1664, 13:128, 128:1) = aten::add(%4299, %4297, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4301 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.407, %residual_tensor.22)
  %4302 : Float(17:1664, 13:128, 128:1), %4303 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4301)
  %4304 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18752.MobileBertSelfOutput = prim::GetAttr[name="output"](%4275)
  %4305 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18749.MobileBertSelfAttention = prim::GetAttr[name="self"](%4275)
  %4306 : __torch__.torch.nn.modules.linear.___torch_mangle_18747.Linear = prim::GetAttr[name="value"](%4305)
  %4307 : __torch__.torch.nn.modules.linear.___torch_mangle_18746.Linear = prim::GetAttr[name="key"](%4305)
  %4308 : __torch__.torch.nn.modules.linear.___torch_mangle_18745.Linear = prim::GetAttr[name="query"](%4305)
  %4309 : Tensor = prim::GetAttr[name="bias"](%4308)
  %4310 : Tensor = prim::GetAttr[name="weight"](%4308)
  %4311 : Float(128:1, 128:128) = aten::t(%4310), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %output.319 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4302, %4311), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %x.127 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.319, %4309, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1678:0
  %4314 : Tensor = prim::GetAttr[name="bias"](%4307)
  %4315 : Tensor = prim::GetAttr[name="weight"](%4307)
  %4316 : Float(128:1, 128:128) = aten::t(%4315), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %output.320 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4302, %4316), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %x.129 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.320, %4314, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1678:0
  %4319 : Tensor = prim::GetAttr[name="bias"](%4306)
  %4320 : Tensor = prim::GetAttr[name="weight"](%4306)
  %4321 : Float(512:1, 128:512) = aten::t(%4320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %output.321 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %x.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.321, %4319, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1678:0
  %4324 : int = aten::size(%x.127, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4325 : int = aten::size(%x.127, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4326 : int[] = prim::ListConstruct(%4324, %4325, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.128 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.127, %4326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4328 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %query_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.128, %4328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4330 : int = aten::size(%x.129, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4331 : int = aten::size(%x.129, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4332 : int[] = prim::ListConstruct(%4330, %4331, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.130 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.129, %4332), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4334 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %key_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.130, %4334), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4336 : int = aten::size(%x.131, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4337 : int = aten::size(%x.131, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4338 : int[] = prim::ListConstruct(%4336, %4337, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.132 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.131, %4338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4340 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %value_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.132, %4340), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4342 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.22, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.43 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.22, %4342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.44 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.43, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.408 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.44, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.409 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.408, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.409, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.43 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.22, %value_layer.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:280:0
  %4349 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %4350 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.43, %4349), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4350, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %4352 : int = aten::size(%context_layer.44, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4353 : int = aten::size(%context_layer.44, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4354 : int[] = prim::ListConstruct(%4352, %4353, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %input.410 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.44, %4354), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:283:0
  %4356 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18751.NoNorm = prim::GetAttr[name="LayerNorm"](%4304)
  %4357 : __torch__.torch.nn.modules.linear.___torch_mangle_18750.Linear = prim::GetAttr[name="dense"](%4304)
  %4358 : Tensor = prim::GetAttr[name="bias"](%4357)
  %4359 : Tensor = prim::GetAttr[name="weight"](%4357)
  %4360 : Float(128:1, 128:128) = aten::t(%4359), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %output.322 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.410, %4360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.322, %4358, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.172 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.106, %4303, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output # transformers/modeling_mobilebert.py:301:0
  %4364 : Tensor = prim::GetAttr[name="bias"](%4356)
  %4365 : Tensor = prim::GetAttr[name="weight"](%4356)
  %4366 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.172, %4365), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.411 : Float(17:1664, 13:128, 128:1) = aten::add(%4366, %4364, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4368 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18774.FFNOutput = prim::GetAttr[name="output"](%4274)
  %4369 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18771.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4274)
  %4370 : __torch__.torch.nn.modules.linear.___torch_mangle_18770.Linear = prim::GetAttr[name="dense"](%4369)
  %4371 : Tensor = prim::GetAttr[name="bias"](%4370)
  %4372 : Tensor = prim::GetAttr[name="weight"](%4370)
  %4373 : Float(128:1, 512:128) = aten::t(%4372), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.323 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.411, %4373), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.412 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.323, %4371, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.413 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4377 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18773.NoNorm = prim::GetAttr[name="LayerNorm"](%4368)
  %4378 : __torch__.torch.nn.modules.linear.___torch_mangle_18772.Linear = prim::GetAttr[name="dense"](%4368)
  %4379 : Tensor = prim::GetAttr[name="bias"](%4378)
  %4380 : Tensor = prim::GetAttr[name="weight"](%4378)
  %4381 : Float(512:1, 128:512) = aten::t(%4380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.324 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.413, %4381), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.324, %4379, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.173 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.107, %input.411, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4385 : Tensor = prim::GetAttr[name="bias"](%4377)
  %4386 : Tensor = prim::GetAttr[name="weight"](%4377)
  %4387 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.173, %4386), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.414 : Float(17:1664, 13:128, 128:1) = aten::add(%4387, %4385, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4389 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18780.FFNOutput = prim::GetAttr[name="output"](%4272)
  %4390 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18777.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4272)
  %4391 : __torch__.torch.nn.modules.linear.___torch_mangle_18776.Linear = prim::GetAttr[name="dense"](%4390)
  %4392 : Tensor = prim::GetAttr[name="bias"](%4391)
  %4393 : Tensor = prim::GetAttr[name="weight"](%4391)
  %4394 : Float(128:1, 512:128) = aten::t(%4393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.325 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.414, %4394), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.415 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.325, %4392, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.416 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4398 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18779.NoNorm = prim::GetAttr[name="LayerNorm"](%4389)
  %4399 : __torch__.torch.nn.modules.linear.___torch_mangle_18778.Linear = prim::GetAttr[name="dense"](%4389)
  %4400 : Tensor = prim::GetAttr[name="bias"](%4399)
  %4401 : Tensor = prim::GetAttr[name="weight"](%4399)
  %4402 : Float(512:1, 128:512) = aten::t(%4401), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.326 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.416, %4402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.108 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.326, %4400, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.174 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.108, %input.414, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4406 : Tensor = prim::GetAttr[name="bias"](%4398)
  %4407 : Tensor = prim::GetAttr[name="weight"](%4398)
  %4408 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.174, %4407), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.417 : Float(17:1664, 13:128, 128:1) = aten::add(%4408, %4406, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4410 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18786.FFNOutput = prim::GetAttr[name="output"](%4270)
  %4411 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18783.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4270)
  %4412 : __torch__.torch.nn.modules.linear.___torch_mangle_18782.Linear = prim::GetAttr[name="dense"](%4411)
  %4413 : Tensor = prim::GetAttr[name="bias"](%4412)
  %4414 : Tensor = prim::GetAttr[name="weight"](%4412)
  %4415 : Float(128:1, 512:128) = aten::t(%4414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.327 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.417, %4415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.418 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.327, %4413, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.419 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4419 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18785.NoNorm = prim::GetAttr[name="LayerNorm"](%4410)
  %4420 : __torch__.torch.nn.modules.linear.___torch_mangle_18784.Linear = prim::GetAttr[name="dense"](%4410)
  %4421 : Tensor = prim::GetAttr[name="bias"](%4420)
  %4422 : Tensor = prim::GetAttr[name="weight"](%4420)
  %4423 : Float(512:1, 128:512) = aten::t(%4422), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.328 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.419, %4423), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.328, %4421, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.175 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.109, %input.417, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4427 : Tensor = prim::GetAttr[name="bias"](%4419)
  %4428 : Tensor = prim::GetAttr[name="weight"](%4419)
  %4429 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.175, %4428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.420 : Float(17:1664, 13:128, 128:1) = aten::add(%4429, %4427, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4431 : __torch__.torch.nn.modules.linear.___torch_mangle_18754.Linear = prim::GetAttr[name="dense"](%4268)
  %4432 : Tensor = prim::GetAttr[name="bias"](%4431)
  %4433 : Tensor = prim::GetAttr[name="weight"](%4431)
  %4434 : Float(128:1, 512:128) = aten::t(%4433), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %output.329 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.420, %4434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %input.421 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.329, %4432, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1678:0
  %input.422 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate # torch/nn/functional.py:1119:0
  %4438 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18761.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4267)
  %4439 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18757.NoNorm = prim::GetAttr[name="LayerNorm"](%4267)
  %4440 : __torch__.torch.nn.modules.linear.___torch_mangle_18756.Linear = prim::GetAttr[name="dense"](%4267)
  %4441 : Tensor = prim::GetAttr[name="bias"](%4440)
  %4442 : Tensor = prim::GetAttr[name="weight"](%4440)
  %4443 : Float(512:1, 128:512) = aten::t(%4442), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %output.330 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.422, %4443), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %layer_output.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.330, %4441, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.176 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.22, %input.420, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output # transformers/modeling_mobilebert.py:405:0
  %4447 : Tensor = prim::GetAttr[name="bias"](%4439)
  %4448 : Tensor = prim::GetAttr[name="weight"](%4439)
  %4449 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.176, %4448), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.423 : Float(17:1664, 13:128, 128:1) = aten::add(%4449, %4447, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4451 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18759.NoNorm = prim::GetAttr[name="LayerNorm"](%4438)
  %4452 : __torch__.torch.nn.modules.linear.___torch_mangle_18758.Linear = prim::GetAttr[name="dense"](%4438)
  %4453 : Tensor = prim::GetAttr[name="bias"](%4452)
  %4454 : Tensor = prim::GetAttr[name="weight"](%4452)
  %4455 : Float(128:1, 512:128) = aten::t(%4454), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.331 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.423, %4455), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.424 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.331, %4453, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.110 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.424, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.177 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.110, %input.406, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4460 : Tensor = prim::GetAttr[name="bias"](%4451)
  %4461 : Tensor = prim::GetAttr[name="weight"](%4451)
  %4462 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.177, %4461), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.425 : Float(17:6656, 13:512, 512:1) = aten::add(%4462, %4460, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4464 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18807.MobileBertOutput = prim::GetAttr[name="output"](%85)
  %4465 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18800.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%85)
  %4466 : __torch__.torch.nn.modules.container.___torch_mangle_18833.ModuleList = prim::GetAttr[name="ffn"](%85)
  %4467 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18832.FFNLayer = prim::GetAttr[name="2"](%4466)
  %4468 : __torch__.torch.nn.modules.container.___torch_mangle_18833.ModuleList = prim::GetAttr[name="ffn"](%85)
  %4469 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18826.FFNLayer = prim::GetAttr[name="1"](%4468)
  %4470 : __torch__.torch.nn.modules.container.___torch_mangle_18833.ModuleList = prim::GetAttr[name="ffn"](%85)
  %4471 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18820.FFNLayer = prim::GetAttr[name="0"](%4470)
  %4472 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18798.MobileBertAttention = prim::GetAttr[name="attention"](%85)
  %4473 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18814.Bottleneck = prim::GetAttr[name="bottleneck"](%85)
  %4474 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18813.BottleneckLayer = prim::GetAttr[name="attention"](%4473)
  %4475 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18810.BottleneckLayer = prim::GetAttr[name="input"](%4473)
  %4476 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18809.NoNorm = prim::GetAttr[name="LayerNorm"](%4475)
  %4477 : __torch__.torch.nn.modules.linear.___torch_mangle_18808.Linear = prim::GetAttr[name="dense"](%4475)
  %4478 : Tensor = prim::GetAttr[name="bias"](%4477)
  %4479 : Tensor = prim::GetAttr[name="weight"](%4477)
  %4480 : Float(512:1, 128:512) = aten::t(%4479), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.332 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4480), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.178 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.332, %4478, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4483 : Tensor = prim::GetAttr[name="bias"](%4476)
  %4484 : Tensor = prim::GetAttr[name="weight"](%4476)
  %4485 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.178, %4484), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%4485, %4483, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4487 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18812.NoNorm = prim::GetAttr[name="LayerNorm"](%4474)
  %4488 : __torch__.torch.nn.modules.linear.___torch_mangle_18811.Linear = prim::GetAttr[name="dense"](%4474)
  %4489 : Tensor = prim::GetAttr[name="bias"](%4488)
  %4490 : Tensor = prim::GetAttr[name="weight"](%4488)
  %4491 : Float(512:1, 128:512) = aten::t(%4490), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.333 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4491), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.179 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.333, %4489, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4494 : Tensor = prim::GetAttr[name="bias"](%4487)
  %4495 : Tensor = prim::GetAttr[name="weight"](%4487)
  %4496 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.179, %4495), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.426 : Float(17:1664, 13:128, 128:1) = aten::add(%4496, %4494, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4498 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.426, %residual_tensor.23)
  %4499 : Float(17:1664, 13:128, 128:1), %4500 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4498)
  %4501 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18797.MobileBertSelfOutput = prim::GetAttr[name="output"](%4472)
  %4502 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18794.MobileBertSelfAttention = prim::GetAttr[name="self"](%4472)
  %4503 : __torch__.torch.nn.modules.linear.___torch_mangle_18792.Linear = prim::GetAttr[name="value"](%4502)
  %4504 : __torch__.torch.nn.modules.linear.___torch_mangle_18791.Linear = prim::GetAttr[name="key"](%4502)
  %4505 : __torch__.torch.nn.modules.linear.___torch_mangle_18790.Linear = prim::GetAttr[name="query"](%4502)
  %4506 : Tensor = prim::GetAttr[name="bias"](%4505)
  %4507 : Tensor = prim::GetAttr[name="weight"](%4505)
  %4508 : Float(128:1, 128:128) = aten::t(%4507), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %output.334 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4499, %4508), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %x.133 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.334, %4506, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1678:0
  %4511 : Tensor = prim::GetAttr[name="bias"](%4504)
  %4512 : Tensor = prim::GetAttr[name="weight"](%4504)
  %4513 : Float(128:1, 128:128) = aten::t(%4512), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %output.335 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4499, %4513), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %x.135 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.335, %4511, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1678:0
  %4516 : Tensor = prim::GetAttr[name="bias"](%4503)
  %4517 : Tensor = prim::GetAttr[name="weight"](%4503)
  %4518 : Float(512:1, 128:512) = aten::t(%4517), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %output.336 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %x.137 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.336, %4516, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1678:0
  %4521 : int = aten::size(%x.133, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4522 : int = aten::size(%x.133, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4523 : int[] = prim::ListConstruct(%4521, %4522, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.134 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.133, %4523), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4525 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %query_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.134, %4525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4527 : int = aten::size(%x.135, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4528 : int = aten::size(%x.135, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4529 : int[] = prim::ListConstruct(%4527, %4528, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.136 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.135, %4529), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4531 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %key_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.136, %4531), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4533 : int = aten::size(%x.137, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4534 : int = aten::size(%x.137, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4535 : int[] = prim::ListConstruct(%4533, %4534, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.138 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.137, %4535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4537 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %value_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.138, %4537), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4539 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.23, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.45 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.23, %4539), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.46 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.45, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.427 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.46, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.428 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.427, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.428, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.45 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.23, %value_layer.23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:280:0
  %4546 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %4547 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.45, %4546), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4547, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %4549 : int = aten::size(%context_layer.46, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4550 : int = aten::size(%context_layer.46, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4551 : int[] = prim::ListConstruct(%4549, %4550, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %input.429 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.46, %4551), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:283:0
  %4553 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18796.NoNorm = prim::GetAttr[name="LayerNorm"](%4501)
  %4554 : __torch__.torch.nn.modules.linear.___torch_mangle_18795.Linear = prim::GetAttr[name="dense"](%4501)
  %4555 : Tensor = prim::GetAttr[name="bias"](%4554)
  %4556 : Tensor = prim::GetAttr[name="weight"](%4554)
  %4557 : Float(128:1, 128:128) = aten::t(%4556), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %output.337 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.429, %4557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.337, %4555, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.180 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.111, %4500, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output # transformers/modeling_mobilebert.py:301:0
  %4561 : Tensor = prim::GetAttr[name="bias"](%4553)
  %4562 : Tensor = prim::GetAttr[name="weight"](%4553)
  %4563 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.180, %4562), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.430 : Float(17:1664, 13:128, 128:1) = aten::add(%4563, %4561, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4565 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18819.FFNOutput = prim::GetAttr[name="output"](%4471)
  %4566 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18816.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4471)
  %4567 : __torch__.torch.nn.modules.linear.___torch_mangle_18815.Linear = prim::GetAttr[name="dense"](%4566)
  %4568 : Tensor = prim::GetAttr[name="bias"](%4567)
  %4569 : Tensor = prim::GetAttr[name="weight"](%4567)
  %4570 : Float(128:1, 512:128) = aten::t(%4569), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.338 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.430, %4570), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.431 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.338, %4568, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.432 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.431), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4574 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18818.NoNorm = prim::GetAttr[name="LayerNorm"](%4565)
  %4575 : __torch__.torch.nn.modules.linear.___torch_mangle_18817.Linear = prim::GetAttr[name="dense"](%4565)
  %4576 : Tensor = prim::GetAttr[name="bias"](%4575)
  %4577 : Tensor = prim::GetAttr[name="weight"](%4575)
  %4578 : Float(512:1, 128:512) = aten::t(%4577), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.339 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.432, %4578), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.112 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.339, %4576, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.181 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.112, %input.430, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4582 : Tensor = prim::GetAttr[name="bias"](%4574)
  %4583 : Tensor = prim::GetAttr[name="weight"](%4574)
  %4584 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.181, %4583), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.433 : Float(17:1664, 13:128, 128:1) = aten::add(%4584, %4582, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4586 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18825.FFNOutput = prim::GetAttr[name="output"](%4469)
  %4587 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18822.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4469)
  %4588 : __torch__.torch.nn.modules.linear.___torch_mangle_18821.Linear = prim::GetAttr[name="dense"](%4587)
  %4589 : Tensor = prim::GetAttr[name="bias"](%4588)
  %4590 : Tensor = prim::GetAttr[name="weight"](%4588)
  %4591 : Float(128:1, 512:128) = aten::t(%4590), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.340 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.433, %4591), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.434 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.340, %4589, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.435 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4595 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18824.NoNorm = prim::GetAttr[name="LayerNorm"](%4586)
  %4596 : __torch__.torch.nn.modules.linear.___torch_mangle_18823.Linear = prim::GetAttr[name="dense"](%4586)
  %4597 : Tensor = prim::GetAttr[name="bias"](%4596)
  %4598 : Tensor = prim::GetAttr[name="weight"](%4596)
  %4599 : Float(512:1, 128:512) = aten::t(%4598), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.341 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.435, %4599), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.341, %4597, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.182 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.113, %input.433, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4603 : Tensor = prim::GetAttr[name="bias"](%4595)
  %4604 : Tensor = prim::GetAttr[name="weight"](%4595)
  %4605 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.182, %4604), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.436 : Float(17:1664, 13:128, 128:1) = aten::add(%4605, %4603, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4607 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18831.FFNOutput = prim::GetAttr[name="output"](%4467)
  %4608 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18828.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4467)
  %4609 : __torch__.torch.nn.modules.linear.___torch_mangle_18827.Linear = prim::GetAttr[name="dense"](%4608)
  %4610 : Tensor = prim::GetAttr[name="bias"](%4609)
  %4611 : Tensor = prim::GetAttr[name="weight"](%4609)
  %4612 : Float(128:1, 512:128) = aten::t(%4611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.342 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.436, %4612), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.437 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.342, %4610, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.438 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4616 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18830.NoNorm = prim::GetAttr[name="LayerNorm"](%4607)
  %4617 : __torch__.torch.nn.modules.linear.___torch_mangle_18829.Linear = prim::GetAttr[name="dense"](%4607)
  %4618 : Tensor = prim::GetAttr[name="bias"](%4617)
  %4619 : Tensor = prim::GetAttr[name="weight"](%4617)
  %4620 : Float(512:1, 128:512) = aten::t(%4619), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.343 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.438, %4620), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.343, %4618, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.183 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.114, %input.436, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4624 : Tensor = prim::GetAttr[name="bias"](%4616)
  %4625 : Tensor = prim::GetAttr[name="weight"](%4616)
  %4626 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.183, %4625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.439 : Float(17:1664, 13:128, 128:1) = aten::add(%4626, %4624, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4628 : __torch__.torch.nn.modules.linear.___torch_mangle_18799.Linear = prim::GetAttr[name="dense"](%4465)
  %4629 : Tensor = prim::GetAttr[name="bias"](%4628)
  %4630 : Tensor = prim::GetAttr[name="weight"](%4628)
  %4631 : Float(128:1, 512:128) = aten::t(%4630), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %output.344 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.439, %4631), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %input.440 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.344, %4629, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1678:0
  %input.441 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate # torch/nn/functional.py:1119:0
  %4635 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18806.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4464)
  %4636 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18802.NoNorm = prim::GetAttr[name="LayerNorm"](%4464)
  %4637 : __torch__.torch.nn.modules.linear.___torch_mangle_18801.Linear = prim::GetAttr[name="dense"](%4464)
  %4638 : Tensor = prim::GetAttr[name="bias"](%4637)
  %4639 : Tensor = prim::GetAttr[name="weight"](%4637)
  %4640 : Float(512:1, 128:512) = aten::t(%4639), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %output.345 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.441, %4640), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %layer_output.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.345, %4638, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.184 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.23, %input.439, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output # transformers/modeling_mobilebert.py:405:0
  %4644 : Tensor = prim::GetAttr[name="bias"](%4636)
  %4645 : Tensor = prim::GetAttr[name="weight"](%4636)
  %4646 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.184, %4645), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.442 : Float(17:1664, 13:128, 128:1) = aten::add(%4646, %4644, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4648 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18804.NoNorm = prim::GetAttr[name="LayerNorm"](%4635)
  %4649 : __torch__.torch.nn.modules.linear.___torch_mangle_18803.Linear = prim::GetAttr[name="dense"](%4635)
  %4650 : Tensor = prim::GetAttr[name="bias"](%4649)
  %4651 : Tensor = prim::GetAttr[name="weight"](%4649)
  %4652 : Float(128:1, 512:128) = aten::t(%4651), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.346 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.442, %4652), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.443 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.346, %4650, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.115 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.443, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.185 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.115, %input.425, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4657 : Tensor = prim::GetAttr[name="bias"](%4648)
  %4658 : Tensor = prim::GetAttr[name="weight"](%4648)
  %4659 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.185, %4658), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.444 : Float(17:6656, 13:512, 512:1) = aten::add(%4659, %4657, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4661 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18852.MobileBertOutput = prim::GetAttr[name="output"](%83)
  %4662 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18845.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%83)
  %4663 : __torch__.torch.nn.modules.container.___torch_mangle_18878.ModuleList = prim::GetAttr[name="ffn"](%83)
  %4664 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18877.FFNLayer = prim::GetAttr[name="2"](%4663)
  %4665 : __torch__.torch.nn.modules.container.___torch_mangle_18878.ModuleList = prim::GetAttr[name="ffn"](%83)
  %4666 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18871.FFNLayer = prim::GetAttr[name="1"](%4665)
  %4667 : __torch__.torch.nn.modules.container.___torch_mangle_18878.ModuleList = prim::GetAttr[name="ffn"](%83)
  %4668 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18865.FFNLayer = prim::GetAttr[name="0"](%4667)
  %4669 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18843.MobileBertAttention = prim::GetAttr[name="attention"](%83)
  %4670 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18859.Bottleneck = prim::GetAttr[name="bottleneck"](%83)
  %4671 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18858.BottleneckLayer = prim::GetAttr[name="attention"](%4670)
  %4672 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18855.BottleneckLayer = prim::GetAttr[name="input"](%4670)
  %4673 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18854.NoNorm = prim::GetAttr[name="LayerNorm"](%4672)
  %4674 : __torch__.torch.nn.modules.linear.___torch_mangle_18853.Linear = prim::GetAttr[name="dense"](%4672)
  %4675 : Tensor = prim::GetAttr[name="bias"](%4674)
  %4676 : Tensor = prim::GetAttr[name="weight"](%4674)
  %4677 : Float(512:1, 128:512) = aten::t(%4676), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.347 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4677), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.186 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.347, %4675, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4680 : Tensor = prim::GetAttr[name="bias"](%4673)
  %4681 : Tensor = prim::GetAttr[name="weight"](%4673)
  %4682 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.186, %4681), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor : Float(17:1664, 13:128, 128:1) = aten::add(%4682, %4680, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4684 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18857.NoNorm = prim::GetAttr[name="LayerNorm"](%4671)
  %4685 : __torch__.torch.nn.modules.linear.___torch_mangle_18856.Linear = prim::GetAttr[name="dense"](%4671)
  %4686 : Tensor = prim::GetAttr[name="bias"](%4685)
  %4687 : Tensor = prim::GetAttr[name="weight"](%4685)
  %4688 : Float(512:1, 128:512) = aten::t(%4687), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.348 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4688), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.187 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.348, %4686, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4691 : Tensor = prim::GetAttr[name="bias"](%4684)
  %4692 : Tensor = prim::GetAttr[name="weight"](%4684)
  %4693 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.187, %4692), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.445 : Float(17:1664, 13:128, 128:1) = aten::add(%4693, %4691, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4695 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.445, %residual_tensor)
  %4696 : Float(17:1664, 13:128, 128:1), %4697 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4695)
  %4698 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18842.MobileBertSelfOutput = prim::GetAttr[name="output"](%4669)
  %4699 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18839.MobileBertSelfAttention = prim::GetAttr[name="self"](%4669)
  %4700 : __torch__.torch.nn.modules.linear.___torch_mangle_18837.Linear = prim::GetAttr[name="value"](%4699)
  %4701 : __torch__.torch.nn.modules.linear.___torch_mangle_18836.Linear = prim::GetAttr[name="key"](%4699)
  %4702 : __torch__.torch.nn.modules.linear.___torch_mangle_18835.Linear = prim::GetAttr[name="query"](%4699)
  %4703 : Tensor = prim::GetAttr[name="bias"](%4702)
  %4704 : Tensor = prim::GetAttr[name="weight"](%4702)
  %4705 : Float(128:1, 128:128) = aten::t(%4704), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %output.349 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4696, %4705), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %x.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.349, %4703, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1678:0
  %4708 : Tensor = prim::GetAttr[name="bias"](%4701)
  %4709 : Tensor = prim::GetAttr[name="weight"](%4701)
  %4710 : Float(128:1, 128:128) = aten::t(%4709), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %output.350 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4696, %4710), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %x.141 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.350, %4708, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1678:0
  %4713 : Tensor = prim::GetAttr[name="bias"](%4700)
  %4714 : Tensor = prim::GetAttr[name="weight"](%4700)
  %4715 : Float(512:1, 128:512) = aten::t(%4714), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %output.351 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %x.143 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.351, %4713, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1678:0
  %4718 : int = aten::size(%x.139, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4719 : int = aten::size(%x.139, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4720 : int[] = prim::ListConstruct(%4718, %4719, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.140 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.139, %4720), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4722 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %query_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.140, %4722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4724 : int = aten::size(%x.141, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4725 : int = aten::size(%x.141, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4726 : int[] = prim::ListConstruct(%4724, %4725, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.142 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.141, %4726), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4728 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %key_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.142, %4728), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4730 : int = aten::size(%x.143, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4731 : int = aten::size(%x.143, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4732 : int[] = prim::ListConstruct(%4730, %4731, %28, %16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.143, %4732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4734 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %value_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x, %4734), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4736 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer, %17, %15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer, %4736), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.47, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.446 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores, %attention_mask, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.447 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.446, %17, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # torch/nn/functional.py:1498:0
  %attention_probs : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.447, %13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.47 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:280:0
  %4743 : int[] = prim::ListConstruct(%30, %24, %29, %23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %4744 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.47, %4743), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4744, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %4746 : int = aten::size(%context_layer, %30), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4747 : int = aten::size(%context_layer, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4748 : int[] = prim::ListConstruct(%4746, %4747, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %input.448 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer, %4748), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:283:0
  %4750 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18841.NoNorm = prim::GetAttr[name="LayerNorm"](%4698)
  %4751 : __torch__.torch.nn.modules.linear.___torch_mangle_18840.Linear = prim::GetAttr[name="dense"](%4698)
  %4752 : Tensor = prim::GetAttr[name="bias"](%4751)
  %4753 : Tensor = prim::GetAttr[name="weight"](%4751)
  %4754 : Float(128:1, 128:128) = aten::t(%4753), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %output.352 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.448, %4754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.116 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.352, %4752, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.188 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.116, %4697, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output # transformers/modeling_mobilebert.py:301:0
  %4758 : Tensor = prim::GetAttr[name="bias"](%4750)
  %4759 : Tensor = prim::GetAttr[name="weight"](%4750)
  %4760 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.188, %4759), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.449 : Float(17:1664, 13:128, 128:1) = aten::add(%4760, %4758, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4762 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18864.FFNOutput = prim::GetAttr[name="output"](%4668)
  %4763 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18861.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4668)
  %4764 : __torch__.torch.nn.modules.linear.___torch_mangle_18860.Linear = prim::GetAttr[name="dense"](%4763)
  %4765 : Tensor = prim::GetAttr[name="bias"](%4764)
  %4766 : Tensor = prim::GetAttr[name="weight"](%4764)
  %4767 : Float(128:1, 512:128) = aten::t(%4766), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.353 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.449, %4767), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.450 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.353, %4765, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.451 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4771 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18863.NoNorm = prim::GetAttr[name="LayerNorm"](%4762)
  %4772 : __torch__.torch.nn.modules.linear.___torch_mangle_18862.Linear = prim::GetAttr[name="dense"](%4762)
  %4773 : Tensor = prim::GetAttr[name="bias"](%4772)
  %4774 : Tensor = prim::GetAttr[name="weight"](%4772)
  %4775 : Float(512:1, 128:512) = aten::t(%4774), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.354 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.451, %4775), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.354, %4773, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.189 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.117, %input.449, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4779 : Tensor = prim::GetAttr[name="bias"](%4771)
  %4780 : Tensor = prim::GetAttr[name="weight"](%4771)
  %4781 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.189, %4780), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.452 : Float(17:1664, 13:128, 128:1) = aten::add(%4781, %4779, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4783 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18870.FFNOutput = prim::GetAttr[name="output"](%4666)
  %4784 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18867.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4666)
  %4785 : __torch__.torch.nn.modules.linear.___torch_mangle_18866.Linear = prim::GetAttr[name="dense"](%4784)
  %4786 : Tensor = prim::GetAttr[name="bias"](%4785)
  %4787 : Tensor = prim::GetAttr[name="weight"](%4785)
  %4788 : Float(128:1, 512:128) = aten::t(%4787), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.355 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.452, %4788), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.453 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.355, %4786, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.454 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4792 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18869.NoNorm = prim::GetAttr[name="LayerNorm"](%4783)
  %4793 : __torch__.torch.nn.modules.linear.___torch_mangle_18868.Linear = prim::GetAttr[name="dense"](%4783)
  %4794 : Tensor = prim::GetAttr[name="bias"](%4793)
  %4795 : Tensor = prim::GetAttr[name="weight"](%4793)
  %4796 : Float(512:1, 128:512) = aten::t(%4795), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.356 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.454, %4796), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.118 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.356, %4794, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.190 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.118, %input.452, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4800 : Tensor = prim::GetAttr[name="bias"](%4792)
  %4801 : Tensor = prim::GetAttr[name="weight"](%4792)
  %4802 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.190, %4801), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.455 : Float(17:1664, 13:128, 128:1) = aten::add(%4802, %4800, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4804 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18876.FFNOutput = prim::GetAttr[name="output"](%4664)
  %4805 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18873.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4664)
  %4806 : __torch__.torch.nn.modules.linear.___torch_mangle_18872.Linear = prim::GetAttr[name="dense"](%4805)
  %4807 : Tensor = prim::GetAttr[name="bias"](%4806)
  %4808 : Tensor = prim::GetAttr[name="weight"](%4806)
  %4809 : Float(128:1, 512:128) = aten::t(%4808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.357 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.455, %4809), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.456 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.357, %4807, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.457 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4813 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18875.NoNorm = prim::GetAttr[name="LayerNorm"](%4804)
  %4814 : __torch__.torch.nn.modules.linear.___torch_mangle_18874.Linear = prim::GetAttr[name="dense"](%4804)
  %4815 : Tensor = prim::GetAttr[name="bias"](%4814)
  %4816 : Tensor = prim::GetAttr[name="weight"](%4814)
  %4817 : Float(512:1, 128:512) = aten::t(%4816), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.358 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.457, %4817), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.358, %4815, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.191 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.119, %input.455, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4821 : Tensor = prim::GetAttr[name="bias"](%4813)
  %4822 : Tensor = prim::GetAttr[name="weight"](%4813)
  %4823 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.191, %4822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.458 : Float(17:1664, 13:128, 128:1) = aten::add(%4823, %4821, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4825 : __torch__.torch.nn.modules.linear.___torch_mangle_18844.Linear = prim::GetAttr[name="dense"](%4662)
  %4826 : Tensor = prim::GetAttr[name="bias"](%4825)
  %4827 : Tensor = prim::GetAttr[name="weight"](%4825)
  %4828 : Float(128:1, 512:128) = aten::t(%4827), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %output.359 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.458, %4828), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %input.459 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.359, %4826, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1678:0
  %input.460 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate # torch/nn/functional.py:1119:0
  %4832 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18851.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4661)
  %4833 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18847.NoNorm = prim::GetAttr[name="LayerNorm"](%4661)
  %4834 : __torch__.torch.nn.modules.linear.___torch_mangle_18846.Linear = prim::GetAttr[name="dense"](%4661)
  %4835 : Tensor = prim::GetAttr[name="bias"](%4834)
  %4836 : Tensor = prim::GetAttr[name="weight"](%4834)
  %4837 : Float(512:1, 128:512) = aten::t(%4836), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %output.360 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.460, %4837), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %layer_output : Float(17:1664, 13:128, 128:1) = aten::add_(%output.360, %4835, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.192 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output, %input.458, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output # transformers/modeling_mobilebert.py:405:0
  %4841 : Tensor = prim::GetAttr[name="bias"](%4833)
  %4842 : Tensor = prim::GetAttr[name="weight"](%4833)
  %4843 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.192, %4842), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.461 : Float(17:1664, 13:128, 128:1) = aten::add(%4843, %4841, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4845 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18849.NoNorm = prim::GetAttr[name="LayerNorm"](%4832)
  %4846 : __torch__.torch.nn.modules.linear.___torch_mangle_18848.Linear = prim::GetAttr[name="dense"](%4832)
  %4847 : Tensor = prim::GetAttr[name="bias"](%4846)
  %4848 : Tensor = prim::GetAttr[name="weight"](%4846)
  %4849 : Float(128:1, 512:128) = aten::t(%4848), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.361 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.461, %4849), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.462 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.361, %4847, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.462, %18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs, %input.444, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4854 : Tensor = prim::GetAttr[name="bias"](%4845)
  %4855 : Tensor = prim::GetAttr[name="weight"](%4845)
  %4856 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor, %4855), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %hidden_states.1 : Float(17:6656, 13:512, 512:1) = aten::add(%4856, %4854, %29), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4858 : __torch__.torch.nn.modules.linear.___torch_mangle_18882.Linear = prim::GetAttr[name="dense"](%31)
  %4859 : Float(17:6656, 13:512, 512:1) = aten::slice(%hidden_states.1, %30, %30, %25, %29), scope: __module.mobilebert/__module.mobilebert.pooler # transformers/modeling_mobilebert.py:603:0
  %input.463 : Float(17:6656, 512:1) = aten::select(%4859, %29, %30), scope: __module.mobilebert/__module.mobilebert.pooler # transformers/modeling_mobilebert.py:603:0
  %4861 : Tensor = prim::GetAttr[name="bias"](%4858)
  %4862 : Tensor = prim::GetAttr[name="weight"](%4858)
  %4863 : Float(512:1, 512:512) = aten::t(%4862), scope: __module.mobilebert/__module.mobilebert.pooler/__module.mobilebert.pooler.dense # torch/nn/functional.py:1674:0
  %pooled_output : Float(17:512, 512:1) = aten::addmm(%4861, %input.463, %4863, %29, %29), scope: __module.mobilebert/__module.mobilebert.pooler/__module.mobilebert.pooler.dense # torch/nn/functional.py:1674:0
  %input : Float(17:512, 512:1) = aten::tanh(%pooled_output), scope: __module.mobilebert/__module.mobilebert.pooler # transformers/modeling_mobilebert.py:608:0
  %4866 : (Float(17:6656, 13:512, 512:1), Float(17:512, 512:1)) = prim::TupleConstruct(%hidden_states.1, %input)
  %6 : Float(17:6656, 13:512, 512:1), %7 : Float(17:512, 512:1) = prim::TupleUnpack(%4866)
  %4867 : int = prim::Constant[value=512](), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm # torch/nn/functional.py:2048:0
  %4868 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm # torch/nn/functional.py:2048:0
  %4869 : bool = prim::Constant[value=1](), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm # torch/nn/functional.py:2048:0
  %4870 : int = prim::Constant[value=1](), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.dense # torch/nn/functional.py:1678:0
  %4871 : int = prim::Constant[value=0](), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:643:0
  %4872 : __torch__.torch.nn.modules.linear.___torch_mangle_18891.Linear = prim::GetAttr[name="seq_relationship"](%3)
  %4873 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18890.MobileBertLMPredictionHead = prim::GetAttr[name="predictions"](%3)
  %4874 : Tensor = prim::GetAttr[name="bias"](%4873)
  %4875 : __torch__.torch.nn.modules.linear.___torch_mangle_18888.Linear = prim::GetAttr[name="dense"](%4873)
  %4876 : Tensor = prim::GetAttr[name="weight"](%4875)
  %4877 : __torch__.torch.nn.modules.linear.___torch_mangle_18889.Linear = prim::GetAttr[name="decoder"](%4873)
  %4878 : Tensor = prim::GetAttr[name="weight"](%4877)
  %4879 : __torch__.transformers.modeling_mobilebert.___torch_mangle_18887.MobileBertPredictionHeadTransform = prim::GetAttr[name="transform"](%4873)
  %4880 : __torch__.torch.nn.modules.normalization.___torch_mangle_18886.LayerNorm = prim::GetAttr[name="LayerNorm"](%4879)
  %4881 : __torch__.torch.nn.modules.linear.___torch_mangle_18885.Linear = prim::GetAttr[name="dense"](%4879)
  %4882 : Tensor = prim::GetAttr[name="bias"](%4881)
  %4883 : Tensor = prim::GetAttr[name="weight"](%4881)
  %4884 : Float(512:1, 512:512) = aten::t(%4883), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.dense # torch/nn/functional.py:1676:0
  %output : Float(17:6656, 13:512, 512:1) = aten::matmul(%6, %4884), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.dense # torch/nn/functional.py:1676:0
  %input.464 : Float(17:6656, 13:512, 512:1) = aten::add_(%output, %4882, %4870), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.dense # torch/nn/functional.py:1678:0
  %input.465 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.464), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform # torch/nn/functional.py:1119:0
  %4888 : Tensor = prim::GetAttr[name="bias"](%4880)
  %4889 : Tensor = prim::GetAttr[name="weight"](%4880)
  %4890 : int[] = prim::ListConstruct(%4867), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm
  %hidden_states.2 : Float(17:6656, 13:512, 512:1) = aten::layer_norm(%input.465, %4890, %4889, %4888, %4868, %4869), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm # torch/nn/functional.py:2048:0
  %4892 : Float(128:1, 30522:128) = aten::t(%4878), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:643:0
  %4893 : Tensor[] = prim::ListConstruct(%4892, %4876), scope: __module.cls/__module.cls.predictions
  %4894 : Float(512:30522, 30522:1) = aten::cat(%4893, %4871), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:643:0
  %hidden_states : Float(17:396786, 13:30522, 30522:1) = aten::matmul(%hidden_states.2, %4894), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:643:0
  %4896 : Float(17:396786, 13:30522, 30522:1) = aten::add_(%hidden_states, %4874, %4870), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:644:0
  %4897 : Tensor = prim::GetAttr[name="bias"](%4872)
  %4898 : Tensor = prim::GetAttr[name="weight"](%4872)
  %4899 : Float(512:1, 2:512) = aten::t(%4898), scope: __module.cls/__module.cls.seq_relationship # torch/nn/functional.py:1674:0
  %4900 : Float(17:2, 2:1) = aten::addmm(%4897, %7, %4899, %4870, %4870), scope: __module.cls/__module.cls.seq_relationship # torch/nn/functional.py:1674:0
  %4901 : (Float(17:396786, 13:30522, 30522:1), Float(17:2, 2:1)) = prim::TupleConstruct(%4896, %4900)
  %9 : Float(17:396786, 13:30522, 30522:1), %10 : Float(17:2, 2:1) = prim::TupleUnpack(%4901)
  %11 : (Float(17:396786, 13:30522, 30522:1), Float(17:2, 2:1)) = prim::TupleConstruct(%9, %10)
  return (%11)
