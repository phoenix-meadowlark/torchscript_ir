graph(%self.1 : __torch__.transformers.modeling_mobilebert.MobileBertForQuestionAnswering,
      %input_ids : Long(17:13, 13:1),
      %attention_mask.1 : Long(17:13, 13:1)):
  %3 : __torch__.torch.nn.modules.linear.___torch_mangle_21083.Linear = prim::GetAttr[name="qa_outputs"](%self.1)
  %4 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21082.MobileBertModel = prim::GetAttr[name="mobilebert"](%self.1)
  %17 : int = prim::Constant[value=128](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %18 : float = prim::Constant[value=0.10000000000000001](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %19 : Double() = prim::Constant[value={5.65685}](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %20 : int = prim::Constant[value=-2](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %21 : int = prim::Constant[value=32](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %22 : int = prim::Constant[value=-1](), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %23 : float = prim::Constant[value=0.](), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %24 : Double() = prim::Constant[value={-10000}](), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %25 : float = prim::Constant[value=1.](), scope: __module.mobilebert # torch/tensor.py:396:0
  %26 : None = prim::Constant(), scope: __module.mobilebert
  %27 : int = prim::Constant[value=6](), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %28 : int = prim::Constant[value=3](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %29 : int = prim::Constant[value=2](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %30 : int = prim::Constant[value=9223372036854775807](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %31 : bool = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %32 : Device = prim::Constant[value="cpu"](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %33 : int = prim::Constant[value=4](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %34 : int = prim::Constant[value=1](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %35 : int = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %36 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21081.MobileBertEncoder = prim::GetAttr[name="encoder"](%4)
  %37 : __torch__.transformers.modeling_mobilebert.___torch_mangle_19999.MobileBertEmbeddings = prim::GetAttr[name="embeddings"](%4)
  %38 : int = aten::size(%input_ids, %35), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %39 : int = aten::size(%input_ids, %34), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %40 : int[] = prim::ListConstruct(%38, %39), scope: __module.mobilebert
  %input.5 : Long(17:13, 13:1) = aten::zeros(%40, %33, %35, %32, %31), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %42 : Long(17:13, 13:1) = aten::slice(%attention_mask.1, %35, %35, %30, %34), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %43 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%42, %34), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %44 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%43, %29), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %extended_attention_mask : Long(17:13, 1:13, 1:13, 13:1) = aten::slice(%44, %28, %35, %30, %34), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %46 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%extended_attention_mask, %27, %31, %31, %26), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %47 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%46, %25, %34), scope: __module.mobilebert # torch/tensor.py:396:0
  %attention_mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%47, %24), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %49 : __torch__.transformers.modeling_mobilebert.___torch_mangle_19997.NoNorm = prim::GetAttr[name="LayerNorm"](%37)
  %50 : __torch__.torch.nn.modules.sparse.___torch_mangle_19995.Embedding = prim::GetAttr[name="token_type_embeddings"](%37)
  %51 : __torch__.torch.nn.modules.sparse.___torch_mangle_19994.Embedding = prim::GetAttr[name="position_embeddings"](%37)
  %52 : __torch__.torch.nn.modules.linear.___torch_mangle_19996.Linear = prim::GetAttr[name="embedding_transformation"](%37)
  %53 : __torch__.torch.nn.modules.sparse.___torch_mangle_19993.Embedding = prim::GetAttr[name="word_embeddings"](%37)
  %54 : Tensor = prim::GetAttr[name="position_ids"](%37)
  %55 : int = aten::size(%input_ids, %34), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:185:0
  %56 : Long(1:512, 512:1) = aten::slice(%54, %35, %35, %30, %34), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %input.4 : Long(1:512, 13:1) = aten::slice(%56, %34, %35, %55, %34), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %58 : Tensor = prim::GetAttr[name="weight"](%53)
  %inputs_embeds.1 : Float(17:1664, 13:128, 128:1) = aten::embedding(%58, %input_ids, %35, %31, %31), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %60 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %35, %35, %30, %34), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %input.1 : Float(17:1664, 12:128, 128:1) = aten::slice(%60, %34, %34, %30, %34), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %62 : int[] = prim::ListConstruct(%35, %35, %35, %34, %35, %35), scope: __module.mobilebert/__module.mobilebert.embeddings
  %63 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.1, %62, %35), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %64 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %35, %35, %30, %34), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %input.2 : Float(17:1664, 12:128, 128:1) = aten::slice(%64, %34, %35, %22, %34), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %66 : int[] = prim::ListConstruct(%35, %35, %34, %35, %35, %35), scope: __module.mobilebert/__module.mobilebert.embeddings
  %67 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.2, %66, %35), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %68 : Tensor[] = prim::ListConstruct(%63, %inputs_embeds.1, %67), scope: __module.mobilebert/__module.mobilebert.embeddings
  %input.3 : Float(17:4992, 13:384, 384:1) = aten::cat(%68, %29), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:207:0
  %70 : Tensor = prim::GetAttr[name="bias"](%52)
  %71 : Tensor = prim::GetAttr[name="weight"](%52)
  %72 : Float(384:1, 512:384) = aten::t(%71), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %output.1 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.3, %72), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %inputs_embeds : Float(17:6656, 13:512, 512:1) = aten::add_(%output.1, %70, %34), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1678:0
  %75 : Tensor = prim::GetAttr[name="weight"](%51)
  %position_embeddings : Float(1:6656, 13:512, 512:1) = aten::embedding(%75, %input.4, %22, %31, %31), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %77 : Tensor = prim::GetAttr[name="weight"](%50)
  %token_type_embeddings : Float(17:6656, 13:512, 512:1) = aten::embedding(%77, %input.5, %22, %31, %31), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %79 : Float(17:6656, 13:512, 512:1) = aten::add(%inputs_embeds, %position_embeddings, %34), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %input_tensor.1 : Float(17:6656, 13:512, 512:1) = aten::add(%79, %token_type_embeddings, %34), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %81 : Tensor = prim::GetAttr[name="bias"](%49)
  %82 : Tensor = prim::GetAttr[name="weight"](%49)
  %83 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.1, %82), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.6 : Float(17:6656, 13:512, 512:1) = aten::add(%83, %81, %34), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.7 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.6, %23, %31), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %86 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %87 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21079.MobileBertLayer = prim::GetAttr[name="23"](%86)
  %88 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %89 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21034.MobileBertLayer = prim::GetAttr[name="22"](%88)
  %90 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %91 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20989.MobileBertLayer = prim::GetAttr[name="21"](%90)
  %92 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %93 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20944.MobileBertLayer = prim::GetAttr[name="20"](%92)
  %94 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %95 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20899.MobileBertLayer = prim::GetAttr[name="19"](%94)
  %96 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %97 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20854.MobileBertLayer = prim::GetAttr[name="18"](%96)
  %98 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %99 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20809.MobileBertLayer = prim::GetAttr[name="17"](%98)
  %100 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %101 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20764.MobileBertLayer = prim::GetAttr[name="16"](%100)
  %102 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20719.MobileBertLayer = prim::GetAttr[name="15"](%102)
  %104 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20674.MobileBertLayer = prim::GetAttr[name="14"](%104)
  %106 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20629.MobileBertLayer = prim::GetAttr[name="13"](%106)
  %108 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20584.MobileBertLayer = prim::GetAttr[name="12"](%108)
  %110 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20539.MobileBertLayer = prim::GetAttr[name="11"](%110)
  %112 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %113 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20494.MobileBertLayer = prim::GetAttr[name="10"](%112)
  %114 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %115 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20449.MobileBertLayer = prim::GetAttr[name="9"](%114)
  %116 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %117 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20404.MobileBertLayer = prim::GetAttr[name="8"](%116)
  %118 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20359.MobileBertLayer = prim::GetAttr[name="7"](%118)
  %120 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %121 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20314.MobileBertLayer = prim::GetAttr[name="6"](%120)
  %122 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %123 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20269.MobileBertLayer = prim::GetAttr[name="5"](%122)
  %124 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %125 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20224.MobileBertLayer = prim::GetAttr[name="4"](%124)
  %126 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20179.MobileBertLayer = prim::GetAttr[name="3"](%126)
  %128 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %129 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20134.MobileBertLayer = prim::GetAttr[name="2"](%128)
  %130 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %131 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20089.MobileBertLayer = prim::GetAttr[name="1"](%130)
  %132 : __torch__.torch.nn.modules.container.___torch_mangle_21080.ModuleList = prim::GetAttr[name="layer"](%36)
  %133 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20044.MobileBertLayer = prim::GetAttr[name="0"](%132)
  %134 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20017.MobileBertOutput = prim::GetAttr[name="output"](%133)
  %135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20010.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%133)
  %136 : __torch__.torch.nn.modules.container.___torch_mangle_20043.ModuleList = prim::GetAttr[name="ffn"](%133)
  %137 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20042.FFNLayer = prim::GetAttr[name="2"](%136)
  %138 : __torch__.torch.nn.modules.container.___torch_mangle_20043.ModuleList = prim::GetAttr[name="ffn"](%133)
  %139 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20036.FFNLayer = prim::GetAttr[name="1"](%138)
  %140 : __torch__.torch.nn.modules.container.___torch_mangle_20043.ModuleList = prim::GetAttr[name="ffn"](%133)
  %141 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20030.FFNLayer = prim::GetAttr[name="0"](%140)
  %142 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20008.MobileBertAttention = prim::GetAttr[name="attention"](%133)
  %143 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20024.Bottleneck = prim::GetAttr[name="bottleneck"](%133)
  %144 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20023.BottleneckLayer = prim::GetAttr[name="attention"](%143)
  %145 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20020.BottleneckLayer = prim::GetAttr[name="input"](%143)
  %146 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20019.NoNorm = prim::GetAttr[name="LayerNorm"](%145)
  %147 : __torch__.torch.nn.modules.linear.___torch_mangle_20018.Linear = prim::GetAttr[name="dense"](%145)
  %148 : Tensor = prim::GetAttr[name="bias"](%147)
  %149 : Tensor = prim::GetAttr[name="weight"](%147)
  %150 : Float(512:1, 128:512) = aten::t(%149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.2 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.2, %148, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %153 : Tensor = prim::GetAttr[name="bias"](%146)
  %154 : Tensor = prim::GetAttr[name="weight"](%146)
  %155 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.2, %154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.1 : Float(17:1664, 13:128, 128:1) = aten::add(%155, %153, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %157 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20022.NoNorm = prim::GetAttr[name="LayerNorm"](%144)
  %158 : __torch__.torch.nn.modules.linear.___torch_mangle_20021.Linear = prim::GetAttr[name="dense"](%144)
  %159 : Tensor = prim::GetAttr[name="bias"](%158)
  %160 : Tensor = prim::GetAttr[name="weight"](%158)
  %161 : Float(512:1, 128:512) = aten::t(%160), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.3 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %161), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.3, %159, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %164 : Tensor = prim::GetAttr[name="bias"](%157)
  %165 : Tensor = prim::GetAttr[name="weight"](%157)
  %166 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.3, %165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.8 : Float(17:1664, 13:128, 128:1) = aten::add(%166, %164, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %168 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.8, %residual_tensor.1)
  %169 : Float(17:1664, 13:128, 128:1), %170 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%168)
  %171 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20007.MobileBertSelfOutput = prim::GetAttr[name="output"](%142)
  %172 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20004.MobileBertSelfAttention = prim::GetAttr[name="self"](%142)
  %173 : __torch__.torch.nn.modules.linear.___torch_mangle_20002.Linear = prim::GetAttr[name="value"](%172)
  %174 : __torch__.torch.nn.modules.linear.___torch_mangle_20001.Linear = prim::GetAttr[name="key"](%172)
  %175 : __torch__.torch.nn.modules.linear.___torch_mangle_20000.Linear = prim::GetAttr[name="query"](%172)
  %176 : Tensor = prim::GetAttr[name="bias"](%175)
  %177 : Tensor = prim::GetAttr[name="weight"](%175)
  %178 : Float(128:1, 128:128) = aten::t(%177), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %output.4 : Float(17:1664, 13:128, 128:1) = aten::matmul(%169, %178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %x.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.4, %176, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %181 : Tensor = prim::GetAttr[name="bias"](%174)
  %182 : Tensor = prim::GetAttr[name="weight"](%174)
  %183 : Float(128:1, 128:128) = aten::t(%182), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %output.5 : Float(17:1664, 13:128, 128:1) = aten::matmul(%169, %183), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %x.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.5, %181, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1678:0
  %186 : Tensor = prim::GetAttr[name="bias"](%173)
  %187 : Tensor = prim::GetAttr[name="weight"](%173)
  %188 : Float(512:1, 128:512) = aten::t(%187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %output.6 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %188), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %x.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.6, %186, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1678:0
  %191 : int = aten::size(%x.1, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %192 : int = aten::size(%x.1, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %193 : int[] = prim::ListConstruct(%191, %192, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.1, %193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %195 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %query_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.2, %195), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %197 : int = aten::size(%x.3, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %198 : int = aten::size(%x.3, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %199 : int[] = prim::ListConstruct(%197, %198, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.3, %199), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %201 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %key_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.4, %201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %203 : int = aten::size(%x.5, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %204 : int = aten::size(%x.5, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %205 : int[] = prim::ListConstruct(%203, %204, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.5, %205), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %207 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %value_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.6, %207), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %209 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.1, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.1, %209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.1, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.2, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.9, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.10, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.1 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:280:0
  %216 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %217 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.1, %216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%217, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %219 : int = aten::size(%context_layer.2, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %220 : int = aten::size(%context_layer.2, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %221 : int[] = prim::ListConstruct(%219, %220, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %input.11 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.2, %221), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %223 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20006.NoNorm = prim::GetAttr[name="LayerNorm"](%171)
  %224 : __torch__.torch.nn.modules.linear.___torch_mangle_20005.Linear = prim::GetAttr[name="dense"](%171)
  %225 : Tensor = prim::GetAttr[name="bias"](%224)
  %226 : Tensor = prim::GetAttr[name="weight"](%224)
  %227 : Float(128:1, 128:128) = aten::t(%226), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %output.7 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.11, %227), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.7, %225, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.1, %170, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output # transformers/modeling_mobilebert.py:301:0
  %231 : Tensor = prim::GetAttr[name="bias"](%223)
  %232 : Tensor = prim::GetAttr[name="weight"](%223)
  %233 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.4, %232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.12 : Float(17:1664, 13:128, 128:1) = aten::add(%233, %231, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %235 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20029.FFNOutput = prim::GetAttr[name="output"](%141)
  %236 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20026.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%141)
  %237 : __torch__.torch.nn.modules.linear.___torch_mangle_20025.Linear = prim::GetAttr[name="dense"](%236)
  %238 : Tensor = prim::GetAttr[name="bias"](%237)
  %239 : Tensor = prim::GetAttr[name="weight"](%237)
  %240 : Float(128:1, 512:128) = aten::t(%239), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.8 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.12, %240), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.13 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.8, %238, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.14 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %244 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20028.NoNorm = prim::GetAttr[name="LayerNorm"](%235)
  %245 : __torch__.torch.nn.modules.linear.___torch_mangle_20027.Linear = prim::GetAttr[name="dense"](%235)
  %246 : Tensor = prim::GetAttr[name="bias"](%245)
  %247 : Tensor = prim::GetAttr[name="weight"](%245)
  %248 : Float(512:1, 128:512) = aten::t(%247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.9 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.14, %248), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.9, %246, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.2, %input.12, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %252 : Tensor = prim::GetAttr[name="bias"](%244)
  %253 : Tensor = prim::GetAttr[name="weight"](%244)
  %254 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.5, %253), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.15 : Float(17:1664, 13:128, 128:1) = aten::add(%254, %252, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %256 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20035.FFNOutput = prim::GetAttr[name="output"](%139)
  %257 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20032.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%139)
  %258 : __torch__.torch.nn.modules.linear.___torch_mangle_20031.Linear = prim::GetAttr[name="dense"](%257)
  %259 : Tensor = prim::GetAttr[name="bias"](%258)
  %260 : Tensor = prim::GetAttr[name="weight"](%258)
  %261 : Float(128:1, 512:128) = aten::t(%260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.10 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.15, %261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.16 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.10, %259, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.17 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %265 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20034.NoNorm = prim::GetAttr[name="LayerNorm"](%256)
  %266 : __torch__.torch.nn.modules.linear.___torch_mangle_20033.Linear = prim::GetAttr[name="dense"](%256)
  %267 : Tensor = prim::GetAttr[name="bias"](%266)
  %268 : Tensor = prim::GetAttr[name="weight"](%266)
  %269 : Float(512:1, 128:512) = aten::t(%268), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.11 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.17, %269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.11, %267, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.3, %input.15, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %273 : Tensor = prim::GetAttr[name="bias"](%265)
  %274 : Tensor = prim::GetAttr[name="weight"](%265)
  %275 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.6, %274), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.18 : Float(17:1664, 13:128, 128:1) = aten::add(%275, %273, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %277 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20041.FFNOutput = prim::GetAttr[name="output"](%137)
  %278 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20038.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%137)
  %279 : __torch__.torch.nn.modules.linear.___torch_mangle_20037.Linear = prim::GetAttr[name="dense"](%278)
  %280 : Tensor = prim::GetAttr[name="bias"](%279)
  %281 : Tensor = prim::GetAttr[name="weight"](%279)
  %282 : Float(128:1, 512:128) = aten::t(%281), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.12 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.18, %282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.19 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.12, %280, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.20 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %286 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20040.NoNorm = prim::GetAttr[name="LayerNorm"](%277)
  %287 : __torch__.torch.nn.modules.linear.___torch_mangle_20039.Linear = prim::GetAttr[name="dense"](%277)
  %288 : Tensor = prim::GetAttr[name="bias"](%287)
  %289 : Tensor = prim::GetAttr[name="weight"](%287)
  %290 : Float(512:1, 128:512) = aten::t(%289), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.13 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.20, %290), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.13, %288, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.4, %input.18, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %294 : Tensor = prim::GetAttr[name="bias"](%286)
  %295 : Tensor = prim::GetAttr[name="weight"](%286)
  %296 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.7, %295), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.21 : Float(17:1664, 13:128, 128:1) = aten::add(%296, %294, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %298 : __torch__.torch.nn.modules.linear.___torch_mangle_20009.Linear = prim::GetAttr[name="dense"](%135)
  %299 : Tensor = prim::GetAttr[name="bias"](%298)
  %300 : Tensor = prim::GetAttr[name="weight"](%298)
  %301 : Float(128:1, 512:128) = aten::t(%300), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.14 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.21, %301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.22 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.14, %299, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.23 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate # torch/nn/functional.py:1119:0
  %305 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20016.OutputBottleneck = prim::GetAttr[name="bottleneck"](%134)
  %306 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20012.NoNorm = prim::GetAttr[name="LayerNorm"](%134)
  %307 : __torch__.torch.nn.modules.linear.___torch_mangle_20011.Linear = prim::GetAttr[name="dense"](%134)
  %308 : Tensor = prim::GetAttr[name="bias"](%307)
  %309 : Tensor = prim::GetAttr[name="weight"](%307)
  %310 : Float(512:1, 128:512) = aten::t(%309), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %output.15 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.23, %310), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %layer_output.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.15, %308, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.1, %input.21, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output # transformers/modeling_mobilebert.py:405:0
  %314 : Tensor = prim::GetAttr[name="bias"](%306)
  %315 : Tensor = prim::GetAttr[name="weight"](%306)
  %316 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.8, %315), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.24 : Float(17:1664, 13:128, 128:1) = aten::add(%316, %314, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %318 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20014.NoNorm = prim::GetAttr[name="LayerNorm"](%305)
  %319 : __torch__.torch.nn.modules.linear.___torch_mangle_20013.Linear = prim::GetAttr[name="dense"](%305)
  %320 : Tensor = prim::GetAttr[name="bias"](%319)
  %321 : Tensor = prim::GetAttr[name="weight"](%319)
  %322 : Float(128:1, 512:128) = aten::t(%321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.16 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.24, %322), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.25 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.16, %320, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.5 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.25, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.9 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.5, %input.7, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %327 : Tensor = prim::GetAttr[name="bias"](%318)
  %328 : Tensor = prim::GetAttr[name="weight"](%318)
  %329 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.9, %328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.26 : Float(17:6656, 13:512, 512:1) = aten::add(%329, %327, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %331 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20062.MobileBertOutput = prim::GetAttr[name="output"](%131)
  %332 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20055.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%131)
  %333 : __torch__.torch.nn.modules.container.___torch_mangle_20088.ModuleList = prim::GetAttr[name="ffn"](%131)
  %334 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20087.FFNLayer = prim::GetAttr[name="2"](%333)
  %335 : __torch__.torch.nn.modules.container.___torch_mangle_20088.ModuleList = prim::GetAttr[name="ffn"](%131)
  %336 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20081.FFNLayer = prim::GetAttr[name="1"](%335)
  %337 : __torch__.torch.nn.modules.container.___torch_mangle_20088.ModuleList = prim::GetAttr[name="ffn"](%131)
  %338 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20075.FFNLayer = prim::GetAttr[name="0"](%337)
  %339 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20053.MobileBertAttention = prim::GetAttr[name="attention"](%131)
  %340 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20069.Bottleneck = prim::GetAttr[name="bottleneck"](%131)
  %341 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20068.BottleneckLayer = prim::GetAttr[name="attention"](%340)
  %342 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20065.BottleneckLayer = prim::GetAttr[name="input"](%340)
  %343 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20064.NoNorm = prim::GetAttr[name="LayerNorm"](%342)
  %344 : __torch__.torch.nn.modules.linear.___torch_mangle_20063.Linear = prim::GetAttr[name="dense"](%342)
  %345 : Tensor = prim::GetAttr[name="bias"](%344)
  %346 : Tensor = prim::GetAttr[name="weight"](%344)
  %347 : Float(512:1, 128:512) = aten::t(%346), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.17 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.17, %345, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %350 : Tensor = prim::GetAttr[name="bias"](%343)
  %351 : Tensor = prim::GetAttr[name="weight"](%343)
  %352 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.10, %351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add(%352, %350, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %354 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20067.NoNorm = prim::GetAttr[name="LayerNorm"](%341)
  %355 : __torch__.torch.nn.modules.linear.___torch_mangle_20066.Linear = prim::GetAttr[name="dense"](%341)
  %356 : Tensor = prim::GetAttr[name="bias"](%355)
  %357 : Tensor = prim::GetAttr[name="weight"](%355)
  %358 : Float(512:1, 128:512) = aten::t(%357), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.18 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.18, %356, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %361 : Tensor = prim::GetAttr[name="bias"](%354)
  %362 : Tensor = prim::GetAttr[name="weight"](%354)
  %363 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.11, %362), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.27 : Float(17:1664, 13:128, 128:1) = aten::add(%363, %361, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %365 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.27, %residual_tensor.2)
  %366 : Float(17:1664, 13:128, 128:1), %367 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%365)
  %368 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20052.MobileBertSelfOutput = prim::GetAttr[name="output"](%339)
  %369 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20049.MobileBertSelfAttention = prim::GetAttr[name="self"](%339)
  %370 : __torch__.torch.nn.modules.linear.___torch_mangle_20047.Linear = prim::GetAttr[name="value"](%369)
  %371 : __torch__.torch.nn.modules.linear.___torch_mangle_20046.Linear = prim::GetAttr[name="key"](%369)
  %372 : __torch__.torch.nn.modules.linear.___torch_mangle_20045.Linear = prim::GetAttr[name="query"](%369)
  %373 : Tensor = prim::GetAttr[name="bias"](%372)
  %374 : Tensor = prim::GetAttr[name="weight"](%372)
  %375 : Float(128:1, 128:128) = aten::t(%374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %output.19 : Float(17:1664, 13:128, 128:1) = aten::matmul(%366, %375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %x.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.19, %373, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1678:0
  %378 : Tensor = prim::GetAttr[name="bias"](%371)
  %379 : Tensor = prim::GetAttr[name="weight"](%371)
  %380 : Float(128:1, 128:128) = aten::t(%379), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %output.20 : Float(17:1664, 13:128, 128:1) = aten::matmul(%366, %380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %x.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.20, %378, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1678:0
  %383 : Tensor = prim::GetAttr[name="bias"](%370)
  %384 : Tensor = prim::GetAttr[name="weight"](%370)
  %385 : Float(512:1, 128:512) = aten::t(%384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %output.21 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %385), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %x.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.21, %383, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1678:0
  %388 : int = aten::size(%x.7, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %389 : int = aten::size(%x.7, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %390 : int[] = prim::ListConstruct(%388, %389, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.7, %390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %392 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %query_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.8, %392), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %394 : int = aten::size(%x.9, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %395 : int = aten::size(%x.9, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %396 : int[] = prim::ListConstruct(%394, %395, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.9, %396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %398 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %key_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.10, %398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %400 : int = aten::size(%x.11, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %401 : int = aten::size(%x.11, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %402 : int[] = prim::ListConstruct(%400, %401, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.11, %402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %404 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %value_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.12, %404), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %406 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.2, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.2, %406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.3, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.4, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.28, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.29, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.3 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.2, %value_layer.2), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:280:0
  %413 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %414 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.3, %413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%414, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %416 : int = aten::size(%context_layer.4, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %417 : int = aten::size(%context_layer.4, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %418 : int[] = prim::ListConstruct(%416, %417, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %input.30 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.4, %418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:283:0
  %420 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20051.NoNorm = prim::GetAttr[name="LayerNorm"](%368)
  %421 : __torch__.torch.nn.modules.linear.___torch_mangle_20050.Linear = prim::GetAttr[name="dense"](%368)
  %422 : Tensor = prim::GetAttr[name="bias"](%421)
  %423 : Tensor = prim::GetAttr[name="weight"](%421)
  %424 : Float(128:1, 128:128) = aten::t(%423), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %output.22 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.30, %424), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.22, %422, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.6, %367, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output # transformers/modeling_mobilebert.py:301:0
  %428 : Tensor = prim::GetAttr[name="bias"](%420)
  %429 : Tensor = prim::GetAttr[name="weight"](%420)
  %430 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.12, %429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.31 : Float(17:1664, 13:128, 128:1) = aten::add(%430, %428, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %432 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20074.FFNOutput = prim::GetAttr[name="output"](%338)
  %433 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20071.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%338)
  %434 : __torch__.torch.nn.modules.linear.___torch_mangle_20070.Linear = prim::GetAttr[name="dense"](%433)
  %435 : Tensor = prim::GetAttr[name="bias"](%434)
  %436 : Tensor = prim::GetAttr[name="weight"](%434)
  %437 : Float(128:1, 512:128) = aten::t(%436), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.23 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.31, %437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.32 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.23, %435, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.33 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.32), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %441 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20073.NoNorm = prim::GetAttr[name="LayerNorm"](%432)
  %442 : __torch__.torch.nn.modules.linear.___torch_mangle_20072.Linear = prim::GetAttr[name="dense"](%432)
  %443 : Tensor = prim::GetAttr[name="bias"](%442)
  %444 : Tensor = prim::GetAttr[name="weight"](%442)
  %445 : Float(512:1, 128:512) = aten::t(%444), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.24 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.33, %445), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.24, %443, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.7, %input.31, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %449 : Tensor = prim::GetAttr[name="bias"](%441)
  %450 : Tensor = prim::GetAttr[name="weight"](%441)
  %451 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.13, %450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.34 : Float(17:1664, 13:128, 128:1) = aten::add(%451, %449, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %453 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20080.FFNOutput = prim::GetAttr[name="output"](%336)
  %454 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20077.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%336)
  %455 : __torch__.torch.nn.modules.linear.___torch_mangle_20076.Linear = prim::GetAttr[name="dense"](%454)
  %456 : Tensor = prim::GetAttr[name="bias"](%455)
  %457 : Tensor = prim::GetAttr[name="weight"](%455)
  %458 : Float(128:1, 512:128) = aten::t(%457), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.25 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.34, %458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.35 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.25, %456, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.36 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %462 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20079.NoNorm = prim::GetAttr[name="LayerNorm"](%453)
  %463 : __torch__.torch.nn.modules.linear.___torch_mangle_20078.Linear = prim::GetAttr[name="dense"](%453)
  %464 : Tensor = prim::GetAttr[name="bias"](%463)
  %465 : Tensor = prim::GetAttr[name="weight"](%463)
  %466 : Float(512:1, 128:512) = aten::t(%465), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.26 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.36, %466), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.26, %464, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.8, %input.34, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %470 : Tensor = prim::GetAttr[name="bias"](%462)
  %471 : Tensor = prim::GetAttr[name="weight"](%462)
  %472 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.14, %471), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.37 : Float(17:1664, 13:128, 128:1) = aten::add(%472, %470, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %474 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20086.FFNOutput = prim::GetAttr[name="output"](%334)
  %475 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20083.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%334)
  %476 : __torch__.torch.nn.modules.linear.___torch_mangle_20082.Linear = prim::GetAttr[name="dense"](%475)
  %477 : Tensor = prim::GetAttr[name="bias"](%476)
  %478 : Tensor = prim::GetAttr[name="weight"](%476)
  %479 : Float(128:1, 512:128) = aten::t(%478), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.27 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.37, %479), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.38 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.27, %477, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.39 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.38), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %483 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20085.NoNorm = prim::GetAttr[name="LayerNorm"](%474)
  %484 : __torch__.torch.nn.modules.linear.___torch_mangle_20084.Linear = prim::GetAttr[name="dense"](%474)
  %485 : Tensor = prim::GetAttr[name="bias"](%484)
  %486 : Tensor = prim::GetAttr[name="weight"](%484)
  %487 : Float(512:1, 128:512) = aten::t(%486), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.28 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.39, %487), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.28, %485, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.9, %input.37, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %491 : Tensor = prim::GetAttr[name="bias"](%483)
  %492 : Tensor = prim::GetAttr[name="weight"](%483)
  %493 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.15, %492), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.40 : Float(17:1664, 13:128, 128:1) = aten::add(%493, %491, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %495 : __torch__.torch.nn.modules.linear.___torch_mangle_20054.Linear = prim::GetAttr[name="dense"](%332)
  %496 : Tensor = prim::GetAttr[name="bias"](%495)
  %497 : Tensor = prim::GetAttr[name="weight"](%495)
  %498 : Float(128:1, 512:128) = aten::t(%497), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.29 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.40, %498), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.41 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.29, %496, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.42 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.41), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate # torch/nn/functional.py:1119:0
  %502 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20061.OutputBottleneck = prim::GetAttr[name="bottleneck"](%331)
  %503 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20057.NoNorm = prim::GetAttr[name="LayerNorm"](%331)
  %504 : __torch__.torch.nn.modules.linear.___torch_mangle_20056.Linear = prim::GetAttr[name="dense"](%331)
  %505 : Tensor = prim::GetAttr[name="bias"](%504)
  %506 : Tensor = prim::GetAttr[name="weight"](%504)
  %507 : Float(512:1, 128:512) = aten::t(%506), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %output.30 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.42, %507), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %layer_output.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.30, %505, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.2, %input.40, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output # transformers/modeling_mobilebert.py:405:0
  %511 : Tensor = prim::GetAttr[name="bias"](%503)
  %512 : Tensor = prim::GetAttr[name="weight"](%503)
  %513 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.16, %512), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.43 : Float(17:1664, 13:128, 128:1) = aten::add(%513, %511, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %515 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20059.NoNorm = prim::GetAttr[name="LayerNorm"](%502)
  %516 : __torch__.torch.nn.modules.linear.___torch_mangle_20058.Linear = prim::GetAttr[name="dense"](%502)
  %517 : Tensor = prim::GetAttr[name="bias"](%516)
  %518 : Tensor = prim::GetAttr[name="weight"](%516)
  %519 : Float(128:1, 512:128) = aten::t(%518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.31 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.43, %519), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.44 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.31, %517, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.10 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.44, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.17 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.10, %input.26, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %524 : Tensor = prim::GetAttr[name="bias"](%515)
  %525 : Tensor = prim::GetAttr[name="weight"](%515)
  %526 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.17, %525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.45 : Float(17:6656, 13:512, 512:1) = aten::add(%526, %524, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %528 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20107.MobileBertOutput = prim::GetAttr[name="output"](%129)
  %529 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20100.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%129)
  %530 : __torch__.torch.nn.modules.container.___torch_mangle_20133.ModuleList = prim::GetAttr[name="ffn"](%129)
  %531 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20132.FFNLayer = prim::GetAttr[name="2"](%530)
  %532 : __torch__.torch.nn.modules.container.___torch_mangle_20133.ModuleList = prim::GetAttr[name="ffn"](%129)
  %533 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20126.FFNLayer = prim::GetAttr[name="1"](%532)
  %534 : __torch__.torch.nn.modules.container.___torch_mangle_20133.ModuleList = prim::GetAttr[name="ffn"](%129)
  %535 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20120.FFNLayer = prim::GetAttr[name="0"](%534)
  %536 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20098.MobileBertAttention = prim::GetAttr[name="attention"](%129)
  %537 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20114.Bottleneck = prim::GetAttr[name="bottleneck"](%129)
  %538 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20113.BottleneckLayer = prim::GetAttr[name="attention"](%537)
  %539 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20110.BottleneckLayer = prim::GetAttr[name="input"](%537)
  %540 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20109.NoNorm = prim::GetAttr[name="LayerNorm"](%539)
  %541 : __torch__.torch.nn.modules.linear.___torch_mangle_20108.Linear = prim::GetAttr[name="dense"](%539)
  %542 : Tensor = prim::GetAttr[name="bias"](%541)
  %543 : Tensor = prim::GetAttr[name="weight"](%541)
  %544 : Float(512:1, 128:512) = aten::t(%543), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.32 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.32, %542, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %547 : Tensor = prim::GetAttr[name="bias"](%540)
  %548 : Tensor = prim::GetAttr[name="weight"](%540)
  %549 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.18, %548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add(%549, %547, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %551 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20112.NoNorm = prim::GetAttr[name="LayerNorm"](%538)
  %552 : __torch__.torch.nn.modules.linear.___torch_mangle_20111.Linear = prim::GetAttr[name="dense"](%538)
  %553 : Tensor = prim::GetAttr[name="bias"](%552)
  %554 : Tensor = prim::GetAttr[name="weight"](%552)
  %555 : Float(512:1, 128:512) = aten::t(%554), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.33 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %555), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.33, %553, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %558 : Tensor = prim::GetAttr[name="bias"](%551)
  %559 : Tensor = prim::GetAttr[name="weight"](%551)
  %560 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.19, %559), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.46 : Float(17:1664, 13:128, 128:1) = aten::add(%560, %558, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %562 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.46, %residual_tensor.3)
  %563 : Float(17:1664, 13:128, 128:1), %564 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%562)
  %565 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20097.MobileBertSelfOutput = prim::GetAttr[name="output"](%536)
  %566 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20094.MobileBertSelfAttention = prim::GetAttr[name="self"](%536)
  %567 : __torch__.torch.nn.modules.linear.___torch_mangle_20092.Linear = prim::GetAttr[name="value"](%566)
  %568 : __torch__.torch.nn.modules.linear.___torch_mangle_20091.Linear = prim::GetAttr[name="key"](%566)
  %569 : __torch__.torch.nn.modules.linear.___torch_mangle_20090.Linear = prim::GetAttr[name="query"](%566)
  %570 : Tensor = prim::GetAttr[name="bias"](%569)
  %571 : Tensor = prim::GetAttr[name="weight"](%569)
  %572 : Float(128:1, 128:128) = aten::t(%571), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %output.34 : Float(17:1664, 13:128, 128:1) = aten::matmul(%563, %572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %x.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.34, %570, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1678:0
  %575 : Tensor = prim::GetAttr[name="bias"](%568)
  %576 : Tensor = prim::GetAttr[name="weight"](%568)
  %577 : Float(128:1, 128:128) = aten::t(%576), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %output.35 : Float(17:1664, 13:128, 128:1) = aten::matmul(%563, %577), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %x.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.35, %575, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1678:0
  %580 : Tensor = prim::GetAttr[name="bias"](%567)
  %581 : Tensor = prim::GetAttr[name="weight"](%567)
  %582 : Float(512:1, 128:512) = aten::t(%581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %output.36 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %582), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %x.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.36, %580, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1678:0
  %585 : int = aten::size(%x.13, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %586 : int = aten::size(%x.13, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %587 : int[] = prim::ListConstruct(%585, %586, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.13, %587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %589 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %query_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.14, %589), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %591 : int = aten::size(%x.15, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %592 : int = aten::size(%x.15, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %593 : int[] = prim::ListConstruct(%591, %592, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.15, %593), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %595 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %key_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.16, %595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %597 : int = aten::size(%x.17, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %598 : int = aten::size(%x.17, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %599 : int[] = prim::ListConstruct(%597, %598, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.17, %599), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %601 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %value_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.18, %601), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %603 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.3, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.3, %603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.5, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.6, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.48 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.47, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.48, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.5 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.3, %value_layer.3), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:280:0
  %610 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %611 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.5, %610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%611, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %613 : int = aten::size(%context_layer.6, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %614 : int = aten::size(%context_layer.6, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %615 : int[] = prim::ListConstruct(%613, %614, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %input.49 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.6, %615), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:283:0
  %617 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20096.NoNorm = prim::GetAttr[name="LayerNorm"](%565)
  %618 : __torch__.torch.nn.modules.linear.___torch_mangle_20095.Linear = prim::GetAttr[name="dense"](%565)
  %619 : Tensor = prim::GetAttr[name="bias"](%618)
  %620 : Tensor = prim::GetAttr[name="weight"](%618)
  %621 : Float(128:1, 128:128) = aten::t(%620), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %output.37 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.49, %621), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.37, %619, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.11, %564, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output # transformers/modeling_mobilebert.py:301:0
  %625 : Tensor = prim::GetAttr[name="bias"](%617)
  %626 : Tensor = prim::GetAttr[name="weight"](%617)
  %627 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.20, %626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.50 : Float(17:1664, 13:128, 128:1) = aten::add(%627, %625, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %629 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20119.FFNOutput = prim::GetAttr[name="output"](%535)
  %630 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20116.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%535)
  %631 : __torch__.torch.nn.modules.linear.___torch_mangle_20115.Linear = prim::GetAttr[name="dense"](%630)
  %632 : Tensor = prim::GetAttr[name="bias"](%631)
  %633 : Tensor = prim::GetAttr[name="weight"](%631)
  %634 : Float(128:1, 512:128) = aten::t(%633), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.38 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.50, %634), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.51 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.38, %632, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.52 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.51), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %638 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20118.NoNorm = prim::GetAttr[name="LayerNorm"](%629)
  %639 : __torch__.torch.nn.modules.linear.___torch_mangle_20117.Linear = prim::GetAttr[name="dense"](%629)
  %640 : Tensor = prim::GetAttr[name="bias"](%639)
  %641 : Tensor = prim::GetAttr[name="weight"](%639)
  %642 : Float(512:1, 128:512) = aten::t(%641), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.39 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.52, %642), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.39, %640, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.12, %input.50, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %646 : Tensor = prim::GetAttr[name="bias"](%638)
  %647 : Tensor = prim::GetAttr[name="weight"](%638)
  %648 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.21, %647), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.53 : Float(17:1664, 13:128, 128:1) = aten::add(%648, %646, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %650 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20125.FFNOutput = prim::GetAttr[name="output"](%533)
  %651 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20122.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%533)
  %652 : __torch__.torch.nn.modules.linear.___torch_mangle_20121.Linear = prim::GetAttr[name="dense"](%651)
  %653 : Tensor = prim::GetAttr[name="bias"](%652)
  %654 : Tensor = prim::GetAttr[name="weight"](%652)
  %655 : Float(128:1, 512:128) = aten::t(%654), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.40 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.53, %655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.54 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.40, %653, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.55 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.54), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %659 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20124.NoNorm = prim::GetAttr[name="LayerNorm"](%650)
  %660 : __torch__.torch.nn.modules.linear.___torch_mangle_20123.Linear = prim::GetAttr[name="dense"](%650)
  %661 : Tensor = prim::GetAttr[name="bias"](%660)
  %662 : Tensor = prim::GetAttr[name="weight"](%660)
  %663 : Float(512:1, 128:512) = aten::t(%662), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.41 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.55, %663), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.41, %661, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.13, %input.53, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %667 : Tensor = prim::GetAttr[name="bias"](%659)
  %668 : Tensor = prim::GetAttr[name="weight"](%659)
  %669 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.22, %668), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.56 : Float(17:1664, 13:128, 128:1) = aten::add(%669, %667, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %671 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20131.FFNOutput = prim::GetAttr[name="output"](%531)
  %672 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20128.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%531)
  %673 : __torch__.torch.nn.modules.linear.___torch_mangle_20127.Linear = prim::GetAttr[name="dense"](%672)
  %674 : Tensor = prim::GetAttr[name="bias"](%673)
  %675 : Tensor = prim::GetAttr[name="weight"](%673)
  %676 : Float(128:1, 512:128) = aten::t(%675), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.42 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.56, %676), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.57 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.42, %674, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.58 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.57), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %680 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20130.NoNorm = prim::GetAttr[name="LayerNorm"](%671)
  %681 : __torch__.torch.nn.modules.linear.___torch_mangle_20129.Linear = prim::GetAttr[name="dense"](%671)
  %682 : Tensor = prim::GetAttr[name="bias"](%681)
  %683 : Tensor = prim::GetAttr[name="weight"](%681)
  %684 : Float(512:1, 128:512) = aten::t(%683), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.43 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.58, %684), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.43, %682, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.14, %input.56, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %688 : Tensor = prim::GetAttr[name="bias"](%680)
  %689 : Tensor = prim::GetAttr[name="weight"](%680)
  %690 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.23, %689), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.59 : Float(17:1664, 13:128, 128:1) = aten::add(%690, %688, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %692 : __torch__.torch.nn.modules.linear.___torch_mangle_20099.Linear = prim::GetAttr[name="dense"](%529)
  %693 : Tensor = prim::GetAttr[name="bias"](%692)
  %694 : Tensor = prim::GetAttr[name="weight"](%692)
  %695 : Float(128:1, 512:128) = aten::t(%694), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.44 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.59, %695), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.60 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.44, %693, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.61 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.60), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate # torch/nn/functional.py:1119:0
  %699 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20106.OutputBottleneck = prim::GetAttr[name="bottleneck"](%528)
  %700 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20102.NoNorm = prim::GetAttr[name="LayerNorm"](%528)
  %701 : __torch__.torch.nn.modules.linear.___torch_mangle_20101.Linear = prim::GetAttr[name="dense"](%528)
  %702 : Tensor = prim::GetAttr[name="bias"](%701)
  %703 : Tensor = prim::GetAttr[name="weight"](%701)
  %704 : Float(512:1, 128:512) = aten::t(%703), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %output.45 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.61, %704), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %layer_output.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.45, %702, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.24 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.3, %input.59, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output # transformers/modeling_mobilebert.py:405:0
  %708 : Tensor = prim::GetAttr[name="bias"](%700)
  %709 : Tensor = prim::GetAttr[name="weight"](%700)
  %710 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.24, %709), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.62 : Float(17:1664, 13:128, 128:1) = aten::add(%710, %708, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %712 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20104.NoNorm = prim::GetAttr[name="LayerNorm"](%699)
  %713 : __torch__.torch.nn.modules.linear.___torch_mangle_20103.Linear = prim::GetAttr[name="dense"](%699)
  %714 : Tensor = prim::GetAttr[name="bias"](%713)
  %715 : Tensor = prim::GetAttr[name="weight"](%713)
  %716 : Float(128:1, 512:128) = aten::t(%715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.46 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.62, %716), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.63 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.46, %714, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.15 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.63, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.25 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.15, %input.45, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %721 : Tensor = prim::GetAttr[name="bias"](%712)
  %722 : Tensor = prim::GetAttr[name="weight"](%712)
  %723 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.25, %722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.64 : Float(17:6656, 13:512, 512:1) = aten::add(%723, %721, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %725 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20152.MobileBertOutput = prim::GetAttr[name="output"](%127)
  %726 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20145.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%127)
  %727 : __torch__.torch.nn.modules.container.___torch_mangle_20178.ModuleList = prim::GetAttr[name="ffn"](%127)
  %728 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20177.FFNLayer = prim::GetAttr[name="2"](%727)
  %729 : __torch__.torch.nn.modules.container.___torch_mangle_20178.ModuleList = prim::GetAttr[name="ffn"](%127)
  %730 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20171.FFNLayer = prim::GetAttr[name="1"](%729)
  %731 : __torch__.torch.nn.modules.container.___torch_mangle_20178.ModuleList = prim::GetAttr[name="ffn"](%127)
  %732 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20165.FFNLayer = prim::GetAttr[name="0"](%731)
  %733 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20143.MobileBertAttention = prim::GetAttr[name="attention"](%127)
  %734 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20159.Bottleneck = prim::GetAttr[name="bottleneck"](%127)
  %735 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20158.BottleneckLayer = prim::GetAttr[name="attention"](%734)
  %736 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20155.BottleneckLayer = prim::GetAttr[name="input"](%734)
  %737 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20154.NoNorm = prim::GetAttr[name="LayerNorm"](%736)
  %738 : __torch__.torch.nn.modules.linear.___torch_mangle_20153.Linear = prim::GetAttr[name="dense"](%736)
  %739 : Tensor = prim::GetAttr[name="bias"](%738)
  %740 : Tensor = prim::GetAttr[name="weight"](%738)
  %741 : Float(512:1, 128:512) = aten::t(%740), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.47 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.47, %739, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %744 : Tensor = prim::GetAttr[name="bias"](%737)
  %745 : Tensor = prim::GetAttr[name="weight"](%737)
  %746 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.26, %745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%746, %744, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %748 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20157.NoNorm = prim::GetAttr[name="LayerNorm"](%735)
  %749 : __torch__.torch.nn.modules.linear.___torch_mangle_20156.Linear = prim::GetAttr[name="dense"](%735)
  %750 : Tensor = prim::GetAttr[name="bias"](%749)
  %751 : Tensor = prim::GetAttr[name="weight"](%749)
  %752 : Float(512:1, 128:512) = aten::t(%751), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.48 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %752), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.48, %750, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %755 : Tensor = prim::GetAttr[name="bias"](%748)
  %756 : Tensor = prim::GetAttr[name="weight"](%748)
  %757 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.27, %756), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.65 : Float(17:1664, 13:128, 128:1) = aten::add(%757, %755, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %759 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.65, %residual_tensor.4)
  %760 : Float(17:1664, 13:128, 128:1), %761 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%759)
  %762 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20142.MobileBertSelfOutput = prim::GetAttr[name="output"](%733)
  %763 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20139.MobileBertSelfAttention = prim::GetAttr[name="self"](%733)
  %764 : __torch__.torch.nn.modules.linear.___torch_mangle_20137.Linear = prim::GetAttr[name="value"](%763)
  %765 : __torch__.torch.nn.modules.linear.___torch_mangle_20136.Linear = prim::GetAttr[name="key"](%763)
  %766 : __torch__.torch.nn.modules.linear.___torch_mangle_20135.Linear = prim::GetAttr[name="query"](%763)
  %767 : Tensor = prim::GetAttr[name="bias"](%766)
  %768 : Tensor = prim::GetAttr[name="weight"](%766)
  %769 : Float(128:1, 128:128) = aten::t(%768), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %output.49 : Float(17:1664, 13:128, 128:1) = aten::matmul(%760, %769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %x.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.49, %767, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1678:0
  %772 : Tensor = prim::GetAttr[name="bias"](%765)
  %773 : Tensor = prim::GetAttr[name="weight"](%765)
  %774 : Float(128:1, 128:128) = aten::t(%773), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %output.50 : Float(17:1664, 13:128, 128:1) = aten::matmul(%760, %774), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %x.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.50, %772, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1678:0
  %777 : Tensor = prim::GetAttr[name="bias"](%764)
  %778 : Tensor = prim::GetAttr[name="weight"](%764)
  %779 : Float(512:1, 128:512) = aten::t(%778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %output.51 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %779), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %x.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.51, %777, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1678:0
  %782 : int = aten::size(%x.19, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %783 : int = aten::size(%x.19, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %784 : int[] = prim::ListConstruct(%782, %783, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.19, %784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %786 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %query_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.20, %786), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %788 : int = aten::size(%x.21, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %789 : int = aten::size(%x.21, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %790 : int[] = prim::ListConstruct(%788, %789, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.21, %790), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %792 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %key_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.22, %792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %794 : int = aten::size(%x.23, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %795 : int = aten::size(%x.23, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %796 : int[] = prim::ListConstruct(%794, %795, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.23, %796), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %798 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %value_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.24, %798), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %800 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.4, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.4, %800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.7, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.66 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.8, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.67 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.66, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.67, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.7 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.4, %value_layer.4), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:280:0
  %807 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %808 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.7, %807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%808, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %810 : int = aten::size(%context_layer.8, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %811 : int = aten::size(%context_layer.8, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %812 : int[] = prim::ListConstruct(%810, %811, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %input.68 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.8, %812), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:283:0
  %814 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20141.NoNorm = prim::GetAttr[name="LayerNorm"](%762)
  %815 : __torch__.torch.nn.modules.linear.___torch_mangle_20140.Linear = prim::GetAttr[name="dense"](%762)
  %816 : Tensor = prim::GetAttr[name="bias"](%815)
  %817 : Tensor = prim::GetAttr[name="weight"](%815)
  %818 : Float(128:1, 128:128) = aten::t(%817), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %output.52 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.68, %818), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.52, %816, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.28 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.16, %761, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output # transformers/modeling_mobilebert.py:301:0
  %822 : Tensor = prim::GetAttr[name="bias"](%814)
  %823 : Tensor = prim::GetAttr[name="weight"](%814)
  %824 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.28, %823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.69 : Float(17:1664, 13:128, 128:1) = aten::add(%824, %822, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %826 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20164.FFNOutput = prim::GetAttr[name="output"](%732)
  %827 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20161.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%732)
  %828 : __torch__.torch.nn.modules.linear.___torch_mangle_20160.Linear = prim::GetAttr[name="dense"](%827)
  %829 : Tensor = prim::GetAttr[name="bias"](%828)
  %830 : Tensor = prim::GetAttr[name="weight"](%828)
  %831 : Float(128:1, 512:128) = aten::t(%830), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.53 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.69, %831), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.70 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.53, %829, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.71 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.70), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %835 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20163.NoNorm = prim::GetAttr[name="LayerNorm"](%826)
  %836 : __torch__.torch.nn.modules.linear.___torch_mangle_20162.Linear = prim::GetAttr[name="dense"](%826)
  %837 : Tensor = prim::GetAttr[name="bias"](%836)
  %838 : Tensor = prim::GetAttr[name="weight"](%836)
  %839 : Float(512:1, 128:512) = aten::t(%838), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.54 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.71, %839), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.54, %837, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.29 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.17, %input.69, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %843 : Tensor = prim::GetAttr[name="bias"](%835)
  %844 : Tensor = prim::GetAttr[name="weight"](%835)
  %845 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.29, %844), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.72 : Float(17:1664, 13:128, 128:1) = aten::add(%845, %843, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %847 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20170.FFNOutput = prim::GetAttr[name="output"](%730)
  %848 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20167.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%730)
  %849 : __torch__.torch.nn.modules.linear.___torch_mangle_20166.Linear = prim::GetAttr[name="dense"](%848)
  %850 : Tensor = prim::GetAttr[name="bias"](%849)
  %851 : Tensor = prim::GetAttr[name="weight"](%849)
  %852 : Float(128:1, 512:128) = aten::t(%851), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.55 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.72, %852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.73 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.55, %850, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.74 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.73), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %856 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20169.NoNorm = prim::GetAttr[name="LayerNorm"](%847)
  %857 : __torch__.torch.nn.modules.linear.___torch_mangle_20168.Linear = prim::GetAttr[name="dense"](%847)
  %858 : Tensor = prim::GetAttr[name="bias"](%857)
  %859 : Tensor = prim::GetAttr[name="weight"](%857)
  %860 : Float(512:1, 128:512) = aten::t(%859), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.56 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.74, %860), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.56, %858, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.30 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.18, %input.72, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %864 : Tensor = prim::GetAttr[name="bias"](%856)
  %865 : Tensor = prim::GetAttr[name="weight"](%856)
  %866 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.30, %865), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.75 : Float(17:1664, 13:128, 128:1) = aten::add(%866, %864, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %868 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20176.FFNOutput = prim::GetAttr[name="output"](%728)
  %869 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20173.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%728)
  %870 : __torch__.torch.nn.modules.linear.___torch_mangle_20172.Linear = prim::GetAttr[name="dense"](%869)
  %871 : Tensor = prim::GetAttr[name="bias"](%870)
  %872 : Tensor = prim::GetAttr[name="weight"](%870)
  %873 : Float(128:1, 512:128) = aten::t(%872), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.57 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.75, %873), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.76 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.57, %871, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.77 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.76), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %877 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20175.NoNorm = prim::GetAttr[name="LayerNorm"](%868)
  %878 : __torch__.torch.nn.modules.linear.___torch_mangle_20174.Linear = prim::GetAttr[name="dense"](%868)
  %879 : Tensor = prim::GetAttr[name="bias"](%878)
  %880 : Tensor = prim::GetAttr[name="weight"](%878)
  %881 : Float(512:1, 128:512) = aten::t(%880), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.58 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.77, %881), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.58, %879, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.31 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.19, %input.75, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %885 : Tensor = prim::GetAttr[name="bias"](%877)
  %886 : Tensor = prim::GetAttr[name="weight"](%877)
  %887 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.31, %886), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.78 : Float(17:1664, 13:128, 128:1) = aten::add(%887, %885, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %889 : __torch__.torch.nn.modules.linear.___torch_mangle_20144.Linear = prim::GetAttr[name="dense"](%726)
  %890 : Tensor = prim::GetAttr[name="bias"](%889)
  %891 : Tensor = prim::GetAttr[name="weight"](%889)
  %892 : Float(128:1, 512:128) = aten::t(%891), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %output.59 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.78, %892), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %input.79 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.59, %890, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1678:0
  %input.80 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.79), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate # torch/nn/functional.py:1119:0
  %896 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20151.OutputBottleneck = prim::GetAttr[name="bottleneck"](%725)
  %897 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20147.NoNorm = prim::GetAttr[name="LayerNorm"](%725)
  %898 : __torch__.torch.nn.modules.linear.___torch_mangle_20146.Linear = prim::GetAttr[name="dense"](%725)
  %899 : Tensor = prim::GetAttr[name="bias"](%898)
  %900 : Tensor = prim::GetAttr[name="weight"](%898)
  %901 : Float(512:1, 128:512) = aten::t(%900), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %output.60 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.80, %901), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %layer_output.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.60, %899, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.32 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.4, %input.78, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output # transformers/modeling_mobilebert.py:405:0
  %905 : Tensor = prim::GetAttr[name="bias"](%897)
  %906 : Tensor = prim::GetAttr[name="weight"](%897)
  %907 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.32, %906), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.81 : Float(17:1664, 13:128, 128:1) = aten::add(%907, %905, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %909 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20149.NoNorm = prim::GetAttr[name="LayerNorm"](%896)
  %910 : __torch__.torch.nn.modules.linear.___torch_mangle_20148.Linear = prim::GetAttr[name="dense"](%896)
  %911 : Tensor = prim::GetAttr[name="bias"](%910)
  %912 : Tensor = prim::GetAttr[name="weight"](%910)
  %913 : Float(128:1, 512:128) = aten::t(%912), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.61 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.81, %913), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.82 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.61, %911, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.20 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.82, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.33 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.20, %input.64, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %918 : Tensor = prim::GetAttr[name="bias"](%909)
  %919 : Tensor = prim::GetAttr[name="weight"](%909)
  %920 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.33, %919), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.83 : Float(17:6656, 13:512, 512:1) = aten::add(%920, %918, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %922 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20197.MobileBertOutput = prim::GetAttr[name="output"](%125)
  %923 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20190.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%125)
  %924 : __torch__.torch.nn.modules.container.___torch_mangle_20223.ModuleList = prim::GetAttr[name="ffn"](%125)
  %925 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20222.FFNLayer = prim::GetAttr[name="2"](%924)
  %926 : __torch__.torch.nn.modules.container.___torch_mangle_20223.ModuleList = prim::GetAttr[name="ffn"](%125)
  %927 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20216.FFNLayer = prim::GetAttr[name="1"](%926)
  %928 : __torch__.torch.nn.modules.container.___torch_mangle_20223.ModuleList = prim::GetAttr[name="ffn"](%125)
  %929 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20210.FFNLayer = prim::GetAttr[name="0"](%928)
  %930 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20188.MobileBertAttention = prim::GetAttr[name="attention"](%125)
  %931 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20204.Bottleneck = prim::GetAttr[name="bottleneck"](%125)
  %932 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20203.BottleneckLayer = prim::GetAttr[name="attention"](%931)
  %933 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20200.BottleneckLayer = prim::GetAttr[name="input"](%931)
  %934 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20199.NoNorm = prim::GetAttr[name="LayerNorm"](%933)
  %935 : __torch__.torch.nn.modules.linear.___torch_mangle_20198.Linear = prim::GetAttr[name="dense"](%933)
  %936 : Tensor = prim::GetAttr[name="bias"](%935)
  %937 : Tensor = prim::GetAttr[name="weight"](%935)
  %938 : Float(512:1, 128:512) = aten::t(%937), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.62 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %938), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.62, %936, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %941 : Tensor = prim::GetAttr[name="bias"](%934)
  %942 : Tensor = prim::GetAttr[name="weight"](%934)
  %943 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.34, %942), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%943, %941, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %945 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20202.NoNorm = prim::GetAttr[name="LayerNorm"](%932)
  %946 : __torch__.torch.nn.modules.linear.___torch_mangle_20201.Linear = prim::GetAttr[name="dense"](%932)
  %947 : Tensor = prim::GetAttr[name="bias"](%946)
  %948 : Tensor = prim::GetAttr[name="weight"](%946)
  %949 : Float(512:1, 128:512) = aten::t(%948), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.63 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %949), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.63, %947, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %952 : Tensor = prim::GetAttr[name="bias"](%945)
  %953 : Tensor = prim::GetAttr[name="weight"](%945)
  %954 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.35, %953), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.84 : Float(17:1664, 13:128, 128:1) = aten::add(%954, %952, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %956 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.84, %residual_tensor.5)
  %957 : Float(17:1664, 13:128, 128:1), %958 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%956)
  %959 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20187.MobileBertSelfOutput = prim::GetAttr[name="output"](%930)
  %960 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20184.MobileBertSelfAttention = prim::GetAttr[name="self"](%930)
  %961 : __torch__.torch.nn.modules.linear.___torch_mangle_20182.Linear = prim::GetAttr[name="value"](%960)
  %962 : __torch__.torch.nn.modules.linear.___torch_mangle_20181.Linear = prim::GetAttr[name="key"](%960)
  %963 : __torch__.torch.nn.modules.linear.___torch_mangle_20180.Linear = prim::GetAttr[name="query"](%960)
  %964 : Tensor = prim::GetAttr[name="bias"](%963)
  %965 : Tensor = prim::GetAttr[name="weight"](%963)
  %966 : Float(128:1, 128:128) = aten::t(%965), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %output.64 : Float(17:1664, 13:128, 128:1) = aten::matmul(%957, %966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %x.25 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.64, %964, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1678:0
  %969 : Tensor = prim::GetAttr[name="bias"](%962)
  %970 : Tensor = prim::GetAttr[name="weight"](%962)
  %971 : Float(128:1, 128:128) = aten::t(%970), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %output.65 : Float(17:1664, 13:128, 128:1) = aten::matmul(%957, %971), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %x.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.65, %969, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1678:0
  %974 : Tensor = prim::GetAttr[name="bias"](%961)
  %975 : Tensor = prim::GetAttr[name="weight"](%961)
  %976 : Float(512:1, 128:512) = aten::t(%975), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %output.66 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %976), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %x.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.66, %974, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1678:0
  %979 : int = aten::size(%x.25, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %980 : int = aten::size(%x.25, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %981 : int[] = prim::ListConstruct(%979, %980, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.25, %981), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %983 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %query_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.26, %983), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %985 : int = aten::size(%x.27, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %986 : int = aten::size(%x.27, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %987 : int[] = prim::ListConstruct(%985, %986, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.27, %987), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %989 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %key_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.28, %989), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %991 : int = aten::size(%x.29, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %992 : int = aten::size(%x.29, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %993 : int[] = prim::ListConstruct(%991, %992, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.29, %993), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %995 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %value_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.30, %995), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %997 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.5, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.5, %997), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.9, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.85 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.10, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.86 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.85, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.86, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.9 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.5, %value_layer.5), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:280:0
  %1004 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %1005 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.9, %1004), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1005, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %1007 : int = aten::size(%context_layer.10, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1008 : int = aten::size(%context_layer.10, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1009 : int[] = prim::ListConstruct(%1007, %1008, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %input.87 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.10, %1009), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:283:0
  %1011 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20186.NoNorm = prim::GetAttr[name="LayerNorm"](%959)
  %1012 : __torch__.torch.nn.modules.linear.___torch_mangle_20185.Linear = prim::GetAttr[name="dense"](%959)
  %1013 : Tensor = prim::GetAttr[name="bias"](%1012)
  %1014 : Tensor = prim::GetAttr[name="weight"](%1012)
  %1015 : Float(128:1, 128:128) = aten::t(%1014), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %output.67 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.87, %1015), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.67, %1013, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.36 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.21, %958, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output # transformers/modeling_mobilebert.py:301:0
  %1019 : Tensor = prim::GetAttr[name="bias"](%1011)
  %1020 : Tensor = prim::GetAttr[name="weight"](%1011)
  %1021 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.36, %1020), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.88 : Float(17:1664, 13:128, 128:1) = aten::add(%1021, %1019, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1023 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20209.FFNOutput = prim::GetAttr[name="output"](%929)
  %1024 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20206.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%929)
  %1025 : __torch__.torch.nn.modules.linear.___torch_mangle_20205.Linear = prim::GetAttr[name="dense"](%1024)
  %1026 : Tensor = prim::GetAttr[name="bias"](%1025)
  %1027 : Tensor = prim::GetAttr[name="weight"](%1025)
  %1028 : Float(128:1, 512:128) = aten::t(%1027), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.68 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.88, %1028), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.89 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.68, %1026, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.90 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.89), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1032 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20208.NoNorm = prim::GetAttr[name="LayerNorm"](%1023)
  %1033 : __torch__.torch.nn.modules.linear.___torch_mangle_20207.Linear = prim::GetAttr[name="dense"](%1023)
  %1034 : Tensor = prim::GetAttr[name="bias"](%1033)
  %1035 : Tensor = prim::GetAttr[name="weight"](%1033)
  %1036 : Float(512:1, 128:512) = aten::t(%1035), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.69 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.90, %1036), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.69, %1034, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.37 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.22, %input.88, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1040 : Tensor = prim::GetAttr[name="bias"](%1032)
  %1041 : Tensor = prim::GetAttr[name="weight"](%1032)
  %1042 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.37, %1041), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.91 : Float(17:1664, 13:128, 128:1) = aten::add(%1042, %1040, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1044 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20215.FFNOutput = prim::GetAttr[name="output"](%927)
  %1045 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20212.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%927)
  %1046 : __torch__.torch.nn.modules.linear.___torch_mangle_20211.Linear = prim::GetAttr[name="dense"](%1045)
  %1047 : Tensor = prim::GetAttr[name="bias"](%1046)
  %1048 : Tensor = prim::GetAttr[name="weight"](%1046)
  %1049 : Float(128:1, 512:128) = aten::t(%1048), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.70 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.91, %1049), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.92 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.70, %1047, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.93 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.92), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1053 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20214.NoNorm = prim::GetAttr[name="LayerNorm"](%1044)
  %1054 : __torch__.torch.nn.modules.linear.___torch_mangle_20213.Linear = prim::GetAttr[name="dense"](%1044)
  %1055 : Tensor = prim::GetAttr[name="bias"](%1054)
  %1056 : Tensor = prim::GetAttr[name="weight"](%1054)
  %1057 : Float(512:1, 128:512) = aten::t(%1056), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.71 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.93, %1057), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.71, %1055, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.38 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.23, %input.91, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1061 : Tensor = prim::GetAttr[name="bias"](%1053)
  %1062 : Tensor = prim::GetAttr[name="weight"](%1053)
  %1063 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.38, %1062), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.94 : Float(17:1664, 13:128, 128:1) = aten::add(%1063, %1061, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1065 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20221.FFNOutput = prim::GetAttr[name="output"](%925)
  %1066 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20218.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%925)
  %1067 : __torch__.torch.nn.modules.linear.___torch_mangle_20217.Linear = prim::GetAttr[name="dense"](%1066)
  %1068 : Tensor = prim::GetAttr[name="bias"](%1067)
  %1069 : Tensor = prim::GetAttr[name="weight"](%1067)
  %1070 : Float(128:1, 512:128) = aten::t(%1069), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.72 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.94, %1070), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.95 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.72, %1068, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.96 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.95), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1074 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20220.NoNorm = prim::GetAttr[name="LayerNorm"](%1065)
  %1075 : __torch__.torch.nn.modules.linear.___torch_mangle_20219.Linear = prim::GetAttr[name="dense"](%1065)
  %1076 : Tensor = prim::GetAttr[name="bias"](%1075)
  %1077 : Tensor = prim::GetAttr[name="weight"](%1075)
  %1078 : Float(512:1, 128:512) = aten::t(%1077), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.73 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.96, %1078), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.24 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.73, %1076, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.39 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.24, %input.94, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1082 : Tensor = prim::GetAttr[name="bias"](%1074)
  %1083 : Tensor = prim::GetAttr[name="weight"](%1074)
  %1084 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.39, %1083), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.97 : Float(17:1664, 13:128, 128:1) = aten::add(%1084, %1082, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1086 : __torch__.torch.nn.modules.linear.___torch_mangle_20189.Linear = prim::GetAttr[name="dense"](%923)
  %1087 : Tensor = prim::GetAttr[name="bias"](%1086)
  %1088 : Tensor = prim::GetAttr[name="weight"](%1086)
  %1089 : Float(128:1, 512:128) = aten::t(%1088), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %output.74 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.97, %1089), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %input.98 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.74, %1087, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1678:0
  %input.99 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.98), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate # torch/nn/functional.py:1119:0
  %1093 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20196.OutputBottleneck = prim::GetAttr[name="bottleneck"](%922)
  %1094 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20192.NoNorm = prim::GetAttr[name="LayerNorm"](%922)
  %1095 : __torch__.torch.nn.modules.linear.___torch_mangle_20191.Linear = prim::GetAttr[name="dense"](%922)
  %1096 : Tensor = prim::GetAttr[name="bias"](%1095)
  %1097 : Tensor = prim::GetAttr[name="weight"](%1095)
  %1098 : Float(512:1, 128:512) = aten::t(%1097), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %output.75 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.99, %1098), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %layer_output.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.75, %1096, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.40 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.5, %input.97, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output # transformers/modeling_mobilebert.py:405:0
  %1102 : Tensor = prim::GetAttr[name="bias"](%1094)
  %1103 : Tensor = prim::GetAttr[name="weight"](%1094)
  %1104 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.40, %1103), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.100 : Float(17:1664, 13:128, 128:1) = aten::add(%1104, %1102, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1106 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20194.NoNorm = prim::GetAttr[name="LayerNorm"](%1093)
  %1107 : __torch__.torch.nn.modules.linear.___torch_mangle_20193.Linear = prim::GetAttr[name="dense"](%1093)
  %1108 : Tensor = prim::GetAttr[name="bias"](%1107)
  %1109 : Tensor = prim::GetAttr[name="weight"](%1107)
  %1110 : Float(128:1, 512:128) = aten::t(%1109), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.76 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.100, %1110), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.101 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.76, %1108, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.25 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.101, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.41 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.25, %input.83, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1115 : Tensor = prim::GetAttr[name="bias"](%1106)
  %1116 : Tensor = prim::GetAttr[name="weight"](%1106)
  %1117 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.41, %1116), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.102 : Float(17:6656, 13:512, 512:1) = aten::add(%1117, %1115, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20242.MobileBertOutput = prim::GetAttr[name="output"](%123)
  %1120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20235.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%123)
  %1121 : __torch__.torch.nn.modules.container.___torch_mangle_20268.ModuleList = prim::GetAttr[name="ffn"](%123)
  %1122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20267.FFNLayer = prim::GetAttr[name="2"](%1121)
  %1123 : __torch__.torch.nn.modules.container.___torch_mangle_20268.ModuleList = prim::GetAttr[name="ffn"](%123)
  %1124 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20261.FFNLayer = prim::GetAttr[name="1"](%1123)
  %1125 : __torch__.torch.nn.modules.container.___torch_mangle_20268.ModuleList = prim::GetAttr[name="ffn"](%123)
  %1126 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20255.FFNLayer = prim::GetAttr[name="0"](%1125)
  %1127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20233.MobileBertAttention = prim::GetAttr[name="attention"](%123)
  %1128 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20249.Bottleneck = prim::GetAttr[name="bottleneck"](%123)
  %1129 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20248.BottleneckLayer = prim::GetAttr[name="attention"](%1128)
  %1130 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20245.BottleneckLayer = prim::GetAttr[name="input"](%1128)
  %1131 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20244.NoNorm = prim::GetAttr[name="LayerNorm"](%1130)
  %1132 : __torch__.torch.nn.modules.linear.___torch_mangle_20243.Linear = prim::GetAttr[name="dense"](%1130)
  %1133 : Tensor = prim::GetAttr[name="bias"](%1132)
  %1134 : Tensor = prim::GetAttr[name="weight"](%1132)
  %1135 : Float(512:1, 128:512) = aten::t(%1134), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.77 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1135), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.77, %1133, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1138 : Tensor = prim::GetAttr[name="bias"](%1131)
  %1139 : Tensor = prim::GetAttr[name="weight"](%1131)
  %1140 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.42, %1139), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%1140, %1138, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1142 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20247.NoNorm = prim::GetAttr[name="LayerNorm"](%1129)
  %1143 : __torch__.torch.nn.modules.linear.___torch_mangle_20246.Linear = prim::GetAttr[name="dense"](%1129)
  %1144 : Tensor = prim::GetAttr[name="bias"](%1143)
  %1145 : Tensor = prim::GetAttr[name="weight"](%1143)
  %1146 : Float(512:1, 128:512) = aten::t(%1145), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.78 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.78, %1144, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1149 : Tensor = prim::GetAttr[name="bias"](%1142)
  %1150 : Tensor = prim::GetAttr[name="weight"](%1142)
  %1151 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.43, %1150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.103 : Float(17:1664, 13:128, 128:1) = aten::add(%1151, %1149, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1153 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.103, %residual_tensor.6)
  %1154 : Float(17:1664, 13:128, 128:1), %1155 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1153)
  %1156 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20232.MobileBertSelfOutput = prim::GetAttr[name="output"](%1127)
  %1157 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20229.MobileBertSelfAttention = prim::GetAttr[name="self"](%1127)
  %1158 : __torch__.torch.nn.modules.linear.___torch_mangle_20227.Linear = prim::GetAttr[name="value"](%1157)
  %1159 : __torch__.torch.nn.modules.linear.___torch_mangle_20226.Linear = prim::GetAttr[name="key"](%1157)
  %1160 : __torch__.torch.nn.modules.linear.___torch_mangle_20225.Linear = prim::GetAttr[name="query"](%1157)
  %1161 : Tensor = prim::GetAttr[name="bias"](%1160)
  %1162 : Tensor = prim::GetAttr[name="weight"](%1160)
  %1163 : Float(128:1, 128:128) = aten::t(%1162), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %output.79 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1154, %1163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %x.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.79, %1161, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1678:0
  %1166 : Tensor = prim::GetAttr[name="bias"](%1159)
  %1167 : Tensor = prim::GetAttr[name="weight"](%1159)
  %1168 : Float(128:1, 128:128) = aten::t(%1167), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %output.80 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1154, %1168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %x.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.80, %1166, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1678:0
  %1171 : Tensor = prim::GetAttr[name="bias"](%1158)
  %1172 : Tensor = prim::GetAttr[name="weight"](%1158)
  %1173 : Float(512:1, 128:512) = aten::t(%1172), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %output.81 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1173), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %x.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.81, %1171, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1678:0
  %1176 : int = aten::size(%x.31, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1177 : int = aten::size(%x.31, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1178 : int[] = prim::ListConstruct(%1176, %1177, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.31, %1178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1180 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %query_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.32, %1180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1182 : int = aten::size(%x.33, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1183 : int = aten::size(%x.33, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1184 : int[] = prim::ListConstruct(%1182, %1183, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.33, %1184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1186 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %key_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.34, %1186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1188 : int = aten::size(%x.35, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1189 : int = aten::size(%x.35, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1190 : int[] = prim::ListConstruct(%1188, %1189, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.35, %1190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1192 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %value_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.36, %1192), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1194 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.6, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.6, %1194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.11, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.104 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.12, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.105 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.104, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.105, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.11 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.6, %value_layer.6), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:280:0
  %1201 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %1202 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.11, %1201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1202, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %1204 : int = aten::size(%context_layer.12, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1205 : int = aten::size(%context_layer.12, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1206 : int[] = prim::ListConstruct(%1204, %1205, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %input.106 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.12, %1206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:283:0
  %1208 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20231.NoNorm = prim::GetAttr[name="LayerNorm"](%1156)
  %1209 : __torch__.torch.nn.modules.linear.___torch_mangle_20230.Linear = prim::GetAttr[name="dense"](%1156)
  %1210 : Tensor = prim::GetAttr[name="bias"](%1209)
  %1211 : Tensor = prim::GetAttr[name="weight"](%1209)
  %1212 : Float(128:1, 128:128) = aten::t(%1211), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %output.82 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.106, %1212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.82, %1210, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.44 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.26, %1155, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output # transformers/modeling_mobilebert.py:301:0
  %1216 : Tensor = prim::GetAttr[name="bias"](%1208)
  %1217 : Tensor = prim::GetAttr[name="weight"](%1208)
  %1218 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.44, %1217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.107 : Float(17:1664, 13:128, 128:1) = aten::add(%1218, %1216, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1220 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20254.FFNOutput = prim::GetAttr[name="output"](%1126)
  %1221 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20251.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1126)
  %1222 : __torch__.torch.nn.modules.linear.___torch_mangle_20250.Linear = prim::GetAttr[name="dense"](%1221)
  %1223 : Tensor = prim::GetAttr[name="bias"](%1222)
  %1224 : Tensor = prim::GetAttr[name="weight"](%1222)
  %1225 : Float(128:1, 512:128) = aten::t(%1224), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.83 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.107, %1225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.108 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.83, %1223, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.109 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1229 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20253.NoNorm = prim::GetAttr[name="LayerNorm"](%1220)
  %1230 : __torch__.torch.nn.modules.linear.___torch_mangle_20252.Linear = prim::GetAttr[name="dense"](%1220)
  %1231 : Tensor = prim::GetAttr[name="bias"](%1230)
  %1232 : Tensor = prim::GetAttr[name="weight"](%1230)
  %1233 : Float(512:1, 128:512) = aten::t(%1232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.84 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.109, %1233), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.84, %1231, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.45 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.27, %input.107, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1237 : Tensor = prim::GetAttr[name="bias"](%1229)
  %1238 : Tensor = prim::GetAttr[name="weight"](%1229)
  %1239 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.45, %1238), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.110 : Float(17:1664, 13:128, 128:1) = aten::add(%1239, %1237, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1241 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20260.FFNOutput = prim::GetAttr[name="output"](%1124)
  %1242 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20257.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1124)
  %1243 : __torch__.torch.nn.modules.linear.___torch_mangle_20256.Linear = prim::GetAttr[name="dense"](%1242)
  %1244 : Tensor = prim::GetAttr[name="bias"](%1243)
  %1245 : Tensor = prim::GetAttr[name="weight"](%1243)
  %1246 : Float(128:1, 512:128) = aten::t(%1245), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.85 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.110, %1246), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.111 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.85, %1244, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.112 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1250 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20259.NoNorm = prim::GetAttr[name="LayerNorm"](%1241)
  %1251 : __torch__.torch.nn.modules.linear.___torch_mangle_20258.Linear = prim::GetAttr[name="dense"](%1241)
  %1252 : Tensor = prim::GetAttr[name="bias"](%1251)
  %1253 : Tensor = prim::GetAttr[name="weight"](%1251)
  %1254 : Float(512:1, 128:512) = aten::t(%1253), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.86 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.112, %1254), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.28 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.86, %1252, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.46 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.28, %input.110, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1258 : Tensor = prim::GetAttr[name="bias"](%1250)
  %1259 : Tensor = prim::GetAttr[name="weight"](%1250)
  %1260 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.46, %1259), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.113 : Float(17:1664, 13:128, 128:1) = aten::add(%1260, %1258, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1262 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20266.FFNOutput = prim::GetAttr[name="output"](%1122)
  %1263 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20263.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1122)
  %1264 : __torch__.torch.nn.modules.linear.___torch_mangle_20262.Linear = prim::GetAttr[name="dense"](%1263)
  %1265 : Tensor = prim::GetAttr[name="bias"](%1264)
  %1266 : Tensor = prim::GetAttr[name="weight"](%1264)
  %1267 : Float(128:1, 512:128) = aten::t(%1266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.87 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.113, %1267), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.114 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.87, %1265, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.115 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.114), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1271 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20265.NoNorm = prim::GetAttr[name="LayerNorm"](%1262)
  %1272 : __torch__.torch.nn.modules.linear.___torch_mangle_20264.Linear = prim::GetAttr[name="dense"](%1262)
  %1273 : Tensor = prim::GetAttr[name="bias"](%1272)
  %1274 : Tensor = prim::GetAttr[name="weight"](%1272)
  %1275 : Float(512:1, 128:512) = aten::t(%1274), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.88 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.115, %1275), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.88, %1273, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.47 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.29, %input.113, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1279 : Tensor = prim::GetAttr[name="bias"](%1271)
  %1280 : Tensor = prim::GetAttr[name="weight"](%1271)
  %1281 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.47, %1280), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.116 : Float(17:1664, 13:128, 128:1) = aten::add(%1281, %1279, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1283 : __torch__.torch.nn.modules.linear.___torch_mangle_20234.Linear = prim::GetAttr[name="dense"](%1120)
  %1284 : Tensor = prim::GetAttr[name="bias"](%1283)
  %1285 : Tensor = prim::GetAttr[name="weight"](%1283)
  %1286 : Float(128:1, 512:128) = aten::t(%1285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %output.89 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.116, %1286), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %input.117 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.89, %1284, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1678:0
  %input.118 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.117), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate # torch/nn/functional.py:1119:0
  %1290 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20241.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1119)
  %1291 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20237.NoNorm = prim::GetAttr[name="LayerNorm"](%1119)
  %1292 : __torch__.torch.nn.modules.linear.___torch_mangle_20236.Linear = prim::GetAttr[name="dense"](%1119)
  %1293 : Tensor = prim::GetAttr[name="bias"](%1292)
  %1294 : Tensor = prim::GetAttr[name="weight"](%1292)
  %1295 : Float(512:1, 128:512) = aten::t(%1294), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %output.90 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.118, %1295), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %layer_output.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.90, %1293, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.48 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.6, %input.116, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output # transformers/modeling_mobilebert.py:405:0
  %1299 : Tensor = prim::GetAttr[name="bias"](%1291)
  %1300 : Tensor = prim::GetAttr[name="weight"](%1291)
  %1301 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.48, %1300), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.119 : Float(17:1664, 13:128, 128:1) = aten::add(%1301, %1299, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1303 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20239.NoNorm = prim::GetAttr[name="LayerNorm"](%1290)
  %1304 : __torch__.torch.nn.modules.linear.___torch_mangle_20238.Linear = prim::GetAttr[name="dense"](%1290)
  %1305 : Tensor = prim::GetAttr[name="bias"](%1304)
  %1306 : Tensor = prim::GetAttr[name="weight"](%1304)
  %1307 : Float(128:1, 512:128) = aten::t(%1306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.91 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.119, %1307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.120 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.91, %1305, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.30 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.120, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.49 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.30, %input.102, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1312 : Tensor = prim::GetAttr[name="bias"](%1303)
  %1313 : Tensor = prim::GetAttr[name="weight"](%1303)
  %1314 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.49, %1313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.121 : Float(17:6656, 13:512, 512:1) = aten::add(%1314, %1312, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1316 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20287.MobileBertOutput = prim::GetAttr[name="output"](%121)
  %1317 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20280.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%121)
  %1318 : __torch__.torch.nn.modules.container.___torch_mangle_20313.ModuleList = prim::GetAttr[name="ffn"](%121)
  %1319 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20312.FFNLayer = prim::GetAttr[name="2"](%1318)
  %1320 : __torch__.torch.nn.modules.container.___torch_mangle_20313.ModuleList = prim::GetAttr[name="ffn"](%121)
  %1321 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20306.FFNLayer = prim::GetAttr[name="1"](%1320)
  %1322 : __torch__.torch.nn.modules.container.___torch_mangle_20313.ModuleList = prim::GetAttr[name="ffn"](%121)
  %1323 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20300.FFNLayer = prim::GetAttr[name="0"](%1322)
  %1324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20278.MobileBertAttention = prim::GetAttr[name="attention"](%121)
  %1325 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20294.Bottleneck = prim::GetAttr[name="bottleneck"](%121)
  %1326 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20293.BottleneckLayer = prim::GetAttr[name="attention"](%1325)
  %1327 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20290.BottleneckLayer = prim::GetAttr[name="input"](%1325)
  %1328 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20289.NoNorm = prim::GetAttr[name="LayerNorm"](%1327)
  %1329 : __torch__.torch.nn.modules.linear.___torch_mangle_20288.Linear = prim::GetAttr[name="dense"](%1327)
  %1330 : Tensor = prim::GetAttr[name="bias"](%1329)
  %1331 : Tensor = prim::GetAttr[name="weight"](%1329)
  %1332 : Float(512:1, 128:512) = aten::t(%1331), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.92 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1332), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.50 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.92, %1330, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1335 : Tensor = prim::GetAttr[name="bias"](%1328)
  %1336 : Tensor = prim::GetAttr[name="weight"](%1328)
  %1337 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.50, %1336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%1337, %1335, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1339 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20292.NoNorm = prim::GetAttr[name="LayerNorm"](%1326)
  %1340 : __torch__.torch.nn.modules.linear.___torch_mangle_20291.Linear = prim::GetAttr[name="dense"](%1326)
  %1341 : Tensor = prim::GetAttr[name="bias"](%1340)
  %1342 : Tensor = prim::GetAttr[name="weight"](%1340)
  %1343 : Float(512:1, 128:512) = aten::t(%1342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.93 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1343), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.93, %1341, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1346 : Tensor = prim::GetAttr[name="bias"](%1339)
  %1347 : Tensor = prim::GetAttr[name="weight"](%1339)
  %1348 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.51, %1347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.122 : Float(17:1664, 13:128, 128:1) = aten::add(%1348, %1346, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1350 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.122, %residual_tensor.7)
  %1351 : Float(17:1664, 13:128, 128:1), %1352 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1350)
  %1353 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20277.MobileBertSelfOutput = prim::GetAttr[name="output"](%1324)
  %1354 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20274.MobileBertSelfAttention = prim::GetAttr[name="self"](%1324)
  %1355 : __torch__.torch.nn.modules.linear.___torch_mangle_20272.Linear = prim::GetAttr[name="value"](%1354)
  %1356 : __torch__.torch.nn.modules.linear.___torch_mangle_20271.Linear = prim::GetAttr[name="key"](%1354)
  %1357 : __torch__.torch.nn.modules.linear.___torch_mangle_20270.Linear = prim::GetAttr[name="query"](%1354)
  %1358 : Tensor = prim::GetAttr[name="bias"](%1357)
  %1359 : Tensor = prim::GetAttr[name="weight"](%1357)
  %1360 : Float(128:1, 128:128) = aten::t(%1359), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %output.94 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1351, %1360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %x.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.94, %1358, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1678:0
  %1363 : Tensor = prim::GetAttr[name="bias"](%1356)
  %1364 : Tensor = prim::GetAttr[name="weight"](%1356)
  %1365 : Float(128:1, 128:128) = aten::t(%1364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %output.95 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1351, %1365), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %x.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.95, %1363, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1678:0
  %1368 : Tensor = prim::GetAttr[name="bias"](%1355)
  %1369 : Tensor = prim::GetAttr[name="weight"](%1355)
  %1370 : Float(512:1, 128:512) = aten::t(%1369), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %output.96 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1370), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %x.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.96, %1368, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1678:0
  %1373 : int = aten::size(%x.37, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1374 : int = aten::size(%x.37, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1375 : int[] = prim::ListConstruct(%1373, %1374, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.37, %1375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1377 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %query_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.38, %1377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1379 : int = aten::size(%x.39, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1380 : int = aten::size(%x.39, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1381 : int[] = prim::ListConstruct(%1379, %1380, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.39, %1381), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1383 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %key_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.40, %1383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1385 : int = aten::size(%x.41, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1386 : int = aten::size(%x.41, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1387 : int[] = prim::ListConstruct(%1385, %1386, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.41, %1387), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1389 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %value_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.42, %1389), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1391 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.7, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.7, %1391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.13, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.123 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.14, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.124 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.123, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.124, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.13 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.7, %value_layer.7), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:280:0
  %1398 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %1399 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.13, %1398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1399, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %1401 : int = aten::size(%context_layer.14, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1402 : int = aten::size(%context_layer.14, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1403 : int[] = prim::ListConstruct(%1401, %1402, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %input.125 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.14, %1403), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:283:0
  %1405 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20276.NoNorm = prim::GetAttr[name="LayerNorm"](%1353)
  %1406 : __torch__.torch.nn.modules.linear.___torch_mangle_20275.Linear = prim::GetAttr[name="dense"](%1353)
  %1407 : Tensor = prim::GetAttr[name="bias"](%1406)
  %1408 : Tensor = prim::GetAttr[name="weight"](%1406)
  %1409 : Float(128:1, 128:128) = aten::t(%1408), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %output.97 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.125, %1409), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.97, %1407, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.52 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.31, %1352, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output # transformers/modeling_mobilebert.py:301:0
  %1413 : Tensor = prim::GetAttr[name="bias"](%1405)
  %1414 : Tensor = prim::GetAttr[name="weight"](%1405)
  %1415 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.52, %1414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.126 : Float(17:1664, 13:128, 128:1) = aten::add(%1415, %1413, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1417 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20299.FFNOutput = prim::GetAttr[name="output"](%1323)
  %1418 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20296.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1323)
  %1419 : __torch__.torch.nn.modules.linear.___torch_mangle_20295.Linear = prim::GetAttr[name="dense"](%1418)
  %1420 : Tensor = prim::GetAttr[name="bias"](%1419)
  %1421 : Tensor = prim::GetAttr[name="weight"](%1419)
  %1422 : Float(128:1, 512:128) = aten::t(%1421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.98 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.126, %1422), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.127 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.98, %1420, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.128 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1426 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20298.NoNorm = prim::GetAttr[name="LayerNorm"](%1417)
  %1427 : __torch__.torch.nn.modules.linear.___torch_mangle_20297.Linear = prim::GetAttr[name="dense"](%1417)
  %1428 : Tensor = prim::GetAttr[name="bias"](%1427)
  %1429 : Tensor = prim::GetAttr[name="weight"](%1427)
  %1430 : Float(512:1, 128:512) = aten::t(%1429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.99 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.128, %1430), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.32 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.99, %1428, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.53 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.32, %input.126, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1434 : Tensor = prim::GetAttr[name="bias"](%1426)
  %1435 : Tensor = prim::GetAttr[name="weight"](%1426)
  %1436 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.53, %1435), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.129 : Float(17:1664, 13:128, 128:1) = aten::add(%1436, %1434, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1438 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20305.FFNOutput = prim::GetAttr[name="output"](%1321)
  %1439 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20302.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1321)
  %1440 : __torch__.torch.nn.modules.linear.___torch_mangle_20301.Linear = prim::GetAttr[name="dense"](%1439)
  %1441 : Tensor = prim::GetAttr[name="bias"](%1440)
  %1442 : Tensor = prim::GetAttr[name="weight"](%1440)
  %1443 : Float(128:1, 512:128) = aten::t(%1442), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.100 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.129, %1443), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.130 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.100, %1441, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.131 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1447 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20304.NoNorm = prim::GetAttr[name="LayerNorm"](%1438)
  %1448 : __torch__.torch.nn.modules.linear.___torch_mangle_20303.Linear = prim::GetAttr[name="dense"](%1438)
  %1449 : Tensor = prim::GetAttr[name="bias"](%1448)
  %1450 : Tensor = prim::GetAttr[name="weight"](%1448)
  %1451 : Float(512:1, 128:512) = aten::t(%1450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.101 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.131, %1451), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.101, %1449, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.54 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.33, %input.129, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1455 : Tensor = prim::GetAttr[name="bias"](%1447)
  %1456 : Tensor = prim::GetAttr[name="weight"](%1447)
  %1457 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.54, %1456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.132 : Float(17:1664, 13:128, 128:1) = aten::add(%1457, %1455, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1459 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20311.FFNOutput = prim::GetAttr[name="output"](%1319)
  %1460 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20308.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1319)
  %1461 : __torch__.torch.nn.modules.linear.___torch_mangle_20307.Linear = prim::GetAttr[name="dense"](%1460)
  %1462 : Tensor = prim::GetAttr[name="bias"](%1461)
  %1463 : Tensor = prim::GetAttr[name="weight"](%1461)
  %1464 : Float(128:1, 512:128) = aten::t(%1463), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.102 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.132, %1464), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.133 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.102, %1462, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.134 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1468 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20310.NoNorm = prim::GetAttr[name="LayerNorm"](%1459)
  %1469 : __torch__.torch.nn.modules.linear.___torch_mangle_20309.Linear = prim::GetAttr[name="dense"](%1459)
  %1470 : Tensor = prim::GetAttr[name="bias"](%1469)
  %1471 : Tensor = prim::GetAttr[name="weight"](%1469)
  %1472 : Float(512:1, 128:512) = aten::t(%1471), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.103 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.134, %1472), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.103, %1470, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.55 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.34, %input.132, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1476 : Tensor = prim::GetAttr[name="bias"](%1468)
  %1477 : Tensor = prim::GetAttr[name="weight"](%1468)
  %1478 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.55, %1477), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.135 : Float(17:1664, 13:128, 128:1) = aten::add(%1478, %1476, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1480 : __torch__.torch.nn.modules.linear.___torch_mangle_20279.Linear = prim::GetAttr[name="dense"](%1317)
  %1481 : Tensor = prim::GetAttr[name="bias"](%1480)
  %1482 : Tensor = prim::GetAttr[name="weight"](%1480)
  %1483 : Float(128:1, 512:128) = aten::t(%1482), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %output.104 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.135, %1483), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %input.136 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.104, %1481, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1678:0
  %input.137 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.136), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate # torch/nn/functional.py:1119:0
  %1487 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20286.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1316)
  %1488 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20282.NoNorm = prim::GetAttr[name="LayerNorm"](%1316)
  %1489 : __torch__.torch.nn.modules.linear.___torch_mangle_20281.Linear = prim::GetAttr[name="dense"](%1316)
  %1490 : Tensor = prim::GetAttr[name="bias"](%1489)
  %1491 : Tensor = prim::GetAttr[name="weight"](%1489)
  %1492 : Float(512:1, 128:512) = aten::t(%1491), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %output.105 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.137, %1492), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %layer_output.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.105, %1490, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.56 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.7, %input.135, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output # transformers/modeling_mobilebert.py:405:0
  %1496 : Tensor = prim::GetAttr[name="bias"](%1488)
  %1497 : Tensor = prim::GetAttr[name="weight"](%1488)
  %1498 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.56, %1497), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.138 : Float(17:1664, 13:128, 128:1) = aten::add(%1498, %1496, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1500 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20284.NoNorm = prim::GetAttr[name="LayerNorm"](%1487)
  %1501 : __torch__.torch.nn.modules.linear.___torch_mangle_20283.Linear = prim::GetAttr[name="dense"](%1487)
  %1502 : Tensor = prim::GetAttr[name="bias"](%1501)
  %1503 : Tensor = prim::GetAttr[name="weight"](%1501)
  %1504 : Float(128:1, 512:128) = aten::t(%1503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.106 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.138, %1504), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.139 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.106, %1502, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.35 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.139, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.57 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.35, %input.121, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1509 : Tensor = prim::GetAttr[name="bias"](%1500)
  %1510 : Tensor = prim::GetAttr[name="weight"](%1500)
  %1511 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.57, %1510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.140 : Float(17:6656, 13:512, 512:1) = aten::add(%1511, %1509, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1513 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20332.MobileBertOutput = prim::GetAttr[name="output"](%119)
  %1514 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20325.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%119)
  %1515 : __torch__.torch.nn.modules.container.___torch_mangle_20358.ModuleList = prim::GetAttr[name="ffn"](%119)
  %1516 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20357.FFNLayer = prim::GetAttr[name="2"](%1515)
  %1517 : __torch__.torch.nn.modules.container.___torch_mangle_20358.ModuleList = prim::GetAttr[name="ffn"](%119)
  %1518 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20351.FFNLayer = prim::GetAttr[name="1"](%1517)
  %1519 : __torch__.torch.nn.modules.container.___torch_mangle_20358.ModuleList = prim::GetAttr[name="ffn"](%119)
  %1520 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20345.FFNLayer = prim::GetAttr[name="0"](%1519)
  %1521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20323.MobileBertAttention = prim::GetAttr[name="attention"](%119)
  %1522 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20339.Bottleneck = prim::GetAttr[name="bottleneck"](%119)
  %1523 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20338.BottleneckLayer = prim::GetAttr[name="attention"](%1522)
  %1524 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20335.BottleneckLayer = prim::GetAttr[name="input"](%1522)
  %1525 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20334.NoNorm = prim::GetAttr[name="LayerNorm"](%1524)
  %1526 : __torch__.torch.nn.modules.linear.___torch_mangle_20333.Linear = prim::GetAttr[name="dense"](%1524)
  %1527 : Tensor = prim::GetAttr[name="bias"](%1526)
  %1528 : Tensor = prim::GetAttr[name="weight"](%1526)
  %1529 : Float(512:1, 128:512) = aten::t(%1528), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.107 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1529), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.107, %1527, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1532 : Tensor = prim::GetAttr[name="bias"](%1525)
  %1533 : Tensor = prim::GetAttr[name="weight"](%1525)
  %1534 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.58, %1533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%1534, %1532, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1536 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20337.NoNorm = prim::GetAttr[name="LayerNorm"](%1523)
  %1537 : __torch__.torch.nn.modules.linear.___torch_mangle_20336.Linear = prim::GetAttr[name="dense"](%1523)
  %1538 : Tensor = prim::GetAttr[name="bias"](%1537)
  %1539 : Tensor = prim::GetAttr[name="weight"](%1537)
  %1540 : Float(512:1, 128:512) = aten::t(%1539), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.108 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1540), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.108, %1538, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1543 : Tensor = prim::GetAttr[name="bias"](%1536)
  %1544 : Tensor = prim::GetAttr[name="weight"](%1536)
  %1545 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.59, %1544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.141 : Float(17:1664, 13:128, 128:1) = aten::add(%1545, %1543, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1547 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.141, %residual_tensor.8)
  %1548 : Float(17:1664, 13:128, 128:1), %1549 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1547)
  %1550 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20322.MobileBertSelfOutput = prim::GetAttr[name="output"](%1521)
  %1551 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20319.MobileBertSelfAttention = prim::GetAttr[name="self"](%1521)
  %1552 : __torch__.torch.nn.modules.linear.___torch_mangle_20317.Linear = prim::GetAttr[name="value"](%1551)
  %1553 : __torch__.torch.nn.modules.linear.___torch_mangle_20316.Linear = prim::GetAttr[name="key"](%1551)
  %1554 : __torch__.torch.nn.modules.linear.___torch_mangle_20315.Linear = prim::GetAttr[name="query"](%1551)
  %1555 : Tensor = prim::GetAttr[name="bias"](%1554)
  %1556 : Tensor = prim::GetAttr[name="weight"](%1554)
  %1557 : Float(128:1, 128:128) = aten::t(%1556), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %output.109 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1548, %1557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %x.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.109, %1555, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1678:0
  %1560 : Tensor = prim::GetAttr[name="bias"](%1553)
  %1561 : Tensor = prim::GetAttr[name="weight"](%1553)
  %1562 : Float(128:1, 128:128) = aten::t(%1561), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %output.110 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1548, %1562), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %x.45 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.110, %1560, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1678:0
  %1565 : Tensor = prim::GetAttr[name="bias"](%1552)
  %1566 : Tensor = prim::GetAttr[name="weight"](%1552)
  %1567 : Float(512:1, 128:512) = aten::t(%1566), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %output.111 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1567), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %x.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.111, %1565, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1678:0
  %1570 : int = aten::size(%x.43, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1571 : int = aten::size(%x.43, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1572 : int[] = prim::ListConstruct(%1570, %1571, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.43, %1572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1574 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %query_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.44, %1574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1576 : int = aten::size(%x.45, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1577 : int = aten::size(%x.45, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1578 : int[] = prim::ListConstruct(%1576, %1577, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.45, %1578), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1580 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %key_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.46, %1580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1582 : int = aten::size(%x.47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1583 : int = aten::size(%x.47, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1584 : int[] = prim::ListConstruct(%1582, %1583, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.48 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.47, %1584), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1586 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %value_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.48, %1586), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1588 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.8, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.8, %1588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.142 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.16, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.143 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.142, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.143, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.15 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.8, %value_layer.8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:280:0
  %1595 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %1596 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.15, %1595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1596, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %1598 : int = aten::size(%context_layer.16, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1599 : int = aten::size(%context_layer.16, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1600 : int[] = prim::ListConstruct(%1598, %1599, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %input.144 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.16, %1600), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:283:0
  %1602 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20321.NoNorm = prim::GetAttr[name="LayerNorm"](%1550)
  %1603 : __torch__.torch.nn.modules.linear.___torch_mangle_20320.Linear = prim::GetAttr[name="dense"](%1550)
  %1604 : Tensor = prim::GetAttr[name="bias"](%1603)
  %1605 : Tensor = prim::GetAttr[name="weight"](%1603)
  %1606 : Float(128:1, 128:128) = aten::t(%1605), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %output.112 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.144, %1606), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.36 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.112, %1604, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.60 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.36, %1549, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output # transformers/modeling_mobilebert.py:301:0
  %1610 : Tensor = prim::GetAttr[name="bias"](%1602)
  %1611 : Tensor = prim::GetAttr[name="weight"](%1602)
  %1612 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.60, %1611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.145 : Float(17:1664, 13:128, 128:1) = aten::add(%1612, %1610, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1614 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20344.FFNOutput = prim::GetAttr[name="output"](%1520)
  %1615 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20341.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1520)
  %1616 : __torch__.torch.nn.modules.linear.___torch_mangle_20340.Linear = prim::GetAttr[name="dense"](%1615)
  %1617 : Tensor = prim::GetAttr[name="bias"](%1616)
  %1618 : Tensor = prim::GetAttr[name="weight"](%1616)
  %1619 : Float(128:1, 512:128) = aten::t(%1618), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.113 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.145, %1619), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.146 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.113, %1617, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.147 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1623 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20343.NoNorm = prim::GetAttr[name="LayerNorm"](%1614)
  %1624 : __torch__.torch.nn.modules.linear.___torch_mangle_20342.Linear = prim::GetAttr[name="dense"](%1614)
  %1625 : Tensor = prim::GetAttr[name="bias"](%1624)
  %1626 : Tensor = prim::GetAttr[name="weight"](%1624)
  %1627 : Float(512:1, 128:512) = aten::t(%1626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.114 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.147, %1627), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.114, %1625, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.61 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.37, %input.145, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1631 : Tensor = prim::GetAttr[name="bias"](%1623)
  %1632 : Tensor = prim::GetAttr[name="weight"](%1623)
  %1633 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.61, %1632), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.148 : Float(17:1664, 13:128, 128:1) = aten::add(%1633, %1631, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1635 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20350.FFNOutput = prim::GetAttr[name="output"](%1518)
  %1636 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20347.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1518)
  %1637 : __torch__.torch.nn.modules.linear.___torch_mangle_20346.Linear = prim::GetAttr[name="dense"](%1636)
  %1638 : Tensor = prim::GetAttr[name="bias"](%1637)
  %1639 : Tensor = prim::GetAttr[name="weight"](%1637)
  %1640 : Float(128:1, 512:128) = aten::t(%1639), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.115 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.148, %1640), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.149 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.115, %1638, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.150 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1644 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20349.NoNorm = prim::GetAttr[name="LayerNorm"](%1635)
  %1645 : __torch__.torch.nn.modules.linear.___torch_mangle_20348.Linear = prim::GetAttr[name="dense"](%1635)
  %1646 : Tensor = prim::GetAttr[name="bias"](%1645)
  %1647 : Tensor = prim::GetAttr[name="weight"](%1645)
  %1648 : Float(512:1, 128:512) = aten::t(%1647), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.116 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.150, %1648), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.38 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.116, %1646, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.62 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.38, %input.148, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1652 : Tensor = prim::GetAttr[name="bias"](%1644)
  %1653 : Tensor = prim::GetAttr[name="weight"](%1644)
  %1654 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.62, %1653), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.151 : Float(17:1664, 13:128, 128:1) = aten::add(%1654, %1652, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1656 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20356.FFNOutput = prim::GetAttr[name="output"](%1516)
  %1657 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20353.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1516)
  %1658 : __torch__.torch.nn.modules.linear.___torch_mangle_20352.Linear = prim::GetAttr[name="dense"](%1657)
  %1659 : Tensor = prim::GetAttr[name="bias"](%1658)
  %1660 : Tensor = prim::GetAttr[name="weight"](%1658)
  %1661 : Float(128:1, 512:128) = aten::t(%1660), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.117 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.151, %1661), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.152 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.117, %1659, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.153 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1665 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20355.NoNorm = prim::GetAttr[name="LayerNorm"](%1656)
  %1666 : __torch__.torch.nn.modules.linear.___torch_mangle_20354.Linear = prim::GetAttr[name="dense"](%1656)
  %1667 : Tensor = prim::GetAttr[name="bias"](%1666)
  %1668 : Tensor = prim::GetAttr[name="weight"](%1666)
  %1669 : Float(512:1, 128:512) = aten::t(%1668), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.118 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.153, %1669), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.118, %1667, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.63 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.39, %input.151, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1673 : Tensor = prim::GetAttr[name="bias"](%1665)
  %1674 : Tensor = prim::GetAttr[name="weight"](%1665)
  %1675 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.63, %1674), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.154 : Float(17:1664, 13:128, 128:1) = aten::add(%1675, %1673, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1677 : __torch__.torch.nn.modules.linear.___torch_mangle_20324.Linear = prim::GetAttr[name="dense"](%1514)
  %1678 : Tensor = prim::GetAttr[name="bias"](%1677)
  %1679 : Tensor = prim::GetAttr[name="weight"](%1677)
  %1680 : Float(128:1, 512:128) = aten::t(%1679), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %output.119 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.154, %1680), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %input.155 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.119, %1678, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1678:0
  %input.156 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate # torch/nn/functional.py:1119:0
  %1684 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20331.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1513)
  %1685 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20327.NoNorm = prim::GetAttr[name="LayerNorm"](%1513)
  %1686 : __torch__.torch.nn.modules.linear.___torch_mangle_20326.Linear = prim::GetAttr[name="dense"](%1513)
  %1687 : Tensor = prim::GetAttr[name="bias"](%1686)
  %1688 : Tensor = prim::GetAttr[name="weight"](%1686)
  %1689 : Float(512:1, 128:512) = aten::t(%1688), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %output.120 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.156, %1689), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %layer_output.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.120, %1687, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.64 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.8, %input.154, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output # transformers/modeling_mobilebert.py:405:0
  %1693 : Tensor = prim::GetAttr[name="bias"](%1685)
  %1694 : Tensor = prim::GetAttr[name="weight"](%1685)
  %1695 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.64, %1694), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.157 : Float(17:1664, 13:128, 128:1) = aten::add(%1695, %1693, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1697 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20329.NoNorm = prim::GetAttr[name="LayerNorm"](%1684)
  %1698 : __torch__.torch.nn.modules.linear.___torch_mangle_20328.Linear = prim::GetAttr[name="dense"](%1684)
  %1699 : Tensor = prim::GetAttr[name="bias"](%1698)
  %1700 : Tensor = prim::GetAttr[name="weight"](%1698)
  %1701 : Float(128:1, 512:128) = aten::t(%1700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.121 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.157, %1701), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.158 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.121, %1699, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.40 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.158, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.65 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.40, %input.140, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1706 : Tensor = prim::GetAttr[name="bias"](%1697)
  %1707 : Tensor = prim::GetAttr[name="weight"](%1697)
  %1708 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.65, %1707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.159 : Float(17:6656, 13:512, 512:1) = aten::add(%1708, %1706, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1710 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20377.MobileBertOutput = prim::GetAttr[name="output"](%117)
  %1711 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20370.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%117)
  %1712 : __torch__.torch.nn.modules.container.___torch_mangle_20403.ModuleList = prim::GetAttr[name="ffn"](%117)
  %1713 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20402.FFNLayer = prim::GetAttr[name="2"](%1712)
  %1714 : __torch__.torch.nn.modules.container.___torch_mangle_20403.ModuleList = prim::GetAttr[name="ffn"](%117)
  %1715 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20396.FFNLayer = prim::GetAttr[name="1"](%1714)
  %1716 : __torch__.torch.nn.modules.container.___torch_mangle_20403.ModuleList = prim::GetAttr[name="ffn"](%117)
  %1717 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20390.FFNLayer = prim::GetAttr[name="0"](%1716)
  %1718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20368.MobileBertAttention = prim::GetAttr[name="attention"](%117)
  %1719 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20384.Bottleneck = prim::GetAttr[name="bottleneck"](%117)
  %1720 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20383.BottleneckLayer = prim::GetAttr[name="attention"](%1719)
  %1721 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20380.BottleneckLayer = prim::GetAttr[name="input"](%1719)
  %1722 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20379.NoNorm = prim::GetAttr[name="LayerNorm"](%1721)
  %1723 : __torch__.torch.nn.modules.linear.___torch_mangle_20378.Linear = prim::GetAttr[name="dense"](%1721)
  %1724 : Tensor = prim::GetAttr[name="bias"](%1723)
  %1725 : Tensor = prim::GetAttr[name="weight"](%1723)
  %1726 : Float(512:1, 128:512) = aten::t(%1725), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.122 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1726), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.122, %1724, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1729 : Tensor = prim::GetAttr[name="bias"](%1722)
  %1730 : Tensor = prim::GetAttr[name="weight"](%1722)
  %1731 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.66, %1730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.9 : Float(17:1664, 13:128, 128:1) = aten::add(%1731, %1729, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1733 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20382.NoNorm = prim::GetAttr[name="LayerNorm"](%1720)
  %1734 : __torch__.torch.nn.modules.linear.___torch_mangle_20381.Linear = prim::GetAttr[name="dense"](%1720)
  %1735 : Tensor = prim::GetAttr[name="bias"](%1734)
  %1736 : Tensor = prim::GetAttr[name="weight"](%1734)
  %1737 : Float(512:1, 128:512) = aten::t(%1736), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.123 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1737), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.123, %1735, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1740 : Tensor = prim::GetAttr[name="bias"](%1733)
  %1741 : Tensor = prim::GetAttr[name="weight"](%1733)
  %1742 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.67, %1741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.160 : Float(17:1664, 13:128, 128:1) = aten::add(%1742, %1740, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1744 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.160, %residual_tensor.9)
  %1745 : Float(17:1664, 13:128, 128:1), %1746 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1744)
  %1747 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20367.MobileBertSelfOutput = prim::GetAttr[name="output"](%1718)
  %1748 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20364.MobileBertSelfAttention = prim::GetAttr[name="self"](%1718)
  %1749 : __torch__.torch.nn.modules.linear.___torch_mangle_20362.Linear = prim::GetAttr[name="value"](%1748)
  %1750 : __torch__.torch.nn.modules.linear.___torch_mangle_20361.Linear = prim::GetAttr[name="key"](%1748)
  %1751 : __torch__.torch.nn.modules.linear.___torch_mangle_20360.Linear = prim::GetAttr[name="query"](%1748)
  %1752 : Tensor = prim::GetAttr[name="bias"](%1751)
  %1753 : Tensor = prim::GetAttr[name="weight"](%1751)
  %1754 : Float(128:1, 128:128) = aten::t(%1753), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %output.124 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1745, %1754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %x.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.124, %1752, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1678:0
  %1757 : Tensor = prim::GetAttr[name="bias"](%1750)
  %1758 : Tensor = prim::GetAttr[name="weight"](%1750)
  %1759 : Float(128:1, 128:128) = aten::t(%1758), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %output.125 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1745, %1759), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %x.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.125, %1757, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1678:0
  %1762 : Tensor = prim::GetAttr[name="bias"](%1749)
  %1763 : Tensor = prim::GetAttr[name="weight"](%1749)
  %1764 : Float(512:1, 128:512) = aten::t(%1763), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %output.126 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1764), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %x.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.126, %1762, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1678:0
  %1767 : int = aten::size(%x.49, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1768 : int = aten::size(%x.49, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1769 : int[] = prim::ListConstruct(%1767, %1768, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.50 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.49, %1769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1771 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %query_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.50, %1771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1773 : int = aten::size(%x.51, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1774 : int = aten::size(%x.51, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1775 : int[] = prim::ListConstruct(%1773, %1774, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.52 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.51, %1775), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1777 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %key_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.52, %1777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1779 : int = aten::size(%x.53, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1780 : int = aten::size(%x.53, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1781 : int[] = prim::ListConstruct(%1779, %1780, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.54 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.53, %1781), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1783 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %value_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.54, %1783), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1785 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.9, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.9, %1785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.17, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.161 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.18, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.162 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.161, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.162, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.17 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.9, %value_layer.9), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:280:0
  %1792 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %1793 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.17, %1792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1793, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %1795 : int = aten::size(%context_layer.18, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1796 : int = aten::size(%context_layer.18, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1797 : int[] = prim::ListConstruct(%1795, %1796, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %input.163 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.18, %1797), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:283:0
  %1799 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20366.NoNorm = prim::GetAttr[name="LayerNorm"](%1747)
  %1800 : __torch__.torch.nn.modules.linear.___torch_mangle_20365.Linear = prim::GetAttr[name="dense"](%1747)
  %1801 : Tensor = prim::GetAttr[name="bias"](%1800)
  %1802 : Tensor = prim::GetAttr[name="weight"](%1800)
  %1803 : Float(128:1, 128:128) = aten::t(%1802), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %output.127 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.163, %1803), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.127, %1801, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.68 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.41, %1746, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output # transformers/modeling_mobilebert.py:301:0
  %1807 : Tensor = prim::GetAttr[name="bias"](%1799)
  %1808 : Tensor = prim::GetAttr[name="weight"](%1799)
  %1809 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.68, %1808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.164 : Float(17:1664, 13:128, 128:1) = aten::add(%1809, %1807, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1811 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20389.FFNOutput = prim::GetAttr[name="output"](%1717)
  %1812 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20386.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1717)
  %1813 : __torch__.torch.nn.modules.linear.___torch_mangle_20385.Linear = prim::GetAttr[name="dense"](%1812)
  %1814 : Tensor = prim::GetAttr[name="bias"](%1813)
  %1815 : Tensor = prim::GetAttr[name="weight"](%1813)
  %1816 : Float(128:1, 512:128) = aten::t(%1815), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.128 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.164, %1816), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.165 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.128, %1814, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.166 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1820 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20388.NoNorm = prim::GetAttr[name="LayerNorm"](%1811)
  %1821 : __torch__.torch.nn.modules.linear.___torch_mangle_20387.Linear = prim::GetAttr[name="dense"](%1811)
  %1822 : Tensor = prim::GetAttr[name="bias"](%1821)
  %1823 : Tensor = prim::GetAttr[name="weight"](%1821)
  %1824 : Float(512:1, 128:512) = aten::t(%1823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.129 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.166, %1824), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.129, %1822, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.69 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.42, %input.164, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1828 : Tensor = prim::GetAttr[name="bias"](%1820)
  %1829 : Tensor = prim::GetAttr[name="weight"](%1820)
  %1830 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.69, %1829), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.167 : Float(17:1664, 13:128, 128:1) = aten::add(%1830, %1828, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1832 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20395.FFNOutput = prim::GetAttr[name="output"](%1715)
  %1833 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20392.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1715)
  %1834 : __torch__.torch.nn.modules.linear.___torch_mangle_20391.Linear = prim::GetAttr[name="dense"](%1833)
  %1835 : Tensor = prim::GetAttr[name="bias"](%1834)
  %1836 : Tensor = prim::GetAttr[name="weight"](%1834)
  %1837 : Float(128:1, 512:128) = aten::t(%1836), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.130 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.167, %1837), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.168 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.130, %1835, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.169 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1841 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20394.NoNorm = prim::GetAttr[name="LayerNorm"](%1832)
  %1842 : __torch__.torch.nn.modules.linear.___torch_mangle_20393.Linear = prim::GetAttr[name="dense"](%1832)
  %1843 : Tensor = prim::GetAttr[name="bias"](%1842)
  %1844 : Tensor = prim::GetAttr[name="weight"](%1842)
  %1845 : Float(512:1, 128:512) = aten::t(%1844), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.131 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.169, %1845), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.131, %1843, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.70 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.43, %input.167, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1849 : Tensor = prim::GetAttr[name="bias"](%1841)
  %1850 : Tensor = prim::GetAttr[name="weight"](%1841)
  %1851 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.70, %1850), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.170 : Float(17:1664, 13:128, 128:1) = aten::add(%1851, %1849, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1853 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20401.FFNOutput = prim::GetAttr[name="output"](%1713)
  %1854 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20398.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1713)
  %1855 : __torch__.torch.nn.modules.linear.___torch_mangle_20397.Linear = prim::GetAttr[name="dense"](%1854)
  %1856 : Tensor = prim::GetAttr[name="bias"](%1855)
  %1857 : Tensor = prim::GetAttr[name="weight"](%1855)
  %1858 : Float(128:1, 512:128) = aten::t(%1857), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.132 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.170, %1858), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.171 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.132, %1856, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.172 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1862 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20400.NoNorm = prim::GetAttr[name="LayerNorm"](%1853)
  %1863 : __torch__.torch.nn.modules.linear.___torch_mangle_20399.Linear = prim::GetAttr[name="dense"](%1853)
  %1864 : Tensor = prim::GetAttr[name="bias"](%1863)
  %1865 : Tensor = prim::GetAttr[name="weight"](%1863)
  %1866 : Float(512:1, 128:512) = aten::t(%1865), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.133 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.172, %1866), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.44 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.133, %1864, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.71 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.44, %input.170, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1870 : Tensor = prim::GetAttr[name="bias"](%1862)
  %1871 : Tensor = prim::GetAttr[name="weight"](%1862)
  %1872 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.71, %1871), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.173 : Float(17:1664, 13:128, 128:1) = aten::add(%1872, %1870, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1874 : __torch__.torch.nn.modules.linear.___torch_mangle_20369.Linear = prim::GetAttr[name="dense"](%1711)
  %1875 : Tensor = prim::GetAttr[name="bias"](%1874)
  %1876 : Tensor = prim::GetAttr[name="weight"](%1874)
  %1877 : Float(128:1, 512:128) = aten::t(%1876), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %output.134 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.173, %1877), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %input.174 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.134, %1875, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1678:0
  %input.175 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate # torch/nn/functional.py:1119:0
  %1881 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20376.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1710)
  %1882 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20372.NoNorm = prim::GetAttr[name="LayerNorm"](%1710)
  %1883 : __torch__.torch.nn.modules.linear.___torch_mangle_20371.Linear = prim::GetAttr[name="dense"](%1710)
  %1884 : Tensor = prim::GetAttr[name="bias"](%1883)
  %1885 : Tensor = prim::GetAttr[name="weight"](%1883)
  %1886 : Float(512:1, 128:512) = aten::t(%1885), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %output.135 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.175, %1886), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %layer_output.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.135, %1884, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.72 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.9, %input.173, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output # transformers/modeling_mobilebert.py:405:0
  %1890 : Tensor = prim::GetAttr[name="bias"](%1882)
  %1891 : Tensor = prim::GetAttr[name="weight"](%1882)
  %1892 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.72, %1891), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.176 : Float(17:1664, 13:128, 128:1) = aten::add(%1892, %1890, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1894 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20374.NoNorm = prim::GetAttr[name="LayerNorm"](%1881)
  %1895 : __torch__.torch.nn.modules.linear.___torch_mangle_20373.Linear = prim::GetAttr[name="dense"](%1881)
  %1896 : Tensor = prim::GetAttr[name="bias"](%1895)
  %1897 : Tensor = prim::GetAttr[name="weight"](%1895)
  %1898 : Float(128:1, 512:128) = aten::t(%1897), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.136 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.176, %1898), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.177 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.136, %1896, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.45 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.177, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.73 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.45, %input.159, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1903 : Tensor = prim::GetAttr[name="bias"](%1894)
  %1904 : Tensor = prim::GetAttr[name="weight"](%1894)
  %1905 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.73, %1904), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.178 : Float(17:6656, 13:512, 512:1) = aten::add(%1905, %1903, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1907 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20422.MobileBertOutput = prim::GetAttr[name="output"](%115)
  %1908 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20415.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%115)
  %1909 : __torch__.torch.nn.modules.container.___torch_mangle_20448.ModuleList = prim::GetAttr[name="ffn"](%115)
  %1910 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20447.FFNLayer = prim::GetAttr[name="2"](%1909)
  %1911 : __torch__.torch.nn.modules.container.___torch_mangle_20448.ModuleList = prim::GetAttr[name="ffn"](%115)
  %1912 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20441.FFNLayer = prim::GetAttr[name="1"](%1911)
  %1913 : __torch__.torch.nn.modules.container.___torch_mangle_20448.ModuleList = prim::GetAttr[name="ffn"](%115)
  %1914 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20435.FFNLayer = prim::GetAttr[name="0"](%1913)
  %1915 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20413.MobileBertAttention = prim::GetAttr[name="attention"](%115)
  %1916 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20429.Bottleneck = prim::GetAttr[name="bottleneck"](%115)
  %1917 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20428.BottleneckLayer = prim::GetAttr[name="attention"](%1916)
  %1918 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20425.BottleneckLayer = prim::GetAttr[name="input"](%1916)
  %1919 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20424.NoNorm = prim::GetAttr[name="LayerNorm"](%1918)
  %1920 : __torch__.torch.nn.modules.linear.___torch_mangle_20423.Linear = prim::GetAttr[name="dense"](%1918)
  %1921 : Tensor = prim::GetAttr[name="bias"](%1920)
  %1922 : Tensor = prim::GetAttr[name="weight"](%1920)
  %1923 : Float(512:1, 128:512) = aten::t(%1922), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.137 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1923), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.137, %1921, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1926 : Tensor = prim::GetAttr[name="bias"](%1919)
  %1927 : Tensor = prim::GetAttr[name="weight"](%1919)
  %1928 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.74, %1927), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add(%1928, %1926, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1930 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20427.NoNorm = prim::GetAttr[name="LayerNorm"](%1917)
  %1931 : __torch__.torch.nn.modules.linear.___torch_mangle_20426.Linear = prim::GetAttr[name="dense"](%1917)
  %1932 : Tensor = prim::GetAttr[name="bias"](%1931)
  %1933 : Tensor = prim::GetAttr[name="weight"](%1931)
  %1934 : Float(512:1, 128:512) = aten::t(%1933), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.138 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1934), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.138, %1932, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1937 : Tensor = prim::GetAttr[name="bias"](%1930)
  %1938 : Tensor = prim::GetAttr[name="weight"](%1930)
  %1939 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.75, %1938), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.179 : Float(17:1664, 13:128, 128:1) = aten::add(%1939, %1937, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1941 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.179, %residual_tensor.10)
  %1942 : Float(17:1664, 13:128, 128:1), %1943 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1941)
  %1944 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20412.MobileBertSelfOutput = prim::GetAttr[name="output"](%1915)
  %1945 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20409.MobileBertSelfAttention = prim::GetAttr[name="self"](%1915)
  %1946 : __torch__.torch.nn.modules.linear.___torch_mangle_20407.Linear = prim::GetAttr[name="value"](%1945)
  %1947 : __torch__.torch.nn.modules.linear.___torch_mangle_20406.Linear = prim::GetAttr[name="key"](%1945)
  %1948 : __torch__.torch.nn.modules.linear.___torch_mangle_20405.Linear = prim::GetAttr[name="query"](%1945)
  %1949 : Tensor = prim::GetAttr[name="bias"](%1948)
  %1950 : Tensor = prim::GetAttr[name="weight"](%1948)
  %1951 : Float(128:1, 128:128) = aten::t(%1950), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %output.139 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1942, %1951), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %x.55 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.139, %1949, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1678:0
  %1954 : Tensor = prim::GetAttr[name="bias"](%1947)
  %1955 : Tensor = prim::GetAttr[name="weight"](%1947)
  %1956 : Float(128:1, 128:128) = aten::t(%1955), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %output.140 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1942, %1956), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %x.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.140, %1954, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1678:0
  %1959 : Tensor = prim::GetAttr[name="bias"](%1946)
  %1960 : Tensor = prim::GetAttr[name="weight"](%1946)
  %1961 : Float(512:1, 128:512) = aten::t(%1960), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %output.141 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1961), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %x.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.141, %1959, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1678:0
  %1964 : int = aten::size(%x.55, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1965 : int = aten::size(%x.55, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1966 : int[] = prim::ListConstruct(%1964, %1965, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.56 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.55, %1966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1968 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %query_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.56, %1968), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1970 : int = aten::size(%x.57, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1971 : int = aten::size(%x.57, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1972 : int[] = prim::ListConstruct(%1970, %1971, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.58 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.57, %1972), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1974 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %key_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.58, %1974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1976 : int = aten::size(%x.59, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1977 : int = aten::size(%x.59, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1978 : int[] = prim::ListConstruct(%1976, %1977, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.60 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.59, %1978), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1980 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %value_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.60, %1980), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1982 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.10, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.10, %1982), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.19, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.180 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.20, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.181 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.180, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.181, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.19 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.10, %value_layer.10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:280:0
  %1989 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %1990 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.19, %1989), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1990, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %1992 : int = aten::size(%context_layer.20, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1993 : int = aten::size(%context_layer.20, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1994 : int[] = prim::ListConstruct(%1992, %1993, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %input.182 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.20, %1994), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:283:0
  %1996 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20411.NoNorm = prim::GetAttr[name="LayerNorm"](%1944)
  %1997 : __torch__.torch.nn.modules.linear.___torch_mangle_20410.Linear = prim::GetAttr[name="dense"](%1944)
  %1998 : Tensor = prim::GetAttr[name="bias"](%1997)
  %1999 : Tensor = prim::GetAttr[name="weight"](%1997)
  %2000 : Float(128:1, 128:128) = aten::t(%1999), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %output.142 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.182, %2000), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.46 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.142, %1998, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.76 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.46, %1943, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output # transformers/modeling_mobilebert.py:301:0
  %2004 : Tensor = prim::GetAttr[name="bias"](%1996)
  %2005 : Tensor = prim::GetAttr[name="weight"](%1996)
  %2006 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.76, %2005), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.183 : Float(17:1664, 13:128, 128:1) = aten::add(%2006, %2004, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2008 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20434.FFNOutput = prim::GetAttr[name="output"](%1914)
  %2009 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20431.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1914)
  %2010 : __torch__.torch.nn.modules.linear.___torch_mangle_20430.Linear = prim::GetAttr[name="dense"](%2009)
  %2011 : Tensor = prim::GetAttr[name="bias"](%2010)
  %2012 : Tensor = prim::GetAttr[name="weight"](%2010)
  %2013 : Float(128:1, 512:128) = aten::t(%2012), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.143 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.183, %2013), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.184 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.143, %2011, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.185 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2017 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20433.NoNorm = prim::GetAttr[name="LayerNorm"](%2008)
  %2018 : __torch__.torch.nn.modules.linear.___torch_mangle_20432.Linear = prim::GetAttr[name="dense"](%2008)
  %2019 : Tensor = prim::GetAttr[name="bias"](%2018)
  %2020 : Tensor = prim::GetAttr[name="weight"](%2018)
  %2021 : Float(512:1, 128:512) = aten::t(%2020), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.144 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.185, %2021), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.144, %2019, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.77 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.47, %input.183, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2025 : Tensor = prim::GetAttr[name="bias"](%2017)
  %2026 : Tensor = prim::GetAttr[name="weight"](%2017)
  %2027 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.77, %2026), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.186 : Float(17:1664, 13:128, 128:1) = aten::add(%2027, %2025, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2029 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20440.FFNOutput = prim::GetAttr[name="output"](%1912)
  %2030 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20437.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1912)
  %2031 : __torch__.torch.nn.modules.linear.___torch_mangle_20436.Linear = prim::GetAttr[name="dense"](%2030)
  %2032 : Tensor = prim::GetAttr[name="bias"](%2031)
  %2033 : Tensor = prim::GetAttr[name="weight"](%2031)
  %2034 : Float(128:1, 512:128) = aten::t(%2033), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.145 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.186, %2034), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.187 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.145, %2032, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.188 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2038 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20439.NoNorm = prim::GetAttr[name="LayerNorm"](%2029)
  %2039 : __torch__.torch.nn.modules.linear.___torch_mangle_20438.Linear = prim::GetAttr[name="dense"](%2029)
  %2040 : Tensor = prim::GetAttr[name="bias"](%2039)
  %2041 : Tensor = prim::GetAttr[name="weight"](%2039)
  %2042 : Float(512:1, 128:512) = aten::t(%2041), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.146 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.188, %2042), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.48 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.146, %2040, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.78 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.48, %input.186, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2046 : Tensor = prim::GetAttr[name="bias"](%2038)
  %2047 : Tensor = prim::GetAttr[name="weight"](%2038)
  %2048 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.78, %2047), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.189 : Float(17:1664, 13:128, 128:1) = aten::add(%2048, %2046, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2050 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20446.FFNOutput = prim::GetAttr[name="output"](%1910)
  %2051 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20443.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1910)
  %2052 : __torch__.torch.nn.modules.linear.___torch_mangle_20442.Linear = prim::GetAttr[name="dense"](%2051)
  %2053 : Tensor = prim::GetAttr[name="bias"](%2052)
  %2054 : Tensor = prim::GetAttr[name="weight"](%2052)
  %2055 : Float(128:1, 512:128) = aten::t(%2054), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.147 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.189, %2055), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.190 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.147, %2053, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.191 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2059 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20445.NoNorm = prim::GetAttr[name="LayerNorm"](%2050)
  %2060 : __torch__.torch.nn.modules.linear.___torch_mangle_20444.Linear = prim::GetAttr[name="dense"](%2050)
  %2061 : Tensor = prim::GetAttr[name="bias"](%2060)
  %2062 : Tensor = prim::GetAttr[name="weight"](%2060)
  %2063 : Float(512:1, 128:512) = aten::t(%2062), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.148 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.191, %2063), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.148, %2061, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.79 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.49, %input.189, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2067 : Tensor = prim::GetAttr[name="bias"](%2059)
  %2068 : Tensor = prim::GetAttr[name="weight"](%2059)
  %2069 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.79, %2068), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.192 : Float(17:1664, 13:128, 128:1) = aten::add(%2069, %2067, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2071 : __torch__.torch.nn.modules.linear.___torch_mangle_20414.Linear = prim::GetAttr[name="dense"](%1908)
  %2072 : Tensor = prim::GetAttr[name="bias"](%2071)
  %2073 : Tensor = prim::GetAttr[name="weight"](%2071)
  %2074 : Float(128:1, 512:128) = aten::t(%2073), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %output.149 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.192, %2074), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %input.193 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.149, %2072, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1678:0
  %input.194 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate # torch/nn/functional.py:1119:0
  %2078 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20421.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1907)
  %2079 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20417.NoNorm = prim::GetAttr[name="LayerNorm"](%1907)
  %2080 : __torch__.torch.nn.modules.linear.___torch_mangle_20416.Linear = prim::GetAttr[name="dense"](%1907)
  %2081 : Tensor = prim::GetAttr[name="bias"](%2080)
  %2082 : Tensor = prim::GetAttr[name="weight"](%2080)
  %2083 : Float(512:1, 128:512) = aten::t(%2082), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %output.150 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.194, %2083), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %layer_output.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.150, %2081, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.80 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.10, %input.192, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output # transformers/modeling_mobilebert.py:405:0
  %2087 : Tensor = prim::GetAttr[name="bias"](%2079)
  %2088 : Tensor = prim::GetAttr[name="weight"](%2079)
  %2089 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.80, %2088), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.195 : Float(17:1664, 13:128, 128:1) = aten::add(%2089, %2087, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2091 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20419.NoNorm = prim::GetAttr[name="LayerNorm"](%2078)
  %2092 : __torch__.torch.nn.modules.linear.___torch_mangle_20418.Linear = prim::GetAttr[name="dense"](%2078)
  %2093 : Tensor = prim::GetAttr[name="bias"](%2092)
  %2094 : Tensor = prim::GetAttr[name="weight"](%2092)
  %2095 : Float(128:1, 512:128) = aten::t(%2094), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.151 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.195, %2095), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.196 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.151, %2093, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.50 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.196, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.81 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.50, %input.178, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2100 : Tensor = prim::GetAttr[name="bias"](%2091)
  %2101 : Tensor = prim::GetAttr[name="weight"](%2091)
  %2102 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.81, %2101), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.197 : Float(17:6656, 13:512, 512:1) = aten::add(%2102, %2100, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20467.MobileBertOutput = prim::GetAttr[name="output"](%113)
  %2105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20460.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%113)
  %2106 : __torch__.torch.nn.modules.container.___torch_mangle_20493.ModuleList = prim::GetAttr[name="ffn"](%113)
  %2107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20492.FFNLayer = prim::GetAttr[name="2"](%2106)
  %2108 : __torch__.torch.nn.modules.container.___torch_mangle_20493.ModuleList = prim::GetAttr[name="ffn"](%113)
  %2109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20486.FFNLayer = prim::GetAttr[name="1"](%2108)
  %2110 : __torch__.torch.nn.modules.container.___torch_mangle_20493.ModuleList = prim::GetAttr[name="ffn"](%113)
  %2111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20480.FFNLayer = prim::GetAttr[name="0"](%2110)
  %2112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20458.MobileBertAttention = prim::GetAttr[name="attention"](%113)
  %2113 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20474.Bottleneck = prim::GetAttr[name="bottleneck"](%113)
  %2114 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20473.BottleneckLayer = prim::GetAttr[name="attention"](%2113)
  %2115 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20470.BottleneckLayer = prim::GetAttr[name="input"](%2113)
  %2116 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20469.NoNorm = prim::GetAttr[name="LayerNorm"](%2115)
  %2117 : __torch__.torch.nn.modules.linear.___torch_mangle_20468.Linear = prim::GetAttr[name="dense"](%2115)
  %2118 : Tensor = prim::GetAttr[name="bias"](%2117)
  %2119 : Tensor = prim::GetAttr[name="weight"](%2117)
  %2120 : Float(512:1, 128:512) = aten::t(%2119), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.152 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2120), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.152, %2118, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2123 : Tensor = prim::GetAttr[name="bias"](%2116)
  %2124 : Tensor = prim::GetAttr[name="weight"](%2116)
  %2125 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.82, %2124), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add(%2125, %2123, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20472.NoNorm = prim::GetAttr[name="LayerNorm"](%2114)
  %2128 : __torch__.torch.nn.modules.linear.___torch_mangle_20471.Linear = prim::GetAttr[name="dense"](%2114)
  %2129 : Tensor = prim::GetAttr[name="bias"](%2128)
  %2130 : Tensor = prim::GetAttr[name="weight"](%2128)
  %2131 : Float(512:1, 128:512) = aten::t(%2130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.153 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2131), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.153, %2129, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2134 : Tensor = prim::GetAttr[name="bias"](%2127)
  %2135 : Tensor = prim::GetAttr[name="weight"](%2127)
  %2136 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.83, %2135), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.198 : Float(17:1664, 13:128, 128:1) = aten::add(%2136, %2134, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2138 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.198, %residual_tensor.11)
  %2139 : Float(17:1664, 13:128, 128:1), %2140 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2138)
  %2141 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20457.MobileBertSelfOutput = prim::GetAttr[name="output"](%2112)
  %2142 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20454.MobileBertSelfAttention = prim::GetAttr[name="self"](%2112)
  %2143 : __torch__.torch.nn.modules.linear.___torch_mangle_20452.Linear = prim::GetAttr[name="value"](%2142)
  %2144 : __torch__.torch.nn.modules.linear.___torch_mangle_20451.Linear = prim::GetAttr[name="key"](%2142)
  %2145 : __torch__.torch.nn.modules.linear.___torch_mangle_20450.Linear = prim::GetAttr[name="query"](%2142)
  %2146 : Tensor = prim::GetAttr[name="bias"](%2145)
  %2147 : Tensor = prim::GetAttr[name="weight"](%2145)
  %2148 : Float(128:1, 128:128) = aten::t(%2147), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %output.154 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2139, %2148), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %x.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.154, %2146, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1678:0
  %2151 : Tensor = prim::GetAttr[name="bias"](%2144)
  %2152 : Tensor = prim::GetAttr[name="weight"](%2144)
  %2153 : Float(128:1, 128:128) = aten::t(%2152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %output.155 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2139, %2153), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %x.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.155, %2151, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1678:0
  %2156 : Tensor = prim::GetAttr[name="bias"](%2143)
  %2157 : Tensor = prim::GetAttr[name="weight"](%2143)
  %2158 : Float(512:1, 128:512) = aten::t(%2157), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %output.156 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2158), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %x.65 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.156, %2156, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1678:0
  %2161 : int = aten::size(%x.61, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2162 : int = aten::size(%x.61, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2163 : int[] = prim::ListConstruct(%2161, %2162, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.62 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.61, %2163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2165 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %query_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.62, %2165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2167 : int = aten::size(%x.63, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2168 : int = aten::size(%x.63, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2169 : int[] = prim::ListConstruct(%2167, %2168, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.64 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.63, %2169), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2171 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %key_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.64, %2171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2173 : int = aten::size(%x.65, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2174 : int = aten::size(%x.65, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2175 : int[] = prim::ListConstruct(%2173, %2174, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.66 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.65, %2175), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2177 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %value_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.66, %2177), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2179 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.11, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.11, %2179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.21, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.199 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.22, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.200 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.199, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.200, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.21 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.11, %value_layer.11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:280:0
  %2186 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %2187 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.21, %2186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2187, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %2189 : int = aten::size(%context_layer.22, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2190 : int = aten::size(%context_layer.22, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2191 : int[] = prim::ListConstruct(%2189, %2190, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %input.201 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.22, %2191), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:283:0
  %2193 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20456.NoNorm = prim::GetAttr[name="LayerNorm"](%2141)
  %2194 : __torch__.torch.nn.modules.linear.___torch_mangle_20455.Linear = prim::GetAttr[name="dense"](%2141)
  %2195 : Tensor = prim::GetAttr[name="bias"](%2194)
  %2196 : Tensor = prim::GetAttr[name="weight"](%2194)
  %2197 : Float(128:1, 128:128) = aten::t(%2196), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %output.157 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.201, %2197), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.157, %2195, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.84 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.51, %2140, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output # transformers/modeling_mobilebert.py:301:0
  %2201 : Tensor = prim::GetAttr[name="bias"](%2193)
  %2202 : Tensor = prim::GetAttr[name="weight"](%2193)
  %2203 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.84, %2202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.202 : Float(17:1664, 13:128, 128:1) = aten::add(%2203, %2201, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2205 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20479.FFNOutput = prim::GetAttr[name="output"](%2111)
  %2206 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20476.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2111)
  %2207 : __torch__.torch.nn.modules.linear.___torch_mangle_20475.Linear = prim::GetAttr[name="dense"](%2206)
  %2208 : Tensor = prim::GetAttr[name="bias"](%2207)
  %2209 : Tensor = prim::GetAttr[name="weight"](%2207)
  %2210 : Float(128:1, 512:128) = aten::t(%2209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.158 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.202, %2210), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.203 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.158, %2208, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.204 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2214 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20478.NoNorm = prim::GetAttr[name="LayerNorm"](%2205)
  %2215 : __torch__.torch.nn.modules.linear.___torch_mangle_20477.Linear = prim::GetAttr[name="dense"](%2205)
  %2216 : Tensor = prim::GetAttr[name="bias"](%2215)
  %2217 : Tensor = prim::GetAttr[name="weight"](%2215)
  %2218 : Float(512:1, 128:512) = aten::t(%2217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.159 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.204, %2218), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.52 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.159, %2216, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.85 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.52, %input.202, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2222 : Tensor = prim::GetAttr[name="bias"](%2214)
  %2223 : Tensor = prim::GetAttr[name="weight"](%2214)
  %2224 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.85, %2223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.205 : Float(17:1664, 13:128, 128:1) = aten::add(%2224, %2222, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2226 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20485.FFNOutput = prim::GetAttr[name="output"](%2109)
  %2227 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20482.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2109)
  %2228 : __torch__.torch.nn.modules.linear.___torch_mangle_20481.Linear = prim::GetAttr[name="dense"](%2227)
  %2229 : Tensor = prim::GetAttr[name="bias"](%2228)
  %2230 : Tensor = prim::GetAttr[name="weight"](%2228)
  %2231 : Float(128:1, 512:128) = aten::t(%2230), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.160 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.205, %2231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.206 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.160, %2229, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.207 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2235 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20484.NoNorm = prim::GetAttr[name="LayerNorm"](%2226)
  %2236 : __torch__.torch.nn.modules.linear.___torch_mangle_20483.Linear = prim::GetAttr[name="dense"](%2226)
  %2237 : Tensor = prim::GetAttr[name="bias"](%2236)
  %2238 : Tensor = prim::GetAttr[name="weight"](%2236)
  %2239 : Float(512:1, 128:512) = aten::t(%2238), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.161 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.207, %2239), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.161, %2237, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.86 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.53, %input.205, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2243 : Tensor = prim::GetAttr[name="bias"](%2235)
  %2244 : Tensor = prim::GetAttr[name="weight"](%2235)
  %2245 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.86, %2244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.208 : Float(17:1664, 13:128, 128:1) = aten::add(%2245, %2243, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2247 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20491.FFNOutput = prim::GetAttr[name="output"](%2107)
  %2248 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20488.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2107)
  %2249 : __torch__.torch.nn.modules.linear.___torch_mangle_20487.Linear = prim::GetAttr[name="dense"](%2248)
  %2250 : Tensor = prim::GetAttr[name="bias"](%2249)
  %2251 : Tensor = prim::GetAttr[name="weight"](%2249)
  %2252 : Float(128:1, 512:128) = aten::t(%2251), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.162 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.208, %2252), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.209 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.162, %2250, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.210 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2256 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20490.NoNorm = prim::GetAttr[name="LayerNorm"](%2247)
  %2257 : __torch__.torch.nn.modules.linear.___torch_mangle_20489.Linear = prim::GetAttr[name="dense"](%2247)
  %2258 : Tensor = prim::GetAttr[name="bias"](%2257)
  %2259 : Tensor = prim::GetAttr[name="weight"](%2257)
  %2260 : Float(512:1, 128:512) = aten::t(%2259), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.163 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.210, %2260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.54 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.163, %2258, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.87 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.54, %input.208, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2264 : Tensor = prim::GetAttr[name="bias"](%2256)
  %2265 : Tensor = prim::GetAttr[name="weight"](%2256)
  %2266 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.87, %2265), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.211 : Float(17:1664, 13:128, 128:1) = aten::add(%2266, %2264, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2268 : __torch__.torch.nn.modules.linear.___torch_mangle_20459.Linear = prim::GetAttr[name="dense"](%2105)
  %2269 : Tensor = prim::GetAttr[name="bias"](%2268)
  %2270 : Tensor = prim::GetAttr[name="weight"](%2268)
  %2271 : Float(128:1, 512:128) = aten::t(%2270), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %output.164 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.211, %2271), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %input.212 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.164, %2269, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1678:0
  %input.213 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate # torch/nn/functional.py:1119:0
  %2275 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20466.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2104)
  %2276 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20462.NoNorm = prim::GetAttr[name="LayerNorm"](%2104)
  %2277 : __torch__.torch.nn.modules.linear.___torch_mangle_20461.Linear = prim::GetAttr[name="dense"](%2104)
  %2278 : Tensor = prim::GetAttr[name="bias"](%2277)
  %2279 : Tensor = prim::GetAttr[name="weight"](%2277)
  %2280 : Float(512:1, 128:512) = aten::t(%2279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %output.165 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.213, %2280), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %layer_output.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.165, %2278, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.88 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.11, %input.211, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output # transformers/modeling_mobilebert.py:405:0
  %2284 : Tensor = prim::GetAttr[name="bias"](%2276)
  %2285 : Tensor = prim::GetAttr[name="weight"](%2276)
  %2286 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.88, %2285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.214 : Float(17:1664, 13:128, 128:1) = aten::add(%2286, %2284, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2288 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20464.NoNorm = prim::GetAttr[name="LayerNorm"](%2275)
  %2289 : __torch__.torch.nn.modules.linear.___torch_mangle_20463.Linear = prim::GetAttr[name="dense"](%2275)
  %2290 : Tensor = prim::GetAttr[name="bias"](%2289)
  %2291 : Tensor = prim::GetAttr[name="weight"](%2289)
  %2292 : Float(128:1, 512:128) = aten::t(%2291), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.166 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.214, %2292), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.215 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.166, %2290, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.55 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.215, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.89 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.55, %input.197, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2297 : Tensor = prim::GetAttr[name="bias"](%2288)
  %2298 : Tensor = prim::GetAttr[name="weight"](%2288)
  %2299 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.89, %2298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.216 : Float(17:6656, 13:512, 512:1) = aten::add(%2299, %2297, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20512.MobileBertOutput = prim::GetAttr[name="output"](%111)
  %2302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20505.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%111)
  %2303 : __torch__.torch.nn.modules.container.___torch_mangle_20538.ModuleList = prim::GetAttr[name="ffn"](%111)
  %2304 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20537.FFNLayer = prim::GetAttr[name="2"](%2303)
  %2305 : __torch__.torch.nn.modules.container.___torch_mangle_20538.ModuleList = prim::GetAttr[name="ffn"](%111)
  %2306 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20531.FFNLayer = prim::GetAttr[name="1"](%2305)
  %2307 : __torch__.torch.nn.modules.container.___torch_mangle_20538.ModuleList = prim::GetAttr[name="ffn"](%111)
  %2308 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20525.FFNLayer = prim::GetAttr[name="0"](%2307)
  %2309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20503.MobileBertAttention = prim::GetAttr[name="attention"](%111)
  %2310 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20519.Bottleneck = prim::GetAttr[name="bottleneck"](%111)
  %2311 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20518.BottleneckLayer = prim::GetAttr[name="attention"](%2310)
  %2312 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20515.BottleneckLayer = prim::GetAttr[name="input"](%2310)
  %2313 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20514.NoNorm = prim::GetAttr[name="LayerNorm"](%2312)
  %2314 : __torch__.torch.nn.modules.linear.___torch_mangle_20513.Linear = prim::GetAttr[name="dense"](%2312)
  %2315 : Tensor = prim::GetAttr[name="bias"](%2314)
  %2316 : Tensor = prim::GetAttr[name="weight"](%2314)
  %2317 : Float(512:1, 128:512) = aten::t(%2316), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.167 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.90 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.167, %2315, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2320 : Tensor = prim::GetAttr[name="bias"](%2313)
  %2321 : Tensor = prim::GetAttr[name="weight"](%2313)
  %2322 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.90, %2321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%2322, %2320, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20517.NoNorm = prim::GetAttr[name="LayerNorm"](%2311)
  %2325 : __torch__.torch.nn.modules.linear.___torch_mangle_20516.Linear = prim::GetAttr[name="dense"](%2311)
  %2326 : Tensor = prim::GetAttr[name="bias"](%2325)
  %2327 : Tensor = prim::GetAttr[name="weight"](%2325)
  %2328 : Float(512:1, 128:512) = aten::t(%2327), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.168 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.168, %2326, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2331 : Tensor = prim::GetAttr[name="bias"](%2324)
  %2332 : Tensor = prim::GetAttr[name="weight"](%2324)
  %2333 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.91, %2332), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.217 : Float(17:1664, 13:128, 128:1) = aten::add(%2333, %2331, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2335 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.217, %residual_tensor.12)
  %2336 : Float(17:1664, 13:128, 128:1), %2337 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2335)
  %2338 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20502.MobileBertSelfOutput = prim::GetAttr[name="output"](%2309)
  %2339 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20499.MobileBertSelfAttention = prim::GetAttr[name="self"](%2309)
  %2340 : __torch__.torch.nn.modules.linear.___torch_mangle_20497.Linear = prim::GetAttr[name="value"](%2339)
  %2341 : __torch__.torch.nn.modules.linear.___torch_mangle_20496.Linear = prim::GetAttr[name="key"](%2339)
  %2342 : __torch__.torch.nn.modules.linear.___torch_mangle_20495.Linear = prim::GetAttr[name="query"](%2339)
  %2343 : Tensor = prim::GetAttr[name="bias"](%2342)
  %2344 : Tensor = prim::GetAttr[name="weight"](%2342)
  %2345 : Float(128:1, 128:128) = aten::t(%2344), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %output.169 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2336, %2345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %x.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.169, %2343, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1678:0
  %2348 : Tensor = prim::GetAttr[name="bias"](%2341)
  %2349 : Tensor = prim::GetAttr[name="weight"](%2341)
  %2350 : Float(128:1, 128:128) = aten::t(%2349), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %output.170 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2336, %2350), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %x.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.170, %2348, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1678:0
  %2353 : Tensor = prim::GetAttr[name="bias"](%2340)
  %2354 : Tensor = prim::GetAttr[name="weight"](%2340)
  %2355 : Float(512:1, 128:512) = aten::t(%2354), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %output.171 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %x.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.171, %2353, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1678:0
  %2358 : int = aten::size(%x.67, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2359 : int = aten::size(%x.67, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2360 : int[] = prim::ListConstruct(%2358, %2359, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.68 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.67, %2360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2362 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %query_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.68, %2362), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2364 : int = aten::size(%x.69, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2365 : int = aten::size(%x.69, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2366 : int[] = prim::ListConstruct(%2364, %2365, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.70 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.69, %2366), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2368 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %key_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.70, %2368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2370 : int = aten::size(%x.71, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2371 : int = aten::size(%x.71, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2372 : int[] = prim::ListConstruct(%2370, %2371, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.72 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.71, %2372), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2374 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %value_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.72, %2374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2376 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.12, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.12, %2376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.24 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.23, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.218 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.24, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.219 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.218, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.219, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.23 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.12, %value_layer.12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:280:0
  %2383 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %2384 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.23, %2383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2384, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %2386 : int = aten::size(%context_layer.24, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2387 : int = aten::size(%context_layer.24, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2388 : int[] = prim::ListConstruct(%2386, %2387, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %input.220 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.24, %2388), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:283:0
  %2390 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20501.NoNorm = prim::GetAttr[name="LayerNorm"](%2338)
  %2391 : __torch__.torch.nn.modules.linear.___torch_mangle_20500.Linear = prim::GetAttr[name="dense"](%2338)
  %2392 : Tensor = prim::GetAttr[name="bias"](%2391)
  %2393 : Tensor = prim::GetAttr[name="weight"](%2391)
  %2394 : Float(128:1, 128:128) = aten::t(%2393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %output.172 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.220, %2394), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.56 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.172, %2392, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.92 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.56, %2337, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output # transformers/modeling_mobilebert.py:301:0
  %2398 : Tensor = prim::GetAttr[name="bias"](%2390)
  %2399 : Tensor = prim::GetAttr[name="weight"](%2390)
  %2400 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.92, %2399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.221 : Float(17:1664, 13:128, 128:1) = aten::add(%2400, %2398, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2402 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20524.FFNOutput = prim::GetAttr[name="output"](%2308)
  %2403 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20521.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2308)
  %2404 : __torch__.torch.nn.modules.linear.___torch_mangle_20520.Linear = prim::GetAttr[name="dense"](%2403)
  %2405 : Tensor = prim::GetAttr[name="bias"](%2404)
  %2406 : Tensor = prim::GetAttr[name="weight"](%2404)
  %2407 : Float(128:1, 512:128) = aten::t(%2406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.173 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.221, %2407), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.222 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.173, %2405, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.223 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2411 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20523.NoNorm = prim::GetAttr[name="LayerNorm"](%2402)
  %2412 : __torch__.torch.nn.modules.linear.___torch_mangle_20522.Linear = prim::GetAttr[name="dense"](%2402)
  %2413 : Tensor = prim::GetAttr[name="bias"](%2412)
  %2414 : Tensor = prim::GetAttr[name="weight"](%2412)
  %2415 : Float(512:1, 128:512) = aten::t(%2414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.174 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.223, %2415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.174, %2413, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.93 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.57, %input.221, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2419 : Tensor = prim::GetAttr[name="bias"](%2411)
  %2420 : Tensor = prim::GetAttr[name="weight"](%2411)
  %2421 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.93, %2420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.224 : Float(17:1664, 13:128, 128:1) = aten::add(%2421, %2419, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2423 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20530.FFNOutput = prim::GetAttr[name="output"](%2306)
  %2424 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20527.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2306)
  %2425 : __torch__.torch.nn.modules.linear.___torch_mangle_20526.Linear = prim::GetAttr[name="dense"](%2424)
  %2426 : Tensor = prim::GetAttr[name="bias"](%2425)
  %2427 : Tensor = prim::GetAttr[name="weight"](%2425)
  %2428 : Float(128:1, 512:128) = aten::t(%2427), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.175 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.224, %2428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.225 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.175, %2426, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.226 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2432 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20529.NoNorm = prim::GetAttr[name="LayerNorm"](%2423)
  %2433 : __torch__.torch.nn.modules.linear.___torch_mangle_20528.Linear = prim::GetAttr[name="dense"](%2423)
  %2434 : Tensor = prim::GetAttr[name="bias"](%2433)
  %2435 : Tensor = prim::GetAttr[name="weight"](%2433)
  %2436 : Float(512:1, 128:512) = aten::t(%2435), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.176 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.226, %2436), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.176, %2434, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.94 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.58, %input.224, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2440 : Tensor = prim::GetAttr[name="bias"](%2432)
  %2441 : Tensor = prim::GetAttr[name="weight"](%2432)
  %2442 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.94, %2441), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.227 : Float(17:1664, 13:128, 128:1) = aten::add(%2442, %2440, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2444 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20536.FFNOutput = prim::GetAttr[name="output"](%2304)
  %2445 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20533.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2304)
  %2446 : __torch__.torch.nn.modules.linear.___torch_mangle_20532.Linear = prim::GetAttr[name="dense"](%2445)
  %2447 : Tensor = prim::GetAttr[name="bias"](%2446)
  %2448 : Tensor = prim::GetAttr[name="weight"](%2446)
  %2449 : Float(128:1, 512:128) = aten::t(%2448), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.177 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.227, %2449), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.228 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.177, %2447, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.229 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2453 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20535.NoNorm = prim::GetAttr[name="LayerNorm"](%2444)
  %2454 : __torch__.torch.nn.modules.linear.___torch_mangle_20534.Linear = prim::GetAttr[name="dense"](%2444)
  %2455 : Tensor = prim::GetAttr[name="bias"](%2454)
  %2456 : Tensor = prim::GetAttr[name="weight"](%2454)
  %2457 : Float(512:1, 128:512) = aten::t(%2456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.178 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.229, %2457), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.178, %2455, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.95 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.59, %input.227, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2461 : Tensor = prim::GetAttr[name="bias"](%2453)
  %2462 : Tensor = prim::GetAttr[name="weight"](%2453)
  %2463 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.95, %2462), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.230 : Float(17:1664, 13:128, 128:1) = aten::add(%2463, %2461, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2465 : __torch__.torch.nn.modules.linear.___torch_mangle_20504.Linear = prim::GetAttr[name="dense"](%2302)
  %2466 : Tensor = prim::GetAttr[name="bias"](%2465)
  %2467 : Tensor = prim::GetAttr[name="weight"](%2465)
  %2468 : Float(128:1, 512:128) = aten::t(%2467), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %output.179 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.230, %2468), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %input.231 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.179, %2466, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1678:0
  %input.232 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate # torch/nn/functional.py:1119:0
  %2472 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20511.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2301)
  %2473 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20507.NoNorm = prim::GetAttr[name="LayerNorm"](%2301)
  %2474 : __torch__.torch.nn.modules.linear.___torch_mangle_20506.Linear = prim::GetAttr[name="dense"](%2301)
  %2475 : Tensor = prim::GetAttr[name="bias"](%2474)
  %2476 : Tensor = prim::GetAttr[name="weight"](%2474)
  %2477 : Float(512:1, 128:512) = aten::t(%2476), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %output.180 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.232, %2477), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %layer_output.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.180, %2475, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.96 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.12, %input.230, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output # transformers/modeling_mobilebert.py:405:0
  %2481 : Tensor = prim::GetAttr[name="bias"](%2473)
  %2482 : Tensor = prim::GetAttr[name="weight"](%2473)
  %2483 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.96, %2482), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.233 : Float(17:1664, 13:128, 128:1) = aten::add(%2483, %2481, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2485 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20509.NoNorm = prim::GetAttr[name="LayerNorm"](%2472)
  %2486 : __torch__.torch.nn.modules.linear.___torch_mangle_20508.Linear = prim::GetAttr[name="dense"](%2472)
  %2487 : Tensor = prim::GetAttr[name="bias"](%2486)
  %2488 : Tensor = prim::GetAttr[name="weight"](%2486)
  %2489 : Float(128:1, 512:128) = aten::t(%2488), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.181 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.233, %2489), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.234 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.181, %2487, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.60 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.234, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.97 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.60, %input.216, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2494 : Tensor = prim::GetAttr[name="bias"](%2485)
  %2495 : Tensor = prim::GetAttr[name="weight"](%2485)
  %2496 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.97, %2495), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.235 : Float(17:6656, 13:512, 512:1) = aten::add(%2496, %2494, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20557.MobileBertOutput = prim::GetAttr[name="output"](%109)
  %2499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20550.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%109)
  %2500 : __torch__.torch.nn.modules.container.___torch_mangle_20583.ModuleList = prim::GetAttr[name="ffn"](%109)
  %2501 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20582.FFNLayer = prim::GetAttr[name="2"](%2500)
  %2502 : __torch__.torch.nn.modules.container.___torch_mangle_20583.ModuleList = prim::GetAttr[name="ffn"](%109)
  %2503 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20576.FFNLayer = prim::GetAttr[name="1"](%2502)
  %2504 : __torch__.torch.nn.modules.container.___torch_mangle_20583.ModuleList = prim::GetAttr[name="ffn"](%109)
  %2505 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20570.FFNLayer = prim::GetAttr[name="0"](%2504)
  %2506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20548.MobileBertAttention = prim::GetAttr[name="attention"](%109)
  %2507 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20564.Bottleneck = prim::GetAttr[name="bottleneck"](%109)
  %2508 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20563.BottleneckLayer = prim::GetAttr[name="attention"](%2507)
  %2509 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20560.BottleneckLayer = prim::GetAttr[name="input"](%2507)
  %2510 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20559.NoNorm = prim::GetAttr[name="LayerNorm"](%2509)
  %2511 : __torch__.torch.nn.modules.linear.___torch_mangle_20558.Linear = prim::GetAttr[name="dense"](%2509)
  %2512 : Tensor = prim::GetAttr[name="bias"](%2511)
  %2513 : Tensor = prim::GetAttr[name="weight"](%2511)
  %2514 : Float(512:1, 128:512) = aten::t(%2513), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.182 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2514), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.182, %2512, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2517 : Tensor = prim::GetAttr[name="bias"](%2510)
  %2518 : Tensor = prim::GetAttr[name="weight"](%2510)
  %2519 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.98, %2518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%2519, %2517, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20562.NoNorm = prim::GetAttr[name="LayerNorm"](%2508)
  %2522 : __torch__.torch.nn.modules.linear.___torch_mangle_20561.Linear = prim::GetAttr[name="dense"](%2508)
  %2523 : Tensor = prim::GetAttr[name="bias"](%2522)
  %2524 : Tensor = prim::GetAttr[name="weight"](%2522)
  %2525 : Float(512:1, 128:512) = aten::t(%2524), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.183 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.183, %2523, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2528 : Tensor = prim::GetAttr[name="bias"](%2521)
  %2529 : Tensor = prim::GetAttr[name="weight"](%2521)
  %2530 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.99, %2529), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.236 : Float(17:1664, 13:128, 128:1) = aten::add(%2530, %2528, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2532 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.236, %residual_tensor.13)
  %2533 : Float(17:1664, 13:128, 128:1), %2534 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2532)
  %2535 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20547.MobileBertSelfOutput = prim::GetAttr[name="output"](%2506)
  %2536 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20544.MobileBertSelfAttention = prim::GetAttr[name="self"](%2506)
  %2537 : __torch__.torch.nn.modules.linear.___torch_mangle_20542.Linear = prim::GetAttr[name="value"](%2536)
  %2538 : __torch__.torch.nn.modules.linear.___torch_mangle_20541.Linear = prim::GetAttr[name="key"](%2536)
  %2539 : __torch__.torch.nn.modules.linear.___torch_mangle_20540.Linear = prim::GetAttr[name="query"](%2536)
  %2540 : Tensor = prim::GetAttr[name="bias"](%2539)
  %2541 : Tensor = prim::GetAttr[name="weight"](%2539)
  %2542 : Float(128:1, 128:128) = aten::t(%2541), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %output.184 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2533, %2542), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %x.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.184, %2540, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1678:0
  %2545 : Tensor = prim::GetAttr[name="bias"](%2538)
  %2546 : Tensor = prim::GetAttr[name="weight"](%2538)
  %2547 : Float(128:1, 128:128) = aten::t(%2546), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %output.185 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2533, %2547), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %x.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.185, %2545, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1678:0
  %2550 : Tensor = prim::GetAttr[name="bias"](%2537)
  %2551 : Tensor = prim::GetAttr[name="weight"](%2537)
  %2552 : Float(512:1, 128:512) = aten::t(%2551), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %output.186 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2552), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %x.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.186, %2550, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1678:0
  %2555 : int = aten::size(%x.73, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2556 : int = aten::size(%x.73, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2557 : int[] = prim::ListConstruct(%2555, %2556, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.74 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.73, %2557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2559 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %query_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.74, %2559), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2561 : int = aten::size(%x.75, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2562 : int = aten::size(%x.75, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2563 : int[] = prim::ListConstruct(%2561, %2562, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.76 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.75, %2563), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2565 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %key_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.76, %2565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2567 : int = aten::size(%x.77, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2568 : int = aten::size(%x.77, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2569 : int[] = prim::ListConstruct(%2567, %2568, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.78 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.77, %2569), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2571 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %value_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.78, %2571), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2573 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.13, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.25 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.13, %2573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.26 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.237 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.26, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.238 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.237, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.238, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.25 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.13, %value_layer.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:280:0
  %2580 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %2581 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.25, %2580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2581, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %2583 : int = aten::size(%context_layer.26, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2584 : int = aten::size(%context_layer.26, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2585 : int[] = prim::ListConstruct(%2583, %2584, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %input.239 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.26, %2585), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:283:0
  %2587 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20546.NoNorm = prim::GetAttr[name="LayerNorm"](%2535)
  %2588 : __torch__.torch.nn.modules.linear.___torch_mangle_20545.Linear = prim::GetAttr[name="dense"](%2535)
  %2589 : Tensor = prim::GetAttr[name="bias"](%2588)
  %2590 : Tensor = prim::GetAttr[name="weight"](%2588)
  %2591 : Float(128:1, 128:128) = aten::t(%2590), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %output.187 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.239, %2591), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.187, %2589, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.100 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.61, %2534, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output # transformers/modeling_mobilebert.py:301:0
  %2595 : Tensor = prim::GetAttr[name="bias"](%2587)
  %2596 : Tensor = prim::GetAttr[name="weight"](%2587)
  %2597 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.100, %2596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.240 : Float(17:1664, 13:128, 128:1) = aten::add(%2597, %2595, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2599 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20569.FFNOutput = prim::GetAttr[name="output"](%2505)
  %2600 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20566.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2505)
  %2601 : __torch__.torch.nn.modules.linear.___torch_mangle_20565.Linear = prim::GetAttr[name="dense"](%2600)
  %2602 : Tensor = prim::GetAttr[name="bias"](%2601)
  %2603 : Tensor = prim::GetAttr[name="weight"](%2601)
  %2604 : Float(128:1, 512:128) = aten::t(%2603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.188 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.240, %2604), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.241 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.188, %2602, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.242 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2608 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20568.NoNorm = prim::GetAttr[name="LayerNorm"](%2599)
  %2609 : __torch__.torch.nn.modules.linear.___torch_mangle_20567.Linear = prim::GetAttr[name="dense"](%2599)
  %2610 : Tensor = prim::GetAttr[name="bias"](%2609)
  %2611 : Tensor = prim::GetAttr[name="weight"](%2609)
  %2612 : Float(512:1, 128:512) = aten::t(%2611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.189 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.242, %2612), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.62 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.189, %2610, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.101 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.62, %input.240, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2616 : Tensor = prim::GetAttr[name="bias"](%2608)
  %2617 : Tensor = prim::GetAttr[name="weight"](%2608)
  %2618 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.101, %2617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.243 : Float(17:1664, 13:128, 128:1) = aten::add(%2618, %2616, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2620 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20575.FFNOutput = prim::GetAttr[name="output"](%2503)
  %2621 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20572.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2503)
  %2622 : __torch__.torch.nn.modules.linear.___torch_mangle_20571.Linear = prim::GetAttr[name="dense"](%2621)
  %2623 : Tensor = prim::GetAttr[name="bias"](%2622)
  %2624 : Tensor = prim::GetAttr[name="weight"](%2622)
  %2625 : Float(128:1, 512:128) = aten::t(%2624), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.190 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.243, %2625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.244 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.190, %2623, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.245 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2629 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20574.NoNorm = prim::GetAttr[name="LayerNorm"](%2620)
  %2630 : __torch__.torch.nn.modules.linear.___torch_mangle_20573.Linear = prim::GetAttr[name="dense"](%2620)
  %2631 : Tensor = prim::GetAttr[name="bias"](%2630)
  %2632 : Tensor = prim::GetAttr[name="weight"](%2630)
  %2633 : Float(512:1, 128:512) = aten::t(%2632), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.191 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.245, %2633), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.191, %2631, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.102 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.63, %input.243, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2637 : Tensor = prim::GetAttr[name="bias"](%2629)
  %2638 : Tensor = prim::GetAttr[name="weight"](%2629)
  %2639 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.102, %2638), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.246 : Float(17:1664, 13:128, 128:1) = aten::add(%2639, %2637, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2641 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20581.FFNOutput = prim::GetAttr[name="output"](%2501)
  %2642 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20578.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2501)
  %2643 : __torch__.torch.nn.modules.linear.___torch_mangle_20577.Linear = prim::GetAttr[name="dense"](%2642)
  %2644 : Tensor = prim::GetAttr[name="bias"](%2643)
  %2645 : Tensor = prim::GetAttr[name="weight"](%2643)
  %2646 : Float(128:1, 512:128) = aten::t(%2645), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.192 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.246, %2646), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.247 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.192, %2644, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.248 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2650 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20580.NoNorm = prim::GetAttr[name="LayerNorm"](%2641)
  %2651 : __torch__.torch.nn.modules.linear.___torch_mangle_20579.Linear = prim::GetAttr[name="dense"](%2641)
  %2652 : Tensor = prim::GetAttr[name="bias"](%2651)
  %2653 : Tensor = prim::GetAttr[name="weight"](%2651)
  %2654 : Float(512:1, 128:512) = aten::t(%2653), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.193 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.248, %2654), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.64 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.193, %2652, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.103 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.64, %input.246, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2658 : Tensor = prim::GetAttr[name="bias"](%2650)
  %2659 : Tensor = prim::GetAttr[name="weight"](%2650)
  %2660 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.103, %2659), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.249 : Float(17:1664, 13:128, 128:1) = aten::add(%2660, %2658, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2662 : __torch__.torch.nn.modules.linear.___torch_mangle_20549.Linear = prim::GetAttr[name="dense"](%2499)
  %2663 : Tensor = prim::GetAttr[name="bias"](%2662)
  %2664 : Tensor = prim::GetAttr[name="weight"](%2662)
  %2665 : Float(128:1, 512:128) = aten::t(%2664), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %output.194 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.249, %2665), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %input.250 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.194, %2663, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1678:0
  %input.251 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate # torch/nn/functional.py:1119:0
  %2669 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20556.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2498)
  %2670 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20552.NoNorm = prim::GetAttr[name="LayerNorm"](%2498)
  %2671 : __torch__.torch.nn.modules.linear.___torch_mangle_20551.Linear = prim::GetAttr[name="dense"](%2498)
  %2672 : Tensor = prim::GetAttr[name="bias"](%2671)
  %2673 : Tensor = prim::GetAttr[name="weight"](%2671)
  %2674 : Float(512:1, 128:512) = aten::t(%2673), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %output.195 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.251, %2674), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %layer_output.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.195, %2672, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.104 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.13, %input.249, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output # transformers/modeling_mobilebert.py:405:0
  %2678 : Tensor = prim::GetAttr[name="bias"](%2670)
  %2679 : Tensor = prim::GetAttr[name="weight"](%2670)
  %2680 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.104, %2679), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.252 : Float(17:1664, 13:128, 128:1) = aten::add(%2680, %2678, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2682 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20554.NoNorm = prim::GetAttr[name="LayerNorm"](%2669)
  %2683 : __torch__.torch.nn.modules.linear.___torch_mangle_20553.Linear = prim::GetAttr[name="dense"](%2669)
  %2684 : Tensor = prim::GetAttr[name="bias"](%2683)
  %2685 : Tensor = prim::GetAttr[name="weight"](%2683)
  %2686 : Float(128:1, 512:128) = aten::t(%2685), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.196 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.252, %2686), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.253 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.196, %2684, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.65 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.253, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.105 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.65, %input.235, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2691 : Tensor = prim::GetAttr[name="bias"](%2682)
  %2692 : Tensor = prim::GetAttr[name="weight"](%2682)
  %2693 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.105, %2692), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.254 : Float(17:6656, 13:512, 512:1) = aten::add(%2693, %2691, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20602.MobileBertOutput = prim::GetAttr[name="output"](%107)
  %2696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20595.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%107)
  %2697 : __torch__.torch.nn.modules.container.___torch_mangle_20628.ModuleList = prim::GetAttr[name="ffn"](%107)
  %2698 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20627.FFNLayer = prim::GetAttr[name="2"](%2697)
  %2699 : __torch__.torch.nn.modules.container.___torch_mangle_20628.ModuleList = prim::GetAttr[name="ffn"](%107)
  %2700 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20621.FFNLayer = prim::GetAttr[name="1"](%2699)
  %2701 : __torch__.torch.nn.modules.container.___torch_mangle_20628.ModuleList = prim::GetAttr[name="ffn"](%107)
  %2702 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20615.FFNLayer = prim::GetAttr[name="0"](%2701)
  %2703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20593.MobileBertAttention = prim::GetAttr[name="attention"](%107)
  %2704 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20609.Bottleneck = prim::GetAttr[name="bottleneck"](%107)
  %2705 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20608.BottleneckLayer = prim::GetAttr[name="attention"](%2704)
  %2706 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20605.BottleneckLayer = prim::GetAttr[name="input"](%2704)
  %2707 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20604.NoNorm = prim::GetAttr[name="LayerNorm"](%2706)
  %2708 : __torch__.torch.nn.modules.linear.___torch_mangle_20603.Linear = prim::GetAttr[name="dense"](%2706)
  %2709 : Tensor = prim::GetAttr[name="bias"](%2708)
  %2710 : Tensor = prim::GetAttr[name="weight"](%2708)
  %2711 : Float(512:1, 128:512) = aten::t(%2710), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.197 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2711), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.197, %2709, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2714 : Tensor = prim::GetAttr[name="bias"](%2707)
  %2715 : Tensor = prim::GetAttr[name="weight"](%2707)
  %2716 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.106, %2715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%2716, %2714, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20607.NoNorm = prim::GetAttr[name="LayerNorm"](%2705)
  %2719 : __torch__.torch.nn.modules.linear.___torch_mangle_20606.Linear = prim::GetAttr[name="dense"](%2705)
  %2720 : Tensor = prim::GetAttr[name="bias"](%2719)
  %2721 : Tensor = prim::GetAttr[name="weight"](%2719)
  %2722 : Float(512:1, 128:512) = aten::t(%2721), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.198 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.198, %2720, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2725 : Tensor = prim::GetAttr[name="bias"](%2718)
  %2726 : Tensor = prim::GetAttr[name="weight"](%2718)
  %2727 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.107, %2726), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.255 : Float(17:1664, 13:128, 128:1) = aten::add(%2727, %2725, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2729 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.255, %residual_tensor.14)
  %2730 : Float(17:1664, 13:128, 128:1), %2731 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2729)
  %2732 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20592.MobileBertSelfOutput = prim::GetAttr[name="output"](%2703)
  %2733 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20589.MobileBertSelfAttention = prim::GetAttr[name="self"](%2703)
  %2734 : __torch__.torch.nn.modules.linear.___torch_mangle_20587.Linear = prim::GetAttr[name="value"](%2733)
  %2735 : __torch__.torch.nn.modules.linear.___torch_mangle_20586.Linear = prim::GetAttr[name="key"](%2733)
  %2736 : __torch__.torch.nn.modules.linear.___torch_mangle_20585.Linear = prim::GetAttr[name="query"](%2733)
  %2737 : Tensor = prim::GetAttr[name="bias"](%2736)
  %2738 : Tensor = prim::GetAttr[name="weight"](%2736)
  %2739 : Float(128:1, 128:128) = aten::t(%2738), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %output.199 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2730, %2739), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %x.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.199, %2737, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1678:0
  %2742 : Tensor = prim::GetAttr[name="bias"](%2735)
  %2743 : Tensor = prim::GetAttr[name="weight"](%2735)
  %2744 : Float(128:1, 128:128) = aten::t(%2743), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %output.200 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2730, %2744), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %x.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.200, %2742, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1678:0
  %2747 : Tensor = prim::GetAttr[name="bias"](%2734)
  %2748 : Tensor = prim::GetAttr[name="weight"](%2734)
  %2749 : Float(512:1, 128:512) = aten::t(%2748), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %output.201 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2749), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %x.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.201, %2747, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1678:0
  %2752 : int = aten::size(%x.79, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2753 : int = aten::size(%x.79, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2754 : int[] = prim::ListConstruct(%2752, %2753, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.80 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.79, %2754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2756 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %query_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.80, %2756), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2758 : int = aten::size(%x.81, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2759 : int = aten::size(%x.81, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2760 : int[] = prim::ListConstruct(%2758, %2759, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.82 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.81, %2760), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2762 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %key_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.82, %2762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2764 : int = aten::size(%x.83, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2765 : int = aten::size(%x.83, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2766 : int[] = prim::ListConstruct(%2764, %2765, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.84 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.83, %2766), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2768 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %value_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.84, %2768), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2770 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.14, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.27 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.14, %2770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.27, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.256 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.28, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.257 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.256, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.257, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.27 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.14, %value_layer.14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:280:0
  %2777 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %2778 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.27, %2777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2778, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %2780 : int = aten::size(%context_layer.28, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2781 : int = aten::size(%context_layer.28, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2782 : int[] = prim::ListConstruct(%2780, %2781, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %input.258 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.28, %2782), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:283:0
  %2784 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20591.NoNorm = prim::GetAttr[name="LayerNorm"](%2732)
  %2785 : __torch__.torch.nn.modules.linear.___torch_mangle_20590.Linear = prim::GetAttr[name="dense"](%2732)
  %2786 : Tensor = prim::GetAttr[name="bias"](%2785)
  %2787 : Tensor = prim::GetAttr[name="weight"](%2785)
  %2788 : Float(128:1, 128:128) = aten::t(%2787), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %output.202 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.258, %2788), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.202, %2786, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.108 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.66, %2731, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output # transformers/modeling_mobilebert.py:301:0
  %2792 : Tensor = prim::GetAttr[name="bias"](%2784)
  %2793 : Tensor = prim::GetAttr[name="weight"](%2784)
  %2794 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.108, %2793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.259 : Float(17:1664, 13:128, 128:1) = aten::add(%2794, %2792, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2796 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20614.FFNOutput = prim::GetAttr[name="output"](%2702)
  %2797 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20611.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2702)
  %2798 : __torch__.torch.nn.modules.linear.___torch_mangle_20610.Linear = prim::GetAttr[name="dense"](%2797)
  %2799 : Tensor = prim::GetAttr[name="bias"](%2798)
  %2800 : Tensor = prim::GetAttr[name="weight"](%2798)
  %2801 : Float(128:1, 512:128) = aten::t(%2800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.203 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.259, %2801), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.260 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.203, %2799, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.261 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2805 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20613.NoNorm = prim::GetAttr[name="LayerNorm"](%2796)
  %2806 : __torch__.torch.nn.modules.linear.___torch_mangle_20612.Linear = prim::GetAttr[name="dense"](%2796)
  %2807 : Tensor = prim::GetAttr[name="bias"](%2806)
  %2808 : Tensor = prim::GetAttr[name="weight"](%2806)
  %2809 : Float(512:1, 128:512) = aten::t(%2808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.204 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.261, %2809), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.204, %2807, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.109 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.67, %input.259, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2813 : Tensor = prim::GetAttr[name="bias"](%2805)
  %2814 : Tensor = prim::GetAttr[name="weight"](%2805)
  %2815 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.109, %2814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.262 : Float(17:1664, 13:128, 128:1) = aten::add(%2815, %2813, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2817 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20620.FFNOutput = prim::GetAttr[name="output"](%2700)
  %2818 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20617.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2700)
  %2819 : __torch__.torch.nn.modules.linear.___torch_mangle_20616.Linear = prim::GetAttr[name="dense"](%2818)
  %2820 : Tensor = prim::GetAttr[name="bias"](%2819)
  %2821 : Tensor = prim::GetAttr[name="weight"](%2819)
  %2822 : Float(128:1, 512:128) = aten::t(%2821), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.205 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.262, %2822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.263 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.205, %2820, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.264 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2826 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20619.NoNorm = prim::GetAttr[name="LayerNorm"](%2817)
  %2827 : __torch__.torch.nn.modules.linear.___torch_mangle_20618.Linear = prim::GetAttr[name="dense"](%2817)
  %2828 : Tensor = prim::GetAttr[name="bias"](%2827)
  %2829 : Tensor = prim::GetAttr[name="weight"](%2827)
  %2830 : Float(512:1, 128:512) = aten::t(%2829), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.206 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.264, %2830), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.68 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.206, %2828, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.110 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.68, %input.262, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2834 : Tensor = prim::GetAttr[name="bias"](%2826)
  %2835 : Tensor = prim::GetAttr[name="weight"](%2826)
  %2836 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.110, %2835), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.265 : Float(17:1664, 13:128, 128:1) = aten::add(%2836, %2834, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2838 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20626.FFNOutput = prim::GetAttr[name="output"](%2698)
  %2839 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20623.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2698)
  %2840 : __torch__.torch.nn.modules.linear.___torch_mangle_20622.Linear = prim::GetAttr[name="dense"](%2839)
  %2841 : Tensor = prim::GetAttr[name="bias"](%2840)
  %2842 : Tensor = prim::GetAttr[name="weight"](%2840)
  %2843 : Float(128:1, 512:128) = aten::t(%2842), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.207 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.265, %2843), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.266 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.207, %2841, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.267 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2847 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20625.NoNorm = prim::GetAttr[name="LayerNorm"](%2838)
  %2848 : __torch__.torch.nn.modules.linear.___torch_mangle_20624.Linear = prim::GetAttr[name="dense"](%2838)
  %2849 : Tensor = prim::GetAttr[name="bias"](%2848)
  %2850 : Tensor = prim::GetAttr[name="weight"](%2848)
  %2851 : Float(512:1, 128:512) = aten::t(%2850), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.208 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.267, %2851), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.208, %2849, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.111 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.69, %input.265, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2855 : Tensor = prim::GetAttr[name="bias"](%2847)
  %2856 : Tensor = prim::GetAttr[name="weight"](%2847)
  %2857 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.111, %2856), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.268 : Float(17:1664, 13:128, 128:1) = aten::add(%2857, %2855, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2859 : __torch__.torch.nn.modules.linear.___torch_mangle_20594.Linear = prim::GetAttr[name="dense"](%2696)
  %2860 : Tensor = prim::GetAttr[name="bias"](%2859)
  %2861 : Tensor = prim::GetAttr[name="weight"](%2859)
  %2862 : Float(128:1, 512:128) = aten::t(%2861), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %output.209 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.268, %2862), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %input.269 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.209, %2860, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1678:0
  %input.270 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate # torch/nn/functional.py:1119:0
  %2866 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20601.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2695)
  %2867 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20597.NoNorm = prim::GetAttr[name="LayerNorm"](%2695)
  %2868 : __torch__.torch.nn.modules.linear.___torch_mangle_20596.Linear = prim::GetAttr[name="dense"](%2695)
  %2869 : Tensor = prim::GetAttr[name="bias"](%2868)
  %2870 : Tensor = prim::GetAttr[name="weight"](%2868)
  %2871 : Float(512:1, 128:512) = aten::t(%2870), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %output.210 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.270, %2871), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %layer_output.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.210, %2869, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.112 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.14, %input.268, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output # transformers/modeling_mobilebert.py:405:0
  %2875 : Tensor = prim::GetAttr[name="bias"](%2867)
  %2876 : Tensor = prim::GetAttr[name="weight"](%2867)
  %2877 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.112, %2876), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.271 : Float(17:1664, 13:128, 128:1) = aten::add(%2877, %2875, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2879 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20599.NoNorm = prim::GetAttr[name="LayerNorm"](%2866)
  %2880 : __torch__.torch.nn.modules.linear.___torch_mangle_20598.Linear = prim::GetAttr[name="dense"](%2866)
  %2881 : Tensor = prim::GetAttr[name="bias"](%2880)
  %2882 : Tensor = prim::GetAttr[name="weight"](%2880)
  %2883 : Float(128:1, 512:128) = aten::t(%2882), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.211 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.271, %2883), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.272 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.211, %2881, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.70 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.272, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.113 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.70, %input.254, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2888 : Tensor = prim::GetAttr[name="bias"](%2879)
  %2889 : Tensor = prim::GetAttr[name="weight"](%2879)
  %2890 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.113, %2889), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.273 : Float(17:6656, 13:512, 512:1) = aten::add(%2890, %2888, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2892 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20647.MobileBertOutput = prim::GetAttr[name="output"](%105)
  %2893 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20640.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%105)
  %2894 : __torch__.torch.nn.modules.container.___torch_mangle_20673.ModuleList = prim::GetAttr[name="ffn"](%105)
  %2895 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20672.FFNLayer = prim::GetAttr[name="2"](%2894)
  %2896 : __torch__.torch.nn.modules.container.___torch_mangle_20673.ModuleList = prim::GetAttr[name="ffn"](%105)
  %2897 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20666.FFNLayer = prim::GetAttr[name="1"](%2896)
  %2898 : __torch__.torch.nn.modules.container.___torch_mangle_20673.ModuleList = prim::GetAttr[name="ffn"](%105)
  %2899 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20660.FFNLayer = prim::GetAttr[name="0"](%2898)
  %2900 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20638.MobileBertAttention = prim::GetAttr[name="attention"](%105)
  %2901 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20654.Bottleneck = prim::GetAttr[name="bottleneck"](%105)
  %2902 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20653.BottleneckLayer = prim::GetAttr[name="attention"](%2901)
  %2903 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20650.BottleneckLayer = prim::GetAttr[name="input"](%2901)
  %2904 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20649.NoNorm = prim::GetAttr[name="LayerNorm"](%2903)
  %2905 : __torch__.torch.nn.modules.linear.___torch_mangle_20648.Linear = prim::GetAttr[name="dense"](%2903)
  %2906 : Tensor = prim::GetAttr[name="bias"](%2905)
  %2907 : Tensor = prim::GetAttr[name="weight"](%2905)
  %2908 : Float(512:1, 128:512) = aten::t(%2907), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.212 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2908), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.212, %2906, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2911 : Tensor = prim::GetAttr[name="bias"](%2904)
  %2912 : Tensor = prim::GetAttr[name="weight"](%2904)
  %2913 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.114, %2912), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%2913, %2911, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2915 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20652.NoNorm = prim::GetAttr[name="LayerNorm"](%2902)
  %2916 : __torch__.torch.nn.modules.linear.___torch_mangle_20651.Linear = prim::GetAttr[name="dense"](%2902)
  %2917 : Tensor = prim::GetAttr[name="bias"](%2916)
  %2918 : Tensor = prim::GetAttr[name="weight"](%2916)
  %2919 : Float(512:1, 128:512) = aten::t(%2918), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.213 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2919), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.213, %2917, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2922 : Tensor = prim::GetAttr[name="bias"](%2915)
  %2923 : Tensor = prim::GetAttr[name="weight"](%2915)
  %2924 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.115, %2923), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.274 : Float(17:1664, 13:128, 128:1) = aten::add(%2924, %2922, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2926 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.274, %residual_tensor.15)
  %2927 : Float(17:1664, 13:128, 128:1), %2928 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2926)
  %2929 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20637.MobileBertSelfOutput = prim::GetAttr[name="output"](%2900)
  %2930 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20634.MobileBertSelfAttention = prim::GetAttr[name="self"](%2900)
  %2931 : __torch__.torch.nn.modules.linear.___torch_mangle_20632.Linear = prim::GetAttr[name="value"](%2930)
  %2932 : __torch__.torch.nn.modules.linear.___torch_mangle_20631.Linear = prim::GetAttr[name="key"](%2930)
  %2933 : __torch__.torch.nn.modules.linear.___torch_mangle_20630.Linear = prim::GetAttr[name="query"](%2930)
  %2934 : Tensor = prim::GetAttr[name="bias"](%2933)
  %2935 : Tensor = prim::GetAttr[name="weight"](%2933)
  %2936 : Float(128:1, 128:128) = aten::t(%2935), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %output.214 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2927, %2936), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %x.85 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.214, %2934, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1678:0
  %2939 : Tensor = prim::GetAttr[name="bias"](%2932)
  %2940 : Tensor = prim::GetAttr[name="weight"](%2932)
  %2941 : Float(128:1, 128:128) = aten::t(%2940), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %output.215 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2927, %2941), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %x.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.215, %2939, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1678:0
  %2944 : Tensor = prim::GetAttr[name="bias"](%2931)
  %2945 : Tensor = prim::GetAttr[name="weight"](%2931)
  %2946 : Float(512:1, 128:512) = aten::t(%2945), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %output.216 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2946), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %x.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.216, %2944, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1678:0
  %2949 : int = aten::size(%x.85, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2950 : int = aten::size(%x.85, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2951 : int[] = prim::ListConstruct(%2949, %2950, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.86 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.85, %2951), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2953 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %query_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.86, %2953), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2955 : int = aten::size(%x.87, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2956 : int = aten::size(%x.87, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2957 : int[] = prim::ListConstruct(%2955, %2956, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.88 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.87, %2957), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2959 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %key_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.88, %2959), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2961 : int = aten::size(%x.89, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2962 : int = aten::size(%x.89, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2963 : int[] = prim::ListConstruct(%2961, %2962, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.90 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.89, %2963), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2965 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %value_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.90, %2965), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2967 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.15, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.15, %2967), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.30 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.29, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.275 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.30, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.276 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.275, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.276, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.29 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.15, %value_layer.15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:280:0
  %2974 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %2975 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.29, %2974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2975, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %2977 : int = aten::size(%context_layer.30, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2978 : int = aten::size(%context_layer.30, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2979 : int[] = prim::ListConstruct(%2977, %2978, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %input.277 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.30, %2979), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:283:0
  %2981 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20636.NoNorm = prim::GetAttr[name="LayerNorm"](%2929)
  %2982 : __torch__.torch.nn.modules.linear.___torch_mangle_20635.Linear = prim::GetAttr[name="dense"](%2929)
  %2983 : Tensor = prim::GetAttr[name="bias"](%2982)
  %2984 : Tensor = prim::GetAttr[name="weight"](%2982)
  %2985 : Float(128:1, 128:128) = aten::t(%2984), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %output.217 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.277, %2985), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.217, %2983, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.116 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.71, %2928, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output # transformers/modeling_mobilebert.py:301:0
  %2989 : Tensor = prim::GetAttr[name="bias"](%2981)
  %2990 : Tensor = prim::GetAttr[name="weight"](%2981)
  %2991 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.116, %2990), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.278 : Float(17:1664, 13:128, 128:1) = aten::add(%2991, %2989, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2993 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20659.FFNOutput = prim::GetAttr[name="output"](%2899)
  %2994 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20656.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2899)
  %2995 : __torch__.torch.nn.modules.linear.___torch_mangle_20655.Linear = prim::GetAttr[name="dense"](%2994)
  %2996 : Tensor = prim::GetAttr[name="bias"](%2995)
  %2997 : Tensor = prim::GetAttr[name="weight"](%2995)
  %2998 : Float(128:1, 512:128) = aten::t(%2997), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.218 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.278, %2998), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.279 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.218, %2996, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.280 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3002 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20658.NoNorm = prim::GetAttr[name="LayerNorm"](%2993)
  %3003 : __torch__.torch.nn.modules.linear.___torch_mangle_20657.Linear = prim::GetAttr[name="dense"](%2993)
  %3004 : Tensor = prim::GetAttr[name="bias"](%3003)
  %3005 : Tensor = prim::GetAttr[name="weight"](%3003)
  %3006 : Float(512:1, 128:512) = aten::t(%3005), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.219 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.280, %3006), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.72 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.219, %3004, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.117 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.72, %input.278, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3010 : Tensor = prim::GetAttr[name="bias"](%3002)
  %3011 : Tensor = prim::GetAttr[name="weight"](%3002)
  %3012 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.117, %3011), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.281 : Float(17:1664, 13:128, 128:1) = aten::add(%3012, %3010, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3014 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20665.FFNOutput = prim::GetAttr[name="output"](%2897)
  %3015 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20662.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2897)
  %3016 : __torch__.torch.nn.modules.linear.___torch_mangle_20661.Linear = prim::GetAttr[name="dense"](%3015)
  %3017 : Tensor = prim::GetAttr[name="bias"](%3016)
  %3018 : Tensor = prim::GetAttr[name="weight"](%3016)
  %3019 : Float(128:1, 512:128) = aten::t(%3018), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.220 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.281, %3019), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.282 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.220, %3017, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.283 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3023 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20664.NoNorm = prim::GetAttr[name="LayerNorm"](%3014)
  %3024 : __torch__.torch.nn.modules.linear.___torch_mangle_20663.Linear = prim::GetAttr[name="dense"](%3014)
  %3025 : Tensor = prim::GetAttr[name="bias"](%3024)
  %3026 : Tensor = prim::GetAttr[name="weight"](%3024)
  %3027 : Float(512:1, 128:512) = aten::t(%3026), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.221 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.283, %3027), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.221, %3025, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.118 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.73, %input.281, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3031 : Tensor = prim::GetAttr[name="bias"](%3023)
  %3032 : Tensor = prim::GetAttr[name="weight"](%3023)
  %3033 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.118, %3032), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.284 : Float(17:1664, 13:128, 128:1) = aten::add(%3033, %3031, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3035 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20671.FFNOutput = prim::GetAttr[name="output"](%2895)
  %3036 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20668.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2895)
  %3037 : __torch__.torch.nn.modules.linear.___torch_mangle_20667.Linear = prim::GetAttr[name="dense"](%3036)
  %3038 : Tensor = prim::GetAttr[name="bias"](%3037)
  %3039 : Tensor = prim::GetAttr[name="weight"](%3037)
  %3040 : Float(128:1, 512:128) = aten::t(%3039), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.222 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.284, %3040), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.285 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.222, %3038, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.286 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3044 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20670.NoNorm = prim::GetAttr[name="LayerNorm"](%3035)
  %3045 : __torch__.torch.nn.modules.linear.___torch_mangle_20669.Linear = prim::GetAttr[name="dense"](%3035)
  %3046 : Tensor = prim::GetAttr[name="bias"](%3045)
  %3047 : Tensor = prim::GetAttr[name="weight"](%3045)
  %3048 : Float(512:1, 128:512) = aten::t(%3047), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.223 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.286, %3048), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.223, %3046, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.119 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.74, %input.284, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3052 : Tensor = prim::GetAttr[name="bias"](%3044)
  %3053 : Tensor = prim::GetAttr[name="weight"](%3044)
  %3054 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.119, %3053), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.287 : Float(17:1664, 13:128, 128:1) = aten::add(%3054, %3052, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3056 : __torch__.torch.nn.modules.linear.___torch_mangle_20639.Linear = prim::GetAttr[name="dense"](%2893)
  %3057 : Tensor = prim::GetAttr[name="bias"](%3056)
  %3058 : Tensor = prim::GetAttr[name="weight"](%3056)
  %3059 : Float(128:1, 512:128) = aten::t(%3058), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %output.224 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.287, %3059), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %input.288 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.224, %3057, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1678:0
  %input.289 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate # torch/nn/functional.py:1119:0
  %3063 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20646.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2892)
  %3064 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20642.NoNorm = prim::GetAttr[name="LayerNorm"](%2892)
  %3065 : __torch__.torch.nn.modules.linear.___torch_mangle_20641.Linear = prim::GetAttr[name="dense"](%2892)
  %3066 : Tensor = prim::GetAttr[name="bias"](%3065)
  %3067 : Tensor = prim::GetAttr[name="weight"](%3065)
  %3068 : Float(512:1, 128:512) = aten::t(%3067), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %output.225 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.289, %3068), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %layer_output.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.225, %3066, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.120 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.15, %input.287, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output # transformers/modeling_mobilebert.py:405:0
  %3072 : Tensor = prim::GetAttr[name="bias"](%3064)
  %3073 : Tensor = prim::GetAttr[name="weight"](%3064)
  %3074 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.120, %3073), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.290 : Float(17:1664, 13:128, 128:1) = aten::add(%3074, %3072, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3076 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20644.NoNorm = prim::GetAttr[name="LayerNorm"](%3063)
  %3077 : __torch__.torch.nn.modules.linear.___torch_mangle_20643.Linear = prim::GetAttr[name="dense"](%3063)
  %3078 : Tensor = prim::GetAttr[name="bias"](%3077)
  %3079 : Tensor = prim::GetAttr[name="weight"](%3077)
  %3080 : Float(128:1, 512:128) = aten::t(%3079), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.226 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.290, %3080), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.291 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.226, %3078, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.75 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.291, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.121 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.75, %input.273, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3085 : Tensor = prim::GetAttr[name="bias"](%3076)
  %3086 : Tensor = prim::GetAttr[name="weight"](%3076)
  %3087 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.121, %3086), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.292 : Float(17:6656, 13:512, 512:1) = aten::add(%3087, %3085, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3089 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20692.MobileBertOutput = prim::GetAttr[name="output"](%103)
  %3090 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20685.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%103)
  %3091 : __torch__.torch.nn.modules.container.___torch_mangle_20718.ModuleList = prim::GetAttr[name="ffn"](%103)
  %3092 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20717.FFNLayer = prim::GetAttr[name="2"](%3091)
  %3093 : __torch__.torch.nn.modules.container.___torch_mangle_20718.ModuleList = prim::GetAttr[name="ffn"](%103)
  %3094 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20711.FFNLayer = prim::GetAttr[name="1"](%3093)
  %3095 : __torch__.torch.nn.modules.container.___torch_mangle_20718.ModuleList = prim::GetAttr[name="ffn"](%103)
  %3096 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20705.FFNLayer = prim::GetAttr[name="0"](%3095)
  %3097 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20683.MobileBertAttention = prim::GetAttr[name="attention"](%103)
  %3098 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20699.Bottleneck = prim::GetAttr[name="bottleneck"](%103)
  %3099 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20698.BottleneckLayer = prim::GetAttr[name="attention"](%3098)
  %3100 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20695.BottleneckLayer = prim::GetAttr[name="input"](%3098)
  %3101 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20694.NoNorm = prim::GetAttr[name="LayerNorm"](%3100)
  %3102 : __torch__.torch.nn.modules.linear.___torch_mangle_20693.Linear = prim::GetAttr[name="dense"](%3100)
  %3103 : Tensor = prim::GetAttr[name="bias"](%3102)
  %3104 : Tensor = prim::GetAttr[name="weight"](%3102)
  %3105 : Float(512:1, 128:512) = aten::t(%3104), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.227 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3105), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.122 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.227, %3103, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3108 : Tensor = prim::GetAttr[name="bias"](%3101)
  %3109 : Tensor = prim::GetAttr[name="weight"](%3101)
  %3110 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.122, %3109), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%3110, %3108, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20697.NoNorm = prim::GetAttr[name="LayerNorm"](%3099)
  %3113 : __torch__.torch.nn.modules.linear.___torch_mangle_20696.Linear = prim::GetAttr[name="dense"](%3099)
  %3114 : Tensor = prim::GetAttr[name="bias"](%3113)
  %3115 : Tensor = prim::GetAttr[name="weight"](%3113)
  %3116 : Float(512:1, 128:512) = aten::t(%3115), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.228 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3116), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.228, %3114, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3119 : Tensor = prim::GetAttr[name="bias"](%3112)
  %3120 : Tensor = prim::GetAttr[name="weight"](%3112)
  %3121 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.123, %3120), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.293 : Float(17:1664, 13:128, 128:1) = aten::add(%3121, %3119, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3123 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.293, %residual_tensor.16)
  %3124 : Float(17:1664, 13:128, 128:1), %3125 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3123)
  %3126 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20682.MobileBertSelfOutput = prim::GetAttr[name="output"](%3097)
  %3127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20679.MobileBertSelfAttention = prim::GetAttr[name="self"](%3097)
  %3128 : __torch__.torch.nn.modules.linear.___torch_mangle_20677.Linear = prim::GetAttr[name="value"](%3127)
  %3129 : __torch__.torch.nn.modules.linear.___torch_mangle_20676.Linear = prim::GetAttr[name="key"](%3127)
  %3130 : __torch__.torch.nn.modules.linear.___torch_mangle_20675.Linear = prim::GetAttr[name="query"](%3127)
  %3131 : Tensor = prim::GetAttr[name="bias"](%3130)
  %3132 : Tensor = prim::GetAttr[name="weight"](%3130)
  %3133 : Float(128:1, 128:128) = aten::t(%3132), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %output.229 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3124, %3133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %x.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.229, %3131, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1678:0
  %3136 : Tensor = prim::GetAttr[name="bias"](%3129)
  %3137 : Tensor = prim::GetAttr[name="weight"](%3129)
  %3138 : Float(128:1, 128:128) = aten::t(%3137), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %output.230 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3124, %3138), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %x.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.230, %3136, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1678:0
  %3141 : Tensor = prim::GetAttr[name="bias"](%3128)
  %3142 : Tensor = prim::GetAttr[name="weight"](%3128)
  %3143 : Float(512:1, 128:512) = aten::t(%3142), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %output.231 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3143), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %x.95 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.231, %3141, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1678:0
  %3146 : int = aten::size(%x.91, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3147 : int = aten::size(%x.91, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3148 : int[] = prim::ListConstruct(%3146, %3147, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.92 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.91, %3148), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3150 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %query_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.92, %3150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3152 : int = aten::size(%x.93, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3153 : int = aten::size(%x.93, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3154 : int[] = prim::ListConstruct(%3152, %3153, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.94 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.93, %3154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3156 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %key_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.94, %3156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3158 : int = aten::size(%x.95, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3159 : int = aten::size(%x.95, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3160 : int[] = prim::ListConstruct(%3158, %3159, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.96 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.95, %3160), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3162 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %value_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.96, %3162), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3164 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.16, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.31 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.16, %3164), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.32 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.31, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.294 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.32, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.295 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.294, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.295, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.31 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.16, %value_layer.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:280:0
  %3171 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %3172 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.31, %3171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3172, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %3174 : int = aten::size(%context_layer.32, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3175 : int = aten::size(%context_layer.32, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3176 : int[] = prim::ListConstruct(%3174, %3175, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %input.296 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.32, %3176), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:283:0
  %3178 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20681.NoNorm = prim::GetAttr[name="LayerNorm"](%3126)
  %3179 : __torch__.torch.nn.modules.linear.___torch_mangle_20680.Linear = prim::GetAttr[name="dense"](%3126)
  %3180 : Tensor = prim::GetAttr[name="bias"](%3179)
  %3181 : Tensor = prim::GetAttr[name="weight"](%3179)
  %3182 : Float(128:1, 128:128) = aten::t(%3181), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %output.232 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.296, %3182), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.76 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.232, %3180, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.124 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.76, %3125, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output # transformers/modeling_mobilebert.py:301:0
  %3186 : Tensor = prim::GetAttr[name="bias"](%3178)
  %3187 : Tensor = prim::GetAttr[name="weight"](%3178)
  %3188 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.124, %3187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.297 : Float(17:1664, 13:128, 128:1) = aten::add(%3188, %3186, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3190 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20704.FFNOutput = prim::GetAttr[name="output"](%3096)
  %3191 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20701.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3096)
  %3192 : __torch__.torch.nn.modules.linear.___torch_mangle_20700.Linear = prim::GetAttr[name="dense"](%3191)
  %3193 : Tensor = prim::GetAttr[name="bias"](%3192)
  %3194 : Tensor = prim::GetAttr[name="weight"](%3192)
  %3195 : Float(128:1, 512:128) = aten::t(%3194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.233 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.297, %3195), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.298 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.233, %3193, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.299 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3199 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20703.NoNorm = prim::GetAttr[name="LayerNorm"](%3190)
  %3200 : __torch__.torch.nn.modules.linear.___torch_mangle_20702.Linear = prim::GetAttr[name="dense"](%3190)
  %3201 : Tensor = prim::GetAttr[name="bias"](%3200)
  %3202 : Tensor = prim::GetAttr[name="weight"](%3200)
  %3203 : Float(512:1, 128:512) = aten::t(%3202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.234 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.299, %3203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.234, %3201, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.125 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.77, %input.297, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3207 : Tensor = prim::GetAttr[name="bias"](%3199)
  %3208 : Tensor = prim::GetAttr[name="weight"](%3199)
  %3209 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.125, %3208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.300 : Float(17:1664, 13:128, 128:1) = aten::add(%3209, %3207, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3211 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20710.FFNOutput = prim::GetAttr[name="output"](%3094)
  %3212 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20707.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3094)
  %3213 : __torch__.torch.nn.modules.linear.___torch_mangle_20706.Linear = prim::GetAttr[name="dense"](%3212)
  %3214 : Tensor = prim::GetAttr[name="bias"](%3213)
  %3215 : Tensor = prim::GetAttr[name="weight"](%3213)
  %3216 : Float(128:1, 512:128) = aten::t(%3215), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.235 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.300, %3216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.301 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.235, %3214, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.302 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3220 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20709.NoNorm = prim::GetAttr[name="LayerNorm"](%3211)
  %3221 : __torch__.torch.nn.modules.linear.___torch_mangle_20708.Linear = prim::GetAttr[name="dense"](%3211)
  %3222 : Tensor = prim::GetAttr[name="bias"](%3221)
  %3223 : Tensor = prim::GetAttr[name="weight"](%3221)
  %3224 : Float(512:1, 128:512) = aten::t(%3223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.236 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.302, %3224), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.78 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.236, %3222, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.126 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.78, %input.300, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3228 : Tensor = prim::GetAttr[name="bias"](%3220)
  %3229 : Tensor = prim::GetAttr[name="weight"](%3220)
  %3230 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.126, %3229), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.303 : Float(17:1664, 13:128, 128:1) = aten::add(%3230, %3228, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3232 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20716.FFNOutput = prim::GetAttr[name="output"](%3092)
  %3233 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20713.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3092)
  %3234 : __torch__.torch.nn.modules.linear.___torch_mangle_20712.Linear = prim::GetAttr[name="dense"](%3233)
  %3235 : Tensor = prim::GetAttr[name="bias"](%3234)
  %3236 : Tensor = prim::GetAttr[name="weight"](%3234)
  %3237 : Float(128:1, 512:128) = aten::t(%3236), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.237 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.303, %3237), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.304 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.237, %3235, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.305 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3241 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20715.NoNorm = prim::GetAttr[name="LayerNorm"](%3232)
  %3242 : __torch__.torch.nn.modules.linear.___torch_mangle_20714.Linear = prim::GetAttr[name="dense"](%3232)
  %3243 : Tensor = prim::GetAttr[name="bias"](%3242)
  %3244 : Tensor = prim::GetAttr[name="weight"](%3242)
  %3245 : Float(512:1, 128:512) = aten::t(%3244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.238 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.305, %3245), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.238, %3243, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.127 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.79, %input.303, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3249 : Tensor = prim::GetAttr[name="bias"](%3241)
  %3250 : Tensor = prim::GetAttr[name="weight"](%3241)
  %3251 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.127, %3250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.306 : Float(17:1664, 13:128, 128:1) = aten::add(%3251, %3249, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3253 : __torch__.torch.nn.modules.linear.___torch_mangle_20684.Linear = prim::GetAttr[name="dense"](%3090)
  %3254 : Tensor = prim::GetAttr[name="bias"](%3253)
  %3255 : Tensor = prim::GetAttr[name="weight"](%3253)
  %3256 : Float(128:1, 512:128) = aten::t(%3255), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %output.239 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.306, %3256), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %input.307 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.239, %3254, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1678:0
  %input.308 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate # torch/nn/functional.py:1119:0
  %3260 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20691.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3089)
  %3261 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20687.NoNorm = prim::GetAttr[name="LayerNorm"](%3089)
  %3262 : __torch__.torch.nn.modules.linear.___torch_mangle_20686.Linear = prim::GetAttr[name="dense"](%3089)
  %3263 : Tensor = prim::GetAttr[name="bias"](%3262)
  %3264 : Tensor = prim::GetAttr[name="weight"](%3262)
  %3265 : Float(512:1, 128:512) = aten::t(%3264), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %output.240 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.308, %3265), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %layer_output.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.240, %3263, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.128 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.16, %input.306, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output # transformers/modeling_mobilebert.py:405:0
  %3269 : Tensor = prim::GetAttr[name="bias"](%3261)
  %3270 : Tensor = prim::GetAttr[name="weight"](%3261)
  %3271 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.128, %3270), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.309 : Float(17:1664, 13:128, 128:1) = aten::add(%3271, %3269, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3273 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20689.NoNorm = prim::GetAttr[name="LayerNorm"](%3260)
  %3274 : __torch__.torch.nn.modules.linear.___torch_mangle_20688.Linear = prim::GetAttr[name="dense"](%3260)
  %3275 : Tensor = prim::GetAttr[name="bias"](%3274)
  %3276 : Tensor = prim::GetAttr[name="weight"](%3274)
  %3277 : Float(128:1, 512:128) = aten::t(%3276), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.241 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.309, %3277), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.310 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.241, %3275, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.80 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.310, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.129 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.80, %input.292, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3282 : Tensor = prim::GetAttr[name="bias"](%3273)
  %3283 : Tensor = prim::GetAttr[name="weight"](%3273)
  %3284 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.129, %3283), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.311 : Float(17:6656, 13:512, 512:1) = aten::add(%3284, %3282, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3286 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20737.MobileBertOutput = prim::GetAttr[name="output"](%101)
  %3287 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20730.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%101)
  %3288 : __torch__.torch.nn.modules.container.___torch_mangle_20763.ModuleList = prim::GetAttr[name="ffn"](%101)
  %3289 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20762.FFNLayer = prim::GetAttr[name="2"](%3288)
  %3290 : __torch__.torch.nn.modules.container.___torch_mangle_20763.ModuleList = prim::GetAttr[name="ffn"](%101)
  %3291 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20756.FFNLayer = prim::GetAttr[name="1"](%3290)
  %3292 : __torch__.torch.nn.modules.container.___torch_mangle_20763.ModuleList = prim::GetAttr[name="ffn"](%101)
  %3293 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20750.FFNLayer = prim::GetAttr[name="0"](%3292)
  %3294 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20728.MobileBertAttention = prim::GetAttr[name="attention"](%101)
  %3295 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20744.Bottleneck = prim::GetAttr[name="bottleneck"](%101)
  %3296 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20743.BottleneckLayer = prim::GetAttr[name="attention"](%3295)
  %3297 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20740.BottleneckLayer = prim::GetAttr[name="input"](%3295)
  %3298 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20739.NoNorm = prim::GetAttr[name="LayerNorm"](%3297)
  %3299 : __torch__.torch.nn.modules.linear.___torch_mangle_20738.Linear = prim::GetAttr[name="dense"](%3297)
  %3300 : Tensor = prim::GetAttr[name="bias"](%3299)
  %3301 : Tensor = prim::GetAttr[name="weight"](%3299)
  %3302 : Float(512:1, 128:512) = aten::t(%3301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.242 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3302), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.130 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.242, %3300, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3305 : Tensor = prim::GetAttr[name="bias"](%3298)
  %3306 : Tensor = prim::GetAttr[name="weight"](%3298)
  %3307 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.130, %3306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.17 : Float(17:1664, 13:128, 128:1) = aten::add(%3307, %3305, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20742.NoNorm = prim::GetAttr[name="LayerNorm"](%3296)
  %3310 : __torch__.torch.nn.modules.linear.___torch_mangle_20741.Linear = prim::GetAttr[name="dense"](%3296)
  %3311 : Tensor = prim::GetAttr[name="bias"](%3310)
  %3312 : Tensor = prim::GetAttr[name="weight"](%3310)
  %3313 : Float(512:1, 128:512) = aten::t(%3312), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.243 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.243, %3311, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3316 : Tensor = prim::GetAttr[name="bias"](%3309)
  %3317 : Tensor = prim::GetAttr[name="weight"](%3309)
  %3318 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.131, %3317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.312 : Float(17:1664, 13:128, 128:1) = aten::add(%3318, %3316, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3320 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.312, %residual_tensor.17)
  %3321 : Float(17:1664, 13:128, 128:1), %3322 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3320)
  %3323 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20727.MobileBertSelfOutput = prim::GetAttr[name="output"](%3294)
  %3324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20724.MobileBertSelfAttention = prim::GetAttr[name="self"](%3294)
  %3325 : __torch__.torch.nn.modules.linear.___torch_mangle_20722.Linear = prim::GetAttr[name="value"](%3324)
  %3326 : __torch__.torch.nn.modules.linear.___torch_mangle_20721.Linear = prim::GetAttr[name="key"](%3324)
  %3327 : __torch__.torch.nn.modules.linear.___torch_mangle_20720.Linear = prim::GetAttr[name="query"](%3324)
  %3328 : Tensor = prim::GetAttr[name="bias"](%3327)
  %3329 : Tensor = prim::GetAttr[name="weight"](%3327)
  %3330 : Float(128:1, 128:128) = aten::t(%3329), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %output.244 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3321, %3330), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %x.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.244, %3328, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1678:0
  %3333 : Tensor = prim::GetAttr[name="bias"](%3326)
  %3334 : Tensor = prim::GetAttr[name="weight"](%3326)
  %3335 : Float(128:1, 128:128) = aten::t(%3334), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %output.245 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3321, %3335), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %x.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.245, %3333, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1678:0
  %3338 : Tensor = prim::GetAttr[name="bias"](%3325)
  %3339 : Tensor = prim::GetAttr[name="weight"](%3325)
  %3340 : Float(512:1, 128:512) = aten::t(%3339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %output.246 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3340), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %x.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.246, %3338, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1678:0
  %3343 : int = aten::size(%x.97, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3344 : int = aten::size(%x.97, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3345 : int[] = prim::ListConstruct(%3343, %3344, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.98 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.97, %3345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3347 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %query_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.98, %3347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3349 : int = aten::size(%x.99, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3350 : int = aten::size(%x.99, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3351 : int[] = prim::ListConstruct(%3349, %3350, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.100 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.99, %3351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3353 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %key_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.100, %3353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3355 : int = aten::size(%x.101, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3356 : int = aten::size(%x.101, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3357 : int[] = prim::ListConstruct(%3355, %3356, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.102 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.101, %3357), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3359 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %value_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.102, %3359), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3361 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.17, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.33 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.17, %3361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.34 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.33, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.313 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.34, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.314 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.313, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.314, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.33 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.17, %value_layer.17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:280:0
  %3368 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %3369 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.33, %3368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3369, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %3371 : int = aten::size(%context_layer.34, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3372 : int = aten::size(%context_layer.34, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3373 : int[] = prim::ListConstruct(%3371, %3372, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %input.315 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.34, %3373), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:283:0
  %3375 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20726.NoNorm = prim::GetAttr[name="LayerNorm"](%3323)
  %3376 : __torch__.torch.nn.modules.linear.___torch_mangle_20725.Linear = prim::GetAttr[name="dense"](%3323)
  %3377 : Tensor = prim::GetAttr[name="bias"](%3376)
  %3378 : Tensor = prim::GetAttr[name="weight"](%3376)
  %3379 : Float(128:1, 128:128) = aten::t(%3378), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %output.247 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.315, %3379), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.247, %3377, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.132 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.81, %3322, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output # transformers/modeling_mobilebert.py:301:0
  %3383 : Tensor = prim::GetAttr[name="bias"](%3375)
  %3384 : Tensor = prim::GetAttr[name="weight"](%3375)
  %3385 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.132, %3384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.316 : Float(17:1664, 13:128, 128:1) = aten::add(%3385, %3383, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3387 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20749.FFNOutput = prim::GetAttr[name="output"](%3293)
  %3388 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20746.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3293)
  %3389 : __torch__.torch.nn.modules.linear.___torch_mangle_20745.Linear = prim::GetAttr[name="dense"](%3388)
  %3390 : Tensor = prim::GetAttr[name="bias"](%3389)
  %3391 : Tensor = prim::GetAttr[name="weight"](%3389)
  %3392 : Float(128:1, 512:128) = aten::t(%3391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.248 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.316, %3392), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.317 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.248, %3390, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.318 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3396 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20748.NoNorm = prim::GetAttr[name="LayerNorm"](%3387)
  %3397 : __torch__.torch.nn.modules.linear.___torch_mangle_20747.Linear = prim::GetAttr[name="dense"](%3387)
  %3398 : Tensor = prim::GetAttr[name="bias"](%3397)
  %3399 : Tensor = prim::GetAttr[name="weight"](%3397)
  %3400 : Float(512:1, 128:512) = aten::t(%3399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.249 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.318, %3400), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.249, %3398, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.133 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.82, %input.316, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3404 : Tensor = prim::GetAttr[name="bias"](%3396)
  %3405 : Tensor = prim::GetAttr[name="weight"](%3396)
  %3406 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.133, %3405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.319 : Float(17:1664, 13:128, 128:1) = aten::add(%3406, %3404, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3408 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20755.FFNOutput = prim::GetAttr[name="output"](%3291)
  %3409 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20752.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3291)
  %3410 : __torch__.torch.nn.modules.linear.___torch_mangle_20751.Linear = prim::GetAttr[name="dense"](%3409)
  %3411 : Tensor = prim::GetAttr[name="bias"](%3410)
  %3412 : Tensor = prim::GetAttr[name="weight"](%3410)
  %3413 : Float(128:1, 512:128) = aten::t(%3412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.250 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.319, %3413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.320 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.250, %3411, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.321 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3417 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20754.NoNorm = prim::GetAttr[name="LayerNorm"](%3408)
  %3418 : __torch__.torch.nn.modules.linear.___torch_mangle_20753.Linear = prim::GetAttr[name="dense"](%3408)
  %3419 : Tensor = prim::GetAttr[name="bias"](%3418)
  %3420 : Tensor = prim::GetAttr[name="weight"](%3418)
  %3421 : Float(512:1, 128:512) = aten::t(%3420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.251 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.321, %3421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.251, %3419, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.134 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.83, %input.319, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3425 : Tensor = prim::GetAttr[name="bias"](%3417)
  %3426 : Tensor = prim::GetAttr[name="weight"](%3417)
  %3427 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.134, %3426), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.322 : Float(17:1664, 13:128, 128:1) = aten::add(%3427, %3425, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3429 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20761.FFNOutput = prim::GetAttr[name="output"](%3289)
  %3430 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20758.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3289)
  %3431 : __torch__.torch.nn.modules.linear.___torch_mangle_20757.Linear = prim::GetAttr[name="dense"](%3430)
  %3432 : Tensor = prim::GetAttr[name="bias"](%3431)
  %3433 : Tensor = prim::GetAttr[name="weight"](%3431)
  %3434 : Float(128:1, 512:128) = aten::t(%3433), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.252 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.322, %3434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.323 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.252, %3432, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.324 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3438 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20760.NoNorm = prim::GetAttr[name="LayerNorm"](%3429)
  %3439 : __torch__.torch.nn.modules.linear.___torch_mangle_20759.Linear = prim::GetAttr[name="dense"](%3429)
  %3440 : Tensor = prim::GetAttr[name="bias"](%3439)
  %3441 : Tensor = prim::GetAttr[name="weight"](%3439)
  %3442 : Float(512:1, 128:512) = aten::t(%3441), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.253 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.324, %3442), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.84 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.253, %3440, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.135 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.84, %input.322, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3446 : Tensor = prim::GetAttr[name="bias"](%3438)
  %3447 : Tensor = prim::GetAttr[name="weight"](%3438)
  %3448 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.135, %3447), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.325 : Float(17:1664, 13:128, 128:1) = aten::add(%3448, %3446, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3450 : __torch__.torch.nn.modules.linear.___torch_mangle_20729.Linear = prim::GetAttr[name="dense"](%3287)
  %3451 : Tensor = prim::GetAttr[name="bias"](%3450)
  %3452 : Tensor = prim::GetAttr[name="weight"](%3450)
  %3453 : Float(128:1, 512:128) = aten::t(%3452), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %output.254 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.325, %3453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %input.326 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.254, %3451, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1678:0
  %input.327 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate # torch/nn/functional.py:1119:0
  %3457 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20736.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3286)
  %3458 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20732.NoNorm = prim::GetAttr[name="LayerNorm"](%3286)
  %3459 : __torch__.torch.nn.modules.linear.___torch_mangle_20731.Linear = prim::GetAttr[name="dense"](%3286)
  %3460 : Tensor = prim::GetAttr[name="bias"](%3459)
  %3461 : Tensor = prim::GetAttr[name="weight"](%3459)
  %3462 : Float(512:1, 128:512) = aten::t(%3461), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %output.255 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.327, %3462), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %layer_output.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.255, %3460, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.136 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.17, %input.325, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output # transformers/modeling_mobilebert.py:405:0
  %3466 : Tensor = prim::GetAttr[name="bias"](%3458)
  %3467 : Tensor = prim::GetAttr[name="weight"](%3458)
  %3468 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.136, %3467), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.328 : Float(17:1664, 13:128, 128:1) = aten::add(%3468, %3466, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3470 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20734.NoNorm = prim::GetAttr[name="LayerNorm"](%3457)
  %3471 : __torch__.torch.nn.modules.linear.___torch_mangle_20733.Linear = prim::GetAttr[name="dense"](%3457)
  %3472 : Tensor = prim::GetAttr[name="bias"](%3471)
  %3473 : Tensor = prim::GetAttr[name="weight"](%3471)
  %3474 : Float(128:1, 512:128) = aten::t(%3473), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.256 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.328, %3474), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.329 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.256, %3472, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.85 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.329, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.137 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.85, %input.311, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3479 : Tensor = prim::GetAttr[name="bias"](%3470)
  %3480 : Tensor = prim::GetAttr[name="weight"](%3470)
  %3481 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.137, %3480), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.330 : Float(17:6656, 13:512, 512:1) = aten::add(%3481, %3479, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3483 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20782.MobileBertOutput = prim::GetAttr[name="output"](%99)
  %3484 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20775.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%99)
  %3485 : __torch__.torch.nn.modules.container.___torch_mangle_20808.ModuleList = prim::GetAttr[name="ffn"](%99)
  %3486 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20807.FFNLayer = prim::GetAttr[name="2"](%3485)
  %3487 : __torch__.torch.nn.modules.container.___torch_mangle_20808.ModuleList = prim::GetAttr[name="ffn"](%99)
  %3488 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20801.FFNLayer = prim::GetAttr[name="1"](%3487)
  %3489 : __torch__.torch.nn.modules.container.___torch_mangle_20808.ModuleList = prim::GetAttr[name="ffn"](%99)
  %3490 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20795.FFNLayer = prim::GetAttr[name="0"](%3489)
  %3491 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20773.MobileBertAttention = prim::GetAttr[name="attention"](%99)
  %3492 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20789.Bottleneck = prim::GetAttr[name="bottleneck"](%99)
  %3493 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20788.BottleneckLayer = prim::GetAttr[name="attention"](%3492)
  %3494 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20785.BottleneckLayer = prim::GetAttr[name="input"](%3492)
  %3495 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20784.NoNorm = prim::GetAttr[name="LayerNorm"](%3494)
  %3496 : __torch__.torch.nn.modules.linear.___torch_mangle_20783.Linear = prim::GetAttr[name="dense"](%3494)
  %3497 : Tensor = prim::GetAttr[name="bias"](%3496)
  %3498 : Tensor = prim::GetAttr[name="weight"](%3496)
  %3499 : Float(512:1, 128:512) = aten::t(%3498), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.257 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3499), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.138 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.257, %3497, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3502 : Tensor = prim::GetAttr[name="bias"](%3495)
  %3503 : Tensor = prim::GetAttr[name="weight"](%3495)
  %3504 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.138, %3503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add(%3504, %3502, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20787.NoNorm = prim::GetAttr[name="LayerNorm"](%3493)
  %3507 : __torch__.torch.nn.modules.linear.___torch_mangle_20786.Linear = prim::GetAttr[name="dense"](%3493)
  %3508 : Tensor = prim::GetAttr[name="bias"](%3507)
  %3509 : Tensor = prim::GetAttr[name="weight"](%3507)
  %3510 : Float(512:1, 128:512) = aten::t(%3509), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.258 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.258, %3508, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3513 : Tensor = prim::GetAttr[name="bias"](%3506)
  %3514 : Tensor = prim::GetAttr[name="weight"](%3506)
  %3515 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.139, %3514), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.331 : Float(17:1664, 13:128, 128:1) = aten::add(%3515, %3513, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3517 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.331, %residual_tensor.18)
  %3518 : Float(17:1664, 13:128, 128:1), %3519 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3517)
  %3520 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20772.MobileBertSelfOutput = prim::GetAttr[name="output"](%3491)
  %3521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20769.MobileBertSelfAttention = prim::GetAttr[name="self"](%3491)
  %3522 : __torch__.torch.nn.modules.linear.___torch_mangle_20767.Linear = prim::GetAttr[name="value"](%3521)
  %3523 : __torch__.torch.nn.modules.linear.___torch_mangle_20766.Linear = prim::GetAttr[name="key"](%3521)
  %3524 : __torch__.torch.nn.modules.linear.___torch_mangle_20765.Linear = prim::GetAttr[name="query"](%3521)
  %3525 : Tensor = prim::GetAttr[name="bias"](%3524)
  %3526 : Tensor = prim::GetAttr[name="weight"](%3524)
  %3527 : Float(128:1, 128:128) = aten::t(%3526), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %output.259 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3518, %3527), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %x.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.259, %3525, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1678:0
  %3530 : Tensor = prim::GetAttr[name="bias"](%3523)
  %3531 : Tensor = prim::GetAttr[name="weight"](%3523)
  %3532 : Float(128:1, 128:128) = aten::t(%3531), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %output.260 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3518, %3532), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %x.105 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.260, %3530, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1678:0
  %3535 : Tensor = prim::GetAttr[name="bias"](%3522)
  %3536 : Tensor = prim::GetAttr[name="weight"](%3522)
  %3537 : Float(512:1, 128:512) = aten::t(%3536), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %output.261 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3537), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %x.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.261, %3535, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1678:0
  %3540 : int = aten::size(%x.103, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3541 : int = aten::size(%x.103, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3542 : int[] = prim::ListConstruct(%3540, %3541, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.104 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.103, %3542), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3544 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %query_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.104, %3544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3546 : int = aten::size(%x.105, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3547 : int = aten::size(%x.105, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3548 : int[] = prim::ListConstruct(%3546, %3547, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.106 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.105, %3548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3550 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %key_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.106, %3550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3552 : int = aten::size(%x.107, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3553 : int = aten::size(%x.107, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3554 : int[] = prim::ListConstruct(%3552, %3553, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.108 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.107, %3554), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3556 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %value_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.108, %3556), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3558 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.18, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.35 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.18, %3558), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.36 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.35, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.332 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.36, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.333 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.332, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.333, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.35 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.18, %value_layer.18), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:280:0
  %3565 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %3566 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.35, %3565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3566, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %3568 : int = aten::size(%context_layer.36, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3569 : int = aten::size(%context_layer.36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3570 : int[] = prim::ListConstruct(%3568, %3569, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %input.334 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.36, %3570), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:283:0
  %3572 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20771.NoNorm = prim::GetAttr[name="LayerNorm"](%3520)
  %3573 : __torch__.torch.nn.modules.linear.___torch_mangle_20770.Linear = prim::GetAttr[name="dense"](%3520)
  %3574 : Tensor = prim::GetAttr[name="bias"](%3573)
  %3575 : Tensor = prim::GetAttr[name="weight"](%3573)
  %3576 : Float(128:1, 128:128) = aten::t(%3575), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %output.262 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.334, %3576), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.86 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.262, %3574, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.140 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.86, %3519, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output # transformers/modeling_mobilebert.py:301:0
  %3580 : Tensor = prim::GetAttr[name="bias"](%3572)
  %3581 : Tensor = prim::GetAttr[name="weight"](%3572)
  %3582 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.140, %3581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.335 : Float(17:1664, 13:128, 128:1) = aten::add(%3582, %3580, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3584 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20794.FFNOutput = prim::GetAttr[name="output"](%3490)
  %3585 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20791.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3490)
  %3586 : __torch__.torch.nn.modules.linear.___torch_mangle_20790.Linear = prim::GetAttr[name="dense"](%3585)
  %3587 : Tensor = prim::GetAttr[name="bias"](%3586)
  %3588 : Tensor = prim::GetAttr[name="weight"](%3586)
  %3589 : Float(128:1, 512:128) = aten::t(%3588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.263 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.335, %3589), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.336 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.263, %3587, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.337 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3593 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20793.NoNorm = prim::GetAttr[name="LayerNorm"](%3584)
  %3594 : __torch__.torch.nn.modules.linear.___torch_mangle_20792.Linear = prim::GetAttr[name="dense"](%3584)
  %3595 : Tensor = prim::GetAttr[name="bias"](%3594)
  %3596 : Tensor = prim::GetAttr[name="weight"](%3594)
  %3597 : Float(512:1, 128:512) = aten::t(%3596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.264 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.337, %3597), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.264, %3595, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.141 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.87, %input.335, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3601 : Tensor = prim::GetAttr[name="bias"](%3593)
  %3602 : Tensor = prim::GetAttr[name="weight"](%3593)
  %3603 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.141, %3602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.338 : Float(17:1664, 13:128, 128:1) = aten::add(%3603, %3601, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3605 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20800.FFNOutput = prim::GetAttr[name="output"](%3488)
  %3606 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20797.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3488)
  %3607 : __torch__.torch.nn.modules.linear.___torch_mangle_20796.Linear = prim::GetAttr[name="dense"](%3606)
  %3608 : Tensor = prim::GetAttr[name="bias"](%3607)
  %3609 : Tensor = prim::GetAttr[name="weight"](%3607)
  %3610 : Float(128:1, 512:128) = aten::t(%3609), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.265 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.338, %3610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.339 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.265, %3608, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.340 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3614 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20799.NoNorm = prim::GetAttr[name="LayerNorm"](%3605)
  %3615 : __torch__.torch.nn.modules.linear.___torch_mangle_20798.Linear = prim::GetAttr[name="dense"](%3605)
  %3616 : Tensor = prim::GetAttr[name="bias"](%3615)
  %3617 : Tensor = prim::GetAttr[name="weight"](%3615)
  %3618 : Float(512:1, 128:512) = aten::t(%3617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.266 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.340, %3618), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.88 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.266, %3616, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.142 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.88, %input.338, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3622 : Tensor = prim::GetAttr[name="bias"](%3614)
  %3623 : Tensor = prim::GetAttr[name="weight"](%3614)
  %3624 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.142, %3623), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.341 : Float(17:1664, 13:128, 128:1) = aten::add(%3624, %3622, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3626 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20806.FFNOutput = prim::GetAttr[name="output"](%3486)
  %3627 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20803.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3486)
  %3628 : __torch__.torch.nn.modules.linear.___torch_mangle_20802.Linear = prim::GetAttr[name="dense"](%3627)
  %3629 : Tensor = prim::GetAttr[name="bias"](%3628)
  %3630 : Tensor = prim::GetAttr[name="weight"](%3628)
  %3631 : Float(128:1, 512:128) = aten::t(%3630), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.267 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.341, %3631), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.342 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.267, %3629, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.343 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3635 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20805.NoNorm = prim::GetAttr[name="LayerNorm"](%3626)
  %3636 : __torch__.torch.nn.modules.linear.___torch_mangle_20804.Linear = prim::GetAttr[name="dense"](%3626)
  %3637 : Tensor = prim::GetAttr[name="bias"](%3636)
  %3638 : Tensor = prim::GetAttr[name="weight"](%3636)
  %3639 : Float(512:1, 128:512) = aten::t(%3638), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.268 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.343, %3639), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.268, %3637, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.143 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.89, %input.341, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3643 : Tensor = prim::GetAttr[name="bias"](%3635)
  %3644 : Tensor = prim::GetAttr[name="weight"](%3635)
  %3645 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.143, %3644), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.344 : Float(17:1664, 13:128, 128:1) = aten::add(%3645, %3643, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3647 : __torch__.torch.nn.modules.linear.___torch_mangle_20774.Linear = prim::GetAttr[name="dense"](%3484)
  %3648 : Tensor = prim::GetAttr[name="bias"](%3647)
  %3649 : Tensor = prim::GetAttr[name="weight"](%3647)
  %3650 : Float(128:1, 512:128) = aten::t(%3649), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %output.269 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.344, %3650), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %input.345 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.269, %3648, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1678:0
  %input.346 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate # torch/nn/functional.py:1119:0
  %3654 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20781.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3483)
  %3655 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20777.NoNorm = prim::GetAttr[name="LayerNorm"](%3483)
  %3656 : __torch__.torch.nn.modules.linear.___torch_mangle_20776.Linear = prim::GetAttr[name="dense"](%3483)
  %3657 : Tensor = prim::GetAttr[name="bias"](%3656)
  %3658 : Tensor = prim::GetAttr[name="weight"](%3656)
  %3659 : Float(512:1, 128:512) = aten::t(%3658), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %output.270 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.346, %3659), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %layer_output.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.270, %3657, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.144 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.18, %input.344, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output # transformers/modeling_mobilebert.py:405:0
  %3663 : Tensor = prim::GetAttr[name="bias"](%3655)
  %3664 : Tensor = prim::GetAttr[name="weight"](%3655)
  %3665 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.144, %3664), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.347 : Float(17:1664, 13:128, 128:1) = aten::add(%3665, %3663, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3667 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20779.NoNorm = prim::GetAttr[name="LayerNorm"](%3654)
  %3668 : __torch__.torch.nn.modules.linear.___torch_mangle_20778.Linear = prim::GetAttr[name="dense"](%3654)
  %3669 : Tensor = prim::GetAttr[name="bias"](%3668)
  %3670 : Tensor = prim::GetAttr[name="weight"](%3668)
  %3671 : Float(128:1, 512:128) = aten::t(%3670), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.271 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.347, %3671), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.348 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.271, %3669, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.90 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.348, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.145 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.90, %input.330, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3676 : Tensor = prim::GetAttr[name="bias"](%3667)
  %3677 : Tensor = prim::GetAttr[name="weight"](%3667)
  %3678 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.145, %3677), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.349 : Float(17:6656, 13:512, 512:1) = aten::add(%3678, %3676, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3680 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20827.MobileBertOutput = prim::GetAttr[name="output"](%97)
  %3681 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20820.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%97)
  %3682 : __torch__.torch.nn.modules.container.___torch_mangle_20853.ModuleList = prim::GetAttr[name="ffn"](%97)
  %3683 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20852.FFNLayer = prim::GetAttr[name="2"](%3682)
  %3684 : __torch__.torch.nn.modules.container.___torch_mangle_20853.ModuleList = prim::GetAttr[name="ffn"](%97)
  %3685 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20846.FFNLayer = prim::GetAttr[name="1"](%3684)
  %3686 : __torch__.torch.nn.modules.container.___torch_mangle_20853.ModuleList = prim::GetAttr[name="ffn"](%97)
  %3687 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20840.FFNLayer = prim::GetAttr[name="0"](%3686)
  %3688 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20818.MobileBertAttention = prim::GetAttr[name="attention"](%97)
  %3689 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20834.Bottleneck = prim::GetAttr[name="bottleneck"](%97)
  %3690 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20833.BottleneckLayer = prim::GetAttr[name="attention"](%3689)
  %3691 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20830.BottleneckLayer = prim::GetAttr[name="input"](%3689)
  %3692 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20829.NoNorm = prim::GetAttr[name="LayerNorm"](%3691)
  %3693 : __torch__.torch.nn.modules.linear.___torch_mangle_20828.Linear = prim::GetAttr[name="dense"](%3691)
  %3694 : Tensor = prim::GetAttr[name="bias"](%3693)
  %3695 : Tensor = prim::GetAttr[name="weight"](%3693)
  %3696 : Float(512:1, 128:512) = aten::t(%3695), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.272 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3696), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.146 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.272, %3694, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3699 : Tensor = prim::GetAttr[name="bias"](%3692)
  %3700 : Tensor = prim::GetAttr[name="weight"](%3692)
  %3701 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.146, %3700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add(%3701, %3699, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20832.NoNorm = prim::GetAttr[name="LayerNorm"](%3690)
  %3704 : __torch__.torch.nn.modules.linear.___torch_mangle_20831.Linear = prim::GetAttr[name="dense"](%3690)
  %3705 : Tensor = prim::GetAttr[name="bias"](%3704)
  %3706 : Tensor = prim::GetAttr[name="weight"](%3704)
  %3707 : Float(512:1, 128:512) = aten::t(%3706), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.273 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.147 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.273, %3705, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3710 : Tensor = prim::GetAttr[name="bias"](%3703)
  %3711 : Tensor = prim::GetAttr[name="weight"](%3703)
  %3712 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.147, %3711), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.350 : Float(17:1664, 13:128, 128:1) = aten::add(%3712, %3710, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3714 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.350, %residual_tensor.19)
  %3715 : Float(17:1664, 13:128, 128:1), %3716 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3714)
  %3717 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20817.MobileBertSelfOutput = prim::GetAttr[name="output"](%3688)
  %3718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20814.MobileBertSelfAttention = prim::GetAttr[name="self"](%3688)
  %3719 : __torch__.torch.nn.modules.linear.___torch_mangle_20812.Linear = prim::GetAttr[name="value"](%3718)
  %3720 : __torch__.torch.nn.modules.linear.___torch_mangle_20811.Linear = prim::GetAttr[name="key"](%3718)
  %3721 : __torch__.torch.nn.modules.linear.___torch_mangle_20810.Linear = prim::GetAttr[name="query"](%3718)
  %3722 : Tensor = prim::GetAttr[name="bias"](%3721)
  %3723 : Tensor = prim::GetAttr[name="weight"](%3721)
  %3724 : Float(128:1, 128:128) = aten::t(%3723), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %output.274 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3715, %3724), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %x.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.274, %3722, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1678:0
  %3727 : Tensor = prim::GetAttr[name="bias"](%3720)
  %3728 : Tensor = prim::GetAttr[name="weight"](%3720)
  %3729 : Float(128:1, 128:128) = aten::t(%3728), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %output.275 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3715, %3729), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %x.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.275, %3727, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1678:0
  %3732 : Tensor = prim::GetAttr[name="bias"](%3719)
  %3733 : Tensor = prim::GetAttr[name="weight"](%3719)
  %3734 : Float(512:1, 128:512) = aten::t(%3733), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %output.276 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3734), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %x.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.276, %3732, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1678:0
  %3737 : int = aten::size(%x.109, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3738 : int = aten::size(%x.109, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3739 : int[] = prim::ListConstruct(%3737, %3738, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.110 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.109, %3739), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3741 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %query_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.110, %3741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3743 : int = aten::size(%x.111, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3744 : int = aten::size(%x.111, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3745 : int[] = prim::ListConstruct(%3743, %3744, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.112 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.111, %3745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3747 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %key_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.112, %3747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3749 : int = aten::size(%x.113, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3750 : int = aten::size(%x.113, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3751 : int[] = prim::ListConstruct(%3749, %3750, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.114 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.113, %3751), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3753 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %value_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.114, %3753), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3755 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.19, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.37 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.19, %3755), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.38 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.37, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.351 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.38, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.352 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.351, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.352, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.37 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.19, %value_layer.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:280:0
  %3762 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %3763 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.37, %3762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3763, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %3765 : int = aten::size(%context_layer.38, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3766 : int = aten::size(%context_layer.38, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3767 : int[] = prim::ListConstruct(%3765, %3766, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %input.353 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.38, %3767), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:283:0
  %3769 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20816.NoNorm = prim::GetAttr[name="LayerNorm"](%3717)
  %3770 : __torch__.torch.nn.modules.linear.___torch_mangle_20815.Linear = prim::GetAttr[name="dense"](%3717)
  %3771 : Tensor = prim::GetAttr[name="bias"](%3770)
  %3772 : Tensor = prim::GetAttr[name="weight"](%3770)
  %3773 : Float(128:1, 128:128) = aten::t(%3772), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %output.277 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.353, %3773), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.277, %3771, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.148 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.91, %3716, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output # transformers/modeling_mobilebert.py:301:0
  %3777 : Tensor = prim::GetAttr[name="bias"](%3769)
  %3778 : Tensor = prim::GetAttr[name="weight"](%3769)
  %3779 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.148, %3778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.354 : Float(17:1664, 13:128, 128:1) = aten::add(%3779, %3777, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3781 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20839.FFNOutput = prim::GetAttr[name="output"](%3687)
  %3782 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20836.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3687)
  %3783 : __torch__.torch.nn.modules.linear.___torch_mangle_20835.Linear = prim::GetAttr[name="dense"](%3782)
  %3784 : Tensor = prim::GetAttr[name="bias"](%3783)
  %3785 : Tensor = prim::GetAttr[name="weight"](%3783)
  %3786 : Float(128:1, 512:128) = aten::t(%3785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.278 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.354, %3786), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.355 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.278, %3784, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.356 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3790 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20838.NoNorm = prim::GetAttr[name="LayerNorm"](%3781)
  %3791 : __torch__.torch.nn.modules.linear.___torch_mangle_20837.Linear = prim::GetAttr[name="dense"](%3781)
  %3792 : Tensor = prim::GetAttr[name="bias"](%3791)
  %3793 : Tensor = prim::GetAttr[name="weight"](%3791)
  %3794 : Float(512:1, 128:512) = aten::t(%3793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.279 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.356, %3794), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.92 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.279, %3792, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.149 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.92, %input.354, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3798 : Tensor = prim::GetAttr[name="bias"](%3790)
  %3799 : Tensor = prim::GetAttr[name="weight"](%3790)
  %3800 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.149, %3799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.357 : Float(17:1664, 13:128, 128:1) = aten::add(%3800, %3798, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3802 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20845.FFNOutput = prim::GetAttr[name="output"](%3685)
  %3803 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20842.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3685)
  %3804 : __torch__.torch.nn.modules.linear.___torch_mangle_20841.Linear = prim::GetAttr[name="dense"](%3803)
  %3805 : Tensor = prim::GetAttr[name="bias"](%3804)
  %3806 : Tensor = prim::GetAttr[name="weight"](%3804)
  %3807 : Float(128:1, 512:128) = aten::t(%3806), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.280 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.357, %3807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.358 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.280, %3805, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.359 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3811 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20844.NoNorm = prim::GetAttr[name="LayerNorm"](%3802)
  %3812 : __torch__.torch.nn.modules.linear.___torch_mangle_20843.Linear = prim::GetAttr[name="dense"](%3802)
  %3813 : Tensor = prim::GetAttr[name="bias"](%3812)
  %3814 : Tensor = prim::GetAttr[name="weight"](%3812)
  %3815 : Float(512:1, 128:512) = aten::t(%3814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.281 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.359, %3815), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.281, %3813, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.150 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.93, %input.357, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3819 : Tensor = prim::GetAttr[name="bias"](%3811)
  %3820 : Tensor = prim::GetAttr[name="weight"](%3811)
  %3821 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.150, %3820), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.360 : Float(17:1664, 13:128, 128:1) = aten::add(%3821, %3819, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3823 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20851.FFNOutput = prim::GetAttr[name="output"](%3683)
  %3824 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20848.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3683)
  %3825 : __torch__.torch.nn.modules.linear.___torch_mangle_20847.Linear = prim::GetAttr[name="dense"](%3824)
  %3826 : Tensor = prim::GetAttr[name="bias"](%3825)
  %3827 : Tensor = prim::GetAttr[name="weight"](%3825)
  %3828 : Float(128:1, 512:128) = aten::t(%3827), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.282 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.360, %3828), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.361 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.282, %3826, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.362 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3832 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20850.NoNorm = prim::GetAttr[name="LayerNorm"](%3823)
  %3833 : __torch__.torch.nn.modules.linear.___torch_mangle_20849.Linear = prim::GetAttr[name="dense"](%3823)
  %3834 : Tensor = prim::GetAttr[name="bias"](%3833)
  %3835 : Tensor = prim::GetAttr[name="weight"](%3833)
  %3836 : Float(512:1, 128:512) = aten::t(%3835), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.283 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.362, %3836), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.94 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.283, %3834, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.151 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.94, %input.360, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3840 : Tensor = prim::GetAttr[name="bias"](%3832)
  %3841 : Tensor = prim::GetAttr[name="weight"](%3832)
  %3842 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.151, %3841), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.363 : Float(17:1664, 13:128, 128:1) = aten::add(%3842, %3840, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3844 : __torch__.torch.nn.modules.linear.___torch_mangle_20819.Linear = prim::GetAttr[name="dense"](%3681)
  %3845 : Tensor = prim::GetAttr[name="bias"](%3844)
  %3846 : Tensor = prim::GetAttr[name="weight"](%3844)
  %3847 : Float(128:1, 512:128) = aten::t(%3846), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %output.284 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.363, %3847), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %input.364 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.284, %3845, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1678:0
  %input.365 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate # torch/nn/functional.py:1119:0
  %3851 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20826.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3680)
  %3852 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20822.NoNorm = prim::GetAttr[name="LayerNorm"](%3680)
  %3853 : __torch__.torch.nn.modules.linear.___torch_mangle_20821.Linear = prim::GetAttr[name="dense"](%3680)
  %3854 : Tensor = prim::GetAttr[name="bias"](%3853)
  %3855 : Tensor = prim::GetAttr[name="weight"](%3853)
  %3856 : Float(512:1, 128:512) = aten::t(%3855), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %output.285 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.365, %3856), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %layer_output.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.285, %3854, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.152 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.19, %input.363, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output # transformers/modeling_mobilebert.py:405:0
  %3860 : Tensor = prim::GetAttr[name="bias"](%3852)
  %3861 : Tensor = prim::GetAttr[name="weight"](%3852)
  %3862 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.152, %3861), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.366 : Float(17:1664, 13:128, 128:1) = aten::add(%3862, %3860, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3864 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20824.NoNorm = prim::GetAttr[name="LayerNorm"](%3851)
  %3865 : __torch__.torch.nn.modules.linear.___torch_mangle_20823.Linear = prim::GetAttr[name="dense"](%3851)
  %3866 : Tensor = prim::GetAttr[name="bias"](%3865)
  %3867 : Tensor = prim::GetAttr[name="weight"](%3865)
  %3868 : Float(128:1, 512:128) = aten::t(%3867), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.286 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.366, %3868), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.367 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.286, %3866, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.95 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.367, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.153 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.95, %input.349, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3873 : Tensor = prim::GetAttr[name="bias"](%3864)
  %3874 : Tensor = prim::GetAttr[name="weight"](%3864)
  %3875 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.153, %3874), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.368 : Float(17:6656, 13:512, 512:1) = aten::add(%3875, %3873, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3877 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20872.MobileBertOutput = prim::GetAttr[name="output"](%95)
  %3878 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20865.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%95)
  %3879 : __torch__.torch.nn.modules.container.___torch_mangle_20898.ModuleList = prim::GetAttr[name="ffn"](%95)
  %3880 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20897.FFNLayer = prim::GetAttr[name="2"](%3879)
  %3881 : __torch__.torch.nn.modules.container.___torch_mangle_20898.ModuleList = prim::GetAttr[name="ffn"](%95)
  %3882 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20891.FFNLayer = prim::GetAttr[name="1"](%3881)
  %3883 : __torch__.torch.nn.modules.container.___torch_mangle_20898.ModuleList = prim::GetAttr[name="ffn"](%95)
  %3884 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20885.FFNLayer = prim::GetAttr[name="0"](%3883)
  %3885 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20863.MobileBertAttention = prim::GetAttr[name="attention"](%95)
  %3886 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20879.Bottleneck = prim::GetAttr[name="bottleneck"](%95)
  %3887 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20878.BottleneckLayer = prim::GetAttr[name="attention"](%3886)
  %3888 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20875.BottleneckLayer = prim::GetAttr[name="input"](%3886)
  %3889 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20874.NoNorm = prim::GetAttr[name="LayerNorm"](%3888)
  %3890 : __torch__.torch.nn.modules.linear.___torch_mangle_20873.Linear = prim::GetAttr[name="dense"](%3888)
  %3891 : Tensor = prim::GetAttr[name="bias"](%3890)
  %3892 : Tensor = prim::GetAttr[name="weight"](%3890)
  %3893 : Float(512:1, 128:512) = aten::t(%3892), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.287 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3893), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.154 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.287, %3891, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3896 : Tensor = prim::GetAttr[name="bias"](%3889)
  %3897 : Tensor = prim::GetAttr[name="weight"](%3889)
  %3898 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.154, %3897), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%3898, %3896, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3900 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20877.NoNorm = prim::GetAttr[name="LayerNorm"](%3887)
  %3901 : __torch__.torch.nn.modules.linear.___torch_mangle_20876.Linear = prim::GetAttr[name="dense"](%3887)
  %3902 : Tensor = prim::GetAttr[name="bias"](%3901)
  %3903 : Tensor = prim::GetAttr[name="weight"](%3901)
  %3904 : Float(512:1, 128:512) = aten::t(%3903), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.288 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3904), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.155 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.288, %3902, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3907 : Tensor = prim::GetAttr[name="bias"](%3900)
  %3908 : Tensor = prim::GetAttr[name="weight"](%3900)
  %3909 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.155, %3908), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.369 : Float(17:1664, 13:128, 128:1) = aten::add(%3909, %3907, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3911 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.369, %residual_tensor.20)
  %3912 : Float(17:1664, 13:128, 128:1), %3913 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3911)
  %3914 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20862.MobileBertSelfOutput = prim::GetAttr[name="output"](%3885)
  %3915 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20859.MobileBertSelfAttention = prim::GetAttr[name="self"](%3885)
  %3916 : __torch__.torch.nn.modules.linear.___torch_mangle_20857.Linear = prim::GetAttr[name="value"](%3915)
  %3917 : __torch__.torch.nn.modules.linear.___torch_mangle_20856.Linear = prim::GetAttr[name="key"](%3915)
  %3918 : __torch__.torch.nn.modules.linear.___torch_mangle_20855.Linear = prim::GetAttr[name="query"](%3915)
  %3919 : Tensor = prim::GetAttr[name="bias"](%3918)
  %3920 : Tensor = prim::GetAttr[name="weight"](%3918)
  %3921 : Float(128:1, 128:128) = aten::t(%3920), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %output.289 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3912, %3921), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %x.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.289, %3919, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1678:0
  %3924 : Tensor = prim::GetAttr[name="bias"](%3917)
  %3925 : Tensor = prim::GetAttr[name="weight"](%3917)
  %3926 : Float(128:1, 128:128) = aten::t(%3925), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %output.290 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3912, %3926), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %x.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.290, %3924, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1678:0
  %3929 : Tensor = prim::GetAttr[name="bias"](%3916)
  %3930 : Tensor = prim::GetAttr[name="weight"](%3916)
  %3931 : Float(512:1, 128:512) = aten::t(%3930), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %output.291 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3931), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %x.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.291, %3929, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1678:0
  %3934 : int = aten::size(%x.115, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3935 : int = aten::size(%x.115, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3936 : int[] = prim::ListConstruct(%3934, %3935, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.116 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.115, %3936), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3938 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %query_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.116, %3938), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3940 : int = aten::size(%x.117, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3941 : int = aten::size(%x.117, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3942 : int[] = prim::ListConstruct(%3940, %3941, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.118 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.117, %3942), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3944 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %key_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.118, %3944), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3946 : int = aten::size(%x.119, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3947 : int = aten::size(%x.119, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3948 : int[] = prim::ListConstruct(%3946, %3947, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.120 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.119, %3948), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3950 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %value_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.120, %3950), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3952 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.20, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.39 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.20, %3952), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.40 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.39, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.370 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.40, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.371 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.370, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.371, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.39 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.20, %value_layer.20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:280:0
  %3959 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %3960 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.39, %3959), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3960, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %3962 : int = aten::size(%context_layer.40, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3963 : int = aten::size(%context_layer.40, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3964 : int[] = prim::ListConstruct(%3962, %3963, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %input.372 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.40, %3964), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:283:0
  %3966 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20861.NoNorm = prim::GetAttr[name="LayerNorm"](%3914)
  %3967 : __torch__.torch.nn.modules.linear.___torch_mangle_20860.Linear = prim::GetAttr[name="dense"](%3914)
  %3968 : Tensor = prim::GetAttr[name="bias"](%3967)
  %3969 : Tensor = prim::GetAttr[name="weight"](%3967)
  %3970 : Float(128:1, 128:128) = aten::t(%3969), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %output.292 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.372, %3970), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.96 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.292, %3968, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.156 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.96, %3913, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output # transformers/modeling_mobilebert.py:301:0
  %3974 : Tensor = prim::GetAttr[name="bias"](%3966)
  %3975 : Tensor = prim::GetAttr[name="weight"](%3966)
  %3976 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.156, %3975), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.373 : Float(17:1664, 13:128, 128:1) = aten::add(%3976, %3974, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3978 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20884.FFNOutput = prim::GetAttr[name="output"](%3884)
  %3979 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20881.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3884)
  %3980 : __torch__.torch.nn.modules.linear.___torch_mangle_20880.Linear = prim::GetAttr[name="dense"](%3979)
  %3981 : Tensor = prim::GetAttr[name="bias"](%3980)
  %3982 : Tensor = prim::GetAttr[name="weight"](%3980)
  %3983 : Float(128:1, 512:128) = aten::t(%3982), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.293 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.373, %3983), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.374 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.293, %3981, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.375 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3987 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20883.NoNorm = prim::GetAttr[name="LayerNorm"](%3978)
  %3988 : __torch__.torch.nn.modules.linear.___torch_mangle_20882.Linear = prim::GetAttr[name="dense"](%3978)
  %3989 : Tensor = prim::GetAttr[name="bias"](%3988)
  %3990 : Tensor = prim::GetAttr[name="weight"](%3988)
  %3991 : Float(512:1, 128:512) = aten::t(%3990), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.294 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.375, %3991), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.294, %3989, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.157 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.97, %input.373, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3995 : Tensor = prim::GetAttr[name="bias"](%3987)
  %3996 : Tensor = prim::GetAttr[name="weight"](%3987)
  %3997 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.157, %3996), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.376 : Float(17:1664, 13:128, 128:1) = aten::add(%3997, %3995, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3999 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20890.FFNOutput = prim::GetAttr[name="output"](%3882)
  %4000 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20887.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3882)
  %4001 : __torch__.torch.nn.modules.linear.___torch_mangle_20886.Linear = prim::GetAttr[name="dense"](%4000)
  %4002 : Tensor = prim::GetAttr[name="bias"](%4001)
  %4003 : Tensor = prim::GetAttr[name="weight"](%4001)
  %4004 : Float(128:1, 512:128) = aten::t(%4003), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.295 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.376, %4004), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.377 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.295, %4002, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.378 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4008 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20889.NoNorm = prim::GetAttr[name="LayerNorm"](%3999)
  %4009 : __torch__.torch.nn.modules.linear.___torch_mangle_20888.Linear = prim::GetAttr[name="dense"](%3999)
  %4010 : Tensor = prim::GetAttr[name="bias"](%4009)
  %4011 : Tensor = prim::GetAttr[name="weight"](%4009)
  %4012 : Float(512:1, 128:512) = aten::t(%4011), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.296 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.378, %4012), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.296, %4010, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.158 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.98, %input.376, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4016 : Tensor = prim::GetAttr[name="bias"](%4008)
  %4017 : Tensor = prim::GetAttr[name="weight"](%4008)
  %4018 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.158, %4017), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.379 : Float(17:1664, 13:128, 128:1) = aten::add(%4018, %4016, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4020 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20896.FFNOutput = prim::GetAttr[name="output"](%3880)
  %4021 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20893.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3880)
  %4022 : __torch__.torch.nn.modules.linear.___torch_mangle_20892.Linear = prim::GetAttr[name="dense"](%4021)
  %4023 : Tensor = prim::GetAttr[name="bias"](%4022)
  %4024 : Tensor = prim::GetAttr[name="weight"](%4022)
  %4025 : Float(128:1, 512:128) = aten::t(%4024), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.297 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.379, %4025), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.380 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.297, %4023, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.381 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4029 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20895.NoNorm = prim::GetAttr[name="LayerNorm"](%4020)
  %4030 : __torch__.torch.nn.modules.linear.___torch_mangle_20894.Linear = prim::GetAttr[name="dense"](%4020)
  %4031 : Tensor = prim::GetAttr[name="bias"](%4030)
  %4032 : Tensor = prim::GetAttr[name="weight"](%4030)
  %4033 : Float(512:1, 128:512) = aten::t(%4032), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.298 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.381, %4033), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.298, %4031, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.159 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.99, %input.379, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4037 : Tensor = prim::GetAttr[name="bias"](%4029)
  %4038 : Tensor = prim::GetAttr[name="weight"](%4029)
  %4039 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.159, %4038), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.382 : Float(17:1664, 13:128, 128:1) = aten::add(%4039, %4037, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4041 : __torch__.torch.nn.modules.linear.___torch_mangle_20864.Linear = prim::GetAttr[name="dense"](%3878)
  %4042 : Tensor = prim::GetAttr[name="bias"](%4041)
  %4043 : Tensor = prim::GetAttr[name="weight"](%4041)
  %4044 : Float(128:1, 512:128) = aten::t(%4043), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %output.299 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.382, %4044), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %input.383 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.299, %4042, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1678:0
  %input.384 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate # torch/nn/functional.py:1119:0
  %4048 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20871.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3877)
  %4049 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20867.NoNorm = prim::GetAttr[name="LayerNorm"](%3877)
  %4050 : __torch__.torch.nn.modules.linear.___torch_mangle_20866.Linear = prim::GetAttr[name="dense"](%3877)
  %4051 : Tensor = prim::GetAttr[name="bias"](%4050)
  %4052 : Tensor = prim::GetAttr[name="weight"](%4050)
  %4053 : Float(512:1, 128:512) = aten::t(%4052), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %output.300 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.384, %4053), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %layer_output.20 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.300, %4051, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.160 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.20, %input.382, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output # transformers/modeling_mobilebert.py:405:0
  %4057 : Tensor = prim::GetAttr[name="bias"](%4049)
  %4058 : Tensor = prim::GetAttr[name="weight"](%4049)
  %4059 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.160, %4058), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.385 : Float(17:1664, 13:128, 128:1) = aten::add(%4059, %4057, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4061 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20869.NoNorm = prim::GetAttr[name="LayerNorm"](%4048)
  %4062 : __torch__.torch.nn.modules.linear.___torch_mangle_20868.Linear = prim::GetAttr[name="dense"](%4048)
  %4063 : Tensor = prim::GetAttr[name="bias"](%4062)
  %4064 : Tensor = prim::GetAttr[name="weight"](%4062)
  %4065 : Float(128:1, 512:128) = aten::t(%4064), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.301 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.385, %4065), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.386 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.301, %4063, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.100 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.386, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.161 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.100, %input.368, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4070 : Tensor = prim::GetAttr[name="bias"](%4061)
  %4071 : Tensor = prim::GetAttr[name="weight"](%4061)
  %4072 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.161, %4071), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.387 : Float(17:6656, 13:512, 512:1) = aten::add(%4072, %4070, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4074 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20917.MobileBertOutput = prim::GetAttr[name="output"](%93)
  %4075 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20910.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%93)
  %4076 : __torch__.torch.nn.modules.container.___torch_mangle_20943.ModuleList = prim::GetAttr[name="ffn"](%93)
  %4077 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20942.FFNLayer = prim::GetAttr[name="2"](%4076)
  %4078 : __torch__.torch.nn.modules.container.___torch_mangle_20943.ModuleList = prim::GetAttr[name="ffn"](%93)
  %4079 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20936.FFNLayer = prim::GetAttr[name="1"](%4078)
  %4080 : __torch__.torch.nn.modules.container.___torch_mangle_20943.ModuleList = prim::GetAttr[name="ffn"](%93)
  %4081 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20930.FFNLayer = prim::GetAttr[name="0"](%4080)
  %4082 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20908.MobileBertAttention = prim::GetAttr[name="attention"](%93)
  %4083 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20924.Bottleneck = prim::GetAttr[name="bottleneck"](%93)
  %4084 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20923.BottleneckLayer = prim::GetAttr[name="attention"](%4083)
  %4085 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20920.BottleneckLayer = prim::GetAttr[name="input"](%4083)
  %4086 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20919.NoNorm = prim::GetAttr[name="LayerNorm"](%4085)
  %4087 : __torch__.torch.nn.modules.linear.___torch_mangle_20918.Linear = prim::GetAttr[name="dense"](%4085)
  %4088 : Tensor = prim::GetAttr[name="bias"](%4087)
  %4089 : Tensor = prim::GetAttr[name="weight"](%4087)
  %4090 : Float(512:1, 128:512) = aten::t(%4089), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.302 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4090), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.162 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.302, %4088, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4093 : Tensor = prim::GetAttr[name="bias"](%4086)
  %4094 : Tensor = prim::GetAttr[name="weight"](%4086)
  %4095 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.162, %4094), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%4095, %4093, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4097 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20922.NoNorm = prim::GetAttr[name="LayerNorm"](%4084)
  %4098 : __torch__.torch.nn.modules.linear.___torch_mangle_20921.Linear = prim::GetAttr[name="dense"](%4084)
  %4099 : Tensor = prim::GetAttr[name="bias"](%4098)
  %4100 : Tensor = prim::GetAttr[name="weight"](%4098)
  %4101 : Float(512:1, 128:512) = aten::t(%4100), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.303 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4101), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.163 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.303, %4099, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4104 : Tensor = prim::GetAttr[name="bias"](%4097)
  %4105 : Tensor = prim::GetAttr[name="weight"](%4097)
  %4106 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.163, %4105), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.388 : Float(17:1664, 13:128, 128:1) = aten::add(%4106, %4104, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4108 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.388, %residual_tensor.21)
  %4109 : Float(17:1664, 13:128, 128:1), %4110 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4108)
  %4111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20907.MobileBertSelfOutput = prim::GetAttr[name="output"](%4082)
  %4112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20904.MobileBertSelfAttention = prim::GetAttr[name="self"](%4082)
  %4113 : __torch__.torch.nn.modules.linear.___torch_mangle_20902.Linear = prim::GetAttr[name="value"](%4112)
  %4114 : __torch__.torch.nn.modules.linear.___torch_mangle_20901.Linear = prim::GetAttr[name="key"](%4112)
  %4115 : __torch__.torch.nn.modules.linear.___torch_mangle_20900.Linear = prim::GetAttr[name="query"](%4112)
  %4116 : Tensor = prim::GetAttr[name="bias"](%4115)
  %4117 : Tensor = prim::GetAttr[name="weight"](%4115)
  %4118 : Float(128:1, 128:128) = aten::t(%4117), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %output.304 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4109, %4118), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %x.121 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.304, %4116, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1678:0
  %4121 : Tensor = prim::GetAttr[name="bias"](%4114)
  %4122 : Tensor = prim::GetAttr[name="weight"](%4114)
  %4123 : Float(128:1, 128:128) = aten::t(%4122), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %output.305 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4109, %4123), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %x.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.305, %4121, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1678:0
  %4126 : Tensor = prim::GetAttr[name="bias"](%4113)
  %4127 : Tensor = prim::GetAttr[name="weight"](%4113)
  %4128 : Float(512:1, 128:512) = aten::t(%4127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %output.306 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4128), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %x.125 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.306, %4126, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1678:0
  %4131 : int = aten::size(%x.121, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4132 : int = aten::size(%x.121, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4133 : int[] = prim::ListConstruct(%4131, %4132, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.122 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.121, %4133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4135 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %query_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.122, %4135), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4137 : int = aten::size(%x.123, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4138 : int = aten::size(%x.123, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4139 : int[] = prim::ListConstruct(%4137, %4138, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.124 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.123, %4139), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4141 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %key_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.124, %4141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4143 : int = aten::size(%x.125, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4144 : int = aten::size(%x.125, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4145 : int[] = prim::ListConstruct(%4143, %4144, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.126 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.125, %4145), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4147 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %value_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.126, %4147), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4149 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.21, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.41 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.21, %4149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.42 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.41, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.389 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.42, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.390 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.389, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.390, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.41 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.21, %value_layer.21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:280:0
  %4156 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %4157 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.41, %4156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4157, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %4159 : int = aten::size(%context_layer.42, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4160 : int = aten::size(%context_layer.42, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4161 : int[] = prim::ListConstruct(%4159, %4160, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %input.391 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.42, %4161), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:283:0
  %4163 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20906.NoNorm = prim::GetAttr[name="LayerNorm"](%4111)
  %4164 : __torch__.torch.nn.modules.linear.___torch_mangle_20905.Linear = prim::GetAttr[name="dense"](%4111)
  %4165 : Tensor = prim::GetAttr[name="bias"](%4164)
  %4166 : Tensor = prim::GetAttr[name="weight"](%4164)
  %4167 : Float(128:1, 128:128) = aten::t(%4166), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %output.307 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.391, %4167), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.307, %4165, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.164 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.101, %4110, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output # transformers/modeling_mobilebert.py:301:0
  %4171 : Tensor = prim::GetAttr[name="bias"](%4163)
  %4172 : Tensor = prim::GetAttr[name="weight"](%4163)
  %4173 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.164, %4172), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.392 : Float(17:1664, 13:128, 128:1) = aten::add(%4173, %4171, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4175 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20929.FFNOutput = prim::GetAttr[name="output"](%4081)
  %4176 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20926.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4081)
  %4177 : __torch__.torch.nn.modules.linear.___torch_mangle_20925.Linear = prim::GetAttr[name="dense"](%4176)
  %4178 : Tensor = prim::GetAttr[name="bias"](%4177)
  %4179 : Tensor = prim::GetAttr[name="weight"](%4177)
  %4180 : Float(128:1, 512:128) = aten::t(%4179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.308 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.392, %4180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.393 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.308, %4178, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.394 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4184 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20928.NoNorm = prim::GetAttr[name="LayerNorm"](%4175)
  %4185 : __torch__.torch.nn.modules.linear.___torch_mangle_20927.Linear = prim::GetAttr[name="dense"](%4175)
  %4186 : Tensor = prim::GetAttr[name="bias"](%4185)
  %4187 : Tensor = prim::GetAttr[name="weight"](%4185)
  %4188 : Float(512:1, 128:512) = aten::t(%4187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.309 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.394, %4188), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.102 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.309, %4186, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.165 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.102, %input.392, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4192 : Tensor = prim::GetAttr[name="bias"](%4184)
  %4193 : Tensor = prim::GetAttr[name="weight"](%4184)
  %4194 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.165, %4193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.395 : Float(17:1664, 13:128, 128:1) = aten::add(%4194, %4192, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4196 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20935.FFNOutput = prim::GetAttr[name="output"](%4079)
  %4197 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20932.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4079)
  %4198 : __torch__.torch.nn.modules.linear.___torch_mangle_20931.Linear = prim::GetAttr[name="dense"](%4197)
  %4199 : Tensor = prim::GetAttr[name="bias"](%4198)
  %4200 : Tensor = prim::GetAttr[name="weight"](%4198)
  %4201 : Float(128:1, 512:128) = aten::t(%4200), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.310 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.395, %4201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.396 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.310, %4199, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.397 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4205 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20934.NoNorm = prim::GetAttr[name="LayerNorm"](%4196)
  %4206 : __torch__.torch.nn.modules.linear.___torch_mangle_20933.Linear = prim::GetAttr[name="dense"](%4196)
  %4207 : Tensor = prim::GetAttr[name="bias"](%4206)
  %4208 : Tensor = prim::GetAttr[name="weight"](%4206)
  %4209 : Float(512:1, 128:512) = aten::t(%4208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.311 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.397, %4209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.311, %4207, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.166 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.103, %input.395, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4213 : Tensor = prim::GetAttr[name="bias"](%4205)
  %4214 : Tensor = prim::GetAttr[name="weight"](%4205)
  %4215 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.166, %4214), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.398 : Float(17:1664, 13:128, 128:1) = aten::add(%4215, %4213, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4217 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20941.FFNOutput = prim::GetAttr[name="output"](%4077)
  %4218 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20938.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4077)
  %4219 : __torch__.torch.nn.modules.linear.___torch_mangle_20937.Linear = prim::GetAttr[name="dense"](%4218)
  %4220 : Tensor = prim::GetAttr[name="bias"](%4219)
  %4221 : Tensor = prim::GetAttr[name="weight"](%4219)
  %4222 : Float(128:1, 512:128) = aten::t(%4221), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.312 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.398, %4222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.399 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.312, %4220, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.400 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4226 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20940.NoNorm = prim::GetAttr[name="LayerNorm"](%4217)
  %4227 : __torch__.torch.nn.modules.linear.___torch_mangle_20939.Linear = prim::GetAttr[name="dense"](%4217)
  %4228 : Tensor = prim::GetAttr[name="bias"](%4227)
  %4229 : Tensor = prim::GetAttr[name="weight"](%4227)
  %4230 : Float(512:1, 128:512) = aten::t(%4229), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.313 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.400, %4230), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.104 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.313, %4228, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.167 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.104, %input.398, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4234 : Tensor = prim::GetAttr[name="bias"](%4226)
  %4235 : Tensor = prim::GetAttr[name="weight"](%4226)
  %4236 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.167, %4235), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.401 : Float(17:1664, 13:128, 128:1) = aten::add(%4236, %4234, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4238 : __torch__.torch.nn.modules.linear.___torch_mangle_20909.Linear = prim::GetAttr[name="dense"](%4075)
  %4239 : Tensor = prim::GetAttr[name="bias"](%4238)
  %4240 : Tensor = prim::GetAttr[name="weight"](%4238)
  %4241 : Float(128:1, 512:128) = aten::t(%4240), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %output.314 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.401, %4241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %input.402 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.314, %4239, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1678:0
  %input.403 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate # torch/nn/functional.py:1119:0
  %4245 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20916.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4074)
  %4246 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20912.NoNorm = prim::GetAttr[name="LayerNorm"](%4074)
  %4247 : __torch__.torch.nn.modules.linear.___torch_mangle_20911.Linear = prim::GetAttr[name="dense"](%4074)
  %4248 : Tensor = prim::GetAttr[name="bias"](%4247)
  %4249 : Tensor = prim::GetAttr[name="weight"](%4247)
  %4250 : Float(512:1, 128:512) = aten::t(%4249), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %output.315 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.403, %4250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %layer_output.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.315, %4248, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.168 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.21, %input.401, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output # transformers/modeling_mobilebert.py:405:0
  %4254 : Tensor = prim::GetAttr[name="bias"](%4246)
  %4255 : Tensor = prim::GetAttr[name="weight"](%4246)
  %4256 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.168, %4255), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.404 : Float(17:1664, 13:128, 128:1) = aten::add(%4256, %4254, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4258 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20914.NoNorm = prim::GetAttr[name="LayerNorm"](%4245)
  %4259 : __torch__.torch.nn.modules.linear.___torch_mangle_20913.Linear = prim::GetAttr[name="dense"](%4245)
  %4260 : Tensor = prim::GetAttr[name="bias"](%4259)
  %4261 : Tensor = prim::GetAttr[name="weight"](%4259)
  %4262 : Float(128:1, 512:128) = aten::t(%4261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.316 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.404, %4262), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.405 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.316, %4260, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.105 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.405, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.169 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.105, %input.387, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4267 : Tensor = prim::GetAttr[name="bias"](%4258)
  %4268 : Tensor = prim::GetAttr[name="weight"](%4258)
  %4269 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.169, %4268), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.406 : Float(17:6656, 13:512, 512:1) = aten::add(%4269, %4267, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4271 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20962.MobileBertOutput = prim::GetAttr[name="output"](%91)
  %4272 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20955.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%91)
  %4273 : __torch__.torch.nn.modules.container.___torch_mangle_20988.ModuleList = prim::GetAttr[name="ffn"](%91)
  %4274 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20987.FFNLayer = prim::GetAttr[name="2"](%4273)
  %4275 : __torch__.torch.nn.modules.container.___torch_mangle_20988.ModuleList = prim::GetAttr[name="ffn"](%91)
  %4276 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20981.FFNLayer = prim::GetAttr[name="1"](%4275)
  %4277 : __torch__.torch.nn.modules.container.___torch_mangle_20988.ModuleList = prim::GetAttr[name="ffn"](%91)
  %4278 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20975.FFNLayer = prim::GetAttr[name="0"](%4277)
  %4279 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20953.MobileBertAttention = prim::GetAttr[name="attention"](%91)
  %4280 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20969.Bottleneck = prim::GetAttr[name="bottleneck"](%91)
  %4281 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20968.BottleneckLayer = prim::GetAttr[name="attention"](%4280)
  %4282 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20965.BottleneckLayer = prim::GetAttr[name="input"](%4280)
  %4283 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20964.NoNorm = prim::GetAttr[name="LayerNorm"](%4282)
  %4284 : __torch__.torch.nn.modules.linear.___torch_mangle_20963.Linear = prim::GetAttr[name="dense"](%4282)
  %4285 : Tensor = prim::GetAttr[name="bias"](%4284)
  %4286 : Tensor = prim::GetAttr[name="weight"](%4284)
  %4287 : Float(512:1, 128:512) = aten::t(%4286), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.317 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4287), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.170 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.317, %4285, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4290 : Tensor = prim::GetAttr[name="bias"](%4283)
  %4291 : Tensor = prim::GetAttr[name="weight"](%4283)
  %4292 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.170, %4291), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%4292, %4290, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4294 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20967.NoNorm = prim::GetAttr[name="LayerNorm"](%4281)
  %4295 : __torch__.torch.nn.modules.linear.___torch_mangle_20966.Linear = prim::GetAttr[name="dense"](%4281)
  %4296 : Tensor = prim::GetAttr[name="bias"](%4295)
  %4297 : Tensor = prim::GetAttr[name="weight"](%4295)
  %4298 : Float(512:1, 128:512) = aten::t(%4297), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.318 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.171 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.318, %4296, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4301 : Tensor = prim::GetAttr[name="bias"](%4294)
  %4302 : Tensor = prim::GetAttr[name="weight"](%4294)
  %4303 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.171, %4302), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.407 : Float(17:1664, 13:128, 128:1) = aten::add(%4303, %4301, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4305 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.407, %residual_tensor.22)
  %4306 : Float(17:1664, 13:128, 128:1), %4307 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4305)
  %4308 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20952.MobileBertSelfOutput = prim::GetAttr[name="output"](%4279)
  %4309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20949.MobileBertSelfAttention = prim::GetAttr[name="self"](%4279)
  %4310 : __torch__.torch.nn.modules.linear.___torch_mangle_20947.Linear = prim::GetAttr[name="value"](%4309)
  %4311 : __torch__.torch.nn.modules.linear.___torch_mangle_20946.Linear = prim::GetAttr[name="key"](%4309)
  %4312 : __torch__.torch.nn.modules.linear.___torch_mangle_20945.Linear = prim::GetAttr[name="query"](%4309)
  %4313 : Tensor = prim::GetAttr[name="bias"](%4312)
  %4314 : Tensor = prim::GetAttr[name="weight"](%4312)
  %4315 : Float(128:1, 128:128) = aten::t(%4314), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %output.319 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4306, %4315), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %x.127 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.319, %4313, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1678:0
  %4318 : Tensor = prim::GetAttr[name="bias"](%4311)
  %4319 : Tensor = prim::GetAttr[name="weight"](%4311)
  %4320 : Float(128:1, 128:128) = aten::t(%4319), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %output.320 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4306, %4320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %x.129 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.320, %4318, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1678:0
  %4323 : Tensor = prim::GetAttr[name="bias"](%4310)
  %4324 : Tensor = prim::GetAttr[name="weight"](%4310)
  %4325 : Float(512:1, 128:512) = aten::t(%4324), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %output.321 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4325), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %x.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.321, %4323, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1678:0
  %4328 : int = aten::size(%x.127, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4329 : int = aten::size(%x.127, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4330 : int[] = prim::ListConstruct(%4328, %4329, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.128 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.127, %4330), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4332 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %query_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.128, %4332), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4334 : int = aten::size(%x.129, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4335 : int = aten::size(%x.129, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4336 : int[] = prim::ListConstruct(%4334, %4335, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.130 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.129, %4336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4338 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %key_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.130, %4338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4340 : int = aten::size(%x.131, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4341 : int = aten::size(%x.131, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4342 : int[] = prim::ListConstruct(%4340, %4341, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.132 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.131, %4342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4344 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %value_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.132, %4344), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4346 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.22, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.43 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.22, %4346), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.44 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.43, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.408 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.44, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.409 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.408, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.409, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.43 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.22, %value_layer.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:280:0
  %4353 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %4354 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.43, %4353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4354, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %4356 : int = aten::size(%context_layer.44, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4357 : int = aten::size(%context_layer.44, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4358 : int[] = prim::ListConstruct(%4356, %4357, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %input.410 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.44, %4358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:283:0
  %4360 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20951.NoNorm = prim::GetAttr[name="LayerNorm"](%4308)
  %4361 : __torch__.torch.nn.modules.linear.___torch_mangle_20950.Linear = prim::GetAttr[name="dense"](%4308)
  %4362 : Tensor = prim::GetAttr[name="bias"](%4361)
  %4363 : Tensor = prim::GetAttr[name="weight"](%4361)
  %4364 : Float(128:1, 128:128) = aten::t(%4363), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %output.322 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.410, %4364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.322, %4362, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.172 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.106, %4307, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output # transformers/modeling_mobilebert.py:301:0
  %4368 : Tensor = prim::GetAttr[name="bias"](%4360)
  %4369 : Tensor = prim::GetAttr[name="weight"](%4360)
  %4370 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.172, %4369), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.411 : Float(17:1664, 13:128, 128:1) = aten::add(%4370, %4368, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4372 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20974.FFNOutput = prim::GetAttr[name="output"](%4278)
  %4373 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20971.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4278)
  %4374 : __torch__.torch.nn.modules.linear.___torch_mangle_20970.Linear = prim::GetAttr[name="dense"](%4373)
  %4375 : Tensor = prim::GetAttr[name="bias"](%4374)
  %4376 : Tensor = prim::GetAttr[name="weight"](%4374)
  %4377 : Float(128:1, 512:128) = aten::t(%4376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.323 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.411, %4377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.412 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.323, %4375, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.413 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4381 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20973.NoNorm = prim::GetAttr[name="LayerNorm"](%4372)
  %4382 : __torch__.torch.nn.modules.linear.___torch_mangle_20972.Linear = prim::GetAttr[name="dense"](%4372)
  %4383 : Tensor = prim::GetAttr[name="bias"](%4382)
  %4384 : Tensor = prim::GetAttr[name="weight"](%4382)
  %4385 : Float(512:1, 128:512) = aten::t(%4384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.324 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.413, %4385), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.324, %4383, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.173 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.107, %input.411, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4389 : Tensor = prim::GetAttr[name="bias"](%4381)
  %4390 : Tensor = prim::GetAttr[name="weight"](%4381)
  %4391 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.173, %4390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.414 : Float(17:1664, 13:128, 128:1) = aten::add(%4391, %4389, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4393 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20980.FFNOutput = prim::GetAttr[name="output"](%4276)
  %4394 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20977.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4276)
  %4395 : __torch__.torch.nn.modules.linear.___torch_mangle_20976.Linear = prim::GetAttr[name="dense"](%4394)
  %4396 : Tensor = prim::GetAttr[name="bias"](%4395)
  %4397 : Tensor = prim::GetAttr[name="weight"](%4395)
  %4398 : Float(128:1, 512:128) = aten::t(%4397), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.325 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.414, %4398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.415 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.325, %4396, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.416 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4402 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20979.NoNorm = prim::GetAttr[name="LayerNorm"](%4393)
  %4403 : __torch__.torch.nn.modules.linear.___torch_mangle_20978.Linear = prim::GetAttr[name="dense"](%4393)
  %4404 : Tensor = prim::GetAttr[name="bias"](%4403)
  %4405 : Tensor = prim::GetAttr[name="weight"](%4403)
  %4406 : Float(512:1, 128:512) = aten::t(%4405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.326 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.416, %4406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.108 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.326, %4404, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.174 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.108, %input.414, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4410 : Tensor = prim::GetAttr[name="bias"](%4402)
  %4411 : Tensor = prim::GetAttr[name="weight"](%4402)
  %4412 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.174, %4411), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.417 : Float(17:1664, 13:128, 128:1) = aten::add(%4412, %4410, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4414 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20986.FFNOutput = prim::GetAttr[name="output"](%4274)
  %4415 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20983.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4274)
  %4416 : __torch__.torch.nn.modules.linear.___torch_mangle_20982.Linear = prim::GetAttr[name="dense"](%4415)
  %4417 : Tensor = prim::GetAttr[name="bias"](%4416)
  %4418 : Tensor = prim::GetAttr[name="weight"](%4416)
  %4419 : Float(128:1, 512:128) = aten::t(%4418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.327 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.417, %4419), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.418 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.327, %4417, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.419 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4423 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20985.NoNorm = prim::GetAttr[name="LayerNorm"](%4414)
  %4424 : __torch__.torch.nn.modules.linear.___torch_mangle_20984.Linear = prim::GetAttr[name="dense"](%4414)
  %4425 : Tensor = prim::GetAttr[name="bias"](%4424)
  %4426 : Tensor = prim::GetAttr[name="weight"](%4424)
  %4427 : Float(512:1, 128:512) = aten::t(%4426), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.328 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.419, %4427), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.328, %4425, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.175 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.109, %input.417, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4431 : Tensor = prim::GetAttr[name="bias"](%4423)
  %4432 : Tensor = prim::GetAttr[name="weight"](%4423)
  %4433 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.175, %4432), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.420 : Float(17:1664, 13:128, 128:1) = aten::add(%4433, %4431, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4435 : __torch__.torch.nn.modules.linear.___torch_mangle_20954.Linear = prim::GetAttr[name="dense"](%4272)
  %4436 : Tensor = prim::GetAttr[name="bias"](%4435)
  %4437 : Tensor = prim::GetAttr[name="weight"](%4435)
  %4438 : Float(128:1, 512:128) = aten::t(%4437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %output.329 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.420, %4438), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %input.421 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.329, %4436, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1678:0
  %input.422 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate # torch/nn/functional.py:1119:0
  %4442 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20961.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4271)
  %4443 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20957.NoNorm = prim::GetAttr[name="LayerNorm"](%4271)
  %4444 : __torch__.torch.nn.modules.linear.___torch_mangle_20956.Linear = prim::GetAttr[name="dense"](%4271)
  %4445 : Tensor = prim::GetAttr[name="bias"](%4444)
  %4446 : Tensor = prim::GetAttr[name="weight"](%4444)
  %4447 : Float(512:1, 128:512) = aten::t(%4446), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %output.330 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.422, %4447), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %layer_output.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.330, %4445, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.176 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.22, %input.420, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output # transformers/modeling_mobilebert.py:405:0
  %4451 : Tensor = prim::GetAttr[name="bias"](%4443)
  %4452 : Tensor = prim::GetAttr[name="weight"](%4443)
  %4453 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.176, %4452), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.423 : Float(17:1664, 13:128, 128:1) = aten::add(%4453, %4451, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4455 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20959.NoNorm = prim::GetAttr[name="LayerNorm"](%4442)
  %4456 : __torch__.torch.nn.modules.linear.___torch_mangle_20958.Linear = prim::GetAttr[name="dense"](%4442)
  %4457 : Tensor = prim::GetAttr[name="bias"](%4456)
  %4458 : Tensor = prim::GetAttr[name="weight"](%4456)
  %4459 : Float(128:1, 512:128) = aten::t(%4458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.331 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.423, %4459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.424 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.331, %4457, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.110 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.424, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.177 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.110, %input.406, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4464 : Tensor = prim::GetAttr[name="bias"](%4455)
  %4465 : Tensor = prim::GetAttr[name="weight"](%4455)
  %4466 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.177, %4465), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.425 : Float(17:6656, 13:512, 512:1) = aten::add(%4466, %4464, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4468 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21007.MobileBertOutput = prim::GetAttr[name="output"](%89)
  %4469 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21000.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%89)
  %4470 : __torch__.torch.nn.modules.container.___torch_mangle_21033.ModuleList = prim::GetAttr[name="ffn"](%89)
  %4471 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21032.FFNLayer = prim::GetAttr[name="2"](%4470)
  %4472 : __torch__.torch.nn.modules.container.___torch_mangle_21033.ModuleList = prim::GetAttr[name="ffn"](%89)
  %4473 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21026.FFNLayer = prim::GetAttr[name="1"](%4472)
  %4474 : __torch__.torch.nn.modules.container.___torch_mangle_21033.ModuleList = prim::GetAttr[name="ffn"](%89)
  %4475 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21020.FFNLayer = prim::GetAttr[name="0"](%4474)
  %4476 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20998.MobileBertAttention = prim::GetAttr[name="attention"](%89)
  %4477 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21014.Bottleneck = prim::GetAttr[name="bottleneck"](%89)
  %4478 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21013.BottleneckLayer = prim::GetAttr[name="attention"](%4477)
  %4479 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21010.BottleneckLayer = prim::GetAttr[name="input"](%4477)
  %4480 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21009.NoNorm = prim::GetAttr[name="LayerNorm"](%4479)
  %4481 : __torch__.torch.nn.modules.linear.___torch_mangle_21008.Linear = prim::GetAttr[name="dense"](%4479)
  %4482 : Tensor = prim::GetAttr[name="bias"](%4481)
  %4483 : Tensor = prim::GetAttr[name="weight"](%4481)
  %4484 : Float(512:1, 128:512) = aten::t(%4483), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.332 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4484), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.178 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.332, %4482, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4487 : Tensor = prim::GetAttr[name="bias"](%4480)
  %4488 : Tensor = prim::GetAttr[name="weight"](%4480)
  %4489 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.178, %4488), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%4489, %4487, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4491 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21012.NoNorm = prim::GetAttr[name="LayerNorm"](%4478)
  %4492 : __torch__.torch.nn.modules.linear.___torch_mangle_21011.Linear = prim::GetAttr[name="dense"](%4478)
  %4493 : Tensor = prim::GetAttr[name="bias"](%4492)
  %4494 : Tensor = prim::GetAttr[name="weight"](%4492)
  %4495 : Float(512:1, 128:512) = aten::t(%4494), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.333 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4495), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.179 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.333, %4493, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4498 : Tensor = prim::GetAttr[name="bias"](%4491)
  %4499 : Tensor = prim::GetAttr[name="weight"](%4491)
  %4500 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.179, %4499), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.426 : Float(17:1664, 13:128, 128:1) = aten::add(%4500, %4498, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4502 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.426, %residual_tensor.23)
  %4503 : Float(17:1664, 13:128, 128:1), %4504 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4502)
  %4505 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20997.MobileBertSelfOutput = prim::GetAttr[name="output"](%4476)
  %4506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20994.MobileBertSelfAttention = prim::GetAttr[name="self"](%4476)
  %4507 : __torch__.torch.nn.modules.linear.___torch_mangle_20992.Linear = prim::GetAttr[name="value"](%4506)
  %4508 : __torch__.torch.nn.modules.linear.___torch_mangle_20991.Linear = prim::GetAttr[name="key"](%4506)
  %4509 : __torch__.torch.nn.modules.linear.___torch_mangle_20990.Linear = prim::GetAttr[name="query"](%4506)
  %4510 : Tensor = prim::GetAttr[name="bias"](%4509)
  %4511 : Tensor = prim::GetAttr[name="weight"](%4509)
  %4512 : Float(128:1, 128:128) = aten::t(%4511), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %output.334 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4503, %4512), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %x.133 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.334, %4510, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1678:0
  %4515 : Tensor = prim::GetAttr[name="bias"](%4508)
  %4516 : Tensor = prim::GetAttr[name="weight"](%4508)
  %4517 : Float(128:1, 128:128) = aten::t(%4516), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %output.335 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4503, %4517), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %x.135 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.335, %4515, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1678:0
  %4520 : Tensor = prim::GetAttr[name="bias"](%4507)
  %4521 : Tensor = prim::GetAttr[name="weight"](%4507)
  %4522 : Float(512:1, 128:512) = aten::t(%4521), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %output.336 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4522), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %x.137 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.336, %4520, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1678:0
  %4525 : int = aten::size(%x.133, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4526 : int = aten::size(%x.133, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4527 : int[] = prim::ListConstruct(%4525, %4526, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.134 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.133, %4527), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4529 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %query_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.134, %4529), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4531 : int = aten::size(%x.135, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4532 : int = aten::size(%x.135, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4533 : int[] = prim::ListConstruct(%4531, %4532, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.136 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.135, %4533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4535 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %key_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.136, %4535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4537 : int = aten::size(%x.137, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4538 : int = aten::size(%x.137, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4539 : int[] = prim::ListConstruct(%4537, %4538, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.138 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.137, %4539), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4541 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %value_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.138, %4541), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4543 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.23, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.45 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.23, %4543), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.46 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.45, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.427 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.46, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.428 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.427, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.428, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.45 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.23, %value_layer.23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:280:0
  %4550 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %4551 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.45, %4550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4551, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %4553 : int = aten::size(%context_layer.46, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4554 : int = aten::size(%context_layer.46, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4555 : int[] = prim::ListConstruct(%4553, %4554, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %input.429 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.46, %4555), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:283:0
  %4557 : __torch__.transformers.modeling_mobilebert.___torch_mangle_20996.NoNorm = prim::GetAttr[name="LayerNorm"](%4505)
  %4558 : __torch__.torch.nn.modules.linear.___torch_mangle_20995.Linear = prim::GetAttr[name="dense"](%4505)
  %4559 : Tensor = prim::GetAttr[name="bias"](%4558)
  %4560 : Tensor = prim::GetAttr[name="weight"](%4558)
  %4561 : Float(128:1, 128:128) = aten::t(%4560), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %output.337 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.429, %4561), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.337, %4559, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.180 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.111, %4504, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output # transformers/modeling_mobilebert.py:301:0
  %4565 : Tensor = prim::GetAttr[name="bias"](%4557)
  %4566 : Tensor = prim::GetAttr[name="weight"](%4557)
  %4567 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.180, %4566), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.430 : Float(17:1664, 13:128, 128:1) = aten::add(%4567, %4565, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4569 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21019.FFNOutput = prim::GetAttr[name="output"](%4475)
  %4570 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21016.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4475)
  %4571 : __torch__.torch.nn.modules.linear.___torch_mangle_21015.Linear = prim::GetAttr[name="dense"](%4570)
  %4572 : Tensor = prim::GetAttr[name="bias"](%4571)
  %4573 : Tensor = prim::GetAttr[name="weight"](%4571)
  %4574 : Float(128:1, 512:128) = aten::t(%4573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.338 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.430, %4574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.431 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.338, %4572, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.432 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.431), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4578 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21018.NoNorm = prim::GetAttr[name="LayerNorm"](%4569)
  %4579 : __torch__.torch.nn.modules.linear.___torch_mangle_21017.Linear = prim::GetAttr[name="dense"](%4569)
  %4580 : Tensor = prim::GetAttr[name="bias"](%4579)
  %4581 : Tensor = prim::GetAttr[name="weight"](%4579)
  %4582 : Float(512:1, 128:512) = aten::t(%4581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.339 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.432, %4582), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.112 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.339, %4580, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.181 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.112, %input.430, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4586 : Tensor = prim::GetAttr[name="bias"](%4578)
  %4587 : Tensor = prim::GetAttr[name="weight"](%4578)
  %4588 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.181, %4587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.433 : Float(17:1664, 13:128, 128:1) = aten::add(%4588, %4586, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4590 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21025.FFNOutput = prim::GetAttr[name="output"](%4473)
  %4591 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21022.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4473)
  %4592 : __torch__.torch.nn.modules.linear.___torch_mangle_21021.Linear = prim::GetAttr[name="dense"](%4591)
  %4593 : Tensor = prim::GetAttr[name="bias"](%4592)
  %4594 : Tensor = prim::GetAttr[name="weight"](%4592)
  %4595 : Float(128:1, 512:128) = aten::t(%4594), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.340 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.433, %4595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.434 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.340, %4593, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.435 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4599 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21024.NoNorm = prim::GetAttr[name="LayerNorm"](%4590)
  %4600 : __torch__.torch.nn.modules.linear.___torch_mangle_21023.Linear = prim::GetAttr[name="dense"](%4590)
  %4601 : Tensor = prim::GetAttr[name="bias"](%4600)
  %4602 : Tensor = prim::GetAttr[name="weight"](%4600)
  %4603 : Float(512:1, 128:512) = aten::t(%4602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.341 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.435, %4603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.341, %4601, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.182 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.113, %input.433, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4607 : Tensor = prim::GetAttr[name="bias"](%4599)
  %4608 : Tensor = prim::GetAttr[name="weight"](%4599)
  %4609 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.182, %4608), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.436 : Float(17:1664, 13:128, 128:1) = aten::add(%4609, %4607, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4611 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21031.FFNOutput = prim::GetAttr[name="output"](%4471)
  %4612 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21028.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4471)
  %4613 : __torch__.torch.nn.modules.linear.___torch_mangle_21027.Linear = prim::GetAttr[name="dense"](%4612)
  %4614 : Tensor = prim::GetAttr[name="bias"](%4613)
  %4615 : Tensor = prim::GetAttr[name="weight"](%4613)
  %4616 : Float(128:1, 512:128) = aten::t(%4615), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.342 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.436, %4616), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.437 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.342, %4614, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.438 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4620 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21030.NoNorm = prim::GetAttr[name="LayerNorm"](%4611)
  %4621 : __torch__.torch.nn.modules.linear.___torch_mangle_21029.Linear = prim::GetAttr[name="dense"](%4611)
  %4622 : Tensor = prim::GetAttr[name="bias"](%4621)
  %4623 : Tensor = prim::GetAttr[name="weight"](%4621)
  %4624 : Float(512:1, 128:512) = aten::t(%4623), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.343 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.438, %4624), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.343, %4622, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.183 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.114, %input.436, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4628 : Tensor = prim::GetAttr[name="bias"](%4620)
  %4629 : Tensor = prim::GetAttr[name="weight"](%4620)
  %4630 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.183, %4629), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.439 : Float(17:1664, 13:128, 128:1) = aten::add(%4630, %4628, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4632 : __torch__.torch.nn.modules.linear.___torch_mangle_20999.Linear = prim::GetAttr[name="dense"](%4469)
  %4633 : Tensor = prim::GetAttr[name="bias"](%4632)
  %4634 : Tensor = prim::GetAttr[name="weight"](%4632)
  %4635 : Float(128:1, 512:128) = aten::t(%4634), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %output.344 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.439, %4635), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %input.440 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.344, %4633, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1678:0
  %input.441 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate # torch/nn/functional.py:1119:0
  %4639 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21006.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4468)
  %4640 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21002.NoNorm = prim::GetAttr[name="LayerNorm"](%4468)
  %4641 : __torch__.torch.nn.modules.linear.___torch_mangle_21001.Linear = prim::GetAttr[name="dense"](%4468)
  %4642 : Tensor = prim::GetAttr[name="bias"](%4641)
  %4643 : Tensor = prim::GetAttr[name="weight"](%4641)
  %4644 : Float(512:1, 128:512) = aten::t(%4643), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %output.345 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.441, %4644), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %layer_output.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.345, %4642, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.184 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.23, %input.439, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output # transformers/modeling_mobilebert.py:405:0
  %4648 : Tensor = prim::GetAttr[name="bias"](%4640)
  %4649 : Tensor = prim::GetAttr[name="weight"](%4640)
  %4650 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.184, %4649), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.442 : Float(17:1664, 13:128, 128:1) = aten::add(%4650, %4648, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4652 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21004.NoNorm = prim::GetAttr[name="LayerNorm"](%4639)
  %4653 : __torch__.torch.nn.modules.linear.___torch_mangle_21003.Linear = prim::GetAttr[name="dense"](%4639)
  %4654 : Tensor = prim::GetAttr[name="bias"](%4653)
  %4655 : Tensor = prim::GetAttr[name="weight"](%4653)
  %4656 : Float(128:1, 512:128) = aten::t(%4655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.346 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.442, %4656), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.443 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.346, %4654, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.115 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.443, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.185 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.115, %input.425, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4661 : Tensor = prim::GetAttr[name="bias"](%4652)
  %4662 : Tensor = prim::GetAttr[name="weight"](%4652)
  %4663 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.185, %4662), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.444 : Float(17:6656, 13:512, 512:1) = aten::add(%4663, %4661, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4665 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21052.MobileBertOutput = prim::GetAttr[name="output"](%87)
  %4666 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21045.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%87)
  %4667 : __torch__.torch.nn.modules.container.___torch_mangle_21078.ModuleList = prim::GetAttr[name="ffn"](%87)
  %4668 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21077.FFNLayer = prim::GetAttr[name="2"](%4667)
  %4669 : __torch__.torch.nn.modules.container.___torch_mangle_21078.ModuleList = prim::GetAttr[name="ffn"](%87)
  %4670 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21071.FFNLayer = prim::GetAttr[name="1"](%4669)
  %4671 : __torch__.torch.nn.modules.container.___torch_mangle_21078.ModuleList = prim::GetAttr[name="ffn"](%87)
  %4672 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21065.FFNLayer = prim::GetAttr[name="0"](%4671)
  %4673 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21043.MobileBertAttention = prim::GetAttr[name="attention"](%87)
  %4674 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21059.Bottleneck = prim::GetAttr[name="bottleneck"](%87)
  %4675 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21058.BottleneckLayer = prim::GetAttr[name="attention"](%4674)
  %4676 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21055.BottleneckLayer = prim::GetAttr[name="input"](%4674)
  %4677 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21054.NoNorm = prim::GetAttr[name="LayerNorm"](%4676)
  %4678 : __torch__.torch.nn.modules.linear.___torch_mangle_21053.Linear = prim::GetAttr[name="dense"](%4676)
  %4679 : Tensor = prim::GetAttr[name="bias"](%4678)
  %4680 : Tensor = prim::GetAttr[name="weight"](%4678)
  %4681 : Float(512:1, 128:512) = aten::t(%4680), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.347 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4681), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.186 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.347, %4679, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4684 : Tensor = prim::GetAttr[name="bias"](%4677)
  %4685 : Tensor = prim::GetAttr[name="weight"](%4677)
  %4686 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.186, %4685), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor : Float(17:1664, 13:128, 128:1) = aten::add(%4686, %4684, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4688 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21057.NoNorm = prim::GetAttr[name="LayerNorm"](%4675)
  %4689 : __torch__.torch.nn.modules.linear.___torch_mangle_21056.Linear = prim::GetAttr[name="dense"](%4675)
  %4690 : Tensor = prim::GetAttr[name="bias"](%4689)
  %4691 : Tensor = prim::GetAttr[name="weight"](%4689)
  %4692 : Float(512:1, 128:512) = aten::t(%4691), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.348 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4692), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.187 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.348, %4690, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4695 : Tensor = prim::GetAttr[name="bias"](%4688)
  %4696 : Tensor = prim::GetAttr[name="weight"](%4688)
  %4697 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.187, %4696), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.445 : Float(17:1664, 13:128, 128:1) = aten::add(%4697, %4695, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4699 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.445, %residual_tensor)
  %4700 : Float(17:1664, 13:128, 128:1), %4701 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4699)
  %4702 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21042.MobileBertSelfOutput = prim::GetAttr[name="output"](%4673)
  %4703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21039.MobileBertSelfAttention = prim::GetAttr[name="self"](%4673)
  %4704 : __torch__.torch.nn.modules.linear.___torch_mangle_21037.Linear = prim::GetAttr[name="value"](%4703)
  %4705 : __torch__.torch.nn.modules.linear.___torch_mangle_21036.Linear = prim::GetAttr[name="key"](%4703)
  %4706 : __torch__.torch.nn.modules.linear.___torch_mangle_21035.Linear = prim::GetAttr[name="query"](%4703)
  %4707 : Tensor = prim::GetAttr[name="bias"](%4706)
  %4708 : Tensor = prim::GetAttr[name="weight"](%4706)
  %4709 : Float(128:1, 128:128) = aten::t(%4708), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %output.349 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4700, %4709), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %x.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.349, %4707, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1678:0
  %4712 : Tensor = prim::GetAttr[name="bias"](%4705)
  %4713 : Tensor = prim::GetAttr[name="weight"](%4705)
  %4714 : Float(128:1, 128:128) = aten::t(%4713), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %output.350 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4700, %4714), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %x.141 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.350, %4712, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1678:0
  %4717 : Tensor = prim::GetAttr[name="bias"](%4704)
  %4718 : Tensor = prim::GetAttr[name="weight"](%4704)
  %4719 : Float(512:1, 128:512) = aten::t(%4718), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %output.351 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4719), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %x.143 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.351, %4717, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1678:0
  %4722 : int = aten::size(%x.139, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4723 : int = aten::size(%x.139, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4724 : int[] = prim::ListConstruct(%4722, %4723, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.140 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.139, %4724), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4726 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %query_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.140, %4726), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4728 : int = aten::size(%x.141, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4729 : int = aten::size(%x.141, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4730 : int[] = prim::ListConstruct(%4728, %4729, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.142 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.141, %4730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4732 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %key_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.142, %4732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4734 : int = aten::size(%x.143, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4735 : int = aten::size(%x.143, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4736 : int[] = prim::ListConstruct(%4734, %4735, %33, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.143, %4736), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4738 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %value_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x, %4738), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4740 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer, %22, %20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer, %4740), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.47, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.446 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores, %attention_mask, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.447 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.446, %22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # torch/nn/functional.py:1498:0
  %attention_probs : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.447, %18, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.47 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:280:0
  %4747 : int[] = prim::ListConstruct(%35, %29, %34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %4748 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.47, %4747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4748, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %4750 : int = aten::size(%context_layer, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4751 : int = aten::size(%context_layer, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4752 : int[] = prim::ListConstruct(%4750, %4751, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %input.448 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer, %4752), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:283:0
  %4754 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21041.NoNorm = prim::GetAttr[name="LayerNorm"](%4702)
  %4755 : __torch__.torch.nn.modules.linear.___torch_mangle_21040.Linear = prim::GetAttr[name="dense"](%4702)
  %4756 : Tensor = prim::GetAttr[name="bias"](%4755)
  %4757 : Tensor = prim::GetAttr[name="weight"](%4755)
  %4758 : Float(128:1, 128:128) = aten::t(%4757), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %output.352 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.448, %4758), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.116 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.352, %4756, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.188 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.116, %4701, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output # transformers/modeling_mobilebert.py:301:0
  %4762 : Tensor = prim::GetAttr[name="bias"](%4754)
  %4763 : Tensor = prim::GetAttr[name="weight"](%4754)
  %4764 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.188, %4763), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.449 : Float(17:1664, 13:128, 128:1) = aten::add(%4764, %4762, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4766 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21064.FFNOutput = prim::GetAttr[name="output"](%4672)
  %4767 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21061.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4672)
  %4768 : __torch__.torch.nn.modules.linear.___torch_mangle_21060.Linear = prim::GetAttr[name="dense"](%4767)
  %4769 : Tensor = prim::GetAttr[name="bias"](%4768)
  %4770 : Tensor = prim::GetAttr[name="weight"](%4768)
  %4771 : Float(128:1, 512:128) = aten::t(%4770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.353 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.449, %4771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.450 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.353, %4769, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.451 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4775 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21063.NoNorm = prim::GetAttr[name="LayerNorm"](%4766)
  %4776 : __torch__.torch.nn.modules.linear.___torch_mangle_21062.Linear = prim::GetAttr[name="dense"](%4766)
  %4777 : Tensor = prim::GetAttr[name="bias"](%4776)
  %4778 : Tensor = prim::GetAttr[name="weight"](%4776)
  %4779 : Float(512:1, 128:512) = aten::t(%4778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.354 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.451, %4779), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.354, %4777, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.189 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.117, %input.449, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4783 : Tensor = prim::GetAttr[name="bias"](%4775)
  %4784 : Tensor = prim::GetAttr[name="weight"](%4775)
  %4785 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.189, %4784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.452 : Float(17:1664, 13:128, 128:1) = aten::add(%4785, %4783, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4787 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21070.FFNOutput = prim::GetAttr[name="output"](%4670)
  %4788 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21067.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4670)
  %4789 : __torch__.torch.nn.modules.linear.___torch_mangle_21066.Linear = prim::GetAttr[name="dense"](%4788)
  %4790 : Tensor = prim::GetAttr[name="bias"](%4789)
  %4791 : Tensor = prim::GetAttr[name="weight"](%4789)
  %4792 : Float(128:1, 512:128) = aten::t(%4791), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.355 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.452, %4792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.453 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.355, %4790, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.454 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4796 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21069.NoNorm = prim::GetAttr[name="LayerNorm"](%4787)
  %4797 : __torch__.torch.nn.modules.linear.___torch_mangle_21068.Linear = prim::GetAttr[name="dense"](%4787)
  %4798 : Tensor = prim::GetAttr[name="bias"](%4797)
  %4799 : Tensor = prim::GetAttr[name="weight"](%4797)
  %4800 : Float(512:1, 128:512) = aten::t(%4799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.356 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.454, %4800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.118 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.356, %4798, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.190 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.118, %input.452, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4804 : Tensor = prim::GetAttr[name="bias"](%4796)
  %4805 : Tensor = prim::GetAttr[name="weight"](%4796)
  %4806 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.190, %4805), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.455 : Float(17:1664, 13:128, 128:1) = aten::add(%4806, %4804, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4808 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21076.FFNOutput = prim::GetAttr[name="output"](%4668)
  %4809 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21073.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4668)
  %4810 : __torch__.torch.nn.modules.linear.___torch_mangle_21072.Linear = prim::GetAttr[name="dense"](%4809)
  %4811 : Tensor = prim::GetAttr[name="bias"](%4810)
  %4812 : Tensor = prim::GetAttr[name="weight"](%4810)
  %4813 : Float(128:1, 512:128) = aten::t(%4812), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.357 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.455, %4813), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.456 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.357, %4811, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.457 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4817 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21075.NoNorm = prim::GetAttr[name="LayerNorm"](%4808)
  %4818 : __torch__.torch.nn.modules.linear.___torch_mangle_21074.Linear = prim::GetAttr[name="dense"](%4808)
  %4819 : Tensor = prim::GetAttr[name="bias"](%4818)
  %4820 : Tensor = prim::GetAttr[name="weight"](%4818)
  %4821 : Float(512:1, 128:512) = aten::t(%4820), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.358 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.457, %4821), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.358, %4819, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.191 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.119, %input.455, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4825 : Tensor = prim::GetAttr[name="bias"](%4817)
  %4826 : Tensor = prim::GetAttr[name="weight"](%4817)
  %4827 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.191, %4826), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.458 : Float(17:1664, 13:128, 128:1) = aten::add(%4827, %4825, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4829 : __torch__.torch.nn.modules.linear.___torch_mangle_21044.Linear = prim::GetAttr[name="dense"](%4666)
  %4830 : Tensor = prim::GetAttr[name="bias"](%4829)
  %4831 : Tensor = prim::GetAttr[name="weight"](%4829)
  %4832 : Float(128:1, 512:128) = aten::t(%4831), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %output.359 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.458, %4832), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %input.459 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.359, %4830, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1678:0
  %input.460 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate # torch/nn/functional.py:1119:0
  %4836 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21051.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4665)
  %4837 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21047.NoNorm = prim::GetAttr[name="LayerNorm"](%4665)
  %4838 : __torch__.torch.nn.modules.linear.___torch_mangle_21046.Linear = prim::GetAttr[name="dense"](%4665)
  %4839 : Tensor = prim::GetAttr[name="bias"](%4838)
  %4840 : Tensor = prim::GetAttr[name="weight"](%4838)
  %4841 : Float(512:1, 128:512) = aten::t(%4840), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %output.360 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.460, %4841), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %layer_output : Float(17:1664, 13:128, 128:1) = aten::add_(%output.360, %4839, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.192 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output, %input.458, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output # transformers/modeling_mobilebert.py:405:0
  %4845 : Tensor = prim::GetAttr[name="bias"](%4837)
  %4846 : Tensor = prim::GetAttr[name="weight"](%4837)
  %4847 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.192, %4846), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.461 : Float(17:1664, 13:128, 128:1) = aten::add(%4847, %4845, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4849 : __torch__.transformers.modeling_mobilebert.___torch_mangle_21049.NoNorm = prim::GetAttr[name="LayerNorm"](%4836)
  %4850 : __torch__.torch.nn.modules.linear.___torch_mangle_21048.Linear = prim::GetAttr[name="dense"](%4836)
  %4851 : Tensor = prim::GetAttr[name="bias"](%4850)
  %4852 : Tensor = prim::GetAttr[name="weight"](%4850)
  %4853 : Float(128:1, 512:128) = aten::t(%4852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.361 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.461, %4853), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.462 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.361, %4851, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.462, %23, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs, %input.444, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4858 : Tensor = prim::GetAttr[name="bias"](%4849)
  %4859 : Tensor = prim::GetAttr[name="weight"](%4849)
  %4860 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor, %4859), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input : Float(17:6656, 13:512, 512:1) = aten::add(%4860, %4858, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4862 : int = prim::Constant[value=1](), scope: __module.qa_outputs # torch/nn/functional.py:1678:0
  %4863 : Tensor = prim::GetAttr[name="bias"](%3)
  %4864 : Tensor = prim::GetAttr[name="weight"](%3)
  %4865 : Float(512:1, 2:512) = aten::t(%4864), scope: __module.qa_outputs # torch/nn/functional.py:1676:0
  %output : Float(17:26, 13:2, 2:1) = aten::matmul(%input, %4865), scope: __module.qa_outputs # torch/nn/functional.py:1676:0
  %4867 : Float(17:26, 13:2, 2:1) = aten::add_(%output, %4863, %4862), scope: __module.qa_outputs # torch/nn/functional.py:1678:0
  %7 : int = prim::Constant[value=1]() # torch/tensor.py:371:0
  %8 : int = prim::Constant[value=-1]() # torch/tensor.py:371:0
  %9 : Tensor[] = aten::split(%4867, %7, %8) # torch/tensor.py:371:0
  %start_logits : Float(17:26, 13:2, 1:1), %end_logits : Float(17:26, 13:2, 1:1) = prim::ListUnpack(%9)
  %12 : int = prim::Constant[value=-1]() # transformers/modeling_mobilebert.py:1413:0
  %13 : Float(17:26, 13:2) = aten::squeeze(%start_logits, %12) # transformers/modeling_mobilebert.py:1413:0
  %14 : int = prim::Constant[value=-1]() # transformers/modeling_mobilebert.py:1414:0
  %15 : Float(17:26, 13:2) = aten::squeeze(%end_logits, %14) # transformers/modeling_mobilebert.py:1414:0
  %16 : (Float(17:26, 13:2), Float(17:26, 13:2)) = prim::TupleConstruct(%13, %15)
  return (%16)
