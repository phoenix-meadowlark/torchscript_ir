graph(%self.1 : __torch__.transformers.modeling_mobilebert.MobileBertForMultipleChoice,
      %input_ids.1 : Long(17:91, 7:13, 13:1),
      %attention_mask.1 : Long(17:91, 7:13, 13:1)):
  %3 : __torch__.torch.nn.modules.linear.___torch_mangle_14509.Linear = prim::GetAttr[name="classifier"](%self.1)
  %4 : __torch__.torch.nn.modules.dropout.___torch_mangle_14508.Dropout = prim::GetAttr[name="dropout"](%self.1)
  %5 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14507.MobileBertModel = prim::GetAttr[name="mobilebert"](%self.1)
  %6 : int = prim::Constant[value=1]() # transformers/modeling_mobilebert.py:1488:0
  %7 : int = aten::size(%input_ids.1, %6) # transformers/modeling_mobilebert.py:1488:0
  %num_choices : Long() = prim::NumToTensor(%7)
  %9 : int = aten::Int(%num_choices)
  %10 : int = prim::Constant[value=-1]() # transformers/modeling_mobilebert.py:1490:0
  %11 : int = aten::size(%input_ids.1, %10) # transformers/modeling_mobilebert.py:1490:0
  %12 : Long() = prim::NumToTensor(%11)
  %13 : int = aten::Int(%12)
  %14 : int = prim::Constant[value=-1]() # transformers/modeling_mobilebert.py:1490:0
  %15 : int[] = prim::ListConstruct(%14, %13)
  %input_ids : Long(119:13, 13:1) = aten::view(%input_ids.1, %15) # transformers/modeling_mobilebert.py:1490:0
  %17 : int = prim::Constant[value=-1]() # transformers/modeling_mobilebert.py:1491:0
  %18 : int = aten::size(%attention_mask.1, %17) # transformers/modeling_mobilebert.py:1491:0
  %19 : Long() = prim::NumToTensor(%18)
  %20 : int = aten::Int(%19)
  %21 : int = prim::Constant[value=-1]() # transformers/modeling_mobilebert.py:1491:0
  %22 : int[] = prim::ListConstruct(%21, %20)
  %attention_mask.2 : Long(119:13, 13:1) = aten::view(%attention_mask.1, %22) # transformers/modeling_mobilebert.py:1491:0
  %31 : int = prim::Constant[value=128](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %32 : float = prim::Constant[value=0.10000000000000001](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %33 : Double() = prim::Constant[value={5.65685}](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %34 : int = prim::Constant[value=-2](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %35 : int = prim::Constant[value=32](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %36 : int = prim::Constant[value=-1](), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %37 : float = prim::Constant[value=0.](), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %38 : Double() = prim::Constant[value={-10000}](), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %39 : float = prim::Constant[value=1.](), scope: __module.mobilebert # torch/tensor.py:396:0
  %40 : None = prim::Constant(), scope: __module.mobilebert
  %41 : int = prim::Constant[value=6](), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %42 : int = prim::Constant[value=3](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %43 : int = prim::Constant[value=2](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %44 : int = prim::Constant[value=9223372036854775807](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %45 : bool = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %46 : Device = prim::Constant[value="cpu"](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %47 : int = prim::Constant[value=4](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %48 : int = prim::Constant[value=1](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %49 : int = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %50 : __torch__.transformers.modeling_mobilebert.MobileBertPooler = prim::GetAttr[name="pooler"](%5)
  %51 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14505.MobileBertEncoder = prim::GetAttr[name="encoder"](%5)
  %52 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13423.MobileBertEmbeddings = prim::GetAttr[name="embeddings"](%5)
  %53 : int = aten::size(%input_ids, %49), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %54 : int = aten::size(%input_ids, %48), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %55 : int[] = prim::ListConstruct(%53, %54), scope: __module.mobilebert
  %input.5 : Long(119:13, 13:1) = aten::zeros(%55, %47, %49, %46, %45), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %57 : Long(119:13, 13:1) = aten::slice(%attention_mask.2, %49, %49, %44, %48), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %58 : Long(119:13, 1:13, 13:1) = aten::unsqueeze(%57, %48), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %59 : Long(119:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%58, %43), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %extended_attention_mask : Long(119:13, 1:13, 1:13, 13:1) = aten::slice(%59, %42, %49, %44, %48), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %61 : Float(119:13, 1:13, 1:13, 13:1) = aten::to(%extended_attention_mask, %41, %45, %45, %40), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %62 : Float(119:13, 1:13, 1:13, 13:1) = aten::rsub(%61, %39, %48), scope: __module.mobilebert # torch/tensor.py:396:0
  %attention_mask : Float(119:13, 1:13, 1:13, 13:1) = aten::mul(%62, %38), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %64 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13421.NoNorm = prim::GetAttr[name="LayerNorm"](%52)
  %65 : __torch__.torch.nn.modules.sparse.___torch_mangle_13419.Embedding = prim::GetAttr[name="token_type_embeddings"](%52)
  %66 : __torch__.torch.nn.modules.sparse.___torch_mangle_13418.Embedding = prim::GetAttr[name="position_embeddings"](%52)
  %67 : __torch__.torch.nn.modules.linear.___torch_mangle_13420.Linear = prim::GetAttr[name="embedding_transformation"](%52)
  %68 : __torch__.torch.nn.modules.sparse.___torch_mangle_13417.Embedding = prim::GetAttr[name="word_embeddings"](%52)
  %69 : Tensor = prim::GetAttr[name="position_ids"](%52)
  %70 : int = aten::size(%input_ids, %48), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:185:0
  %71 : Long(1:512, 512:1) = aten::slice(%69, %49, %49, %44, %48), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %input.4 : Long(1:512, 13:1) = aten::slice(%71, %48, %49, %70, %48), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %73 : Tensor = prim::GetAttr[name="weight"](%68)
  %inputs_embeds.1 : Float(119:1664, 13:128, 128:1) = aten::embedding(%73, %input_ids, %49, %45, %45), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %75 : Float(119:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %49, %49, %44, %48), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %input.1 : Float(119:1664, 12:128, 128:1) = aten::slice(%75, %48, %48, %44, %48), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %77 : int[] = prim::ListConstruct(%49, %49, %49, %48, %49, %49), scope: __module.mobilebert/__module.mobilebert.embeddings
  %78 : Float(119:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.1, %77, %49), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %79 : Float(119:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %49, %49, %44, %48), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %input.2 : Float(119:1664, 12:128, 128:1) = aten::slice(%79, %48, %49, %36, %48), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %81 : int[] = prim::ListConstruct(%49, %49, %48, %49, %49, %49), scope: __module.mobilebert/__module.mobilebert.embeddings
  %82 : Float(119:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.2, %81, %49), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %83 : Tensor[] = prim::ListConstruct(%78, %inputs_embeds.1, %82), scope: __module.mobilebert/__module.mobilebert.embeddings
  %input.3 : Float(119:4992, 13:384, 384:1) = aten::cat(%83, %43), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:207:0
  %85 : Tensor = prim::GetAttr[name="bias"](%67)
  %86 : Tensor = prim::GetAttr[name="weight"](%67)
  %87 : Float(384:1, 512:384) = aten::t(%86), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %output.1 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.3, %87), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %inputs_embeds : Float(119:6656, 13:512, 512:1) = aten::add_(%output.1, %85, %48), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1678:0
  %90 : Tensor = prim::GetAttr[name="weight"](%66)
  %position_embeddings : Float(1:6656, 13:512, 512:1) = aten::embedding(%90, %input.4, %36, %45, %45), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %92 : Tensor = prim::GetAttr[name="weight"](%65)
  %token_type_embeddings : Float(119:6656, 13:512, 512:1) = aten::embedding(%92, %input.5, %36, %45, %45), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %94 : Float(119:6656, 13:512, 512:1) = aten::add(%inputs_embeds, %position_embeddings, %48), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %input_tensor.1 : Float(119:6656, 13:512, 512:1) = aten::add(%94, %token_type_embeddings, %48), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %96 : Tensor = prim::GetAttr[name="bias"](%64)
  %97 : Tensor = prim::GetAttr[name="weight"](%64)
  %98 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.1, %97), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.6 : Float(119:6656, 13:512, 512:1) = aten::add(%98, %96, %48), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.7 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.6, %37, %45), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %101 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %102 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14503.MobileBertLayer = prim::GetAttr[name="23"](%101)
  %103 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14458.MobileBertLayer = prim::GetAttr[name="22"](%103)
  %105 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %106 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14413.MobileBertLayer = prim::GetAttr[name="21"](%105)
  %107 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %108 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14368.MobileBertLayer = prim::GetAttr[name="20"](%107)
  %109 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %110 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14323.MobileBertLayer = prim::GetAttr[name="19"](%109)
  %111 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14278.MobileBertLayer = prim::GetAttr[name="18"](%111)
  %113 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %114 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14233.MobileBertLayer = prim::GetAttr[name="17"](%113)
  %115 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %116 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14188.MobileBertLayer = prim::GetAttr[name="16"](%115)
  %117 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14143.MobileBertLayer = prim::GetAttr[name="15"](%117)
  %119 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14098.MobileBertLayer = prim::GetAttr[name="14"](%119)
  %121 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14053.MobileBertLayer = prim::GetAttr[name="13"](%121)
  %123 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %124 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14008.MobileBertLayer = prim::GetAttr[name="12"](%123)
  %125 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %126 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13963.MobileBertLayer = prim::GetAttr[name="11"](%125)
  %127 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %128 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13918.MobileBertLayer = prim::GetAttr[name="10"](%127)
  %129 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %130 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13873.MobileBertLayer = prim::GetAttr[name="9"](%129)
  %131 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %132 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13828.MobileBertLayer = prim::GetAttr[name="8"](%131)
  %133 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %134 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13783.MobileBertLayer = prim::GetAttr[name="7"](%133)
  %135 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %136 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13738.MobileBertLayer = prim::GetAttr[name="6"](%135)
  %137 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %138 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13693.MobileBertLayer = prim::GetAttr[name="5"](%137)
  %139 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %140 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13648.MobileBertLayer = prim::GetAttr[name="4"](%139)
  %141 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %142 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13603.MobileBertLayer = prim::GetAttr[name="3"](%141)
  %143 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %144 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13558.MobileBertLayer = prim::GetAttr[name="2"](%143)
  %145 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %146 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13513.MobileBertLayer = prim::GetAttr[name="1"](%145)
  %147 : __torch__.torch.nn.modules.container.___torch_mangle_14504.ModuleList = prim::GetAttr[name="layer"](%51)
  %148 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13468.MobileBertLayer = prim::GetAttr[name="0"](%147)
  %149 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13441.MobileBertOutput = prim::GetAttr[name="output"](%148)
  %150 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13434.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%148)
  %151 : __torch__.torch.nn.modules.container.___torch_mangle_13467.ModuleList = prim::GetAttr[name="ffn"](%148)
  %152 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13466.FFNLayer = prim::GetAttr[name="2"](%151)
  %153 : __torch__.torch.nn.modules.container.___torch_mangle_13467.ModuleList = prim::GetAttr[name="ffn"](%148)
  %154 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13460.FFNLayer = prim::GetAttr[name="1"](%153)
  %155 : __torch__.torch.nn.modules.container.___torch_mangle_13467.ModuleList = prim::GetAttr[name="ffn"](%148)
  %156 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13454.FFNLayer = prim::GetAttr[name="0"](%155)
  %157 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13432.MobileBertAttention = prim::GetAttr[name="attention"](%148)
  %158 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13448.Bottleneck = prim::GetAttr[name="bottleneck"](%148)
  %159 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13447.BottleneckLayer = prim::GetAttr[name="attention"](%158)
  %160 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13444.BottleneckLayer = prim::GetAttr[name="input"](%158)
  %161 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13443.NoNorm = prim::GetAttr[name="LayerNorm"](%160)
  %162 : __torch__.torch.nn.modules.linear.___torch_mangle_13442.Linear = prim::GetAttr[name="dense"](%160)
  %163 : Tensor = prim::GetAttr[name="bias"](%162)
  %164 : Tensor = prim::GetAttr[name="weight"](%162)
  %165 : Float(512:1, 128:512) = aten::t(%164), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.2 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.7, %165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.2 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.2, %163, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %168 : Tensor = prim::GetAttr[name="bias"](%161)
  %169 : Tensor = prim::GetAttr[name="weight"](%161)
  %170 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.2, %169), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.1 : Float(119:1664, 13:128, 128:1) = aten::add(%170, %168, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %172 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13446.NoNorm = prim::GetAttr[name="LayerNorm"](%159)
  %173 : __torch__.torch.nn.modules.linear.___torch_mangle_13445.Linear = prim::GetAttr[name="dense"](%159)
  %174 : Tensor = prim::GetAttr[name="bias"](%173)
  %175 : Tensor = prim::GetAttr[name="weight"](%173)
  %176 : Float(512:1, 128:512) = aten::t(%175), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.3 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.7, %176), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.3 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.3, %174, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %179 : Tensor = prim::GetAttr[name="bias"](%172)
  %180 : Tensor = prim::GetAttr[name="weight"](%172)
  %181 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.3, %180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.8 : Float(119:1664, 13:128, 128:1) = aten::add(%181, %179, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %183 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.8, %residual_tensor.1)
  %184 : Float(119:1664, 13:128, 128:1), %185 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%183)
  %186 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13431.MobileBertSelfOutput = prim::GetAttr[name="output"](%157)
  %187 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13428.MobileBertSelfAttention = prim::GetAttr[name="self"](%157)
  %188 : __torch__.torch.nn.modules.linear.___torch_mangle_13426.Linear = prim::GetAttr[name="value"](%187)
  %189 : __torch__.torch.nn.modules.linear.___torch_mangle_13425.Linear = prim::GetAttr[name="key"](%187)
  %190 : __torch__.torch.nn.modules.linear.___torch_mangle_13424.Linear = prim::GetAttr[name="query"](%187)
  %191 : Tensor = prim::GetAttr[name="bias"](%190)
  %192 : Tensor = prim::GetAttr[name="weight"](%190)
  %193 : Float(128:1, 128:128) = aten::t(%192), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %output.4 : Float(119:1664, 13:128, 128:1) = aten::matmul(%184, %193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %x.1 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.4, %191, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %196 : Tensor = prim::GetAttr[name="bias"](%189)
  %197 : Tensor = prim::GetAttr[name="weight"](%189)
  %198 : Float(128:1, 128:128) = aten::t(%197), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %output.5 : Float(119:1664, 13:128, 128:1) = aten::matmul(%184, %198), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %x.3 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.5, %196, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1678:0
  %201 : Tensor = prim::GetAttr[name="bias"](%188)
  %202 : Tensor = prim::GetAttr[name="weight"](%188)
  %203 : Float(512:1, 128:512) = aten::t(%202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %output.6 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.7, %203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %x.5 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.6, %201, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1678:0
  %206 : int = aten::size(%x.1, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %207 : int = aten::size(%x.1, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %208 : int[] = prim::ListConstruct(%206, %207, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.2 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.1, %208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %210 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %query_layer.1 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.2, %210), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %212 : int = aten::size(%x.3, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %213 : int = aten::size(%x.3, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %214 : int[] = prim::ListConstruct(%212, %213, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.4 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.3, %214), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %216 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %key_layer.1 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.4, %216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %218 : int = aten::size(%x.5, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %219 : int = aten::size(%x.5, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %220 : int[] = prim::ListConstruct(%218, %219, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.6 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.5, %220), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %222 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %value_layer.1 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.6, %222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %224 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.1, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.1 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.1, %224), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.2 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.1, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.9 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.2, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.10 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.9, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.1 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.10, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.1 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:280:0
  %231 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %232 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.1, %231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.2 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%232, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %234 : int = aten::size(%context_layer.2, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %235 : int = aten::size(%context_layer.2, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %236 : int[] = prim::ListConstruct(%234, %235, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %input.11 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.2, %236), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %238 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13430.NoNorm = prim::GetAttr[name="LayerNorm"](%186)
  %239 : __torch__.torch.nn.modules.linear.___torch_mangle_13429.Linear = prim::GetAttr[name="dense"](%186)
  %240 : Tensor = prim::GetAttr[name="bias"](%239)
  %241 : Tensor = prim::GetAttr[name="weight"](%239)
  %242 : Float(128:1, 128:128) = aten::t(%241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %output.7 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.11, %242), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.1 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.7, %240, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.4 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.1, %185, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output # transformers/modeling_mobilebert.py:301:0
  %246 : Tensor = prim::GetAttr[name="bias"](%238)
  %247 : Tensor = prim::GetAttr[name="weight"](%238)
  %248 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.4, %247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.12 : Float(119:1664, 13:128, 128:1) = aten::add(%248, %246, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %250 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13453.FFNOutput = prim::GetAttr[name="output"](%156)
  %251 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13450.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%156)
  %252 : __torch__.torch.nn.modules.linear.___torch_mangle_13449.Linear = prim::GetAttr[name="dense"](%251)
  %253 : Tensor = prim::GetAttr[name="bias"](%252)
  %254 : Tensor = prim::GetAttr[name="weight"](%252)
  %255 : Float(128:1, 512:128) = aten::t(%254), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.8 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.12, %255), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.13 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.8, %253, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.14 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %259 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13452.NoNorm = prim::GetAttr[name="LayerNorm"](%250)
  %260 : __torch__.torch.nn.modules.linear.___torch_mangle_13451.Linear = prim::GetAttr[name="dense"](%250)
  %261 : Tensor = prim::GetAttr[name="bias"](%260)
  %262 : Tensor = prim::GetAttr[name="weight"](%260)
  %263 : Float(512:1, 128:512) = aten::t(%262), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.9 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.14, %263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.2 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.9, %261, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.5 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.2, %input.12, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %267 : Tensor = prim::GetAttr[name="bias"](%259)
  %268 : Tensor = prim::GetAttr[name="weight"](%259)
  %269 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.5, %268), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.15 : Float(119:1664, 13:128, 128:1) = aten::add(%269, %267, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %271 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13459.FFNOutput = prim::GetAttr[name="output"](%154)
  %272 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13456.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%154)
  %273 : __torch__.torch.nn.modules.linear.___torch_mangle_13455.Linear = prim::GetAttr[name="dense"](%272)
  %274 : Tensor = prim::GetAttr[name="bias"](%273)
  %275 : Tensor = prim::GetAttr[name="weight"](%273)
  %276 : Float(128:1, 512:128) = aten::t(%275), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.10 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.15, %276), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.16 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.10, %274, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.17 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %280 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13458.NoNorm = prim::GetAttr[name="LayerNorm"](%271)
  %281 : __torch__.torch.nn.modules.linear.___torch_mangle_13457.Linear = prim::GetAttr[name="dense"](%271)
  %282 : Tensor = prim::GetAttr[name="bias"](%281)
  %283 : Tensor = prim::GetAttr[name="weight"](%281)
  %284 : Float(512:1, 128:512) = aten::t(%283), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.11 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.17, %284), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.3 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.11, %282, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.6 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.3, %input.15, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %288 : Tensor = prim::GetAttr[name="bias"](%280)
  %289 : Tensor = prim::GetAttr[name="weight"](%280)
  %290 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.6, %289), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.18 : Float(119:1664, 13:128, 128:1) = aten::add(%290, %288, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %292 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13465.FFNOutput = prim::GetAttr[name="output"](%152)
  %293 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13462.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%152)
  %294 : __torch__.torch.nn.modules.linear.___torch_mangle_13461.Linear = prim::GetAttr[name="dense"](%293)
  %295 : Tensor = prim::GetAttr[name="bias"](%294)
  %296 : Tensor = prim::GetAttr[name="weight"](%294)
  %297 : Float(128:1, 512:128) = aten::t(%296), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.12 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.18, %297), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.19 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.12, %295, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.20 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13464.NoNorm = prim::GetAttr[name="LayerNorm"](%292)
  %302 : __torch__.torch.nn.modules.linear.___torch_mangle_13463.Linear = prim::GetAttr[name="dense"](%292)
  %303 : Tensor = prim::GetAttr[name="bias"](%302)
  %304 : Tensor = prim::GetAttr[name="weight"](%302)
  %305 : Float(512:1, 128:512) = aten::t(%304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.13 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.20, %305), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.4 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.13, %303, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.7 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.4, %input.18, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %309 : Tensor = prim::GetAttr[name="bias"](%301)
  %310 : Tensor = prim::GetAttr[name="weight"](%301)
  %311 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.7, %310), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.21 : Float(119:1664, 13:128, 128:1) = aten::add(%311, %309, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %313 : __torch__.torch.nn.modules.linear.___torch_mangle_13433.Linear = prim::GetAttr[name="dense"](%150)
  %314 : Tensor = prim::GetAttr[name="bias"](%313)
  %315 : Tensor = prim::GetAttr[name="weight"](%313)
  %316 : Float(128:1, 512:128) = aten::t(%315), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.14 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.21, %316), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.22 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.14, %314, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.23 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate # torch/nn/functional.py:1119:0
  %320 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13440.OutputBottleneck = prim::GetAttr[name="bottleneck"](%149)
  %321 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13436.NoNorm = prim::GetAttr[name="LayerNorm"](%149)
  %322 : __torch__.torch.nn.modules.linear.___torch_mangle_13435.Linear = prim::GetAttr[name="dense"](%149)
  %323 : Tensor = prim::GetAttr[name="bias"](%322)
  %324 : Tensor = prim::GetAttr[name="weight"](%322)
  %325 : Float(512:1, 128:512) = aten::t(%324), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %output.15 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.23, %325), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %layer_output.1 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.15, %323, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.8 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.1, %input.21, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output # transformers/modeling_mobilebert.py:405:0
  %329 : Tensor = prim::GetAttr[name="bias"](%321)
  %330 : Tensor = prim::GetAttr[name="weight"](%321)
  %331 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.8, %330), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.24 : Float(119:1664, 13:128, 128:1) = aten::add(%331, %329, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %333 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13438.NoNorm = prim::GetAttr[name="LayerNorm"](%320)
  %334 : __torch__.torch.nn.modules.linear.___torch_mangle_13437.Linear = prim::GetAttr[name="dense"](%320)
  %335 : Tensor = prim::GetAttr[name="bias"](%334)
  %336 : Tensor = prim::GetAttr[name="weight"](%334)
  %337 : Float(128:1, 512:128) = aten::t(%336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.16 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.24, %337), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.25 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.16, %335, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.5 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.25, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.9 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.5, %input.7, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %342 : Tensor = prim::GetAttr[name="bias"](%333)
  %343 : Tensor = prim::GetAttr[name="weight"](%333)
  %344 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.9, %343), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.26 : Float(119:6656, 13:512, 512:1) = aten::add(%344, %342, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %346 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13486.MobileBertOutput = prim::GetAttr[name="output"](%146)
  %347 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13479.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%146)
  %348 : __torch__.torch.nn.modules.container.___torch_mangle_13512.ModuleList = prim::GetAttr[name="ffn"](%146)
  %349 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13511.FFNLayer = prim::GetAttr[name="2"](%348)
  %350 : __torch__.torch.nn.modules.container.___torch_mangle_13512.ModuleList = prim::GetAttr[name="ffn"](%146)
  %351 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13505.FFNLayer = prim::GetAttr[name="1"](%350)
  %352 : __torch__.torch.nn.modules.container.___torch_mangle_13512.ModuleList = prim::GetAttr[name="ffn"](%146)
  %353 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13499.FFNLayer = prim::GetAttr[name="0"](%352)
  %354 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13477.MobileBertAttention = prim::GetAttr[name="attention"](%146)
  %355 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13493.Bottleneck = prim::GetAttr[name="bottleneck"](%146)
  %356 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13492.BottleneckLayer = prim::GetAttr[name="attention"](%355)
  %357 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13489.BottleneckLayer = prim::GetAttr[name="input"](%355)
  %358 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13488.NoNorm = prim::GetAttr[name="LayerNorm"](%357)
  %359 : __torch__.torch.nn.modules.linear.___torch_mangle_13487.Linear = prim::GetAttr[name="dense"](%357)
  %360 : Tensor = prim::GetAttr[name="bias"](%359)
  %361 : Tensor = prim::GetAttr[name="weight"](%359)
  %362 : Float(512:1, 128:512) = aten::t(%361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.17 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.26, %362), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.10 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.17, %360, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %365 : Tensor = prim::GetAttr[name="bias"](%358)
  %366 : Tensor = prim::GetAttr[name="weight"](%358)
  %367 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.10, %366), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.2 : Float(119:1664, 13:128, 128:1) = aten::add(%367, %365, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %369 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13491.NoNorm = prim::GetAttr[name="LayerNorm"](%356)
  %370 : __torch__.torch.nn.modules.linear.___torch_mangle_13490.Linear = prim::GetAttr[name="dense"](%356)
  %371 : Tensor = prim::GetAttr[name="bias"](%370)
  %372 : Tensor = prim::GetAttr[name="weight"](%370)
  %373 : Float(512:1, 128:512) = aten::t(%372), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.18 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.26, %373), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.11 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.18, %371, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %376 : Tensor = prim::GetAttr[name="bias"](%369)
  %377 : Tensor = prim::GetAttr[name="weight"](%369)
  %378 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.11, %377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.27 : Float(119:1664, 13:128, 128:1) = aten::add(%378, %376, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %380 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.27, %residual_tensor.2)
  %381 : Float(119:1664, 13:128, 128:1), %382 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%380)
  %383 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13476.MobileBertSelfOutput = prim::GetAttr[name="output"](%354)
  %384 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13473.MobileBertSelfAttention = prim::GetAttr[name="self"](%354)
  %385 : __torch__.torch.nn.modules.linear.___torch_mangle_13471.Linear = prim::GetAttr[name="value"](%384)
  %386 : __torch__.torch.nn.modules.linear.___torch_mangle_13470.Linear = prim::GetAttr[name="key"](%384)
  %387 : __torch__.torch.nn.modules.linear.___torch_mangle_13469.Linear = prim::GetAttr[name="query"](%384)
  %388 : Tensor = prim::GetAttr[name="bias"](%387)
  %389 : Tensor = prim::GetAttr[name="weight"](%387)
  %390 : Float(128:1, 128:128) = aten::t(%389), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %output.19 : Float(119:1664, 13:128, 128:1) = aten::matmul(%381, %390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %x.7 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.19, %388, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1678:0
  %393 : Tensor = prim::GetAttr[name="bias"](%386)
  %394 : Tensor = prim::GetAttr[name="weight"](%386)
  %395 : Float(128:1, 128:128) = aten::t(%394), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %output.20 : Float(119:1664, 13:128, 128:1) = aten::matmul(%381, %395), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %x.9 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.20, %393, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1678:0
  %398 : Tensor = prim::GetAttr[name="bias"](%385)
  %399 : Tensor = prim::GetAttr[name="weight"](%385)
  %400 : Float(512:1, 128:512) = aten::t(%399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %output.21 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.26, %400), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %x.11 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.21, %398, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1678:0
  %403 : int = aten::size(%x.7, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %404 : int = aten::size(%x.7, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %405 : int[] = prim::ListConstruct(%403, %404, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.8 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.7, %405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %407 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %query_layer.2 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.8, %407), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %409 : int = aten::size(%x.9, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %410 : int = aten::size(%x.9, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %411 : int[] = prim::ListConstruct(%409, %410, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.10 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.9, %411), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %413 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %key_layer.2 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.10, %413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %415 : int = aten::size(%x.11, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %416 : int = aten::size(%x.11, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %417 : int[] = prim::ListConstruct(%415, %416, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.12 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.11, %417), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %419 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %value_layer.2 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.12, %419), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %421 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.2, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.3 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.2, %421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.4 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.3, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.28 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.4, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.29 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.28, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.2 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.29, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.3 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.2, %value_layer.2), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:280:0
  %428 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %429 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.3, %428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.4 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%429, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %431 : int = aten::size(%context_layer.4, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %432 : int = aten::size(%context_layer.4, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %433 : int[] = prim::ListConstruct(%431, %432, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %input.30 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.4, %433), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:283:0
  %435 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13475.NoNorm = prim::GetAttr[name="LayerNorm"](%383)
  %436 : __torch__.torch.nn.modules.linear.___torch_mangle_13474.Linear = prim::GetAttr[name="dense"](%383)
  %437 : Tensor = prim::GetAttr[name="bias"](%436)
  %438 : Tensor = prim::GetAttr[name="weight"](%436)
  %439 : Float(128:1, 128:128) = aten::t(%438), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %output.22 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.30, %439), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.6 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.22, %437, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.12 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.6, %382, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output # transformers/modeling_mobilebert.py:301:0
  %443 : Tensor = prim::GetAttr[name="bias"](%435)
  %444 : Tensor = prim::GetAttr[name="weight"](%435)
  %445 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.12, %444), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.31 : Float(119:1664, 13:128, 128:1) = aten::add(%445, %443, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %447 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13498.FFNOutput = prim::GetAttr[name="output"](%353)
  %448 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13495.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%353)
  %449 : __torch__.torch.nn.modules.linear.___torch_mangle_13494.Linear = prim::GetAttr[name="dense"](%448)
  %450 : Tensor = prim::GetAttr[name="bias"](%449)
  %451 : Tensor = prim::GetAttr[name="weight"](%449)
  %452 : Float(128:1, 512:128) = aten::t(%451), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.23 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.31, %452), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.32 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.23, %450, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.33 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.32), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %456 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13497.NoNorm = prim::GetAttr[name="LayerNorm"](%447)
  %457 : __torch__.torch.nn.modules.linear.___torch_mangle_13496.Linear = prim::GetAttr[name="dense"](%447)
  %458 : Tensor = prim::GetAttr[name="bias"](%457)
  %459 : Tensor = prim::GetAttr[name="weight"](%457)
  %460 : Float(512:1, 128:512) = aten::t(%459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.24 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.33, %460), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.7 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.24, %458, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.13 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.7, %input.31, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %464 : Tensor = prim::GetAttr[name="bias"](%456)
  %465 : Tensor = prim::GetAttr[name="weight"](%456)
  %466 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.13, %465), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.34 : Float(119:1664, 13:128, 128:1) = aten::add(%466, %464, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %468 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13504.FFNOutput = prim::GetAttr[name="output"](%351)
  %469 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13501.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%351)
  %470 : __torch__.torch.nn.modules.linear.___torch_mangle_13500.Linear = prim::GetAttr[name="dense"](%469)
  %471 : Tensor = prim::GetAttr[name="bias"](%470)
  %472 : Tensor = prim::GetAttr[name="weight"](%470)
  %473 : Float(128:1, 512:128) = aten::t(%472), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.25 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.34, %473), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.35 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.25, %471, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.36 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %477 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13503.NoNorm = prim::GetAttr[name="LayerNorm"](%468)
  %478 : __torch__.torch.nn.modules.linear.___torch_mangle_13502.Linear = prim::GetAttr[name="dense"](%468)
  %479 : Tensor = prim::GetAttr[name="bias"](%478)
  %480 : Tensor = prim::GetAttr[name="weight"](%478)
  %481 : Float(512:1, 128:512) = aten::t(%480), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.26 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.36, %481), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.8 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.26, %479, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.14 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.8, %input.34, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %485 : Tensor = prim::GetAttr[name="bias"](%477)
  %486 : Tensor = prim::GetAttr[name="weight"](%477)
  %487 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.14, %486), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.37 : Float(119:1664, 13:128, 128:1) = aten::add(%487, %485, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %489 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13510.FFNOutput = prim::GetAttr[name="output"](%349)
  %490 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13507.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%349)
  %491 : __torch__.torch.nn.modules.linear.___torch_mangle_13506.Linear = prim::GetAttr[name="dense"](%490)
  %492 : Tensor = prim::GetAttr[name="bias"](%491)
  %493 : Tensor = prim::GetAttr[name="weight"](%491)
  %494 : Float(128:1, 512:128) = aten::t(%493), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.27 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.37, %494), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.38 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.27, %492, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.39 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.38), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13509.NoNorm = prim::GetAttr[name="LayerNorm"](%489)
  %499 : __torch__.torch.nn.modules.linear.___torch_mangle_13508.Linear = prim::GetAttr[name="dense"](%489)
  %500 : Tensor = prim::GetAttr[name="bias"](%499)
  %501 : Tensor = prim::GetAttr[name="weight"](%499)
  %502 : Float(512:1, 128:512) = aten::t(%501), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.28 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.39, %502), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.9 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.28, %500, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.15 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.9, %input.37, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %506 : Tensor = prim::GetAttr[name="bias"](%498)
  %507 : Tensor = prim::GetAttr[name="weight"](%498)
  %508 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.15, %507), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.40 : Float(119:1664, 13:128, 128:1) = aten::add(%508, %506, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %510 : __torch__.torch.nn.modules.linear.___torch_mangle_13478.Linear = prim::GetAttr[name="dense"](%347)
  %511 : Tensor = prim::GetAttr[name="bias"](%510)
  %512 : Tensor = prim::GetAttr[name="weight"](%510)
  %513 : Float(128:1, 512:128) = aten::t(%512), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.29 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.40, %513), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.41 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.29, %511, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.42 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.41), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate # torch/nn/functional.py:1119:0
  %517 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13485.OutputBottleneck = prim::GetAttr[name="bottleneck"](%346)
  %518 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13481.NoNorm = prim::GetAttr[name="LayerNorm"](%346)
  %519 : __torch__.torch.nn.modules.linear.___torch_mangle_13480.Linear = prim::GetAttr[name="dense"](%346)
  %520 : Tensor = prim::GetAttr[name="bias"](%519)
  %521 : Tensor = prim::GetAttr[name="weight"](%519)
  %522 : Float(512:1, 128:512) = aten::t(%521), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %output.30 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.42, %522), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %layer_output.2 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.30, %520, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.16 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.2, %input.40, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output # transformers/modeling_mobilebert.py:405:0
  %526 : Tensor = prim::GetAttr[name="bias"](%518)
  %527 : Tensor = prim::GetAttr[name="weight"](%518)
  %528 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.16, %527), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.43 : Float(119:1664, 13:128, 128:1) = aten::add(%528, %526, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %530 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13483.NoNorm = prim::GetAttr[name="LayerNorm"](%517)
  %531 : __torch__.torch.nn.modules.linear.___torch_mangle_13482.Linear = prim::GetAttr[name="dense"](%517)
  %532 : Tensor = prim::GetAttr[name="bias"](%531)
  %533 : Tensor = prim::GetAttr[name="weight"](%531)
  %534 : Float(128:1, 512:128) = aten::t(%533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.31 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.43, %534), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.44 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.31, %532, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.10 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.44, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.17 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.10, %input.26, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %539 : Tensor = prim::GetAttr[name="bias"](%530)
  %540 : Tensor = prim::GetAttr[name="weight"](%530)
  %541 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.17, %540), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.45 : Float(119:6656, 13:512, 512:1) = aten::add(%541, %539, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %543 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13531.MobileBertOutput = prim::GetAttr[name="output"](%144)
  %544 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13524.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%144)
  %545 : __torch__.torch.nn.modules.container.___torch_mangle_13557.ModuleList = prim::GetAttr[name="ffn"](%144)
  %546 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13556.FFNLayer = prim::GetAttr[name="2"](%545)
  %547 : __torch__.torch.nn.modules.container.___torch_mangle_13557.ModuleList = prim::GetAttr[name="ffn"](%144)
  %548 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13550.FFNLayer = prim::GetAttr[name="1"](%547)
  %549 : __torch__.torch.nn.modules.container.___torch_mangle_13557.ModuleList = prim::GetAttr[name="ffn"](%144)
  %550 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13544.FFNLayer = prim::GetAttr[name="0"](%549)
  %551 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13522.MobileBertAttention = prim::GetAttr[name="attention"](%144)
  %552 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13538.Bottleneck = prim::GetAttr[name="bottleneck"](%144)
  %553 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13537.BottleneckLayer = prim::GetAttr[name="attention"](%552)
  %554 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13534.BottleneckLayer = prim::GetAttr[name="input"](%552)
  %555 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13533.NoNorm = prim::GetAttr[name="LayerNorm"](%554)
  %556 : __torch__.torch.nn.modules.linear.___torch_mangle_13532.Linear = prim::GetAttr[name="dense"](%554)
  %557 : Tensor = prim::GetAttr[name="bias"](%556)
  %558 : Tensor = prim::GetAttr[name="weight"](%556)
  %559 : Float(512:1, 128:512) = aten::t(%558), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.32 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.45, %559), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.18 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.32, %557, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %562 : Tensor = prim::GetAttr[name="bias"](%555)
  %563 : Tensor = prim::GetAttr[name="weight"](%555)
  %564 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.18, %563), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.3 : Float(119:1664, 13:128, 128:1) = aten::add(%564, %562, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %566 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13536.NoNorm = prim::GetAttr[name="LayerNorm"](%553)
  %567 : __torch__.torch.nn.modules.linear.___torch_mangle_13535.Linear = prim::GetAttr[name="dense"](%553)
  %568 : Tensor = prim::GetAttr[name="bias"](%567)
  %569 : Tensor = prim::GetAttr[name="weight"](%567)
  %570 : Float(512:1, 128:512) = aten::t(%569), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.33 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.45, %570), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.19 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.33, %568, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %573 : Tensor = prim::GetAttr[name="bias"](%566)
  %574 : Tensor = prim::GetAttr[name="weight"](%566)
  %575 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.19, %574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.46 : Float(119:1664, 13:128, 128:1) = aten::add(%575, %573, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %577 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.46, %residual_tensor.3)
  %578 : Float(119:1664, 13:128, 128:1), %579 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%577)
  %580 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13521.MobileBertSelfOutput = prim::GetAttr[name="output"](%551)
  %581 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13518.MobileBertSelfAttention = prim::GetAttr[name="self"](%551)
  %582 : __torch__.torch.nn.modules.linear.___torch_mangle_13516.Linear = prim::GetAttr[name="value"](%581)
  %583 : __torch__.torch.nn.modules.linear.___torch_mangle_13515.Linear = prim::GetAttr[name="key"](%581)
  %584 : __torch__.torch.nn.modules.linear.___torch_mangle_13514.Linear = prim::GetAttr[name="query"](%581)
  %585 : Tensor = prim::GetAttr[name="bias"](%584)
  %586 : Tensor = prim::GetAttr[name="weight"](%584)
  %587 : Float(128:1, 128:128) = aten::t(%586), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %output.34 : Float(119:1664, 13:128, 128:1) = aten::matmul(%578, %587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %x.13 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.34, %585, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1678:0
  %590 : Tensor = prim::GetAttr[name="bias"](%583)
  %591 : Tensor = prim::GetAttr[name="weight"](%583)
  %592 : Float(128:1, 128:128) = aten::t(%591), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %output.35 : Float(119:1664, 13:128, 128:1) = aten::matmul(%578, %592), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %x.15 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.35, %590, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1678:0
  %595 : Tensor = prim::GetAttr[name="bias"](%582)
  %596 : Tensor = prim::GetAttr[name="weight"](%582)
  %597 : Float(512:1, 128:512) = aten::t(%596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %output.36 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.45, %597), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %x.17 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.36, %595, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1678:0
  %600 : int = aten::size(%x.13, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %601 : int = aten::size(%x.13, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %602 : int[] = prim::ListConstruct(%600, %601, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.14 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.13, %602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %604 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %query_layer.3 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.14, %604), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %606 : int = aten::size(%x.15, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %607 : int = aten::size(%x.15, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %608 : int[] = prim::ListConstruct(%606, %607, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.16 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.15, %608), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %610 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %key_layer.3 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.16, %610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %612 : int = aten::size(%x.17, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %613 : int = aten::size(%x.17, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %614 : int[] = prim::ListConstruct(%612, %613, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.18 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.17, %614), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %616 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %value_layer.3 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.18, %616), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %618 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.3, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.5 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.3, %618), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.6 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.5, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.47 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.6, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.48 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.47, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.3 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.48, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.5 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.3, %value_layer.3), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:280:0
  %625 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %626 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.5, %625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.6 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%626, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %628 : int = aten::size(%context_layer.6, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %629 : int = aten::size(%context_layer.6, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %630 : int[] = prim::ListConstruct(%628, %629, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %input.49 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.6, %630), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:283:0
  %632 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13520.NoNorm = prim::GetAttr[name="LayerNorm"](%580)
  %633 : __torch__.torch.nn.modules.linear.___torch_mangle_13519.Linear = prim::GetAttr[name="dense"](%580)
  %634 : Tensor = prim::GetAttr[name="bias"](%633)
  %635 : Tensor = prim::GetAttr[name="weight"](%633)
  %636 : Float(128:1, 128:128) = aten::t(%635), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %output.37 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.49, %636), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.11 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.37, %634, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.20 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.11, %579, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output # transformers/modeling_mobilebert.py:301:0
  %640 : Tensor = prim::GetAttr[name="bias"](%632)
  %641 : Tensor = prim::GetAttr[name="weight"](%632)
  %642 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.20, %641), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.50 : Float(119:1664, 13:128, 128:1) = aten::add(%642, %640, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %644 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13543.FFNOutput = prim::GetAttr[name="output"](%550)
  %645 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13540.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%550)
  %646 : __torch__.torch.nn.modules.linear.___torch_mangle_13539.Linear = prim::GetAttr[name="dense"](%645)
  %647 : Tensor = prim::GetAttr[name="bias"](%646)
  %648 : Tensor = prim::GetAttr[name="weight"](%646)
  %649 : Float(128:1, 512:128) = aten::t(%648), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.38 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.50, %649), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.51 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.38, %647, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.52 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.51), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %653 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13542.NoNorm = prim::GetAttr[name="LayerNorm"](%644)
  %654 : __torch__.torch.nn.modules.linear.___torch_mangle_13541.Linear = prim::GetAttr[name="dense"](%644)
  %655 : Tensor = prim::GetAttr[name="bias"](%654)
  %656 : Tensor = prim::GetAttr[name="weight"](%654)
  %657 : Float(512:1, 128:512) = aten::t(%656), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.39 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.52, %657), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.12 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.39, %655, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.21 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.12, %input.50, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %661 : Tensor = prim::GetAttr[name="bias"](%653)
  %662 : Tensor = prim::GetAttr[name="weight"](%653)
  %663 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.21, %662), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.53 : Float(119:1664, 13:128, 128:1) = aten::add(%663, %661, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %665 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13549.FFNOutput = prim::GetAttr[name="output"](%548)
  %666 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13546.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%548)
  %667 : __torch__.torch.nn.modules.linear.___torch_mangle_13545.Linear = prim::GetAttr[name="dense"](%666)
  %668 : Tensor = prim::GetAttr[name="bias"](%667)
  %669 : Tensor = prim::GetAttr[name="weight"](%667)
  %670 : Float(128:1, 512:128) = aten::t(%669), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.40 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.53, %670), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.54 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.40, %668, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.55 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.54), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %674 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13548.NoNorm = prim::GetAttr[name="LayerNorm"](%665)
  %675 : __torch__.torch.nn.modules.linear.___torch_mangle_13547.Linear = prim::GetAttr[name="dense"](%665)
  %676 : Tensor = prim::GetAttr[name="bias"](%675)
  %677 : Tensor = prim::GetAttr[name="weight"](%675)
  %678 : Float(512:1, 128:512) = aten::t(%677), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.41 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.55, %678), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.13 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.41, %676, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.22 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.13, %input.53, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %682 : Tensor = prim::GetAttr[name="bias"](%674)
  %683 : Tensor = prim::GetAttr[name="weight"](%674)
  %684 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.22, %683), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.56 : Float(119:1664, 13:128, 128:1) = aten::add(%684, %682, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %686 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13555.FFNOutput = prim::GetAttr[name="output"](%546)
  %687 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13552.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%546)
  %688 : __torch__.torch.nn.modules.linear.___torch_mangle_13551.Linear = prim::GetAttr[name="dense"](%687)
  %689 : Tensor = prim::GetAttr[name="bias"](%688)
  %690 : Tensor = prim::GetAttr[name="weight"](%688)
  %691 : Float(128:1, 512:128) = aten::t(%690), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.42 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.56, %691), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.57 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.42, %689, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.58 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.57), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13554.NoNorm = prim::GetAttr[name="LayerNorm"](%686)
  %696 : __torch__.torch.nn.modules.linear.___torch_mangle_13553.Linear = prim::GetAttr[name="dense"](%686)
  %697 : Tensor = prim::GetAttr[name="bias"](%696)
  %698 : Tensor = prim::GetAttr[name="weight"](%696)
  %699 : Float(512:1, 128:512) = aten::t(%698), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.43 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.58, %699), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.14 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.43, %697, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.23 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.14, %input.56, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %703 : Tensor = prim::GetAttr[name="bias"](%695)
  %704 : Tensor = prim::GetAttr[name="weight"](%695)
  %705 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.23, %704), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.59 : Float(119:1664, 13:128, 128:1) = aten::add(%705, %703, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %707 : __torch__.torch.nn.modules.linear.___torch_mangle_13523.Linear = prim::GetAttr[name="dense"](%544)
  %708 : Tensor = prim::GetAttr[name="bias"](%707)
  %709 : Tensor = prim::GetAttr[name="weight"](%707)
  %710 : Float(128:1, 512:128) = aten::t(%709), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.44 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.59, %710), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.60 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.44, %708, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.61 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.60), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate # torch/nn/functional.py:1119:0
  %714 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13530.OutputBottleneck = prim::GetAttr[name="bottleneck"](%543)
  %715 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13526.NoNorm = prim::GetAttr[name="LayerNorm"](%543)
  %716 : __torch__.torch.nn.modules.linear.___torch_mangle_13525.Linear = prim::GetAttr[name="dense"](%543)
  %717 : Tensor = prim::GetAttr[name="bias"](%716)
  %718 : Tensor = prim::GetAttr[name="weight"](%716)
  %719 : Float(512:1, 128:512) = aten::t(%718), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %output.45 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.61, %719), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %layer_output.3 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.45, %717, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.24 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.3, %input.59, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output # transformers/modeling_mobilebert.py:405:0
  %723 : Tensor = prim::GetAttr[name="bias"](%715)
  %724 : Tensor = prim::GetAttr[name="weight"](%715)
  %725 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.24, %724), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.62 : Float(119:1664, 13:128, 128:1) = aten::add(%725, %723, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %727 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13528.NoNorm = prim::GetAttr[name="LayerNorm"](%714)
  %728 : __torch__.torch.nn.modules.linear.___torch_mangle_13527.Linear = prim::GetAttr[name="dense"](%714)
  %729 : Tensor = prim::GetAttr[name="bias"](%728)
  %730 : Tensor = prim::GetAttr[name="weight"](%728)
  %731 : Float(128:1, 512:128) = aten::t(%730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.46 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.62, %731), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.63 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.46, %729, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.15 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.63, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.25 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.15, %input.45, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %736 : Tensor = prim::GetAttr[name="bias"](%727)
  %737 : Tensor = prim::GetAttr[name="weight"](%727)
  %738 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.25, %737), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.64 : Float(119:6656, 13:512, 512:1) = aten::add(%738, %736, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %740 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13576.MobileBertOutput = prim::GetAttr[name="output"](%142)
  %741 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13569.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%142)
  %742 : __torch__.torch.nn.modules.container.___torch_mangle_13602.ModuleList = prim::GetAttr[name="ffn"](%142)
  %743 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13601.FFNLayer = prim::GetAttr[name="2"](%742)
  %744 : __torch__.torch.nn.modules.container.___torch_mangle_13602.ModuleList = prim::GetAttr[name="ffn"](%142)
  %745 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13595.FFNLayer = prim::GetAttr[name="1"](%744)
  %746 : __torch__.torch.nn.modules.container.___torch_mangle_13602.ModuleList = prim::GetAttr[name="ffn"](%142)
  %747 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13589.FFNLayer = prim::GetAttr[name="0"](%746)
  %748 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13567.MobileBertAttention = prim::GetAttr[name="attention"](%142)
  %749 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13583.Bottleneck = prim::GetAttr[name="bottleneck"](%142)
  %750 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13582.BottleneckLayer = prim::GetAttr[name="attention"](%749)
  %751 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13579.BottleneckLayer = prim::GetAttr[name="input"](%749)
  %752 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13578.NoNorm = prim::GetAttr[name="LayerNorm"](%751)
  %753 : __torch__.torch.nn.modules.linear.___torch_mangle_13577.Linear = prim::GetAttr[name="dense"](%751)
  %754 : Tensor = prim::GetAttr[name="bias"](%753)
  %755 : Tensor = prim::GetAttr[name="weight"](%753)
  %756 : Float(512:1, 128:512) = aten::t(%755), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.47 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.64, %756), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.26 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.47, %754, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %759 : Tensor = prim::GetAttr[name="bias"](%752)
  %760 : Tensor = prim::GetAttr[name="weight"](%752)
  %761 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.26, %760), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.4 : Float(119:1664, 13:128, 128:1) = aten::add(%761, %759, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %763 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13581.NoNorm = prim::GetAttr[name="LayerNorm"](%750)
  %764 : __torch__.torch.nn.modules.linear.___torch_mangle_13580.Linear = prim::GetAttr[name="dense"](%750)
  %765 : Tensor = prim::GetAttr[name="bias"](%764)
  %766 : Tensor = prim::GetAttr[name="weight"](%764)
  %767 : Float(512:1, 128:512) = aten::t(%766), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.48 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.64, %767), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.27 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.48, %765, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %770 : Tensor = prim::GetAttr[name="bias"](%763)
  %771 : Tensor = prim::GetAttr[name="weight"](%763)
  %772 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.27, %771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.65 : Float(119:1664, 13:128, 128:1) = aten::add(%772, %770, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %774 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.65, %residual_tensor.4)
  %775 : Float(119:1664, 13:128, 128:1), %776 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%774)
  %777 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13566.MobileBertSelfOutput = prim::GetAttr[name="output"](%748)
  %778 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13563.MobileBertSelfAttention = prim::GetAttr[name="self"](%748)
  %779 : __torch__.torch.nn.modules.linear.___torch_mangle_13561.Linear = prim::GetAttr[name="value"](%778)
  %780 : __torch__.torch.nn.modules.linear.___torch_mangle_13560.Linear = prim::GetAttr[name="key"](%778)
  %781 : __torch__.torch.nn.modules.linear.___torch_mangle_13559.Linear = prim::GetAttr[name="query"](%778)
  %782 : Tensor = prim::GetAttr[name="bias"](%781)
  %783 : Tensor = prim::GetAttr[name="weight"](%781)
  %784 : Float(128:1, 128:128) = aten::t(%783), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %output.49 : Float(119:1664, 13:128, 128:1) = aten::matmul(%775, %784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %x.19 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.49, %782, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1678:0
  %787 : Tensor = prim::GetAttr[name="bias"](%780)
  %788 : Tensor = prim::GetAttr[name="weight"](%780)
  %789 : Float(128:1, 128:128) = aten::t(%788), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %output.50 : Float(119:1664, 13:128, 128:1) = aten::matmul(%775, %789), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %x.21 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.50, %787, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1678:0
  %792 : Tensor = prim::GetAttr[name="bias"](%779)
  %793 : Tensor = prim::GetAttr[name="weight"](%779)
  %794 : Float(512:1, 128:512) = aten::t(%793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %output.51 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.64, %794), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %x.23 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.51, %792, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1678:0
  %797 : int = aten::size(%x.19, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %798 : int = aten::size(%x.19, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %799 : int[] = prim::ListConstruct(%797, %798, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.20 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.19, %799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %801 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %query_layer.4 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.20, %801), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %803 : int = aten::size(%x.21, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %804 : int = aten::size(%x.21, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %805 : int[] = prim::ListConstruct(%803, %804, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.22 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.21, %805), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %807 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %key_layer.4 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.22, %807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %809 : int = aten::size(%x.23, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %810 : int = aten::size(%x.23, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %811 : int[] = prim::ListConstruct(%809, %810, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.24 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.23, %811), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %813 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %value_layer.4 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.24, %813), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %815 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.4, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.7 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.4, %815), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.8 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.7, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.66 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.8, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.67 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.66, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.4 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.67, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.7 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.4, %value_layer.4), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:280:0
  %822 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %823 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.7, %822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.8 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%823, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %825 : int = aten::size(%context_layer.8, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %826 : int = aten::size(%context_layer.8, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %827 : int[] = prim::ListConstruct(%825, %826, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %input.68 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.8, %827), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:283:0
  %829 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13565.NoNorm = prim::GetAttr[name="LayerNorm"](%777)
  %830 : __torch__.torch.nn.modules.linear.___torch_mangle_13564.Linear = prim::GetAttr[name="dense"](%777)
  %831 : Tensor = prim::GetAttr[name="bias"](%830)
  %832 : Tensor = prim::GetAttr[name="weight"](%830)
  %833 : Float(128:1, 128:128) = aten::t(%832), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %output.52 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.68, %833), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.16 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.52, %831, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.28 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.16, %776, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output # transformers/modeling_mobilebert.py:301:0
  %837 : Tensor = prim::GetAttr[name="bias"](%829)
  %838 : Tensor = prim::GetAttr[name="weight"](%829)
  %839 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.28, %838), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.69 : Float(119:1664, 13:128, 128:1) = aten::add(%839, %837, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %841 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13588.FFNOutput = prim::GetAttr[name="output"](%747)
  %842 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13585.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%747)
  %843 : __torch__.torch.nn.modules.linear.___torch_mangle_13584.Linear = prim::GetAttr[name="dense"](%842)
  %844 : Tensor = prim::GetAttr[name="bias"](%843)
  %845 : Tensor = prim::GetAttr[name="weight"](%843)
  %846 : Float(128:1, 512:128) = aten::t(%845), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.53 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.69, %846), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.70 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.53, %844, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.71 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.70), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %850 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13587.NoNorm = prim::GetAttr[name="LayerNorm"](%841)
  %851 : __torch__.torch.nn.modules.linear.___torch_mangle_13586.Linear = prim::GetAttr[name="dense"](%841)
  %852 : Tensor = prim::GetAttr[name="bias"](%851)
  %853 : Tensor = prim::GetAttr[name="weight"](%851)
  %854 : Float(512:1, 128:512) = aten::t(%853), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.54 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.71, %854), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.17 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.54, %852, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.29 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.17, %input.69, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %858 : Tensor = prim::GetAttr[name="bias"](%850)
  %859 : Tensor = prim::GetAttr[name="weight"](%850)
  %860 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.29, %859), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.72 : Float(119:1664, 13:128, 128:1) = aten::add(%860, %858, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %862 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13594.FFNOutput = prim::GetAttr[name="output"](%745)
  %863 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13591.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%745)
  %864 : __torch__.torch.nn.modules.linear.___torch_mangle_13590.Linear = prim::GetAttr[name="dense"](%863)
  %865 : Tensor = prim::GetAttr[name="bias"](%864)
  %866 : Tensor = prim::GetAttr[name="weight"](%864)
  %867 : Float(128:1, 512:128) = aten::t(%866), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.55 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.72, %867), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.73 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.55, %865, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.74 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.73), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %871 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13593.NoNorm = prim::GetAttr[name="LayerNorm"](%862)
  %872 : __torch__.torch.nn.modules.linear.___torch_mangle_13592.Linear = prim::GetAttr[name="dense"](%862)
  %873 : Tensor = prim::GetAttr[name="bias"](%872)
  %874 : Tensor = prim::GetAttr[name="weight"](%872)
  %875 : Float(512:1, 128:512) = aten::t(%874), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.56 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.74, %875), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.18 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.56, %873, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.30 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.18, %input.72, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %879 : Tensor = prim::GetAttr[name="bias"](%871)
  %880 : Tensor = prim::GetAttr[name="weight"](%871)
  %881 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.30, %880), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.75 : Float(119:1664, 13:128, 128:1) = aten::add(%881, %879, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %883 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13600.FFNOutput = prim::GetAttr[name="output"](%743)
  %884 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13597.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%743)
  %885 : __torch__.torch.nn.modules.linear.___torch_mangle_13596.Linear = prim::GetAttr[name="dense"](%884)
  %886 : Tensor = prim::GetAttr[name="bias"](%885)
  %887 : Tensor = prim::GetAttr[name="weight"](%885)
  %888 : Float(128:1, 512:128) = aten::t(%887), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.57 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.75, %888), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.76 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.57, %886, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.77 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.76), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %892 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13599.NoNorm = prim::GetAttr[name="LayerNorm"](%883)
  %893 : __torch__.torch.nn.modules.linear.___torch_mangle_13598.Linear = prim::GetAttr[name="dense"](%883)
  %894 : Tensor = prim::GetAttr[name="bias"](%893)
  %895 : Tensor = prim::GetAttr[name="weight"](%893)
  %896 : Float(512:1, 128:512) = aten::t(%895), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.58 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.77, %896), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.19 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.58, %894, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.31 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.19, %input.75, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %900 : Tensor = prim::GetAttr[name="bias"](%892)
  %901 : Tensor = prim::GetAttr[name="weight"](%892)
  %902 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.31, %901), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.78 : Float(119:1664, 13:128, 128:1) = aten::add(%902, %900, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %904 : __torch__.torch.nn.modules.linear.___torch_mangle_13568.Linear = prim::GetAttr[name="dense"](%741)
  %905 : Tensor = prim::GetAttr[name="bias"](%904)
  %906 : Tensor = prim::GetAttr[name="weight"](%904)
  %907 : Float(128:1, 512:128) = aten::t(%906), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %output.59 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.78, %907), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %input.79 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.59, %905, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1678:0
  %input.80 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.79), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate # torch/nn/functional.py:1119:0
  %911 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13575.OutputBottleneck = prim::GetAttr[name="bottleneck"](%740)
  %912 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13571.NoNorm = prim::GetAttr[name="LayerNorm"](%740)
  %913 : __torch__.torch.nn.modules.linear.___torch_mangle_13570.Linear = prim::GetAttr[name="dense"](%740)
  %914 : Tensor = prim::GetAttr[name="bias"](%913)
  %915 : Tensor = prim::GetAttr[name="weight"](%913)
  %916 : Float(512:1, 128:512) = aten::t(%915), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %output.60 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.80, %916), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %layer_output.4 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.60, %914, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.32 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.4, %input.78, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output # transformers/modeling_mobilebert.py:405:0
  %920 : Tensor = prim::GetAttr[name="bias"](%912)
  %921 : Tensor = prim::GetAttr[name="weight"](%912)
  %922 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.32, %921), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.81 : Float(119:1664, 13:128, 128:1) = aten::add(%922, %920, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %924 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13573.NoNorm = prim::GetAttr[name="LayerNorm"](%911)
  %925 : __torch__.torch.nn.modules.linear.___torch_mangle_13572.Linear = prim::GetAttr[name="dense"](%911)
  %926 : Tensor = prim::GetAttr[name="bias"](%925)
  %927 : Tensor = prim::GetAttr[name="weight"](%925)
  %928 : Float(128:1, 512:128) = aten::t(%927), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.61 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.81, %928), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.82 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.61, %926, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.20 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.82, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.33 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.20, %input.64, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %933 : Tensor = prim::GetAttr[name="bias"](%924)
  %934 : Tensor = prim::GetAttr[name="weight"](%924)
  %935 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.33, %934), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.83 : Float(119:6656, 13:512, 512:1) = aten::add(%935, %933, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %937 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13621.MobileBertOutput = prim::GetAttr[name="output"](%140)
  %938 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13614.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%140)
  %939 : __torch__.torch.nn.modules.container.___torch_mangle_13647.ModuleList = prim::GetAttr[name="ffn"](%140)
  %940 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13646.FFNLayer = prim::GetAttr[name="2"](%939)
  %941 : __torch__.torch.nn.modules.container.___torch_mangle_13647.ModuleList = prim::GetAttr[name="ffn"](%140)
  %942 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13640.FFNLayer = prim::GetAttr[name="1"](%941)
  %943 : __torch__.torch.nn.modules.container.___torch_mangle_13647.ModuleList = prim::GetAttr[name="ffn"](%140)
  %944 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13634.FFNLayer = prim::GetAttr[name="0"](%943)
  %945 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13612.MobileBertAttention = prim::GetAttr[name="attention"](%140)
  %946 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13628.Bottleneck = prim::GetAttr[name="bottleneck"](%140)
  %947 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13627.BottleneckLayer = prim::GetAttr[name="attention"](%946)
  %948 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13624.BottleneckLayer = prim::GetAttr[name="input"](%946)
  %949 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13623.NoNorm = prim::GetAttr[name="LayerNorm"](%948)
  %950 : __torch__.torch.nn.modules.linear.___torch_mangle_13622.Linear = prim::GetAttr[name="dense"](%948)
  %951 : Tensor = prim::GetAttr[name="bias"](%950)
  %952 : Tensor = prim::GetAttr[name="weight"](%950)
  %953 : Float(512:1, 128:512) = aten::t(%952), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.62 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.83, %953), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.34 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.62, %951, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %956 : Tensor = prim::GetAttr[name="bias"](%949)
  %957 : Tensor = prim::GetAttr[name="weight"](%949)
  %958 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.34, %957), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.5 : Float(119:1664, 13:128, 128:1) = aten::add(%958, %956, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %960 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13626.NoNorm = prim::GetAttr[name="LayerNorm"](%947)
  %961 : __torch__.torch.nn.modules.linear.___torch_mangle_13625.Linear = prim::GetAttr[name="dense"](%947)
  %962 : Tensor = prim::GetAttr[name="bias"](%961)
  %963 : Tensor = prim::GetAttr[name="weight"](%961)
  %964 : Float(512:1, 128:512) = aten::t(%963), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.63 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.83, %964), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.35 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.63, %962, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %967 : Tensor = prim::GetAttr[name="bias"](%960)
  %968 : Tensor = prim::GetAttr[name="weight"](%960)
  %969 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.35, %968), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.84 : Float(119:1664, 13:128, 128:1) = aten::add(%969, %967, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %971 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.84, %residual_tensor.5)
  %972 : Float(119:1664, 13:128, 128:1), %973 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%971)
  %974 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13611.MobileBertSelfOutput = prim::GetAttr[name="output"](%945)
  %975 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13608.MobileBertSelfAttention = prim::GetAttr[name="self"](%945)
  %976 : __torch__.torch.nn.modules.linear.___torch_mangle_13606.Linear = prim::GetAttr[name="value"](%975)
  %977 : __torch__.torch.nn.modules.linear.___torch_mangle_13605.Linear = prim::GetAttr[name="key"](%975)
  %978 : __torch__.torch.nn.modules.linear.___torch_mangle_13604.Linear = prim::GetAttr[name="query"](%975)
  %979 : Tensor = prim::GetAttr[name="bias"](%978)
  %980 : Tensor = prim::GetAttr[name="weight"](%978)
  %981 : Float(128:1, 128:128) = aten::t(%980), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %output.64 : Float(119:1664, 13:128, 128:1) = aten::matmul(%972, %981), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %x.25 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.64, %979, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1678:0
  %984 : Tensor = prim::GetAttr[name="bias"](%977)
  %985 : Tensor = prim::GetAttr[name="weight"](%977)
  %986 : Float(128:1, 128:128) = aten::t(%985), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %output.65 : Float(119:1664, 13:128, 128:1) = aten::matmul(%972, %986), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %x.27 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.65, %984, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1678:0
  %989 : Tensor = prim::GetAttr[name="bias"](%976)
  %990 : Tensor = prim::GetAttr[name="weight"](%976)
  %991 : Float(512:1, 128:512) = aten::t(%990), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %output.66 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.83, %991), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %x.29 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.66, %989, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1678:0
  %994 : int = aten::size(%x.25, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %995 : int = aten::size(%x.25, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %996 : int[] = prim::ListConstruct(%994, %995, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.26 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.25, %996), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %998 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %query_layer.5 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.26, %998), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %1000 : int = aten::size(%x.27, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1001 : int = aten::size(%x.27, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1002 : int[] = prim::ListConstruct(%1000, %1001, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.28 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.27, %1002), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %1004 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %key_layer.5 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.28, %1004), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %1006 : int = aten::size(%x.29, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1007 : int = aten::size(%x.29, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %1008 : int[] = prim::ListConstruct(%1006, %1007, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.30 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.29, %1008), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %1010 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %value_layer.5 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.30, %1010), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %1012 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.5, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.9 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.5, %1012), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.10 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.9, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.85 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.10, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.86 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.85, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.5 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.86, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.9 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.5, %value_layer.5), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:280:0
  %1019 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %1020 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.9, %1019), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.10 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1020, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %1022 : int = aten::size(%context_layer.10, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1023 : int = aten::size(%context_layer.10, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1024 : int[] = prim::ListConstruct(%1022, %1023, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %input.87 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.10, %1024), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:283:0
  %1026 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13610.NoNorm = prim::GetAttr[name="LayerNorm"](%974)
  %1027 : __torch__.torch.nn.modules.linear.___torch_mangle_13609.Linear = prim::GetAttr[name="dense"](%974)
  %1028 : Tensor = prim::GetAttr[name="bias"](%1027)
  %1029 : Tensor = prim::GetAttr[name="weight"](%1027)
  %1030 : Float(128:1, 128:128) = aten::t(%1029), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %output.67 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.87, %1030), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.21 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.67, %1028, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.36 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.21, %973, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output # transformers/modeling_mobilebert.py:301:0
  %1034 : Tensor = prim::GetAttr[name="bias"](%1026)
  %1035 : Tensor = prim::GetAttr[name="weight"](%1026)
  %1036 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.36, %1035), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.88 : Float(119:1664, 13:128, 128:1) = aten::add(%1036, %1034, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1038 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13633.FFNOutput = prim::GetAttr[name="output"](%944)
  %1039 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13630.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%944)
  %1040 : __torch__.torch.nn.modules.linear.___torch_mangle_13629.Linear = prim::GetAttr[name="dense"](%1039)
  %1041 : Tensor = prim::GetAttr[name="bias"](%1040)
  %1042 : Tensor = prim::GetAttr[name="weight"](%1040)
  %1043 : Float(128:1, 512:128) = aten::t(%1042), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.68 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.88, %1043), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.89 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.68, %1041, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.90 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.89), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1047 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13632.NoNorm = prim::GetAttr[name="LayerNorm"](%1038)
  %1048 : __torch__.torch.nn.modules.linear.___torch_mangle_13631.Linear = prim::GetAttr[name="dense"](%1038)
  %1049 : Tensor = prim::GetAttr[name="bias"](%1048)
  %1050 : Tensor = prim::GetAttr[name="weight"](%1048)
  %1051 : Float(512:1, 128:512) = aten::t(%1050), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.69 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.90, %1051), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.22 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.69, %1049, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.37 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.22, %input.88, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1055 : Tensor = prim::GetAttr[name="bias"](%1047)
  %1056 : Tensor = prim::GetAttr[name="weight"](%1047)
  %1057 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.37, %1056), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.91 : Float(119:1664, 13:128, 128:1) = aten::add(%1057, %1055, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1059 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13639.FFNOutput = prim::GetAttr[name="output"](%942)
  %1060 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13636.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%942)
  %1061 : __torch__.torch.nn.modules.linear.___torch_mangle_13635.Linear = prim::GetAttr[name="dense"](%1060)
  %1062 : Tensor = prim::GetAttr[name="bias"](%1061)
  %1063 : Tensor = prim::GetAttr[name="weight"](%1061)
  %1064 : Float(128:1, 512:128) = aten::t(%1063), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.70 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.91, %1064), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.92 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.70, %1062, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.93 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.92), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1068 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13638.NoNorm = prim::GetAttr[name="LayerNorm"](%1059)
  %1069 : __torch__.torch.nn.modules.linear.___torch_mangle_13637.Linear = prim::GetAttr[name="dense"](%1059)
  %1070 : Tensor = prim::GetAttr[name="bias"](%1069)
  %1071 : Tensor = prim::GetAttr[name="weight"](%1069)
  %1072 : Float(512:1, 128:512) = aten::t(%1071), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.71 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.93, %1072), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.23 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.71, %1070, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.38 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.23, %input.91, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1076 : Tensor = prim::GetAttr[name="bias"](%1068)
  %1077 : Tensor = prim::GetAttr[name="weight"](%1068)
  %1078 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.38, %1077), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.94 : Float(119:1664, 13:128, 128:1) = aten::add(%1078, %1076, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1080 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13645.FFNOutput = prim::GetAttr[name="output"](%940)
  %1081 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13642.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%940)
  %1082 : __torch__.torch.nn.modules.linear.___torch_mangle_13641.Linear = prim::GetAttr[name="dense"](%1081)
  %1083 : Tensor = prim::GetAttr[name="bias"](%1082)
  %1084 : Tensor = prim::GetAttr[name="weight"](%1082)
  %1085 : Float(128:1, 512:128) = aten::t(%1084), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.72 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.94, %1085), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.95 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.72, %1083, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.96 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.95), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1089 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13644.NoNorm = prim::GetAttr[name="LayerNorm"](%1080)
  %1090 : __torch__.torch.nn.modules.linear.___torch_mangle_13643.Linear = prim::GetAttr[name="dense"](%1080)
  %1091 : Tensor = prim::GetAttr[name="bias"](%1090)
  %1092 : Tensor = prim::GetAttr[name="weight"](%1090)
  %1093 : Float(512:1, 128:512) = aten::t(%1092), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.73 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.96, %1093), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.24 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.73, %1091, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.39 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.24, %input.94, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1097 : Tensor = prim::GetAttr[name="bias"](%1089)
  %1098 : Tensor = prim::GetAttr[name="weight"](%1089)
  %1099 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.39, %1098), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.97 : Float(119:1664, 13:128, 128:1) = aten::add(%1099, %1097, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1101 : __torch__.torch.nn.modules.linear.___torch_mangle_13613.Linear = prim::GetAttr[name="dense"](%938)
  %1102 : Tensor = prim::GetAttr[name="bias"](%1101)
  %1103 : Tensor = prim::GetAttr[name="weight"](%1101)
  %1104 : Float(128:1, 512:128) = aten::t(%1103), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %output.74 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.97, %1104), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %input.98 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.74, %1102, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1678:0
  %input.99 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.98), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate # torch/nn/functional.py:1119:0
  %1108 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13620.OutputBottleneck = prim::GetAttr[name="bottleneck"](%937)
  %1109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13616.NoNorm = prim::GetAttr[name="LayerNorm"](%937)
  %1110 : __torch__.torch.nn.modules.linear.___torch_mangle_13615.Linear = prim::GetAttr[name="dense"](%937)
  %1111 : Tensor = prim::GetAttr[name="bias"](%1110)
  %1112 : Tensor = prim::GetAttr[name="weight"](%1110)
  %1113 : Float(512:1, 128:512) = aten::t(%1112), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %output.75 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.99, %1113), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %layer_output.5 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.75, %1111, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.40 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.5, %input.97, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output # transformers/modeling_mobilebert.py:405:0
  %1117 : Tensor = prim::GetAttr[name="bias"](%1109)
  %1118 : Tensor = prim::GetAttr[name="weight"](%1109)
  %1119 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.40, %1118), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.100 : Float(119:1664, 13:128, 128:1) = aten::add(%1119, %1117, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1121 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13618.NoNorm = prim::GetAttr[name="LayerNorm"](%1108)
  %1122 : __torch__.torch.nn.modules.linear.___torch_mangle_13617.Linear = prim::GetAttr[name="dense"](%1108)
  %1123 : Tensor = prim::GetAttr[name="bias"](%1122)
  %1124 : Tensor = prim::GetAttr[name="weight"](%1122)
  %1125 : Float(128:1, 512:128) = aten::t(%1124), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.76 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.100, %1125), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.101 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.76, %1123, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.25 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.101, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.41 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.25, %input.83, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1130 : Tensor = prim::GetAttr[name="bias"](%1121)
  %1131 : Tensor = prim::GetAttr[name="weight"](%1121)
  %1132 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.41, %1131), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.102 : Float(119:6656, 13:512, 512:1) = aten::add(%1132, %1130, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1134 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13666.MobileBertOutput = prim::GetAttr[name="output"](%138)
  %1135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13659.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%138)
  %1136 : __torch__.torch.nn.modules.container.___torch_mangle_13692.ModuleList = prim::GetAttr[name="ffn"](%138)
  %1137 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13691.FFNLayer = prim::GetAttr[name="2"](%1136)
  %1138 : __torch__.torch.nn.modules.container.___torch_mangle_13692.ModuleList = prim::GetAttr[name="ffn"](%138)
  %1139 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13685.FFNLayer = prim::GetAttr[name="1"](%1138)
  %1140 : __torch__.torch.nn.modules.container.___torch_mangle_13692.ModuleList = prim::GetAttr[name="ffn"](%138)
  %1141 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13679.FFNLayer = prim::GetAttr[name="0"](%1140)
  %1142 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13657.MobileBertAttention = prim::GetAttr[name="attention"](%138)
  %1143 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13673.Bottleneck = prim::GetAttr[name="bottleneck"](%138)
  %1144 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13672.BottleneckLayer = prim::GetAttr[name="attention"](%1143)
  %1145 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13669.BottleneckLayer = prim::GetAttr[name="input"](%1143)
  %1146 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13668.NoNorm = prim::GetAttr[name="LayerNorm"](%1145)
  %1147 : __torch__.torch.nn.modules.linear.___torch_mangle_13667.Linear = prim::GetAttr[name="dense"](%1145)
  %1148 : Tensor = prim::GetAttr[name="bias"](%1147)
  %1149 : Tensor = prim::GetAttr[name="weight"](%1147)
  %1150 : Float(512:1, 128:512) = aten::t(%1149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.77 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.102, %1150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.42 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.77, %1148, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1153 : Tensor = prim::GetAttr[name="bias"](%1146)
  %1154 : Tensor = prim::GetAttr[name="weight"](%1146)
  %1155 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.42, %1154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.6 : Float(119:1664, 13:128, 128:1) = aten::add(%1155, %1153, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1157 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13671.NoNorm = prim::GetAttr[name="LayerNorm"](%1144)
  %1158 : __torch__.torch.nn.modules.linear.___torch_mangle_13670.Linear = prim::GetAttr[name="dense"](%1144)
  %1159 : Tensor = prim::GetAttr[name="bias"](%1158)
  %1160 : Tensor = prim::GetAttr[name="weight"](%1158)
  %1161 : Float(512:1, 128:512) = aten::t(%1160), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.78 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.102, %1161), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.43 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.78, %1159, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1164 : Tensor = prim::GetAttr[name="bias"](%1157)
  %1165 : Tensor = prim::GetAttr[name="weight"](%1157)
  %1166 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.43, %1165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.103 : Float(119:1664, 13:128, 128:1) = aten::add(%1166, %1164, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1168 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.103, %residual_tensor.6)
  %1169 : Float(119:1664, 13:128, 128:1), %1170 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%1168)
  %1171 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13656.MobileBertSelfOutput = prim::GetAttr[name="output"](%1142)
  %1172 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13653.MobileBertSelfAttention = prim::GetAttr[name="self"](%1142)
  %1173 : __torch__.torch.nn.modules.linear.___torch_mangle_13651.Linear = prim::GetAttr[name="value"](%1172)
  %1174 : __torch__.torch.nn.modules.linear.___torch_mangle_13650.Linear = prim::GetAttr[name="key"](%1172)
  %1175 : __torch__.torch.nn.modules.linear.___torch_mangle_13649.Linear = prim::GetAttr[name="query"](%1172)
  %1176 : Tensor = prim::GetAttr[name="bias"](%1175)
  %1177 : Tensor = prim::GetAttr[name="weight"](%1175)
  %1178 : Float(128:1, 128:128) = aten::t(%1177), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %output.79 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1169, %1178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %x.31 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.79, %1176, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1678:0
  %1181 : Tensor = prim::GetAttr[name="bias"](%1174)
  %1182 : Tensor = prim::GetAttr[name="weight"](%1174)
  %1183 : Float(128:1, 128:128) = aten::t(%1182), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %output.80 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1169, %1183), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %x.33 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.80, %1181, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1678:0
  %1186 : Tensor = prim::GetAttr[name="bias"](%1173)
  %1187 : Tensor = prim::GetAttr[name="weight"](%1173)
  %1188 : Float(512:1, 128:512) = aten::t(%1187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %output.81 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.102, %1188), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %x.35 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.81, %1186, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1678:0
  %1191 : int = aten::size(%x.31, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1192 : int = aten::size(%x.31, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1193 : int[] = prim::ListConstruct(%1191, %1192, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.32 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.31, %1193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1195 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %query_layer.6 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.32, %1195), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1197 : int = aten::size(%x.33, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1198 : int = aten::size(%x.33, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1199 : int[] = prim::ListConstruct(%1197, %1198, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.34 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.33, %1199), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1201 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %key_layer.6 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.34, %1201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1203 : int = aten::size(%x.35, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1204 : int = aten::size(%x.35, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1205 : int[] = prim::ListConstruct(%1203, %1204, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.36 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.35, %1205), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1207 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %value_layer.6 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.36, %1207), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1209 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.6, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.11 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.6, %1209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.12 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.11, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.104 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.12, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.105 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.104, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.6 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.105, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.11 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.6, %value_layer.6), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:280:0
  %1216 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %1217 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.11, %1216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.12 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1217, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %1219 : int = aten::size(%context_layer.12, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1220 : int = aten::size(%context_layer.12, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1221 : int[] = prim::ListConstruct(%1219, %1220, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %input.106 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.12, %1221), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:283:0
  %1223 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13655.NoNorm = prim::GetAttr[name="LayerNorm"](%1171)
  %1224 : __torch__.torch.nn.modules.linear.___torch_mangle_13654.Linear = prim::GetAttr[name="dense"](%1171)
  %1225 : Tensor = prim::GetAttr[name="bias"](%1224)
  %1226 : Tensor = prim::GetAttr[name="weight"](%1224)
  %1227 : Float(128:1, 128:128) = aten::t(%1226), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %output.82 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.106, %1227), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.26 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.82, %1225, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.44 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.26, %1170, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output # transformers/modeling_mobilebert.py:301:0
  %1231 : Tensor = prim::GetAttr[name="bias"](%1223)
  %1232 : Tensor = prim::GetAttr[name="weight"](%1223)
  %1233 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.44, %1232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.107 : Float(119:1664, 13:128, 128:1) = aten::add(%1233, %1231, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1235 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13678.FFNOutput = prim::GetAttr[name="output"](%1141)
  %1236 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13675.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1141)
  %1237 : __torch__.torch.nn.modules.linear.___torch_mangle_13674.Linear = prim::GetAttr[name="dense"](%1236)
  %1238 : Tensor = prim::GetAttr[name="bias"](%1237)
  %1239 : Tensor = prim::GetAttr[name="weight"](%1237)
  %1240 : Float(128:1, 512:128) = aten::t(%1239), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.83 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.107, %1240), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.108 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.83, %1238, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.109 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1244 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13677.NoNorm = prim::GetAttr[name="LayerNorm"](%1235)
  %1245 : __torch__.torch.nn.modules.linear.___torch_mangle_13676.Linear = prim::GetAttr[name="dense"](%1235)
  %1246 : Tensor = prim::GetAttr[name="bias"](%1245)
  %1247 : Tensor = prim::GetAttr[name="weight"](%1245)
  %1248 : Float(512:1, 128:512) = aten::t(%1247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.84 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.109, %1248), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.27 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.84, %1246, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.45 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.27, %input.107, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1252 : Tensor = prim::GetAttr[name="bias"](%1244)
  %1253 : Tensor = prim::GetAttr[name="weight"](%1244)
  %1254 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.45, %1253), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.110 : Float(119:1664, 13:128, 128:1) = aten::add(%1254, %1252, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1256 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13684.FFNOutput = prim::GetAttr[name="output"](%1139)
  %1257 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13681.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1139)
  %1258 : __torch__.torch.nn.modules.linear.___torch_mangle_13680.Linear = prim::GetAttr[name="dense"](%1257)
  %1259 : Tensor = prim::GetAttr[name="bias"](%1258)
  %1260 : Tensor = prim::GetAttr[name="weight"](%1258)
  %1261 : Float(128:1, 512:128) = aten::t(%1260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.85 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.110, %1261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.111 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.85, %1259, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.112 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1265 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13683.NoNorm = prim::GetAttr[name="LayerNorm"](%1256)
  %1266 : __torch__.torch.nn.modules.linear.___torch_mangle_13682.Linear = prim::GetAttr[name="dense"](%1256)
  %1267 : Tensor = prim::GetAttr[name="bias"](%1266)
  %1268 : Tensor = prim::GetAttr[name="weight"](%1266)
  %1269 : Float(512:1, 128:512) = aten::t(%1268), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.86 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.112, %1269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.28 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.86, %1267, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.46 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.28, %input.110, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1273 : Tensor = prim::GetAttr[name="bias"](%1265)
  %1274 : Tensor = prim::GetAttr[name="weight"](%1265)
  %1275 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.46, %1274), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.113 : Float(119:1664, 13:128, 128:1) = aten::add(%1275, %1273, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1277 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13690.FFNOutput = prim::GetAttr[name="output"](%1137)
  %1278 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13687.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1137)
  %1279 : __torch__.torch.nn.modules.linear.___torch_mangle_13686.Linear = prim::GetAttr[name="dense"](%1278)
  %1280 : Tensor = prim::GetAttr[name="bias"](%1279)
  %1281 : Tensor = prim::GetAttr[name="weight"](%1279)
  %1282 : Float(128:1, 512:128) = aten::t(%1281), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.87 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.113, %1282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.114 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.87, %1280, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.115 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.114), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1286 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13689.NoNorm = prim::GetAttr[name="LayerNorm"](%1277)
  %1287 : __torch__.torch.nn.modules.linear.___torch_mangle_13688.Linear = prim::GetAttr[name="dense"](%1277)
  %1288 : Tensor = prim::GetAttr[name="bias"](%1287)
  %1289 : Tensor = prim::GetAttr[name="weight"](%1287)
  %1290 : Float(512:1, 128:512) = aten::t(%1289), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.88 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.115, %1290), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.29 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.88, %1288, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.47 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.29, %input.113, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1294 : Tensor = prim::GetAttr[name="bias"](%1286)
  %1295 : Tensor = prim::GetAttr[name="weight"](%1286)
  %1296 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.47, %1295), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.116 : Float(119:1664, 13:128, 128:1) = aten::add(%1296, %1294, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1298 : __torch__.torch.nn.modules.linear.___torch_mangle_13658.Linear = prim::GetAttr[name="dense"](%1135)
  %1299 : Tensor = prim::GetAttr[name="bias"](%1298)
  %1300 : Tensor = prim::GetAttr[name="weight"](%1298)
  %1301 : Float(128:1, 512:128) = aten::t(%1300), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %output.89 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.116, %1301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %input.117 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.89, %1299, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1678:0
  %input.118 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.117), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate # torch/nn/functional.py:1119:0
  %1305 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13665.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1134)
  %1306 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13661.NoNorm = prim::GetAttr[name="LayerNorm"](%1134)
  %1307 : __torch__.torch.nn.modules.linear.___torch_mangle_13660.Linear = prim::GetAttr[name="dense"](%1134)
  %1308 : Tensor = prim::GetAttr[name="bias"](%1307)
  %1309 : Tensor = prim::GetAttr[name="weight"](%1307)
  %1310 : Float(512:1, 128:512) = aten::t(%1309), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %output.90 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.118, %1310), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %layer_output.6 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.90, %1308, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.48 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.6, %input.116, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output # transformers/modeling_mobilebert.py:405:0
  %1314 : Tensor = prim::GetAttr[name="bias"](%1306)
  %1315 : Tensor = prim::GetAttr[name="weight"](%1306)
  %1316 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.48, %1315), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.119 : Float(119:1664, 13:128, 128:1) = aten::add(%1316, %1314, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1318 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13663.NoNorm = prim::GetAttr[name="LayerNorm"](%1305)
  %1319 : __torch__.torch.nn.modules.linear.___torch_mangle_13662.Linear = prim::GetAttr[name="dense"](%1305)
  %1320 : Tensor = prim::GetAttr[name="bias"](%1319)
  %1321 : Tensor = prim::GetAttr[name="weight"](%1319)
  %1322 : Float(128:1, 512:128) = aten::t(%1321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.91 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.119, %1322), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.120 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.91, %1320, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.30 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.120, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.49 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.30, %input.102, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1327 : Tensor = prim::GetAttr[name="bias"](%1318)
  %1328 : Tensor = prim::GetAttr[name="weight"](%1318)
  %1329 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.49, %1328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.121 : Float(119:6656, 13:512, 512:1) = aten::add(%1329, %1327, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1331 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13711.MobileBertOutput = prim::GetAttr[name="output"](%136)
  %1332 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13704.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%136)
  %1333 : __torch__.torch.nn.modules.container.___torch_mangle_13737.ModuleList = prim::GetAttr[name="ffn"](%136)
  %1334 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13736.FFNLayer = prim::GetAttr[name="2"](%1333)
  %1335 : __torch__.torch.nn.modules.container.___torch_mangle_13737.ModuleList = prim::GetAttr[name="ffn"](%136)
  %1336 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13730.FFNLayer = prim::GetAttr[name="1"](%1335)
  %1337 : __torch__.torch.nn.modules.container.___torch_mangle_13737.ModuleList = prim::GetAttr[name="ffn"](%136)
  %1338 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13724.FFNLayer = prim::GetAttr[name="0"](%1337)
  %1339 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13702.MobileBertAttention = prim::GetAttr[name="attention"](%136)
  %1340 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13718.Bottleneck = prim::GetAttr[name="bottleneck"](%136)
  %1341 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13717.BottleneckLayer = prim::GetAttr[name="attention"](%1340)
  %1342 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13714.BottleneckLayer = prim::GetAttr[name="input"](%1340)
  %1343 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13713.NoNorm = prim::GetAttr[name="LayerNorm"](%1342)
  %1344 : __torch__.torch.nn.modules.linear.___torch_mangle_13712.Linear = prim::GetAttr[name="dense"](%1342)
  %1345 : Tensor = prim::GetAttr[name="bias"](%1344)
  %1346 : Tensor = prim::GetAttr[name="weight"](%1344)
  %1347 : Float(512:1, 128:512) = aten::t(%1346), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.92 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.121, %1347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.50 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.92, %1345, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1350 : Tensor = prim::GetAttr[name="bias"](%1343)
  %1351 : Tensor = prim::GetAttr[name="weight"](%1343)
  %1352 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.50, %1351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.7 : Float(119:1664, 13:128, 128:1) = aten::add(%1352, %1350, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1354 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13716.NoNorm = prim::GetAttr[name="LayerNorm"](%1341)
  %1355 : __torch__.torch.nn.modules.linear.___torch_mangle_13715.Linear = prim::GetAttr[name="dense"](%1341)
  %1356 : Tensor = prim::GetAttr[name="bias"](%1355)
  %1357 : Tensor = prim::GetAttr[name="weight"](%1355)
  %1358 : Float(512:1, 128:512) = aten::t(%1357), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.93 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.121, %1358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.51 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.93, %1356, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1361 : Tensor = prim::GetAttr[name="bias"](%1354)
  %1362 : Tensor = prim::GetAttr[name="weight"](%1354)
  %1363 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.51, %1362), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.122 : Float(119:1664, 13:128, 128:1) = aten::add(%1363, %1361, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1365 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.122, %residual_tensor.7)
  %1366 : Float(119:1664, 13:128, 128:1), %1367 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%1365)
  %1368 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13701.MobileBertSelfOutput = prim::GetAttr[name="output"](%1339)
  %1369 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13698.MobileBertSelfAttention = prim::GetAttr[name="self"](%1339)
  %1370 : __torch__.torch.nn.modules.linear.___torch_mangle_13696.Linear = prim::GetAttr[name="value"](%1369)
  %1371 : __torch__.torch.nn.modules.linear.___torch_mangle_13695.Linear = prim::GetAttr[name="key"](%1369)
  %1372 : __torch__.torch.nn.modules.linear.___torch_mangle_13694.Linear = prim::GetAttr[name="query"](%1369)
  %1373 : Tensor = prim::GetAttr[name="bias"](%1372)
  %1374 : Tensor = prim::GetAttr[name="weight"](%1372)
  %1375 : Float(128:1, 128:128) = aten::t(%1374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %output.94 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1366, %1375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %x.37 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.94, %1373, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1678:0
  %1378 : Tensor = prim::GetAttr[name="bias"](%1371)
  %1379 : Tensor = prim::GetAttr[name="weight"](%1371)
  %1380 : Float(128:1, 128:128) = aten::t(%1379), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %output.95 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1366, %1380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %x.39 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.95, %1378, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1678:0
  %1383 : Tensor = prim::GetAttr[name="bias"](%1370)
  %1384 : Tensor = prim::GetAttr[name="weight"](%1370)
  %1385 : Float(512:1, 128:512) = aten::t(%1384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %output.96 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.121, %1385), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %x.41 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.96, %1383, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1678:0
  %1388 : int = aten::size(%x.37, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1389 : int = aten::size(%x.37, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1390 : int[] = prim::ListConstruct(%1388, %1389, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.38 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.37, %1390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1392 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %query_layer.7 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.38, %1392), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1394 : int = aten::size(%x.39, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1395 : int = aten::size(%x.39, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1396 : int[] = prim::ListConstruct(%1394, %1395, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.40 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.39, %1396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1398 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %key_layer.7 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.40, %1398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1400 : int = aten::size(%x.41, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1401 : int = aten::size(%x.41, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1402 : int[] = prim::ListConstruct(%1400, %1401, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.42 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.41, %1402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1404 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %value_layer.7 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.42, %1404), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1406 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.7, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.13 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.7, %1406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.14 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.13, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.123 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.14, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.124 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.123, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.7 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.124, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.13 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.7, %value_layer.7), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:280:0
  %1413 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %1414 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.13, %1413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.14 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1414, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %1416 : int = aten::size(%context_layer.14, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1417 : int = aten::size(%context_layer.14, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1418 : int[] = prim::ListConstruct(%1416, %1417, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %input.125 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.14, %1418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:283:0
  %1420 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13700.NoNorm = prim::GetAttr[name="LayerNorm"](%1368)
  %1421 : __torch__.torch.nn.modules.linear.___torch_mangle_13699.Linear = prim::GetAttr[name="dense"](%1368)
  %1422 : Tensor = prim::GetAttr[name="bias"](%1421)
  %1423 : Tensor = prim::GetAttr[name="weight"](%1421)
  %1424 : Float(128:1, 128:128) = aten::t(%1423), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %output.97 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.125, %1424), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.31 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.97, %1422, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.52 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.31, %1367, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output # transformers/modeling_mobilebert.py:301:0
  %1428 : Tensor = prim::GetAttr[name="bias"](%1420)
  %1429 : Tensor = prim::GetAttr[name="weight"](%1420)
  %1430 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.52, %1429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.126 : Float(119:1664, 13:128, 128:1) = aten::add(%1430, %1428, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1432 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13723.FFNOutput = prim::GetAttr[name="output"](%1338)
  %1433 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13720.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1338)
  %1434 : __torch__.torch.nn.modules.linear.___torch_mangle_13719.Linear = prim::GetAttr[name="dense"](%1433)
  %1435 : Tensor = prim::GetAttr[name="bias"](%1434)
  %1436 : Tensor = prim::GetAttr[name="weight"](%1434)
  %1437 : Float(128:1, 512:128) = aten::t(%1436), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.98 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.126, %1437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.127 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.98, %1435, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.128 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1441 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13722.NoNorm = prim::GetAttr[name="LayerNorm"](%1432)
  %1442 : __torch__.torch.nn.modules.linear.___torch_mangle_13721.Linear = prim::GetAttr[name="dense"](%1432)
  %1443 : Tensor = prim::GetAttr[name="bias"](%1442)
  %1444 : Tensor = prim::GetAttr[name="weight"](%1442)
  %1445 : Float(512:1, 128:512) = aten::t(%1444), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.99 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.128, %1445), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.32 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.99, %1443, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.53 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.32, %input.126, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1449 : Tensor = prim::GetAttr[name="bias"](%1441)
  %1450 : Tensor = prim::GetAttr[name="weight"](%1441)
  %1451 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.53, %1450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.129 : Float(119:1664, 13:128, 128:1) = aten::add(%1451, %1449, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1453 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13729.FFNOutput = prim::GetAttr[name="output"](%1336)
  %1454 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13726.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1336)
  %1455 : __torch__.torch.nn.modules.linear.___torch_mangle_13725.Linear = prim::GetAttr[name="dense"](%1454)
  %1456 : Tensor = prim::GetAttr[name="bias"](%1455)
  %1457 : Tensor = prim::GetAttr[name="weight"](%1455)
  %1458 : Float(128:1, 512:128) = aten::t(%1457), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.100 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.129, %1458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.130 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.100, %1456, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.131 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1462 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13728.NoNorm = prim::GetAttr[name="LayerNorm"](%1453)
  %1463 : __torch__.torch.nn.modules.linear.___torch_mangle_13727.Linear = prim::GetAttr[name="dense"](%1453)
  %1464 : Tensor = prim::GetAttr[name="bias"](%1463)
  %1465 : Tensor = prim::GetAttr[name="weight"](%1463)
  %1466 : Float(512:1, 128:512) = aten::t(%1465), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.101 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.131, %1466), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.33 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.101, %1464, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.54 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.33, %input.129, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1470 : Tensor = prim::GetAttr[name="bias"](%1462)
  %1471 : Tensor = prim::GetAttr[name="weight"](%1462)
  %1472 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.54, %1471), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.132 : Float(119:1664, 13:128, 128:1) = aten::add(%1472, %1470, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1474 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13735.FFNOutput = prim::GetAttr[name="output"](%1334)
  %1475 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13732.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1334)
  %1476 : __torch__.torch.nn.modules.linear.___torch_mangle_13731.Linear = prim::GetAttr[name="dense"](%1475)
  %1477 : Tensor = prim::GetAttr[name="bias"](%1476)
  %1478 : Tensor = prim::GetAttr[name="weight"](%1476)
  %1479 : Float(128:1, 512:128) = aten::t(%1478), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.102 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.132, %1479), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.133 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.102, %1477, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.134 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1483 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13734.NoNorm = prim::GetAttr[name="LayerNorm"](%1474)
  %1484 : __torch__.torch.nn.modules.linear.___torch_mangle_13733.Linear = prim::GetAttr[name="dense"](%1474)
  %1485 : Tensor = prim::GetAttr[name="bias"](%1484)
  %1486 : Tensor = prim::GetAttr[name="weight"](%1484)
  %1487 : Float(512:1, 128:512) = aten::t(%1486), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.103 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.134, %1487), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.34 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.103, %1485, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.55 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.34, %input.132, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1491 : Tensor = prim::GetAttr[name="bias"](%1483)
  %1492 : Tensor = prim::GetAttr[name="weight"](%1483)
  %1493 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.55, %1492), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.135 : Float(119:1664, 13:128, 128:1) = aten::add(%1493, %1491, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1495 : __torch__.torch.nn.modules.linear.___torch_mangle_13703.Linear = prim::GetAttr[name="dense"](%1332)
  %1496 : Tensor = prim::GetAttr[name="bias"](%1495)
  %1497 : Tensor = prim::GetAttr[name="weight"](%1495)
  %1498 : Float(128:1, 512:128) = aten::t(%1497), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %output.104 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.135, %1498), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %input.136 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.104, %1496, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1678:0
  %input.137 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.136), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate # torch/nn/functional.py:1119:0
  %1502 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13710.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1331)
  %1503 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13706.NoNorm = prim::GetAttr[name="LayerNorm"](%1331)
  %1504 : __torch__.torch.nn.modules.linear.___torch_mangle_13705.Linear = prim::GetAttr[name="dense"](%1331)
  %1505 : Tensor = prim::GetAttr[name="bias"](%1504)
  %1506 : Tensor = prim::GetAttr[name="weight"](%1504)
  %1507 : Float(512:1, 128:512) = aten::t(%1506), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %output.105 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.137, %1507), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %layer_output.7 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.105, %1505, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.56 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.7, %input.135, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output # transformers/modeling_mobilebert.py:405:0
  %1511 : Tensor = prim::GetAttr[name="bias"](%1503)
  %1512 : Tensor = prim::GetAttr[name="weight"](%1503)
  %1513 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.56, %1512), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.138 : Float(119:1664, 13:128, 128:1) = aten::add(%1513, %1511, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1515 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13708.NoNorm = prim::GetAttr[name="LayerNorm"](%1502)
  %1516 : __torch__.torch.nn.modules.linear.___torch_mangle_13707.Linear = prim::GetAttr[name="dense"](%1502)
  %1517 : Tensor = prim::GetAttr[name="bias"](%1516)
  %1518 : Tensor = prim::GetAttr[name="weight"](%1516)
  %1519 : Float(128:1, 512:128) = aten::t(%1518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.106 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.138, %1519), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.139 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.106, %1517, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.35 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.139, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.57 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.35, %input.121, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1524 : Tensor = prim::GetAttr[name="bias"](%1515)
  %1525 : Tensor = prim::GetAttr[name="weight"](%1515)
  %1526 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.57, %1525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.140 : Float(119:6656, 13:512, 512:1) = aten::add(%1526, %1524, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1528 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13756.MobileBertOutput = prim::GetAttr[name="output"](%134)
  %1529 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13749.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%134)
  %1530 : __torch__.torch.nn.modules.container.___torch_mangle_13782.ModuleList = prim::GetAttr[name="ffn"](%134)
  %1531 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13781.FFNLayer = prim::GetAttr[name="2"](%1530)
  %1532 : __torch__.torch.nn.modules.container.___torch_mangle_13782.ModuleList = prim::GetAttr[name="ffn"](%134)
  %1533 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13775.FFNLayer = prim::GetAttr[name="1"](%1532)
  %1534 : __torch__.torch.nn.modules.container.___torch_mangle_13782.ModuleList = prim::GetAttr[name="ffn"](%134)
  %1535 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13769.FFNLayer = prim::GetAttr[name="0"](%1534)
  %1536 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13747.MobileBertAttention = prim::GetAttr[name="attention"](%134)
  %1537 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13763.Bottleneck = prim::GetAttr[name="bottleneck"](%134)
  %1538 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13762.BottleneckLayer = prim::GetAttr[name="attention"](%1537)
  %1539 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13759.BottleneckLayer = prim::GetAttr[name="input"](%1537)
  %1540 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13758.NoNorm = prim::GetAttr[name="LayerNorm"](%1539)
  %1541 : __torch__.torch.nn.modules.linear.___torch_mangle_13757.Linear = prim::GetAttr[name="dense"](%1539)
  %1542 : Tensor = prim::GetAttr[name="bias"](%1541)
  %1543 : Tensor = prim::GetAttr[name="weight"](%1541)
  %1544 : Float(512:1, 128:512) = aten::t(%1543), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.107 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.140, %1544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.58 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.107, %1542, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1547 : Tensor = prim::GetAttr[name="bias"](%1540)
  %1548 : Tensor = prim::GetAttr[name="weight"](%1540)
  %1549 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.58, %1548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.8 : Float(119:1664, 13:128, 128:1) = aten::add(%1549, %1547, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1551 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13761.NoNorm = prim::GetAttr[name="LayerNorm"](%1538)
  %1552 : __torch__.torch.nn.modules.linear.___torch_mangle_13760.Linear = prim::GetAttr[name="dense"](%1538)
  %1553 : Tensor = prim::GetAttr[name="bias"](%1552)
  %1554 : Tensor = prim::GetAttr[name="weight"](%1552)
  %1555 : Float(512:1, 128:512) = aten::t(%1554), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.108 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.140, %1555), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.59 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.108, %1553, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1558 : Tensor = prim::GetAttr[name="bias"](%1551)
  %1559 : Tensor = prim::GetAttr[name="weight"](%1551)
  %1560 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.59, %1559), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.141 : Float(119:1664, 13:128, 128:1) = aten::add(%1560, %1558, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1562 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.141, %residual_tensor.8)
  %1563 : Float(119:1664, 13:128, 128:1), %1564 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%1562)
  %1565 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13746.MobileBertSelfOutput = prim::GetAttr[name="output"](%1536)
  %1566 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13743.MobileBertSelfAttention = prim::GetAttr[name="self"](%1536)
  %1567 : __torch__.torch.nn.modules.linear.___torch_mangle_13741.Linear = prim::GetAttr[name="value"](%1566)
  %1568 : __torch__.torch.nn.modules.linear.___torch_mangle_13740.Linear = prim::GetAttr[name="key"](%1566)
  %1569 : __torch__.torch.nn.modules.linear.___torch_mangle_13739.Linear = prim::GetAttr[name="query"](%1566)
  %1570 : Tensor = prim::GetAttr[name="bias"](%1569)
  %1571 : Tensor = prim::GetAttr[name="weight"](%1569)
  %1572 : Float(128:1, 128:128) = aten::t(%1571), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %output.109 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1563, %1572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %x.43 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.109, %1570, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1678:0
  %1575 : Tensor = prim::GetAttr[name="bias"](%1568)
  %1576 : Tensor = prim::GetAttr[name="weight"](%1568)
  %1577 : Float(128:1, 128:128) = aten::t(%1576), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %output.110 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1563, %1577), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %x.45 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.110, %1575, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1678:0
  %1580 : Tensor = prim::GetAttr[name="bias"](%1567)
  %1581 : Tensor = prim::GetAttr[name="weight"](%1567)
  %1582 : Float(512:1, 128:512) = aten::t(%1581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %output.111 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.140, %1582), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %x.47 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.111, %1580, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1678:0
  %1585 : int = aten::size(%x.43, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1586 : int = aten::size(%x.43, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1587 : int[] = prim::ListConstruct(%1585, %1586, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.44 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.43, %1587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1589 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %query_layer.8 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.44, %1589), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1591 : int = aten::size(%x.45, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1592 : int = aten::size(%x.45, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1593 : int[] = prim::ListConstruct(%1591, %1592, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.46 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.45, %1593), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1595 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %key_layer.8 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.46, %1595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1597 : int = aten::size(%x.47, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1598 : int = aten::size(%x.47, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1599 : int[] = prim::ListConstruct(%1597, %1598, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.48 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.47, %1599), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1601 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %value_layer.8 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.48, %1601), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1603 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.8, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.15 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.8, %1603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.16 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.15, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.142 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.16, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.143 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.142, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.8 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.143, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.15 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.8, %value_layer.8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:280:0
  %1610 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %1611 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.15, %1610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.16 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1611, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %1613 : int = aten::size(%context_layer.16, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1614 : int = aten::size(%context_layer.16, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1615 : int[] = prim::ListConstruct(%1613, %1614, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %input.144 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.16, %1615), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:283:0
  %1617 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13745.NoNorm = prim::GetAttr[name="LayerNorm"](%1565)
  %1618 : __torch__.torch.nn.modules.linear.___torch_mangle_13744.Linear = prim::GetAttr[name="dense"](%1565)
  %1619 : Tensor = prim::GetAttr[name="bias"](%1618)
  %1620 : Tensor = prim::GetAttr[name="weight"](%1618)
  %1621 : Float(128:1, 128:128) = aten::t(%1620), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %output.112 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.144, %1621), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.36 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.112, %1619, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.60 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.36, %1564, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output # transformers/modeling_mobilebert.py:301:0
  %1625 : Tensor = prim::GetAttr[name="bias"](%1617)
  %1626 : Tensor = prim::GetAttr[name="weight"](%1617)
  %1627 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.60, %1626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.145 : Float(119:1664, 13:128, 128:1) = aten::add(%1627, %1625, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1629 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13768.FFNOutput = prim::GetAttr[name="output"](%1535)
  %1630 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13765.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1535)
  %1631 : __torch__.torch.nn.modules.linear.___torch_mangle_13764.Linear = prim::GetAttr[name="dense"](%1630)
  %1632 : Tensor = prim::GetAttr[name="bias"](%1631)
  %1633 : Tensor = prim::GetAttr[name="weight"](%1631)
  %1634 : Float(128:1, 512:128) = aten::t(%1633), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.113 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.145, %1634), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.146 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.113, %1632, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.147 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1638 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13767.NoNorm = prim::GetAttr[name="LayerNorm"](%1629)
  %1639 : __torch__.torch.nn.modules.linear.___torch_mangle_13766.Linear = prim::GetAttr[name="dense"](%1629)
  %1640 : Tensor = prim::GetAttr[name="bias"](%1639)
  %1641 : Tensor = prim::GetAttr[name="weight"](%1639)
  %1642 : Float(512:1, 128:512) = aten::t(%1641), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.114 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.147, %1642), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.37 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.114, %1640, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.61 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.37, %input.145, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1646 : Tensor = prim::GetAttr[name="bias"](%1638)
  %1647 : Tensor = prim::GetAttr[name="weight"](%1638)
  %1648 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.61, %1647), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.148 : Float(119:1664, 13:128, 128:1) = aten::add(%1648, %1646, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1650 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13774.FFNOutput = prim::GetAttr[name="output"](%1533)
  %1651 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13771.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1533)
  %1652 : __torch__.torch.nn.modules.linear.___torch_mangle_13770.Linear = prim::GetAttr[name="dense"](%1651)
  %1653 : Tensor = prim::GetAttr[name="bias"](%1652)
  %1654 : Tensor = prim::GetAttr[name="weight"](%1652)
  %1655 : Float(128:1, 512:128) = aten::t(%1654), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.115 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.148, %1655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.149 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.115, %1653, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.150 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1659 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13773.NoNorm = prim::GetAttr[name="LayerNorm"](%1650)
  %1660 : __torch__.torch.nn.modules.linear.___torch_mangle_13772.Linear = prim::GetAttr[name="dense"](%1650)
  %1661 : Tensor = prim::GetAttr[name="bias"](%1660)
  %1662 : Tensor = prim::GetAttr[name="weight"](%1660)
  %1663 : Float(512:1, 128:512) = aten::t(%1662), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.116 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.150, %1663), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.38 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.116, %1661, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.62 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.38, %input.148, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1667 : Tensor = prim::GetAttr[name="bias"](%1659)
  %1668 : Tensor = prim::GetAttr[name="weight"](%1659)
  %1669 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.62, %1668), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.151 : Float(119:1664, 13:128, 128:1) = aten::add(%1669, %1667, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1671 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13780.FFNOutput = prim::GetAttr[name="output"](%1531)
  %1672 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13777.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1531)
  %1673 : __torch__.torch.nn.modules.linear.___torch_mangle_13776.Linear = prim::GetAttr[name="dense"](%1672)
  %1674 : Tensor = prim::GetAttr[name="bias"](%1673)
  %1675 : Tensor = prim::GetAttr[name="weight"](%1673)
  %1676 : Float(128:1, 512:128) = aten::t(%1675), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.117 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.151, %1676), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.152 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.117, %1674, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.153 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1680 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13779.NoNorm = prim::GetAttr[name="LayerNorm"](%1671)
  %1681 : __torch__.torch.nn.modules.linear.___torch_mangle_13778.Linear = prim::GetAttr[name="dense"](%1671)
  %1682 : Tensor = prim::GetAttr[name="bias"](%1681)
  %1683 : Tensor = prim::GetAttr[name="weight"](%1681)
  %1684 : Float(512:1, 128:512) = aten::t(%1683), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.118 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.153, %1684), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.39 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.118, %1682, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.63 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.39, %input.151, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1688 : Tensor = prim::GetAttr[name="bias"](%1680)
  %1689 : Tensor = prim::GetAttr[name="weight"](%1680)
  %1690 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.63, %1689), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.154 : Float(119:1664, 13:128, 128:1) = aten::add(%1690, %1688, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1692 : __torch__.torch.nn.modules.linear.___torch_mangle_13748.Linear = prim::GetAttr[name="dense"](%1529)
  %1693 : Tensor = prim::GetAttr[name="bias"](%1692)
  %1694 : Tensor = prim::GetAttr[name="weight"](%1692)
  %1695 : Float(128:1, 512:128) = aten::t(%1694), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %output.119 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.154, %1695), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %input.155 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.119, %1693, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1678:0
  %input.156 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate # torch/nn/functional.py:1119:0
  %1699 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13755.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1528)
  %1700 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13751.NoNorm = prim::GetAttr[name="LayerNorm"](%1528)
  %1701 : __torch__.torch.nn.modules.linear.___torch_mangle_13750.Linear = prim::GetAttr[name="dense"](%1528)
  %1702 : Tensor = prim::GetAttr[name="bias"](%1701)
  %1703 : Tensor = prim::GetAttr[name="weight"](%1701)
  %1704 : Float(512:1, 128:512) = aten::t(%1703), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %output.120 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.156, %1704), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %layer_output.8 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.120, %1702, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.64 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.8, %input.154, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output # transformers/modeling_mobilebert.py:405:0
  %1708 : Tensor = prim::GetAttr[name="bias"](%1700)
  %1709 : Tensor = prim::GetAttr[name="weight"](%1700)
  %1710 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.64, %1709), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.157 : Float(119:1664, 13:128, 128:1) = aten::add(%1710, %1708, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1712 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13753.NoNorm = prim::GetAttr[name="LayerNorm"](%1699)
  %1713 : __torch__.torch.nn.modules.linear.___torch_mangle_13752.Linear = prim::GetAttr[name="dense"](%1699)
  %1714 : Tensor = prim::GetAttr[name="bias"](%1713)
  %1715 : Tensor = prim::GetAttr[name="weight"](%1713)
  %1716 : Float(128:1, 512:128) = aten::t(%1715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.121 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.157, %1716), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.158 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.121, %1714, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.40 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.158, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.65 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.40, %input.140, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1721 : Tensor = prim::GetAttr[name="bias"](%1712)
  %1722 : Tensor = prim::GetAttr[name="weight"](%1712)
  %1723 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.65, %1722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.159 : Float(119:6656, 13:512, 512:1) = aten::add(%1723, %1721, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1725 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13801.MobileBertOutput = prim::GetAttr[name="output"](%132)
  %1726 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13794.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%132)
  %1727 : __torch__.torch.nn.modules.container.___torch_mangle_13827.ModuleList = prim::GetAttr[name="ffn"](%132)
  %1728 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13826.FFNLayer = prim::GetAttr[name="2"](%1727)
  %1729 : __torch__.torch.nn.modules.container.___torch_mangle_13827.ModuleList = prim::GetAttr[name="ffn"](%132)
  %1730 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13820.FFNLayer = prim::GetAttr[name="1"](%1729)
  %1731 : __torch__.torch.nn.modules.container.___torch_mangle_13827.ModuleList = prim::GetAttr[name="ffn"](%132)
  %1732 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13814.FFNLayer = prim::GetAttr[name="0"](%1731)
  %1733 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13792.MobileBertAttention = prim::GetAttr[name="attention"](%132)
  %1734 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13808.Bottleneck = prim::GetAttr[name="bottleneck"](%132)
  %1735 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13807.BottleneckLayer = prim::GetAttr[name="attention"](%1734)
  %1736 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13804.BottleneckLayer = prim::GetAttr[name="input"](%1734)
  %1737 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13803.NoNorm = prim::GetAttr[name="LayerNorm"](%1736)
  %1738 : __torch__.torch.nn.modules.linear.___torch_mangle_13802.Linear = prim::GetAttr[name="dense"](%1736)
  %1739 : Tensor = prim::GetAttr[name="bias"](%1738)
  %1740 : Tensor = prim::GetAttr[name="weight"](%1738)
  %1741 : Float(512:1, 128:512) = aten::t(%1740), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.122 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.159, %1741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.66 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.122, %1739, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1744 : Tensor = prim::GetAttr[name="bias"](%1737)
  %1745 : Tensor = prim::GetAttr[name="weight"](%1737)
  %1746 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.66, %1745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.9 : Float(119:1664, 13:128, 128:1) = aten::add(%1746, %1744, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1748 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13806.NoNorm = prim::GetAttr[name="LayerNorm"](%1735)
  %1749 : __torch__.torch.nn.modules.linear.___torch_mangle_13805.Linear = prim::GetAttr[name="dense"](%1735)
  %1750 : Tensor = prim::GetAttr[name="bias"](%1749)
  %1751 : Tensor = prim::GetAttr[name="weight"](%1749)
  %1752 : Float(512:1, 128:512) = aten::t(%1751), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.123 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.159, %1752), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.67 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.123, %1750, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1755 : Tensor = prim::GetAttr[name="bias"](%1748)
  %1756 : Tensor = prim::GetAttr[name="weight"](%1748)
  %1757 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.67, %1756), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.160 : Float(119:1664, 13:128, 128:1) = aten::add(%1757, %1755, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1759 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.160, %residual_tensor.9)
  %1760 : Float(119:1664, 13:128, 128:1), %1761 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%1759)
  %1762 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13791.MobileBertSelfOutput = prim::GetAttr[name="output"](%1733)
  %1763 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13788.MobileBertSelfAttention = prim::GetAttr[name="self"](%1733)
  %1764 : __torch__.torch.nn.modules.linear.___torch_mangle_13786.Linear = prim::GetAttr[name="value"](%1763)
  %1765 : __torch__.torch.nn.modules.linear.___torch_mangle_13785.Linear = prim::GetAttr[name="key"](%1763)
  %1766 : __torch__.torch.nn.modules.linear.___torch_mangle_13784.Linear = prim::GetAttr[name="query"](%1763)
  %1767 : Tensor = prim::GetAttr[name="bias"](%1766)
  %1768 : Tensor = prim::GetAttr[name="weight"](%1766)
  %1769 : Float(128:1, 128:128) = aten::t(%1768), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %output.124 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1760, %1769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %x.49 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.124, %1767, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1678:0
  %1772 : Tensor = prim::GetAttr[name="bias"](%1765)
  %1773 : Tensor = prim::GetAttr[name="weight"](%1765)
  %1774 : Float(128:1, 128:128) = aten::t(%1773), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %output.125 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1760, %1774), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %x.51 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.125, %1772, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1678:0
  %1777 : Tensor = prim::GetAttr[name="bias"](%1764)
  %1778 : Tensor = prim::GetAttr[name="weight"](%1764)
  %1779 : Float(512:1, 128:512) = aten::t(%1778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %output.126 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.159, %1779), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %x.53 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.126, %1777, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1678:0
  %1782 : int = aten::size(%x.49, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1783 : int = aten::size(%x.49, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1784 : int[] = prim::ListConstruct(%1782, %1783, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.50 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.49, %1784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1786 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %query_layer.9 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.50, %1786), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1788 : int = aten::size(%x.51, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1789 : int = aten::size(%x.51, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1790 : int[] = prim::ListConstruct(%1788, %1789, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.52 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.51, %1790), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1792 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %key_layer.9 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.52, %1792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1794 : int = aten::size(%x.53, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1795 : int = aten::size(%x.53, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1796 : int[] = prim::ListConstruct(%1794, %1795, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.54 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.53, %1796), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1798 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %value_layer.9 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.54, %1798), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1800 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.9, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.17 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.9, %1800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.18 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.17, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.161 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.18, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.162 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.161, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.9 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.162, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.17 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.9, %value_layer.9), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:280:0
  %1807 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %1808 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.17, %1807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.18 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1808, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %1810 : int = aten::size(%context_layer.18, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1811 : int = aten::size(%context_layer.18, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1812 : int[] = prim::ListConstruct(%1810, %1811, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %input.163 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.18, %1812), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:283:0
  %1814 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13790.NoNorm = prim::GetAttr[name="LayerNorm"](%1762)
  %1815 : __torch__.torch.nn.modules.linear.___torch_mangle_13789.Linear = prim::GetAttr[name="dense"](%1762)
  %1816 : Tensor = prim::GetAttr[name="bias"](%1815)
  %1817 : Tensor = prim::GetAttr[name="weight"](%1815)
  %1818 : Float(128:1, 128:128) = aten::t(%1817), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %output.127 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.163, %1818), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.41 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.127, %1816, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.68 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.41, %1761, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output # transformers/modeling_mobilebert.py:301:0
  %1822 : Tensor = prim::GetAttr[name="bias"](%1814)
  %1823 : Tensor = prim::GetAttr[name="weight"](%1814)
  %1824 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.68, %1823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.164 : Float(119:1664, 13:128, 128:1) = aten::add(%1824, %1822, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1826 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13813.FFNOutput = prim::GetAttr[name="output"](%1732)
  %1827 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13810.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1732)
  %1828 : __torch__.torch.nn.modules.linear.___torch_mangle_13809.Linear = prim::GetAttr[name="dense"](%1827)
  %1829 : Tensor = prim::GetAttr[name="bias"](%1828)
  %1830 : Tensor = prim::GetAttr[name="weight"](%1828)
  %1831 : Float(128:1, 512:128) = aten::t(%1830), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.128 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.164, %1831), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.165 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.128, %1829, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.166 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1835 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13812.NoNorm = prim::GetAttr[name="LayerNorm"](%1826)
  %1836 : __torch__.torch.nn.modules.linear.___torch_mangle_13811.Linear = prim::GetAttr[name="dense"](%1826)
  %1837 : Tensor = prim::GetAttr[name="bias"](%1836)
  %1838 : Tensor = prim::GetAttr[name="weight"](%1836)
  %1839 : Float(512:1, 128:512) = aten::t(%1838), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.129 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.166, %1839), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.42 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.129, %1837, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.69 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.42, %input.164, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1843 : Tensor = prim::GetAttr[name="bias"](%1835)
  %1844 : Tensor = prim::GetAttr[name="weight"](%1835)
  %1845 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.69, %1844), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.167 : Float(119:1664, 13:128, 128:1) = aten::add(%1845, %1843, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1847 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13819.FFNOutput = prim::GetAttr[name="output"](%1730)
  %1848 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13816.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1730)
  %1849 : __torch__.torch.nn.modules.linear.___torch_mangle_13815.Linear = prim::GetAttr[name="dense"](%1848)
  %1850 : Tensor = prim::GetAttr[name="bias"](%1849)
  %1851 : Tensor = prim::GetAttr[name="weight"](%1849)
  %1852 : Float(128:1, 512:128) = aten::t(%1851), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.130 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.167, %1852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.168 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.130, %1850, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.169 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1856 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13818.NoNorm = prim::GetAttr[name="LayerNorm"](%1847)
  %1857 : __torch__.torch.nn.modules.linear.___torch_mangle_13817.Linear = prim::GetAttr[name="dense"](%1847)
  %1858 : Tensor = prim::GetAttr[name="bias"](%1857)
  %1859 : Tensor = prim::GetAttr[name="weight"](%1857)
  %1860 : Float(512:1, 128:512) = aten::t(%1859), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.131 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.169, %1860), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.43 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.131, %1858, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.70 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.43, %input.167, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1864 : Tensor = prim::GetAttr[name="bias"](%1856)
  %1865 : Tensor = prim::GetAttr[name="weight"](%1856)
  %1866 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.70, %1865), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.170 : Float(119:1664, 13:128, 128:1) = aten::add(%1866, %1864, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1868 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13825.FFNOutput = prim::GetAttr[name="output"](%1728)
  %1869 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13822.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1728)
  %1870 : __torch__.torch.nn.modules.linear.___torch_mangle_13821.Linear = prim::GetAttr[name="dense"](%1869)
  %1871 : Tensor = prim::GetAttr[name="bias"](%1870)
  %1872 : Tensor = prim::GetAttr[name="weight"](%1870)
  %1873 : Float(128:1, 512:128) = aten::t(%1872), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.132 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.170, %1873), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.171 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.132, %1871, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.172 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1877 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13824.NoNorm = prim::GetAttr[name="LayerNorm"](%1868)
  %1878 : __torch__.torch.nn.modules.linear.___torch_mangle_13823.Linear = prim::GetAttr[name="dense"](%1868)
  %1879 : Tensor = prim::GetAttr[name="bias"](%1878)
  %1880 : Tensor = prim::GetAttr[name="weight"](%1878)
  %1881 : Float(512:1, 128:512) = aten::t(%1880), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.133 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.172, %1881), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.44 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.133, %1879, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.71 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.44, %input.170, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1885 : Tensor = prim::GetAttr[name="bias"](%1877)
  %1886 : Tensor = prim::GetAttr[name="weight"](%1877)
  %1887 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.71, %1886), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.173 : Float(119:1664, 13:128, 128:1) = aten::add(%1887, %1885, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1889 : __torch__.torch.nn.modules.linear.___torch_mangle_13793.Linear = prim::GetAttr[name="dense"](%1726)
  %1890 : Tensor = prim::GetAttr[name="bias"](%1889)
  %1891 : Tensor = prim::GetAttr[name="weight"](%1889)
  %1892 : Float(128:1, 512:128) = aten::t(%1891), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %output.134 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.173, %1892), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %input.174 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.134, %1890, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1678:0
  %input.175 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate # torch/nn/functional.py:1119:0
  %1896 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13800.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1725)
  %1897 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13796.NoNorm = prim::GetAttr[name="LayerNorm"](%1725)
  %1898 : __torch__.torch.nn.modules.linear.___torch_mangle_13795.Linear = prim::GetAttr[name="dense"](%1725)
  %1899 : Tensor = prim::GetAttr[name="bias"](%1898)
  %1900 : Tensor = prim::GetAttr[name="weight"](%1898)
  %1901 : Float(512:1, 128:512) = aten::t(%1900), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %output.135 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.175, %1901), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %layer_output.9 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.135, %1899, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.72 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.9, %input.173, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output # transformers/modeling_mobilebert.py:405:0
  %1905 : Tensor = prim::GetAttr[name="bias"](%1897)
  %1906 : Tensor = prim::GetAttr[name="weight"](%1897)
  %1907 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.72, %1906), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.176 : Float(119:1664, 13:128, 128:1) = aten::add(%1907, %1905, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1909 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13798.NoNorm = prim::GetAttr[name="LayerNorm"](%1896)
  %1910 : __torch__.torch.nn.modules.linear.___torch_mangle_13797.Linear = prim::GetAttr[name="dense"](%1896)
  %1911 : Tensor = prim::GetAttr[name="bias"](%1910)
  %1912 : Tensor = prim::GetAttr[name="weight"](%1910)
  %1913 : Float(128:1, 512:128) = aten::t(%1912), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.136 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.176, %1913), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.177 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.136, %1911, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.45 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.177, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.73 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.45, %input.159, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1918 : Tensor = prim::GetAttr[name="bias"](%1909)
  %1919 : Tensor = prim::GetAttr[name="weight"](%1909)
  %1920 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.73, %1919), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.178 : Float(119:6656, 13:512, 512:1) = aten::add(%1920, %1918, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1922 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13846.MobileBertOutput = prim::GetAttr[name="output"](%130)
  %1923 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13839.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%130)
  %1924 : __torch__.torch.nn.modules.container.___torch_mangle_13872.ModuleList = prim::GetAttr[name="ffn"](%130)
  %1925 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13871.FFNLayer = prim::GetAttr[name="2"](%1924)
  %1926 : __torch__.torch.nn.modules.container.___torch_mangle_13872.ModuleList = prim::GetAttr[name="ffn"](%130)
  %1927 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13865.FFNLayer = prim::GetAttr[name="1"](%1926)
  %1928 : __torch__.torch.nn.modules.container.___torch_mangle_13872.ModuleList = prim::GetAttr[name="ffn"](%130)
  %1929 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13859.FFNLayer = prim::GetAttr[name="0"](%1928)
  %1930 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13837.MobileBertAttention = prim::GetAttr[name="attention"](%130)
  %1931 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13853.Bottleneck = prim::GetAttr[name="bottleneck"](%130)
  %1932 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13852.BottleneckLayer = prim::GetAttr[name="attention"](%1931)
  %1933 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13849.BottleneckLayer = prim::GetAttr[name="input"](%1931)
  %1934 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13848.NoNorm = prim::GetAttr[name="LayerNorm"](%1933)
  %1935 : __torch__.torch.nn.modules.linear.___torch_mangle_13847.Linear = prim::GetAttr[name="dense"](%1933)
  %1936 : Tensor = prim::GetAttr[name="bias"](%1935)
  %1937 : Tensor = prim::GetAttr[name="weight"](%1935)
  %1938 : Float(512:1, 128:512) = aten::t(%1937), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.137 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.178, %1938), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.74 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.137, %1936, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1941 : Tensor = prim::GetAttr[name="bias"](%1934)
  %1942 : Tensor = prim::GetAttr[name="weight"](%1934)
  %1943 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.74, %1942), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.10 : Float(119:1664, 13:128, 128:1) = aten::add(%1943, %1941, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1945 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13851.NoNorm = prim::GetAttr[name="LayerNorm"](%1932)
  %1946 : __torch__.torch.nn.modules.linear.___torch_mangle_13850.Linear = prim::GetAttr[name="dense"](%1932)
  %1947 : Tensor = prim::GetAttr[name="bias"](%1946)
  %1948 : Tensor = prim::GetAttr[name="weight"](%1946)
  %1949 : Float(512:1, 128:512) = aten::t(%1948), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.138 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.178, %1949), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.75 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.138, %1947, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1952 : Tensor = prim::GetAttr[name="bias"](%1945)
  %1953 : Tensor = prim::GetAttr[name="weight"](%1945)
  %1954 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.75, %1953), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.179 : Float(119:1664, 13:128, 128:1) = aten::add(%1954, %1952, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1956 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.179, %residual_tensor.10)
  %1957 : Float(119:1664, 13:128, 128:1), %1958 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%1956)
  %1959 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13836.MobileBertSelfOutput = prim::GetAttr[name="output"](%1930)
  %1960 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13833.MobileBertSelfAttention = prim::GetAttr[name="self"](%1930)
  %1961 : __torch__.torch.nn.modules.linear.___torch_mangle_13831.Linear = prim::GetAttr[name="value"](%1960)
  %1962 : __torch__.torch.nn.modules.linear.___torch_mangle_13830.Linear = prim::GetAttr[name="key"](%1960)
  %1963 : __torch__.torch.nn.modules.linear.___torch_mangle_13829.Linear = prim::GetAttr[name="query"](%1960)
  %1964 : Tensor = prim::GetAttr[name="bias"](%1963)
  %1965 : Tensor = prim::GetAttr[name="weight"](%1963)
  %1966 : Float(128:1, 128:128) = aten::t(%1965), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %output.139 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1957, %1966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %x.55 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.139, %1964, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1678:0
  %1969 : Tensor = prim::GetAttr[name="bias"](%1962)
  %1970 : Tensor = prim::GetAttr[name="weight"](%1962)
  %1971 : Float(128:1, 128:128) = aten::t(%1970), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %output.140 : Float(119:1664, 13:128, 128:1) = aten::matmul(%1957, %1971), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %x.57 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.140, %1969, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1678:0
  %1974 : Tensor = prim::GetAttr[name="bias"](%1961)
  %1975 : Tensor = prim::GetAttr[name="weight"](%1961)
  %1976 : Float(512:1, 128:512) = aten::t(%1975), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %output.141 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.178, %1976), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %x.59 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.141, %1974, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1678:0
  %1979 : int = aten::size(%x.55, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1980 : int = aten::size(%x.55, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1981 : int[] = prim::ListConstruct(%1979, %1980, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.56 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.55, %1981), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1983 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %query_layer.10 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.56, %1983), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1985 : int = aten::size(%x.57, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1986 : int = aten::size(%x.57, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1987 : int[] = prim::ListConstruct(%1985, %1986, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.58 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.57, %1987), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1989 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %key_layer.10 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.58, %1989), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1991 : int = aten::size(%x.59, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1992 : int = aten::size(%x.59, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1993 : int[] = prim::ListConstruct(%1991, %1992, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.60 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.59, %1993), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1995 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %value_layer.10 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.60, %1995), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1997 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.10, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.19 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.10, %1997), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.20 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.19, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.180 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.20, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.181 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.180, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.10 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.181, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.19 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.10, %value_layer.10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:280:0
  %2004 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %2005 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.19, %2004), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.20 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2005, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %2007 : int = aten::size(%context_layer.20, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %2008 : int = aten::size(%context_layer.20, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %2009 : int[] = prim::ListConstruct(%2007, %2008, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %input.182 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.20, %2009), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:283:0
  %2011 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13835.NoNorm = prim::GetAttr[name="LayerNorm"](%1959)
  %2012 : __torch__.torch.nn.modules.linear.___torch_mangle_13834.Linear = prim::GetAttr[name="dense"](%1959)
  %2013 : Tensor = prim::GetAttr[name="bias"](%2012)
  %2014 : Tensor = prim::GetAttr[name="weight"](%2012)
  %2015 : Float(128:1, 128:128) = aten::t(%2014), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %output.142 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.182, %2015), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.46 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.142, %2013, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.76 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.46, %1958, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output # transformers/modeling_mobilebert.py:301:0
  %2019 : Tensor = prim::GetAttr[name="bias"](%2011)
  %2020 : Tensor = prim::GetAttr[name="weight"](%2011)
  %2021 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.76, %2020), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.183 : Float(119:1664, 13:128, 128:1) = aten::add(%2021, %2019, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2023 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13858.FFNOutput = prim::GetAttr[name="output"](%1929)
  %2024 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13855.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1929)
  %2025 : __torch__.torch.nn.modules.linear.___torch_mangle_13854.Linear = prim::GetAttr[name="dense"](%2024)
  %2026 : Tensor = prim::GetAttr[name="bias"](%2025)
  %2027 : Tensor = prim::GetAttr[name="weight"](%2025)
  %2028 : Float(128:1, 512:128) = aten::t(%2027), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.143 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.183, %2028), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.184 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.143, %2026, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.185 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2032 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13857.NoNorm = prim::GetAttr[name="LayerNorm"](%2023)
  %2033 : __torch__.torch.nn.modules.linear.___torch_mangle_13856.Linear = prim::GetAttr[name="dense"](%2023)
  %2034 : Tensor = prim::GetAttr[name="bias"](%2033)
  %2035 : Tensor = prim::GetAttr[name="weight"](%2033)
  %2036 : Float(512:1, 128:512) = aten::t(%2035), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.144 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.185, %2036), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.47 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.144, %2034, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.77 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.47, %input.183, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2040 : Tensor = prim::GetAttr[name="bias"](%2032)
  %2041 : Tensor = prim::GetAttr[name="weight"](%2032)
  %2042 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.77, %2041), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.186 : Float(119:1664, 13:128, 128:1) = aten::add(%2042, %2040, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2044 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13864.FFNOutput = prim::GetAttr[name="output"](%1927)
  %2045 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13861.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1927)
  %2046 : __torch__.torch.nn.modules.linear.___torch_mangle_13860.Linear = prim::GetAttr[name="dense"](%2045)
  %2047 : Tensor = prim::GetAttr[name="bias"](%2046)
  %2048 : Tensor = prim::GetAttr[name="weight"](%2046)
  %2049 : Float(128:1, 512:128) = aten::t(%2048), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.145 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.186, %2049), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.187 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.145, %2047, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.188 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2053 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13863.NoNorm = prim::GetAttr[name="LayerNorm"](%2044)
  %2054 : __torch__.torch.nn.modules.linear.___torch_mangle_13862.Linear = prim::GetAttr[name="dense"](%2044)
  %2055 : Tensor = prim::GetAttr[name="bias"](%2054)
  %2056 : Tensor = prim::GetAttr[name="weight"](%2054)
  %2057 : Float(512:1, 128:512) = aten::t(%2056), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.146 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.188, %2057), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.48 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.146, %2055, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.78 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.48, %input.186, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2061 : Tensor = prim::GetAttr[name="bias"](%2053)
  %2062 : Tensor = prim::GetAttr[name="weight"](%2053)
  %2063 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.78, %2062), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.189 : Float(119:1664, 13:128, 128:1) = aten::add(%2063, %2061, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2065 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13870.FFNOutput = prim::GetAttr[name="output"](%1925)
  %2066 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13867.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1925)
  %2067 : __torch__.torch.nn.modules.linear.___torch_mangle_13866.Linear = prim::GetAttr[name="dense"](%2066)
  %2068 : Tensor = prim::GetAttr[name="bias"](%2067)
  %2069 : Tensor = prim::GetAttr[name="weight"](%2067)
  %2070 : Float(128:1, 512:128) = aten::t(%2069), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.147 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.189, %2070), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.190 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.147, %2068, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.191 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2074 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13869.NoNorm = prim::GetAttr[name="LayerNorm"](%2065)
  %2075 : __torch__.torch.nn.modules.linear.___torch_mangle_13868.Linear = prim::GetAttr[name="dense"](%2065)
  %2076 : Tensor = prim::GetAttr[name="bias"](%2075)
  %2077 : Tensor = prim::GetAttr[name="weight"](%2075)
  %2078 : Float(512:1, 128:512) = aten::t(%2077), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.148 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.191, %2078), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.49 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.148, %2076, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.79 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.49, %input.189, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2082 : Tensor = prim::GetAttr[name="bias"](%2074)
  %2083 : Tensor = prim::GetAttr[name="weight"](%2074)
  %2084 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.79, %2083), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.192 : Float(119:1664, 13:128, 128:1) = aten::add(%2084, %2082, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2086 : __torch__.torch.nn.modules.linear.___torch_mangle_13838.Linear = prim::GetAttr[name="dense"](%1923)
  %2087 : Tensor = prim::GetAttr[name="bias"](%2086)
  %2088 : Tensor = prim::GetAttr[name="weight"](%2086)
  %2089 : Float(128:1, 512:128) = aten::t(%2088), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %output.149 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.192, %2089), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %input.193 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.149, %2087, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1678:0
  %input.194 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate # torch/nn/functional.py:1119:0
  %2093 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13845.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1922)
  %2094 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13841.NoNorm = prim::GetAttr[name="LayerNorm"](%1922)
  %2095 : __torch__.torch.nn.modules.linear.___torch_mangle_13840.Linear = prim::GetAttr[name="dense"](%1922)
  %2096 : Tensor = prim::GetAttr[name="bias"](%2095)
  %2097 : Tensor = prim::GetAttr[name="weight"](%2095)
  %2098 : Float(512:1, 128:512) = aten::t(%2097), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %output.150 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.194, %2098), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %layer_output.10 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.150, %2096, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.80 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.10, %input.192, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output # transformers/modeling_mobilebert.py:405:0
  %2102 : Tensor = prim::GetAttr[name="bias"](%2094)
  %2103 : Tensor = prim::GetAttr[name="weight"](%2094)
  %2104 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.80, %2103), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.195 : Float(119:1664, 13:128, 128:1) = aten::add(%2104, %2102, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2106 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13843.NoNorm = prim::GetAttr[name="LayerNorm"](%2093)
  %2107 : __torch__.torch.nn.modules.linear.___torch_mangle_13842.Linear = prim::GetAttr[name="dense"](%2093)
  %2108 : Tensor = prim::GetAttr[name="bias"](%2107)
  %2109 : Tensor = prim::GetAttr[name="weight"](%2107)
  %2110 : Float(128:1, 512:128) = aten::t(%2109), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.151 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.195, %2110), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.196 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.151, %2108, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.50 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.196, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.81 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.50, %input.178, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2115 : Tensor = prim::GetAttr[name="bias"](%2106)
  %2116 : Tensor = prim::GetAttr[name="weight"](%2106)
  %2117 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.81, %2116), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.197 : Float(119:6656, 13:512, 512:1) = aten::add(%2117, %2115, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13891.MobileBertOutput = prim::GetAttr[name="output"](%128)
  %2120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13884.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%128)
  %2121 : __torch__.torch.nn.modules.container.___torch_mangle_13917.ModuleList = prim::GetAttr[name="ffn"](%128)
  %2122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13916.FFNLayer = prim::GetAttr[name="2"](%2121)
  %2123 : __torch__.torch.nn.modules.container.___torch_mangle_13917.ModuleList = prim::GetAttr[name="ffn"](%128)
  %2124 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13910.FFNLayer = prim::GetAttr[name="1"](%2123)
  %2125 : __torch__.torch.nn.modules.container.___torch_mangle_13917.ModuleList = prim::GetAttr[name="ffn"](%128)
  %2126 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13904.FFNLayer = prim::GetAttr[name="0"](%2125)
  %2127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13882.MobileBertAttention = prim::GetAttr[name="attention"](%128)
  %2128 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13898.Bottleneck = prim::GetAttr[name="bottleneck"](%128)
  %2129 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13897.BottleneckLayer = prim::GetAttr[name="attention"](%2128)
  %2130 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13894.BottleneckLayer = prim::GetAttr[name="input"](%2128)
  %2131 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13893.NoNorm = prim::GetAttr[name="LayerNorm"](%2130)
  %2132 : __torch__.torch.nn.modules.linear.___torch_mangle_13892.Linear = prim::GetAttr[name="dense"](%2130)
  %2133 : Tensor = prim::GetAttr[name="bias"](%2132)
  %2134 : Tensor = prim::GetAttr[name="weight"](%2132)
  %2135 : Float(512:1, 128:512) = aten::t(%2134), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.152 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.197, %2135), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.82 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.152, %2133, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2138 : Tensor = prim::GetAttr[name="bias"](%2131)
  %2139 : Tensor = prim::GetAttr[name="weight"](%2131)
  %2140 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.82, %2139), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.11 : Float(119:1664, 13:128, 128:1) = aten::add(%2140, %2138, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2142 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13896.NoNorm = prim::GetAttr[name="LayerNorm"](%2129)
  %2143 : __torch__.torch.nn.modules.linear.___torch_mangle_13895.Linear = prim::GetAttr[name="dense"](%2129)
  %2144 : Tensor = prim::GetAttr[name="bias"](%2143)
  %2145 : Tensor = prim::GetAttr[name="weight"](%2143)
  %2146 : Float(512:1, 128:512) = aten::t(%2145), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.153 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.197, %2146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.83 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.153, %2144, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2149 : Tensor = prim::GetAttr[name="bias"](%2142)
  %2150 : Tensor = prim::GetAttr[name="weight"](%2142)
  %2151 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.83, %2150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.198 : Float(119:1664, 13:128, 128:1) = aten::add(%2151, %2149, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2153 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.198, %residual_tensor.11)
  %2154 : Float(119:1664, 13:128, 128:1), %2155 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%2153)
  %2156 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13881.MobileBertSelfOutput = prim::GetAttr[name="output"](%2127)
  %2157 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13878.MobileBertSelfAttention = prim::GetAttr[name="self"](%2127)
  %2158 : __torch__.torch.nn.modules.linear.___torch_mangle_13876.Linear = prim::GetAttr[name="value"](%2157)
  %2159 : __torch__.torch.nn.modules.linear.___torch_mangle_13875.Linear = prim::GetAttr[name="key"](%2157)
  %2160 : __torch__.torch.nn.modules.linear.___torch_mangle_13874.Linear = prim::GetAttr[name="query"](%2157)
  %2161 : Tensor = prim::GetAttr[name="bias"](%2160)
  %2162 : Tensor = prim::GetAttr[name="weight"](%2160)
  %2163 : Float(128:1, 128:128) = aten::t(%2162), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %output.154 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2154, %2163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %x.61 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.154, %2161, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1678:0
  %2166 : Tensor = prim::GetAttr[name="bias"](%2159)
  %2167 : Tensor = prim::GetAttr[name="weight"](%2159)
  %2168 : Float(128:1, 128:128) = aten::t(%2167), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %output.155 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2154, %2168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %x.63 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.155, %2166, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1678:0
  %2171 : Tensor = prim::GetAttr[name="bias"](%2158)
  %2172 : Tensor = prim::GetAttr[name="weight"](%2158)
  %2173 : Float(512:1, 128:512) = aten::t(%2172), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %output.156 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.197, %2173), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %x.65 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.156, %2171, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1678:0
  %2176 : int = aten::size(%x.61, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2177 : int = aten::size(%x.61, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2178 : int[] = prim::ListConstruct(%2176, %2177, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.62 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.61, %2178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2180 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %query_layer.11 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.62, %2180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2182 : int = aten::size(%x.63, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2183 : int = aten::size(%x.63, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2184 : int[] = prim::ListConstruct(%2182, %2183, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.64 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.63, %2184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2186 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %key_layer.11 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.64, %2186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2188 : int = aten::size(%x.65, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2189 : int = aten::size(%x.65, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2190 : int[] = prim::ListConstruct(%2188, %2189, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.66 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.65, %2190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2192 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %value_layer.11 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.66, %2192), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2194 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.11, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.21 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.11, %2194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.22 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.21, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.199 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.22, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.200 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.199, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.11 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.200, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.21 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.11, %value_layer.11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:280:0
  %2201 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %2202 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.21, %2201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.22 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2202, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %2204 : int = aten::size(%context_layer.22, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2205 : int = aten::size(%context_layer.22, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2206 : int[] = prim::ListConstruct(%2204, %2205, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %input.201 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.22, %2206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:283:0
  %2208 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13880.NoNorm = prim::GetAttr[name="LayerNorm"](%2156)
  %2209 : __torch__.torch.nn.modules.linear.___torch_mangle_13879.Linear = prim::GetAttr[name="dense"](%2156)
  %2210 : Tensor = prim::GetAttr[name="bias"](%2209)
  %2211 : Tensor = prim::GetAttr[name="weight"](%2209)
  %2212 : Float(128:1, 128:128) = aten::t(%2211), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %output.157 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.201, %2212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.51 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.157, %2210, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.84 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.51, %2155, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output # transformers/modeling_mobilebert.py:301:0
  %2216 : Tensor = prim::GetAttr[name="bias"](%2208)
  %2217 : Tensor = prim::GetAttr[name="weight"](%2208)
  %2218 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.84, %2217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.202 : Float(119:1664, 13:128, 128:1) = aten::add(%2218, %2216, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2220 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13903.FFNOutput = prim::GetAttr[name="output"](%2126)
  %2221 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13900.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2126)
  %2222 : __torch__.torch.nn.modules.linear.___torch_mangle_13899.Linear = prim::GetAttr[name="dense"](%2221)
  %2223 : Tensor = prim::GetAttr[name="bias"](%2222)
  %2224 : Tensor = prim::GetAttr[name="weight"](%2222)
  %2225 : Float(128:1, 512:128) = aten::t(%2224), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.158 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.202, %2225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.203 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.158, %2223, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.204 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2229 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13902.NoNorm = prim::GetAttr[name="LayerNorm"](%2220)
  %2230 : __torch__.torch.nn.modules.linear.___torch_mangle_13901.Linear = prim::GetAttr[name="dense"](%2220)
  %2231 : Tensor = prim::GetAttr[name="bias"](%2230)
  %2232 : Tensor = prim::GetAttr[name="weight"](%2230)
  %2233 : Float(512:1, 128:512) = aten::t(%2232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.159 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.204, %2233), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.52 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.159, %2231, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.85 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.52, %input.202, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2237 : Tensor = prim::GetAttr[name="bias"](%2229)
  %2238 : Tensor = prim::GetAttr[name="weight"](%2229)
  %2239 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.85, %2238), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.205 : Float(119:1664, 13:128, 128:1) = aten::add(%2239, %2237, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2241 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13909.FFNOutput = prim::GetAttr[name="output"](%2124)
  %2242 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13906.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2124)
  %2243 : __torch__.torch.nn.modules.linear.___torch_mangle_13905.Linear = prim::GetAttr[name="dense"](%2242)
  %2244 : Tensor = prim::GetAttr[name="bias"](%2243)
  %2245 : Tensor = prim::GetAttr[name="weight"](%2243)
  %2246 : Float(128:1, 512:128) = aten::t(%2245), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.160 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.205, %2246), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.206 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.160, %2244, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.207 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2250 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13908.NoNorm = prim::GetAttr[name="LayerNorm"](%2241)
  %2251 : __torch__.torch.nn.modules.linear.___torch_mangle_13907.Linear = prim::GetAttr[name="dense"](%2241)
  %2252 : Tensor = prim::GetAttr[name="bias"](%2251)
  %2253 : Tensor = prim::GetAttr[name="weight"](%2251)
  %2254 : Float(512:1, 128:512) = aten::t(%2253), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.161 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.207, %2254), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.53 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.161, %2252, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.86 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.53, %input.205, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2258 : Tensor = prim::GetAttr[name="bias"](%2250)
  %2259 : Tensor = prim::GetAttr[name="weight"](%2250)
  %2260 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.86, %2259), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.208 : Float(119:1664, 13:128, 128:1) = aten::add(%2260, %2258, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2262 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13915.FFNOutput = prim::GetAttr[name="output"](%2122)
  %2263 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13912.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2122)
  %2264 : __torch__.torch.nn.modules.linear.___torch_mangle_13911.Linear = prim::GetAttr[name="dense"](%2263)
  %2265 : Tensor = prim::GetAttr[name="bias"](%2264)
  %2266 : Tensor = prim::GetAttr[name="weight"](%2264)
  %2267 : Float(128:1, 512:128) = aten::t(%2266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.162 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.208, %2267), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.209 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.162, %2265, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.210 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2271 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13914.NoNorm = prim::GetAttr[name="LayerNorm"](%2262)
  %2272 : __torch__.torch.nn.modules.linear.___torch_mangle_13913.Linear = prim::GetAttr[name="dense"](%2262)
  %2273 : Tensor = prim::GetAttr[name="bias"](%2272)
  %2274 : Tensor = prim::GetAttr[name="weight"](%2272)
  %2275 : Float(512:1, 128:512) = aten::t(%2274), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.163 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.210, %2275), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.54 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.163, %2273, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.87 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.54, %input.208, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2279 : Tensor = prim::GetAttr[name="bias"](%2271)
  %2280 : Tensor = prim::GetAttr[name="weight"](%2271)
  %2281 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.87, %2280), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.211 : Float(119:1664, 13:128, 128:1) = aten::add(%2281, %2279, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2283 : __torch__.torch.nn.modules.linear.___torch_mangle_13883.Linear = prim::GetAttr[name="dense"](%2120)
  %2284 : Tensor = prim::GetAttr[name="bias"](%2283)
  %2285 : Tensor = prim::GetAttr[name="weight"](%2283)
  %2286 : Float(128:1, 512:128) = aten::t(%2285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %output.164 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.211, %2286), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %input.212 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.164, %2284, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1678:0
  %input.213 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate # torch/nn/functional.py:1119:0
  %2290 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13890.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2119)
  %2291 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13886.NoNorm = prim::GetAttr[name="LayerNorm"](%2119)
  %2292 : __torch__.torch.nn.modules.linear.___torch_mangle_13885.Linear = prim::GetAttr[name="dense"](%2119)
  %2293 : Tensor = prim::GetAttr[name="bias"](%2292)
  %2294 : Tensor = prim::GetAttr[name="weight"](%2292)
  %2295 : Float(512:1, 128:512) = aten::t(%2294), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %output.165 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.213, %2295), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %layer_output.11 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.165, %2293, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.88 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.11, %input.211, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output # transformers/modeling_mobilebert.py:405:0
  %2299 : Tensor = prim::GetAttr[name="bias"](%2291)
  %2300 : Tensor = prim::GetAttr[name="weight"](%2291)
  %2301 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.88, %2300), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.214 : Float(119:1664, 13:128, 128:1) = aten::add(%2301, %2299, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2303 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13888.NoNorm = prim::GetAttr[name="LayerNorm"](%2290)
  %2304 : __torch__.torch.nn.modules.linear.___torch_mangle_13887.Linear = prim::GetAttr[name="dense"](%2290)
  %2305 : Tensor = prim::GetAttr[name="bias"](%2304)
  %2306 : Tensor = prim::GetAttr[name="weight"](%2304)
  %2307 : Float(128:1, 512:128) = aten::t(%2306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.166 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.214, %2307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.215 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.166, %2305, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.55 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.215, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.89 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.55, %input.197, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2312 : Tensor = prim::GetAttr[name="bias"](%2303)
  %2313 : Tensor = prim::GetAttr[name="weight"](%2303)
  %2314 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.89, %2313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.216 : Float(119:6656, 13:512, 512:1) = aten::add(%2314, %2312, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2316 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13936.MobileBertOutput = prim::GetAttr[name="output"](%126)
  %2317 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13929.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%126)
  %2318 : __torch__.torch.nn.modules.container.___torch_mangle_13962.ModuleList = prim::GetAttr[name="ffn"](%126)
  %2319 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13961.FFNLayer = prim::GetAttr[name="2"](%2318)
  %2320 : __torch__.torch.nn.modules.container.___torch_mangle_13962.ModuleList = prim::GetAttr[name="ffn"](%126)
  %2321 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13955.FFNLayer = prim::GetAttr[name="1"](%2320)
  %2322 : __torch__.torch.nn.modules.container.___torch_mangle_13962.ModuleList = prim::GetAttr[name="ffn"](%126)
  %2323 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13949.FFNLayer = prim::GetAttr[name="0"](%2322)
  %2324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13927.MobileBertAttention = prim::GetAttr[name="attention"](%126)
  %2325 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13943.Bottleneck = prim::GetAttr[name="bottleneck"](%126)
  %2326 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13942.BottleneckLayer = prim::GetAttr[name="attention"](%2325)
  %2327 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13939.BottleneckLayer = prim::GetAttr[name="input"](%2325)
  %2328 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13938.NoNorm = prim::GetAttr[name="LayerNorm"](%2327)
  %2329 : __torch__.torch.nn.modules.linear.___torch_mangle_13937.Linear = prim::GetAttr[name="dense"](%2327)
  %2330 : Tensor = prim::GetAttr[name="bias"](%2329)
  %2331 : Tensor = prim::GetAttr[name="weight"](%2329)
  %2332 : Float(512:1, 128:512) = aten::t(%2331), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.167 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.216, %2332), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.90 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.167, %2330, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2335 : Tensor = prim::GetAttr[name="bias"](%2328)
  %2336 : Tensor = prim::GetAttr[name="weight"](%2328)
  %2337 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.90, %2336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.12 : Float(119:1664, 13:128, 128:1) = aten::add(%2337, %2335, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2339 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13941.NoNorm = prim::GetAttr[name="LayerNorm"](%2326)
  %2340 : __torch__.torch.nn.modules.linear.___torch_mangle_13940.Linear = prim::GetAttr[name="dense"](%2326)
  %2341 : Tensor = prim::GetAttr[name="bias"](%2340)
  %2342 : Tensor = prim::GetAttr[name="weight"](%2340)
  %2343 : Float(512:1, 128:512) = aten::t(%2342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.168 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.216, %2343), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.91 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.168, %2341, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2346 : Tensor = prim::GetAttr[name="bias"](%2339)
  %2347 : Tensor = prim::GetAttr[name="weight"](%2339)
  %2348 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.91, %2347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.217 : Float(119:1664, 13:128, 128:1) = aten::add(%2348, %2346, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2350 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.217, %residual_tensor.12)
  %2351 : Float(119:1664, 13:128, 128:1), %2352 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%2350)
  %2353 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13926.MobileBertSelfOutput = prim::GetAttr[name="output"](%2324)
  %2354 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13923.MobileBertSelfAttention = prim::GetAttr[name="self"](%2324)
  %2355 : __torch__.torch.nn.modules.linear.___torch_mangle_13921.Linear = prim::GetAttr[name="value"](%2354)
  %2356 : __torch__.torch.nn.modules.linear.___torch_mangle_13920.Linear = prim::GetAttr[name="key"](%2354)
  %2357 : __torch__.torch.nn.modules.linear.___torch_mangle_13919.Linear = prim::GetAttr[name="query"](%2354)
  %2358 : Tensor = prim::GetAttr[name="bias"](%2357)
  %2359 : Tensor = prim::GetAttr[name="weight"](%2357)
  %2360 : Float(128:1, 128:128) = aten::t(%2359), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %output.169 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2351, %2360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %x.67 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.169, %2358, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1678:0
  %2363 : Tensor = prim::GetAttr[name="bias"](%2356)
  %2364 : Tensor = prim::GetAttr[name="weight"](%2356)
  %2365 : Float(128:1, 128:128) = aten::t(%2364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %output.170 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2351, %2365), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %x.69 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.170, %2363, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1678:0
  %2368 : Tensor = prim::GetAttr[name="bias"](%2355)
  %2369 : Tensor = prim::GetAttr[name="weight"](%2355)
  %2370 : Float(512:1, 128:512) = aten::t(%2369), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %output.171 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.216, %2370), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %x.71 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.171, %2368, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1678:0
  %2373 : int = aten::size(%x.67, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2374 : int = aten::size(%x.67, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2375 : int[] = prim::ListConstruct(%2373, %2374, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.68 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.67, %2375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2377 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %query_layer.12 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.68, %2377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2379 : int = aten::size(%x.69, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2380 : int = aten::size(%x.69, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2381 : int[] = prim::ListConstruct(%2379, %2380, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.70 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.69, %2381), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2383 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %key_layer.12 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.70, %2383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2385 : int = aten::size(%x.71, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2386 : int = aten::size(%x.71, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2387 : int[] = prim::ListConstruct(%2385, %2386, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.72 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.71, %2387), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2389 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %value_layer.12 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.72, %2389), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2391 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.12, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.23 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.12, %2391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.24 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.23, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.218 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.24, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.219 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.218, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.12 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.219, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.23 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.12, %value_layer.12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:280:0
  %2398 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %2399 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.23, %2398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.24 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2399, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %2401 : int = aten::size(%context_layer.24, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2402 : int = aten::size(%context_layer.24, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2403 : int[] = prim::ListConstruct(%2401, %2402, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %input.220 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.24, %2403), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:283:0
  %2405 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13925.NoNorm = prim::GetAttr[name="LayerNorm"](%2353)
  %2406 : __torch__.torch.nn.modules.linear.___torch_mangle_13924.Linear = prim::GetAttr[name="dense"](%2353)
  %2407 : Tensor = prim::GetAttr[name="bias"](%2406)
  %2408 : Tensor = prim::GetAttr[name="weight"](%2406)
  %2409 : Float(128:1, 128:128) = aten::t(%2408), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %output.172 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.220, %2409), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.56 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.172, %2407, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.92 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.56, %2352, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output # transformers/modeling_mobilebert.py:301:0
  %2413 : Tensor = prim::GetAttr[name="bias"](%2405)
  %2414 : Tensor = prim::GetAttr[name="weight"](%2405)
  %2415 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.92, %2414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.221 : Float(119:1664, 13:128, 128:1) = aten::add(%2415, %2413, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2417 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13948.FFNOutput = prim::GetAttr[name="output"](%2323)
  %2418 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13945.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2323)
  %2419 : __torch__.torch.nn.modules.linear.___torch_mangle_13944.Linear = prim::GetAttr[name="dense"](%2418)
  %2420 : Tensor = prim::GetAttr[name="bias"](%2419)
  %2421 : Tensor = prim::GetAttr[name="weight"](%2419)
  %2422 : Float(128:1, 512:128) = aten::t(%2421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.173 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.221, %2422), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.222 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.173, %2420, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.223 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2426 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13947.NoNorm = prim::GetAttr[name="LayerNorm"](%2417)
  %2427 : __torch__.torch.nn.modules.linear.___torch_mangle_13946.Linear = prim::GetAttr[name="dense"](%2417)
  %2428 : Tensor = prim::GetAttr[name="bias"](%2427)
  %2429 : Tensor = prim::GetAttr[name="weight"](%2427)
  %2430 : Float(512:1, 128:512) = aten::t(%2429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.174 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.223, %2430), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.57 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.174, %2428, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.93 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.57, %input.221, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2434 : Tensor = prim::GetAttr[name="bias"](%2426)
  %2435 : Tensor = prim::GetAttr[name="weight"](%2426)
  %2436 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.93, %2435), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.224 : Float(119:1664, 13:128, 128:1) = aten::add(%2436, %2434, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2438 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13954.FFNOutput = prim::GetAttr[name="output"](%2321)
  %2439 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13951.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2321)
  %2440 : __torch__.torch.nn.modules.linear.___torch_mangle_13950.Linear = prim::GetAttr[name="dense"](%2439)
  %2441 : Tensor = prim::GetAttr[name="bias"](%2440)
  %2442 : Tensor = prim::GetAttr[name="weight"](%2440)
  %2443 : Float(128:1, 512:128) = aten::t(%2442), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.175 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.224, %2443), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.225 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.175, %2441, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.226 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2447 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13953.NoNorm = prim::GetAttr[name="LayerNorm"](%2438)
  %2448 : __torch__.torch.nn.modules.linear.___torch_mangle_13952.Linear = prim::GetAttr[name="dense"](%2438)
  %2449 : Tensor = prim::GetAttr[name="bias"](%2448)
  %2450 : Tensor = prim::GetAttr[name="weight"](%2448)
  %2451 : Float(512:1, 128:512) = aten::t(%2450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.176 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.226, %2451), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.58 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.176, %2449, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.94 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.58, %input.224, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2455 : Tensor = prim::GetAttr[name="bias"](%2447)
  %2456 : Tensor = prim::GetAttr[name="weight"](%2447)
  %2457 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.94, %2456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.227 : Float(119:1664, 13:128, 128:1) = aten::add(%2457, %2455, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2459 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13960.FFNOutput = prim::GetAttr[name="output"](%2319)
  %2460 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13957.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2319)
  %2461 : __torch__.torch.nn.modules.linear.___torch_mangle_13956.Linear = prim::GetAttr[name="dense"](%2460)
  %2462 : Tensor = prim::GetAttr[name="bias"](%2461)
  %2463 : Tensor = prim::GetAttr[name="weight"](%2461)
  %2464 : Float(128:1, 512:128) = aten::t(%2463), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.177 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.227, %2464), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.228 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.177, %2462, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.229 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2468 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13959.NoNorm = prim::GetAttr[name="LayerNorm"](%2459)
  %2469 : __torch__.torch.nn.modules.linear.___torch_mangle_13958.Linear = prim::GetAttr[name="dense"](%2459)
  %2470 : Tensor = prim::GetAttr[name="bias"](%2469)
  %2471 : Tensor = prim::GetAttr[name="weight"](%2469)
  %2472 : Float(512:1, 128:512) = aten::t(%2471), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.178 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.229, %2472), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.59 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.178, %2470, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.95 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.59, %input.227, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2476 : Tensor = prim::GetAttr[name="bias"](%2468)
  %2477 : Tensor = prim::GetAttr[name="weight"](%2468)
  %2478 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.95, %2477), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.230 : Float(119:1664, 13:128, 128:1) = aten::add(%2478, %2476, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2480 : __torch__.torch.nn.modules.linear.___torch_mangle_13928.Linear = prim::GetAttr[name="dense"](%2317)
  %2481 : Tensor = prim::GetAttr[name="bias"](%2480)
  %2482 : Tensor = prim::GetAttr[name="weight"](%2480)
  %2483 : Float(128:1, 512:128) = aten::t(%2482), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %output.179 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.230, %2483), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %input.231 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.179, %2481, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1678:0
  %input.232 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate # torch/nn/functional.py:1119:0
  %2487 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13935.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2316)
  %2488 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13931.NoNorm = prim::GetAttr[name="LayerNorm"](%2316)
  %2489 : __torch__.torch.nn.modules.linear.___torch_mangle_13930.Linear = prim::GetAttr[name="dense"](%2316)
  %2490 : Tensor = prim::GetAttr[name="bias"](%2489)
  %2491 : Tensor = prim::GetAttr[name="weight"](%2489)
  %2492 : Float(512:1, 128:512) = aten::t(%2491), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %output.180 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.232, %2492), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %layer_output.12 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.180, %2490, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.96 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.12, %input.230, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output # transformers/modeling_mobilebert.py:405:0
  %2496 : Tensor = prim::GetAttr[name="bias"](%2488)
  %2497 : Tensor = prim::GetAttr[name="weight"](%2488)
  %2498 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.96, %2497), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.233 : Float(119:1664, 13:128, 128:1) = aten::add(%2498, %2496, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2500 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13933.NoNorm = prim::GetAttr[name="LayerNorm"](%2487)
  %2501 : __torch__.torch.nn.modules.linear.___torch_mangle_13932.Linear = prim::GetAttr[name="dense"](%2487)
  %2502 : Tensor = prim::GetAttr[name="bias"](%2501)
  %2503 : Tensor = prim::GetAttr[name="weight"](%2501)
  %2504 : Float(128:1, 512:128) = aten::t(%2503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.181 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.233, %2504), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.234 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.181, %2502, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.60 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.234, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.97 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.60, %input.216, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2509 : Tensor = prim::GetAttr[name="bias"](%2500)
  %2510 : Tensor = prim::GetAttr[name="weight"](%2500)
  %2511 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.97, %2510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.235 : Float(119:6656, 13:512, 512:1) = aten::add(%2511, %2509, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2513 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13981.MobileBertOutput = prim::GetAttr[name="output"](%124)
  %2514 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13974.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%124)
  %2515 : __torch__.torch.nn.modules.container.___torch_mangle_14007.ModuleList = prim::GetAttr[name="ffn"](%124)
  %2516 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14006.FFNLayer = prim::GetAttr[name="2"](%2515)
  %2517 : __torch__.torch.nn.modules.container.___torch_mangle_14007.ModuleList = prim::GetAttr[name="ffn"](%124)
  %2518 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14000.FFNLayer = prim::GetAttr[name="1"](%2517)
  %2519 : __torch__.torch.nn.modules.container.___torch_mangle_14007.ModuleList = prim::GetAttr[name="ffn"](%124)
  %2520 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13994.FFNLayer = prim::GetAttr[name="0"](%2519)
  %2521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13972.MobileBertAttention = prim::GetAttr[name="attention"](%124)
  %2522 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13988.Bottleneck = prim::GetAttr[name="bottleneck"](%124)
  %2523 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13987.BottleneckLayer = prim::GetAttr[name="attention"](%2522)
  %2524 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13984.BottleneckLayer = prim::GetAttr[name="input"](%2522)
  %2525 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13983.NoNorm = prim::GetAttr[name="LayerNorm"](%2524)
  %2526 : __torch__.torch.nn.modules.linear.___torch_mangle_13982.Linear = prim::GetAttr[name="dense"](%2524)
  %2527 : Tensor = prim::GetAttr[name="bias"](%2526)
  %2528 : Tensor = prim::GetAttr[name="weight"](%2526)
  %2529 : Float(512:1, 128:512) = aten::t(%2528), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.182 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.235, %2529), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.98 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.182, %2527, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2532 : Tensor = prim::GetAttr[name="bias"](%2525)
  %2533 : Tensor = prim::GetAttr[name="weight"](%2525)
  %2534 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.98, %2533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.13 : Float(119:1664, 13:128, 128:1) = aten::add(%2534, %2532, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2536 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13986.NoNorm = prim::GetAttr[name="LayerNorm"](%2523)
  %2537 : __torch__.torch.nn.modules.linear.___torch_mangle_13985.Linear = prim::GetAttr[name="dense"](%2523)
  %2538 : Tensor = prim::GetAttr[name="bias"](%2537)
  %2539 : Tensor = prim::GetAttr[name="weight"](%2537)
  %2540 : Float(512:1, 128:512) = aten::t(%2539), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.183 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.235, %2540), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.99 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.183, %2538, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2543 : Tensor = prim::GetAttr[name="bias"](%2536)
  %2544 : Tensor = prim::GetAttr[name="weight"](%2536)
  %2545 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.99, %2544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.236 : Float(119:1664, 13:128, 128:1) = aten::add(%2545, %2543, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2547 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.236, %residual_tensor.13)
  %2548 : Float(119:1664, 13:128, 128:1), %2549 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%2547)
  %2550 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13971.MobileBertSelfOutput = prim::GetAttr[name="output"](%2521)
  %2551 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13968.MobileBertSelfAttention = prim::GetAttr[name="self"](%2521)
  %2552 : __torch__.torch.nn.modules.linear.___torch_mangle_13966.Linear = prim::GetAttr[name="value"](%2551)
  %2553 : __torch__.torch.nn.modules.linear.___torch_mangle_13965.Linear = prim::GetAttr[name="key"](%2551)
  %2554 : __torch__.torch.nn.modules.linear.___torch_mangle_13964.Linear = prim::GetAttr[name="query"](%2551)
  %2555 : Tensor = prim::GetAttr[name="bias"](%2554)
  %2556 : Tensor = prim::GetAttr[name="weight"](%2554)
  %2557 : Float(128:1, 128:128) = aten::t(%2556), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %output.184 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2548, %2557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %x.73 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.184, %2555, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1678:0
  %2560 : Tensor = prim::GetAttr[name="bias"](%2553)
  %2561 : Tensor = prim::GetAttr[name="weight"](%2553)
  %2562 : Float(128:1, 128:128) = aten::t(%2561), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %output.185 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2548, %2562), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %x.75 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.185, %2560, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1678:0
  %2565 : Tensor = prim::GetAttr[name="bias"](%2552)
  %2566 : Tensor = prim::GetAttr[name="weight"](%2552)
  %2567 : Float(512:1, 128:512) = aten::t(%2566), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %output.186 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.235, %2567), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %x.77 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.186, %2565, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1678:0
  %2570 : int = aten::size(%x.73, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2571 : int = aten::size(%x.73, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2572 : int[] = prim::ListConstruct(%2570, %2571, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.74 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.73, %2572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2574 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %query_layer.13 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.74, %2574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2576 : int = aten::size(%x.75, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2577 : int = aten::size(%x.75, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2578 : int[] = prim::ListConstruct(%2576, %2577, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.76 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.75, %2578), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2580 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %key_layer.13 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.76, %2580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2582 : int = aten::size(%x.77, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2583 : int = aten::size(%x.77, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2584 : int[] = prim::ListConstruct(%2582, %2583, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.78 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.77, %2584), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2586 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %value_layer.13 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.78, %2586), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2588 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.13, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.25 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.13, %2588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.26 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.25, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.237 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.26, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.238 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.237, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.13 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.238, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.25 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.13, %value_layer.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:280:0
  %2595 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %2596 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.25, %2595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.26 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2596, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %2598 : int = aten::size(%context_layer.26, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2599 : int = aten::size(%context_layer.26, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2600 : int[] = prim::ListConstruct(%2598, %2599, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %input.239 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.26, %2600), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:283:0
  %2602 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13970.NoNorm = prim::GetAttr[name="LayerNorm"](%2550)
  %2603 : __torch__.torch.nn.modules.linear.___torch_mangle_13969.Linear = prim::GetAttr[name="dense"](%2550)
  %2604 : Tensor = prim::GetAttr[name="bias"](%2603)
  %2605 : Tensor = prim::GetAttr[name="weight"](%2603)
  %2606 : Float(128:1, 128:128) = aten::t(%2605), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %output.187 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.239, %2606), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.61 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.187, %2604, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.100 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.61, %2549, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output # transformers/modeling_mobilebert.py:301:0
  %2610 : Tensor = prim::GetAttr[name="bias"](%2602)
  %2611 : Tensor = prim::GetAttr[name="weight"](%2602)
  %2612 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.100, %2611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.240 : Float(119:1664, 13:128, 128:1) = aten::add(%2612, %2610, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2614 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13993.FFNOutput = prim::GetAttr[name="output"](%2520)
  %2615 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13990.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2520)
  %2616 : __torch__.torch.nn.modules.linear.___torch_mangle_13989.Linear = prim::GetAttr[name="dense"](%2615)
  %2617 : Tensor = prim::GetAttr[name="bias"](%2616)
  %2618 : Tensor = prim::GetAttr[name="weight"](%2616)
  %2619 : Float(128:1, 512:128) = aten::t(%2618), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.188 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.240, %2619), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.241 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.188, %2617, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.242 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2623 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13992.NoNorm = prim::GetAttr[name="LayerNorm"](%2614)
  %2624 : __torch__.torch.nn.modules.linear.___torch_mangle_13991.Linear = prim::GetAttr[name="dense"](%2614)
  %2625 : Tensor = prim::GetAttr[name="bias"](%2624)
  %2626 : Tensor = prim::GetAttr[name="weight"](%2624)
  %2627 : Float(512:1, 128:512) = aten::t(%2626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.189 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.242, %2627), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.62 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.189, %2625, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.101 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.62, %input.240, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2631 : Tensor = prim::GetAttr[name="bias"](%2623)
  %2632 : Tensor = prim::GetAttr[name="weight"](%2623)
  %2633 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.101, %2632), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.243 : Float(119:1664, 13:128, 128:1) = aten::add(%2633, %2631, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2635 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13999.FFNOutput = prim::GetAttr[name="output"](%2518)
  %2636 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13996.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2518)
  %2637 : __torch__.torch.nn.modules.linear.___torch_mangle_13995.Linear = prim::GetAttr[name="dense"](%2636)
  %2638 : Tensor = prim::GetAttr[name="bias"](%2637)
  %2639 : Tensor = prim::GetAttr[name="weight"](%2637)
  %2640 : Float(128:1, 512:128) = aten::t(%2639), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.190 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.243, %2640), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.244 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.190, %2638, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.245 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2644 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13998.NoNorm = prim::GetAttr[name="LayerNorm"](%2635)
  %2645 : __torch__.torch.nn.modules.linear.___torch_mangle_13997.Linear = prim::GetAttr[name="dense"](%2635)
  %2646 : Tensor = prim::GetAttr[name="bias"](%2645)
  %2647 : Tensor = prim::GetAttr[name="weight"](%2645)
  %2648 : Float(512:1, 128:512) = aten::t(%2647), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.191 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.245, %2648), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.63 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.191, %2646, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.102 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.63, %input.243, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2652 : Tensor = prim::GetAttr[name="bias"](%2644)
  %2653 : Tensor = prim::GetAttr[name="weight"](%2644)
  %2654 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.102, %2653), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.246 : Float(119:1664, 13:128, 128:1) = aten::add(%2654, %2652, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2656 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14005.FFNOutput = prim::GetAttr[name="output"](%2516)
  %2657 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14002.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2516)
  %2658 : __torch__.torch.nn.modules.linear.___torch_mangle_14001.Linear = prim::GetAttr[name="dense"](%2657)
  %2659 : Tensor = prim::GetAttr[name="bias"](%2658)
  %2660 : Tensor = prim::GetAttr[name="weight"](%2658)
  %2661 : Float(128:1, 512:128) = aten::t(%2660), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.192 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.246, %2661), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.247 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.192, %2659, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.248 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2665 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14004.NoNorm = prim::GetAttr[name="LayerNorm"](%2656)
  %2666 : __torch__.torch.nn.modules.linear.___torch_mangle_14003.Linear = prim::GetAttr[name="dense"](%2656)
  %2667 : Tensor = prim::GetAttr[name="bias"](%2666)
  %2668 : Tensor = prim::GetAttr[name="weight"](%2666)
  %2669 : Float(512:1, 128:512) = aten::t(%2668), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.193 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.248, %2669), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.64 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.193, %2667, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.103 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.64, %input.246, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2673 : Tensor = prim::GetAttr[name="bias"](%2665)
  %2674 : Tensor = prim::GetAttr[name="weight"](%2665)
  %2675 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.103, %2674), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.249 : Float(119:1664, 13:128, 128:1) = aten::add(%2675, %2673, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2677 : __torch__.torch.nn.modules.linear.___torch_mangle_13973.Linear = prim::GetAttr[name="dense"](%2514)
  %2678 : Tensor = prim::GetAttr[name="bias"](%2677)
  %2679 : Tensor = prim::GetAttr[name="weight"](%2677)
  %2680 : Float(128:1, 512:128) = aten::t(%2679), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %output.194 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.249, %2680), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %input.250 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.194, %2678, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1678:0
  %input.251 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate # torch/nn/functional.py:1119:0
  %2684 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13980.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2513)
  %2685 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13976.NoNorm = prim::GetAttr[name="LayerNorm"](%2513)
  %2686 : __torch__.torch.nn.modules.linear.___torch_mangle_13975.Linear = prim::GetAttr[name="dense"](%2513)
  %2687 : Tensor = prim::GetAttr[name="bias"](%2686)
  %2688 : Tensor = prim::GetAttr[name="weight"](%2686)
  %2689 : Float(512:1, 128:512) = aten::t(%2688), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %output.195 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.251, %2689), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %layer_output.13 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.195, %2687, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.104 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.13, %input.249, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output # transformers/modeling_mobilebert.py:405:0
  %2693 : Tensor = prim::GetAttr[name="bias"](%2685)
  %2694 : Tensor = prim::GetAttr[name="weight"](%2685)
  %2695 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.104, %2694), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.252 : Float(119:1664, 13:128, 128:1) = aten::add(%2695, %2693, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2697 : __torch__.transformers.modeling_mobilebert.___torch_mangle_13978.NoNorm = prim::GetAttr[name="LayerNorm"](%2684)
  %2698 : __torch__.torch.nn.modules.linear.___torch_mangle_13977.Linear = prim::GetAttr[name="dense"](%2684)
  %2699 : Tensor = prim::GetAttr[name="bias"](%2698)
  %2700 : Tensor = prim::GetAttr[name="weight"](%2698)
  %2701 : Float(128:1, 512:128) = aten::t(%2700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.196 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.252, %2701), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.253 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.196, %2699, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.65 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.253, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.105 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.65, %input.235, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2706 : Tensor = prim::GetAttr[name="bias"](%2697)
  %2707 : Tensor = prim::GetAttr[name="weight"](%2697)
  %2708 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.105, %2707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.254 : Float(119:6656, 13:512, 512:1) = aten::add(%2708, %2706, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2710 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14026.MobileBertOutput = prim::GetAttr[name="output"](%122)
  %2711 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14019.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%122)
  %2712 : __torch__.torch.nn.modules.container.___torch_mangle_14052.ModuleList = prim::GetAttr[name="ffn"](%122)
  %2713 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14051.FFNLayer = prim::GetAttr[name="2"](%2712)
  %2714 : __torch__.torch.nn.modules.container.___torch_mangle_14052.ModuleList = prim::GetAttr[name="ffn"](%122)
  %2715 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14045.FFNLayer = prim::GetAttr[name="1"](%2714)
  %2716 : __torch__.torch.nn.modules.container.___torch_mangle_14052.ModuleList = prim::GetAttr[name="ffn"](%122)
  %2717 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14039.FFNLayer = prim::GetAttr[name="0"](%2716)
  %2718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14017.MobileBertAttention = prim::GetAttr[name="attention"](%122)
  %2719 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14033.Bottleneck = prim::GetAttr[name="bottleneck"](%122)
  %2720 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14032.BottleneckLayer = prim::GetAttr[name="attention"](%2719)
  %2721 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14029.BottleneckLayer = prim::GetAttr[name="input"](%2719)
  %2722 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14028.NoNorm = prim::GetAttr[name="LayerNorm"](%2721)
  %2723 : __torch__.torch.nn.modules.linear.___torch_mangle_14027.Linear = prim::GetAttr[name="dense"](%2721)
  %2724 : Tensor = prim::GetAttr[name="bias"](%2723)
  %2725 : Tensor = prim::GetAttr[name="weight"](%2723)
  %2726 : Float(512:1, 128:512) = aten::t(%2725), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.197 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.254, %2726), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.106 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.197, %2724, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2729 : Tensor = prim::GetAttr[name="bias"](%2722)
  %2730 : Tensor = prim::GetAttr[name="weight"](%2722)
  %2731 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.106, %2730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.14 : Float(119:1664, 13:128, 128:1) = aten::add(%2731, %2729, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2733 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14031.NoNorm = prim::GetAttr[name="LayerNorm"](%2720)
  %2734 : __torch__.torch.nn.modules.linear.___torch_mangle_14030.Linear = prim::GetAttr[name="dense"](%2720)
  %2735 : Tensor = prim::GetAttr[name="bias"](%2734)
  %2736 : Tensor = prim::GetAttr[name="weight"](%2734)
  %2737 : Float(512:1, 128:512) = aten::t(%2736), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.198 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.254, %2737), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.107 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.198, %2735, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2740 : Tensor = prim::GetAttr[name="bias"](%2733)
  %2741 : Tensor = prim::GetAttr[name="weight"](%2733)
  %2742 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.107, %2741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.255 : Float(119:1664, 13:128, 128:1) = aten::add(%2742, %2740, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2744 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.255, %residual_tensor.14)
  %2745 : Float(119:1664, 13:128, 128:1), %2746 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%2744)
  %2747 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14016.MobileBertSelfOutput = prim::GetAttr[name="output"](%2718)
  %2748 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14013.MobileBertSelfAttention = prim::GetAttr[name="self"](%2718)
  %2749 : __torch__.torch.nn.modules.linear.___torch_mangle_14011.Linear = prim::GetAttr[name="value"](%2748)
  %2750 : __torch__.torch.nn.modules.linear.___torch_mangle_14010.Linear = prim::GetAttr[name="key"](%2748)
  %2751 : __torch__.torch.nn.modules.linear.___torch_mangle_14009.Linear = prim::GetAttr[name="query"](%2748)
  %2752 : Tensor = prim::GetAttr[name="bias"](%2751)
  %2753 : Tensor = prim::GetAttr[name="weight"](%2751)
  %2754 : Float(128:1, 128:128) = aten::t(%2753), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %output.199 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2745, %2754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %x.79 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.199, %2752, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1678:0
  %2757 : Tensor = prim::GetAttr[name="bias"](%2750)
  %2758 : Tensor = prim::GetAttr[name="weight"](%2750)
  %2759 : Float(128:1, 128:128) = aten::t(%2758), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %output.200 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2745, %2759), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %x.81 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.200, %2757, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1678:0
  %2762 : Tensor = prim::GetAttr[name="bias"](%2749)
  %2763 : Tensor = prim::GetAttr[name="weight"](%2749)
  %2764 : Float(512:1, 128:512) = aten::t(%2763), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %output.201 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.254, %2764), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %x.83 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.201, %2762, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1678:0
  %2767 : int = aten::size(%x.79, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2768 : int = aten::size(%x.79, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2769 : int[] = prim::ListConstruct(%2767, %2768, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.80 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.79, %2769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2771 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %query_layer.14 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.80, %2771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2773 : int = aten::size(%x.81, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2774 : int = aten::size(%x.81, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2775 : int[] = prim::ListConstruct(%2773, %2774, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.82 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.81, %2775), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2777 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %key_layer.14 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.82, %2777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2779 : int = aten::size(%x.83, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2780 : int = aten::size(%x.83, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2781 : int[] = prim::ListConstruct(%2779, %2780, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.84 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.83, %2781), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2783 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %value_layer.14 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.84, %2783), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2785 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.14, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.27 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.14, %2785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.28 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.27, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.256 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.28, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.257 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.256, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.14 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.257, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.27 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.14, %value_layer.14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:280:0
  %2792 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %2793 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.27, %2792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.28 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2793, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %2795 : int = aten::size(%context_layer.28, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2796 : int = aten::size(%context_layer.28, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2797 : int[] = prim::ListConstruct(%2795, %2796, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %input.258 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.28, %2797), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:283:0
  %2799 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14015.NoNorm = prim::GetAttr[name="LayerNorm"](%2747)
  %2800 : __torch__.torch.nn.modules.linear.___torch_mangle_14014.Linear = prim::GetAttr[name="dense"](%2747)
  %2801 : Tensor = prim::GetAttr[name="bias"](%2800)
  %2802 : Tensor = prim::GetAttr[name="weight"](%2800)
  %2803 : Float(128:1, 128:128) = aten::t(%2802), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %output.202 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.258, %2803), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.66 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.202, %2801, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.108 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.66, %2746, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output # transformers/modeling_mobilebert.py:301:0
  %2807 : Tensor = prim::GetAttr[name="bias"](%2799)
  %2808 : Tensor = prim::GetAttr[name="weight"](%2799)
  %2809 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.108, %2808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.259 : Float(119:1664, 13:128, 128:1) = aten::add(%2809, %2807, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2811 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14038.FFNOutput = prim::GetAttr[name="output"](%2717)
  %2812 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14035.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2717)
  %2813 : __torch__.torch.nn.modules.linear.___torch_mangle_14034.Linear = prim::GetAttr[name="dense"](%2812)
  %2814 : Tensor = prim::GetAttr[name="bias"](%2813)
  %2815 : Tensor = prim::GetAttr[name="weight"](%2813)
  %2816 : Float(128:1, 512:128) = aten::t(%2815), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.203 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.259, %2816), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.260 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.203, %2814, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.261 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2820 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14037.NoNorm = prim::GetAttr[name="LayerNorm"](%2811)
  %2821 : __torch__.torch.nn.modules.linear.___torch_mangle_14036.Linear = prim::GetAttr[name="dense"](%2811)
  %2822 : Tensor = prim::GetAttr[name="bias"](%2821)
  %2823 : Tensor = prim::GetAttr[name="weight"](%2821)
  %2824 : Float(512:1, 128:512) = aten::t(%2823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.204 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.261, %2824), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.67 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.204, %2822, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.109 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.67, %input.259, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2828 : Tensor = prim::GetAttr[name="bias"](%2820)
  %2829 : Tensor = prim::GetAttr[name="weight"](%2820)
  %2830 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.109, %2829), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.262 : Float(119:1664, 13:128, 128:1) = aten::add(%2830, %2828, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2832 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14044.FFNOutput = prim::GetAttr[name="output"](%2715)
  %2833 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14041.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2715)
  %2834 : __torch__.torch.nn.modules.linear.___torch_mangle_14040.Linear = prim::GetAttr[name="dense"](%2833)
  %2835 : Tensor = prim::GetAttr[name="bias"](%2834)
  %2836 : Tensor = prim::GetAttr[name="weight"](%2834)
  %2837 : Float(128:1, 512:128) = aten::t(%2836), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.205 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.262, %2837), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.263 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.205, %2835, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.264 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2841 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14043.NoNorm = prim::GetAttr[name="LayerNorm"](%2832)
  %2842 : __torch__.torch.nn.modules.linear.___torch_mangle_14042.Linear = prim::GetAttr[name="dense"](%2832)
  %2843 : Tensor = prim::GetAttr[name="bias"](%2842)
  %2844 : Tensor = prim::GetAttr[name="weight"](%2842)
  %2845 : Float(512:1, 128:512) = aten::t(%2844), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.206 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.264, %2845), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.68 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.206, %2843, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.110 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.68, %input.262, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2849 : Tensor = prim::GetAttr[name="bias"](%2841)
  %2850 : Tensor = prim::GetAttr[name="weight"](%2841)
  %2851 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.110, %2850), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.265 : Float(119:1664, 13:128, 128:1) = aten::add(%2851, %2849, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2853 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14050.FFNOutput = prim::GetAttr[name="output"](%2713)
  %2854 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14047.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2713)
  %2855 : __torch__.torch.nn.modules.linear.___torch_mangle_14046.Linear = prim::GetAttr[name="dense"](%2854)
  %2856 : Tensor = prim::GetAttr[name="bias"](%2855)
  %2857 : Tensor = prim::GetAttr[name="weight"](%2855)
  %2858 : Float(128:1, 512:128) = aten::t(%2857), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.207 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.265, %2858), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.266 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.207, %2856, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.267 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2862 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14049.NoNorm = prim::GetAttr[name="LayerNorm"](%2853)
  %2863 : __torch__.torch.nn.modules.linear.___torch_mangle_14048.Linear = prim::GetAttr[name="dense"](%2853)
  %2864 : Tensor = prim::GetAttr[name="bias"](%2863)
  %2865 : Tensor = prim::GetAttr[name="weight"](%2863)
  %2866 : Float(512:1, 128:512) = aten::t(%2865), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.208 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.267, %2866), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.69 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.208, %2864, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.111 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.69, %input.265, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2870 : Tensor = prim::GetAttr[name="bias"](%2862)
  %2871 : Tensor = prim::GetAttr[name="weight"](%2862)
  %2872 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.111, %2871), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.268 : Float(119:1664, 13:128, 128:1) = aten::add(%2872, %2870, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2874 : __torch__.torch.nn.modules.linear.___torch_mangle_14018.Linear = prim::GetAttr[name="dense"](%2711)
  %2875 : Tensor = prim::GetAttr[name="bias"](%2874)
  %2876 : Tensor = prim::GetAttr[name="weight"](%2874)
  %2877 : Float(128:1, 512:128) = aten::t(%2876), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %output.209 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.268, %2877), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %input.269 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.209, %2875, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1678:0
  %input.270 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate # torch/nn/functional.py:1119:0
  %2881 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14025.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2710)
  %2882 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14021.NoNorm = prim::GetAttr[name="LayerNorm"](%2710)
  %2883 : __torch__.torch.nn.modules.linear.___torch_mangle_14020.Linear = prim::GetAttr[name="dense"](%2710)
  %2884 : Tensor = prim::GetAttr[name="bias"](%2883)
  %2885 : Tensor = prim::GetAttr[name="weight"](%2883)
  %2886 : Float(512:1, 128:512) = aten::t(%2885), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %output.210 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.270, %2886), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %layer_output.14 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.210, %2884, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.112 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.14, %input.268, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output # transformers/modeling_mobilebert.py:405:0
  %2890 : Tensor = prim::GetAttr[name="bias"](%2882)
  %2891 : Tensor = prim::GetAttr[name="weight"](%2882)
  %2892 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.112, %2891), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.271 : Float(119:1664, 13:128, 128:1) = aten::add(%2892, %2890, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2894 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14023.NoNorm = prim::GetAttr[name="LayerNorm"](%2881)
  %2895 : __torch__.torch.nn.modules.linear.___torch_mangle_14022.Linear = prim::GetAttr[name="dense"](%2881)
  %2896 : Tensor = prim::GetAttr[name="bias"](%2895)
  %2897 : Tensor = prim::GetAttr[name="weight"](%2895)
  %2898 : Float(128:1, 512:128) = aten::t(%2897), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.211 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.271, %2898), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.272 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.211, %2896, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.70 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.272, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.113 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.70, %input.254, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2903 : Tensor = prim::GetAttr[name="bias"](%2894)
  %2904 : Tensor = prim::GetAttr[name="weight"](%2894)
  %2905 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.113, %2904), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.273 : Float(119:6656, 13:512, 512:1) = aten::add(%2905, %2903, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2907 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14071.MobileBertOutput = prim::GetAttr[name="output"](%120)
  %2908 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14064.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%120)
  %2909 : __torch__.torch.nn.modules.container.___torch_mangle_14097.ModuleList = prim::GetAttr[name="ffn"](%120)
  %2910 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14096.FFNLayer = prim::GetAttr[name="2"](%2909)
  %2911 : __torch__.torch.nn.modules.container.___torch_mangle_14097.ModuleList = prim::GetAttr[name="ffn"](%120)
  %2912 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14090.FFNLayer = prim::GetAttr[name="1"](%2911)
  %2913 : __torch__.torch.nn.modules.container.___torch_mangle_14097.ModuleList = prim::GetAttr[name="ffn"](%120)
  %2914 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14084.FFNLayer = prim::GetAttr[name="0"](%2913)
  %2915 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14062.MobileBertAttention = prim::GetAttr[name="attention"](%120)
  %2916 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14078.Bottleneck = prim::GetAttr[name="bottleneck"](%120)
  %2917 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14077.BottleneckLayer = prim::GetAttr[name="attention"](%2916)
  %2918 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14074.BottleneckLayer = prim::GetAttr[name="input"](%2916)
  %2919 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14073.NoNorm = prim::GetAttr[name="LayerNorm"](%2918)
  %2920 : __torch__.torch.nn.modules.linear.___torch_mangle_14072.Linear = prim::GetAttr[name="dense"](%2918)
  %2921 : Tensor = prim::GetAttr[name="bias"](%2920)
  %2922 : Tensor = prim::GetAttr[name="weight"](%2920)
  %2923 : Float(512:1, 128:512) = aten::t(%2922), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.212 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.273, %2923), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.114 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.212, %2921, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2926 : Tensor = prim::GetAttr[name="bias"](%2919)
  %2927 : Tensor = prim::GetAttr[name="weight"](%2919)
  %2928 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.114, %2927), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.15 : Float(119:1664, 13:128, 128:1) = aten::add(%2928, %2926, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2930 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14076.NoNorm = prim::GetAttr[name="LayerNorm"](%2917)
  %2931 : __torch__.torch.nn.modules.linear.___torch_mangle_14075.Linear = prim::GetAttr[name="dense"](%2917)
  %2932 : Tensor = prim::GetAttr[name="bias"](%2931)
  %2933 : Tensor = prim::GetAttr[name="weight"](%2931)
  %2934 : Float(512:1, 128:512) = aten::t(%2933), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.213 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.273, %2934), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.115 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.213, %2932, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2937 : Tensor = prim::GetAttr[name="bias"](%2930)
  %2938 : Tensor = prim::GetAttr[name="weight"](%2930)
  %2939 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.115, %2938), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.274 : Float(119:1664, 13:128, 128:1) = aten::add(%2939, %2937, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2941 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.274, %residual_tensor.15)
  %2942 : Float(119:1664, 13:128, 128:1), %2943 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%2941)
  %2944 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14061.MobileBertSelfOutput = prim::GetAttr[name="output"](%2915)
  %2945 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14058.MobileBertSelfAttention = prim::GetAttr[name="self"](%2915)
  %2946 : __torch__.torch.nn.modules.linear.___torch_mangle_14056.Linear = prim::GetAttr[name="value"](%2945)
  %2947 : __torch__.torch.nn.modules.linear.___torch_mangle_14055.Linear = prim::GetAttr[name="key"](%2945)
  %2948 : __torch__.torch.nn.modules.linear.___torch_mangle_14054.Linear = prim::GetAttr[name="query"](%2945)
  %2949 : Tensor = prim::GetAttr[name="bias"](%2948)
  %2950 : Tensor = prim::GetAttr[name="weight"](%2948)
  %2951 : Float(128:1, 128:128) = aten::t(%2950), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %output.214 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2942, %2951), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %x.85 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.214, %2949, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1678:0
  %2954 : Tensor = prim::GetAttr[name="bias"](%2947)
  %2955 : Tensor = prim::GetAttr[name="weight"](%2947)
  %2956 : Float(128:1, 128:128) = aten::t(%2955), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %output.215 : Float(119:1664, 13:128, 128:1) = aten::matmul(%2942, %2956), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %x.87 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.215, %2954, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1678:0
  %2959 : Tensor = prim::GetAttr[name="bias"](%2946)
  %2960 : Tensor = prim::GetAttr[name="weight"](%2946)
  %2961 : Float(512:1, 128:512) = aten::t(%2960), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %output.216 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.273, %2961), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %x.89 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.216, %2959, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1678:0
  %2964 : int = aten::size(%x.85, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2965 : int = aten::size(%x.85, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2966 : int[] = prim::ListConstruct(%2964, %2965, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.86 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.85, %2966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2968 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %query_layer.15 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.86, %2968), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2970 : int = aten::size(%x.87, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2971 : int = aten::size(%x.87, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2972 : int[] = prim::ListConstruct(%2970, %2971, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.88 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.87, %2972), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2974 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %key_layer.15 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.88, %2974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2976 : int = aten::size(%x.89, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2977 : int = aten::size(%x.89, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2978 : int[] = prim::ListConstruct(%2976, %2977, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.90 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.89, %2978), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2980 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %value_layer.15 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.90, %2980), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2982 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.15, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.29 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.15, %2982), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.30 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.29, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.275 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.30, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.276 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.275, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.15 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.276, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.29 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.15, %value_layer.15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:280:0
  %2989 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %2990 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.29, %2989), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.30 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2990, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %2992 : int = aten::size(%context_layer.30, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2993 : int = aten::size(%context_layer.30, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2994 : int[] = prim::ListConstruct(%2992, %2993, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %input.277 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.30, %2994), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:283:0
  %2996 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14060.NoNorm = prim::GetAttr[name="LayerNorm"](%2944)
  %2997 : __torch__.torch.nn.modules.linear.___torch_mangle_14059.Linear = prim::GetAttr[name="dense"](%2944)
  %2998 : Tensor = prim::GetAttr[name="bias"](%2997)
  %2999 : Tensor = prim::GetAttr[name="weight"](%2997)
  %3000 : Float(128:1, 128:128) = aten::t(%2999), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %output.217 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.277, %3000), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.71 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.217, %2998, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.116 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.71, %2943, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output # transformers/modeling_mobilebert.py:301:0
  %3004 : Tensor = prim::GetAttr[name="bias"](%2996)
  %3005 : Tensor = prim::GetAttr[name="weight"](%2996)
  %3006 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.116, %3005), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.278 : Float(119:1664, 13:128, 128:1) = aten::add(%3006, %3004, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3008 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14083.FFNOutput = prim::GetAttr[name="output"](%2914)
  %3009 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14080.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2914)
  %3010 : __torch__.torch.nn.modules.linear.___torch_mangle_14079.Linear = prim::GetAttr[name="dense"](%3009)
  %3011 : Tensor = prim::GetAttr[name="bias"](%3010)
  %3012 : Tensor = prim::GetAttr[name="weight"](%3010)
  %3013 : Float(128:1, 512:128) = aten::t(%3012), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.218 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.278, %3013), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.279 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.218, %3011, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.280 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3017 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14082.NoNorm = prim::GetAttr[name="LayerNorm"](%3008)
  %3018 : __torch__.torch.nn.modules.linear.___torch_mangle_14081.Linear = prim::GetAttr[name="dense"](%3008)
  %3019 : Tensor = prim::GetAttr[name="bias"](%3018)
  %3020 : Tensor = prim::GetAttr[name="weight"](%3018)
  %3021 : Float(512:1, 128:512) = aten::t(%3020), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.219 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.280, %3021), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.72 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.219, %3019, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.117 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.72, %input.278, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3025 : Tensor = prim::GetAttr[name="bias"](%3017)
  %3026 : Tensor = prim::GetAttr[name="weight"](%3017)
  %3027 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.117, %3026), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.281 : Float(119:1664, 13:128, 128:1) = aten::add(%3027, %3025, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3029 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14089.FFNOutput = prim::GetAttr[name="output"](%2912)
  %3030 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14086.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2912)
  %3031 : __torch__.torch.nn.modules.linear.___torch_mangle_14085.Linear = prim::GetAttr[name="dense"](%3030)
  %3032 : Tensor = prim::GetAttr[name="bias"](%3031)
  %3033 : Tensor = prim::GetAttr[name="weight"](%3031)
  %3034 : Float(128:1, 512:128) = aten::t(%3033), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.220 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.281, %3034), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.282 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.220, %3032, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.283 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3038 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14088.NoNorm = prim::GetAttr[name="LayerNorm"](%3029)
  %3039 : __torch__.torch.nn.modules.linear.___torch_mangle_14087.Linear = prim::GetAttr[name="dense"](%3029)
  %3040 : Tensor = prim::GetAttr[name="bias"](%3039)
  %3041 : Tensor = prim::GetAttr[name="weight"](%3039)
  %3042 : Float(512:1, 128:512) = aten::t(%3041), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.221 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.283, %3042), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.73 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.221, %3040, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.118 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.73, %input.281, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3046 : Tensor = prim::GetAttr[name="bias"](%3038)
  %3047 : Tensor = prim::GetAttr[name="weight"](%3038)
  %3048 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.118, %3047), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.284 : Float(119:1664, 13:128, 128:1) = aten::add(%3048, %3046, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3050 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14095.FFNOutput = prim::GetAttr[name="output"](%2910)
  %3051 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14092.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2910)
  %3052 : __torch__.torch.nn.modules.linear.___torch_mangle_14091.Linear = prim::GetAttr[name="dense"](%3051)
  %3053 : Tensor = prim::GetAttr[name="bias"](%3052)
  %3054 : Tensor = prim::GetAttr[name="weight"](%3052)
  %3055 : Float(128:1, 512:128) = aten::t(%3054), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.222 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.284, %3055), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.285 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.222, %3053, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.286 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3059 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14094.NoNorm = prim::GetAttr[name="LayerNorm"](%3050)
  %3060 : __torch__.torch.nn.modules.linear.___torch_mangle_14093.Linear = prim::GetAttr[name="dense"](%3050)
  %3061 : Tensor = prim::GetAttr[name="bias"](%3060)
  %3062 : Tensor = prim::GetAttr[name="weight"](%3060)
  %3063 : Float(512:1, 128:512) = aten::t(%3062), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.223 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.286, %3063), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.74 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.223, %3061, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.119 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.74, %input.284, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3067 : Tensor = prim::GetAttr[name="bias"](%3059)
  %3068 : Tensor = prim::GetAttr[name="weight"](%3059)
  %3069 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.119, %3068), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.287 : Float(119:1664, 13:128, 128:1) = aten::add(%3069, %3067, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3071 : __torch__.torch.nn.modules.linear.___torch_mangle_14063.Linear = prim::GetAttr[name="dense"](%2908)
  %3072 : Tensor = prim::GetAttr[name="bias"](%3071)
  %3073 : Tensor = prim::GetAttr[name="weight"](%3071)
  %3074 : Float(128:1, 512:128) = aten::t(%3073), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %output.224 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.287, %3074), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %input.288 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.224, %3072, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1678:0
  %input.289 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate # torch/nn/functional.py:1119:0
  %3078 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14070.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2907)
  %3079 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14066.NoNorm = prim::GetAttr[name="LayerNorm"](%2907)
  %3080 : __torch__.torch.nn.modules.linear.___torch_mangle_14065.Linear = prim::GetAttr[name="dense"](%2907)
  %3081 : Tensor = prim::GetAttr[name="bias"](%3080)
  %3082 : Tensor = prim::GetAttr[name="weight"](%3080)
  %3083 : Float(512:1, 128:512) = aten::t(%3082), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %output.225 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.289, %3083), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %layer_output.15 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.225, %3081, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.120 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.15, %input.287, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output # transformers/modeling_mobilebert.py:405:0
  %3087 : Tensor = prim::GetAttr[name="bias"](%3079)
  %3088 : Tensor = prim::GetAttr[name="weight"](%3079)
  %3089 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.120, %3088), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.290 : Float(119:1664, 13:128, 128:1) = aten::add(%3089, %3087, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3091 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14068.NoNorm = prim::GetAttr[name="LayerNorm"](%3078)
  %3092 : __torch__.torch.nn.modules.linear.___torch_mangle_14067.Linear = prim::GetAttr[name="dense"](%3078)
  %3093 : Tensor = prim::GetAttr[name="bias"](%3092)
  %3094 : Tensor = prim::GetAttr[name="weight"](%3092)
  %3095 : Float(128:1, 512:128) = aten::t(%3094), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.226 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.290, %3095), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.291 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.226, %3093, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.75 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.291, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.121 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.75, %input.273, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3100 : Tensor = prim::GetAttr[name="bias"](%3091)
  %3101 : Tensor = prim::GetAttr[name="weight"](%3091)
  %3102 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.121, %3101), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.292 : Float(119:6656, 13:512, 512:1) = aten::add(%3102, %3100, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14116.MobileBertOutput = prim::GetAttr[name="output"](%118)
  %3105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14109.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%118)
  %3106 : __torch__.torch.nn.modules.container.___torch_mangle_14142.ModuleList = prim::GetAttr[name="ffn"](%118)
  %3107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14141.FFNLayer = prim::GetAttr[name="2"](%3106)
  %3108 : __torch__.torch.nn.modules.container.___torch_mangle_14142.ModuleList = prim::GetAttr[name="ffn"](%118)
  %3109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14135.FFNLayer = prim::GetAttr[name="1"](%3108)
  %3110 : __torch__.torch.nn.modules.container.___torch_mangle_14142.ModuleList = prim::GetAttr[name="ffn"](%118)
  %3111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14129.FFNLayer = prim::GetAttr[name="0"](%3110)
  %3112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14107.MobileBertAttention = prim::GetAttr[name="attention"](%118)
  %3113 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14123.Bottleneck = prim::GetAttr[name="bottleneck"](%118)
  %3114 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14122.BottleneckLayer = prim::GetAttr[name="attention"](%3113)
  %3115 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14119.BottleneckLayer = prim::GetAttr[name="input"](%3113)
  %3116 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14118.NoNorm = prim::GetAttr[name="LayerNorm"](%3115)
  %3117 : __torch__.torch.nn.modules.linear.___torch_mangle_14117.Linear = prim::GetAttr[name="dense"](%3115)
  %3118 : Tensor = prim::GetAttr[name="bias"](%3117)
  %3119 : Tensor = prim::GetAttr[name="weight"](%3117)
  %3120 : Float(512:1, 128:512) = aten::t(%3119), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.227 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.292, %3120), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.122 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.227, %3118, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3123 : Tensor = prim::GetAttr[name="bias"](%3116)
  %3124 : Tensor = prim::GetAttr[name="weight"](%3116)
  %3125 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.122, %3124), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.16 : Float(119:1664, 13:128, 128:1) = aten::add(%3125, %3123, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14121.NoNorm = prim::GetAttr[name="LayerNorm"](%3114)
  %3128 : __torch__.torch.nn.modules.linear.___torch_mangle_14120.Linear = prim::GetAttr[name="dense"](%3114)
  %3129 : Tensor = prim::GetAttr[name="bias"](%3128)
  %3130 : Tensor = prim::GetAttr[name="weight"](%3128)
  %3131 : Float(512:1, 128:512) = aten::t(%3130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.228 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.292, %3131), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.123 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.228, %3129, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3134 : Tensor = prim::GetAttr[name="bias"](%3127)
  %3135 : Tensor = prim::GetAttr[name="weight"](%3127)
  %3136 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.123, %3135), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.293 : Float(119:1664, 13:128, 128:1) = aten::add(%3136, %3134, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3138 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.293, %residual_tensor.16)
  %3139 : Float(119:1664, 13:128, 128:1), %3140 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%3138)
  %3141 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14106.MobileBertSelfOutput = prim::GetAttr[name="output"](%3112)
  %3142 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14103.MobileBertSelfAttention = prim::GetAttr[name="self"](%3112)
  %3143 : __torch__.torch.nn.modules.linear.___torch_mangle_14101.Linear = prim::GetAttr[name="value"](%3142)
  %3144 : __torch__.torch.nn.modules.linear.___torch_mangle_14100.Linear = prim::GetAttr[name="key"](%3142)
  %3145 : __torch__.torch.nn.modules.linear.___torch_mangle_14099.Linear = prim::GetAttr[name="query"](%3142)
  %3146 : Tensor = prim::GetAttr[name="bias"](%3145)
  %3147 : Tensor = prim::GetAttr[name="weight"](%3145)
  %3148 : Float(128:1, 128:128) = aten::t(%3147), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %output.229 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3139, %3148), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %x.91 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.229, %3146, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1678:0
  %3151 : Tensor = prim::GetAttr[name="bias"](%3144)
  %3152 : Tensor = prim::GetAttr[name="weight"](%3144)
  %3153 : Float(128:1, 128:128) = aten::t(%3152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %output.230 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3139, %3153), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %x.93 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.230, %3151, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1678:0
  %3156 : Tensor = prim::GetAttr[name="bias"](%3143)
  %3157 : Tensor = prim::GetAttr[name="weight"](%3143)
  %3158 : Float(512:1, 128:512) = aten::t(%3157), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %output.231 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.292, %3158), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %x.95 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.231, %3156, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1678:0
  %3161 : int = aten::size(%x.91, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3162 : int = aten::size(%x.91, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3163 : int[] = prim::ListConstruct(%3161, %3162, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.92 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.91, %3163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3165 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %query_layer.16 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.92, %3165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3167 : int = aten::size(%x.93, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3168 : int = aten::size(%x.93, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3169 : int[] = prim::ListConstruct(%3167, %3168, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.94 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.93, %3169), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3171 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %key_layer.16 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.94, %3171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3173 : int = aten::size(%x.95, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3174 : int = aten::size(%x.95, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3175 : int[] = prim::ListConstruct(%3173, %3174, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.96 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.95, %3175), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3177 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %value_layer.16 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.96, %3177), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3179 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.16, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.31 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.16, %3179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.32 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.31, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.294 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.32, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.295 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.294, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.16 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.295, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.31 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.16, %value_layer.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:280:0
  %3186 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %3187 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.31, %3186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.32 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3187, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %3189 : int = aten::size(%context_layer.32, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3190 : int = aten::size(%context_layer.32, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3191 : int[] = prim::ListConstruct(%3189, %3190, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %input.296 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.32, %3191), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:283:0
  %3193 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14105.NoNorm = prim::GetAttr[name="LayerNorm"](%3141)
  %3194 : __torch__.torch.nn.modules.linear.___torch_mangle_14104.Linear = prim::GetAttr[name="dense"](%3141)
  %3195 : Tensor = prim::GetAttr[name="bias"](%3194)
  %3196 : Tensor = prim::GetAttr[name="weight"](%3194)
  %3197 : Float(128:1, 128:128) = aten::t(%3196), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %output.232 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.296, %3197), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.76 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.232, %3195, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.124 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.76, %3140, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output # transformers/modeling_mobilebert.py:301:0
  %3201 : Tensor = prim::GetAttr[name="bias"](%3193)
  %3202 : Tensor = prim::GetAttr[name="weight"](%3193)
  %3203 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.124, %3202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.297 : Float(119:1664, 13:128, 128:1) = aten::add(%3203, %3201, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3205 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14128.FFNOutput = prim::GetAttr[name="output"](%3111)
  %3206 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14125.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3111)
  %3207 : __torch__.torch.nn.modules.linear.___torch_mangle_14124.Linear = prim::GetAttr[name="dense"](%3206)
  %3208 : Tensor = prim::GetAttr[name="bias"](%3207)
  %3209 : Tensor = prim::GetAttr[name="weight"](%3207)
  %3210 : Float(128:1, 512:128) = aten::t(%3209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.233 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.297, %3210), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.298 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.233, %3208, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.299 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3214 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14127.NoNorm = prim::GetAttr[name="LayerNorm"](%3205)
  %3215 : __torch__.torch.nn.modules.linear.___torch_mangle_14126.Linear = prim::GetAttr[name="dense"](%3205)
  %3216 : Tensor = prim::GetAttr[name="bias"](%3215)
  %3217 : Tensor = prim::GetAttr[name="weight"](%3215)
  %3218 : Float(512:1, 128:512) = aten::t(%3217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.234 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.299, %3218), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.77 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.234, %3216, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.125 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.77, %input.297, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3222 : Tensor = prim::GetAttr[name="bias"](%3214)
  %3223 : Tensor = prim::GetAttr[name="weight"](%3214)
  %3224 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.125, %3223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.300 : Float(119:1664, 13:128, 128:1) = aten::add(%3224, %3222, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3226 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14134.FFNOutput = prim::GetAttr[name="output"](%3109)
  %3227 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14131.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3109)
  %3228 : __torch__.torch.nn.modules.linear.___torch_mangle_14130.Linear = prim::GetAttr[name="dense"](%3227)
  %3229 : Tensor = prim::GetAttr[name="bias"](%3228)
  %3230 : Tensor = prim::GetAttr[name="weight"](%3228)
  %3231 : Float(128:1, 512:128) = aten::t(%3230), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.235 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.300, %3231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.301 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.235, %3229, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.302 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3235 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14133.NoNorm = prim::GetAttr[name="LayerNorm"](%3226)
  %3236 : __torch__.torch.nn.modules.linear.___torch_mangle_14132.Linear = prim::GetAttr[name="dense"](%3226)
  %3237 : Tensor = prim::GetAttr[name="bias"](%3236)
  %3238 : Tensor = prim::GetAttr[name="weight"](%3236)
  %3239 : Float(512:1, 128:512) = aten::t(%3238), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.236 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.302, %3239), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.78 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.236, %3237, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.126 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.78, %input.300, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3243 : Tensor = prim::GetAttr[name="bias"](%3235)
  %3244 : Tensor = prim::GetAttr[name="weight"](%3235)
  %3245 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.126, %3244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.303 : Float(119:1664, 13:128, 128:1) = aten::add(%3245, %3243, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3247 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14140.FFNOutput = prim::GetAttr[name="output"](%3107)
  %3248 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14137.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3107)
  %3249 : __torch__.torch.nn.modules.linear.___torch_mangle_14136.Linear = prim::GetAttr[name="dense"](%3248)
  %3250 : Tensor = prim::GetAttr[name="bias"](%3249)
  %3251 : Tensor = prim::GetAttr[name="weight"](%3249)
  %3252 : Float(128:1, 512:128) = aten::t(%3251), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.237 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.303, %3252), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.304 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.237, %3250, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.305 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3256 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14139.NoNorm = prim::GetAttr[name="LayerNorm"](%3247)
  %3257 : __torch__.torch.nn.modules.linear.___torch_mangle_14138.Linear = prim::GetAttr[name="dense"](%3247)
  %3258 : Tensor = prim::GetAttr[name="bias"](%3257)
  %3259 : Tensor = prim::GetAttr[name="weight"](%3257)
  %3260 : Float(512:1, 128:512) = aten::t(%3259), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.238 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.305, %3260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.79 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.238, %3258, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.127 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.79, %input.303, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3264 : Tensor = prim::GetAttr[name="bias"](%3256)
  %3265 : Tensor = prim::GetAttr[name="weight"](%3256)
  %3266 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.127, %3265), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.306 : Float(119:1664, 13:128, 128:1) = aten::add(%3266, %3264, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3268 : __torch__.torch.nn.modules.linear.___torch_mangle_14108.Linear = prim::GetAttr[name="dense"](%3105)
  %3269 : Tensor = prim::GetAttr[name="bias"](%3268)
  %3270 : Tensor = prim::GetAttr[name="weight"](%3268)
  %3271 : Float(128:1, 512:128) = aten::t(%3270), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %output.239 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.306, %3271), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %input.307 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.239, %3269, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1678:0
  %input.308 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate # torch/nn/functional.py:1119:0
  %3275 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14115.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3104)
  %3276 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14111.NoNorm = prim::GetAttr[name="LayerNorm"](%3104)
  %3277 : __torch__.torch.nn.modules.linear.___torch_mangle_14110.Linear = prim::GetAttr[name="dense"](%3104)
  %3278 : Tensor = prim::GetAttr[name="bias"](%3277)
  %3279 : Tensor = prim::GetAttr[name="weight"](%3277)
  %3280 : Float(512:1, 128:512) = aten::t(%3279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %output.240 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.308, %3280), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %layer_output.16 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.240, %3278, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.128 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.16, %input.306, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output # transformers/modeling_mobilebert.py:405:0
  %3284 : Tensor = prim::GetAttr[name="bias"](%3276)
  %3285 : Tensor = prim::GetAttr[name="weight"](%3276)
  %3286 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.128, %3285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.309 : Float(119:1664, 13:128, 128:1) = aten::add(%3286, %3284, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3288 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14113.NoNorm = prim::GetAttr[name="LayerNorm"](%3275)
  %3289 : __torch__.torch.nn.modules.linear.___torch_mangle_14112.Linear = prim::GetAttr[name="dense"](%3275)
  %3290 : Tensor = prim::GetAttr[name="bias"](%3289)
  %3291 : Tensor = prim::GetAttr[name="weight"](%3289)
  %3292 : Float(128:1, 512:128) = aten::t(%3291), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.241 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.309, %3292), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.310 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.241, %3290, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.80 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.310, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.129 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.80, %input.292, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3297 : Tensor = prim::GetAttr[name="bias"](%3288)
  %3298 : Tensor = prim::GetAttr[name="weight"](%3288)
  %3299 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.129, %3298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.311 : Float(119:6656, 13:512, 512:1) = aten::add(%3299, %3297, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14161.MobileBertOutput = prim::GetAttr[name="output"](%116)
  %3302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14154.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%116)
  %3303 : __torch__.torch.nn.modules.container.___torch_mangle_14187.ModuleList = prim::GetAttr[name="ffn"](%116)
  %3304 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14186.FFNLayer = prim::GetAttr[name="2"](%3303)
  %3305 : __torch__.torch.nn.modules.container.___torch_mangle_14187.ModuleList = prim::GetAttr[name="ffn"](%116)
  %3306 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14180.FFNLayer = prim::GetAttr[name="1"](%3305)
  %3307 : __torch__.torch.nn.modules.container.___torch_mangle_14187.ModuleList = prim::GetAttr[name="ffn"](%116)
  %3308 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14174.FFNLayer = prim::GetAttr[name="0"](%3307)
  %3309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14152.MobileBertAttention = prim::GetAttr[name="attention"](%116)
  %3310 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14168.Bottleneck = prim::GetAttr[name="bottleneck"](%116)
  %3311 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14167.BottleneckLayer = prim::GetAttr[name="attention"](%3310)
  %3312 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14164.BottleneckLayer = prim::GetAttr[name="input"](%3310)
  %3313 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14163.NoNorm = prim::GetAttr[name="LayerNorm"](%3312)
  %3314 : __torch__.torch.nn.modules.linear.___torch_mangle_14162.Linear = prim::GetAttr[name="dense"](%3312)
  %3315 : Tensor = prim::GetAttr[name="bias"](%3314)
  %3316 : Tensor = prim::GetAttr[name="weight"](%3314)
  %3317 : Float(512:1, 128:512) = aten::t(%3316), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.242 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.311, %3317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.130 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.242, %3315, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3320 : Tensor = prim::GetAttr[name="bias"](%3313)
  %3321 : Tensor = prim::GetAttr[name="weight"](%3313)
  %3322 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.130, %3321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.17 : Float(119:1664, 13:128, 128:1) = aten::add(%3322, %3320, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14166.NoNorm = prim::GetAttr[name="LayerNorm"](%3311)
  %3325 : __torch__.torch.nn.modules.linear.___torch_mangle_14165.Linear = prim::GetAttr[name="dense"](%3311)
  %3326 : Tensor = prim::GetAttr[name="bias"](%3325)
  %3327 : Tensor = prim::GetAttr[name="weight"](%3325)
  %3328 : Float(512:1, 128:512) = aten::t(%3327), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.243 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.311, %3328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.131 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.243, %3326, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3331 : Tensor = prim::GetAttr[name="bias"](%3324)
  %3332 : Tensor = prim::GetAttr[name="weight"](%3324)
  %3333 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.131, %3332), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.312 : Float(119:1664, 13:128, 128:1) = aten::add(%3333, %3331, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3335 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.312, %residual_tensor.17)
  %3336 : Float(119:1664, 13:128, 128:1), %3337 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%3335)
  %3338 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14151.MobileBertSelfOutput = prim::GetAttr[name="output"](%3309)
  %3339 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14148.MobileBertSelfAttention = prim::GetAttr[name="self"](%3309)
  %3340 : __torch__.torch.nn.modules.linear.___torch_mangle_14146.Linear = prim::GetAttr[name="value"](%3339)
  %3341 : __torch__.torch.nn.modules.linear.___torch_mangle_14145.Linear = prim::GetAttr[name="key"](%3339)
  %3342 : __torch__.torch.nn.modules.linear.___torch_mangle_14144.Linear = prim::GetAttr[name="query"](%3339)
  %3343 : Tensor = prim::GetAttr[name="bias"](%3342)
  %3344 : Tensor = prim::GetAttr[name="weight"](%3342)
  %3345 : Float(128:1, 128:128) = aten::t(%3344), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %output.244 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3336, %3345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %x.97 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.244, %3343, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1678:0
  %3348 : Tensor = prim::GetAttr[name="bias"](%3341)
  %3349 : Tensor = prim::GetAttr[name="weight"](%3341)
  %3350 : Float(128:1, 128:128) = aten::t(%3349), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %output.245 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3336, %3350), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %x.99 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.245, %3348, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1678:0
  %3353 : Tensor = prim::GetAttr[name="bias"](%3340)
  %3354 : Tensor = prim::GetAttr[name="weight"](%3340)
  %3355 : Float(512:1, 128:512) = aten::t(%3354), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %output.246 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.311, %3355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %x.101 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.246, %3353, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1678:0
  %3358 : int = aten::size(%x.97, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3359 : int = aten::size(%x.97, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3360 : int[] = prim::ListConstruct(%3358, %3359, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.98 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.97, %3360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3362 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %query_layer.17 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.98, %3362), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3364 : int = aten::size(%x.99, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3365 : int = aten::size(%x.99, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3366 : int[] = prim::ListConstruct(%3364, %3365, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.100 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.99, %3366), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3368 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %key_layer.17 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.100, %3368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3370 : int = aten::size(%x.101, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3371 : int = aten::size(%x.101, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3372 : int[] = prim::ListConstruct(%3370, %3371, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.102 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.101, %3372), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3374 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %value_layer.17 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.102, %3374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3376 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.17, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.33 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.17, %3376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.34 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.33, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.313 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.34, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.314 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.313, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.17 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.314, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.33 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.17, %value_layer.17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:280:0
  %3383 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %3384 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.33, %3383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.34 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3384, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %3386 : int = aten::size(%context_layer.34, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3387 : int = aten::size(%context_layer.34, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3388 : int[] = prim::ListConstruct(%3386, %3387, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %input.315 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.34, %3388), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:283:0
  %3390 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14150.NoNorm = prim::GetAttr[name="LayerNorm"](%3338)
  %3391 : __torch__.torch.nn.modules.linear.___torch_mangle_14149.Linear = prim::GetAttr[name="dense"](%3338)
  %3392 : Tensor = prim::GetAttr[name="bias"](%3391)
  %3393 : Tensor = prim::GetAttr[name="weight"](%3391)
  %3394 : Float(128:1, 128:128) = aten::t(%3393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %output.247 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.315, %3394), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.81 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.247, %3392, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.132 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.81, %3337, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output # transformers/modeling_mobilebert.py:301:0
  %3398 : Tensor = prim::GetAttr[name="bias"](%3390)
  %3399 : Tensor = prim::GetAttr[name="weight"](%3390)
  %3400 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.132, %3399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.316 : Float(119:1664, 13:128, 128:1) = aten::add(%3400, %3398, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3402 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14173.FFNOutput = prim::GetAttr[name="output"](%3308)
  %3403 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14170.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3308)
  %3404 : __torch__.torch.nn.modules.linear.___torch_mangle_14169.Linear = prim::GetAttr[name="dense"](%3403)
  %3405 : Tensor = prim::GetAttr[name="bias"](%3404)
  %3406 : Tensor = prim::GetAttr[name="weight"](%3404)
  %3407 : Float(128:1, 512:128) = aten::t(%3406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.248 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.316, %3407), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.317 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.248, %3405, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.318 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3411 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14172.NoNorm = prim::GetAttr[name="LayerNorm"](%3402)
  %3412 : __torch__.torch.nn.modules.linear.___torch_mangle_14171.Linear = prim::GetAttr[name="dense"](%3402)
  %3413 : Tensor = prim::GetAttr[name="bias"](%3412)
  %3414 : Tensor = prim::GetAttr[name="weight"](%3412)
  %3415 : Float(512:1, 128:512) = aten::t(%3414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.249 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.318, %3415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.82 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.249, %3413, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.133 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.82, %input.316, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3419 : Tensor = prim::GetAttr[name="bias"](%3411)
  %3420 : Tensor = prim::GetAttr[name="weight"](%3411)
  %3421 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.133, %3420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.319 : Float(119:1664, 13:128, 128:1) = aten::add(%3421, %3419, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3423 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14179.FFNOutput = prim::GetAttr[name="output"](%3306)
  %3424 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14176.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3306)
  %3425 : __torch__.torch.nn.modules.linear.___torch_mangle_14175.Linear = prim::GetAttr[name="dense"](%3424)
  %3426 : Tensor = prim::GetAttr[name="bias"](%3425)
  %3427 : Tensor = prim::GetAttr[name="weight"](%3425)
  %3428 : Float(128:1, 512:128) = aten::t(%3427), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.250 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.319, %3428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.320 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.250, %3426, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.321 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3432 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14178.NoNorm = prim::GetAttr[name="LayerNorm"](%3423)
  %3433 : __torch__.torch.nn.modules.linear.___torch_mangle_14177.Linear = prim::GetAttr[name="dense"](%3423)
  %3434 : Tensor = prim::GetAttr[name="bias"](%3433)
  %3435 : Tensor = prim::GetAttr[name="weight"](%3433)
  %3436 : Float(512:1, 128:512) = aten::t(%3435), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.251 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.321, %3436), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.83 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.251, %3434, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.134 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.83, %input.319, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3440 : Tensor = prim::GetAttr[name="bias"](%3432)
  %3441 : Tensor = prim::GetAttr[name="weight"](%3432)
  %3442 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.134, %3441), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.322 : Float(119:1664, 13:128, 128:1) = aten::add(%3442, %3440, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3444 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14185.FFNOutput = prim::GetAttr[name="output"](%3304)
  %3445 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14182.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3304)
  %3446 : __torch__.torch.nn.modules.linear.___torch_mangle_14181.Linear = prim::GetAttr[name="dense"](%3445)
  %3447 : Tensor = prim::GetAttr[name="bias"](%3446)
  %3448 : Tensor = prim::GetAttr[name="weight"](%3446)
  %3449 : Float(128:1, 512:128) = aten::t(%3448), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.252 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.322, %3449), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.323 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.252, %3447, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.324 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3453 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14184.NoNorm = prim::GetAttr[name="LayerNorm"](%3444)
  %3454 : __torch__.torch.nn.modules.linear.___torch_mangle_14183.Linear = prim::GetAttr[name="dense"](%3444)
  %3455 : Tensor = prim::GetAttr[name="bias"](%3454)
  %3456 : Tensor = prim::GetAttr[name="weight"](%3454)
  %3457 : Float(512:1, 128:512) = aten::t(%3456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.253 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.324, %3457), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.84 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.253, %3455, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.135 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.84, %input.322, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3461 : Tensor = prim::GetAttr[name="bias"](%3453)
  %3462 : Tensor = prim::GetAttr[name="weight"](%3453)
  %3463 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.135, %3462), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.325 : Float(119:1664, 13:128, 128:1) = aten::add(%3463, %3461, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3465 : __torch__.torch.nn.modules.linear.___torch_mangle_14153.Linear = prim::GetAttr[name="dense"](%3302)
  %3466 : Tensor = prim::GetAttr[name="bias"](%3465)
  %3467 : Tensor = prim::GetAttr[name="weight"](%3465)
  %3468 : Float(128:1, 512:128) = aten::t(%3467), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %output.254 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.325, %3468), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %input.326 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.254, %3466, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1678:0
  %input.327 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate # torch/nn/functional.py:1119:0
  %3472 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14160.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3301)
  %3473 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14156.NoNorm = prim::GetAttr[name="LayerNorm"](%3301)
  %3474 : __torch__.torch.nn.modules.linear.___torch_mangle_14155.Linear = prim::GetAttr[name="dense"](%3301)
  %3475 : Tensor = prim::GetAttr[name="bias"](%3474)
  %3476 : Tensor = prim::GetAttr[name="weight"](%3474)
  %3477 : Float(512:1, 128:512) = aten::t(%3476), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %output.255 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.327, %3477), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %layer_output.17 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.255, %3475, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.136 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.17, %input.325, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output # transformers/modeling_mobilebert.py:405:0
  %3481 : Tensor = prim::GetAttr[name="bias"](%3473)
  %3482 : Tensor = prim::GetAttr[name="weight"](%3473)
  %3483 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.136, %3482), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.328 : Float(119:1664, 13:128, 128:1) = aten::add(%3483, %3481, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3485 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14158.NoNorm = prim::GetAttr[name="LayerNorm"](%3472)
  %3486 : __torch__.torch.nn.modules.linear.___torch_mangle_14157.Linear = prim::GetAttr[name="dense"](%3472)
  %3487 : Tensor = prim::GetAttr[name="bias"](%3486)
  %3488 : Tensor = prim::GetAttr[name="weight"](%3486)
  %3489 : Float(128:1, 512:128) = aten::t(%3488), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.256 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.328, %3489), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.329 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.256, %3487, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.85 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.329, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.137 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.85, %input.311, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3494 : Tensor = prim::GetAttr[name="bias"](%3485)
  %3495 : Tensor = prim::GetAttr[name="weight"](%3485)
  %3496 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.137, %3495), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.330 : Float(119:6656, 13:512, 512:1) = aten::add(%3496, %3494, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14206.MobileBertOutput = prim::GetAttr[name="output"](%114)
  %3499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14199.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%114)
  %3500 : __torch__.torch.nn.modules.container.___torch_mangle_14232.ModuleList = prim::GetAttr[name="ffn"](%114)
  %3501 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14231.FFNLayer = prim::GetAttr[name="2"](%3500)
  %3502 : __torch__.torch.nn.modules.container.___torch_mangle_14232.ModuleList = prim::GetAttr[name="ffn"](%114)
  %3503 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14225.FFNLayer = prim::GetAttr[name="1"](%3502)
  %3504 : __torch__.torch.nn.modules.container.___torch_mangle_14232.ModuleList = prim::GetAttr[name="ffn"](%114)
  %3505 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14219.FFNLayer = prim::GetAttr[name="0"](%3504)
  %3506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14197.MobileBertAttention = prim::GetAttr[name="attention"](%114)
  %3507 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14213.Bottleneck = prim::GetAttr[name="bottleneck"](%114)
  %3508 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14212.BottleneckLayer = prim::GetAttr[name="attention"](%3507)
  %3509 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14209.BottleneckLayer = prim::GetAttr[name="input"](%3507)
  %3510 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14208.NoNorm = prim::GetAttr[name="LayerNorm"](%3509)
  %3511 : __torch__.torch.nn.modules.linear.___torch_mangle_14207.Linear = prim::GetAttr[name="dense"](%3509)
  %3512 : Tensor = prim::GetAttr[name="bias"](%3511)
  %3513 : Tensor = prim::GetAttr[name="weight"](%3511)
  %3514 : Float(512:1, 128:512) = aten::t(%3513), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.257 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.330, %3514), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.138 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.257, %3512, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3517 : Tensor = prim::GetAttr[name="bias"](%3510)
  %3518 : Tensor = prim::GetAttr[name="weight"](%3510)
  %3519 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.138, %3518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.18 : Float(119:1664, 13:128, 128:1) = aten::add(%3519, %3517, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14211.NoNorm = prim::GetAttr[name="LayerNorm"](%3508)
  %3522 : __torch__.torch.nn.modules.linear.___torch_mangle_14210.Linear = prim::GetAttr[name="dense"](%3508)
  %3523 : Tensor = prim::GetAttr[name="bias"](%3522)
  %3524 : Tensor = prim::GetAttr[name="weight"](%3522)
  %3525 : Float(512:1, 128:512) = aten::t(%3524), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.258 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.330, %3525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.139 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.258, %3523, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3528 : Tensor = prim::GetAttr[name="bias"](%3521)
  %3529 : Tensor = prim::GetAttr[name="weight"](%3521)
  %3530 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.139, %3529), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.331 : Float(119:1664, 13:128, 128:1) = aten::add(%3530, %3528, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3532 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.331, %residual_tensor.18)
  %3533 : Float(119:1664, 13:128, 128:1), %3534 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%3532)
  %3535 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14196.MobileBertSelfOutput = prim::GetAttr[name="output"](%3506)
  %3536 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14193.MobileBertSelfAttention = prim::GetAttr[name="self"](%3506)
  %3537 : __torch__.torch.nn.modules.linear.___torch_mangle_14191.Linear = prim::GetAttr[name="value"](%3536)
  %3538 : __torch__.torch.nn.modules.linear.___torch_mangle_14190.Linear = prim::GetAttr[name="key"](%3536)
  %3539 : __torch__.torch.nn.modules.linear.___torch_mangle_14189.Linear = prim::GetAttr[name="query"](%3536)
  %3540 : Tensor = prim::GetAttr[name="bias"](%3539)
  %3541 : Tensor = prim::GetAttr[name="weight"](%3539)
  %3542 : Float(128:1, 128:128) = aten::t(%3541), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %output.259 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3533, %3542), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %x.103 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.259, %3540, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1678:0
  %3545 : Tensor = prim::GetAttr[name="bias"](%3538)
  %3546 : Tensor = prim::GetAttr[name="weight"](%3538)
  %3547 : Float(128:1, 128:128) = aten::t(%3546), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %output.260 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3533, %3547), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %x.105 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.260, %3545, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1678:0
  %3550 : Tensor = prim::GetAttr[name="bias"](%3537)
  %3551 : Tensor = prim::GetAttr[name="weight"](%3537)
  %3552 : Float(512:1, 128:512) = aten::t(%3551), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %output.261 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.330, %3552), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %x.107 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.261, %3550, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1678:0
  %3555 : int = aten::size(%x.103, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3556 : int = aten::size(%x.103, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3557 : int[] = prim::ListConstruct(%3555, %3556, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.104 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.103, %3557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3559 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %query_layer.18 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.104, %3559), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3561 : int = aten::size(%x.105, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3562 : int = aten::size(%x.105, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3563 : int[] = prim::ListConstruct(%3561, %3562, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.106 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.105, %3563), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3565 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %key_layer.18 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.106, %3565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3567 : int = aten::size(%x.107, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3568 : int = aten::size(%x.107, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3569 : int[] = prim::ListConstruct(%3567, %3568, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.108 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.107, %3569), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3571 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %value_layer.18 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.108, %3571), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3573 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.18, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.35 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.18, %3573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.36 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.35, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.332 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.36, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.333 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.332, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.18 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.333, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.35 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.18, %value_layer.18), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:280:0
  %3580 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %3581 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.35, %3580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.36 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3581, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %3583 : int = aten::size(%context_layer.36, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3584 : int = aten::size(%context_layer.36, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3585 : int[] = prim::ListConstruct(%3583, %3584, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %input.334 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.36, %3585), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:283:0
  %3587 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14195.NoNorm = prim::GetAttr[name="LayerNorm"](%3535)
  %3588 : __torch__.torch.nn.modules.linear.___torch_mangle_14194.Linear = prim::GetAttr[name="dense"](%3535)
  %3589 : Tensor = prim::GetAttr[name="bias"](%3588)
  %3590 : Tensor = prim::GetAttr[name="weight"](%3588)
  %3591 : Float(128:1, 128:128) = aten::t(%3590), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %output.262 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.334, %3591), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.86 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.262, %3589, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.140 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.86, %3534, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output # transformers/modeling_mobilebert.py:301:0
  %3595 : Tensor = prim::GetAttr[name="bias"](%3587)
  %3596 : Tensor = prim::GetAttr[name="weight"](%3587)
  %3597 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.140, %3596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.335 : Float(119:1664, 13:128, 128:1) = aten::add(%3597, %3595, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3599 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14218.FFNOutput = prim::GetAttr[name="output"](%3505)
  %3600 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14215.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3505)
  %3601 : __torch__.torch.nn.modules.linear.___torch_mangle_14214.Linear = prim::GetAttr[name="dense"](%3600)
  %3602 : Tensor = prim::GetAttr[name="bias"](%3601)
  %3603 : Tensor = prim::GetAttr[name="weight"](%3601)
  %3604 : Float(128:1, 512:128) = aten::t(%3603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.263 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.335, %3604), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.336 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.263, %3602, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.337 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3608 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14217.NoNorm = prim::GetAttr[name="LayerNorm"](%3599)
  %3609 : __torch__.torch.nn.modules.linear.___torch_mangle_14216.Linear = prim::GetAttr[name="dense"](%3599)
  %3610 : Tensor = prim::GetAttr[name="bias"](%3609)
  %3611 : Tensor = prim::GetAttr[name="weight"](%3609)
  %3612 : Float(512:1, 128:512) = aten::t(%3611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.264 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.337, %3612), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.87 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.264, %3610, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.141 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.87, %input.335, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3616 : Tensor = prim::GetAttr[name="bias"](%3608)
  %3617 : Tensor = prim::GetAttr[name="weight"](%3608)
  %3618 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.141, %3617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.338 : Float(119:1664, 13:128, 128:1) = aten::add(%3618, %3616, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3620 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14224.FFNOutput = prim::GetAttr[name="output"](%3503)
  %3621 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14221.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3503)
  %3622 : __torch__.torch.nn.modules.linear.___torch_mangle_14220.Linear = prim::GetAttr[name="dense"](%3621)
  %3623 : Tensor = prim::GetAttr[name="bias"](%3622)
  %3624 : Tensor = prim::GetAttr[name="weight"](%3622)
  %3625 : Float(128:1, 512:128) = aten::t(%3624), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.265 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.338, %3625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.339 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.265, %3623, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.340 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3629 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14223.NoNorm = prim::GetAttr[name="LayerNorm"](%3620)
  %3630 : __torch__.torch.nn.modules.linear.___torch_mangle_14222.Linear = prim::GetAttr[name="dense"](%3620)
  %3631 : Tensor = prim::GetAttr[name="bias"](%3630)
  %3632 : Tensor = prim::GetAttr[name="weight"](%3630)
  %3633 : Float(512:1, 128:512) = aten::t(%3632), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.266 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.340, %3633), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.88 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.266, %3631, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.142 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.88, %input.338, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3637 : Tensor = prim::GetAttr[name="bias"](%3629)
  %3638 : Tensor = prim::GetAttr[name="weight"](%3629)
  %3639 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.142, %3638), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.341 : Float(119:1664, 13:128, 128:1) = aten::add(%3639, %3637, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3641 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14230.FFNOutput = prim::GetAttr[name="output"](%3501)
  %3642 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14227.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3501)
  %3643 : __torch__.torch.nn.modules.linear.___torch_mangle_14226.Linear = prim::GetAttr[name="dense"](%3642)
  %3644 : Tensor = prim::GetAttr[name="bias"](%3643)
  %3645 : Tensor = prim::GetAttr[name="weight"](%3643)
  %3646 : Float(128:1, 512:128) = aten::t(%3645), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.267 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.341, %3646), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.342 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.267, %3644, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.343 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3650 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14229.NoNorm = prim::GetAttr[name="LayerNorm"](%3641)
  %3651 : __torch__.torch.nn.modules.linear.___torch_mangle_14228.Linear = prim::GetAttr[name="dense"](%3641)
  %3652 : Tensor = prim::GetAttr[name="bias"](%3651)
  %3653 : Tensor = prim::GetAttr[name="weight"](%3651)
  %3654 : Float(512:1, 128:512) = aten::t(%3653), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.268 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.343, %3654), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.89 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.268, %3652, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.143 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.89, %input.341, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3658 : Tensor = prim::GetAttr[name="bias"](%3650)
  %3659 : Tensor = prim::GetAttr[name="weight"](%3650)
  %3660 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.143, %3659), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.344 : Float(119:1664, 13:128, 128:1) = aten::add(%3660, %3658, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3662 : __torch__.torch.nn.modules.linear.___torch_mangle_14198.Linear = prim::GetAttr[name="dense"](%3499)
  %3663 : Tensor = prim::GetAttr[name="bias"](%3662)
  %3664 : Tensor = prim::GetAttr[name="weight"](%3662)
  %3665 : Float(128:1, 512:128) = aten::t(%3664), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %output.269 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.344, %3665), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %input.345 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.269, %3663, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1678:0
  %input.346 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate # torch/nn/functional.py:1119:0
  %3669 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14205.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3498)
  %3670 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14201.NoNorm = prim::GetAttr[name="LayerNorm"](%3498)
  %3671 : __torch__.torch.nn.modules.linear.___torch_mangle_14200.Linear = prim::GetAttr[name="dense"](%3498)
  %3672 : Tensor = prim::GetAttr[name="bias"](%3671)
  %3673 : Tensor = prim::GetAttr[name="weight"](%3671)
  %3674 : Float(512:1, 128:512) = aten::t(%3673), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %output.270 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.346, %3674), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %layer_output.18 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.270, %3672, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.144 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.18, %input.344, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output # transformers/modeling_mobilebert.py:405:0
  %3678 : Tensor = prim::GetAttr[name="bias"](%3670)
  %3679 : Tensor = prim::GetAttr[name="weight"](%3670)
  %3680 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.144, %3679), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.347 : Float(119:1664, 13:128, 128:1) = aten::add(%3680, %3678, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3682 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14203.NoNorm = prim::GetAttr[name="LayerNorm"](%3669)
  %3683 : __torch__.torch.nn.modules.linear.___torch_mangle_14202.Linear = prim::GetAttr[name="dense"](%3669)
  %3684 : Tensor = prim::GetAttr[name="bias"](%3683)
  %3685 : Tensor = prim::GetAttr[name="weight"](%3683)
  %3686 : Float(128:1, 512:128) = aten::t(%3685), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.271 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.347, %3686), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.348 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.271, %3684, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.90 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.348, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.145 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.90, %input.330, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3691 : Tensor = prim::GetAttr[name="bias"](%3682)
  %3692 : Tensor = prim::GetAttr[name="weight"](%3682)
  %3693 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.145, %3692), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.349 : Float(119:6656, 13:512, 512:1) = aten::add(%3693, %3691, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14251.MobileBertOutput = prim::GetAttr[name="output"](%112)
  %3696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14244.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%112)
  %3697 : __torch__.torch.nn.modules.container.___torch_mangle_14277.ModuleList = prim::GetAttr[name="ffn"](%112)
  %3698 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14276.FFNLayer = prim::GetAttr[name="2"](%3697)
  %3699 : __torch__.torch.nn.modules.container.___torch_mangle_14277.ModuleList = prim::GetAttr[name="ffn"](%112)
  %3700 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14270.FFNLayer = prim::GetAttr[name="1"](%3699)
  %3701 : __torch__.torch.nn.modules.container.___torch_mangle_14277.ModuleList = prim::GetAttr[name="ffn"](%112)
  %3702 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14264.FFNLayer = prim::GetAttr[name="0"](%3701)
  %3703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14242.MobileBertAttention = prim::GetAttr[name="attention"](%112)
  %3704 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14258.Bottleneck = prim::GetAttr[name="bottleneck"](%112)
  %3705 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14257.BottleneckLayer = prim::GetAttr[name="attention"](%3704)
  %3706 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14254.BottleneckLayer = prim::GetAttr[name="input"](%3704)
  %3707 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14253.NoNorm = prim::GetAttr[name="LayerNorm"](%3706)
  %3708 : __torch__.torch.nn.modules.linear.___torch_mangle_14252.Linear = prim::GetAttr[name="dense"](%3706)
  %3709 : Tensor = prim::GetAttr[name="bias"](%3708)
  %3710 : Tensor = prim::GetAttr[name="weight"](%3708)
  %3711 : Float(512:1, 128:512) = aten::t(%3710), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.272 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.349, %3711), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.146 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.272, %3709, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3714 : Tensor = prim::GetAttr[name="bias"](%3707)
  %3715 : Tensor = prim::GetAttr[name="weight"](%3707)
  %3716 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.146, %3715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.19 : Float(119:1664, 13:128, 128:1) = aten::add(%3716, %3714, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14256.NoNorm = prim::GetAttr[name="LayerNorm"](%3705)
  %3719 : __torch__.torch.nn.modules.linear.___torch_mangle_14255.Linear = prim::GetAttr[name="dense"](%3705)
  %3720 : Tensor = prim::GetAttr[name="bias"](%3719)
  %3721 : Tensor = prim::GetAttr[name="weight"](%3719)
  %3722 : Float(512:1, 128:512) = aten::t(%3721), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.273 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.349, %3722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.147 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.273, %3720, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3725 : Tensor = prim::GetAttr[name="bias"](%3718)
  %3726 : Tensor = prim::GetAttr[name="weight"](%3718)
  %3727 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.147, %3726), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.350 : Float(119:1664, 13:128, 128:1) = aten::add(%3727, %3725, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3729 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.350, %residual_tensor.19)
  %3730 : Float(119:1664, 13:128, 128:1), %3731 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%3729)
  %3732 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14241.MobileBertSelfOutput = prim::GetAttr[name="output"](%3703)
  %3733 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14238.MobileBertSelfAttention = prim::GetAttr[name="self"](%3703)
  %3734 : __torch__.torch.nn.modules.linear.___torch_mangle_14236.Linear = prim::GetAttr[name="value"](%3733)
  %3735 : __torch__.torch.nn.modules.linear.___torch_mangle_14235.Linear = prim::GetAttr[name="key"](%3733)
  %3736 : __torch__.torch.nn.modules.linear.___torch_mangle_14234.Linear = prim::GetAttr[name="query"](%3733)
  %3737 : Tensor = prim::GetAttr[name="bias"](%3736)
  %3738 : Tensor = prim::GetAttr[name="weight"](%3736)
  %3739 : Float(128:1, 128:128) = aten::t(%3738), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %output.274 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3730, %3739), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %x.109 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.274, %3737, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1678:0
  %3742 : Tensor = prim::GetAttr[name="bias"](%3735)
  %3743 : Tensor = prim::GetAttr[name="weight"](%3735)
  %3744 : Float(128:1, 128:128) = aten::t(%3743), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %output.275 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3730, %3744), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %x.111 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.275, %3742, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1678:0
  %3747 : Tensor = prim::GetAttr[name="bias"](%3734)
  %3748 : Tensor = prim::GetAttr[name="weight"](%3734)
  %3749 : Float(512:1, 128:512) = aten::t(%3748), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %output.276 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.349, %3749), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %x.113 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.276, %3747, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1678:0
  %3752 : int = aten::size(%x.109, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3753 : int = aten::size(%x.109, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3754 : int[] = prim::ListConstruct(%3752, %3753, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.110 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.109, %3754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3756 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %query_layer.19 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.110, %3756), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3758 : int = aten::size(%x.111, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3759 : int = aten::size(%x.111, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3760 : int[] = prim::ListConstruct(%3758, %3759, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.112 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.111, %3760), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3762 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %key_layer.19 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.112, %3762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3764 : int = aten::size(%x.113, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3765 : int = aten::size(%x.113, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3766 : int[] = prim::ListConstruct(%3764, %3765, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.114 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.113, %3766), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3768 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %value_layer.19 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.114, %3768), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3770 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.19, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.37 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.19, %3770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.38 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.37, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.351 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.38, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.352 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.351, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.19 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.352, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.37 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.19, %value_layer.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:280:0
  %3777 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %3778 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.37, %3777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.38 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3778, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %3780 : int = aten::size(%context_layer.38, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3781 : int = aten::size(%context_layer.38, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3782 : int[] = prim::ListConstruct(%3780, %3781, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %input.353 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.38, %3782), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:283:0
  %3784 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14240.NoNorm = prim::GetAttr[name="LayerNorm"](%3732)
  %3785 : __torch__.torch.nn.modules.linear.___torch_mangle_14239.Linear = prim::GetAttr[name="dense"](%3732)
  %3786 : Tensor = prim::GetAttr[name="bias"](%3785)
  %3787 : Tensor = prim::GetAttr[name="weight"](%3785)
  %3788 : Float(128:1, 128:128) = aten::t(%3787), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %output.277 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.353, %3788), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.91 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.277, %3786, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.148 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.91, %3731, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output # transformers/modeling_mobilebert.py:301:0
  %3792 : Tensor = prim::GetAttr[name="bias"](%3784)
  %3793 : Tensor = prim::GetAttr[name="weight"](%3784)
  %3794 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.148, %3793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.354 : Float(119:1664, 13:128, 128:1) = aten::add(%3794, %3792, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3796 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14263.FFNOutput = prim::GetAttr[name="output"](%3702)
  %3797 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14260.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3702)
  %3798 : __torch__.torch.nn.modules.linear.___torch_mangle_14259.Linear = prim::GetAttr[name="dense"](%3797)
  %3799 : Tensor = prim::GetAttr[name="bias"](%3798)
  %3800 : Tensor = prim::GetAttr[name="weight"](%3798)
  %3801 : Float(128:1, 512:128) = aten::t(%3800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.278 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.354, %3801), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.355 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.278, %3799, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.356 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3805 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14262.NoNorm = prim::GetAttr[name="LayerNorm"](%3796)
  %3806 : __torch__.torch.nn.modules.linear.___torch_mangle_14261.Linear = prim::GetAttr[name="dense"](%3796)
  %3807 : Tensor = prim::GetAttr[name="bias"](%3806)
  %3808 : Tensor = prim::GetAttr[name="weight"](%3806)
  %3809 : Float(512:1, 128:512) = aten::t(%3808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.279 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.356, %3809), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.92 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.279, %3807, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.149 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.92, %input.354, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3813 : Tensor = prim::GetAttr[name="bias"](%3805)
  %3814 : Tensor = prim::GetAttr[name="weight"](%3805)
  %3815 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.149, %3814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.357 : Float(119:1664, 13:128, 128:1) = aten::add(%3815, %3813, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3817 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14269.FFNOutput = prim::GetAttr[name="output"](%3700)
  %3818 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14266.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3700)
  %3819 : __torch__.torch.nn.modules.linear.___torch_mangle_14265.Linear = prim::GetAttr[name="dense"](%3818)
  %3820 : Tensor = prim::GetAttr[name="bias"](%3819)
  %3821 : Tensor = prim::GetAttr[name="weight"](%3819)
  %3822 : Float(128:1, 512:128) = aten::t(%3821), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.280 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.357, %3822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.358 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.280, %3820, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.359 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3826 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14268.NoNorm = prim::GetAttr[name="LayerNorm"](%3817)
  %3827 : __torch__.torch.nn.modules.linear.___torch_mangle_14267.Linear = prim::GetAttr[name="dense"](%3817)
  %3828 : Tensor = prim::GetAttr[name="bias"](%3827)
  %3829 : Tensor = prim::GetAttr[name="weight"](%3827)
  %3830 : Float(512:1, 128:512) = aten::t(%3829), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.281 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.359, %3830), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.93 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.281, %3828, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.150 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.93, %input.357, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3834 : Tensor = prim::GetAttr[name="bias"](%3826)
  %3835 : Tensor = prim::GetAttr[name="weight"](%3826)
  %3836 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.150, %3835), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.360 : Float(119:1664, 13:128, 128:1) = aten::add(%3836, %3834, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3838 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14275.FFNOutput = prim::GetAttr[name="output"](%3698)
  %3839 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14272.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3698)
  %3840 : __torch__.torch.nn.modules.linear.___torch_mangle_14271.Linear = prim::GetAttr[name="dense"](%3839)
  %3841 : Tensor = prim::GetAttr[name="bias"](%3840)
  %3842 : Tensor = prim::GetAttr[name="weight"](%3840)
  %3843 : Float(128:1, 512:128) = aten::t(%3842), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.282 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.360, %3843), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.361 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.282, %3841, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.362 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3847 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14274.NoNorm = prim::GetAttr[name="LayerNorm"](%3838)
  %3848 : __torch__.torch.nn.modules.linear.___torch_mangle_14273.Linear = prim::GetAttr[name="dense"](%3838)
  %3849 : Tensor = prim::GetAttr[name="bias"](%3848)
  %3850 : Tensor = prim::GetAttr[name="weight"](%3848)
  %3851 : Float(512:1, 128:512) = aten::t(%3850), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.283 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.362, %3851), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.94 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.283, %3849, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.151 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.94, %input.360, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3855 : Tensor = prim::GetAttr[name="bias"](%3847)
  %3856 : Tensor = prim::GetAttr[name="weight"](%3847)
  %3857 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.151, %3856), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.363 : Float(119:1664, 13:128, 128:1) = aten::add(%3857, %3855, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3859 : __torch__.torch.nn.modules.linear.___torch_mangle_14243.Linear = prim::GetAttr[name="dense"](%3696)
  %3860 : Tensor = prim::GetAttr[name="bias"](%3859)
  %3861 : Tensor = prim::GetAttr[name="weight"](%3859)
  %3862 : Float(128:1, 512:128) = aten::t(%3861), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %output.284 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.363, %3862), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %input.364 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.284, %3860, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1678:0
  %input.365 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate # torch/nn/functional.py:1119:0
  %3866 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14250.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3695)
  %3867 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14246.NoNorm = prim::GetAttr[name="LayerNorm"](%3695)
  %3868 : __torch__.torch.nn.modules.linear.___torch_mangle_14245.Linear = prim::GetAttr[name="dense"](%3695)
  %3869 : Tensor = prim::GetAttr[name="bias"](%3868)
  %3870 : Tensor = prim::GetAttr[name="weight"](%3868)
  %3871 : Float(512:1, 128:512) = aten::t(%3870), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %output.285 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.365, %3871), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %layer_output.19 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.285, %3869, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.152 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.19, %input.363, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output # transformers/modeling_mobilebert.py:405:0
  %3875 : Tensor = prim::GetAttr[name="bias"](%3867)
  %3876 : Tensor = prim::GetAttr[name="weight"](%3867)
  %3877 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.152, %3876), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.366 : Float(119:1664, 13:128, 128:1) = aten::add(%3877, %3875, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3879 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14248.NoNorm = prim::GetAttr[name="LayerNorm"](%3866)
  %3880 : __torch__.torch.nn.modules.linear.___torch_mangle_14247.Linear = prim::GetAttr[name="dense"](%3866)
  %3881 : Tensor = prim::GetAttr[name="bias"](%3880)
  %3882 : Tensor = prim::GetAttr[name="weight"](%3880)
  %3883 : Float(128:1, 512:128) = aten::t(%3882), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.286 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.366, %3883), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.367 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.286, %3881, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.95 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.367, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.153 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.95, %input.349, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3888 : Tensor = prim::GetAttr[name="bias"](%3879)
  %3889 : Tensor = prim::GetAttr[name="weight"](%3879)
  %3890 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.153, %3889), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.368 : Float(119:6656, 13:512, 512:1) = aten::add(%3890, %3888, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3892 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14296.MobileBertOutput = prim::GetAttr[name="output"](%110)
  %3893 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14289.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%110)
  %3894 : __torch__.torch.nn.modules.container.___torch_mangle_14322.ModuleList = prim::GetAttr[name="ffn"](%110)
  %3895 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14321.FFNLayer = prim::GetAttr[name="2"](%3894)
  %3896 : __torch__.torch.nn.modules.container.___torch_mangle_14322.ModuleList = prim::GetAttr[name="ffn"](%110)
  %3897 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14315.FFNLayer = prim::GetAttr[name="1"](%3896)
  %3898 : __torch__.torch.nn.modules.container.___torch_mangle_14322.ModuleList = prim::GetAttr[name="ffn"](%110)
  %3899 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14309.FFNLayer = prim::GetAttr[name="0"](%3898)
  %3900 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14287.MobileBertAttention = prim::GetAttr[name="attention"](%110)
  %3901 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14303.Bottleneck = prim::GetAttr[name="bottleneck"](%110)
  %3902 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14302.BottleneckLayer = prim::GetAttr[name="attention"](%3901)
  %3903 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14299.BottleneckLayer = prim::GetAttr[name="input"](%3901)
  %3904 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14298.NoNorm = prim::GetAttr[name="LayerNorm"](%3903)
  %3905 : __torch__.torch.nn.modules.linear.___torch_mangle_14297.Linear = prim::GetAttr[name="dense"](%3903)
  %3906 : Tensor = prim::GetAttr[name="bias"](%3905)
  %3907 : Tensor = prim::GetAttr[name="weight"](%3905)
  %3908 : Float(512:1, 128:512) = aten::t(%3907), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.287 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.368, %3908), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.154 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.287, %3906, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3911 : Tensor = prim::GetAttr[name="bias"](%3904)
  %3912 : Tensor = prim::GetAttr[name="weight"](%3904)
  %3913 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.154, %3912), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.20 : Float(119:1664, 13:128, 128:1) = aten::add(%3913, %3911, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3915 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14301.NoNorm = prim::GetAttr[name="LayerNorm"](%3902)
  %3916 : __torch__.torch.nn.modules.linear.___torch_mangle_14300.Linear = prim::GetAttr[name="dense"](%3902)
  %3917 : Tensor = prim::GetAttr[name="bias"](%3916)
  %3918 : Tensor = prim::GetAttr[name="weight"](%3916)
  %3919 : Float(512:1, 128:512) = aten::t(%3918), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.288 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.368, %3919), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.155 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.288, %3917, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3922 : Tensor = prim::GetAttr[name="bias"](%3915)
  %3923 : Tensor = prim::GetAttr[name="weight"](%3915)
  %3924 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.155, %3923), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.369 : Float(119:1664, 13:128, 128:1) = aten::add(%3924, %3922, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3926 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.369, %residual_tensor.20)
  %3927 : Float(119:1664, 13:128, 128:1), %3928 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%3926)
  %3929 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14286.MobileBertSelfOutput = prim::GetAttr[name="output"](%3900)
  %3930 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14283.MobileBertSelfAttention = prim::GetAttr[name="self"](%3900)
  %3931 : __torch__.torch.nn.modules.linear.___torch_mangle_14281.Linear = prim::GetAttr[name="value"](%3930)
  %3932 : __torch__.torch.nn.modules.linear.___torch_mangle_14280.Linear = prim::GetAttr[name="key"](%3930)
  %3933 : __torch__.torch.nn.modules.linear.___torch_mangle_14279.Linear = prim::GetAttr[name="query"](%3930)
  %3934 : Tensor = prim::GetAttr[name="bias"](%3933)
  %3935 : Tensor = prim::GetAttr[name="weight"](%3933)
  %3936 : Float(128:1, 128:128) = aten::t(%3935), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %output.289 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3927, %3936), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %x.115 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.289, %3934, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1678:0
  %3939 : Tensor = prim::GetAttr[name="bias"](%3932)
  %3940 : Tensor = prim::GetAttr[name="weight"](%3932)
  %3941 : Float(128:1, 128:128) = aten::t(%3940), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %output.290 : Float(119:1664, 13:128, 128:1) = aten::matmul(%3927, %3941), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %x.117 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.290, %3939, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1678:0
  %3944 : Tensor = prim::GetAttr[name="bias"](%3931)
  %3945 : Tensor = prim::GetAttr[name="weight"](%3931)
  %3946 : Float(512:1, 128:512) = aten::t(%3945), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %output.291 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.368, %3946), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %x.119 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.291, %3944, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1678:0
  %3949 : int = aten::size(%x.115, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3950 : int = aten::size(%x.115, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3951 : int[] = prim::ListConstruct(%3949, %3950, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.116 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.115, %3951), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3953 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %query_layer.20 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.116, %3953), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3955 : int = aten::size(%x.117, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3956 : int = aten::size(%x.117, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3957 : int[] = prim::ListConstruct(%3955, %3956, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.118 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.117, %3957), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3959 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %key_layer.20 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.118, %3959), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3961 : int = aten::size(%x.119, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3962 : int = aten::size(%x.119, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3963 : int[] = prim::ListConstruct(%3961, %3962, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.120 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.119, %3963), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3965 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %value_layer.20 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.120, %3965), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3967 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.20, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.39 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.20, %3967), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.40 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.39, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.370 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.40, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.371 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.370, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.20 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.371, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.39 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.20, %value_layer.20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:280:0
  %3974 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %3975 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.39, %3974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.40 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3975, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %3977 : int = aten::size(%context_layer.40, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3978 : int = aten::size(%context_layer.40, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3979 : int[] = prim::ListConstruct(%3977, %3978, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %input.372 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.40, %3979), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:283:0
  %3981 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14285.NoNorm = prim::GetAttr[name="LayerNorm"](%3929)
  %3982 : __torch__.torch.nn.modules.linear.___torch_mangle_14284.Linear = prim::GetAttr[name="dense"](%3929)
  %3983 : Tensor = prim::GetAttr[name="bias"](%3982)
  %3984 : Tensor = prim::GetAttr[name="weight"](%3982)
  %3985 : Float(128:1, 128:128) = aten::t(%3984), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %output.292 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.372, %3985), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.96 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.292, %3983, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.156 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.96, %3928, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output # transformers/modeling_mobilebert.py:301:0
  %3989 : Tensor = prim::GetAttr[name="bias"](%3981)
  %3990 : Tensor = prim::GetAttr[name="weight"](%3981)
  %3991 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.156, %3990), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.373 : Float(119:1664, 13:128, 128:1) = aten::add(%3991, %3989, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3993 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14308.FFNOutput = prim::GetAttr[name="output"](%3899)
  %3994 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14305.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3899)
  %3995 : __torch__.torch.nn.modules.linear.___torch_mangle_14304.Linear = prim::GetAttr[name="dense"](%3994)
  %3996 : Tensor = prim::GetAttr[name="bias"](%3995)
  %3997 : Tensor = prim::GetAttr[name="weight"](%3995)
  %3998 : Float(128:1, 512:128) = aten::t(%3997), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.293 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.373, %3998), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.374 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.293, %3996, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.375 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4002 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14307.NoNorm = prim::GetAttr[name="LayerNorm"](%3993)
  %4003 : __torch__.torch.nn.modules.linear.___torch_mangle_14306.Linear = prim::GetAttr[name="dense"](%3993)
  %4004 : Tensor = prim::GetAttr[name="bias"](%4003)
  %4005 : Tensor = prim::GetAttr[name="weight"](%4003)
  %4006 : Float(512:1, 128:512) = aten::t(%4005), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.294 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.375, %4006), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.97 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.294, %4004, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.157 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.97, %input.373, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4010 : Tensor = prim::GetAttr[name="bias"](%4002)
  %4011 : Tensor = prim::GetAttr[name="weight"](%4002)
  %4012 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.157, %4011), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.376 : Float(119:1664, 13:128, 128:1) = aten::add(%4012, %4010, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4014 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14314.FFNOutput = prim::GetAttr[name="output"](%3897)
  %4015 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14311.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3897)
  %4016 : __torch__.torch.nn.modules.linear.___torch_mangle_14310.Linear = prim::GetAttr[name="dense"](%4015)
  %4017 : Tensor = prim::GetAttr[name="bias"](%4016)
  %4018 : Tensor = prim::GetAttr[name="weight"](%4016)
  %4019 : Float(128:1, 512:128) = aten::t(%4018), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.295 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.376, %4019), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.377 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.295, %4017, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.378 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4023 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14313.NoNorm = prim::GetAttr[name="LayerNorm"](%4014)
  %4024 : __torch__.torch.nn.modules.linear.___torch_mangle_14312.Linear = prim::GetAttr[name="dense"](%4014)
  %4025 : Tensor = prim::GetAttr[name="bias"](%4024)
  %4026 : Tensor = prim::GetAttr[name="weight"](%4024)
  %4027 : Float(512:1, 128:512) = aten::t(%4026), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.296 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.378, %4027), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.98 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.296, %4025, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.158 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.98, %input.376, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4031 : Tensor = prim::GetAttr[name="bias"](%4023)
  %4032 : Tensor = prim::GetAttr[name="weight"](%4023)
  %4033 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.158, %4032), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.379 : Float(119:1664, 13:128, 128:1) = aten::add(%4033, %4031, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4035 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14320.FFNOutput = prim::GetAttr[name="output"](%3895)
  %4036 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14317.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3895)
  %4037 : __torch__.torch.nn.modules.linear.___torch_mangle_14316.Linear = prim::GetAttr[name="dense"](%4036)
  %4038 : Tensor = prim::GetAttr[name="bias"](%4037)
  %4039 : Tensor = prim::GetAttr[name="weight"](%4037)
  %4040 : Float(128:1, 512:128) = aten::t(%4039), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.297 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.379, %4040), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.380 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.297, %4038, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.381 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4044 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14319.NoNorm = prim::GetAttr[name="LayerNorm"](%4035)
  %4045 : __torch__.torch.nn.modules.linear.___torch_mangle_14318.Linear = prim::GetAttr[name="dense"](%4035)
  %4046 : Tensor = prim::GetAttr[name="bias"](%4045)
  %4047 : Tensor = prim::GetAttr[name="weight"](%4045)
  %4048 : Float(512:1, 128:512) = aten::t(%4047), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.298 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.381, %4048), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.99 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.298, %4046, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.159 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.99, %input.379, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4052 : Tensor = prim::GetAttr[name="bias"](%4044)
  %4053 : Tensor = prim::GetAttr[name="weight"](%4044)
  %4054 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.159, %4053), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.382 : Float(119:1664, 13:128, 128:1) = aten::add(%4054, %4052, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4056 : __torch__.torch.nn.modules.linear.___torch_mangle_14288.Linear = prim::GetAttr[name="dense"](%3893)
  %4057 : Tensor = prim::GetAttr[name="bias"](%4056)
  %4058 : Tensor = prim::GetAttr[name="weight"](%4056)
  %4059 : Float(128:1, 512:128) = aten::t(%4058), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %output.299 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.382, %4059), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %input.383 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.299, %4057, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1678:0
  %input.384 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate # torch/nn/functional.py:1119:0
  %4063 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14295.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3892)
  %4064 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14291.NoNorm = prim::GetAttr[name="LayerNorm"](%3892)
  %4065 : __torch__.torch.nn.modules.linear.___torch_mangle_14290.Linear = prim::GetAttr[name="dense"](%3892)
  %4066 : Tensor = prim::GetAttr[name="bias"](%4065)
  %4067 : Tensor = prim::GetAttr[name="weight"](%4065)
  %4068 : Float(512:1, 128:512) = aten::t(%4067), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %output.300 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.384, %4068), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %layer_output.20 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.300, %4066, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.160 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.20, %input.382, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output # transformers/modeling_mobilebert.py:405:0
  %4072 : Tensor = prim::GetAttr[name="bias"](%4064)
  %4073 : Tensor = prim::GetAttr[name="weight"](%4064)
  %4074 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.160, %4073), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.385 : Float(119:1664, 13:128, 128:1) = aten::add(%4074, %4072, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4076 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14293.NoNorm = prim::GetAttr[name="LayerNorm"](%4063)
  %4077 : __torch__.torch.nn.modules.linear.___torch_mangle_14292.Linear = prim::GetAttr[name="dense"](%4063)
  %4078 : Tensor = prim::GetAttr[name="bias"](%4077)
  %4079 : Tensor = prim::GetAttr[name="weight"](%4077)
  %4080 : Float(128:1, 512:128) = aten::t(%4079), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.301 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.385, %4080), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.386 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.301, %4078, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.100 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.386, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.161 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.100, %input.368, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4085 : Tensor = prim::GetAttr[name="bias"](%4076)
  %4086 : Tensor = prim::GetAttr[name="weight"](%4076)
  %4087 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.161, %4086), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.387 : Float(119:6656, 13:512, 512:1) = aten::add(%4087, %4085, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4089 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14341.MobileBertOutput = prim::GetAttr[name="output"](%108)
  %4090 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14334.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%108)
  %4091 : __torch__.torch.nn.modules.container.___torch_mangle_14367.ModuleList = prim::GetAttr[name="ffn"](%108)
  %4092 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14366.FFNLayer = prim::GetAttr[name="2"](%4091)
  %4093 : __torch__.torch.nn.modules.container.___torch_mangle_14367.ModuleList = prim::GetAttr[name="ffn"](%108)
  %4094 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14360.FFNLayer = prim::GetAttr[name="1"](%4093)
  %4095 : __torch__.torch.nn.modules.container.___torch_mangle_14367.ModuleList = prim::GetAttr[name="ffn"](%108)
  %4096 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14354.FFNLayer = prim::GetAttr[name="0"](%4095)
  %4097 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14332.MobileBertAttention = prim::GetAttr[name="attention"](%108)
  %4098 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14348.Bottleneck = prim::GetAttr[name="bottleneck"](%108)
  %4099 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14347.BottleneckLayer = prim::GetAttr[name="attention"](%4098)
  %4100 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14344.BottleneckLayer = prim::GetAttr[name="input"](%4098)
  %4101 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14343.NoNorm = prim::GetAttr[name="LayerNorm"](%4100)
  %4102 : __torch__.torch.nn.modules.linear.___torch_mangle_14342.Linear = prim::GetAttr[name="dense"](%4100)
  %4103 : Tensor = prim::GetAttr[name="bias"](%4102)
  %4104 : Tensor = prim::GetAttr[name="weight"](%4102)
  %4105 : Float(512:1, 128:512) = aten::t(%4104), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.302 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.387, %4105), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.162 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.302, %4103, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4108 : Tensor = prim::GetAttr[name="bias"](%4101)
  %4109 : Tensor = prim::GetAttr[name="weight"](%4101)
  %4110 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.162, %4109), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.21 : Float(119:1664, 13:128, 128:1) = aten::add(%4110, %4108, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14346.NoNorm = prim::GetAttr[name="LayerNorm"](%4099)
  %4113 : __torch__.torch.nn.modules.linear.___torch_mangle_14345.Linear = prim::GetAttr[name="dense"](%4099)
  %4114 : Tensor = prim::GetAttr[name="bias"](%4113)
  %4115 : Tensor = prim::GetAttr[name="weight"](%4113)
  %4116 : Float(512:1, 128:512) = aten::t(%4115), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.303 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.387, %4116), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.163 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.303, %4114, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4119 : Tensor = prim::GetAttr[name="bias"](%4112)
  %4120 : Tensor = prim::GetAttr[name="weight"](%4112)
  %4121 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.163, %4120), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.388 : Float(119:1664, 13:128, 128:1) = aten::add(%4121, %4119, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4123 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.388, %residual_tensor.21)
  %4124 : Float(119:1664, 13:128, 128:1), %4125 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%4123)
  %4126 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14331.MobileBertSelfOutput = prim::GetAttr[name="output"](%4097)
  %4127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14328.MobileBertSelfAttention = prim::GetAttr[name="self"](%4097)
  %4128 : __torch__.torch.nn.modules.linear.___torch_mangle_14326.Linear = prim::GetAttr[name="value"](%4127)
  %4129 : __torch__.torch.nn.modules.linear.___torch_mangle_14325.Linear = prim::GetAttr[name="key"](%4127)
  %4130 : __torch__.torch.nn.modules.linear.___torch_mangle_14324.Linear = prim::GetAttr[name="query"](%4127)
  %4131 : Tensor = prim::GetAttr[name="bias"](%4130)
  %4132 : Tensor = prim::GetAttr[name="weight"](%4130)
  %4133 : Float(128:1, 128:128) = aten::t(%4132), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %output.304 : Float(119:1664, 13:128, 128:1) = aten::matmul(%4124, %4133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %x.121 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.304, %4131, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1678:0
  %4136 : Tensor = prim::GetAttr[name="bias"](%4129)
  %4137 : Tensor = prim::GetAttr[name="weight"](%4129)
  %4138 : Float(128:1, 128:128) = aten::t(%4137), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %output.305 : Float(119:1664, 13:128, 128:1) = aten::matmul(%4124, %4138), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %x.123 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.305, %4136, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1678:0
  %4141 : Tensor = prim::GetAttr[name="bias"](%4128)
  %4142 : Tensor = prim::GetAttr[name="weight"](%4128)
  %4143 : Float(512:1, 128:512) = aten::t(%4142), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %output.306 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.387, %4143), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %x.125 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.306, %4141, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1678:0
  %4146 : int = aten::size(%x.121, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4147 : int = aten::size(%x.121, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4148 : int[] = prim::ListConstruct(%4146, %4147, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.122 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.121, %4148), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4150 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %query_layer.21 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.122, %4150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4152 : int = aten::size(%x.123, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4153 : int = aten::size(%x.123, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4154 : int[] = prim::ListConstruct(%4152, %4153, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.124 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.123, %4154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4156 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %key_layer.21 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.124, %4156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4158 : int = aten::size(%x.125, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4159 : int = aten::size(%x.125, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4160 : int[] = prim::ListConstruct(%4158, %4159, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.126 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.125, %4160), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4162 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %value_layer.21 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.126, %4162), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4164 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.21, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.41 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.21, %4164), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.42 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.41, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.389 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.42, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.390 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.389, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.21 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.390, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.41 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.21, %value_layer.21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:280:0
  %4171 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %4172 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.41, %4171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.42 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4172, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %4174 : int = aten::size(%context_layer.42, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4175 : int = aten::size(%context_layer.42, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4176 : int[] = prim::ListConstruct(%4174, %4175, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %input.391 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.42, %4176), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:283:0
  %4178 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14330.NoNorm = prim::GetAttr[name="LayerNorm"](%4126)
  %4179 : __torch__.torch.nn.modules.linear.___torch_mangle_14329.Linear = prim::GetAttr[name="dense"](%4126)
  %4180 : Tensor = prim::GetAttr[name="bias"](%4179)
  %4181 : Tensor = prim::GetAttr[name="weight"](%4179)
  %4182 : Float(128:1, 128:128) = aten::t(%4181), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %output.307 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.391, %4182), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.101 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.307, %4180, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.164 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.101, %4125, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output # transformers/modeling_mobilebert.py:301:0
  %4186 : Tensor = prim::GetAttr[name="bias"](%4178)
  %4187 : Tensor = prim::GetAttr[name="weight"](%4178)
  %4188 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.164, %4187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.392 : Float(119:1664, 13:128, 128:1) = aten::add(%4188, %4186, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4190 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14353.FFNOutput = prim::GetAttr[name="output"](%4096)
  %4191 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14350.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4096)
  %4192 : __torch__.torch.nn.modules.linear.___torch_mangle_14349.Linear = prim::GetAttr[name="dense"](%4191)
  %4193 : Tensor = prim::GetAttr[name="bias"](%4192)
  %4194 : Tensor = prim::GetAttr[name="weight"](%4192)
  %4195 : Float(128:1, 512:128) = aten::t(%4194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.308 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.392, %4195), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.393 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.308, %4193, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.394 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4199 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14352.NoNorm = prim::GetAttr[name="LayerNorm"](%4190)
  %4200 : __torch__.torch.nn.modules.linear.___torch_mangle_14351.Linear = prim::GetAttr[name="dense"](%4190)
  %4201 : Tensor = prim::GetAttr[name="bias"](%4200)
  %4202 : Tensor = prim::GetAttr[name="weight"](%4200)
  %4203 : Float(512:1, 128:512) = aten::t(%4202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.309 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.394, %4203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.102 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.309, %4201, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.165 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.102, %input.392, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4207 : Tensor = prim::GetAttr[name="bias"](%4199)
  %4208 : Tensor = prim::GetAttr[name="weight"](%4199)
  %4209 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.165, %4208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.395 : Float(119:1664, 13:128, 128:1) = aten::add(%4209, %4207, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4211 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14359.FFNOutput = prim::GetAttr[name="output"](%4094)
  %4212 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14356.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4094)
  %4213 : __torch__.torch.nn.modules.linear.___torch_mangle_14355.Linear = prim::GetAttr[name="dense"](%4212)
  %4214 : Tensor = prim::GetAttr[name="bias"](%4213)
  %4215 : Tensor = prim::GetAttr[name="weight"](%4213)
  %4216 : Float(128:1, 512:128) = aten::t(%4215), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.310 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.395, %4216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.396 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.310, %4214, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.397 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4220 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14358.NoNorm = prim::GetAttr[name="LayerNorm"](%4211)
  %4221 : __torch__.torch.nn.modules.linear.___torch_mangle_14357.Linear = prim::GetAttr[name="dense"](%4211)
  %4222 : Tensor = prim::GetAttr[name="bias"](%4221)
  %4223 : Tensor = prim::GetAttr[name="weight"](%4221)
  %4224 : Float(512:1, 128:512) = aten::t(%4223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.311 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.397, %4224), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.103 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.311, %4222, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.166 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.103, %input.395, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4228 : Tensor = prim::GetAttr[name="bias"](%4220)
  %4229 : Tensor = prim::GetAttr[name="weight"](%4220)
  %4230 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.166, %4229), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.398 : Float(119:1664, 13:128, 128:1) = aten::add(%4230, %4228, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4232 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14365.FFNOutput = prim::GetAttr[name="output"](%4092)
  %4233 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14362.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4092)
  %4234 : __torch__.torch.nn.modules.linear.___torch_mangle_14361.Linear = prim::GetAttr[name="dense"](%4233)
  %4235 : Tensor = prim::GetAttr[name="bias"](%4234)
  %4236 : Tensor = prim::GetAttr[name="weight"](%4234)
  %4237 : Float(128:1, 512:128) = aten::t(%4236), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.312 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.398, %4237), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.399 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.312, %4235, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.400 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4241 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14364.NoNorm = prim::GetAttr[name="LayerNorm"](%4232)
  %4242 : __torch__.torch.nn.modules.linear.___torch_mangle_14363.Linear = prim::GetAttr[name="dense"](%4232)
  %4243 : Tensor = prim::GetAttr[name="bias"](%4242)
  %4244 : Tensor = prim::GetAttr[name="weight"](%4242)
  %4245 : Float(512:1, 128:512) = aten::t(%4244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.313 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.400, %4245), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.104 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.313, %4243, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.167 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.104, %input.398, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4249 : Tensor = prim::GetAttr[name="bias"](%4241)
  %4250 : Tensor = prim::GetAttr[name="weight"](%4241)
  %4251 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.167, %4250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.401 : Float(119:1664, 13:128, 128:1) = aten::add(%4251, %4249, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4253 : __torch__.torch.nn.modules.linear.___torch_mangle_14333.Linear = prim::GetAttr[name="dense"](%4090)
  %4254 : Tensor = prim::GetAttr[name="bias"](%4253)
  %4255 : Tensor = prim::GetAttr[name="weight"](%4253)
  %4256 : Float(128:1, 512:128) = aten::t(%4255), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %output.314 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.401, %4256), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %input.402 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.314, %4254, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1678:0
  %input.403 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate # torch/nn/functional.py:1119:0
  %4260 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14340.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4089)
  %4261 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14336.NoNorm = prim::GetAttr[name="LayerNorm"](%4089)
  %4262 : __torch__.torch.nn.modules.linear.___torch_mangle_14335.Linear = prim::GetAttr[name="dense"](%4089)
  %4263 : Tensor = prim::GetAttr[name="bias"](%4262)
  %4264 : Tensor = prim::GetAttr[name="weight"](%4262)
  %4265 : Float(512:1, 128:512) = aten::t(%4264), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %output.315 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.403, %4265), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %layer_output.21 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.315, %4263, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.168 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.21, %input.401, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output # transformers/modeling_mobilebert.py:405:0
  %4269 : Tensor = prim::GetAttr[name="bias"](%4261)
  %4270 : Tensor = prim::GetAttr[name="weight"](%4261)
  %4271 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.168, %4270), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.404 : Float(119:1664, 13:128, 128:1) = aten::add(%4271, %4269, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4273 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14338.NoNorm = prim::GetAttr[name="LayerNorm"](%4260)
  %4274 : __torch__.torch.nn.modules.linear.___torch_mangle_14337.Linear = prim::GetAttr[name="dense"](%4260)
  %4275 : Tensor = prim::GetAttr[name="bias"](%4274)
  %4276 : Tensor = prim::GetAttr[name="weight"](%4274)
  %4277 : Float(128:1, 512:128) = aten::t(%4276), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.316 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.404, %4277), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.405 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.316, %4275, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.105 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.405, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.169 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.105, %input.387, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4282 : Tensor = prim::GetAttr[name="bias"](%4273)
  %4283 : Tensor = prim::GetAttr[name="weight"](%4273)
  %4284 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.169, %4283), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.406 : Float(119:6656, 13:512, 512:1) = aten::add(%4284, %4282, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4286 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14386.MobileBertOutput = prim::GetAttr[name="output"](%106)
  %4287 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14379.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%106)
  %4288 : __torch__.torch.nn.modules.container.___torch_mangle_14412.ModuleList = prim::GetAttr[name="ffn"](%106)
  %4289 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14411.FFNLayer = prim::GetAttr[name="2"](%4288)
  %4290 : __torch__.torch.nn.modules.container.___torch_mangle_14412.ModuleList = prim::GetAttr[name="ffn"](%106)
  %4291 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14405.FFNLayer = prim::GetAttr[name="1"](%4290)
  %4292 : __torch__.torch.nn.modules.container.___torch_mangle_14412.ModuleList = prim::GetAttr[name="ffn"](%106)
  %4293 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14399.FFNLayer = prim::GetAttr[name="0"](%4292)
  %4294 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14377.MobileBertAttention = prim::GetAttr[name="attention"](%106)
  %4295 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14393.Bottleneck = prim::GetAttr[name="bottleneck"](%106)
  %4296 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14392.BottleneckLayer = prim::GetAttr[name="attention"](%4295)
  %4297 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14389.BottleneckLayer = prim::GetAttr[name="input"](%4295)
  %4298 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14388.NoNorm = prim::GetAttr[name="LayerNorm"](%4297)
  %4299 : __torch__.torch.nn.modules.linear.___torch_mangle_14387.Linear = prim::GetAttr[name="dense"](%4297)
  %4300 : Tensor = prim::GetAttr[name="bias"](%4299)
  %4301 : Tensor = prim::GetAttr[name="weight"](%4299)
  %4302 : Float(512:1, 128:512) = aten::t(%4301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.317 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.406, %4302), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.170 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.317, %4300, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4305 : Tensor = prim::GetAttr[name="bias"](%4298)
  %4306 : Tensor = prim::GetAttr[name="weight"](%4298)
  %4307 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.170, %4306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.22 : Float(119:1664, 13:128, 128:1) = aten::add(%4307, %4305, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14391.NoNorm = prim::GetAttr[name="LayerNorm"](%4296)
  %4310 : __torch__.torch.nn.modules.linear.___torch_mangle_14390.Linear = prim::GetAttr[name="dense"](%4296)
  %4311 : Tensor = prim::GetAttr[name="bias"](%4310)
  %4312 : Tensor = prim::GetAttr[name="weight"](%4310)
  %4313 : Float(512:1, 128:512) = aten::t(%4312), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.318 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.406, %4313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.171 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.318, %4311, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4316 : Tensor = prim::GetAttr[name="bias"](%4309)
  %4317 : Tensor = prim::GetAttr[name="weight"](%4309)
  %4318 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.171, %4317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.407 : Float(119:1664, 13:128, 128:1) = aten::add(%4318, %4316, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4320 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.407, %residual_tensor.22)
  %4321 : Float(119:1664, 13:128, 128:1), %4322 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%4320)
  %4323 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14376.MobileBertSelfOutput = prim::GetAttr[name="output"](%4294)
  %4324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14373.MobileBertSelfAttention = prim::GetAttr[name="self"](%4294)
  %4325 : __torch__.torch.nn.modules.linear.___torch_mangle_14371.Linear = prim::GetAttr[name="value"](%4324)
  %4326 : __torch__.torch.nn.modules.linear.___torch_mangle_14370.Linear = prim::GetAttr[name="key"](%4324)
  %4327 : __torch__.torch.nn.modules.linear.___torch_mangle_14369.Linear = prim::GetAttr[name="query"](%4324)
  %4328 : Tensor = prim::GetAttr[name="bias"](%4327)
  %4329 : Tensor = prim::GetAttr[name="weight"](%4327)
  %4330 : Float(128:1, 128:128) = aten::t(%4329), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %output.319 : Float(119:1664, 13:128, 128:1) = aten::matmul(%4321, %4330), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %x.127 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.319, %4328, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1678:0
  %4333 : Tensor = prim::GetAttr[name="bias"](%4326)
  %4334 : Tensor = prim::GetAttr[name="weight"](%4326)
  %4335 : Float(128:1, 128:128) = aten::t(%4334), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %output.320 : Float(119:1664, 13:128, 128:1) = aten::matmul(%4321, %4335), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %x.129 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.320, %4333, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1678:0
  %4338 : Tensor = prim::GetAttr[name="bias"](%4325)
  %4339 : Tensor = prim::GetAttr[name="weight"](%4325)
  %4340 : Float(512:1, 128:512) = aten::t(%4339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %output.321 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.406, %4340), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %x.131 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.321, %4338, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1678:0
  %4343 : int = aten::size(%x.127, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4344 : int = aten::size(%x.127, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4345 : int[] = prim::ListConstruct(%4343, %4344, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.128 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.127, %4345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4347 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %query_layer.22 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.128, %4347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4349 : int = aten::size(%x.129, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4350 : int = aten::size(%x.129, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4351 : int[] = prim::ListConstruct(%4349, %4350, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.130 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.129, %4351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4353 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %key_layer.22 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.130, %4353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4355 : int = aten::size(%x.131, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4356 : int = aten::size(%x.131, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4357 : int[] = prim::ListConstruct(%4355, %4356, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.132 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.131, %4357), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4359 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %value_layer.22 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.132, %4359), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4361 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.22, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.43 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.22, %4361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.44 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.43, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.408 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.44, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.409 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.408, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.22 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.409, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.43 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.22, %value_layer.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:280:0
  %4368 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %4369 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.43, %4368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.44 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4369, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %4371 : int = aten::size(%context_layer.44, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4372 : int = aten::size(%context_layer.44, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4373 : int[] = prim::ListConstruct(%4371, %4372, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %input.410 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.44, %4373), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:283:0
  %4375 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14375.NoNorm = prim::GetAttr[name="LayerNorm"](%4323)
  %4376 : __torch__.torch.nn.modules.linear.___torch_mangle_14374.Linear = prim::GetAttr[name="dense"](%4323)
  %4377 : Tensor = prim::GetAttr[name="bias"](%4376)
  %4378 : Tensor = prim::GetAttr[name="weight"](%4376)
  %4379 : Float(128:1, 128:128) = aten::t(%4378), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %output.322 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.410, %4379), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.106 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.322, %4377, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.172 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.106, %4322, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output # transformers/modeling_mobilebert.py:301:0
  %4383 : Tensor = prim::GetAttr[name="bias"](%4375)
  %4384 : Tensor = prim::GetAttr[name="weight"](%4375)
  %4385 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.172, %4384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.411 : Float(119:1664, 13:128, 128:1) = aten::add(%4385, %4383, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4387 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14398.FFNOutput = prim::GetAttr[name="output"](%4293)
  %4388 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14395.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4293)
  %4389 : __torch__.torch.nn.modules.linear.___torch_mangle_14394.Linear = prim::GetAttr[name="dense"](%4388)
  %4390 : Tensor = prim::GetAttr[name="bias"](%4389)
  %4391 : Tensor = prim::GetAttr[name="weight"](%4389)
  %4392 : Float(128:1, 512:128) = aten::t(%4391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.323 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.411, %4392), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.412 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.323, %4390, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.413 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4396 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14397.NoNorm = prim::GetAttr[name="LayerNorm"](%4387)
  %4397 : __torch__.torch.nn.modules.linear.___torch_mangle_14396.Linear = prim::GetAttr[name="dense"](%4387)
  %4398 : Tensor = prim::GetAttr[name="bias"](%4397)
  %4399 : Tensor = prim::GetAttr[name="weight"](%4397)
  %4400 : Float(512:1, 128:512) = aten::t(%4399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.324 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.413, %4400), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.107 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.324, %4398, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.173 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.107, %input.411, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4404 : Tensor = prim::GetAttr[name="bias"](%4396)
  %4405 : Tensor = prim::GetAttr[name="weight"](%4396)
  %4406 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.173, %4405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.414 : Float(119:1664, 13:128, 128:1) = aten::add(%4406, %4404, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4408 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14404.FFNOutput = prim::GetAttr[name="output"](%4291)
  %4409 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14401.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4291)
  %4410 : __torch__.torch.nn.modules.linear.___torch_mangle_14400.Linear = prim::GetAttr[name="dense"](%4409)
  %4411 : Tensor = prim::GetAttr[name="bias"](%4410)
  %4412 : Tensor = prim::GetAttr[name="weight"](%4410)
  %4413 : Float(128:1, 512:128) = aten::t(%4412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.325 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.414, %4413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.415 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.325, %4411, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.416 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4417 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14403.NoNorm = prim::GetAttr[name="LayerNorm"](%4408)
  %4418 : __torch__.torch.nn.modules.linear.___torch_mangle_14402.Linear = prim::GetAttr[name="dense"](%4408)
  %4419 : Tensor = prim::GetAttr[name="bias"](%4418)
  %4420 : Tensor = prim::GetAttr[name="weight"](%4418)
  %4421 : Float(512:1, 128:512) = aten::t(%4420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.326 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.416, %4421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.108 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.326, %4419, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.174 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.108, %input.414, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4425 : Tensor = prim::GetAttr[name="bias"](%4417)
  %4426 : Tensor = prim::GetAttr[name="weight"](%4417)
  %4427 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.174, %4426), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.417 : Float(119:1664, 13:128, 128:1) = aten::add(%4427, %4425, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4429 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14410.FFNOutput = prim::GetAttr[name="output"](%4289)
  %4430 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14407.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4289)
  %4431 : __torch__.torch.nn.modules.linear.___torch_mangle_14406.Linear = prim::GetAttr[name="dense"](%4430)
  %4432 : Tensor = prim::GetAttr[name="bias"](%4431)
  %4433 : Tensor = prim::GetAttr[name="weight"](%4431)
  %4434 : Float(128:1, 512:128) = aten::t(%4433), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.327 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.417, %4434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.418 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.327, %4432, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.419 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4438 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14409.NoNorm = prim::GetAttr[name="LayerNorm"](%4429)
  %4439 : __torch__.torch.nn.modules.linear.___torch_mangle_14408.Linear = prim::GetAttr[name="dense"](%4429)
  %4440 : Tensor = prim::GetAttr[name="bias"](%4439)
  %4441 : Tensor = prim::GetAttr[name="weight"](%4439)
  %4442 : Float(512:1, 128:512) = aten::t(%4441), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.328 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.419, %4442), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.109 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.328, %4440, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.175 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.109, %input.417, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4446 : Tensor = prim::GetAttr[name="bias"](%4438)
  %4447 : Tensor = prim::GetAttr[name="weight"](%4438)
  %4448 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.175, %4447), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.420 : Float(119:1664, 13:128, 128:1) = aten::add(%4448, %4446, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4450 : __torch__.torch.nn.modules.linear.___torch_mangle_14378.Linear = prim::GetAttr[name="dense"](%4287)
  %4451 : Tensor = prim::GetAttr[name="bias"](%4450)
  %4452 : Tensor = prim::GetAttr[name="weight"](%4450)
  %4453 : Float(128:1, 512:128) = aten::t(%4452), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %output.329 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.420, %4453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %input.421 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.329, %4451, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1678:0
  %input.422 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate # torch/nn/functional.py:1119:0
  %4457 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14385.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4286)
  %4458 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14381.NoNorm = prim::GetAttr[name="LayerNorm"](%4286)
  %4459 : __torch__.torch.nn.modules.linear.___torch_mangle_14380.Linear = prim::GetAttr[name="dense"](%4286)
  %4460 : Tensor = prim::GetAttr[name="bias"](%4459)
  %4461 : Tensor = prim::GetAttr[name="weight"](%4459)
  %4462 : Float(512:1, 128:512) = aten::t(%4461), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %output.330 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.422, %4462), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %layer_output.22 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.330, %4460, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.176 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.22, %input.420, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output # transformers/modeling_mobilebert.py:405:0
  %4466 : Tensor = prim::GetAttr[name="bias"](%4458)
  %4467 : Tensor = prim::GetAttr[name="weight"](%4458)
  %4468 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.176, %4467), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.423 : Float(119:1664, 13:128, 128:1) = aten::add(%4468, %4466, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4470 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14383.NoNorm = prim::GetAttr[name="LayerNorm"](%4457)
  %4471 : __torch__.torch.nn.modules.linear.___torch_mangle_14382.Linear = prim::GetAttr[name="dense"](%4457)
  %4472 : Tensor = prim::GetAttr[name="bias"](%4471)
  %4473 : Tensor = prim::GetAttr[name="weight"](%4471)
  %4474 : Float(128:1, 512:128) = aten::t(%4473), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.331 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.423, %4474), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.424 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.331, %4472, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.110 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.424, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.177 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.110, %input.406, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4479 : Tensor = prim::GetAttr[name="bias"](%4470)
  %4480 : Tensor = prim::GetAttr[name="weight"](%4470)
  %4481 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.177, %4480), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.425 : Float(119:6656, 13:512, 512:1) = aten::add(%4481, %4479, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4483 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14431.MobileBertOutput = prim::GetAttr[name="output"](%104)
  %4484 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14424.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%104)
  %4485 : __torch__.torch.nn.modules.container.___torch_mangle_14457.ModuleList = prim::GetAttr[name="ffn"](%104)
  %4486 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14456.FFNLayer = prim::GetAttr[name="2"](%4485)
  %4487 : __torch__.torch.nn.modules.container.___torch_mangle_14457.ModuleList = prim::GetAttr[name="ffn"](%104)
  %4488 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14450.FFNLayer = prim::GetAttr[name="1"](%4487)
  %4489 : __torch__.torch.nn.modules.container.___torch_mangle_14457.ModuleList = prim::GetAttr[name="ffn"](%104)
  %4490 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14444.FFNLayer = prim::GetAttr[name="0"](%4489)
  %4491 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14422.MobileBertAttention = prim::GetAttr[name="attention"](%104)
  %4492 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14438.Bottleneck = prim::GetAttr[name="bottleneck"](%104)
  %4493 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14437.BottleneckLayer = prim::GetAttr[name="attention"](%4492)
  %4494 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14434.BottleneckLayer = prim::GetAttr[name="input"](%4492)
  %4495 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14433.NoNorm = prim::GetAttr[name="LayerNorm"](%4494)
  %4496 : __torch__.torch.nn.modules.linear.___torch_mangle_14432.Linear = prim::GetAttr[name="dense"](%4494)
  %4497 : Tensor = prim::GetAttr[name="bias"](%4496)
  %4498 : Tensor = prim::GetAttr[name="weight"](%4496)
  %4499 : Float(512:1, 128:512) = aten::t(%4498), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.332 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.425, %4499), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.178 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.332, %4497, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4502 : Tensor = prim::GetAttr[name="bias"](%4495)
  %4503 : Tensor = prim::GetAttr[name="weight"](%4495)
  %4504 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.178, %4503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.23 : Float(119:1664, 13:128, 128:1) = aten::add(%4504, %4502, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14436.NoNorm = prim::GetAttr[name="LayerNorm"](%4493)
  %4507 : __torch__.torch.nn.modules.linear.___torch_mangle_14435.Linear = prim::GetAttr[name="dense"](%4493)
  %4508 : Tensor = prim::GetAttr[name="bias"](%4507)
  %4509 : Tensor = prim::GetAttr[name="weight"](%4507)
  %4510 : Float(512:1, 128:512) = aten::t(%4509), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.333 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.425, %4510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.179 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.333, %4508, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4513 : Tensor = prim::GetAttr[name="bias"](%4506)
  %4514 : Tensor = prim::GetAttr[name="weight"](%4506)
  %4515 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.179, %4514), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.426 : Float(119:1664, 13:128, 128:1) = aten::add(%4515, %4513, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4517 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.426, %residual_tensor.23)
  %4518 : Float(119:1664, 13:128, 128:1), %4519 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%4517)
  %4520 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14421.MobileBertSelfOutput = prim::GetAttr[name="output"](%4491)
  %4521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14418.MobileBertSelfAttention = prim::GetAttr[name="self"](%4491)
  %4522 : __torch__.torch.nn.modules.linear.___torch_mangle_14416.Linear = prim::GetAttr[name="value"](%4521)
  %4523 : __torch__.torch.nn.modules.linear.___torch_mangle_14415.Linear = prim::GetAttr[name="key"](%4521)
  %4524 : __torch__.torch.nn.modules.linear.___torch_mangle_14414.Linear = prim::GetAttr[name="query"](%4521)
  %4525 : Tensor = prim::GetAttr[name="bias"](%4524)
  %4526 : Tensor = prim::GetAttr[name="weight"](%4524)
  %4527 : Float(128:1, 128:128) = aten::t(%4526), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %output.334 : Float(119:1664, 13:128, 128:1) = aten::matmul(%4518, %4527), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %x.133 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.334, %4525, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1678:0
  %4530 : Tensor = prim::GetAttr[name="bias"](%4523)
  %4531 : Tensor = prim::GetAttr[name="weight"](%4523)
  %4532 : Float(128:1, 128:128) = aten::t(%4531), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %output.335 : Float(119:1664, 13:128, 128:1) = aten::matmul(%4518, %4532), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %x.135 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.335, %4530, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1678:0
  %4535 : Tensor = prim::GetAttr[name="bias"](%4522)
  %4536 : Tensor = prim::GetAttr[name="weight"](%4522)
  %4537 : Float(512:1, 128:512) = aten::t(%4536), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %output.336 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.425, %4537), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %x.137 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.336, %4535, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1678:0
  %4540 : int = aten::size(%x.133, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4541 : int = aten::size(%x.133, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4542 : int[] = prim::ListConstruct(%4540, %4541, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.134 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.133, %4542), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4544 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %query_layer.23 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.134, %4544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4546 : int = aten::size(%x.135, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4547 : int = aten::size(%x.135, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4548 : int[] = prim::ListConstruct(%4546, %4547, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.136 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.135, %4548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4550 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %key_layer.23 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.136, %4550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4552 : int = aten::size(%x.137, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4553 : int = aten::size(%x.137, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4554 : int[] = prim::ListConstruct(%4552, %4553, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.138 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.137, %4554), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4556 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %value_layer.23 : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.138, %4556), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4558 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.23, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.45 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.23, %4558), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.46 : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.45, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.427 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.46, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.428 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.427, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.23 : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.428, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.45 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.23, %value_layer.23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:280:0
  %4565 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %4566 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.45, %4565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.46 : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4566, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %4568 : int = aten::size(%context_layer.46, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4569 : int = aten::size(%context_layer.46, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4570 : int[] = prim::ListConstruct(%4568, %4569, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %input.429 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer.46, %4570), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:283:0
  %4572 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14420.NoNorm = prim::GetAttr[name="LayerNorm"](%4520)
  %4573 : __torch__.torch.nn.modules.linear.___torch_mangle_14419.Linear = prim::GetAttr[name="dense"](%4520)
  %4574 : Tensor = prim::GetAttr[name="bias"](%4573)
  %4575 : Tensor = prim::GetAttr[name="weight"](%4573)
  %4576 : Float(128:1, 128:128) = aten::t(%4575), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %output.337 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.429, %4576), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.111 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.337, %4574, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.180 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.111, %4519, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output # transformers/modeling_mobilebert.py:301:0
  %4580 : Tensor = prim::GetAttr[name="bias"](%4572)
  %4581 : Tensor = prim::GetAttr[name="weight"](%4572)
  %4582 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.180, %4581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.430 : Float(119:1664, 13:128, 128:1) = aten::add(%4582, %4580, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4584 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14443.FFNOutput = prim::GetAttr[name="output"](%4490)
  %4585 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14440.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4490)
  %4586 : __torch__.torch.nn.modules.linear.___torch_mangle_14439.Linear = prim::GetAttr[name="dense"](%4585)
  %4587 : Tensor = prim::GetAttr[name="bias"](%4586)
  %4588 : Tensor = prim::GetAttr[name="weight"](%4586)
  %4589 : Float(128:1, 512:128) = aten::t(%4588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.338 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.430, %4589), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.431 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.338, %4587, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.432 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.431), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4593 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14442.NoNorm = prim::GetAttr[name="LayerNorm"](%4584)
  %4594 : __torch__.torch.nn.modules.linear.___torch_mangle_14441.Linear = prim::GetAttr[name="dense"](%4584)
  %4595 : Tensor = prim::GetAttr[name="bias"](%4594)
  %4596 : Tensor = prim::GetAttr[name="weight"](%4594)
  %4597 : Float(512:1, 128:512) = aten::t(%4596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.339 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.432, %4597), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.112 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.339, %4595, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.181 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.112, %input.430, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4601 : Tensor = prim::GetAttr[name="bias"](%4593)
  %4602 : Tensor = prim::GetAttr[name="weight"](%4593)
  %4603 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.181, %4602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.433 : Float(119:1664, 13:128, 128:1) = aten::add(%4603, %4601, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4605 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14449.FFNOutput = prim::GetAttr[name="output"](%4488)
  %4606 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14446.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4488)
  %4607 : __torch__.torch.nn.modules.linear.___torch_mangle_14445.Linear = prim::GetAttr[name="dense"](%4606)
  %4608 : Tensor = prim::GetAttr[name="bias"](%4607)
  %4609 : Tensor = prim::GetAttr[name="weight"](%4607)
  %4610 : Float(128:1, 512:128) = aten::t(%4609), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.340 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.433, %4610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.434 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.340, %4608, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.435 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4614 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14448.NoNorm = prim::GetAttr[name="LayerNorm"](%4605)
  %4615 : __torch__.torch.nn.modules.linear.___torch_mangle_14447.Linear = prim::GetAttr[name="dense"](%4605)
  %4616 : Tensor = prim::GetAttr[name="bias"](%4615)
  %4617 : Tensor = prim::GetAttr[name="weight"](%4615)
  %4618 : Float(512:1, 128:512) = aten::t(%4617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.341 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.435, %4618), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.113 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.341, %4616, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.182 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.113, %input.433, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4622 : Tensor = prim::GetAttr[name="bias"](%4614)
  %4623 : Tensor = prim::GetAttr[name="weight"](%4614)
  %4624 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.182, %4623), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.436 : Float(119:1664, 13:128, 128:1) = aten::add(%4624, %4622, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4626 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14455.FFNOutput = prim::GetAttr[name="output"](%4486)
  %4627 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14452.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4486)
  %4628 : __torch__.torch.nn.modules.linear.___torch_mangle_14451.Linear = prim::GetAttr[name="dense"](%4627)
  %4629 : Tensor = prim::GetAttr[name="bias"](%4628)
  %4630 : Tensor = prim::GetAttr[name="weight"](%4628)
  %4631 : Float(128:1, 512:128) = aten::t(%4630), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.342 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.436, %4631), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.437 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.342, %4629, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.438 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4635 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14454.NoNorm = prim::GetAttr[name="LayerNorm"](%4626)
  %4636 : __torch__.torch.nn.modules.linear.___torch_mangle_14453.Linear = prim::GetAttr[name="dense"](%4626)
  %4637 : Tensor = prim::GetAttr[name="bias"](%4636)
  %4638 : Tensor = prim::GetAttr[name="weight"](%4636)
  %4639 : Float(512:1, 128:512) = aten::t(%4638), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.343 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.438, %4639), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.114 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.343, %4637, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.183 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.114, %input.436, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4643 : Tensor = prim::GetAttr[name="bias"](%4635)
  %4644 : Tensor = prim::GetAttr[name="weight"](%4635)
  %4645 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.183, %4644), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.439 : Float(119:1664, 13:128, 128:1) = aten::add(%4645, %4643, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4647 : __torch__.torch.nn.modules.linear.___torch_mangle_14423.Linear = prim::GetAttr[name="dense"](%4484)
  %4648 : Tensor = prim::GetAttr[name="bias"](%4647)
  %4649 : Tensor = prim::GetAttr[name="weight"](%4647)
  %4650 : Float(128:1, 512:128) = aten::t(%4649), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %output.344 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.439, %4650), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %input.440 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.344, %4648, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1678:0
  %input.441 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate # torch/nn/functional.py:1119:0
  %4654 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14430.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4483)
  %4655 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14426.NoNorm = prim::GetAttr[name="LayerNorm"](%4483)
  %4656 : __torch__.torch.nn.modules.linear.___torch_mangle_14425.Linear = prim::GetAttr[name="dense"](%4483)
  %4657 : Tensor = prim::GetAttr[name="bias"](%4656)
  %4658 : Tensor = prim::GetAttr[name="weight"](%4656)
  %4659 : Float(512:1, 128:512) = aten::t(%4658), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %output.345 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.441, %4659), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %layer_output.23 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.345, %4657, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.184 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output.23, %input.439, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output # transformers/modeling_mobilebert.py:405:0
  %4663 : Tensor = prim::GetAttr[name="bias"](%4655)
  %4664 : Tensor = prim::GetAttr[name="weight"](%4655)
  %4665 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.184, %4664), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.442 : Float(119:1664, 13:128, 128:1) = aten::add(%4665, %4663, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4667 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14428.NoNorm = prim::GetAttr[name="LayerNorm"](%4654)
  %4668 : __torch__.torch.nn.modules.linear.___torch_mangle_14427.Linear = prim::GetAttr[name="dense"](%4654)
  %4669 : Tensor = prim::GetAttr[name="bias"](%4668)
  %4670 : Tensor = prim::GetAttr[name="weight"](%4668)
  %4671 : Float(128:1, 512:128) = aten::t(%4670), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.346 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.442, %4671), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.443 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.346, %4669, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.115 : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.443, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.185 : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs.115, %input.425, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4676 : Tensor = prim::GetAttr[name="bias"](%4667)
  %4677 : Tensor = prim::GetAttr[name="weight"](%4667)
  %4678 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor.185, %4677), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.444 : Float(119:6656, 13:512, 512:1) = aten::add(%4678, %4676, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4680 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14476.MobileBertOutput = prim::GetAttr[name="output"](%102)
  %4681 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14469.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%102)
  %4682 : __torch__.torch.nn.modules.container.___torch_mangle_14502.ModuleList = prim::GetAttr[name="ffn"](%102)
  %4683 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14501.FFNLayer = prim::GetAttr[name="2"](%4682)
  %4684 : __torch__.torch.nn.modules.container.___torch_mangle_14502.ModuleList = prim::GetAttr[name="ffn"](%102)
  %4685 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14495.FFNLayer = prim::GetAttr[name="1"](%4684)
  %4686 : __torch__.torch.nn.modules.container.___torch_mangle_14502.ModuleList = prim::GetAttr[name="ffn"](%102)
  %4687 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14489.FFNLayer = prim::GetAttr[name="0"](%4686)
  %4688 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14467.MobileBertAttention = prim::GetAttr[name="attention"](%102)
  %4689 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14483.Bottleneck = prim::GetAttr[name="bottleneck"](%102)
  %4690 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14482.BottleneckLayer = prim::GetAttr[name="attention"](%4689)
  %4691 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14479.BottleneckLayer = prim::GetAttr[name="input"](%4689)
  %4692 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14478.NoNorm = prim::GetAttr[name="LayerNorm"](%4691)
  %4693 : __torch__.torch.nn.modules.linear.___torch_mangle_14477.Linear = prim::GetAttr[name="dense"](%4691)
  %4694 : Tensor = prim::GetAttr[name="bias"](%4693)
  %4695 : Tensor = prim::GetAttr[name="weight"](%4693)
  %4696 : Float(512:1, 128:512) = aten::t(%4695), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.347 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.444, %4696), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.186 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.347, %4694, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4699 : Tensor = prim::GetAttr[name="bias"](%4692)
  %4700 : Tensor = prim::GetAttr[name="weight"](%4692)
  %4701 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.186, %4700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor : Float(119:1664, 13:128, 128:1) = aten::add(%4701, %4699, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14481.NoNorm = prim::GetAttr[name="LayerNorm"](%4690)
  %4704 : __torch__.torch.nn.modules.linear.___torch_mangle_14480.Linear = prim::GetAttr[name="dense"](%4690)
  %4705 : Tensor = prim::GetAttr[name="bias"](%4704)
  %4706 : Tensor = prim::GetAttr[name="weight"](%4704)
  %4707 : Float(512:1, 128:512) = aten::t(%4706), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.348 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.444, %4707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.187 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.348, %4705, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4710 : Tensor = prim::GetAttr[name="bias"](%4703)
  %4711 : Tensor = prim::GetAttr[name="weight"](%4703)
  %4712 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.187, %4711), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.445 : Float(119:1664, 13:128, 128:1) = aten::add(%4712, %4710, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4714 : (Float(119:1664, 13:128, 128:1), Float(119:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.445, %residual_tensor)
  %4715 : Float(119:1664, 13:128, 128:1), %4716 : Float(119:1664, 13:128, 128:1) = prim::TupleUnpack(%4714)
  %4717 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14466.MobileBertSelfOutput = prim::GetAttr[name="output"](%4688)
  %4718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14463.MobileBertSelfAttention = prim::GetAttr[name="self"](%4688)
  %4719 : __torch__.torch.nn.modules.linear.___torch_mangle_14461.Linear = prim::GetAttr[name="value"](%4718)
  %4720 : __torch__.torch.nn.modules.linear.___torch_mangle_14460.Linear = prim::GetAttr[name="key"](%4718)
  %4721 : __torch__.torch.nn.modules.linear.___torch_mangle_14459.Linear = prim::GetAttr[name="query"](%4718)
  %4722 : Tensor = prim::GetAttr[name="bias"](%4721)
  %4723 : Tensor = prim::GetAttr[name="weight"](%4721)
  %4724 : Float(128:1, 128:128) = aten::t(%4723), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %output.349 : Float(119:1664, 13:128, 128:1) = aten::matmul(%4715, %4724), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %x.139 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.349, %4722, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1678:0
  %4727 : Tensor = prim::GetAttr[name="bias"](%4720)
  %4728 : Tensor = prim::GetAttr[name="weight"](%4720)
  %4729 : Float(128:1, 128:128) = aten::t(%4728), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %output.350 : Float(119:1664, 13:128, 128:1) = aten::matmul(%4715, %4729), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %x.141 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.350, %4727, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1678:0
  %4732 : Tensor = prim::GetAttr[name="bias"](%4719)
  %4733 : Tensor = prim::GetAttr[name="weight"](%4719)
  %4734 : Float(512:1, 128:512) = aten::t(%4733), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %output.351 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.444, %4734), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %x.143 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.351, %4732, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1678:0
  %4737 : int = aten::size(%x.139, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4738 : int = aten::size(%x.139, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4739 : int[] = prim::ListConstruct(%4737, %4738, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.140 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.139, %4739), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4741 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %query_layer : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.140, %4741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4743 : int = aten::size(%x.141, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4744 : int = aten::size(%x.141, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4745 : int[] = prim::ListConstruct(%4743, %4744, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.142 : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.141, %4745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4747 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %key_layer : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x.142, %4747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4749 : int = aten::size(%x.143, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4750 : int = aten::size(%x.143, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4751 : int[] = prim::ListConstruct(%4749, %4750, %47, %35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x : Float(119:1664, 13:128, 4:32, 32:1) = aten::view(%x.143, %4751), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4753 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %value_layer : Float(119:1664, 4:32, 13:128, 32:1) = aten::permute(%x, %4753), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4755 : Float(119:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer, %36, %34), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.47 : Float(119:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer, %4755), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores : Float(119:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.47, %33), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.446 : Float(119:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores, %attention_mask, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.447 : Float(119:676, 4:169, 13:13, 13:1) = aten::softmax(%input.446, %36, %40), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # torch/nn/functional.py:1498:0
  %attention_probs : Float(119:676, 4:169, 13:13, 13:1) = aten::dropout(%input.447, %32, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.47 : Float(119:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:280:0
  %4762 : int[] = prim::ListConstruct(%49, %43, %48, %42), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %4763 : Float(119:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.47, %4762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer : Float(119:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4763, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %4765 : int = aten::size(%context_layer, %49), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4766 : int = aten::size(%context_layer, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4767 : int[] = prim::ListConstruct(%4765, %4766, %31), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %input.448 : Float(119:1664, 13:128, 128:1) = aten::view(%context_layer, %4767), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:283:0
  %4769 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14465.NoNorm = prim::GetAttr[name="LayerNorm"](%4717)
  %4770 : __torch__.torch.nn.modules.linear.___torch_mangle_14464.Linear = prim::GetAttr[name="dense"](%4717)
  %4771 : Tensor = prim::GetAttr[name="bias"](%4770)
  %4772 : Tensor = prim::GetAttr[name="weight"](%4770)
  %4773 : Float(128:1, 128:128) = aten::t(%4772), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %output.352 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.448, %4773), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.116 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.352, %4771, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.188 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.116, %4716, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output # transformers/modeling_mobilebert.py:301:0
  %4777 : Tensor = prim::GetAttr[name="bias"](%4769)
  %4778 : Tensor = prim::GetAttr[name="weight"](%4769)
  %4779 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.188, %4778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.449 : Float(119:1664, 13:128, 128:1) = aten::add(%4779, %4777, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4781 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14488.FFNOutput = prim::GetAttr[name="output"](%4687)
  %4782 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14485.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4687)
  %4783 : __torch__.torch.nn.modules.linear.___torch_mangle_14484.Linear = prim::GetAttr[name="dense"](%4782)
  %4784 : Tensor = prim::GetAttr[name="bias"](%4783)
  %4785 : Tensor = prim::GetAttr[name="weight"](%4783)
  %4786 : Float(128:1, 512:128) = aten::t(%4785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.353 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.449, %4786), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.450 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.353, %4784, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.451 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4790 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14487.NoNorm = prim::GetAttr[name="LayerNorm"](%4781)
  %4791 : __torch__.torch.nn.modules.linear.___torch_mangle_14486.Linear = prim::GetAttr[name="dense"](%4781)
  %4792 : Tensor = prim::GetAttr[name="bias"](%4791)
  %4793 : Tensor = prim::GetAttr[name="weight"](%4791)
  %4794 : Float(512:1, 128:512) = aten::t(%4793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.354 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.451, %4794), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.117 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.354, %4792, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.189 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.117, %input.449, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4798 : Tensor = prim::GetAttr[name="bias"](%4790)
  %4799 : Tensor = prim::GetAttr[name="weight"](%4790)
  %4800 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.189, %4799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.452 : Float(119:1664, 13:128, 128:1) = aten::add(%4800, %4798, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4802 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14494.FFNOutput = prim::GetAttr[name="output"](%4685)
  %4803 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14491.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4685)
  %4804 : __torch__.torch.nn.modules.linear.___torch_mangle_14490.Linear = prim::GetAttr[name="dense"](%4803)
  %4805 : Tensor = prim::GetAttr[name="bias"](%4804)
  %4806 : Tensor = prim::GetAttr[name="weight"](%4804)
  %4807 : Float(128:1, 512:128) = aten::t(%4806), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.355 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.452, %4807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.453 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.355, %4805, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.454 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4811 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14493.NoNorm = prim::GetAttr[name="LayerNorm"](%4802)
  %4812 : __torch__.torch.nn.modules.linear.___torch_mangle_14492.Linear = prim::GetAttr[name="dense"](%4802)
  %4813 : Tensor = prim::GetAttr[name="bias"](%4812)
  %4814 : Tensor = prim::GetAttr[name="weight"](%4812)
  %4815 : Float(512:1, 128:512) = aten::t(%4814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.356 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.454, %4815), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.118 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.356, %4813, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.190 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.118, %input.452, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4819 : Tensor = prim::GetAttr[name="bias"](%4811)
  %4820 : Tensor = prim::GetAttr[name="weight"](%4811)
  %4821 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.190, %4820), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.455 : Float(119:1664, 13:128, 128:1) = aten::add(%4821, %4819, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4823 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14500.FFNOutput = prim::GetAttr[name="output"](%4683)
  %4824 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14497.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4683)
  %4825 : __torch__.torch.nn.modules.linear.___torch_mangle_14496.Linear = prim::GetAttr[name="dense"](%4824)
  %4826 : Tensor = prim::GetAttr[name="bias"](%4825)
  %4827 : Tensor = prim::GetAttr[name="weight"](%4825)
  %4828 : Float(128:1, 512:128) = aten::t(%4827), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.357 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.455, %4828), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.456 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.357, %4826, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.457 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4832 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14499.NoNorm = prim::GetAttr[name="LayerNorm"](%4823)
  %4833 : __torch__.torch.nn.modules.linear.___torch_mangle_14498.Linear = prim::GetAttr[name="dense"](%4823)
  %4834 : Tensor = prim::GetAttr[name="bias"](%4833)
  %4835 : Tensor = prim::GetAttr[name="weight"](%4833)
  %4836 : Float(512:1, 128:512) = aten::t(%4835), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.358 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.457, %4836), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.119 : Float(119:1664, 13:128, 128:1) = aten::add_(%output.358, %4834, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.191 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_outputs.119, %input.455, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4840 : Tensor = prim::GetAttr[name="bias"](%4832)
  %4841 : Tensor = prim::GetAttr[name="weight"](%4832)
  %4842 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.191, %4841), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.458 : Float(119:1664, 13:128, 128:1) = aten::add(%4842, %4840, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4844 : __torch__.torch.nn.modules.linear.___torch_mangle_14468.Linear = prim::GetAttr[name="dense"](%4681)
  %4845 : Tensor = prim::GetAttr[name="bias"](%4844)
  %4846 : Tensor = prim::GetAttr[name="weight"](%4844)
  %4847 : Float(128:1, 512:128) = aten::t(%4846), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %output.359 : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.458, %4847), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %input.459 : Float(119:6656, 13:512, 512:1) = aten::add_(%output.359, %4845, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1678:0
  %input.460 : Float(119:6656, 13:512, 512:1) = aten::relu(%input.459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate # torch/nn/functional.py:1119:0
  %4851 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14475.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4680)
  %4852 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14471.NoNorm = prim::GetAttr[name="LayerNorm"](%4680)
  %4853 : __torch__.torch.nn.modules.linear.___torch_mangle_14470.Linear = prim::GetAttr[name="dense"](%4680)
  %4854 : Tensor = prim::GetAttr[name="bias"](%4853)
  %4855 : Tensor = prim::GetAttr[name="weight"](%4853)
  %4856 : Float(512:1, 128:512) = aten::t(%4855), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %output.360 : Float(119:1664, 13:128, 128:1) = aten::matmul(%input.460, %4856), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %layer_output : Float(119:1664, 13:128, 128:1) = aten::add_(%output.360, %4854, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.192 : Float(119:1664, 13:128, 128:1) = aten::add(%layer_output, %input.458, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output # transformers/modeling_mobilebert.py:405:0
  %4860 : Tensor = prim::GetAttr[name="bias"](%4852)
  %4861 : Tensor = prim::GetAttr[name="weight"](%4852)
  %4862 : Float(119:1664, 13:128, 128:1) = aten::mul(%input_tensor.192, %4861), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.461 : Float(119:1664, 13:128, 128:1) = aten::add(%4862, %4860, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4864 : __torch__.transformers.modeling_mobilebert.___torch_mangle_14473.NoNorm = prim::GetAttr[name="LayerNorm"](%4851)
  %4865 : __torch__.torch.nn.modules.linear.___torch_mangle_14472.Linear = prim::GetAttr[name="dense"](%4851)
  %4866 : Tensor = prim::GetAttr[name="bias"](%4865)
  %4867 : Tensor = prim::GetAttr[name="weight"](%4865)
  %4868 : Float(128:1, 512:128) = aten::t(%4867), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output : Float(119:6656, 13:512, 512:1) = aten::matmul(%input.461, %4868), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.462 : Float(119:6656, 13:512, 512:1) = aten::add_(%output, %4866, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs : Float(119:6656, 13:512, 512:1) = aten::dropout(%input.462, %37, %45), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor : Float(119:6656, 13:512, 512:1) = aten::add(%layer_outputs, %input.444, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4873 : Tensor = prim::GetAttr[name="bias"](%4864)
  %4874 : Tensor = prim::GetAttr[name="weight"](%4864)
  %4875 : Float(119:6656, 13:512, 512:1) = aten::mul(%input_tensor, %4874), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %hidden_states : Float(119:6656, 13:512, 512:1) = aten::add(%4875, %4873, %48), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4877 : __torch__.torch.nn.modules.linear.___torch_mangle_14506.Linear = prim::GetAttr[name="dense"](%50)
  %4878 : Float(119:6656, 13:512, 512:1) = aten::slice(%hidden_states, %49, %49, %44, %48), scope: __module.mobilebert/__module.mobilebert.pooler # transformers/modeling_mobilebert.py:603:0
  %input.463 : Float(119:6656, 512:1) = aten::select(%4878, %48, %49), scope: __module.mobilebert/__module.mobilebert.pooler # transformers/modeling_mobilebert.py:603:0
  %4880 : Tensor = prim::GetAttr[name="bias"](%4877)
  %4881 : Tensor = prim::GetAttr[name="weight"](%4877)
  %4882 : Float(512:1, 512:512) = aten::t(%4881), scope: __module.mobilebert/__module.mobilebert.pooler/__module.mobilebert.pooler.dense # torch/nn/functional.py:1674:0
  %pooled_output : Float(119:512, 512:1) = aten::addmm(%4880, %input.463, %4882, %48, %48), scope: __module.mobilebert/__module.mobilebert.pooler/__module.mobilebert.pooler.dense # torch/nn/functional.py:1674:0
  %input.464 : Float(119:512, 512:1) = aten::tanh(%pooled_output), scope: __module.mobilebert/__module.mobilebert.pooler # transformers/modeling_mobilebert.py:608:0
  %4885 : bool = prim::Constant[value=0](), scope: __module.dropout # torch/nn/functional.py:973:0
  %4886 : float = prim::Constant[value=0.](), scope: __module.dropout # torch/nn/functional.py:973:0
  %input : Float(119:512, 512:1) = aten::dropout(%input.464, %4886, %4885), scope: __module.dropout # torch/nn/functional.py:973:0
  %4888 : int = prim::Constant[value=1](), scope: __module.classifier # torch/nn/functional.py:1674:0
  %4889 : Tensor = prim::GetAttr[name="bias"](%3)
  %4890 : Tensor = prim::GetAttr[name="weight"](%3)
  %4891 : Float(512:1, 1:512) = aten::t(%4890), scope: __module.classifier # torch/nn/functional.py:1674:0
  %logits : Float(119:1, 1:1) = aten::addmm(%4889, %input, %4891, %4888, %4888), scope: __module.classifier # torch/nn/functional.py:1674:0
  %27 : int = prim::Constant[value=-1]() # transformers/modeling_mobilebert.py:1516:0
  %28 : int[] = prim::ListConstruct(%27, %9)
  %29 : Float(17:7, 7:1) = aten::view(%logits, %28) # transformers/modeling_mobilebert.py:1516:0
  %30 : (Float(17:7, 7:1)) = prim::TupleConstruct(%29)
  return (%30)
