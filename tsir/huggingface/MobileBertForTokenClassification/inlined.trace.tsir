graph(%self.1 : __torch__.transformers.modeling_mobilebert.MobileBertForTokenClassification,
      %input_ids : Long(17:13, 13:1),
      %attention_mask.1 : Long(17:13, 13:1)):
  %3 : __torch__.torch.nn.modules.linear.___torch_mangle_25456.Linear = prim::GetAttr[name="classifier"](%self.1)
  %4 : __torch__.torch.nn.modules.dropout.___torch_mangle_25455.Dropout = prim::GetAttr[name="dropout"](%self.1)
  %5 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25454.MobileBertModel = prim::GetAttr[name="mobilebert"](%self.1)
  %10 : int = prim::Constant[value=128](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %11 : float = prim::Constant[value=0.10000000000000001](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %12 : Double() = prim::Constant[value={5.65685}](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %13 : int = prim::Constant[value=-2](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %14 : int = prim::Constant[value=32](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %15 : int = prim::Constant[value=-1](), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %16 : float = prim::Constant[value=0.](), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %17 : Double() = prim::Constant[value={-10000}](), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %18 : float = prim::Constant[value=1.](), scope: __module.mobilebert # torch/tensor.py:396:0
  %19 : None = prim::Constant(), scope: __module.mobilebert
  %20 : int = prim::Constant[value=6](), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %21 : int = prim::Constant[value=3](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %22 : int = prim::Constant[value=2](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %23 : int = prim::Constant[value=9223372036854775807](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %24 : bool = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %25 : Device = prim::Constant[value="cpu"](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %26 : int = prim::Constant[value=4](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %27 : int = prim::Constant[value=1](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %28 : int = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %29 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25453.MobileBertEncoder = prim::GetAttr[name="encoder"](%5)
  %30 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24371.MobileBertEmbeddings = prim::GetAttr[name="embeddings"](%5)
  %31 : int = aten::size(%input_ids, %28), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %32 : int = aten::size(%input_ids, %27), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %33 : int[] = prim::ListConstruct(%31, %32), scope: __module.mobilebert
  %input.5 : Long(17:13, 13:1) = aten::zeros(%33, %26, %28, %25, %24), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %35 : Long(17:13, 13:1) = aten::slice(%attention_mask.1, %28, %28, %23, %27), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %36 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%35, %27), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %37 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%36, %22), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %extended_attention_mask : Long(17:13, 1:13, 1:13, 13:1) = aten::slice(%37, %21, %28, %23, %27), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %39 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%extended_attention_mask, %20, %24, %24, %19), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %40 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%39, %18, %27), scope: __module.mobilebert # torch/tensor.py:396:0
  %attention_mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%40, %17), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %42 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24369.NoNorm = prim::GetAttr[name="LayerNorm"](%30)
  %43 : __torch__.torch.nn.modules.sparse.___torch_mangle_24367.Embedding = prim::GetAttr[name="token_type_embeddings"](%30)
  %44 : __torch__.torch.nn.modules.sparse.___torch_mangle_24366.Embedding = prim::GetAttr[name="position_embeddings"](%30)
  %45 : __torch__.torch.nn.modules.linear.___torch_mangle_24368.Linear = prim::GetAttr[name="embedding_transformation"](%30)
  %46 : __torch__.torch.nn.modules.sparse.___torch_mangle_24365.Embedding = prim::GetAttr[name="word_embeddings"](%30)
  %47 : Tensor = prim::GetAttr[name="position_ids"](%30)
  %48 : int = aten::size(%input_ids, %27), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:185:0
  %49 : Long(1:512, 512:1) = aten::slice(%47, %28, %28, %23, %27), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %input.4 : Long(1:512, 13:1) = aten::slice(%49, %27, %28, %48, %27), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %51 : Tensor = prim::GetAttr[name="weight"](%46)
  %inputs_embeds.1 : Float(17:1664, 13:128, 128:1) = aten::embedding(%51, %input_ids, %28, %24, %24), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %53 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %28, %28, %23, %27), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %input.1 : Float(17:1664, 12:128, 128:1) = aten::slice(%53, %27, %27, %23, %27), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %55 : int[] = prim::ListConstruct(%28, %28, %28, %27, %28, %28), scope: __module.mobilebert/__module.mobilebert.embeddings
  %56 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.1, %55, %28), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %57 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %28, %28, %23, %27), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %input.2 : Float(17:1664, 12:128, 128:1) = aten::slice(%57, %27, %28, %15, %27), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %59 : int[] = prim::ListConstruct(%28, %28, %27, %28, %28, %28), scope: __module.mobilebert/__module.mobilebert.embeddings
  %60 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.2, %59, %28), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %61 : Tensor[] = prim::ListConstruct(%56, %inputs_embeds.1, %60), scope: __module.mobilebert/__module.mobilebert.embeddings
  %input.3 : Float(17:4992, 13:384, 384:1) = aten::cat(%61, %22), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:207:0
  %63 : Tensor = prim::GetAttr[name="bias"](%45)
  %64 : Tensor = prim::GetAttr[name="weight"](%45)
  %65 : Float(384:1, 512:384) = aten::t(%64), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %output.1 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.3, %65), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %inputs_embeds : Float(17:6656, 13:512, 512:1) = aten::add_(%output.1, %63, %27), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1678:0
  %68 : Tensor = prim::GetAttr[name="weight"](%44)
  %position_embeddings : Float(1:6656, 13:512, 512:1) = aten::embedding(%68, %input.4, %15, %24, %24), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %70 : Tensor = prim::GetAttr[name="weight"](%43)
  %token_type_embeddings : Float(17:6656, 13:512, 512:1) = aten::embedding(%70, %input.5, %15, %24, %24), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %72 : Float(17:6656, 13:512, 512:1) = aten::add(%inputs_embeds, %position_embeddings, %27), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %input_tensor.1 : Float(17:6656, 13:512, 512:1) = aten::add(%72, %token_type_embeddings, %27), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %74 : Tensor = prim::GetAttr[name="bias"](%42)
  %75 : Tensor = prim::GetAttr[name="weight"](%42)
  %76 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.1, %75), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.6 : Float(17:6656, 13:512, 512:1) = aten::add(%76, %74, %27), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.7 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.6, %16, %24), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %79 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %80 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25451.MobileBertLayer = prim::GetAttr[name="23"](%79)
  %81 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %82 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25406.MobileBertLayer = prim::GetAttr[name="22"](%81)
  %83 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %84 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25361.MobileBertLayer = prim::GetAttr[name="21"](%83)
  %85 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %86 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25316.MobileBertLayer = prim::GetAttr[name="20"](%85)
  %87 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %88 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25271.MobileBertLayer = prim::GetAttr[name="19"](%87)
  %89 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %90 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25226.MobileBertLayer = prim::GetAttr[name="18"](%89)
  %91 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %92 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25181.MobileBertLayer = prim::GetAttr[name="17"](%91)
  %93 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %94 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25136.MobileBertLayer = prim::GetAttr[name="16"](%93)
  %95 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %96 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25091.MobileBertLayer = prim::GetAttr[name="15"](%95)
  %97 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %98 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25046.MobileBertLayer = prim::GetAttr[name="14"](%97)
  %99 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %100 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25001.MobileBertLayer = prim::GetAttr[name="13"](%99)
  %101 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %102 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24956.MobileBertLayer = prim::GetAttr[name="12"](%101)
  %103 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24911.MobileBertLayer = prim::GetAttr[name="11"](%103)
  %105 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %106 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24866.MobileBertLayer = prim::GetAttr[name="10"](%105)
  %107 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %108 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24821.MobileBertLayer = prim::GetAttr[name="9"](%107)
  %109 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %110 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24776.MobileBertLayer = prim::GetAttr[name="8"](%109)
  %111 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24731.MobileBertLayer = prim::GetAttr[name="7"](%111)
  %113 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %114 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24686.MobileBertLayer = prim::GetAttr[name="6"](%113)
  %115 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %116 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24641.MobileBertLayer = prim::GetAttr[name="5"](%115)
  %117 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24596.MobileBertLayer = prim::GetAttr[name="4"](%117)
  %119 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24551.MobileBertLayer = prim::GetAttr[name="3"](%119)
  %121 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24506.MobileBertLayer = prim::GetAttr[name="2"](%121)
  %123 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %124 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24461.MobileBertLayer = prim::GetAttr[name="1"](%123)
  %125 : __torch__.torch.nn.modules.container.___torch_mangle_25452.ModuleList = prim::GetAttr[name="layer"](%29)
  %126 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24416.MobileBertLayer = prim::GetAttr[name="0"](%125)
  %127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24389.MobileBertOutput = prim::GetAttr[name="output"](%126)
  %128 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24382.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%126)
  %129 : __torch__.torch.nn.modules.container.___torch_mangle_24415.ModuleList = prim::GetAttr[name="ffn"](%126)
  %130 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24414.FFNLayer = prim::GetAttr[name="2"](%129)
  %131 : __torch__.torch.nn.modules.container.___torch_mangle_24415.ModuleList = prim::GetAttr[name="ffn"](%126)
  %132 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24408.FFNLayer = prim::GetAttr[name="1"](%131)
  %133 : __torch__.torch.nn.modules.container.___torch_mangle_24415.ModuleList = prim::GetAttr[name="ffn"](%126)
  %134 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24402.FFNLayer = prim::GetAttr[name="0"](%133)
  %135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24380.MobileBertAttention = prim::GetAttr[name="attention"](%126)
  %136 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24396.Bottleneck = prim::GetAttr[name="bottleneck"](%126)
  %137 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24395.BottleneckLayer = prim::GetAttr[name="attention"](%136)
  %138 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24392.BottleneckLayer = prim::GetAttr[name="input"](%136)
  %139 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24391.NoNorm = prim::GetAttr[name="LayerNorm"](%138)
  %140 : __torch__.torch.nn.modules.linear.___torch_mangle_24390.Linear = prim::GetAttr[name="dense"](%138)
  %141 : Tensor = prim::GetAttr[name="bias"](%140)
  %142 : Tensor = prim::GetAttr[name="weight"](%140)
  %143 : Float(512:1, 128:512) = aten::t(%142), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.2 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %143), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.2, %141, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %146 : Tensor = prim::GetAttr[name="bias"](%139)
  %147 : Tensor = prim::GetAttr[name="weight"](%139)
  %148 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.2, %147), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.1 : Float(17:1664, 13:128, 128:1) = aten::add(%148, %146, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %150 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24394.NoNorm = prim::GetAttr[name="LayerNorm"](%137)
  %151 : __torch__.torch.nn.modules.linear.___torch_mangle_24393.Linear = prim::GetAttr[name="dense"](%137)
  %152 : Tensor = prim::GetAttr[name="bias"](%151)
  %153 : Tensor = prim::GetAttr[name="weight"](%151)
  %154 : Float(512:1, 128:512) = aten::t(%153), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.3 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.3, %152, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %157 : Tensor = prim::GetAttr[name="bias"](%150)
  %158 : Tensor = prim::GetAttr[name="weight"](%150)
  %159 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.3, %158), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.8 : Float(17:1664, 13:128, 128:1) = aten::add(%159, %157, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %161 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.8, %residual_tensor.1)
  %162 : Float(17:1664, 13:128, 128:1), %163 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%161)
  %164 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24379.MobileBertSelfOutput = prim::GetAttr[name="output"](%135)
  %165 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24376.MobileBertSelfAttention = prim::GetAttr[name="self"](%135)
  %166 : __torch__.torch.nn.modules.linear.___torch_mangle_24374.Linear = prim::GetAttr[name="value"](%165)
  %167 : __torch__.torch.nn.modules.linear.___torch_mangle_24373.Linear = prim::GetAttr[name="key"](%165)
  %168 : __torch__.torch.nn.modules.linear.___torch_mangle_24372.Linear = prim::GetAttr[name="query"](%165)
  %169 : Tensor = prim::GetAttr[name="bias"](%168)
  %170 : Tensor = prim::GetAttr[name="weight"](%168)
  %171 : Float(128:1, 128:128) = aten::t(%170), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %output.4 : Float(17:1664, 13:128, 128:1) = aten::matmul(%162, %171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %x.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.4, %169, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %174 : Tensor = prim::GetAttr[name="bias"](%167)
  %175 : Tensor = prim::GetAttr[name="weight"](%167)
  %176 : Float(128:1, 128:128) = aten::t(%175), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %output.5 : Float(17:1664, 13:128, 128:1) = aten::matmul(%162, %176), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %x.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.5, %174, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1678:0
  %179 : Tensor = prim::GetAttr[name="bias"](%166)
  %180 : Tensor = prim::GetAttr[name="weight"](%166)
  %181 : Float(512:1, 128:512) = aten::t(%180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %output.6 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %181), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %x.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.6, %179, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1678:0
  %184 : int = aten::size(%x.1, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %185 : int = aten::size(%x.1, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %186 : int[] = prim::ListConstruct(%184, %185, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.1, %186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %188 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %query_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.2, %188), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %190 : int = aten::size(%x.3, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %191 : int = aten::size(%x.3, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %192 : int[] = prim::ListConstruct(%190, %191, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.3, %192), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %194 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %key_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.4, %194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %196 : int = aten::size(%x.5, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %197 : int = aten::size(%x.5, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %198 : int[] = prim::ListConstruct(%196, %197, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.5, %198), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %200 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %value_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.6, %200), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %202 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.1, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.1, %202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.1, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.2, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.9, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.10, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.1 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:280:0
  %209 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %210 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.1, %209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%210, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %212 : int = aten::size(%context_layer.2, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %213 : int = aten::size(%context_layer.2, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %214 : int[] = prim::ListConstruct(%212, %213, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %input.11 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.2, %214), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %216 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24378.NoNorm = prim::GetAttr[name="LayerNorm"](%164)
  %217 : __torch__.torch.nn.modules.linear.___torch_mangle_24377.Linear = prim::GetAttr[name="dense"](%164)
  %218 : Tensor = prim::GetAttr[name="bias"](%217)
  %219 : Tensor = prim::GetAttr[name="weight"](%217)
  %220 : Float(128:1, 128:128) = aten::t(%219), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %output.7 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.11, %220), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.7, %218, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.1, %163, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output # transformers/modeling_mobilebert.py:301:0
  %224 : Tensor = prim::GetAttr[name="bias"](%216)
  %225 : Tensor = prim::GetAttr[name="weight"](%216)
  %226 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.4, %225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.12 : Float(17:1664, 13:128, 128:1) = aten::add(%226, %224, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %228 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24401.FFNOutput = prim::GetAttr[name="output"](%134)
  %229 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24398.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%134)
  %230 : __torch__.torch.nn.modules.linear.___torch_mangle_24397.Linear = prim::GetAttr[name="dense"](%229)
  %231 : Tensor = prim::GetAttr[name="bias"](%230)
  %232 : Tensor = prim::GetAttr[name="weight"](%230)
  %233 : Float(128:1, 512:128) = aten::t(%232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.8 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.12, %233), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.13 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.8, %231, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.14 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %237 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24400.NoNorm = prim::GetAttr[name="LayerNorm"](%228)
  %238 : __torch__.torch.nn.modules.linear.___torch_mangle_24399.Linear = prim::GetAttr[name="dense"](%228)
  %239 : Tensor = prim::GetAttr[name="bias"](%238)
  %240 : Tensor = prim::GetAttr[name="weight"](%238)
  %241 : Float(512:1, 128:512) = aten::t(%240), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.9 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.14, %241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.9, %239, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.2, %input.12, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %245 : Tensor = prim::GetAttr[name="bias"](%237)
  %246 : Tensor = prim::GetAttr[name="weight"](%237)
  %247 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.5, %246), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.15 : Float(17:1664, 13:128, 128:1) = aten::add(%247, %245, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %249 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24407.FFNOutput = prim::GetAttr[name="output"](%132)
  %250 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24404.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%132)
  %251 : __torch__.torch.nn.modules.linear.___torch_mangle_24403.Linear = prim::GetAttr[name="dense"](%250)
  %252 : Tensor = prim::GetAttr[name="bias"](%251)
  %253 : Tensor = prim::GetAttr[name="weight"](%251)
  %254 : Float(128:1, 512:128) = aten::t(%253), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.10 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.15, %254), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.16 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.10, %252, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.17 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %258 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24406.NoNorm = prim::GetAttr[name="LayerNorm"](%249)
  %259 : __torch__.torch.nn.modules.linear.___torch_mangle_24405.Linear = prim::GetAttr[name="dense"](%249)
  %260 : Tensor = prim::GetAttr[name="bias"](%259)
  %261 : Tensor = prim::GetAttr[name="weight"](%259)
  %262 : Float(512:1, 128:512) = aten::t(%261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.11 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.17, %262), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.11, %260, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.3, %input.15, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %266 : Tensor = prim::GetAttr[name="bias"](%258)
  %267 : Tensor = prim::GetAttr[name="weight"](%258)
  %268 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.6, %267), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.18 : Float(17:1664, 13:128, 128:1) = aten::add(%268, %266, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %270 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24413.FFNOutput = prim::GetAttr[name="output"](%130)
  %271 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24410.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%130)
  %272 : __torch__.torch.nn.modules.linear.___torch_mangle_24409.Linear = prim::GetAttr[name="dense"](%271)
  %273 : Tensor = prim::GetAttr[name="bias"](%272)
  %274 : Tensor = prim::GetAttr[name="weight"](%272)
  %275 : Float(128:1, 512:128) = aten::t(%274), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.12 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.18, %275), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.19 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.12, %273, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.20 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %279 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24412.NoNorm = prim::GetAttr[name="LayerNorm"](%270)
  %280 : __torch__.torch.nn.modules.linear.___torch_mangle_24411.Linear = prim::GetAttr[name="dense"](%270)
  %281 : Tensor = prim::GetAttr[name="bias"](%280)
  %282 : Tensor = prim::GetAttr[name="weight"](%280)
  %283 : Float(512:1, 128:512) = aten::t(%282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.13 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.20, %283), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.13, %281, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.4, %input.18, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %287 : Tensor = prim::GetAttr[name="bias"](%279)
  %288 : Tensor = prim::GetAttr[name="weight"](%279)
  %289 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.7, %288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.21 : Float(17:1664, 13:128, 128:1) = aten::add(%289, %287, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %291 : __torch__.torch.nn.modules.linear.___torch_mangle_24381.Linear = prim::GetAttr[name="dense"](%128)
  %292 : Tensor = prim::GetAttr[name="bias"](%291)
  %293 : Tensor = prim::GetAttr[name="weight"](%291)
  %294 : Float(128:1, 512:128) = aten::t(%293), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.14 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.21, %294), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.22 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.14, %292, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.23 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate # torch/nn/functional.py:1119:0
  %298 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24388.OutputBottleneck = prim::GetAttr[name="bottleneck"](%127)
  %299 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24384.NoNorm = prim::GetAttr[name="LayerNorm"](%127)
  %300 : __torch__.torch.nn.modules.linear.___torch_mangle_24383.Linear = prim::GetAttr[name="dense"](%127)
  %301 : Tensor = prim::GetAttr[name="bias"](%300)
  %302 : Tensor = prim::GetAttr[name="weight"](%300)
  %303 : Float(512:1, 128:512) = aten::t(%302), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %output.15 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.23, %303), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %layer_output.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.15, %301, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.1, %input.21, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output # transformers/modeling_mobilebert.py:405:0
  %307 : Tensor = prim::GetAttr[name="bias"](%299)
  %308 : Tensor = prim::GetAttr[name="weight"](%299)
  %309 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.8, %308), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.24 : Float(17:1664, 13:128, 128:1) = aten::add(%309, %307, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %311 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24386.NoNorm = prim::GetAttr[name="LayerNorm"](%298)
  %312 : __torch__.torch.nn.modules.linear.___torch_mangle_24385.Linear = prim::GetAttr[name="dense"](%298)
  %313 : Tensor = prim::GetAttr[name="bias"](%312)
  %314 : Tensor = prim::GetAttr[name="weight"](%312)
  %315 : Float(128:1, 512:128) = aten::t(%314), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.16 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.24, %315), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.25 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.16, %313, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.5 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.25, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.9 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.5, %input.7, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %320 : Tensor = prim::GetAttr[name="bias"](%311)
  %321 : Tensor = prim::GetAttr[name="weight"](%311)
  %322 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.9, %321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.26 : Float(17:6656, 13:512, 512:1) = aten::add(%322, %320, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24434.MobileBertOutput = prim::GetAttr[name="output"](%124)
  %325 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24427.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%124)
  %326 : __torch__.torch.nn.modules.container.___torch_mangle_24460.ModuleList = prim::GetAttr[name="ffn"](%124)
  %327 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24459.FFNLayer = prim::GetAttr[name="2"](%326)
  %328 : __torch__.torch.nn.modules.container.___torch_mangle_24460.ModuleList = prim::GetAttr[name="ffn"](%124)
  %329 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24453.FFNLayer = prim::GetAttr[name="1"](%328)
  %330 : __torch__.torch.nn.modules.container.___torch_mangle_24460.ModuleList = prim::GetAttr[name="ffn"](%124)
  %331 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24447.FFNLayer = prim::GetAttr[name="0"](%330)
  %332 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24425.MobileBertAttention = prim::GetAttr[name="attention"](%124)
  %333 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24441.Bottleneck = prim::GetAttr[name="bottleneck"](%124)
  %334 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24440.BottleneckLayer = prim::GetAttr[name="attention"](%333)
  %335 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24437.BottleneckLayer = prim::GetAttr[name="input"](%333)
  %336 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24436.NoNorm = prim::GetAttr[name="LayerNorm"](%335)
  %337 : __torch__.torch.nn.modules.linear.___torch_mangle_24435.Linear = prim::GetAttr[name="dense"](%335)
  %338 : Tensor = prim::GetAttr[name="bias"](%337)
  %339 : Tensor = prim::GetAttr[name="weight"](%337)
  %340 : Float(512:1, 128:512) = aten::t(%339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.17 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %340), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.17, %338, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %343 : Tensor = prim::GetAttr[name="bias"](%336)
  %344 : Tensor = prim::GetAttr[name="weight"](%336)
  %345 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.10, %344), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add(%345, %343, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %347 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24439.NoNorm = prim::GetAttr[name="LayerNorm"](%334)
  %348 : __torch__.torch.nn.modules.linear.___torch_mangle_24438.Linear = prim::GetAttr[name="dense"](%334)
  %349 : Tensor = prim::GetAttr[name="bias"](%348)
  %350 : Tensor = prim::GetAttr[name="weight"](%348)
  %351 : Float(512:1, 128:512) = aten::t(%350), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.18 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.18, %349, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %354 : Tensor = prim::GetAttr[name="bias"](%347)
  %355 : Tensor = prim::GetAttr[name="weight"](%347)
  %356 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.11, %355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.27 : Float(17:1664, 13:128, 128:1) = aten::add(%356, %354, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %358 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.27, %residual_tensor.2)
  %359 : Float(17:1664, 13:128, 128:1), %360 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%358)
  %361 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24424.MobileBertSelfOutput = prim::GetAttr[name="output"](%332)
  %362 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24421.MobileBertSelfAttention = prim::GetAttr[name="self"](%332)
  %363 : __torch__.torch.nn.modules.linear.___torch_mangle_24419.Linear = prim::GetAttr[name="value"](%362)
  %364 : __torch__.torch.nn.modules.linear.___torch_mangle_24418.Linear = prim::GetAttr[name="key"](%362)
  %365 : __torch__.torch.nn.modules.linear.___torch_mangle_24417.Linear = prim::GetAttr[name="query"](%362)
  %366 : Tensor = prim::GetAttr[name="bias"](%365)
  %367 : Tensor = prim::GetAttr[name="weight"](%365)
  %368 : Float(128:1, 128:128) = aten::t(%367), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %output.19 : Float(17:1664, 13:128, 128:1) = aten::matmul(%359, %368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %x.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.19, %366, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1678:0
  %371 : Tensor = prim::GetAttr[name="bias"](%364)
  %372 : Tensor = prim::GetAttr[name="weight"](%364)
  %373 : Float(128:1, 128:128) = aten::t(%372), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %output.20 : Float(17:1664, 13:128, 128:1) = aten::matmul(%359, %373), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %x.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.20, %371, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1678:0
  %376 : Tensor = prim::GetAttr[name="bias"](%363)
  %377 : Tensor = prim::GetAttr[name="weight"](%363)
  %378 : Float(512:1, 128:512) = aten::t(%377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %output.21 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %378), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %x.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.21, %376, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1678:0
  %381 : int = aten::size(%x.7, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %382 : int = aten::size(%x.7, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %383 : int[] = prim::ListConstruct(%381, %382, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.7, %383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %385 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %query_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.8, %385), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %387 : int = aten::size(%x.9, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %388 : int = aten::size(%x.9, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %389 : int[] = prim::ListConstruct(%387, %388, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.9, %389), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %391 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %key_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.10, %391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %393 : int = aten::size(%x.11, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %394 : int = aten::size(%x.11, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %395 : int[] = prim::ListConstruct(%393, %394, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.11, %395), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %397 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %value_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.12, %397), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %399 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.2, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.2, %399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.3, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.4, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.28, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.29, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.3 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.2, %value_layer.2), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:280:0
  %406 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %407 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.3, %406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%407, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %409 : int = aten::size(%context_layer.4, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %410 : int = aten::size(%context_layer.4, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %411 : int[] = prim::ListConstruct(%409, %410, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %input.30 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.4, %411), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:283:0
  %413 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24423.NoNorm = prim::GetAttr[name="LayerNorm"](%361)
  %414 : __torch__.torch.nn.modules.linear.___torch_mangle_24422.Linear = prim::GetAttr[name="dense"](%361)
  %415 : Tensor = prim::GetAttr[name="bias"](%414)
  %416 : Tensor = prim::GetAttr[name="weight"](%414)
  %417 : Float(128:1, 128:128) = aten::t(%416), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %output.22 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.30, %417), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.22, %415, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.6, %360, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output # transformers/modeling_mobilebert.py:301:0
  %421 : Tensor = prim::GetAttr[name="bias"](%413)
  %422 : Tensor = prim::GetAttr[name="weight"](%413)
  %423 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.12, %422), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.31 : Float(17:1664, 13:128, 128:1) = aten::add(%423, %421, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %425 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24446.FFNOutput = prim::GetAttr[name="output"](%331)
  %426 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24443.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%331)
  %427 : __torch__.torch.nn.modules.linear.___torch_mangle_24442.Linear = prim::GetAttr[name="dense"](%426)
  %428 : Tensor = prim::GetAttr[name="bias"](%427)
  %429 : Tensor = prim::GetAttr[name="weight"](%427)
  %430 : Float(128:1, 512:128) = aten::t(%429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.23 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.31, %430), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.32 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.23, %428, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.33 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.32), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %434 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24445.NoNorm = prim::GetAttr[name="LayerNorm"](%425)
  %435 : __torch__.torch.nn.modules.linear.___torch_mangle_24444.Linear = prim::GetAttr[name="dense"](%425)
  %436 : Tensor = prim::GetAttr[name="bias"](%435)
  %437 : Tensor = prim::GetAttr[name="weight"](%435)
  %438 : Float(512:1, 128:512) = aten::t(%437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.24 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.33, %438), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.24, %436, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.7, %input.31, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %442 : Tensor = prim::GetAttr[name="bias"](%434)
  %443 : Tensor = prim::GetAttr[name="weight"](%434)
  %444 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.13, %443), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.34 : Float(17:1664, 13:128, 128:1) = aten::add(%444, %442, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %446 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24452.FFNOutput = prim::GetAttr[name="output"](%329)
  %447 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24449.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%329)
  %448 : __torch__.torch.nn.modules.linear.___torch_mangle_24448.Linear = prim::GetAttr[name="dense"](%447)
  %449 : Tensor = prim::GetAttr[name="bias"](%448)
  %450 : Tensor = prim::GetAttr[name="weight"](%448)
  %451 : Float(128:1, 512:128) = aten::t(%450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.25 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.34, %451), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.35 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.25, %449, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.36 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %455 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24451.NoNorm = prim::GetAttr[name="LayerNorm"](%446)
  %456 : __torch__.torch.nn.modules.linear.___torch_mangle_24450.Linear = prim::GetAttr[name="dense"](%446)
  %457 : Tensor = prim::GetAttr[name="bias"](%456)
  %458 : Tensor = prim::GetAttr[name="weight"](%456)
  %459 : Float(512:1, 128:512) = aten::t(%458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.26 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.36, %459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.26, %457, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.8, %input.34, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %463 : Tensor = prim::GetAttr[name="bias"](%455)
  %464 : Tensor = prim::GetAttr[name="weight"](%455)
  %465 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.14, %464), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.37 : Float(17:1664, 13:128, 128:1) = aten::add(%465, %463, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %467 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24458.FFNOutput = prim::GetAttr[name="output"](%327)
  %468 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24455.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%327)
  %469 : __torch__.torch.nn.modules.linear.___torch_mangle_24454.Linear = prim::GetAttr[name="dense"](%468)
  %470 : Tensor = prim::GetAttr[name="bias"](%469)
  %471 : Tensor = prim::GetAttr[name="weight"](%469)
  %472 : Float(128:1, 512:128) = aten::t(%471), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.27 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.37, %472), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.38 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.27, %470, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.39 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.38), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %476 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24457.NoNorm = prim::GetAttr[name="LayerNorm"](%467)
  %477 : __torch__.torch.nn.modules.linear.___torch_mangle_24456.Linear = prim::GetAttr[name="dense"](%467)
  %478 : Tensor = prim::GetAttr[name="bias"](%477)
  %479 : Tensor = prim::GetAttr[name="weight"](%477)
  %480 : Float(512:1, 128:512) = aten::t(%479), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.28 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.39, %480), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.28, %478, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.9, %input.37, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %484 : Tensor = prim::GetAttr[name="bias"](%476)
  %485 : Tensor = prim::GetAttr[name="weight"](%476)
  %486 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.15, %485), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.40 : Float(17:1664, 13:128, 128:1) = aten::add(%486, %484, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %488 : __torch__.torch.nn.modules.linear.___torch_mangle_24426.Linear = prim::GetAttr[name="dense"](%325)
  %489 : Tensor = prim::GetAttr[name="bias"](%488)
  %490 : Tensor = prim::GetAttr[name="weight"](%488)
  %491 : Float(128:1, 512:128) = aten::t(%490), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.29 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.40, %491), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.41 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.29, %489, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.42 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.41), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate # torch/nn/functional.py:1119:0
  %495 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24433.OutputBottleneck = prim::GetAttr[name="bottleneck"](%324)
  %496 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24429.NoNorm = prim::GetAttr[name="LayerNorm"](%324)
  %497 : __torch__.torch.nn.modules.linear.___torch_mangle_24428.Linear = prim::GetAttr[name="dense"](%324)
  %498 : Tensor = prim::GetAttr[name="bias"](%497)
  %499 : Tensor = prim::GetAttr[name="weight"](%497)
  %500 : Float(512:1, 128:512) = aten::t(%499), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %output.30 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.42, %500), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %layer_output.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.30, %498, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.2, %input.40, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output # transformers/modeling_mobilebert.py:405:0
  %504 : Tensor = prim::GetAttr[name="bias"](%496)
  %505 : Tensor = prim::GetAttr[name="weight"](%496)
  %506 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.16, %505), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.43 : Float(17:1664, 13:128, 128:1) = aten::add(%506, %504, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %508 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24431.NoNorm = prim::GetAttr[name="LayerNorm"](%495)
  %509 : __torch__.torch.nn.modules.linear.___torch_mangle_24430.Linear = prim::GetAttr[name="dense"](%495)
  %510 : Tensor = prim::GetAttr[name="bias"](%509)
  %511 : Tensor = prim::GetAttr[name="weight"](%509)
  %512 : Float(128:1, 512:128) = aten::t(%511), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.31 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.43, %512), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.44 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.31, %510, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.10 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.44, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.17 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.10, %input.26, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %517 : Tensor = prim::GetAttr[name="bias"](%508)
  %518 : Tensor = prim::GetAttr[name="weight"](%508)
  %519 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.17, %518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.45 : Float(17:6656, 13:512, 512:1) = aten::add(%519, %517, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24479.MobileBertOutput = prim::GetAttr[name="output"](%122)
  %522 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24472.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%122)
  %523 : __torch__.torch.nn.modules.container.___torch_mangle_24505.ModuleList = prim::GetAttr[name="ffn"](%122)
  %524 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24504.FFNLayer = prim::GetAttr[name="2"](%523)
  %525 : __torch__.torch.nn.modules.container.___torch_mangle_24505.ModuleList = prim::GetAttr[name="ffn"](%122)
  %526 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24498.FFNLayer = prim::GetAttr[name="1"](%525)
  %527 : __torch__.torch.nn.modules.container.___torch_mangle_24505.ModuleList = prim::GetAttr[name="ffn"](%122)
  %528 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24492.FFNLayer = prim::GetAttr[name="0"](%527)
  %529 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24470.MobileBertAttention = prim::GetAttr[name="attention"](%122)
  %530 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24486.Bottleneck = prim::GetAttr[name="bottleneck"](%122)
  %531 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24485.BottleneckLayer = prim::GetAttr[name="attention"](%530)
  %532 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24482.BottleneckLayer = prim::GetAttr[name="input"](%530)
  %533 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24481.NoNorm = prim::GetAttr[name="LayerNorm"](%532)
  %534 : __torch__.torch.nn.modules.linear.___torch_mangle_24480.Linear = prim::GetAttr[name="dense"](%532)
  %535 : Tensor = prim::GetAttr[name="bias"](%534)
  %536 : Tensor = prim::GetAttr[name="weight"](%534)
  %537 : Float(512:1, 128:512) = aten::t(%536), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.32 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %537), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.32, %535, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %540 : Tensor = prim::GetAttr[name="bias"](%533)
  %541 : Tensor = prim::GetAttr[name="weight"](%533)
  %542 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.18, %541), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add(%542, %540, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %544 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24484.NoNorm = prim::GetAttr[name="LayerNorm"](%531)
  %545 : __torch__.torch.nn.modules.linear.___torch_mangle_24483.Linear = prim::GetAttr[name="dense"](%531)
  %546 : Tensor = prim::GetAttr[name="bias"](%545)
  %547 : Tensor = prim::GetAttr[name="weight"](%545)
  %548 : Float(512:1, 128:512) = aten::t(%547), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.33 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.33, %546, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %551 : Tensor = prim::GetAttr[name="bias"](%544)
  %552 : Tensor = prim::GetAttr[name="weight"](%544)
  %553 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.19, %552), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.46 : Float(17:1664, 13:128, 128:1) = aten::add(%553, %551, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %555 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.46, %residual_tensor.3)
  %556 : Float(17:1664, 13:128, 128:1), %557 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%555)
  %558 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24469.MobileBertSelfOutput = prim::GetAttr[name="output"](%529)
  %559 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24466.MobileBertSelfAttention = prim::GetAttr[name="self"](%529)
  %560 : __torch__.torch.nn.modules.linear.___torch_mangle_24464.Linear = prim::GetAttr[name="value"](%559)
  %561 : __torch__.torch.nn.modules.linear.___torch_mangle_24463.Linear = prim::GetAttr[name="key"](%559)
  %562 : __torch__.torch.nn.modules.linear.___torch_mangle_24462.Linear = prim::GetAttr[name="query"](%559)
  %563 : Tensor = prim::GetAttr[name="bias"](%562)
  %564 : Tensor = prim::GetAttr[name="weight"](%562)
  %565 : Float(128:1, 128:128) = aten::t(%564), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %output.34 : Float(17:1664, 13:128, 128:1) = aten::matmul(%556, %565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %x.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.34, %563, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1678:0
  %568 : Tensor = prim::GetAttr[name="bias"](%561)
  %569 : Tensor = prim::GetAttr[name="weight"](%561)
  %570 : Float(128:1, 128:128) = aten::t(%569), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %output.35 : Float(17:1664, 13:128, 128:1) = aten::matmul(%556, %570), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %x.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.35, %568, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1678:0
  %573 : Tensor = prim::GetAttr[name="bias"](%560)
  %574 : Tensor = prim::GetAttr[name="weight"](%560)
  %575 : Float(512:1, 128:512) = aten::t(%574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %output.36 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %575), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %x.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.36, %573, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1678:0
  %578 : int = aten::size(%x.13, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %579 : int = aten::size(%x.13, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %580 : int[] = prim::ListConstruct(%578, %579, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.13, %580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %582 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %query_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.14, %582), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %584 : int = aten::size(%x.15, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %585 : int = aten::size(%x.15, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %586 : int[] = prim::ListConstruct(%584, %585, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.15, %586), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %588 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %key_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.16, %588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %590 : int = aten::size(%x.17, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %591 : int = aten::size(%x.17, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %592 : int[] = prim::ListConstruct(%590, %591, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.17, %592), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %594 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %value_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.18, %594), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %596 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.3, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.3, %596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.5, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.6, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.48 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.47, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.48, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.5 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.3, %value_layer.3), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:280:0
  %603 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %604 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.5, %603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%604, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %606 : int = aten::size(%context_layer.6, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %607 : int = aten::size(%context_layer.6, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %608 : int[] = prim::ListConstruct(%606, %607, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %input.49 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.6, %608), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:283:0
  %610 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24468.NoNorm = prim::GetAttr[name="LayerNorm"](%558)
  %611 : __torch__.torch.nn.modules.linear.___torch_mangle_24467.Linear = prim::GetAttr[name="dense"](%558)
  %612 : Tensor = prim::GetAttr[name="bias"](%611)
  %613 : Tensor = prim::GetAttr[name="weight"](%611)
  %614 : Float(128:1, 128:128) = aten::t(%613), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %output.37 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.49, %614), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.37, %612, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.11, %557, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output # transformers/modeling_mobilebert.py:301:0
  %618 : Tensor = prim::GetAttr[name="bias"](%610)
  %619 : Tensor = prim::GetAttr[name="weight"](%610)
  %620 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.20, %619), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.50 : Float(17:1664, 13:128, 128:1) = aten::add(%620, %618, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %622 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24491.FFNOutput = prim::GetAttr[name="output"](%528)
  %623 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24488.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%528)
  %624 : __torch__.torch.nn.modules.linear.___torch_mangle_24487.Linear = prim::GetAttr[name="dense"](%623)
  %625 : Tensor = prim::GetAttr[name="bias"](%624)
  %626 : Tensor = prim::GetAttr[name="weight"](%624)
  %627 : Float(128:1, 512:128) = aten::t(%626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.38 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.50, %627), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.51 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.38, %625, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.52 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.51), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %631 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24490.NoNorm = prim::GetAttr[name="LayerNorm"](%622)
  %632 : __torch__.torch.nn.modules.linear.___torch_mangle_24489.Linear = prim::GetAttr[name="dense"](%622)
  %633 : Tensor = prim::GetAttr[name="bias"](%632)
  %634 : Tensor = prim::GetAttr[name="weight"](%632)
  %635 : Float(512:1, 128:512) = aten::t(%634), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.39 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.52, %635), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.39, %633, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.12, %input.50, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %639 : Tensor = prim::GetAttr[name="bias"](%631)
  %640 : Tensor = prim::GetAttr[name="weight"](%631)
  %641 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.21, %640), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.53 : Float(17:1664, 13:128, 128:1) = aten::add(%641, %639, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %643 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24497.FFNOutput = prim::GetAttr[name="output"](%526)
  %644 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24494.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%526)
  %645 : __torch__.torch.nn.modules.linear.___torch_mangle_24493.Linear = prim::GetAttr[name="dense"](%644)
  %646 : Tensor = prim::GetAttr[name="bias"](%645)
  %647 : Tensor = prim::GetAttr[name="weight"](%645)
  %648 : Float(128:1, 512:128) = aten::t(%647), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.40 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.53, %648), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.54 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.40, %646, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.55 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.54), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %652 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24496.NoNorm = prim::GetAttr[name="LayerNorm"](%643)
  %653 : __torch__.torch.nn.modules.linear.___torch_mangle_24495.Linear = prim::GetAttr[name="dense"](%643)
  %654 : Tensor = prim::GetAttr[name="bias"](%653)
  %655 : Tensor = prim::GetAttr[name="weight"](%653)
  %656 : Float(512:1, 128:512) = aten::t(%655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.41 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.55, %656), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.41, %654, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.13, %input.53, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %660 : Tensor = prim::GetAttr[name="bias"](%652)
  %661 : Tensor = prim::GetAttr[name="weight"](%652)
  %662 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.22, %661), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.56 : Float(17:1664, 13:128, 128:1) = aten::add(%662, %660, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %664 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24503.FFNOutput = prim::GetAttr[name="output"](%524)
  %665 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24500.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%524)
  %666 : __torch__.torch.nn.modules.linear.___torch_mangle_24499.Linear = prim::GetAttr[name="dense"](%665)
  %667 : Tensor = prim::GetAttr[name="bias"](%666)
  %668 : Tensor = prim::GetAttr[name="weight"](%666)
  %669 : Float(128:1, 512:128) = aten::t(%668), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.42 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.56, %669), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.57 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.42, %667, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.58 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.57), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %673 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24502.NoNorm = prim::GetAttr[name="LayerNorm"](%664)
  %674 : __torch__.torch.nn.modules.linear.___torch_mangle_24501.Linear = prim::GetAttr[name="dense"](%664)
  %675 : Tensor = prim::GetAttr[name="bias"](%674)
  %676 : Tensor = prim::GetAttr[name="weight"](%674)
  %677 : Float(512:1, 128:512) = aten::t(%676), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.43 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.58, %677), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.43, %675, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.14, %input.56, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %681 : Tensor = prim::GetAttr[name="bias"](%673)
  %682 : Tensor = prim::GetAttr[name="weight"](%673)
  %683 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.23, %682), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.59 : Float(17:1664, 13:128, 128:1) = aten::add(%683, %681, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %685 : __torch__.torch.nn.modules.linear.___torch_mangle_24471.Linear = prim::GetAttr[name="dense"](%522)
  %686 : Tensor = prim::GetAttr[name="bias"](%685)
  %687 : Tensor = prim::GetAttr[name="weight"](%685)
  %688 : Float(128:1, 512:128) = aten::t(%687), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.44 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.59, %688), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.60 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.44, %686, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.61 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.60), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate # torch/nn/functional.py:1119:0
  %692 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24478.OutputBottleneck = prim::GetAttr[name="bottleneck"](%521)
  %693 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24474.NoNorm = prim::GetAttr[name="LayerNorm"](%521)
  %694 : __torch__.torch.nn.modules.linear.___torch_mangle_24473.Linear = prim::GetAttr[name="dense"](%521)
  %695 : Tensor = prim::GetAttr[name="bias"](%694)
  %696 : Tensor = prim::GetAttr[name="weight"](%694)
  %697 : Float(512:1, 128:512) = aten::t(%696), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %output.45 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.61, %697), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %layer_output.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.45, %695, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.24 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.3, %input.59, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output # transformers/modeling_mobilebert.py:405:0
  %701 : Tensor = prim::GetAttr[name="bias"](%693)
  %702 : Tensor = prim::GetAttr[name="weight"](%693)
  %703 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.24, %702), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.62 : Float(17:1664, 13:128, 128:1) = aten::add(%703, %701, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %705 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24476.NoNorm = prim::GetAttr[name="LayerNorm"](%692)
  %706 : __torch__.torch.nn.modules.linear.___torch_mangle_24475.Linear = prim::GetAttr[name="dense"](%692)
  %707 : Tensor = prim::GetAttr[name="bias"](%706)
  %708 : Tensor = prim::GetAttr[name="weight"](%706)
  %709 : Float(128:1, 512:128) = aten::t(%708), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.46 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.62, %709), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.63 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.46, %707, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.15 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.63, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.25 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.15, %input.45, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %714 : Tensor = prim::GetAttr[name="bias"](%705)
  %715 : Tensor = prim::GetAttr[name="weight"](%705)
  %716 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.25, %715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.64 : Float(17:6656, 13:512, 512:1) = aten::add(%716, %714, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24524.MobileBertOutput = prim::GetAttr[name="output"](%120)
  %719 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24517.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%120)
  %720 : __torch__.torch.nn.modules.container.___torch_mangle_24550.ModuleList = prim::GetAttr[name="ffn"](%120)
  %721 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24549.FFNLayer = prim::GetAttr[name="2"](%720)
  %722 : __torch__.torch.nn.modules.container.___torch_mangle_24550.ModuleList = prim::GetAttr[name="ffn"](%120)
  %723 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24543.FFNLayer = prim::GetAttr[name="1"](%722)
  %724 : __torch__.torch.nn.modules.container.___torch_mangle_24550.ModuleList = prim::GetAttr[name="ffn"](%120)
  %725 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24537.FFNLayer = prim::GetAttr[name="0"](%724)
  %726 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24515.MobileBertAttention = prim::GetAttr[name="attention"](%120)
  %727 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24531.Bottleneck = prim::GetAttr[name="bottleneck"](%120)
  %728 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24530.BottleneckLayer = prim::GetAttr[name="attention"](%727)
  %729 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24527.BottleneckLayer = prim::GetAttr[name="input"](%727)
  %730 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24526.NoNorm = prim::GetAttr[name="LayerNorm"](%729)
  %731 : __torch__.torch.nn.modules.linear.___torch_mangle_24525.Linear = prim::GetAttr[name="dense"](%729)
  %732 : Tensor = prim::GetAttr[name="bias"](%731)
  %733 : Tensor = prim::GetAttr[name="weight"](%731)
  %734 : Float(512:1, 128:512) = aten::t(%733), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.47 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %734), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.47, %732, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %737 : Tensor = prim::GetAttr[name="bias"](%730)
  %738 : Tensor = prim::GetAttr[name="weight"](%730)
  %739 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.26, %738), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%739, %737, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %741 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24529.NoNorm = prim::GetAttr[name="LayerNorm"](%728)
  %742 : __torch__.torch.nn.modules.linear.___torch_mangle_24528.Linear = prim::GetAttr[name="dense"](%728)
  %743 : Tensor = prim::GetAttr[name="bias"](%742)
  %744 : Tensor = prim::GetAttr[name="weight"](%742)
  %745 : Float(512:1, 128:512) = aten::t(%744), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.48 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.48, %743, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %748 : Tensor = prim::GetAttr[name="bias"](%741)
  %749 : Tensor = prim::GetAttr[name="weight"](%741)
  %750 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.27, %749), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.65 : Float(17:1664, 13:128, 128:1) = aten::add(%750, %748, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %752 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.65, %residual_tensor.4)
  %753 : Float(17:1664, 13:128, 128:1), %754 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%752)
  %755 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24514.MobileBertSelfOutput = prim::GetAttr[name="output"](%726)
  %756 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24511.MobileBertSelfAttention = prim::GetAttr[name="self"](%726)
  %757 : __torch__.torch.nn.modules.linear.___torch_mangle_24509.Linear = prim::GetAttr[name="value"](%756)
  %758 : __torch__.torch.nn.modules.linear.___torch_mangle_24508.Linear = prim::GetAttr[name="key"](%756)
  %759 : __torch__.torch.nn.modules.linear.___torch_mangle_24507.Linear = prim::GetAttr[name="query"](%756)
  %760 : Tensor = prim::GetAttr[name="bias"](%759)
  %761 : Tensor = prim::GetAttr[name="weight"](%759)
  %762 : Float(128:1, 128:128) = aten::t(%761), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %output.49 : Float(17:1664, 13:128, 128:1) = aten::matmul(%753, %762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %x.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.49, %760, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1678:0
  %765 : Tensor = prim::GetAttr[name="bias"](%758)
  %766 : Tensor = prim::GetAttr[name="weight"](%758)
  %767 : Float(128:1, 128:128) = aten::t(%766), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %output.50 : Float(17:1664, 13:128, 128:1) = aten::matmul(%753, %767), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %x.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.50, %765, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1678:0
  %770 : Tensor = prim::GetAttr[name="bias"](%757)
  %771 : Tensor = prim::GetAttr[name="weight"](%757)
  %772 : Float(512:1, 128:512) = aten::t(%771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %output.51 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %772), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %x.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.51, %770, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1678:0
  %775 : int = aten::size(%x.19, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %776 : int = aten::size(%x.19, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %777 : int[] = prim::ListConstruct(%775, %776, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.19, %777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %779 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %query_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.20, %779), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %781 : int = aten::size(%x.21, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %782 : int = aten::size(%x.21, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %783 : int[] = prim::ListConstruct(%781, %782, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.21, %783), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %785 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %key_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.22, %785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %787 : int = aten::size(%x.23, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %788 : int = aten::size(%x.23, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %789 : int[] = prim::ListConstruct(%787, %788, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.23, %789), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %791 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %value_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.24, %791), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %793 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.4, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.4, %793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.7, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.66 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.8, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.67 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.66, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.67, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.7 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.4, %value_layer.4), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:280:0
  %800 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %801 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.7, %800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%801, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %803 : int = aten::size(%context_layer.8, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %804 : int = aten::size(%context_layer.8, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %805 : int[] = prim::ListConstruct(%803, %804, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %input.68 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.8, %805), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:283:0
  %807 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24513.NoNorm = prim::GetAttr[name="LayerNorm"](%755)
  %808 : __torch__.torch.nn.modules.linear.___torch_mangle_24512.Linear = prim::GetAttr[name="dense"](%755)
  %809 : Tensor = prim::GetAttr[name="bias"](%808)
  %810 : Tensor = prim::GetAttr[name="weight"](%808)
  %811 : Float(128:1, 128:128) = aten::t(%810), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %output.52 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.68, %811), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.52, %809, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.28 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.16, %754, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output # transformers/modeling_mobilebert.py:301:0
  %815 : Tensor = prim::GetAttr[name="bias"](%807)
  %816 : Tensor = prim::GetAttr[name="weight"](%807)
  %817 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.28, %816), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.69 : Float(17:1664, 13:128, 128:1) = aten::add(%817, %815, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %819 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24536.FFNOutput = prim::GetAttr[name="output"](%725)
  %820 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24533.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%725)
  %821 : __torch__.torch.nn.modules.linear.___torch_mangle_24532.Linear = prim::GetAttr[name="dense"](%820)
  %822 : Tensor = prim::GetAttr[name="bias"](%821)
  %823 : Tensor = prim::GetAttr[name="weight"](%821)
  %824 : Float(128:1, 512:128) = aten::t(%823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.53 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.69, %824), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.70 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.53, %822, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.71 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.70), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %828 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24535.NoNorm = prim::GetAttr[name="LayerNorm"](%819)
  %829 : __torch__.torch.nn.modules.linear.___torch_mangle_24534.Linear = prim::GetAttr[name="dense"](%819)
  %830 : Tensor = prim::GetAttr[name="bias"](%829)
  %831 : Tensor = prim::GetAttr[name="weight"](%829)
  %832 : Float(512:1, 128:512) = aten::t(%831), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.54 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.71, %832), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.54, %830, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.29 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.17, %input.69, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %836 : Tensor = prim::GetAttr[name="bias"](%828)
  %837 : Tensor = prim::GetAttr[name="weight"](%828)
  %838 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.29, %837), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.72 : Float(17:1664, 13:128, 128:1) = aten::add(%838, %836, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %840 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24542.FFNOutput = prim::GetAttr[name="output"](%723)
  %841 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24539.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%723)
  %842 : __torch__.torch.nn.modules.linear.___torch_mangle_24538.Linear = prim::GetAttr[name="dense"](%841)
  %843 : Tensor = prim::GetAttr[name="bias"](%842)
  %844 : Tensor = prim::GetAttr[name="weight"](%842)
  %845 : Float(128:1, 512:128) = aten::t(%844), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.55 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.72, %845), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.73 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.55, %843, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.74 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.73), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %849 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24541.NoNorm = prim::GetAttr[name="LayerNorm"](%840)
  %850 : __torch__.torch.nn.modules.linear.___torch_mangle_24540.Linear = prim::GetAttr[name="dense"](%840)
  %851 : Tensor = prim::GetAttr[name="bias"](%850)
  %852 : Tensor = prim::GetAttr[name="weight"](%850)
  %853 : Float(512:1, 128:512) = aten::t(%852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.56 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.74, %853), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.56, %851, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.30 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.18, %input.72, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %857 : Tensor = prim::GetAttr[name="bias"](%849)
  %858 : Tensor = prim::GetAttr[name="weight"](%849)
  %859 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.30, %858), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.75 : Float(17:1664, 13:128, 128:1) = aten::add(%859, %857, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %861 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24548.FFNOutput = prim::GetAttr[name="output"](%721)
  %862 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24545.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%721)
  %863 : __torch__.torch.nn.modules.linear.___torch_mangle_24544.Linear = prim::GetAttr[name="dense"](%862)
  %864 : Tensor = prim::GetAttr[name="bias"](%863)
  %865 : Tensor = prim::GetAttr[name="weight"](%863)
  %866 : Float(128:1, 512:128) = aten::t(%865), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.57 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.75, %866), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.76 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.57, %864, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.77 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.76), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %870 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24547.NoNorm = prim::GetAttr[name="LayerNorm"](%861)
  %871 : __torch__.torch.nn.modules.linear.___torch_mangle_24546.Linear = prim::GetAttr[name="dense"](%861)
  %872 : Tensor = prim::GetAttr[name="bias"](%871)
  %873 : Tensor = prim::GetAttr[name="weight"](%871)
  %874 : Float(512:1, 128:512) = aten::t(%873), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.58 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.77, %874), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.58, %872, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.31 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.19, %input.75, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %878 : Tensor = prim::GetAttr[name="bias"](%870)
  %879 : Tensor = prim::GetAttr[name="weight"](%870)
  %880 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.31, %879), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.78 : Float(17:1664, 13:128, 128:1) = aten::add(%880, %878, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %882 : __torch__.torch.nn.modules.linear.___torch_mangle_24516.Linear = prim::GetAttr[name="dense"](%719)
  %883 : Tensor = prim::GetAttr[name="bias"](%882)
  %884 : Tensor = prim::GetAttr[name="weight"](%882)
  %885 : Float(128:1, 512:128) = aten::t(%884), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %output.59 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.78, %885), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %input.79 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.59, %883, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1678:0
  %input.80 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.79), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate # torch/nn/functional.py:1119:0
  %889 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24523.OutputBottleneck = prim::GetAttr[name="bottleneck"](%718)
  %890 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24519.NoNorm = prim::GetAttr[name="LayerNorm"](%718)
  %891 : __torch__.torch.nn.modules.linear.___torch_mangle_24518.Linear = prim::GetAttr[name="dense"](%718)
  %892 : Tensor = prim::GetAttr[name="bias"](%891)
  %893 : Tensor = prim::GetAttr[name="weight"](%891)
  %894 : Float(512:1, 128:512) = aten::t(%893), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %output.60 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.80, %894), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %layer_output.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.60, %892, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.32 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.4, %input.78, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output # transformers/modeling_mobilebert.py:405:0
  %898 : Tensor = prim::GetAttr[name="bias"](%890)
  %899 : Tensor = prim::GetAttr[name="weight"](%890)
  %900 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.32, %899), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.81 : Float(17:1664, 13:128, 128:1) = aten::add(%900, %898, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %902 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24521.NoNorm = prim::GetAttr[name="LayerNorm"](%889)
  %903 : __torch__.torch.nn.modules.linear.___torch_mangle_24520.Linear = prim::GetAttr[name="dense"](%889)
  %904 : Tensor = prim::GetAttr[name="bias"](%903)
  %905 : Tensor = prim::GetAttr[name="weight"](%903)
  %906 : Float(128:1, 512:128) = aten::t(%905), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.61 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.81, %906), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.82 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.61, %904, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.20 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.82, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.33 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.20, %input.64, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %911 : Tensor = prim::GetAttr[name="bias"](%902)
  %912 : Tensor = prim::GetAttr[name="weight"](%902)
  %913 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.33, %912), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.83 : Float(17:6656, 13:512, 512:1) = aten::add(%913, %911, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %915 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24569.MobileBertOutput = prim::GetAttr[name="output"](%118)
  %916 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24562.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%118)
  %917 : __torch__.torch.nn.modules.container.___torch_mangle_24595.ModuleList = prim::GetAttr[name="ffn"](%118)
  %918 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24594.FFNLayer = prim::GetAttr[name="2"](%917)
  %919 : __torch__.torch.nn.modules.container.___torch_mangle_24595.ModuleList = prim::GetAttr[name="ffn"](%118)
  %920 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24588.FFNLayer = prim::GetAttr[name="1"](%919)
  %921 : __torch__.torch.nn.modules.container.___torch_mangle_24595.ModuleList = prim::GetAttr[name="ffn"](%118)
  %922 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24582.FFNLayer = prim::GetAttr[name="0"](%921)
  %923 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24560.MobileBertAttention = prim::GetAttr[name="attention"](%118)
  %924 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24576.Bottleneck = prim::GetAttr[name="bottleneck"](%118)
  %925 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24575.BottleneckLayer = prim::GetAttr[name="attention"](%924)
  %926 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24572.BottleneckLayer = prim::GetAttr[name="input"](%924)
  %927 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24571.NoNorm = prim::GetAttr[name="LayerNorm"](%926)
  %928 : __torch__.torch.nn.modules.linear.___torch_mangle_24570.Linear = prim::GetAttr[name="dense"](%926)
  %929 : Tensor = prim::GetAttr[name="bias"](%928)
  %930 : Tensor = prim::GetAttr[name="weight"](%928)
  %931 : Float(512:1, 128:512) = aten::t(%930), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.62 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %931), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.62, %929, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %934 : Tensor = prim::GetAttr[name="bias"](%927)
  %935 : Tensor = prim::GetAttr[name="weight"](%927)
  %936 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.34, %935), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%936, %934, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %938 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24574.NoNorm = prim::GetAttr[name="LayerNorm"](%925)
  %939 : __torch__.torch.nn.modules.linear.___torch_mangle_24573.Linear = prim::GetAttr[name="dense"](%925)
  %940 : Tensor = prim::GetAttr[name="bias"](%939)
  %941 : Tensor = prim::GetAttr[name="weight"](%939)
  %942 : Float(512:1, 128:512) = aten::t(%941), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.63 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %942), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.63, %940, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %945 : Tensor = prim::GetAttr[name="bias"](%938)
  %946 : Tensor = prim::GetAttr[name="weight"](%938)
  %947 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.35, %946), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.84 : Float(17:1664, 13:128, 128:1) = aten::add(%947, %945, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %949 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.84, %residual_tensor.5)
  %950 : Float(17:1664, 13:128, 128:1), %951 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%949)
  %952 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24559.MobileBertSelfOutput = prim::GetAttr[name="output"](%923)
  %953 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24556.MobileBertSelfAttention = prim::GetAttr[name="self"](%923)
  %954 : __torch__.torch.nn.modules.linear.___torch_mangle_24554.Linear = prim::GetAttr[name="value"](%953)
  %955 : __torch__.torch.nn.modules.linear.___torch_mangle_24553.Linear = prim::GetAttr[name="key"](%953)
  %956 : __torch__.torch.nn.modules.linear.___torch_mangle_24552.Linear = prim::GetAttr[name="query"](%953)
  %957 : Tensor = prim::GetAttr[name="bias"](%956)
  %958 : Tensor = prim::GetAttr[name="weight"](%956)
  %959 : Float(128:1, 128:128) = aten::t(%958), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %output.64 : Float(17:1664, 13:128, 128:1) = aten::matmul(%950, %959), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %x.25 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.64, %957, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1678:0
  %962 : Tensor = prim::GetAttr[name="bias"](%955)
  %963 : Tensor = prim::GetAttr[name="weight"](%955)
  %964 : Float(128:1, 128:128) = aten::t(%963), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %output.65 : Float(17:1664, 13:128, 128:1) = aten::matmul(%950, %964), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %x.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.65, %962, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1678:0
  %967 : Tensor = prim::GetAttr[name="bias"](%954)
  %968 : Tensor = prim::GetAttr[name="weight"](%954)
  %969 : Float(512:1, 128:512) = aten::t(%968), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %output.66 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %969), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %x.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.66, %967, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1678:0
  %972 : int = aten::size(%x.25, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %973 : int = aten::size(%x.25, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %974 : int[] = prim::ListConstruct(%972, %973, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.25, %974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %976 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %query_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.26, %976), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %978 : int = aten::size(%x.27, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %979 : int = aten::size(%x.27, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %980 : int[] = prim::ListConstruct(%978, %979, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.27, %980), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %982 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %key_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.28, %982), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %984 : int = aten::size(%x.29, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %985 : int = aten::size(%x.29, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %986 : int[] = prim::ListConstruct(%984, %985, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.29, %986), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %988 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %value_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.30, %988), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %990 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.5, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.5, %990), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.9, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.85 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.10, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.86 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.85, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.86, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.9 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.5, %value_layer.5), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:280:0
  %997 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %998 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.9, %997), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%998, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %1000 : int = aten::size(%context_layer.10, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1001 : int = aten::size(%context_layer.10, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1002 : int[] = prim::ListConstruct(%1000, %1001, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %input.87 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.10, %1002), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:283:0
  %1004 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24558.NoNorm = prim::GetAttr[name="LayerNorm"](%952)
  %1005 : __torch__.torch.nn.modules.linear.___torch_mangle_24557.Linear = prim::GetAttr[name="dense"](%952)
  %1006 : Tensor = prim::GetAttr[name="bias"](%1005)
  %1007 : Tensor = prim::GetAttr[name="weight"](%1005)
  %1008 : Float(128:1, 128:128) = aten::t(%1007), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %output.67 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.87, %1008), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.67, %1006, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.36 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.21, %951, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output # transformers/modeling_mobilebert.py:301:0
  %1012 : Tensor = prim::GetAttr[name="bias"](%1004)
  %1013 : Tensor = prim::GetAttr[name="weight"](%1004)
  %1014 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.36, %1013), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.88 : Float(17:1664, 13:128, 128:1) = aten::add(%1014, %1012, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1016 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24581.FFNOutput = prim::GetAttr[name="output"](%922)
  %1017 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24578.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%922)
  %1018 : __torch__.torch.nn.modules.linear.___torch_mangle_24577.Linear = prim::GetAttr[name="dense"](%1017)
  %1019 : Tensor = prim::GetAttr[name="bias"](%1018)
  %1020 : Tensor = prim::GetAttr[name="weight"](%1018)
  %1021 : Float(128:1, 512:128) = aten::t(%1020), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.68 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.88, %1021), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.89 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.68, %1019, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.90 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.89), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1025 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24580.NoNorm = prim::GetAttr[name="LayerNorm"](%1016)
  %1026 : __torch__.torch.nn.modules.linear.___torch_mangle_24579.Linear = prim::GetAttr[name="dense"](%1016)
  %1027 : Tensor = prim::GetAttr[name="bias"](%1026)
  %1028 : Tensor = prim::GetAttr[name="weight"](%1026)
  %1029 : Float(512:1, 128:512) = aten::t(%1028), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.69 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.90, %1029), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.69, %1027, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.37 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.22, %input.88, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1033 : Tensor = prim::GetAttr[name="bias"](%1025)
  %1034 : Tensor = prim::GetAttr[name="weight"](%1025)
  %1035 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.37, %1034), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.91 : Float(17:1664, 13:128, 128:1) = aten::add(%1035, %1033, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1037 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24587.FFNOutput = prim::GetAttr[name="output"](%920)
  %1038 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24584.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%920)
  %1039 : __torch__.torch.nn.modules.linear.___torch_mangle_24583.Linear = prim::GetAttr[name="dense"](%1038)
  %1040 : Tensor = prim::GetAttr[name="bias"](%1039)
  %1041 : Tensor = prim::GetAttr[name="weight"](%1039)
  %1042 : Float(128:1, 512:128) = aten::t(%1041), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.70 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.91, %1042), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.92 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.70, %1040, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.93 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.92), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1046 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24586.NoNorm = prim::GetAttr[name="LayerNorm"](%1037)
  %1047 : __torch__.torch.nn.modules.linear.___torch_mangle_24585.Linear = prim::GetAttr[name="dense"](%1037)
  %1048 : Tensor = prim::GetAttr[name="bias"](%1047)
  %1049 : Tensor = prim::GetAttr[name="weight"](%1047)
  %1050 : Float(512:1, 128:512) = aten::t(%1049), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.71 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.93, %1050), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.71, %1048, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.38 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.23, %input.91, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1054 : Tensor = prim::GetAttr[name="bias"](%1046)
  %1055 : Tensor = prim::GetAttr[name="weight"](%1046)
  %1056 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.38, %1055), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.94 : Float(17:1664, 13:128, 128:1) = aten::add(%1056, %1054, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1058 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24593.FFNOutput = prim::GetAttr[name="output"](%918)
  %1059 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24590.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%918)
  %1060 : __torch__.torch.nn.modules.linear.___torch_mangle_24589.Linear = prim::GetAttr[name="dense"](%1059)
  %1061 : Tensor = prim::GetAttr[name="bias"](%1060)
  %1062 : Tensor = prim::GetAttr[name="weight"](%1060)
  %1063 : Float(128:1, 512:128) = aten::t(%1062), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.72 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.94, %1063), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.95 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.72, %1061, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.96 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.95), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1067 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24592.NoNorm = prim::GetAttr[name="LayerNorm"](%1058)
  %1068 : __torch__.torch.nn.modules.linear.___torch_mangle_24591.Linear = prim::GetAttr[name="dense"](%1058)
  %1069 : Tensor = prim::GetAttr[name="bias"](%1068)
  %1070 : Tensor = prim::GetAttr[name="weight"](%1068)
  %1071 : Float(512:1, 128:512) = aten::t(%1070), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.73 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.96, %1071), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.24 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.73, %1069, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.39 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.24, %input.94, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1075 : Tensor = prim::GetAttr[name="bias"](%1067)
  %1076 : Tensor = prim::GetAttr[name="weight"](%1067)
  %1077 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.39, %1076), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.97 : Float(17:1664, 13:128, 128:1) = aten::add(%1077, %1075, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1079 : __torch__.torch.nn.modules.linear.___torch_mangle_24561.Linear = prim::GetAttr[name="dense"](%916)
  %1080 : Tensor = prim::GetAttr[name="bias"](%1079)
  %1081 : Tensor = prim::GetAttr[name="weight"](%1079)
  %1082 : Float(128:1, 512:128) = aten::t(%1081), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %output.74 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.97, %1082), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %input.98 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.74, %1080, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1678:0
  %input.99 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.98), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate # torch/nn/functional.py:1119:0
  %1086 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24568.OutputBottleneck = prim::GetAttr[name="bottleneck"](%915)
  %1087 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24564.NoNorm = prim::GetAttr[name="LayerNorm"](%915)
  %1088 : __torch__.torch.nn.modules.linear.___torch_mangle_24563.Linear = prim::GetAttr[name="dense"](%915)
  %1089 : Tensor = prim::GetAttr[name="bias"](%1088)
  %1090 : Tensor = prim::GetAttr[name="weight"](%1088)
  %1091 : Float(512:1, 128:512) = aten::t(%1090), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %output.75 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.99, %1091), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %layer_output.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.75, %1089, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.40 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.5, %input.97, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output # transformers/modeling_mobilebert.py:405:0
  %1095 : Tensor = prim::GetAttr[name="bias"](%1087)
  %1096 : Tensor = prim::GetAttr[name="weight"](%1087)
  %1097 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.40, %1096), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.100 : Float(17:1664, 13:128, 128:1) = aten::add(%1097, %1095, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1099 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24566.NoNorm = prim::GetAttr[name="LayerNorm"](%1086)
  %1100 : __torch__.torch.nn.modules.linear.___torch_mangle_24565.Linear = prim::GetAttr[name="dense"](%1086)
  %1101 : Tensor = prim::GetAttr[name="bias"](%1100)
  %1102 : Tensor = prim::GetAttr[name="weight"](%1100)
  %1103 : Float(128:1, 512:128) = aten::t(%1102), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.76 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.100, %1103), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.101 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.76, %1101, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.25 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.101, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.41 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.25, %input.83, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1108 : Tensor = prim::GetAttr[name="bias"](%1099)
  %1109 : Tensor = prim::GetAttr[name="weight"](%1099)
  %1110 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.41, %1109), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.102 : Float(17:6656, 13:512, 512:1) = aten::add(%1110, %1108, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24614.MobileBertOutput = prim::GetAttr[name="output"](%116)
  %1113 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24607.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%116)
  %1114 : __torch__.torch.nn.modules.container.___torch_mangle_24640.ModuleList = prim::GetAttr[name="ffn"](%116)
  %1115 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24639.FFNLayer = prim::GetAttr[name="2"](%1114)
  %1116 : __torch__.torch.nn.modules.container.___torch_mangle_24640.ModuleList = prim::GetAttr[name="ffn"](%116)
  %1117 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24633.FFNLayer = prim::GetAttr[name="1"](%1116)
  %1118 : __torch__.torch.nn.modules.container.___torch_mangle_24640.ModuleList = prim::GetAttr[name="ffn"](%116)
  %1119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24627.FFNLayer = prim::GetAttr[name="0"](%1118)
  %1120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24605.MobileBertAttention = prim::GetAttr[name="attention"](%116)
  %1121 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24621.Bottleneck = prim::GetAttr[name="bottleneck"](%116)
  %1122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24620.BottleneckLayer = prim::GetAttr[name="attention"](%1121)
  %1123 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24617.BottleneckLayer = prim::GetAttr[name="input"](%1121)
  %1124 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24616.NoNorm = prim::GetAttr[name="LayerNorm"](%1123)
  %1125 : __torch__.torch.nn.modules.linear.___torch_mangle_24615.Linear = prim::GetAttr[name="dense"](%1123)
  %1126 : Tensor = prim::GetAttr[name="bias"](%1125)
  %1127 : Tensor = prim::GetAttr[name="weight"](%1125)
  %1128 : Float(512:1, 128:512) = aten::t(%1127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.77 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1128), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.77, %1126, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1131 : Tensor = prim::GetAttr[name="bias"](%1124)
  %1132 : Tensor = prim::GetAttr[name="weight"](%1124)
  %1133 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.42, %1132), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%1133, %1131, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24619.NoNorm = prim::GetAttr[name="LayerNorm"](%1122)
  %1136 : __torch__.torch.nn.modules.linear.___torch_mangle_24618.Linear = prim::GetAttr[name="dense"](%1122)
  %1137 : Tensor = prim::GetAttr[name="bias"](%1136)
  %1138 : Tensor = prim::GetAttr[name="weight"](%1136)
  %1139 : Float(512:1, 128:512) = aten::t(%1138), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.78 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1139), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.78, %1137, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1142 : Tensor = prim::GetAttr[name="bias"](%1135)
  %1143 : Tensor = prim::GetAttr[name="weight"](%1135)
  %1144 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.43, %1143), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.103 : Float(17:1664, 13:128, 128:1) = aten::add(%1144, %1142, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1146 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.103, %residual_tensor.6)
  %1147 : Float(17:1664, 13:128, 128:1), %1148 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1146)
  %1149 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24604.MobileBertSelfOutput = prim::GetAttr[name="output"](%1120)
  %1150 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24601.MobileBertSelfAttention = prim::GetAttr[name="self"](%1120)
  %1151 : __torch__.torch.nn.modules.linear.___torch_mangle_24599.Linear = prim::GetAttr[name="value"](%1150)
  %1152 : __torch__.torch.nn.modules.linear.___torch_mangle_24598.Linear = prim::GetAttr[name="key"](%1150)
  %1153 : __torch__.torch.nn.modules.linear.___torch_mangle_24597.Linear = prim::GetAttr[name="query"](%1150)
  %1154 : Tensor = prim::GetAttr[name="bias"](%1153)
  %1155 : Tensor = prim::GetAttr[name="weight"](%1153)
  %1156 : Float(128:1, 128:128) = aten::t(%1155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %output.79 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1147, %1156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %x.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.79, %1154, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1678:0
  %1159 : Tensor = prim::GetAttr[name="bias"](%1152)
  %1160 : Tensor = prim::GetAttr[name="weight"](%1152)
  %1161 : Float(128:1, 128:128) = aten::t(%1160), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %output.80 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1147, %1161), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %x.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.80, %1159, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1678:0
  %1164 : Tensor = prim::GetAttr[name="bias"](%1151)
  %1165 : Tensor = prim::GetAttr[name="weight"](%1151)
  %1166 : Float(512:1, 128:512) = aten::t(%1165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %output.81 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1166), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %x.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.81, %1164, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1678:0
  %1169 : int = aten::size(%x.31, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1170 : int = aten::size(%x.31, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1171 : int[] = prim::ListConstruct(%1169, %1170, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.31, %1171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1173 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %query_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.32, %1173), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1175 : int = aten::size(%x.33, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1176 : int = aten::size(%x.33, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1177 : int[] = prim::ListConstruct(%1175, %1176, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.33, %1177), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1179 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %key_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.34, %1179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1181 : int = aten::size(%x.35, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1182 : int = aten::size(%x.35, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1183 : int[] = prim::ListConstruct(%1181, %1182, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.35, %1183), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1185 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %value_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.36, %1185), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1187 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.6, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.6, %1187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.11, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.104 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.12, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.105 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.104, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.105, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.11 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.6, %value_layer.6), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:280:0
  %1194 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %1195 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.11, %1194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1195, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %1197 : int = aten::size(%context_layer.12, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1198 : int = aten::size(%context_layer.12, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1199 : int[] = prim::ListConstruct(%1197, %1198, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %input.106 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.12, %1199), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:283:0
  %1201 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24603.NoNorm = prim::GetAttr[name="LayerNorm"](%1149)
  %1202 : __torch__.torch.nn.modules.linear.___torch_mangle_24602.Linear = prim::GetAttr[name="dense"](%1149)
  %1203 : Tensor = prim::GetAttr[name="bias"](%1202)
  %1204 : Tensor = prim::GetAttr[name="weight"](%1202)
  %1205 : Float(128:1, 128:128) = aten::t(%1204), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %output.82 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.106, %1205), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.82, %1203, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.44 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.26, %1148, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output # transformers/modeling_mobilebert.py:301:0
  %1209 : Tensor = prim::GetAttr[name="bias"](%1201)
  %1210 : Tensor = prim::GetAttr[name="weight"](%1201)
  %1211 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.44, %1210), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.107 : Float(17:1664, 13:128, 128:1) = aten::add(%1211, %1209, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1213 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24626.FFNOutput = prim::GetAttr[name="output"](%1119)
  %1214 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24623.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1119)
  %1215 : __torch__.torch.nn.modules.linear.___torch_mangle_24622.Linear = prim::GetAttr[name="dense"](%1214)
  %1216 : Tensor = prim::GetAttr[name="bias"](%1215)
  %1217 : Tensor = prim::GetAttr[name="weight"](%1215)
  %1218 : Float(128:1, 512:128) = aten::t(%1217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.83 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.107, %1218), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.108 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.83, %1216, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.109 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1222 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24625.NoNorm = prim::GetAttr[name="LayerNorm"](%1213)
  %1223 : __torch__.torch.nn.modules.linear.___torch_mangle_24624.Linear = prim::GetAttr[name="dense"](%1213)
  %1224 : Tensor = prim::GetAttr[name="bias"](%1223)
  %1225 : Tensor = prim::GetAttr[name="weight"](%1223)
  %1226 : Float(512:1, 128:512) = aten::t(%1225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.84 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.109, %1226), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.84, %1224, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.45 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.27, %input.107, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1230 : Tensor = prim::GetAttr[name="bias"](%1222)
  %1231 : Tensor = prim::GetAttr[name="weight"](%1222)
  %1232 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.45, %1231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.110 : Float(17:1664, 13:128, 128:1) = aten::add(%1232, %1230, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1234 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24632.FFNOutput = prim::GetAttr[name="output"](%1117)
  %1235 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24629.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1117)
  %1236 : __torch__.torch.nn.modules.linear.___torch_mangle_24628.Linear = prim::GetAttr[name="dense"](%1235)
  %1237 : Tensor = prim::GetAttr[name="bias"](%1236)
  %1238 : Tensor = prim::GetAttr[name="weight"](%1236)
  %1239 : Float(128:1, 512:128) = aten::t(%1238), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.85 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.110, %1239), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.111 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.85, %1237, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.112 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1243 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24631.NoNorm = prim::GetAttr[name="LayerNorm"](%1234)
  %1244 : __torch__.torch.nn.modules.linear.___torch_mangle_24630.Linear = prim::GetAttr[name="dense"](%1234)
  %1245 : Tensor = prim::GetAttr[name="bias"](%1244)
  %1246 : Tensor = prim::GetAttr[name="weight"](%1244)
  %1247 : Float(512:1, 128:512) = aten::t(%1246), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.86 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.112, %1247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.28 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.86, %1245, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.46 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.28, %input.110, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1251 : Tensor = prim::GetAttr[name="bias"](%1243)
  %1252 : Tensor = prim::GetAttr[name="weight"](%1243)
  %1253 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.46, %1252), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.113 : Float(17:1664, 13:128, 128:1) = aten::add(%1253, %1251, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1255 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24638.FFNOutput = prim::GetAttr[name="output"](%1115)
  %1256 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24635.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1115)
  %1257 : __torch__.torch.nn.modules.linear.___torch_mangle_24634.Linear = prim::GetAttr[name="dense"](%1256)
  %1258 : Tensor = prim::GetAttr[name="bias"](%1257)
  %1259 : Tensor = prim::GetAttr[name="weight"](%1257)
  %1260 : Float(128:1, 512:128) = aten::t(%1259), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.87 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.113, %1260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.114 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.87, %1258, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.115 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.114), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1264 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24637.NoNorm = prim::GetAttr[name="LayerNorm"](%1255)
  %1265 : __torch__.torch.nn.modules.linear.___torch_mangle_24636.Linear = prim::GetAttr[name="dense"](%1255)
  %1266 : Tensor = prim::GetAttr[name="bias"](%1265)
  %1267 : Tensor = prim::GetAttr[name="weight"](%1265)
  %1268 : Float(512:1, 128:512) = aten::t(%1267), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.88 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.115, %1268), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.88, %1266, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.47 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.29, %input.113, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1272 : Tensor = prim::GetAttr[name="bias"](%1264)
  %1273 : Tensor = prim::GetAttr[name="weight"](%1264)
  %1274 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.47, %1273), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.116 : Float(17:1664, 13:128, 128:1) = aten::add(%1274, %1272, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1276 : __torch__.torch.nn.modules.linear.___torch_mangle_24606.Linear = prim::GetAttr[name="dense"](%1113)
  %1277 : Tensor = prim::GetAttr[name="bias"](%1276)
  %1278 : Tensor = prim::GetAttr[name="weight"](%1276)
  %1279 : Float(128:1, 512:128) = aten::t(%1278), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %output.89 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.116, %1279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %input.117 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.89, %1277, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1678:0
  %input.118 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.117), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate # torch/nn/functional.py:1119:0
  %1283 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24613.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1112)
  %1284 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24609.NoNorm = prim::GetAttr[name="LayerNorm"](%1112)
  %1285 : __torch__.torch.nn.modules.linear.___torch_mangle_24608.Linear = prim::GetAttr[name="dense"](%1112)
  %1286 : Tensor = prim::GetAttr[name="bias"](%1285)
  %1287 : Tensor = prim::GetAttr[name="weight"](%1285)
  %1288 : Float(512:1, 128:512) = aten::t(%1287), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %output.90 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.118, %1288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %layer_output.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.90, %1286, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.48 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.6, %input.116, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output # transformers/modeling_mobilebert.py:405:0
  %1292 : Tensor = prim::GetAttr[name="bias"](%1284)
  %1293 : Tensor = prim::GetAttr[name="weight"](%1284)
  %1294 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.48, %1293), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.119 : Float(17:1664, 13:128, 128:1) = aten::add(%1294, %1292, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1296 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24611.NoNorm = prim::GetAttr[name="LayerNorm"](%1283)
  %1297 : __torch__.torch.nn.modules.linear.___torch_mangle_24610.Linear = prim::GetAttr[name="dense"](%1283)
  %1298 : Tensor = prim::GetAttr[name="bias"](%1297)
  %1299 : Tensor = prim::GetAttr[name="weight"](%1297)
  %1300 : Float(128:1, 512:128) = aten::t(%1299), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.91 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.119, %1300), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.120 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.91, %1298, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.30 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.120, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.49 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.30, %input.102, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1305 : Tensor = prim::GetAttr[name="bias"](%1296)
  %1306 : Tensor = prim::GetAttr[name="weight"](%1296)
  %1307 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.49, %1306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.121 : Float(17:6656, 13:512, 512:1) = aten::add(%1307, %1305, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24659.MobileBertOutput = prim::GetAttr[name="output"](%114)
  %1310 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24652.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%114)
  %1311 : __torch__.torch.nn.modules.container.___torch_mangle_24685.ModuleList = prim::GetAttr[name="ffn"](%114)
  %1312 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24684.FFNLayer = prim::GetAttr[name="2"](%1311)
  %1313 : __torch__.torch.nn.modules.container.___torch_mangle_24685.ModuleList = prim::GetAttr[name="ffn"](%114)
  %1314 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24678.FFNLayer = prim::GetAttr[name="1"](%1313)
  %1315 : __torch__.torch.nn.modules.container.___torch_mangle_24685.ModuleList = prim::GetAttr[name="ffn"](%114)
  %1316 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24672.FFNLayer = prim::GetAttr[name="0"](%1315)
  %1317 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24650.MobileBertAttention = prim::GetAttr[name="attention"](%114)
  %1318 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24666.Bottleneck = prim::GetAttr[name="bottleneck"](%114)
  %1319 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24665.BottleneckLayer = prim::GetAttr[name="attention"](%1318)
  %1320 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24662.BottleneckLayer = prim::GetAttr[name="input"](%1318)
  %1321 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24661.NoNorm = prim::GetAttr[name="LayerNorm"](%1320)
  %1322 : __torch__.torch.nn.modules.linear.___torch_mangle_24660.Linear = prim::GetAttr[name="dense"](%1320)
  %1323 : Tensor = prim::GetAttr[name="bias"](%1322)
  %1324 : Tensor = prim::GetAttr[name="weight"](%1322)
  %1325 : Float(512:1, 128:512) = aten::t(%1324), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.92 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1325), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.50 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.92, %1323, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1328 : Tensor = prim::GetAttr[name="bias"](%1321)
  %1329 : Tensor = prim::GetAttr[name="weight"](%1321)
  %1330 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.50, %1329), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%1330, %1328, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1332 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24664.NoNorm = prim::GetAttr[name="LayerNorm"](%1319)
  %1333 : __torch__.torch.nn.modules.linear.___torch_mangle_24663.Linear = prim::GetAttr[name="dense"](%1319)
  %1334 : Tensor = prim::GetAttr[name="bias"](%1333)
  %1335 : Tensor = prim::GetAttr[name="weight"](%1333)
  %1336 : Float(512:1, 128:512) = aten::t(%1335), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.93 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.93, %1334, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1339 : Tensor = prim::GetAttr[name="bias"](%1332)
  %1340 : Tensor = prim::GetAttr[name="weight"](%1332)
  %1341 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.51, %1340), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.122 : Float(17:1664, 13:128, 128:1) = aten::add(%1341, %1339, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1343 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.122, %residual_tensor.7)
  %1344 : Float(17:1664, 13:128, 128:1), %1345 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1343)
  %1346 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24649.MobileBertSelfOutput = prim::GetAttr[name="output"](%1317)
  %1347 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24646.MobileBertSelfAttention = prim::GetAttr[name="self"](%1317)
  %1348 : __torch__.torch.nn.modules.linear.___torch_mangle_24644.Linear = prim::GetAttr[name="value"](%1347)
  %1349 : __torch__.torch.nn.modules.linear.___torch_mangle_24643.Linear = prim::GetAttr[name="key"](%1347)
  %1350 : __torch__.torch.nn.modules.linear.___torch_mangle_24642.Linear = prim::GetAttr[name="query"](%1347)
  %1351 : Tensor = prim::GetAttr[name="bias"](%1350)
  %1352 : Tensor = prim::GetAttr[name="weight"](%1350)
  %1353 : Float(128:1, 128:128) = aten::t(%1352), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %output.94 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1344, %1353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %x.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.94, %1351, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1678:0
  %1356 : Tensor = prim::GetAttr[name="bias"](%1349)
  %1357 : Tensor = prim::GetAttr[name="weight"](%1349)
  %1358 : Float(128:1, 128:128) = aten::t(%1357), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %output.95 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1344, %1358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %x.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.95, %1356, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1678:0
  %1361 : Tensor = prim::GetAttr[name="bias"](%1348)
  %1362 : Tensor = prim::GetAttr[name="weight"](%1348)
  %1363 : Float(512:1, 128:512) = aten::t(%1362), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %output.96 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1363), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %x.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.96, %1361, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1678:0
  %1366 : int = aten::size(%x.37, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1367 : int = aten::size(%x.37, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1368 : int[] = prim::ListConstruct(%1366, %1367, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.37, %1368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1370 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %query_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.38, %1370), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1372 : int = aten::size(%x.39, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1373 : int = aten::size(%x.39, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1374 : int[] = prim::ListConstruct(%1372, %1373, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.39, %1374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1376 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %key_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.40, %1376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1378 : int = aten::size(%x.41, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1379 : int = aten::size(%x.41, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1380 : int[] = prim::ListConstruct(%1378, %1379, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.41, %1380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1382 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %value_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.42, %1382), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1384 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.7, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.7, %1384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.13, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.123 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.14, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.124 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.123, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.124, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.13 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.7, %value_layer.7), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:280:0
  %1391 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %1392 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.13, %1391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1392, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %1394 : int = aten::size(%context_layer.14, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1395 : int = aten::size(%context_layer.14, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1396 : int[] = prim::ListConstruct(%1394, %1395, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %input.125 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.14, %1396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:283:0
  %1398 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24648.NoNorm = prim::GetAttr[name="LayerNorm"](%1346)
  %1399 : __torch__.torch.nn.modules.linear.___torch_mangle_24647.Linear = prim::GetAttr[name="dense"](%1346)
  %1400 : Tensor = prim::GetAttr[name="bias"](%1399)
  %1401 : Tensor = prim::GetAttr[name="weight"](%1399)
  %1402 : Float(128:1, 128:128) = aten::t(%1401), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %output.97 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.125, %1402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.97, %1400, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.52 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.31, %1345, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output # transformers/modeling_mobilebert.py:301:0
  %1406 : Tensor = prim::GetAttr[name="bias"](%1398)
  %1407 : Tensor = prim::GetAttr[name="weight"](%1398)
  %1408 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.52, %1407), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.126 : Float(17:1664, 13:128, 128:1) = aten::add(%1408, %1406, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1410 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24671.FFNOutput = prim::GetAttr[name="output"](%1316)
  %1411 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24668.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1316)
  %1412 : __torch__.torch.nn.modules.linear.___torch_mangle_24667.Linear = prim::GetAttr[name="dense"](%1411)
  %1413 : Tensor = prim::GetAttr[name="bias"](%1412)
  %1414 : Tensor = prim::GetAttr[name="weight"](%1412)
  %1415 : Float(128:1, 512:128) = aten::t(%1414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.98 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.126, %1415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.127 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.98, %1413, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.128 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1419 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24670.NoNorm = prim::GetAttr[name="LayerNorm"](%1410)
  %1420 : __torch__.torch.nn.modules.linear.___torch_mangle_24669.Linear = prim::GetAttr[name="dense"](%1410)
  %1421 : Tensor = prim::GetAttr[name="bias"](%1420)
  %1422 : Tensor = prim::GetAttr[name="weight"](%1420)
  %1423 : Float(512:1, 128:512) = aten::t(%1422), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.99 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.128, %1423), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.32 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.99, %1421, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.53 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.32, %input.126, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1427 : Tensor = prim::GetAttr[name="bias"](%1419)
  %1428 : Tensor = prim::GetAttr[name="weight"](%1419)
  %1429 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.53, %1428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.129 : Float(17:1664, 13:128, 128:1) = aten::add(%1429, %1427, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1431 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24677.FFNOutput = prim::GetAttr[name="output"](%1314)
  %1432 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24674.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1314)
  %1433 : __torch__.torch.nn.modules.linear.___torch_mangle_24673.Linear = prim::GetAttr[name="dense"](%1432)
  %1434 : Tensor = prim::GetAttr[name="bias"](%1433)
  %1435 : Tensor = prim::GetAttr[name="weight"](%1433)
  %1436 : Float(128:1, 512:128) = aten::t(%1435), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.100 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.129, %1436), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.130 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.100, %1434, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.131 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1440 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24676.NoNorm = prim::GetAttr[name="LayerNorm"](%1431)
  %1441 : __torch__.torch.nn.modules.linear.___torch_mangle_24675.Linear = prim::GetAttr[name="dense"](%1431)
  %1442 : Tensor = prim::GetAttr[name="bias"](%1441)
  %1443 : Tensor = prim::GetAttr[name="weight"](%1441)
  %1444 : Float(512:1, 128:512) = aten::t(%1443), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.101 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.131, %1444), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.101, %1442, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.54 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.33, %input.129, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1448 : Tensor = prim::GetAttr[name="bias"](%1440)
  %1449 : Tensor = prim::GetAttr[name="weight"](%1440)
  %1450 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.54, %1449), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.132 : Float(17:1664, 13:128, 128:1) = aten::add(%1450, %1448, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1452 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24683.FFNOutput = prim::GetAttr[name="output"](%1312)
  %1453 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24680.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1312)
  %1454 : __torch__.torch.nn.modules.linear.___torch_mangle_24679.Linear = prim::GetAttr[name="dense"](%1453)
  %1455 : Tensor = prim::GetAttr[name="bias"](%1454)
  %1456 : Tensor = prim::GetAttr[name="weight"](%1454)
  %1457 : Float(128:1, 512:128) = aten::t(%1456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.102 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.132, %1457), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.133 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.102, %1455, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.134 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1461 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24682.NoNorm = prim::GetAttr[name="LayerNorm"](%1452)
  %1462 : __torch__.torch.nn.modules.linear.___torch_mangle_24681.Linear = prim::GetAttr[name="dense"](%1452)
  %1463 : Tensor = prim::GetAttr[name="bias"](%1462)
  %1464 : Tensor = prim::GetAttr[name="weight"](%1462)
  %1465 : Float(512:1, 128:512) = aten::t(%1464), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.103 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.134, %1465), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.103, %1463, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.55 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.34, %input.132, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1469 : Tensor = prim::GetAttr[name="bias"](%1461)
  %1470 : Tensor = prim::GetAttr[name="weight"](%1461)
  %1471 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.55, %1470), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.135 : Float(17:1664, 13:128, 128:1) = aten::add(%1471, %1469, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1473 : __torch__.torch.nn.modules.linear.___torch_mangle_24651.Linear = prim::GetAttr[name="dense"](%1310)
  %1474 : Tensor = prim::GetAttr[name="bias"](%1473)
  %1475 : Tensor = prim::GetAttr[name="weight"](%1473)
  %1476 : Float(128:1, 512:128) = aten::t(%1475), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %output.104 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.135, %1476), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %input.136 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.104, %1474, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1678:0
  %input.137 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.136), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate # torch/nn/functional.py:1119:0
  %1480 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24658.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1309)
  %1481 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24654.NoNorm = prim::GetAttr[name="LayerNorm"](%1309)
  %1482 : __torch__.torch.nn.modules.linear.___torch_mangle_24653.Linear = prim::GetAttr[name="dense"](%1309)
  %1483 : Tensor = prim::GetAttr[name="bias"](%1482)
  %1484 : Tensor = prim::GetAttr[name="weight"](%1482)
  %1485 : Float(512:1, 128:512) = aten::t(%1484), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %output.105 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.137, %1485), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %layer_output.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.105, %1483, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.56 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.7, %input.135, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output # transformers/modeling_mobilebert.py:405:0
  %1489 : Tensor = prim::GetAttr[name="bias"](%1481)
  %1490 : Tensor = prim::GetAttr[name="weight"](%1481)
  %1491 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.56, %1490), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.138 : Float(17:1664, 13:128, 128:1) = aten::add(%1491, %1489, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1493 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24656.NoNorm = prim::GetAttr[name="LayerNorm"](%1480)
  %1494 : __torch__.torch.nn.modules.linear.___torch_mangle_24655.Linear = prim::GetAttr[name="dense"](%1480)
  %1495 : Tensor = prim::GetAttr[name="bias"](%1494)
  %1496 : Tensor = prim::GetAttr[name="weight"](%1494)
  %1497 : Float(128:1, 512:128) = aten::t(%1496), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.106 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.138, %1497), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.139 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.106, %1495, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.35 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.139, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.57 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.35, %input.121, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1502 : Tensor = prim::GetAttr[name="bias"](%1493)
  %1503 : Tensor = prim::GetAttr[name="weight"](%1493)
  %1504 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.57, %1503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.140 : Float(17:6656, 13:512, 512:1) = aten::add(%1504, %1502, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24704.MobileBertOutput = prim::GetAttr[name="output"](%112)
  %1507 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24697.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%112)
  %1508 : __torch__.torch.nn.modules.container.___torch_mangle_24730.ModuleList = prim::GetAttr[name="ffn"](%112)
  %1509 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24729.FFNLayer = prim::GetAttr[name="2"](%1508)
  %1510 : __torch__.torch.nn.modules.container.___torch_mangle_24730.ModuleList = prim::GetAttr[name="ffn"](%112)
  %1511 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24723.FFNLayer = prim::GetAttr[name="1"](%1510)
  %1512 : __torch__.torch.nn.modules.container.___torch_mangle_24730.ModuleList = prim::GetAttr[name="ffn"](%112)
  %1513 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24717.FFNLayer = prim::GetAttr[name="0"](%1512)
  %1514 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24695.MobileBertAttention = prim::GetAttr[name="attention"](%112)
  %1515 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24711.Bottleneck = prim::GetAttr[name="bottleneck"](%112)
  %1516 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24710.BottleneckLayer = prim::GetAttr[name="attention"](%1515)
  %1517 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24707.BottleneckLayer = prim::GetAttr[name="input"](%1515)
  %1518 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24706.NoNorm = prim::GetAttr[name="LayerNorm"](%1517)
  %1519 : __torch__.torch.nn.modules.linear.___torch_mangle_24705.Linear = prim::GetAttr[name="dense"](%1517)
  %1520 : Tensor = prim::GetAttr[name="bias"](%1519)
  %1521 : Tensor = prim::GetAttr[name="weight"](%1519)
  %1522 : Float(512:1, 128:512) = aten::t(%1521), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.107 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1522), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.107, %1520, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1525 : Tensor = prim::GetAttr[name="bias"](%1518)
  %1526 : Tensor = prim::GetAttr[name="weight"](%1518)
  %1527 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.58, %1526), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%1527, %1525, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1529 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24709.NoNorm = prim::GetAttr[name="LayerNorm"](%1516)
  %1530 : __torch__.torch.nn.modules.linear.___torch_mangle_24708.Linear = prim::GetAttr[name="dense"](%1516)
  %1531 : Tensor = prim::GetAttr[name="bias"](%1530)
  %1532 : Tensor = prim::GetAttr[name="weight"](%1530)
  %1533 : Float(512:1, 128:512) = aten::t(%1532), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.108 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.108, %1531, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1536 : Tensor = prim::GetAttr[name="bias"](%1529)
  %1537 : Tensor = prim::GetAttr[name="weight"](%1529)
  %1538 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.59, %1537), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.141 : Float(17:1664, 13:128, 128:1) = aten::add(%1538, %1536, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1540 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.141, %residual_tensor.8)
  %1541 : Float(17:1664, 13:128, 128:1), %1542 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1540)
  %1543 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24694.MobileBertSelfOutput = prim::GetAttr[name="output"](%1514)
  %1544 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24691.MobileBertSelfAttention = prim::GetAttr[name="self"](%1514)
  %1545 : __torch__.torch.nn.modules.linear.___torch_mangle_24689.Linear = prim::GetAttr[name="value"](%1544)
  %1546 : __torch__.torch.nn.modules.linear.___torch_mangle_24688.Linear = prim::GetAttr[name="key"](%1544)
  %1547 : __torch__.torch.nn.modules.linear.___torch_mangle_24687.Linear = prim::GetAttr[name="query"](%1544)
  %1548 : Tensor = prim::GetAttr[name="bias"](%1547)
  %1549 : Tensor = prim::GetAttr[name="weight"](%1547)
  %1550 : Float(128:1, 128:128) = aten::t(%1549), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %output.109 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1541, %1550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %x.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.109, %1548, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1678:0
  %1553 : Tensor = prim::GetAttr[name="bias"](%1546)
  %1554 : Tensor = prim::GetAttr[name="weight"](%1546)
  %1555 : Float(128:1, 128:128) = aten::t(%1554), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %output.110 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1541, %1555), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %x.45 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.110, %1553, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1678:0
  %1558 : Tensor = prim::GetAttr[name="bias"](%1545)
  %1559 : Tensor = prim::GetAttr[name="weight"](%1545)
  %1560 : Float(512:1, 128:512) = aten::t(%1559), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %output.111 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1560), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %x.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.111, %1558, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1678:0
  %1563 : int = aten::size(%x.43, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1564 : int = aten::size(%x.43, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1565 : int[] = prim::ListConstruct(%1563, %1564, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.43, %1565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1567 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %query_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.44, %1567), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1569 : int = aten::size(%x.45, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1570 : int = aten::size(%x.45, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1571 : int[] = prim::ListConstruct(%1569, %1570, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.45, %1571), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1573 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %key_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.46, %1573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1575 : int = aten::size(%x.47, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1576 : int = aten::size(%x.47, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1577 : int[] = prim::ListConstruct(%1575, %1576, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.48 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.47, %1577), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1579 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %value_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.48, %1579), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1581 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.8, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.8, %1581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.15, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.142 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.16, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.143 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.142, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.143, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.15 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.8, %value_layer.8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:280:0
  %1588 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %1589 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.15, %1588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1589, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %1591 : int = aten::size(%context_layer.16, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1592 : int = aten::size(%context_layer.16, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1593 : int[] = prim::ListConstruct(%1591, %1592, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %input.144 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.16, %1593), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:283:0
  %1595 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24693.NoNorm = prim::GetAttr[name="LayerNorm"](%1543)
  %1596 : __torch__.torch.nn.modules.linear.___torch_mangle_24692.Linear = prim::GetAttr[name="dense"](%1543)
  %1597 : Tensor = prim::GetAttr[name="bias"](%1596)
  %1598 : Tensor = prim::GetAttr[name="weight"](%1596)
  %1599 : Float(128:1, 128:128) = aten::t(%1598), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %output.112 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.144, %1599), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.36 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.112, %1597, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.60 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.36, %1542, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output # transformers/modeling_mobilebert.py:301:0
  %1603 : Tensor = prim::GetAttr[name="bias"](%1595)
  %1604 : Tensor = prim::GetAttr[name="weight"](%1595)
  %1605 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.60, %1604), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.145 : Float(17:1664, 13:128, 128:1) = aten::add(%1605, %1603, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1607 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24716.FFNOutput = prim::GetAttr[name="output"](%1513)
  %1608 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24713.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1513)
  %1609 : __torch__.torch.nn.modules.linear.___torch_mangle_24712.Linear = prim::GetAttr[name="dense"](%1608)
  %1610 : Tensor = prim::GetAttr[name="bias"](%1609)
  %1611 : Tensor = prim::GetAttr[name="weight"](%1609)
  %1612 : Float(128:1, 512:128) = aten::t(%1611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.113 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.145, %1612), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.146 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.113, %1610, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.147 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1616 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24715.NoNorm = prim::GetAttr[name="LayerNorm"](%1607)
  %1617 : __torch__.torch.nn.modules.linear.___torch_mangle_24714.Linear = prim::GetAttr[name="dense"](%1607)
  %1618 : Tensor = prim::GetAttr[name="bias"](%1617)
  %1619 : Tensor = prim::GetAttr[name="weight"](%1617)
  %1620 : Float(512:1, 128:512) = aten::t(%1619), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.114 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.147, %1620), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.114, %1618, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.61 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.37, %input.145, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1624 : Tensor = prim::GetAttr[name="bias"](%1616)
  %1625 : Tensor = prim::GetAttr[name="weight"](%1616)
  %1626 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.61, %1625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.148 : Float(17:1664, 13:128, 128:1) = aten::add(%1626, %1624, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1628 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24722.FFNOutput = prim::GetAttr[name="output"](%1511)
  %1629 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24719.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1511)
  %1630 : __torch__.torch.nn.modules.linear.___torch_mangle_24718.Linear = prim::GetAttr[name="dense"](%1629)
  %1631 : Tensor = prim::GetAttr[name="bias"](%1630)
  %1632 : Tensor = prim::GetAttr[name="weight"](%1630)
  %1633 : Float(128:1, 512:128) = aten::t(%1632), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.115 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.148, %1633), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.149 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.115, %1631, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.150 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1637 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24721.NoNorm = prim::GetAttr[name="LayerNorm"](%1628)
  %1638 : __torch__.torch.nn.modules.linear.___torch_mangle_24720.Linear = prim::GetAttr[name="dense"](%1628)
  %1639 : Tensor = prim::GetAttr[name="bias"](%1638)
  %1640 : Tensor = prim::GetAttr[name="weight"](%1638)
  %1641 : Float(512:1, 128:512) = aten::t(%1640), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.116 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.150, %1641), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.38 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.116, %1639, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.62 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.38, %input.148, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1645 : Tensor = prim::GetAttr[name="bias"](%1637)
  %1646 : Tensor = prim::GetAttr[name="weight"](%1637)
  %1647 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.62, %1646), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.151 : Float(17:1664, 13:128, 128:1) = aten::add(%1647, %1645, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1649 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24728.FFNOutput = prim::GetAttr[name="output"](%1509)
  %1650 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24725.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1509)
  %1651 : __torch__.torch.nn.modules.linear.___torch_mangle_24724.Linear = prim::GetAttr[name="dense"](%1650)
  %1652 : Tensor = prim::GetAttr[name="bias"](%1651)
  %1653 : Tensor = prim::GetAttr[name="weight"](%1651)
  %1654 : Float(128:1, 512:128) = aten::t(%1653), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.117 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.151, %1654), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.152 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.117, %1652, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.153 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1658 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24727.NoNorm = prim::GetAttr[name="LayerNorm"](%1649)
  %1659 : __torch__.torch.nn.modules.linear.___torch_mangle_24726.Linear = prim::GetAttr[name="dense"](%1649)
  %1660 : Tensor = prim::GetAttr[name="bias"](%1659)
  %1661 : Tensor = prim::GetAttr[name="weight"](%1659)
  %1662 : Float(512:1, 128:512) = aten::t(%1661), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.118 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.153, %1662), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.118, %1660, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.63 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.39, %input.151, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1666 : Tensor = prim::GetAttr[name="bias"](%1658)
  %1667 : Tensor = prim::GetAttr[name="weight"](%1658)
  %1668 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.63, %1667), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.154 : Float(17:1664, 13:128, 128:1) = aten::add(%1668, %1666, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1670 : __torch__.torch.nn.modules.linear.___torch_mangle_24696.Linear = prim::GetAttr[name="dense"](%1507)
  %1671 : Tensor = prim::GetAttr[name="bias"](%1670)
  %1672 : Tensor = prim::GetAttr[name="weight"](%1670)
  %1673 : Float(128:1, 512:128) = aten::t(%1672), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %output.119 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.154, %1673), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %input.155 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.119, %1671, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1678:0
  %input.156 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate # torch/nn/functional.py:1119:0
  %1677 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24703.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1506)
  %1678 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24699.NoNorm = prim::GetAttr[name="LayerNorm"](%1506)
  %1679 : __torch__.torch.nn.modules.linear.___torch_mangle_24698.Linear = prim::GetAttr[name="dense"](%1506)
  %1680 : Tensor = prim::GetAttr[name="bias"](%1679)
  %1681 : Tensor = prim::GetAttr[name="weight"](%1679)
  %1682 : Float(512:1, 128:512) = aten::t(%1681), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %output.120 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.156, %1682), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %layer_output.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.120, %1680, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.64 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.8, %input.154, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output # transformers/modeling_mobilebert.py:405:0
  %1686 : Tensor = prim::GetAttr[name="bias"](%1678)
  %1687 : Tensor = prim::GetAttr[name="weight"](%1678)
  %1688 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.64, %1687), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.157 : Float(17:1664, 13:128, 128:1) = aten::add(%1688, %1686, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1690 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24701.NoNorm = prim::GetAttr[name="LayerNorm"](%1677)
  %1691 : __torch__.torch.nn.modules.linear.___torch_mangle_24700.Linear = prim::GetAttr[name="dense"](%1677)
  %1692 : Tensor = prim::GetAttr[name="bias"](%1691)
  %1693 : Tensor = prim::GetAttr[name="weight"](%1691)
  %1694 : Float(128:1, 512:128) = aten::t(%1693), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.121 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.157, %1694), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.158 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.121, %1692, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.40 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.158, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.65 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.40, %input.140, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1699 : Tensor = prim::GetAttr[name="bias"](%1690)
  %1700 : Tensor = prim::GetAttr[name="weight"](%1690)
  %1701 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.65, %1700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.159 : Float(17:6656, 13:512, 512:1) = aten::add(%1701, %1699, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24749.MobileBertOutput = prim::GetAttr[name="output"](%110)
  %1704 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24742.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%110)
  %1705 : __torch__.torch.nn.modules.container.___torch_mangle_24775.ModuleList = prim::GetAttr[name="ffn"](%110)
  %1706 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24774.FFNLayer = prim::GetAttr[name="2"](%1705)
  %1707 : __torch__.torch.nn.modules.container.___torch_mangle_24775.ModuleList = prim::GetAttr[name="ffn"](%110)
  %1708 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24768.FFNLayer = prim::GetAttr[name="1"](%1707)
  %1709 : __torch__.torch.nn.modules.container.___torch_mangle_24775.ModuleList = prim::GetAttr[name="ffn"](%110)
  %1710 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24762.FFNLayer = prim::GetAttr[name="0"](%1709)
  %1711 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24740.MobileBertAttention = prim::GetAttr[name="attention"](%110)
  %1712 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24756.Bottleneck = prim::GetAttr[name="bottleneck"](%110)
  %1713 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24755.BottleneckLayer = prim::GetAttr[name="attention"](%1712)
  %1714 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24752.BottleneckLayer = prim::GetAttr[name="input"](%1712)
  %1715 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24751.NoNorm = prim::GetAttr[name="LayerNorm"](%1714)
  %1716 : __torch__.torch.nn.modules.linear.___torch_mangle_24750.Linear = prim::GetAttr[name="dense"](%1714)
  %1717 : Tensor = prim::GetAttr[name="bias"](%1716)
  %1718 : Tensor = prim::GetAttr[name="weight"](%1716)
  %1719 : Float(512:1, 128:512) = aten::t(%1718), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.122 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1719), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.122, %1717, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1722 : Tensor = prim::GetAttr[name="bias"](%1715)
  %1723 : Tensor = prim::GetAttr[name="weight"](%1715)
  %1724 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.66, %1723), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.9 : Float(17:1664, 13:128, 128:1) = aten::add(%1724, %1722, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1726 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24754.NoNorm = prim::GetAttr[name="LayerNorm"](%1713)
  %1727 : __torch__.torch.nn.modules.linear.___torch_mangle_24753.Linear = prim::GetAttr[name="dense"](%1713)
  %1728 : Tensor = prim::GetAttr[name="bias"](%1727)
  %1729 : Tensor = prim::GetAttr[name="weight"](%1727)
  %1730 : Float(512:1, 128:512) = aten::t(%1729), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.123 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.123, %1728, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1733 : Tensor = prim::GetAttr[name="bias"](%1726)
  %1734 : Tensor = prim::GetAttr[name="weight"](%1726)
  %1735 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.67, %1734), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.160 : Float(17:1664, 13:128, 128:1) = aten::add(%1735, %1733, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1737 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.160, %residual_tensor.9)
  %1738 : Float(17:1664, 13:128, 128:1), %1739 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1737)
  %1740 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24739.MobileBertSelfOutput = prim::GetAttr[name="output"](%1711)
  %1741 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24736.MobileBertSelfAttention = prim::GetAttr[name="self"](%1711)
  %1742 : __torch__.torch.nn.modules.linear.___torch_mangle_24734.Linear = prim::GetAttr[name="value"](%1741)
  %1743 : __torch__.torch.nn.modules.linear.___torch_mangle_24733.Linear = prim::GetAttr[name="key"](%1741)
  %1744 : __torch__.torch.nn.modules.linear.___torch_mangle_24732.Linear = prim::GetAttr[name="query"](%1741)
  %1745 : Tensor = prim::GetAttr[name="bias"](%1744)
  %1746 : Tensor = prim::GetAttr[name="weight"](%1744)
  %1747 : Float(128:1, 128:128) = aten::t(%1746), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %output.124 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1738, %1747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %x.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.124, %1745, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1678:0
  %1750 : Tensor = prim::GetAttr[name="bias"](%1743)
  %1751 : Tensor = prim::GetAttr[name="weight"](%1743)
  %1752 : Float(128:1, 128:128) = aten::t(%1751), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %output.125 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1738, %1752), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %x.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.125, %1750, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1678:0
  %1755 : Tensor = prim::GetAttr[name="bias"](%1742)
  %1756 : Tensor = prim::GetAttr[name="weight"](%1742)
  %1757 : Float(512:1, 128:512) = aten::t(%1756), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %output.126 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1757), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %x.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.126, %1755, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1678:0
  %1760 : int = aten::size(%x.49, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1761 : int = aten::size(%x.49, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1762 : int[] = prim::ListConstruct(%1760, %1761, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.50 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.49, %1762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1764 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %query_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.50, %1764), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1766 : int = aten::size(%x.51, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1767 : int = aten::size(%x.51, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1768 : int[] = prim::ListConstruct(%1766, %1767, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.52 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.51, %1768), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1770 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %key_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.52, %1770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1772 : int = aten::size(%x.53, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1773 : int = aten::size(%x.53, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1774 : int[] = prim::ListConstruct(%1772, %1773, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.54 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.53, %1774), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1776 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %value_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.54, %1776), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1778 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.9, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.9, %1778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.17, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.161 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.18, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.162 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.161, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.162, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.17 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.9, %value_layer.9), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:280:0
  %1785 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %1786 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.17, %1785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1786, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %1788 : int = aten::size(%context_layer.18, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1789 : int = aten::size(%context_layer.18, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1790 : int[] = prim::ListConstruct(%1788, %1789, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %input.163 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.18, %1790), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:283:0
  %1792 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24738.NoNorm = prim::GetAttr[name="LayerNorm"](%1740)
  %1793 : __torch__.torch.nn.modules.linear.___torch_mangle_24737.Linear = prim::GetAttr[name="dense"](%1740)
  %1794 : Tensor = prim::GetAttr[name="bias"](%1793)
  %1795 : Tensor = prim::GetAttr[name="weight"](%1793)
  %1796 : Float(128:1, 128:128) = aten::t(%1795), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %output.127 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.163, %1796), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.127, %1794, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.68 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.41, %1739, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output # transformers/modeling_mobilebert.py:301:0
  %1800 : Tensor = prim::GetAttr[name="bias"](%1792)
  %1801 : Tensor = prim::GetAttr[name="weight"](%1792)
  %1802 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.68, %1801), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.164 : Float(17:1664, 13:128, 128:1) = aten::add(%1802, %1800, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1804 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24761.FFNOutput = prim::GetAttr[name="output"](%1710)
  %1805 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24758.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1710)
  %1806 : __torch__.torch.nn.modules.linear.___torch_mangle_24757.Linear = prim::GetAttr[name="dense"](%1805)
  %1807 : Tensor = prim::GetAttr[name="bias"](%1806)
  %1808 : Tensor = prim::GetAttr[name="weight"](%1806)
  %1809 : Float(128:1, 512:128) = aten::t(%1808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.128 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.164, %1809), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.165 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.128, %1807, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.166 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1813 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24760.NoNorm = prim::GetAttr[name="LayerNorm"](%1804)
  %1814 : __torch__.torch.nn.modules.linear.___torch_mangle_24759.Linear = prim::GetAttr[name="dense"](%1804)
  %1815 : Tensor = prim::GetAttr[name="bias"](%1814)
  %1816 : Tensor = prim::GetAttr[name="weight"](%1814)
  %1817 : Float(512:1, 128:512) = aten::t(%1816), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.129 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.166, %1817), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.129, %1815, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.69 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.42, %input.164, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1821 : Tensor = prim::GetAttr[name="bias"](%1813)
  %1822 : Tensor = prim::GetAttr[name="weight"](%1813)
  %1823 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.69, %1822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.167 : Float(17:1664, 13:128, 128:1) = aten::add(%1823, %1821, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1825 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24767.FFNOutput = prim::GetAttr[name="output"](%1708)
  %1826 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24764.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1708)
  %1827 : __torch__.torch.nn.modules.linear.___torch_mangle_24763.Linear = prim::GetAttr[name="dense"](%1826)
  %1828 : Tensor = prim::GetAttr[name="bias"](%1827)
  %1829 : Tensor = prim::GetAttr[name="weight"](%1827)
  %1830 : Float(128:1, 512:128) = aten::t(%1829), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.130 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.167, %1830), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.168 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.130, %1828, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.169 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1834 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24766.NoNorm = prim::GetAttr[name="LayerNorm"](%1825)
  %1835 : __torch__.torch.nn.modules.linear.___torch_mangle_24765.Linear = prim::GetAttr[name="dense"](%1825)
  %1836 : Tensor = prim::GetAttr[name="bias"](%1835)
  %1837 : Tensor = prim::GetAttr[name="weight"](%1835)
  %1838 : Float(512:1, 128:512) = aten::t(%1837), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.131 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.169, %1838), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.131, %1836, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.70 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.43, %input.167, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1842 : Tensor = prim::GetAttr[name="bias"](%1834)
  %1843 : Tensor = prim::GetAttr[name="weight"](%1834)
  %1844 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.70, %1843), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.170 : Float(17:1664, 13:128, 128:1) = aten::add(%1844, %1842, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1846 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24773.FFNOutput = prim::GetAttr[name="output"](%1706)
  %1847 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24770.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1706)
  %1848 : __torch__.torch.nn.modules.linear.___torch_mangle_24769.Linear = prim::GetAttr[name="dense"](%1847)
  %1849 : Tensor = prim::GetAttr[name="bias"](%1848)
  %1850 : Tensor = prim::GetAttr[name="weight"](%1848)
  %1851 : Float(128:1, 512:128) = aten::t(%1850), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.132 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.170, %1851), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.171 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.132, %1849, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.172 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1855 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24772.NoNorm = prim::GetAttr[name="LayerNorm"](%1846)
  %1856 : __torch__.torch.nn.modules.linear.___torch_mangle_24771.Linear = prim::GetAttr[name="dense"](%1846)
  %1857 : Tensor = prim::GetAttr[name="bias"](%1856)
  %1858 : Tensor = prim::GetAttr[name="weight"](%1856)
  %1859 : Float(512:1, 128:512) = aten::t(%1858), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.133 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.172, %1859), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.44 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.133, %1857, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.71 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.44, %input.170, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1863 : Tensor = prim::GetAttr[name="bias"](%1855)
  %1864 : Tensor = prim::GetAttr[name="weight"](%1855)
  %1865 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.71, %1864), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.173 : Float(17:1664, 13:128, 128:1) = aten::add(%1865, %1863, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1867 : __torch__.torch.nn.modules.linear.___torch_mangle_24741.Linear = prim::GetAttr[name="dense"](%1704)
  %1868 : Tensor = prim::GetAttr[name="bias"](%1867)
  %1869 : Tensor = prim::GetAttr[name="weight"](%1867)
  %1870 : Float(128:1, 512:128) = aten::t(%1869), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %output.134 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.173, %1870), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %input.174 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.134, %1868, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1678:0
  %input.175 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate # torch/nn/functional.py:1119:0
  %1874 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24748.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1703)
  %1875 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24744.NoNorm = prim::GetAttr[name="LayerNorm"](%1703)
  %1876 : __torch__.torch.nn.modules.linear.___torch_mangle_24743.Linear = prim::GetAttr[name="dense"](%1703)
  %1877 : Tensor = prim::GetAttr[name="bias"](%1876)
  %1878 : Tensor = prim::GetAttr[name="weight"](%1876)
  %1879 : Float(512:1, 128:512) = aten::t(%1878), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %output.135 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.175, %1879), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %layer_output.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.135, %1877, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.72 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.9, %input.173, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output # transformers/modeling_mobilebert.py:405:0
  %1883 : Tensor = prim::GetAttr[name="bias"](%1875)
  %1884 : Tensor = prim::GetAttr[name="weight"](%1875)
  %1885 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.72, %1884), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.176 : Float(17:1664, 13:128, 128:1) = aten::add(%1885, %1883, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1887 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24746.NoNorm = prim::GetAttr[name="LayerNorm"](%1874)
  %1888 : __torch__.torch.nn.modules.linear.___torch_mangle_24745.Linear = prim::GetAttr[name="dense"](%1874)
  %1889 : Tensor = prim::GetAttr[name="bias"](%1888)
  %1890 : Tensor = prim::GetAttr[name="weight"](%1888)
  %1891 : Float(128:1, 512:128) = aten::t(%1890), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.136 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.176, %1891), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.177 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.136, %1889, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.45 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.177, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.73 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.45, %input.159, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1896 : Tensor = prim::GetAttr[name="bias"](%1887)
  %1897 : Tensor = prim::GetAttr[name="weight"](%1887)
  %1898 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.73, %1897), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.178 : Float(17:6656, 13:512, 512:1) = aten::add(%1898, %1896, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1900 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24794.MobileBertOutput = prim::GetAttr[name="output"](%108)
  %1901 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24787.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%108)
  %1902 : __torch__.torch.nn.modules.container.___torch_mangle_24820.ModuleList = prim::GetAttr[name="ffn"](%108)
  %1903 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24819.FFNLayer = prim::GetAttr[name="2"](%1902)
  %1904 : __torch__.torch.nn.modules.container.___torch_mangle_24820.ModuleList = prim::GetAttr[name="ffn"](%108)
  %1905 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24813.FFNLayer = prim::GetAttr[name="1"](%1904)
  %1906 : __torch__.torch.nn.modules.container.___torch_mangle_24820.ModuleList = prim::GetAttr[name="ffn"](%108)
  %1907 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24807.FFNLayer = prim::GetAttr[name="0"](%1906)
  %1908 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24785.MobileBertAttention = prim::GetAttr[name="attention"](%108)
  %1909 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24801.Bottleneck = prim::GetAttr[name="bottleneck"](%108)
  %1910 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24800.BottleneckLayer = prim::GetAttr[name="attention"](%1909)
  %1911 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24797.BottleneckLayer = prim::GetAttr[name="input"](%1909)
  %1912 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24796.NoNorm = prim::GetAttr[name="LayerNorm"](%1911)
  %1913 : __torch__.torch.nn.modules.linear.___torch_mangle_24795.Linear = prim::GetAttr[name="dense"](%1911)
  %1914 : Tensor = prim::GetAttr[name="bias"](%1913)
  %1915 : Tensor = prim::GetAttr[name="weight"](%1913)
  %1916 : Float(512:1, 128:512) = aten::t(%1915), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.137 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1916), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.137, %1914, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1919 : Tensor = prim::GetAttr[name="bias"](%1912)
  %1920 : Tensor = prim::GetAttr[name="weight"](%1912)
  %1921 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.74, %1920), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add(%1921, %1919, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1923 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24799.NoNorm = prim::GetAttr[name="LayerNorm"](%1910)
  %1924 : __torch__.torch.nn.modules.linear.___torch_mangle_24798.Linear = prim::GetAttr[name="dense"](%1910)
  %1925 : Tensor = prim::GetAttr[name="bias"](%1924)
  %1926 : Tensor = prim::GetAttr[name="weight"](%1924)
  %1927 : Float(512:1, 128:512) = aten::t(%1926), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.138 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1927), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.138, %1925, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1930 : Tensor = prim::GetAttr[name="bias"](%1923)
  %1931 : Tensor = prim::GetAttr[name="weight"](%1923)
  %1932 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.75, %1931), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.179 : Float(17:1664, 13:128, 128:1) = aten::add(%1932, %1930, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1934 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.179, %residual_tensor.10)
  %1935 : Float(17:1664, 13:128, 128:1), %1936 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1934)
  %1937 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24784.MobileBertSelfOutput = prim::GetAttr[name="output"](%1908)
  %1938 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24781.MobileBertSelfAttention = prim::GetAttr[name="self"](%1908)
  %1939 : __torch__.torch.nn.modules.linear.___torch_mangle_24779.Linear = prim::GetAttr[name="value"](%1938)
  %1940 : __torch__.torch.nn.modules.linear.___torch_mangle_24778.Linear = prim::GetAttr[name="key"](%1938)
  %1941 : __torch__.torch.nn.modules.linear.___torch_mangle_24777.Linear = prim::GetAttr[name="query"](%1938)
  %1942 : Tensor = prim::GetAttr[name="bias"](%1941)
  %1943 : Tensor = prim::GetAttr[name="weight"](%1941)
  %1944 : Float(128:1, 128:128) = aten::t(%1943), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %output.139 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1935, %1944), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %x.55 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.139, %1942, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1678:0
  %1947 : Tensor = prim::GetAttr[name="bias"](%1940)
  %1948 : Tensor = prim::GetAttr[name="weight"](%1940)
  %1949 : Float(128:1, 128:128) = aten::t(%1948), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %output.140 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1935, %1949), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %x.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.140, %1947, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1678:0
  %1952 : Tensor = prim::GetAttr[name="bias"](%1939)
  %1953 : Tensor = prim::GetAttr[name="weight"](%1939)
  %1954 : Float(512:1, 128:512) = aten::t(%1953), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %output.141 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1954), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %x.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.141, %1952, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1678:0
  %1957 : int = aten::size(%x.55, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1958 : int = aten::size(%x.55, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1959 : int[] = prim::ListConstruct(%1957, %1958, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.56 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.55, %1959), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1961 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %query_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.56, %1961), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1963 : int = aten::size(%x.57, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1964 : int = aten::size(%x.57, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1965 : int[] = prim::ListConstruct(%1963, %1964, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.58 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.57, %1965), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1967 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %key_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.58, %1967), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1969 : int = aten::size(%x.59, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1970 : int = aten::size(%x.59, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1971 : int[] = prim::ListConstruct(%1969, %1970, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.60 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.59, %1971), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1973 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %value_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.60, %1973), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1975 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.10, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.10, %1975), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.19, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.180 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.20, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.181 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.180, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.181, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.19 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.10, %value_layer.10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:280:0
  %1982 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %1983 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.19, %1982), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1983, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %1985 : int = aten::size(%context_layer.20, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1986 : int = aten::size(%context_layer.20, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1987 : int[] = prim::ListConstruct(%1985, %1986, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %input.182 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.20, %1987), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:283:0
  %1989 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24783.NoNorm = prim::GetAttr[name="LayerNorm"](%1937)
  %1990 : __torch__.torch.nn.modules.linear.___torch_mangle_24782.Linear = prim::GetAttr[name="dense"](%1937)
  %1991 : Tensor = prim::GetAttr[name="bias"](%1990)
  %1992 : Tensor = prim::GetAttr[name="weight"](%1990)
  %1993 : Float(128:1, 128:128) = aten::t(%1992), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %output.142 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.182, %1993), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.46 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.142, %1991, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.76 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.46, %1936, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output # transformers/modeling_mobilebert.py:301:0
  %1997 : Tensor = prim::GetAttr[name="bias"](%1989)
  %1998 : Tensor = prim::GetAttr[name="weight"](%1989)
  %1999 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.76, %1998), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.183 : Float(17:1664, 13:128, 128:1) = aten::add(%1999, %1997, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2001 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24806.FFNOutput = prim::GetAttr[name="output"](%1907)
  %2002 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24803.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1907)
  %2003 : __torch__.torch.nn.modules.linear.___torch_mangle_24802.Linear = prim::GetAttr[name="dense"](%2002)
  %2004 : Tensor = prim::GetAttr[name="bias"](%2003)
  %2005 : Tensor = prim::GetAttr[name="weight"](%2003)
  %2006 : Float(128:1, 512:128) = aten::t(%2005), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.143 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.183, %2006), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.184 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.143, %2004, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.185 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2010 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24805.NoNorm = prim::GetAttr[name="LayerNorm"](%2001)
  %2011 : __torch__.torch.nn.modules.linear.___torch_mangle_24804.Linear = prim::GetAttr[name="dense"](%2001)
  %2012 : Tensor = prim::GetAttr[name="bias"](%2011)
  %2013 : Tensor = prim::GetAttr[name="weight"](%2011)
  %2014 : Float(512:1, 128:512) = aten::t(%2013), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.144 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.185, %2014), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.144, %2012, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.77 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.47, %input.183, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2018 : Tensor = prim::GetAttr[name="bias"](%2010)
  %2019 : Tensor = prim::GetAttr[name="weight"](%2010)
  %2020 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.77, %2019), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.186 : Float(17:1664, 13:128, 128:1) = aten::add(%2020, %2018, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2022 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24812.FFNOutput = prim::GetAttr[name="output"](%1905)
  %2023 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24809.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1905)
  %2024 : __torch__.torch.nn.modules.linear.___torch_mangle_24808.Linear = prim::GetAttr[name="dense"](%2023)
  %2025 : Tensor = prim::GetAttr[name="bias"](%2024)
  %2026 : Tensor = prim::GetAttr[name="weight"](%2024)
  %2027 : Float(128:1, 512:128) = aten::t(%2026), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.145 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.186, %2027), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.187 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.145, %2025, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.188 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2031 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24811.NoNorm = prim::GetAttr[name="LayerNorm"](%2022)
  %2032 : __torch__.torch.nn.modules.linear.___torch_mangle_24810.Linear = prim::GetAttr[name="dense"](%2022)
  %2033 : Tensor = prim::GetAttr[name="bias"](%2032)
  %2034 : Tensor = prim::GetAttr[name="weight"](%2032)
  %2035 : Float(512:1, 128:512) = aten::t(%2034), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.146 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.188, %2035), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.48 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.146, %2033, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.78 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.48, %input.186, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2039 : Tensor = prim::GetAttr[name="bias"](%2031)
  %2040 : Tensor = prim::GetAttr[name="weight"](%2031)
  %2041 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.78, %2040), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.189 : Float(17:1664, 13:128, 128:1) = aten::add(%2041, %2039, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2043 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24818.FFNOutput = prim::GetAttr[name="output"](%1903)
  %2044 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24815.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1903)
  %2045 : __torch__.torch.nn.modules.linear.___torch_mangle_24814.Linear = prim::GetAttr[name="dense"](%2044)
  %2046 : Tensor = prim::GetAttr[name="bias"](%2045)
  %2047 : Tensor = prim::GetAttr[name="weight"](%2045)
  %2048 : Float(128:1, 512:128) = aten::t(%2047), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.147 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.189, %2048), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.190 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.147, %2046, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.191 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2052 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24817.NoNorm = prim::GetAttr[name="LayerNorm"](%2043)
  %2053 : __torch__.torch.nn.modules.linear.___torch_mangle_24816.Linear = prim::GetAttr[name="dense"](%2043)
  %2054 : Tensor = prim::GetAttr[name="bias"](%2053)
  %2055 : Tensor = prim::GetAttr[name="weight"](%2053)
  %2056 : Float(512:1, 128:512) = aten::t(%2055), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.148 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.191, %2056), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.148, %2054, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.79 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.49, %input.189, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2060 : Tensor = prim::GetAttr[name="bias"](%2052)
  %2061 : Tensor = prim::GetAttr[name="weight"](%2052)
  %2062 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.79, %2061), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.192 : Float(17:1664, 13:128, 128:1) = aten::add(%2062, %2060, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2064 : __torch__.torch.nn.modules.linear.___torch_mangle_24786.Linear = prim::GetAttr[name="dense"](%1901)
  %2065 : Tensor = prim::GetAttr[name="bias"](%2064)
  %2066 : Tensor = prim::GetAttr[name="weight"](%2064)
  %2067 : Float(128:1, 512:128) = aten::t(%2066), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %output.149 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.192, %2067), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %input.193 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.149, %2065, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1678:0
  %input.194 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate # torch/nn/functional.py:1119:0
  %2071 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24793.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1900)
  %2072 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24789.NoNorm = prim::GetAttr[name="LayerNorm"](%1900)
  %2073 : __torch__.torch.nn.modules.linear.___torch_mangle_24788.Linear = prim::GetAttr[name="dense"](%1900)
  %2074 : Tensor = prim::GetAttr[name="bias"](%2073)
  %2075 : Tensor = prim::GetAttr[name="weight"](%2073)
  %2076 : Float(512:1, 128:512) = aten::t(%2075), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %output.150 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.194, %2076), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %layer_output.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.150, %2074, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.80 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.10, %input.192, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output # transformers/modeling_mobilebert.py:405:0
  %2080 : Tensor = prim::GetAttr[name="bias"](%2072)
  %2081 : Tensor = prim::GetAttr[name="weight"](%2072)
  %2082 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.80, %2081), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.195 : Float(17:1664, 13:128, 128:1) = aten::add(%2082, %2080, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2084 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24791.NoNorm = prim::GetAttr[name="LayerNorm"](%2071)
  %2085 : __torch__.torch.nn.modules.linear.___torch_mangle_24790.Linear = prim::GetAttr[name="dense"](%2071)
  %2086 : Tensor = prim::GetAttr[name="bias"](%2085)
  %2087 : Tensor = prim::GetAttr[name="weight"](%2085)
  %2088 : Float(128:1, 512:128) = aten::t(%2087), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.151 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.195, %2088), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.196 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.151, %2086, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.50 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.196, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.81 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.50, %input.178, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2093 : Tensor = prim::GetAttr[name="bias"](%2084)
  %2094 : Tensor = prim::GetAttr[name="weight"](%2084)
  %2095 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.81, %2094), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.197 : Float(17:6656, 13:512, 512:1) = aten::add(%2095, %2093, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2097 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24839.MobileBertOutput = prim::GetAttr[name="output"](%106)
  %2098 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24832.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%106)
  %2099 : __torch__.torch.nn.modules.container.___torch_mangle_24865.ModuleList = prim::GetAttr[name="ffn"](%106)
  %2100 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24864.FFNLayer = prim::GetAttr[name="2"](%2099)
  %2101 : __torch__.torch.nn.modules.container.___torch_mangle_24865.ModuleList = prim::GetAttr[name="ffn"](%106)
  %2102 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24858.FFNLayer = prim::GetAttr[name="1"](%2101)
  %2103 : __torch__.torch.nn.modules.container.___torch_mangle_24865.ModuleList = prim::GetAttr[name="ffn"](%106)
  %2104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24852.FFNLayer = prim::GetAttr[name="0"](%2103)
  %2105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24830.MobileBertAttention = prim::GetAttr[name="attention"](%106)
  %2106 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24846.Bottleneck = prim::GetAttr[name="bottleneck"](%106)
  %2107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24845.BottleneckLayer = prim::GetAttr[name="attention"](%2106)
  %2108 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24842.BottleneckLayer = prim::GetAttr[name="input"](%2106)
  %2109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24841.NoNorm = prim::GetAttr[name="LayerNorm"](%2108)
  %2110 : __torch__.torch.nn.modules.linear.___torch_mangle_24840.Linear = prim::GetAttr[name="dense"](%2108)
  %2111 : Tensor = prim::GetAttr[name="bias"](%2110)
  %2112 : Tensor = prim::GetAttr[name="weight"](%2110)
  %2113 : Float(512:1, 128:512) = aten::t(%2112), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.152 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2113), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.152, %2111, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2116 : Tensor = prim::GetAttr[name="bias"](%2109)
  %2117 : Tensor = prim::GetAttr[name="weight"](%2109)
  %2118 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.82, %2117), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add(%2118, %2116, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24844.NoNorm = prim::GetAttr[name="LayerNorm"](%2107)
  %2121 : __torch__.torch.nn.modules.linear.___torch_mangle_24843.Linear = prim::GetAttr[name="dense"](%2107)
  %2122 : Tensor = prim::GetAttr[name="bias"](%2121)
  %2123 : Tensor = prim::GetAttr[name="weight"](%2121)
  %2124 : Float(512:1, 128:512) = aten::t(%2123), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.153 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2124), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.153, %2122, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2127 : Tensor = prim::GetAttr[name="bias"](%2120)
  %2128 : Tensor = prim::GetAttr[name="weight"](%2120)
  %2129 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.83, %2128), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.198 : Float(17:1664, 13:128, 128:1) = aten::add(%2129, %2127, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2131 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.198, %residual_tensor.11)
  %2132 : Float(17:1664, 13:128, 128:1), %2133 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2131)
  %2134 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24829.MobileBertSelfOutput = prim::GetAttr[name="output"](%2105)
  %2135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24826.MobileBertSelfAttention = prim::GetAttr[name="self"](%2105)
  %2136 : __torch__.torch.nn.modules.linear.___torch_mangle_24824.Linear = prim::GetAttr[name="value"](%2135)
  %2137 : __torch__.torch.nn.modules.linear.___torch_mangle_24823.Linear = prim::GetAttr[name="key"](%2135)
  %2138 : __torch__.torch.nn.modules.linear.___torch_mangle_24822.Linear = prim::GetAttr[name="query"](%2135)
  %2139 : Tensor = prim::GetAttr[name="bias"](%2138)
  %2140 : Tensor = prim::GetAttr[name="weight"](%2138)
  %2141 : Float(128:1, 128:128) = aten::t(%2140), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %output.154 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2132, %2141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %x.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.154, %2139, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1678:0
  %2144 : Tensor = prim::GetAttr[name="bias"](%2137)
  %2145 : Tensor = prim::GetAttr[name="weight"](%2137)
  %2146 : Float(128:1, 128:128) = aten::t(%2145), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %output.155 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2132, %2146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %x.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.155, %2144, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1678:0
  %2149 : Tensor = prim::GetAttr[name="bias"](%2136)
  %2150 : Tensor = prim::GetAttr[name="weight"](%2136)
  %2151 : Float(512:1, 128:512) = aten::t(%2150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %output.156 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2151), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %x.65 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.156, %2149, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1678:0
  %2154 : int = aten::size(%x.61, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2155 : int = aten::size(%x.61, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2156 : int[] = prim::ListConstruct(%2154, %2155, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.62 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.61, %2156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2158 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %query_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.62, %2158), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2160 : int = aten::size(%x.63, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2161 : int = aten::size(%x.63, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2162 : int[] = prim::ListConstruct(%2160, %2161, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.64 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.63, %2162), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2164 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %key_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.64, %2164), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2166 : int = aten::size(%x.65, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2167 : int = aten::size(%x.65, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2168 : int[] = prim::ListConstruct(%2166, %2167, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.66 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.65, %2168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2170 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %value_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.66, %2170), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2172 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.11, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.11, %2172), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.21, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.199 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.22, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.200 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.199, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.200, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.21 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.11, %value_layer.11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:280:0
  %2179 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %2180 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.21, %2179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2180, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %2182 : int = aten::size(%context_layer.22, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2183 : int = aten::size(%context_layer.22, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2184 : int[] = prim::ListConstruct(%2182, %2183, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %input.201 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.22, %2184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:283:0
  %2186 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24828.NoNorm = prim::GetAttr[name="LayerNorm"](%2134)
  %2187 : __torch__.torch.nn.modules.linear.___torch_mangle_24827.Linear = prim::GetAttr[name="dense"](%2134)
  %2188 : Tensor = prim::GetAttr[name="bias"](%2187)
  %2189 : Tensor = prim::GetAttr[name="weight"](%2187)
  %2190 : Float(128:1, 128:128) = aten::t(%2189), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %output.157 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.201, %2190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.157, %2188, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.84 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.51, %2133, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output # transformers/modeling_mobilebert.py:301:0
  %2194 : Tensor = prim::GetAttr[name="bias"](%2186)
  %2195 : Tensor = prim::GetAttr[name="weight"](%2186)
  %2196 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.84, %2195), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.202 : Float(17:1664, 13:128, 128:1) = aten::add(%2196, %2194, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2198 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24851.FFNOutput = prim::GetAttr[name="output"](%2104)
  %2199 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24848.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2104)
  %2200 : __torch__.torch.nn.modules.linear.___torch_mangle_24847.Linear = prim::GetAttr[name="dense"](%2199)
  %2201 : Tensor = prim::GetAttr[name="bias"](%2200)
  %2202 : Tensor = prim::GetAttr[name="weight"](%2200)
  %2203 : Float(128:1, 512:128) = aten::t(%2202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.158 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.202, %2203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.203 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.158, %2201, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.204 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2207 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24850.NoNorm = prim::GetAttr[name="LayerNorm"](%2198)
  %2208 : __torch__.torch.nn.modules.linear.___torch_mangle_24849.Linear = prim::GetAttr[name="dense"](%2198)
  %2209 : Tensor = prim::GetAttr[name="bias"](%2208)
  %2210 : Tensor = prim::GetAttr[name="weight"](%2208)
  %2211 : Float(512:1, 128:512) = aten::t(%2210), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.159 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.204, %2211), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.52 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.159, %2209, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.85 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.52, %input.202, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2215 : Tensor = prim::GetAttr[name="bias"](%2207)
  %2216 : Tensor = prim::GetAttr[name="weight"](%2207)
  %2217 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.85, %2216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.205 : Float(17:1664, 13:128, 128:1) = aten::add(%2217, %2215, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2219 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24857.FFNOutput = prim::GetAttr[name="output"](%2102)
  %2220 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24854.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2102)
  %2221 : __torch__.torch.nn.modules.linear.___torch_mangle_24853.Linear = prim::GetAttr[name="dense"](%2220)
  %2222 : Tensor = prim::GetAttr[name="bias"](%2221)
  %2223 : Tensor = prim::GetAttr[name="weight"](%2221)
  %2224 : Float(128:1, 512:128) = aten::t(%2223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.160 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.205, %2224), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.206 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.160, %2222, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.207 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2228 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24856.NoNorm = prim::GetAttr[name="LayerNorm"](%2219)
  %2229 : __torch__.torch.nn.modules.linear.___torch_mangle_24855.Linear = prim::GetAttr[name="dense"](%2219)
  %2230 : Tensor = prim::GetAttr[name="bias"](%2229)
  %2231 : Tensor = prim::GetAttr[name="weight"](%2229)
  %2232 : Float(512:1, 128:512) = aten::t(%2231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.161 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.207, %2232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.161, %2230, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.86 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.53, %input.205, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2236 : Tensor = prim::GetAttr[name="bias"](%2228)
  %2237 : Tensor = prim::GetAttr[name="weight"](%2228)
  %2238 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.86, %2237), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.208 : Float(17:1664, 13:128, 128:1) = aten::add(%2238, %2236, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2240 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24863.FFNOutput = prim::GetAttr[name="output"](%2100)
  %2241 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24860.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2100)
  %2242 : __torch__.torch.nn.modules.linear.___torch_mangle_24859.Linear = prim::GetAttr[name="dense"](%2241)
  %2243 : Tensor = prim::GetAttr[name="bias"](%2242)
  %2244 : Tensor = prim::GetAttr[name="weight"](%2242)
  %2245 : Float(128:1, 512:128) = aten::t(%2244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.162 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.208, %2245), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.209 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.162, %2243, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.210 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2249 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24862.NoNorm = prim::GetAttr[name="LayerNorm"](%2240)
  %2250 : __torch__.torch.nn.modules.linear.___torch_mangle_24861.Linear = prim::GetAttr[name="dense"](%2240)
  %2251 : Tensor = prim::GetAttr[name="bias"](%2250)
  %2252 : Tensor = prim::GetAttr[name="weight"](%2250)
  %2253 : Float(512:1, 128:512) = aten::t(%2252), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.163 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.210, %2253), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.54 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.163, %2251, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.87 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.54, %input.208, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2257 : Tensor = prim::GetAttr[name="bias"](%2249)
  %2258 : Tensor = prim::GetAttr[name="weight"](%2249)
  %2259 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.87, %2258), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.211 : Float(17:1664, 13:128, 128:1) = aten::add(%2259, %2257, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2261 : __torch__.torch.nn.modules.linear.___torch_mangle_24831.Linear = prim::GetAttr[name="dense"](%2098)
  %2262 : Tensor = prim::GetAttr[name="bias"](%2261)
  %2263 : Tensor = prim::GetAttr[name="weight"](%2261)
  %2264 : Float(128:1, 512:128) = aten::t(%2263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %output.164 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.211, %2264), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %input.212 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.164, %2262, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1678:0
  %input.213 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate # torch/nn/functional.py:1119:0
  %2268 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24838.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2097)
  %2269 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24834.NoNorm = prim::GetAttr[name="LayerNorm"](%2097)
  %2270 : __torch__.torch.nn.modules.linear.___torch_mangle_24833.Linear = prim::GetAttr[name="dense"](%2097)
  %2271 : Tensor = prim::GetAttr[name="bias"](%2270)
  %2272 : Tensor = prim::GetAttr[name="weight"](%2270)
  %2273 : Float(512:1, 128:512) = aten::t(%2272), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %output.165 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.213, %2273), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %layer_output.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.165, %2271, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.88 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.11, %input.211, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output # transformers/modeling_mobilebert.py:405:0
  %2277 : Tensor = prim::GetAttr[name="bias"](%2269)
  %2278 : Tensor = prim::GetAttr[name="weight"](%2269)
  %2279 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.88, %2278), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.214 : Float(17:1664, 13:128, 128:1) = aten::add(%2279, %2277, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2281 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24836.NoNorm = prim::GetAttr[name="LayerNorm"](%2268)
  %2282 : __torch__.torch.nn.modules.linear.___torch_mangle_24835.Linear = prim::GetAttr[name="dense"](%2268)
  %2283 : Tensor = prim::GetAttr[name="bias"](%2282)
  %2284 : Tensor = prim::GetAttr[name="weight"](%2282)
  %2285 : Float(128:1, 512:128) = aten::t(%2284), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.166 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.214, %2285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.215 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.166, %2283, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.55 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.215, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.89 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.55, %input.197, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2290 : Tensor = prim::GetAttr[name="bias"](%2281)
  %2291 : Tensor = prim::GetAttr[name="weight"](%2281)
  %2292 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.89, %2291), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.216 : Float(17:6656, 13:512, 512:1) = aten::add(%2292, %2290, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2294 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24884.MobileBertOutput = prim::GetAttr[name="output"](%104)
  %2295 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24877.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%104)
  %2296 : __torch__.torch.nn.modules.container.___torch_mangle_24910.ModuleList = prim::GetAttr[name="ffn"](%104)
  %2297 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24909.FFNLayer = prim::GetAttr[name="2"](%2296)
  %2298 : __torch__.torch.nn.modules.container.___torch_mangle_24910.ModuleList = prim::GetAttr[name="ffn"](%104)
  %2299 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24903.FFNLayer = prim::GetAttr[name="1"](%2298)
  %2300 : __torch__.torch.nn.modules.container.___torch_mangle_24910.ModuleList = prim::GetAttr[name="ffn"](%104)
  %2301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24897.FFNLayer = prim::GetAttr[name="0"](%2300)
  %2302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24875.MobileBertAttention = prim::GetAttr[name="attention"](%104)
  %2303 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24891.Bottleneck = prim::GetAttr[name="bottleneck"](%104)
  %2304 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24890.BottleneckLayer = prim::GetAttr[name="attention"](%2303)
  %2305 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24887.BottleneckLayer = prim::GetAttr[name="input"](%2303)
  %2306 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24886.NoNorm = prim::GetAttr[name="LayerNorm"](%2305)
  %2307 : __torch__.torch.nn.modules.linear.___torch_mangle_24885.Linear = prim::GetAttr[name="dense"](%2305)
  %2308 : Tensor = prim::GetAttr[name="bias"](%2307)
  %2309 : Tensor = prim::GetAttr[name="weight"](%2307)
  %2310 : Float(512:1, 128:512) = aten::t(%2309), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.167 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2310), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.90 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.167, %2308, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2313 : Tensor = prim::GetAttr[name="bias"](%2306)
  %2314 : Tensor = prim::GetAttr[name="weight"](%2306)
  %2315 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.90, %2314), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%2315, %2313, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2317 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24889.NoNorm = prim::GetAttr[name="LayerNorm"](%2304)
  %2318 : __torch__.torch.nn.modules.linear.___torch_mangle_24888.Linear = prim::GetAttr[name="dense"](%2304)
  %2319 : Tensor = prim::GetAttr[name="bias"](%2318)
  %2320 : Tensor = prim::GetAttr[name="weight"](%2318)
  %2321 : Float(512:1, 128:512) = aten::t(%2320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.168 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.168, %2319, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2324 : Tensor = prim::GetAttr[name="bias"](%2317)
  %2325 : Tensor = prim::GetAttr[name="weight"](%2317)
  %2326 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.91, %2325), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.217 : Float(17:1664, 13:128, 128:1) = aten::add(%2326, %2324, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2328 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.217, %residual_tensor.12)
  %2329 : Float(17:1664, 13:128, 128:1), %2330 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2328)
  %2331 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24874.MobileBertSelfOutput = prim::GetAttr[name="output"](%2302)
  %2332 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24871.MobileBertSelfAttention = prim::GetAttr[name="self"](%2302)
  %2333 : __torch__.torch.nn.modules.linear.___torch_mangle_24869.Linear = prim::GetAttr[name="value"](%2332)
  %2334 : __torch__.torch.nn.modules.linear.___torch_mangle_24868.Linear = prim::GetAttr[name="key"](%2332)
  %2335 : __torch__.torch.nn.modules.linear.___torch_mangle_24867.Linear = prim::GetAttr[name="query"](%2332)
  %2336 : Tensor = prim::GetAttr[name="bias"](%2335)
  %2337 : Tensor = prim::GetAttr[name="weight"](%2335)
  %2338 : Float(128:1, 128:128) = aten::t(%2337), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %output.169 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2329, %2338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %x.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.169, %2336, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1678:0
  %2341 : Tensor = prim::GetAttr[name="bias"](%2334)
  %2342 : Tensor = prim::GetAttr[name="weight"](%2334)
  %2343 : Float(128:1, 128:128) = aten::t(%2342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %output.170 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2329, %2343), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %x.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.170, %2341, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1678:0
  %2346 : Tensor = prim::GetAttr[name="bias"](%2333)
  %2347 : Tensor = prim::GetAttr[name="weight"](%2333)
  %2348 : Float(512:1, 128:512) = aten::t(%2347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %output.171 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2348), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %x.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.171, %2346, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1678:0
  %2351 : int = aten::size(%x.67, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2352 : int = aten::size(%x.67, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2353 : int[] = prim::ListConstruct(%2351, %2352, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.68 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.67, %2353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2355 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %query_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.68, %2355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2357 : int = aten::size(%x.69, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2358 : int = aten::size(%x.69, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2359 : int[] = prim::ListConstruct(%2357, %2358, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.70 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.69, %2359), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2361 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %key_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.70, %2361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2363 : int = aten::size(%x.71, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2364 : int = aten::size(%x.71, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2365 : int[] = prim::ListConstruct(%2363, %2364, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.72 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.71, %2365), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2367 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %value_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.72, %2367), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2369 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.12, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.12, %2369), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.24 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.23, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.218 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.24, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.219 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.218, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.219, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.23 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.12, %value_layer.12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:280:0
  %2376 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %2377 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.23, %2376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2377, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %2379 : int = aten::size(%context_layer.24, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2380 : int = aten::size(%context_layer.24, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2381 : int[] = prim::ListConstruct(%2379, %2380, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %input.220 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.24, %2381), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:283:0
  %2383 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24873.NoNorm = prim::GetAttr[name="LayerNorm"](%2331)
  %2384 : __torch__.torch.nn.modules.linear.___torch_mangle_24872.Linear = prim::GetAttr[name="dense"](%2331)
  %2385 : Tensor = prim::GetAttr[name="bias"](%2384)
  %2386 : Tensor = prim::GetAttr[name="weight"](%2384)
  %2387 : Float(128:1, 128:128) = aten::t(%2386), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %output.172 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.220, %2387), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.56 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.172, %2385, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.92 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.56, %2330, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output # transformers/modeling_mobilebert.py:301:0
  %2391 : Tensor = prim::GetAttr[name="bias"](%2383)
  %2392 : Tensor = prim::GetAttr[name="weight"](%2383)
  %2393 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.92, %2392), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.221 : Float(17:1664, 13:128, 128:1) = aten::add(%2393, %2391, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2395 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24896.FFNOutput = prim::GetAttr[name="output"](%2301)
  %2396 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24893.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2301)
  %2397 : __torch__.torch.nn.modules.linear.___torch_mangle_24892.Linear = prim::GetAttr[name="dense"](%2396)
  %2398 : Tensor = prim::GetAttr[name="bias"](%2397)
  %2399 : Tensor = prim::GetAttr[name="weight"](%2397)
  %2400 : Float(128:1, 512:128) = aten::t(%2399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.173 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.221, %2400), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.222 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.173, %2398, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.223 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2404 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24895.NoNorm = prim::GetAttr[name="LayerNorm"](%2395)
  %2405 : __torch__.torch.nn.modules.linear.___torch_mangle_24894.Linear = prim::GetAttr[name="dense"](%2395)
  %2406 : Tensor = prim::GetAttr[name="bias"](%2405)
  %2407 : Tensor = prim::GetAttr[name="weight"](%2405)
  %2408 : Float(512:1, 128:512) = aten::t(%2407), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.174 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.223, %2408), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.174, %2406, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.93 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.57, %input.221, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2412 : Tensor = prim::GetAttr[name="bias"](%2404)
  %2413 : Tensor = prim::GetAttr[name="weight"](%2404)
  %2414 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.93, %2413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.224 : Float(17:1664, 13:128, 128:1) = aten::add(%2414, %2412, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2416 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24902.FFNOutput = prim::GetAttr[name="output"](%2299)
  %2417 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24899.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2299)
  %2418 : __torch__.torch.nn.modules.linear.___torch_mangle_24898.Linear = prim::GetAttr[name="dense"](%2417)
  %2419 : Tensor = prim::GetAttr[name="bias"](%2418)
  %2420 : Tensor = prim::GetAttr[name="weight"](%2418)
  %2421 : Float(128:1, 512:128) = aten::t(%2420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.175 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.224, %2421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.225 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.175, %2419, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.226 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2425 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24901.NoNorm = prim::GetAttr[name="LayerNorm"](%2416)
  %2426 : __torch__.torch.nn.modules.linear.___torch_mangle_24900.Linear = prim::GetAttr[name="dense"](%2416)
  %2427 : Tensor = prim::GetAttr[name="bias"](%2426)
  %2428 : Tensor = prim::GetAttr[name="weight"](%2426)
  %2429 : Float(512:1, 128:512) = aten::t(%2428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.176 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.226, %2429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.176, %2427, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.94 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.58, %input.224, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2433 : Tensor = prim::GetAttr[name="bias"](%2425)
  %2434 : Tensor = prim::GetAttr[name="weight"](%2425)
  %2435 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.94, %2434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.227 : Float(17:1664, 13:128, 128:1) = aten::add(%2435, %2433, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2437 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24908.FFNOutput = prim::GetAttr[name="output"](%2297)
  %2438 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24905.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2297)
  %2439 : __torch__.torch.nn.modules.linear.___torch_mangle_24904.Linear = prim::GetAttr[name="dense"](%2438)
  %2440 : Tensor = prim::GetAttr[name="bias"](%2439)
  %2441 : Tensor = prim::GetAttr[name="weight"](%2439)
  %2442 : Float(128:1, 512:128) = aten::t(%2441), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.177 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.227, %2442), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.228 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.177, %2440, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.229 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2446 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24907.NoNorm = prim::GetAttr[name="LayerNorm"](%2437)
  %2447 : __torch__.torch.nn.modules.linear.___torch_mangle_24906.Linear = prim::GetAttr[name="dense"](%2437)
  %2448 : Tensor = prim::GetAttr[name="bias"](%2447)
  %2449 : Tensor = prim::GetAttr[name="weight"](%2447)
  %2450 : Float(512:1, 128:512) = aten::t(%2449), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.178 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.229, %2450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.178, %2448, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.95 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.59, %input.227, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2454 : Tensor = prim::GetAttr[name="bias"](%2446)
  %2455 : Tensor = prim::GetAttr[name="weight"](%2446)
  %2456 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.95, %2455), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.230 : Float(17:1664, 13:128, 128:1) = aten::add(%2456, %2454, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2458 : __torch__.torch.nn.modules.linear.___torch_mangle_24876.Linear = prim::GetAttr[name="dense"](%2295)
  %2459 : Tensor = prim::GetAttr[name="bias"](%2458)
  %2460 : Tensor = prim::GetAttr[name="weight"](%2458)
  %2461 : Float(128:1, 512:128) = aten::t(%2460), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %output.179 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.230, %2461), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %input.231 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.179, %2459, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1678:0
  %input.232 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate # torch/nn/functional.py:1119:0
  %2465 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24883.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2294)
  %2466 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24879.NoNorm = prim::GetAttr[name="LayerNorm"](%2294)
  %2467 : __torch__.torch.nn.modules.linear.___torch_mangle_24878.Linear = prim::GetAttr[name="dense"](%2294)
  %2468 : Tensor = prim::GetAttr[name="bias"](%2467)
  %2469 : Tensor = prim::GetAttr[name="weight"](%2467)
  %2470 : Float(512:1, 128:512) = aten::t(%2469), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %output.180 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.232, %2470), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %layer_output.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.180, %2468, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.96 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.12, %input.230, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output # transformers/modeling_mobilebert.py:405:0
  %2474 : Tensor = prim::GetAttr[name="bias"](%2466)
  %2475 : Tensor = prim::GetAttr[name="weight"](%2466)
  %2476 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.96, %2475), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.233 : Float(17:1664, 13:128, 128:1) = aten::add(%2476, %2474, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2478 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24881.NoNorm = prim::GetAttr[name="LayerNorm"](%2465)
  %2479 : __torch__.torch.nn.modules.linear.___torch_mangle_24880.Linear = prim::GetAttr[name="dense"](%2465)
  %2480 : Tensor = prim::GetAttr[name="bias"](%2479)
  %2481 : Tensor = prim::GetAttr[name="weight"](%2479)
  %2482 : Float(128:1, 512:128) = aten::t(%2481), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.181 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.233, %2482), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.234 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.181, %2480, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.60 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.234, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.97 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.60, %input.216, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2487 : Tensor = prim::GetAttr[name="bias"](%2478)
  %2488 : Tensor = prim::GetAttr[name="weight"](%2478)
  %2489 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.97, %2488), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.235 : Float(17:6656, 13:512, 512:1) = aten::add(%2489, %2487, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2491 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24929.MobileBertOutput = prim::GetAttr[name="output"](%102)
  %2492 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24922.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%102)
  %2493 : __torch__.torch.nn.modules.container.___torch_mangle_24955.ModuleList = prim::GetAttr[name="ffn"](%102)
  %2494 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24954.FFNLayer = prim::GetAttr[name="2"](%2493)
  %2495 : __torch__.torch.nn.modules.container.___torch_mangle_24955.ModuleList = prim::GetAttr[name="ffn"](%102)
  %2496 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24948.FFNLayer = prim::GetAttr[name="1"](%2495)
  %2497 : __torch__.torch.nn.modules.container.___torch_mangle_24955.ModuleList = prim::GetAttr[name="ffn"](%102)
  %2498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24942.FFNLayer = prim::GetAttr[name="0"](%2497)
  %2499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24920.MobileBertAttention = prim::GetAttr[name="attention"](%102)
  %2500 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24936.Bottleneck = prim::GetAttr[name="bottleneck"](%102)
  %2501 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24935.BottleneckLayer = prim::GetAttr[name="attention"](%2500)
  %2502 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24932.BottleneckLayer = prim::GetAttr[name="input"](%2500)
  %2503 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24931.NoNorm = prim::GetAttr[name="LayerNorm"](%2502)
  %2504 : __torch__.torch.nn.modules.linear.___torch_mangle_24930.Linear = prim::GetAttr[name="dense"](%2502)
  %2505 : Tensor = prim::GetAttr[name="bias"](%2504)
  %2506 : Tensor = prim::GetAttr[name="weight"](%2504)
  %2507 : Float(512:1, 128:512) = aten::t(%2506), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.182 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2507), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.182, %2505, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2510 : Tensor = prim::GetAttr[name="bias"](%2503)
  %2511 : Tensor = prim::GetAttr[name="weight"](%2503)
  %2512 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.98, %2511), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%2512, %2510, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2514 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24934.NoNorm = prim::GetAttr[name="LayerNorm"](%2501)
  %2515 : __torch__.torch.nn.modules.linear.___torch_mangle_24933.Linear = prim::GetAttr[name="dense"](%2501)
  %2516 : Tensor = prim::GetAttr[name="bias"](%2515)
  %2517 : Tensor = prim::GetAttr[name="weight"](%2515)
  %2518 : Float(512:1, 128:512) = aten::t(%2517), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.183 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.183, %2516, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2521 : Tensor = prim::GetAttr[name="bias"](%2514)
  %2522 : Tensor = prim::GetAttr[name="weight"](%2514)
  %2523 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.99, %2522), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.236 : Float(17:1664, 13:128, 128:1) = aten::add(%2523, %2521, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2525 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.236, %residual_tensor.13)
  %2526 : Float(17:1664, 13:128, 128:1), %2527 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2525)
  %2528 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24919.MobileBertSelfOutput = prim::GetAttr[name="output"](%2499)
  %2529 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24916.MobileBertSelfAttention = prim::GetAttr[name="self"](%2499)
  %2530 : __torch__.torch.nn.modules.linear.___torch_mangle_24914.Linear = prim::GetAttr[name="value"](%2529)
  %2531 : __torch__.torch.nn.modules.linear.___torch_mangle_24913.Linear = prim::GetAttr[name="key"](%2529)
  %2532 : __torch__.torch.nn.modules.linear.___torch_mangle_24912.Linear = prim::GetAttr[name="query"](%2529)
  %2533 : Tensor = prim::GetAttr[name="bias"](%2532)
  %2534 : Tensor = prim::GetAttr[name="weight"](%2532)
  %2535 : Float(128:1, 128:128) = aten::t(%2534), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %output.184 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2526, %2535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %x.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.184, %2533, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1678:0
  %2538 : Tensor = prim::GetAttr[name="bias"](%2531)
  %2539 : Tensor = prim::GetAttr[name="weight"](%2531)
  %2540 : Float(128:1, 128:128) = aten::t(%2539), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %output.185 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2526, %2540), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %x.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.185, %2538, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1678:0
  %2543 : Tensor = prim::GetAttr[name="bias"](%2530)
  %2544 : Tensor = prim::GetAttr[name="weight"](%2530)
  %2545 : Float(512:1, 128:512) = aten::t(%2544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %output.186 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2545), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %x.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.186, %2543, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1678:0
  %2548 : int = aten::size(%x.73, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2549 : int = aten::size(%x.73, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2550 : int[] = prim::ListConstruct(%2548, %2549, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.74 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.73, %2550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2552 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %query_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.74, %2552), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2554 : int = aten::size(%x.75, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2555 : int = aten::size(%x.75, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2556 : int[] = prim::ListConstruct(%2554, %2555, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.76 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.75, %2556), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2558 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %key_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.76, %2558), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2560 : int = aten::size(%x.77, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2561 : int = aten::size(%x.77, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2562 : int[] = prim::ListConstruct(%2560, %2561, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.78 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.77, %2562), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2564 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %value_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.78, %2564), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2566 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.13, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.25 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.13, %2566), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.26 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.25, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.237 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.26, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.238 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.237, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.238, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.25 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.13, %value_layer.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:280:0
  %2573 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %2574 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.25, %2573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2574, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %2576 : int = aten::size(%context_layer.26, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2577 : int = aten::size(%context_layer.26, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2578 : int[] = prim::ListConstruct(%2576, %2577, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %input.239 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.26, %2578), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:283:0
  %2580 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24918.NoNorm = prim::GetAttr[name="LayerNorm"](%2528)
  %2581 : __torch__.torch.nn.modules.linear.___torch_mangle_24917.Linear = prim::GetAttr[name="dense"](%2528)
  %2582 : Tensor = prim::GetAttr[name="bias"](%2581)
  %2583 : Tensor = prim::GetAttr[name="weight"](%2581)
  %2584 : Float(128:1, 128:128) = aten::t(%2583), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %output.187 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.239, %2584), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.187, %2582, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.100 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.61, %2527, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output # transformers/modeling_mobilebert.py:301:0
  %2588 : Tensor = prim::GetAttr[name="bias"](%2580)
  %2589 : Tensor = prim::GetAttr[name="weight"](%2580)
  %2590 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.100, %2589), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.240 : Float(17:1664, 13:128, 128:1) = aten::add(%2590, %2588, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2592 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24941.FFNOutput = prim::GetAttr[name="output"](%2498)
  %2593 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24938.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2498)
  %2594 : __torch__.torch.nn.modules.linear.___torch_mangle_24937.Linear = prim::GetAttr[name="dense"](%2593)
  %2595 : Tensor = prim::GetAttr[name="bias"](%2594)
  %2596 : Tensor = prim::GetAttr[name="weight"](%2594)
  %2597 : Float(128:1, 512:128) = aten::t(%2596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.188 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.240, %2597), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.241 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.188, %2595, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.242 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2601 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24940.NoNorm = prim::GetAttr[name="LayerNorm"](%2592)
  %2602 : __torch__.torch.nn.modules.linear.___torch_mangle_24939.Linear = prim::GetAttr[name="dense"](%2592)
  %2603 : Tensor = prim::GetAttr[name="bias"](%2602)
  %2604 : Tensor = prim::GetAttr[name="weight"](%2602)
  %2605 : Float(512:1, 128:512) = aten::t(%2604), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.189 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.242, %2605), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.62 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.189, %2603, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.101 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.62, %input.240, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2609 : Tensor = prim::GetAttr[name="bias"](%2601)
  %2610 : Tensor = prim::GetAttr[name="weight"](%2601)
  %2611 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.101, %2610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.243 : Float(17:1664, 13:128, 128:1) = aten::add(%2611, %2609, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2613 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24947.FFNOutput = prim::GetAttr[name="output"](%2496)
  %2614 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24944.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2496)
  %2615 : __torch__.torch.nn.modules.linear.___torch_mangle_24943.Linear = prim::GetAttr[name="dense"](%2614)
  %2616 : Tensor = prim::GetAttr[name="bias"](%2615)
  %2617 : Tensor = prim::GetAttr[name="weight"](%2615)
  %2618 : Float(128:1, 512:128) = aten::t(%2617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.190 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.243, %2618), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.244 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.190, %2616, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.245 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2622 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24946.NoNorm = prim::GetAttr[name="LayerNorm"](%2613)
  %2623 : __torch__.torch.nn.modules.linear.___torch_mangle_24945.Linear = prim::GetAttr[name="dense"](%2613)
  %2624 : Tensor = prim::GetAttr[name="bias"](%2623)
  %2625 : Tensor = prim::GetAttr[name="weight"](%2623)
  %2626 : Float(512:1, 128:512) = aten::t(%2625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.191 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.245, %2626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.191, %2624, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.102 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.63, %input.243, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2630 : Tensor = prim::GetAttr[name="bias"](%2622)
  %2631 : Tensor = prim::GetAttr[name="weight"](%2622)
  %2632 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.102, %2631), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.246 : Float(17:1664, 13:128, 128:1) = aten::add(%2632, %2630, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2634 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24953.FFNOutput = prim::GetAttr[name="output"](%2494)
  %2635 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24950.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2494)
  %2636 : __torch__.torch.nn.modules.linear.___torch_mangle_24949.Linear = prim::GetAttr[name="dense"](%2635)
  %2637 : Tensor = prim::GetAttr[name="bias"](%2636)
  %2638 : Tensor = prim::GetAttr[name="weight"](%2636)
  %2639 : Float(128:1, 512:128) = aten::t(%2638), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.192 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.246, %2639), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.247 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.192, %2637, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.248 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2643 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24952.NoNorm = prim::GetAttr[name="LayerNorm"](%2634)
  %2644 : __torch__.torch.nn.modules.linear.___torch_mangle_24951.Linear = prim::GetAttr[name="dense"](%2634)
  %2645 : Tensor = prim::GetAttr[name="bias"](%2644)
  %2646 : Tensor = prim::GetAttr[name="weight"](%2644)
  %2647 : Float(512:1, 128:512) = aten::t(%2646), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.193 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.248, %2647), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.64 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.193, %2645, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.103 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.64, %input.246, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2651 : Tensor = prim::GetAttr[name="bias"](%2643)
  %2652 : Tensor = prim::GetAttr[name="weight"](%2643)
  %2653 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.103, %2652), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.249 : Float(17:1664, 13:128, 128:1) = aten::add(%2653, %2651, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2655 : __torch__.torch.nn.modules.linear.___torch_mangle_24921.Linear = prim::GetAttr[name="dense"](%2492)
  %2656 : Tensor = prim::GetAttr[name="bias"](%2655)
  %2657 : Tensor = prim::GetAttr[name="weight"](%2655)
  %2658 : Float(128:1, 512:128) = aten::t(%2657), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %output.194 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.249, %2658), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %input.250 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.194, %2656, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1678:0
  %input.251 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate # torch/nn/functional.py:1119:0
  %2662 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24928.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2491)
  %2663 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24924.NoNorm = prim::GetAttr[name="LayerNorm"](%2491)
  %2664 : __torch__.torch.nn.modules.linear.___torch_mangle_24923.Linear = prim::GetAttr[name="dense"](%2491)
  %2665 : Tensor = prim::GetAttr[name="bias"](%2664)
  %2666 : Tensor = prim::GetAttr[name="weight"](%2664)
  %2667 : Float(512:1, 128:512) = aten::t(%2666), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %output.195 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.251, %2667), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %layer_output.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.195, %2665, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.104 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.13, %input.249, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output # transformers/modeling_mobilebert.py:405:0
  %2671 : Tensor = prim::GetAttr[name="bias"](%2663)
  %2672 : Tensor = prim::GetAttr[name="weight"](%2663)
  %2673 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.104, %2672), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.252 : Float(17:1664, 13:128, 128:1) = aten::add(%2673, %2671, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2675 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24926.NoNorm = prim::GetAttr[name="LayerNorm"](%2662)
  %2676 : __torch__.torch.nn.modules.linear.___torch_mangle_24925.Linear = prim::GetAttr[name="dense"](%2662)
  %2677 : Tensor = prim::GetAttr[name="bias"](%2676)
  %2678 : Tensor = prim::GetAttr[name="weight"](%2676)
  %2679 : Float(128:1, 512:128) = aten::t(%2678), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.196 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.252, %2679), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.253 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.196, %2677, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.65 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.253, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.105 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.65, %input.235, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2684 : Tensor = prim::GetAttr[name="bias"](%2675)
  %2685 : Tensor = prim::GetAttr[name="weight"](%2675)
  %2686 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.105, %2685), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.254 : Float(17:6656, 13:512, 512:1) = aten::add(%2686, %2684, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2688 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24974.MobileBertOutput = prim::GetAttr[name="output"](%100)
  %2689 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24967.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%100)
  %2690 : __torch__.torch.nn.modules.container.___torch_mangle_25000.ModuleList = prim::GetAttr[name="ffn"](%100)
  %2691 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24999.FFNLayer = prim::GetAttr[name="2"](%2690)
  %2692 : __torch__.torch.nn.modules.container.___torch_mangle_25000.ModuleList = prim::GetAttr[name="ffn"](%100)
  %2693 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24993.FFNLayer = prim::GetAttr[name="1"](%2692)
  %2694 : __torch__.torch.nn.modules.container.___torch_mangle_25000.ModuleList = prim::GetAttr[name="ffn"](%100)
  %2695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24987.FFNLayer = prim::GetAttr[name="0"](%2694)
  %2696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24965.MobileBertAttention = prim::GetAttr[name="attention"](%100)
  %2697 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24981.Bottleneck = prim::GetAttr[name="bottleneck"](%100)
  %2698 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24980.BottleneckLayer = prim::GetAttr[name="attention"](%2697)
  %2699 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24977.BottleneckLayer = prim::GetAttr[name="input"](%2697)
  %2700 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24976.NoNorm = prim::GetAttr[name="LayerNorm"](%2699)
  %2701 : __torch__.torch.nn.modules.linear.___torch_mangle_24975.Linear = prim::GetAttr[name="dense"](%2699)
  %2702 : Tensor = prim::GetAttr[name="bias"](%2701)
  %2703 : Tensor = prim::GetAttr[name="weight"](%2701)
  %2704 : Float(512:1, 128:512) = aten::t(%2703), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.197 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2704), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.197, %2702, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2707 : Tensor = prim::GetAttr[name="bias"](%2700)
  %2708 : Tensor = prim::GetAttr[name="weight"](%2700)
  %2709 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.106, %2708), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%2709, %2707, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2711 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24979.NoNorm = prim::GetAttr[name="LayerNorm"](%2698)
  %2712 : __torch__.torch.nn.modules.linear.___torch_mangle_24978.Linear = prim::GetAttr[name="dense"](%2698)
  %2713 : Tensor = prim::GetAttr[name="bias"](%2712)
  %2714 : Tensor = prim::GetAttr[name="weight"](%2712)
  %2715 : Float(512:1, 128:512) = aten::t(%2714), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.198 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.198, %2713, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2718 : Tensor = prim::GetAttr[name="bias"](%2711)
  %2719 : Tensor = prim::GetAttr[name="weight"](%2711)
  %2720 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.107, %2719), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.255 : Float(17:1664, 13:128, 128:1) = aten::add(%2720, %2718, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2722 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.255, %residual_tensor.14)
  %2723 : Float(17:1664, 13:128, 128:1), %2724 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2722)
  %2725 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24964.MobileBertSelfOutput = prim::GetAttr[name="output"](%2696)
  %2726 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24961.MobileBertSelfAttention = prim::GetAttr[name="self"](%2696)
  %2727 : __torch__.torch.nn.modules.linear.___torch_mangle_24959.Linear = prim::GetAttr[name="value"](%2726)
  %2728 : __torch__.torch.nn.modules.linear.___torch_mangle_24958.Linear = prim::GetAttr[name="key"](%2726)
  %2729 : __torch__.torch.nn.modules.linear.___torch_mangle_24957.Linear = prim::GetAttr[name="query"](%2726)
  %2730 : Tensor = prim::GetAttr[name="bias"](%2729)
  %2731 : Tensor = prim::GetAttr[name="weight"](%2729)
  %2732 : Float(128:1, 128:128) = aten::t(%2731), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %output.199 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2723, %2732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %x.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.199, %2730, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1678:0
  %2735 : Tensor = prim::GetAttr[name="bias"](%2728)
  %2736 : Tensor = prim::GetAttr[name="weight"](%2728)
  %2737 : Float(128:1, 128:128) = aten::t(%2736), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %output.200 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2723, %2737), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %x.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.200, %2735, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1678:0
  %2740 : Tensor = prim::GetAttr[name="bias"](%2727)
  %2741 : Tensor = prim::GetAttr[name="weight"](%2727)
  %2742 : Float(512:1, 128:512) = aten::t(%2741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %output.201 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2742), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %x.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.201, %2740, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1678:0
  %2745 : int = aten::size(%x.79, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2746 : int = aten::size(%x.79, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2747 : int[] = prim::ListConstruct(%2745, %2746, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.80 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.79, %2747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2749 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %query_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.80, %2749), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2751 : int = aten::size(%x.81, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2752 : int = aten::size(%x.81, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2753 : int[] = prim::ListConstruct(%2751, %2752, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.82 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.81, %2753), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2755 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %key_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.82, %2755), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2757 : int = aten::size(%x.83, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2758 : int = aten::size(%x.83, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2759 : int[] = prim::ListConstruct(%2757, %2758, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.84 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.83, %2759), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2761 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %value_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.84, %2761), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2763 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.14, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.27 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.14, %2763), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.27, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.256 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.28, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.257 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.256, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.257, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.27 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.14, %value_layer.14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:280:0
  %2770 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %2771 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.27, %2770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2771, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %2773 : int = aten::size(%context_layer.28, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2774 : int = aten::size(%context_layer.28, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2775 : int[] = prim::ListConstruct(%2773, %2774, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %input.258 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.28, %2775), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:283:0
  %2777 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24963.NoNorm = prim::GetAttr[name="LayerNorm"](%2725)
  %2778 : __torch__.torch.nn.modules.linear.___torch_mangle_24962.Linear = prim::GetAttr[name="dense"](%2725)
  %2779 : Tensor = prim::GetAttr[name="bias"](%2778)
  %2780 : Tensor = prim::GetAttr[name="weight"](%2778)
  %2781 : Float(128:1, 128:128) = aten::t(%2780), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %output.202 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.258, %2781), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.202, %2779, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.108 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.66, %2724, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output # transformers/modeling_mobilebert.py:301:0
  %2785 : Tensor = prim::GetAttr[name="bias"](%2777)
  %2786 : Tensor = prim::GetAttr[name="weight"](%2777)
  %2787 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.108, %2786), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.259 : Float(17:1664, 13:128, 128:1) = aten::add(%2787, %2785, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2789 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24986.FFNOutput = prim::GetAttr[name="output"](%2695)
  %2790 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24983.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2695)
  %2791 : __torch__.torch.nn.modules.linear.___torch_mangle_24982.Linear = prim::GetAttr[name="dense"](%2790)
  %2792 : Tensor = prim::GetAttr[name="bias"](%2791)
  %2793 : Tensor = prim::GetAttr[name="weight"](%2791)
  %2794 : Float(128:1, 512:128) = aten::t(%2793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.203 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.259, %2794), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.260 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.203, %2792, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.261 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2798 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24985.NoNorm = prim::GetAttr[name="LayerNorm"](%2789)
  %2799 : __torch__.torch.nn.modules.linear.___torch_mangle_24984.Linear = prim::GetAttr[name="dense"](%2789)
  %2800 : Tensor = prim::GetAttr[name="bias"](%2799)
  %2801 : Tensor = prim::GetAttr[name="weight"](%2799)
  %2802 : Float(512:1, 128:512) = aten::t(%2801), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.204 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.261, %2802), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.204, %2800, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.109 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.67, %input.259, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2806 : Tensor = prim::GetAttr[name="bias"](%2798)
  %2807 : Tensor = prim::GetAttr[name="weight"](%2798)
  %2808 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.109, %2807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.262 : Float(17:1664, 13:128, 128:1) = aten::add(%2808, %2806, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2810 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24992.FFNOutput = prim::GetAttr[name="output"](%2693)
  %2811 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24989.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2693)
  %2812 : __torch__.torch.nn.modules.linear.___torch_mangle_24988.Linear = prim::GetAttr[name="dense"](%2811)
  %2813 : Tensor = prim::GetAttr[name="bias"](%2812)
  %2814 : Tensor = prim::GetAttr[name="weight"](%2812)
  %2815 : Float(128:1, 512:128) = aten::t(%2814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.205 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.262, %2815), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.263 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.205, %2813, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.264 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2819 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24991.NoNorm = prim::GetAttr[name="LayerNorm"](%2810)
  %2820 : __torch__.torch.nn.modules.linear.___torch_mangle_24990.Linear = prim::GetAttr[name="dense"](%2810)
  %2821 : Tensor = prim::GetAttr[name="bias"](%2820)
  %2822 : Tensor = prim::GetAttr[name="weight"](%2820)
  %2823 : Float(512:1, 128:512) = aten::t(%2822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.206 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.264, %2823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.68 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.206, %2821, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.110 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.68, %input.262, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2827 : Tensor = prim::GetAttr[name="bias"](%2819)
  %2828 : Tensor = prim::GetAttr[name="weight"](%2819)
  %2829 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.110, %2828), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.265 : Float(17:1664, 13:128, 128:1) = aten::add(%2829, %2827, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2831 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24998.FFNOutput = prim::GetAttr[name="output"](%2691)
  %2832 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24995.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2691)
  %2833 : __torch__.torch.nn.modules.linear.___torch_mangle_24994.Linear = prim::GetAttr[name="dense"](%2832)
  %2834 : Tensor = prim::GetAttr[name="bias"](%2833)
  %2835 : Tensor = prim::GetAttr[name="weight"](%2833)
  %2836 : Float(128:1, 512:128) = aten::t(%2835), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.207 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.265, %2836), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.266 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.207, %2834, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.267 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2840 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24997.NoNorm = prim::GetAttr[name="LayerNorm"](%2831)
  %2841 : __torch__.torch.nn.modules.linear.___torch_mangle_24996.Linear = prim::GetAttr[name="dense"](%2831)
  %2842 : Tensor = prim::GetAttr[name="bias"](%2841)
  %2843 : Tensor = prim::GetAttr[name="weight"](%2841)
  %2844 : Float(512:1, 128:512) = aten::t(%2843), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.208 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.267, %2844), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.208, %2842, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.111 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.69, %input.265, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2848 : Tensor = prim::GetAttr[name="bias"](%2840)
  %2849 : Tensor = prim::GetAttr[name="weight"](%2840)
  %2850 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.111, %2849), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.268 : Float(17:1664, 13:128, 128:1) = aten::add(%2850, %2848, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2852 : __torch__.torch.nn.modules.linear.___torch_mangle_24966.Linear = prim::GetAttr[name="dense"](%2689)
  %2853 : Tensor = prim::GetAttr[name="bias"](%2852)
  %2854 : Tensor = prim::GetAttr[name="weight"](%2852)
  %2855 : Float(128:1, 512:128) = aten::t(%2854), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %output.209 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.268, %2855), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %input.269 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.209, %2853, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1678:0
  %input.270 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate # torch/nn/functional.py:1119:0
  %2859 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24973.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2688)
  %2860 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24969.NoNorm = prim::GetAttr[name="LayerNorm"](%2688)
  %2861 : __torch__.torch.nn.modules.linear.___torch_mangle_24968.Linear = prim::GetAttr[name="dense"](%2688)
  %2862 : Tensor = prim::GetAttr[name="bias"](%2861)
  %2863 : Tensor = prim::GetAttr[name="weight"](%2861)
  %2864 : Float(512:1, 128:512) = aten::t(%2863), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %output.210 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.270, %2864), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %layer_output.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.210, %2862, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.112 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.14, %input.268, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output # transformers/modeling_mobilebert.py:405:0
  %2868 : Tensor = prim::GetAttr[name="bias"](%2860)
  %2869 : Tensor = prim::GetAttr[name="weight"](%2860)
  %2870 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.112, %2869), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.271 : Float(17:1664, 13:128, 128:1) = aten::add(%2870, %2868, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2872 : __torch__.transformers.modeling_mobilebert.___torch_mangle_24971.NoNorm = prim::GetAttr[name="LayerNorm"](%2859)
  %2873 : __torch__.torch.nn.modules.linear.___torch_mangle_24970.Linear = prim::GetAttr[name="dense"](%2859)
  %2874 : Tensor = prim::GetAttr[name="bias"](%2873)
  %2875 : Tensor = prim::GetAttr[name="weight"](%2873)
  %2876 : Float(128:1, 512:128) = aten::t(%2875), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.211 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.271, %2876), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.272 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.211, %2874, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.70 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.272, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.113 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.70, %input.254, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2881 : Tensor = prim::GetAttr[name="bias"](%2872)
  %2882 : Tensor = prim::GetAttr[name="weight"](%2872)
  %2883 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.113, %2882), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.273 : Float(17:6656, 13:512, 512:1) = aten::add(%2883, %2881, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2885 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25019.MobileBertOutput = prim::GetAttr[name="output"](%98)
  %2886 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25012.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%98)
  %2887 : __torch__.torch.nn.modules.container.___torch_mangle_25045.ModuleList = prim::GetAttr[name="ffn"](%98)
  %2888 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25044.FFNLayer = prim::GetAttr[name="2"](%2887)
  %2889 : __torch__.torch.nn.modules.container.___torch_mangle_25045.ModuleList = prim::GetAttr[name="ffn"](%98)
  %2890 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25038.FFNLayer = prim::GetAttr[name="1"](%2889)
  %2891 : __torch__.torch.nn.modules.container.___torch_mangle_25045.ModuleList = prim::GetAttr[name="ffn"](%98)
  %2892 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25032.FFNLayer = prim::GetAttr[name="0"](%2891)
  %2893 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25010.MobileBertAttention = prim::GetAttr[name="attention"](%98)
  %2894 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25026.Bottleneck = prim::GetAttr[name="bottleneck"](%98)
  %2895 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25025.BottleneckLayer = prim::GetAttr[name="attention"](%2894)
  %2896 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25022.BottleneckLayer = prim::GetAttr[name="input"](%2894)
  %2897 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25021.NoNorm = prim::GetAttr[name="LayerNorm"](%2896)
  %2898 : __torch__.torch.nn.modules.linear.___torch_mangle_25020.Linear = prim::GetAttr[name="dense"](%2896)
  %2899 : Tensor = prim::GetAttr[name="bias"](%2898)
  %2900 : Tensor = prim::GetAttr[name="weight"](%2898)
  %2901 : Float(512:1, 128:512) = aten::t(%2900), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.212 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2901), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.212, %2899, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2904 : Tensor = prim::GetAttr[name="bias"](%2897)
  %2905 : Tensor = prim::GetAttr[name="weight"](%2897)
  %2906 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.114, %2905), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%2906, %2904, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2908 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25024.NoNorm = prim::GetAttr[name="LayerNorm"](%2895)
  %2909 : __torch__.torch.nn.modules.linear.___torch_mangle_25023.Linear = prim::GetAttr[name="dense"](%2895)
  %2910 : Tensor = prim::GetAttr[name="bias"](%2909)
  %2911 : Tensor = prim::GetAttr[name="weight"](%2909)
  %2912 : Float(512:1, 128:512) = aten::t(%2911), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.213 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2912), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.213, %2910, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2915 : Tensor = prim::GetAttr[name="bias"](%2908)
  %2916 : Tensor = prim::GetAttr[name="weight"](%2908)
  %2917 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.115, %2916), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.274 : Float(17:1664, 13:128, 128:1) = aten::add(%2917, %2915, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2919 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.274, %residual_tensor.15)
  %2920 : Float(17:1664, 13:128, 128:1), %2921 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2919)
  %2922 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25009.MobileBertSelfOutput = prim::GetAttr[name="output"](%2893)
  %2923 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25006.MobileBertSelfAttention = prim::GetAttr[name="self"](%2893)
  %2924 : __torch__.torch.nn.modules.linear.___torch_mangle_25004.Linear = prim::GetAttr[name="value"](%2923)
  %2925 : __torch__.torch.nn.modules.linear.___torch_mangle_25003.Linear = prim::GetAttr[name="key"](%2923)
  %2926 : __torch__.torch.nn.modules.linear.___torch_mangle_25002.Linear = prim::GetAttr[name="query"](%2923)
  %2927 : Tensor = prim::GetAttr[name="bias"](%2926)
  %2928 : Tensor = prim::GetAttr[name="weight"](%2926)
  %2929 : Float(128:1, 128:128) = aten::t(%2928), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %output.214 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2920, %2929), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %x.85 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.214, %2927, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1678:0
  %2932 : Tensor = prim::GetAttr[name="bias"](%2925)
  %2933 : Tensor = prim::GetAttr[name="weight"](%2925)
  %2934 : Float(128:1, 128:128) = aten::t(%2933), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %output.215 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2920, %2934), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %x.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.215, %2932, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1678:0
  %2937 : Tensor = prim::GetAttr[name="bias"](%2924)
  %2938 : Tensor = prim::GetAttr[name="weight"](%2924)
  %2939 : Float(512:1, 128:512) = aten::t(%2938), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %output.216 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2939), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %x.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.216, %2937, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1678:0
  %2942 : int = aten::size(%x.85, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2943 : int = aten::size(%x.85, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2944 : int[] = prim::ListConstruct(%2942, %2943, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.86 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.85, %2944), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2946 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %query_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.86, %2946), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2948 : int = aten::size(%x.87, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2949 : int = aten::size(%x.87, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2950 : int[] = prim::ListConstruct(%2948, %2949, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.88 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.87, %2950), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2952 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %key_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.88, %2952), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2954 : int = aten::size(%x.89, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2955 : int = aten::size(%x.89, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2956 : int[] = prim::ListConstruct(%2954, %2955, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.90 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.89, %2956), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2958 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %value_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.90, %2958), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2960 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.15, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.15, %2960), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.30 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.29, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.275 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.30, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.276 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.275, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.276, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.29 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.15, %value_layer.15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:280:0
  %2967 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %2968 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.29, %2967), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2968, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %2970 : int = aten::size(%context_layer.30, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2971 : int = aten::size(%context_layer.30, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2972 : int[] = prim::ListConstruct(%2970, %2971, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %input.277 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.30, %2972), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:283:0
  %2974 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25008.NoNorm = prim::GetAttr[name="LayerNorm"](%2922)
  %2975 : __torch__.torch.nn.modules.linear.___torch_mangle_25007.Linear = prim::GetAttr[name="dense"](%2922)
  %2976 : Tensor = prim::GetAttr[name="bias"](%2975)
  %2977 : Tensor = prim::GetAttr[name="weight"](%2975)
  %2978 : Float(128:1, 128:128) = aten::t(%2977), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %output.217 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.277, %2978), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.217, %2976, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.116 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.71, %2921, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output # transformers/modeling_mobilebert.py:301:0
  %2982 : Tensor = prim::GetAttr[name="bias"](%2974)
  %2983 : Tensor = prim::GetAttr[name="weight"](%2974)
  %2984 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.116, %2983), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.278 : Float(17:1664, 13:128, 128:1) = aten::add(%2984, %2982, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2986 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25031.FFNOutput = prim::GetAttr[name="output"](%2892)
  %2987 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25028.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2892)
  %2988 : __torch__.torch.nn.modules.linear.___torch_mangle_25027.Linear = prim::GetAttr[name="dense"](%2987)
  %2989 : Tensor = prim::GetAttr[name="bias"](%2988)
  %2990 : Tensor = prim::GetAttr[name="weight"](%2988)
  %2991 : Float(128:1, 512:128) = aten::t(%2990), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.218 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.278, %2991), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.279 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.218, %2989, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.280 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2995 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25030.NoNorm = prim::GetAttr[name="LayerNorm"](%2986)
  %2996 : __torch__.torch.nn.modules.linear.___torch_mangle_25029.Linear = prim::GetAttr[name="dense"](%2986)
  %2997 : Tensor = prim::GetAttr[name="bias"](%2996)
  %2998 : Tensor = prim::GetAttr[name="weight"](%2996)
  %2999 : Float(512:1, 128:512) = aten::t(%2998), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.219 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.280, %2999), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.72 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.219, %2997, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.117 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.72, %input.278, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3003 : Tensor = prim::GetAttr[name="bias"](%2995)
  %3004 : Tensor = prim::GetAttr[name="weight"](%2995)
  %3005 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.117, %3004), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.281 : Float(17:1664, 13:128, 128:1) = aten::add(%3005, %3003, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3007 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25037.FFNOutput = prim::GetAttr[name="output"](%2890)
  %3008 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25034.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2890)
  %3009 : __torch__.torch.nn.modules.linear.___torch_mangle_25033.Linear = prim::GetAttr[name="dense"](%3008)
  %3010 : Tensor = prim::GetAttr[name="bias"](%3009)
  %3011 : Tensor = prim::GetAttr[name="weight"](%3009)
  %3012 : Float(128:1, 512:128) = aten::t(%3011), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.220 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.281, %3012), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.282 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.220, %3010, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.283 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3016 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25036.NoNorm = prim::GetAttr[name="LayerNorm"](%3007)
  %3017 : __torch__.torch.nn.modules.linear.___torch_mangle_25035.Linear = prim::GetAttr[name="dense"](%3007)
  %3018 : Tensor = prim::GetAttr[name="bias"](%3017)
  %3019 : Tensor = prim::GetAttr[name="weight"](%3017)
  %3020 : Float(512:1, 128:512) = aten::t(%3019), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.221 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.283, %3020), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.221, %3018, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.118 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.73, %input.281, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3024 : Tensor = prim::GetAttr[name="bias"](%3016)
  %3025 : Tensor = prim::GetAttr[name="weight"](%3016)
  %3026 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.118, %3025), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.284 : Float(17:1664, 13:128, 128:1) = aten::add(%3026, %3024, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3028 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25043.FFNOutput = prim::GetAttr[name="output"](%2888)
  %3029 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25040.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2888)
  %3030 : __torch__.torch.nn.modules.linear.___torch_mangle_25039.Linear = prim::GetAttr[name="dense"](%3029)
  %3031 : Tensor = prim::GetAttr[name="bias"](%3030)
  %3032 : Tensor = prim::GetAttr[name="weight"](%3030)
  %3033 : Float(128:1, 512:128) = aten::t(%3032), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.222 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.284, %3033), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.285 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.222, %3031, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.286 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3037 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25042.NoNorm = prim::GetAttr[name="LayerNorm"](%3028)
  %3038 : __torch__.torch.nn.modules.linear.___torch_mangle_25041.Linear = prim::GetAttr[name="dense"](%3028)
  %3039 : Tensor = prim::GetAttr[name="bias"](%3038)
  %3040 : Tensor = prim::GetAttr[name="weight"](%3038)
  %3041 : Float(512:1, 128:512) = aten::t(%3040), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.223 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.286, %3041), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.223, %3039, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.119 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.74, %input.284, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3045 : Tensor = prim::GetAttr[name="bias"](%3037)
  %3046 : Tensor = prim::GetAttr[name="weight"](%3037)
  %3047 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.119, %3046), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.287 : Float(17:1664, 13:128, 128:1) = aten::add(%3047, %3045, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3049 : __torch__.torch.nn.modules.linear.___torch_mangle_25011.Linear = prim::GetAttr[name="dense"](%2886)
  %3050 : Tensor = prim::GetAttr[name="bias"](%3049)
  %3051 : Tensor = prim::GetAttr[name="weight"](%3049)
  %3052 : Float(128:1, 512:128) = aten::t(%3051), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %output.224 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.287, %3052), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %input.288 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.224, %3050, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1678:0
  %input.289 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate # torch/nn/functional.py:1119:0
  %3056 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25018.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2885)
  %3057 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25014.NoNorm = prim::GetAttr[name="LayerNorm"](%2885)
  %3058 : __torch__.torch.nn.modules.linear.___torch_mangle_25013.Linear = prim::GetAttr[name="dense"](%2885)
  %3059 : Tensor = prim::GetAttr[name="bias"](%3058)
  %3060 : Tensor = prim::GetAttr[name="weight"](%3058)
  %3061 : Float(512:1, 128:512) = aten::t(%3060), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %output.225 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.289, %3061), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %layer_output.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.225, %3059, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.120 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.15, %input.287, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output # transformers/modeling_mobilebert.py:405:0
  %3065 : Tensor = prim::GetAttr[name="bias"](%3057)
  %3066 : Tensor = prim::GetAttr[name="weight"](%3057)
  %3067 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.120, %3066), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.290 : Float(17:1664, 13:128, 128:1) = aten::add(%3067, %3065, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3069 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25016.NoNorm = prim::GetAttr[name="LayerNorm"](%3056)
  %3070 : __torch__.torch.nn.modules.linear.___torch_mangle_25015.Linear = prim::GetAttr[name="dense"](%3056)
  %3071 : Tensor = prim::GetAttr[name="bias"](%3070)
  %3072 : Tensor = prim::GetAttr[name="weight"](%3070)
  %3073 : Float(128:1, 512:128) = aten::t(%3072), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.226 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.290, %3073), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.291 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.226, %3071, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.75 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.291, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.121 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.75, %input.273, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3078 : Tensor = prim::GetAttr[name="bias"](%3069)
  %3079 : Tensor = prim::GetAttr[name="weight"](%3069)
  %3080 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.121, %3079), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.292 : Float(17:6656, 13:512, 512:1) = aten::add(%3080, %3078, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3082 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25064.MobileBertOutput = prim::GetAttr[name="output"](%96)
  %3083 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25057.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%96)
  %3084 : __torch__.torch.nn.modules.container.___torch_mangle_25090.ModuleList = prim::GetAttr[name="ffn"](%96)
  %3085 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25089.FFNLayer = prim::GetAttr[name="2"](%3084)
  %3086 : __torch__.torch.nn.modules.container.___torch_mangle_25090.ModuleList = prim::GetAttr[name="ffn"](%96)
  %3087 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25083.FFNLayer = prim::GetAttr[name="1"](%3086)
  %3088 : __torch__.torch.nn.modules.container.___torch_mangle_25090.ModuleList = prim::GetAttr[name="ffn"](%96)
  %3089 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25077.FFNLayer = prim::GetAttr[name="0"](%3088)
  %3090 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25055.MobileBertAttention = prim::GetAttr[name="attention"](%96)
  %3091 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25071.Bottleneck = prim::GetAttr[name="bottleneck"](%96)
  %3092 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25070.BottleneckLayer = prim::GetAttr[name="attention"](%3091)
  %3093 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25067.BottleneckLayer = prim::GetAttr[name="input"](%3091)
  %3094 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25066.NoNorm = prim::GetAttr[name="LayerNorm"](%3093)
  %3095 : __torch__.torch.nn.modules.linear.___torch_mangle_25065.Linear = prim::GetAttr[name="dense"](%3093)
  %3096 : Tensor = prim::GetAttr[name="bias"](%3095)
  %3097 : Tensor = prim::GetAttr[name="weight"](%3095)
  %3098 : Float(512:1, 128:512) = aten::t(%3097), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.227 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3098), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.122 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.227, %3096, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3101 : Tensor = prim::GetAttr[name="bias"](%3094)
  %3102 : Tensor = prim::GetAttr[name="weight"](%3094)
  %3103 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.122, %3102), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%3103, %3101, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25069.NoNorm = prim::GetAttr[name="LayerNorm"](%3092)
  %3106 : __torch__.torch.nn.modules.linear.___torch_mangle_25068.Linear = prim::GetAttr[name="dense"](%3092)
  %3107 : Tensor = prim::GetAttr[name="bias"](%3106)
  %3108 : Tensor = prim::GetAttr[name="weight"](%3106)
  %3109 : Float(512:1, 128:512) = aten::t(%3108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.228 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3109), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.228, %3107, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3112 : Tensor = prim::GetAttr[name="bias"](%3105)
  %3113 : Tensor = prim::GetAttr[name="weight"](%3105)
  %3114 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.123, %3113), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.293 : Float(17:1664, 13:128, 128:1) = aten::add(%3114, %3112, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3116 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.293, %residual_tensor.16)
  %3117 : Float(17:1664, 13:128, 128:1), %3118 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3116)
  %3119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25054.MobileBertSelfOutput = prim::GetAttr[name="output"](%3090)
  %3120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25051.MobileBertSelfAttention = prim::GetAttr[name="self"](%3090)
  %3121 : __torch__.torch.nn.modules.linear.___torch_mangle_25049.Linear = prim::GetAttr[name="value"](%3120)
  %3122 : __torch__.torch.nn.modules.linear.___torch_mangle_25048.Linear = prim::GetAttr[name="key"](%3120)
  %3123 : __torch__.torch.nn.modules.linear.___torch_mangle_25047.Linear = prim::GetAttr[name="query"](%3120)
  %3124 : Tensor = prim::GetAttr[name="bias"](%3123)
  %3125 : Tensor = prim::GetAttr[name="weight"](%3123)
  %3126 : Float(128:1, 128:128) = aten::t(%3125), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %output.229 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3117, %3126), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %x.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.229, %3124, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1678:0
  %3129 : Tensor = prim::GetAttr[name="bias"](%3122)
  %3130 : Tensor = prim::GetAttr[name="weight"](%3122)
  %3131 : Float(128:1, 128:128) = aten::t(%3130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %output.230 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3117, %3131), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %x.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.230, %3129, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1678:0
  %3134 : Tensor = prim::GetAttr[name="bias"](%3121)
  %3135 : Tensor = prim::GetAttr[name="weight"](%3121)
  %3136 : Float(512:1, 128:512) = aten::t(%3135), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %output.231 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3136), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %x.95 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.231, %3134, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1678:0
  %3139 : int = aten::size(%x.91, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3140 : int = aten::size(%x.91, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3141 : int[] = prim::ListConstruct(%3139, %3140, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.92 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.91, %3141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3143 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %query_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.92, %3143), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3145 : int = aten::size(%x.93, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3146 : int = aten::size(%x.93, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3147 : int[] = prim::ListConstruct(%3145, %3146, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.94 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.93, %3147), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3149 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %key_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.94, %3149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3151 : int = aten::size(%x.95, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3152 : int = aten::size(%x.95, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3153 : int[] = prim::ListConstruct(%3151, %3152, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.96 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.95, %3153), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3155 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %value_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.96, %3155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3157 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.16, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.31 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.16, %3157), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.32 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.31, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.294 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.32, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.295 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.294, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.295, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.31 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.16, %value_layer.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:280:0
  %3164 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %3165 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.31, %3164), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3165, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %3167 : int = aten::size(%context_layer.32, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3168 : int = aten::size(%context_layer.32, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3169 : int[] = prim::ListConstruct(%3167, %3168, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %input.296 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.32, %3169), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:283:0
  %3171 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25053.NoNorm = prim::GetAttr[name="LayerNorm"](%3119)
  %3172 : __torch__.torch.nn.modules.linear.___torch_mangle_25052.Linear = prim::GetAttr[name="dense"](%3119)
  %3173 : Tensor = prim::GetAttr[name="bias"](%3172)
  %3174 : Tensor = prim::GetAttr[name="weight"](%3172)
  %3175 : Float(128:1, 128:128) = aten::t(%3174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %output.232 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.296, %3175), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.76 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.232, %3173, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.124 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.76, %3118, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output # transformers/modeling_mobilebert.py:301:0
  %3179 : Tensor = prim::GetAttr[name="bias"](%3171)
  %3180 : Tensor = prim::GetAttr[name="weight"](%3171)
  %3181 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.124, %3180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.297 : Float(17:1664, 13:128, 128:1) = aten::add(%3181, %3179, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3183 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25076.FFNOutput = prim::GetAttr[name="output"](%3089)
  %3184 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25073.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3089)
  %3185 : __torch__.torch.nn.modules.linear.___torch_mangle_25072.Linear = prim::GetAttr[name="dense"](%3184)
  %3186 : Tensor = prim::GetAttr[name="bias"](%3185)
  %3187 : Tensor = prim::GetAttr[name="weight"](%3185)
  %3188 : Float(128:1, 512:128) = aten::t(%3187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.233 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.297, %3188), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.298 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.233, %3186, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.299 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3192 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25075.NoNorm = prim::GetAttr[name="LayerNorm"](%3183)
  %3193 : __torch__.torch.nn.modules.linear.___torch_mangle_25074.Linear = prim::GetAttr[name="dense"](%3183)
  %3194 : Tensor = prim::GetAttr[name="bias"](%3193)
  %3195 : Tensor = prim::GetAttr[name="weight"](%3193)
  %3196 : Float(512:1, 128:512) = aten::t(%3195), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.234 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.299, %3196), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.234, %3194, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.125 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.77, %input.297, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3200 : Tensor = prim::GetAttr[name="bias"](%3192)
  %3201 : Tensor = prim::GetAttr[name="weight"](%3192)
  %3202 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.125, %3201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.300 : Float(17:1664, 13:128, 128:1) = aten::add(%3202, %3200, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3204 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25082.FFNOutput = prim::GetAttr[name="output"](%3087)
  %3205 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25079.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3087)
  %3206 : __torch__.torch.nn.modules.linear.___torch_mangle_25078.Linear = prim::GetAttr[name="dense"](%3205)
  %3207 : Tensor = prim::GetAttr[name="bias"](%3206)
  %3208 : Tensor = prim::GetAttr[name="weight"](%3206)
  %3209 : Float(128:1, 512:128) = aten::t(%3208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.235 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.300, %3209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.301 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.235, %3207, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.302 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3213 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25081.NoNorm = prim::GetAttr[name="LayerNorm"](%3204)
  %3214 : __torch__.torch.nn.modules.linear.___torch_mangle_25080.Linear = prim::GetAttr[name="dense"](%3204)
  %3215 : Tensor = prim::GetAttr[name="bias"](%3214)
  %3216 : Tensor = prim::GetAttr[name="weight"](%3214)
  %3217 : Float(512:1, 128:512) = aten::t(%3216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.236 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.302, %3217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.78 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.236, %3215, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.126 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.78, %input.300, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3221 : Tensor = prim::GetAttr[name="bias"](%3213)
  %3222 : Tensor = prim::GetAttr[name="weight"](%3213)
  %3223 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.126, %3222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.303 : Float(17:1664, 13:128, 128:1) = aten::add(%3223, %3221, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3225 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25088.FFNOutput = prim::GetAttr[name="output"](%3085)
  %3226 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25085.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3085)
  %3227 : __torch__.torch.nn.modules.linear.___torch_mangle_25084.Linear = prim::GetAttr[name="dense"](%3226)
  %3228 : Tensor = prim::GetAttr[name="bias"](%3227)
  %3229 : Tensor = prim::GetAttr[name="weight"](%3227)
  %3230 : Float(128:1, 512:128) = aten::t(%3229), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.237 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.303, %3230), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.304 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.237, %3228, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.305 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3234 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25087.NoNorm = prim::GetAttr[name="LayerNorm"](%3225)
  %3235 : __torch__.torch.nn.modules.linear.___torch_mangle_25086.Linear = prim::GetAttr[name="dense"](%3225)
  %3236 : Tensor = prim::GetAttr[name="bias"](%3235)
  %3237 : Tensor = prim::GetAttr[name="weight"](%3235)
  %3238 : Float(512:1, 128:512) = aten::t(%3237), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.238 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.305, %3238), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.238, %3236, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.127 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.79, %input.303, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3242 : Tensor = prim::GetAttr[name="bias"](%3234)
  %3243 : Tensor = prim::GetAttr[name="weight"](%3234)
  %3244 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.127, %3243), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.306 : Float(17:1664, 13:128, 128:1) = aten::add(%3244, %3242, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3246 : __torch__.torch.nn.modules.linear.___torch_mangle_25056.Linear = prim::GetAttr[name="dense"](%3083)
  %3247 : Tensor = prim::GetAttr[name="bias"](%3246)
  %3248 : Tensor = prim::GetAttr[name="weight"](%3246)
  %3249 : Float(128:1, 512:128) = aten::t(%3248), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %output.239 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.306, %3249), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %input.307 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.239, %3247, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1678:0
  %input.308 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate # torch/nn/functional.py:1119:0
  %3253 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25063.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3082)
  %3254 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25059.NoNorm = prim::GetAttr[name="LayerNorm"](%3082)
  %3255 : __torch__.torch.nn.modules.linear.___torch_mangle_25058.Linear = prim::GetAttr[name="dense"](%3082)
  %3256 : Tensor = prim::GetAttr[name="bias"](%3255)
  %3257 : Tensor = prim::GetAttr[name="weight"](%3255)
  %3258 : Float(512:1, 128:512) = aten::t(%3257), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %output.240 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.308, %3258), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %layer_output.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.240, %3256, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.128 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.16, %input.306, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output # transformers/modeling_mobilebert.py:405:0
  %3262 : Tensor = prim::GetAttr[name="bias"](%3254)
  %3263 : Tensor = prim::GetAttr[name="weight"](%3254)
  %3264 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.128, %3263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.309 : Float(17:1664, 13:128, 128:1) = aten::add(%3264, %3262, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3266 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25061.NoNorm = prim::GetAttr[name="LayerNorm"](%3253)
  %3267 : __torch__.torch.nn.modules.linear.___torch_mangle_25060.Linear = prim::GetAttr[name="dense"](%3253)
  %3268 : Tensor = prim::GetAttr[name="bias"](%3267)
  %3269 : Tensor = prim::GetAttr[name="weight"](%3267)
  %3270 : Float(128:1, 512:128) = aten::t(%3269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.241 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.309, %3270), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.310 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.241, %3268, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.80 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.310, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.129 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.80, %input.292, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3275 : Tensor = prim::GetAttr[name="bias"](%3266)
  %3276 : Tensor = prim::GetAttr[name="weight"](%3266)
  %3277 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.129, %3276), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.311 : Float(17:6656, 13:512, 512:1) = aten::add(%3277, %3275, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3279 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25109.MobileBertOutput = prim::GetAttr[name="output"](%94)
  %3280 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25102.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%94)
  %3281 : __torch__.torch.nn.modules.container.___torch_mangle_25135.ModuleList = prim::GetAttr[name="ffn"](%94)
  %3282 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25134.FFNLayer = prim::GetAttr[name="2"](%3281)
  %3283 : __torch__.torch.nn.modules.container.___torch_mangle_25135.ModuleList = prim::GetAttr[name="ffn"](%94)
  %3284 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25128.FFNLayer = prim::GetAttr[name="1"](%3283)
  %3285 : __torch__.torch.nn.modules.container.___torch_mangle_25135.ModuleList = prim::GetAttr[name="ffn"](%94)
  %3286 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25122.FFNLayer = prim::GetAttr[name="0"](%3285)
  %3287 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25100.MobileBertAttention = prim::GetAttr[name="attention"](%94)
  %3288 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25116.Bottleneck = prim::GetAttr[name="bottleneck"](%94)
  %3289 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25115.BottleneckLayer = prim::GetAttr[name="attention"](%3288)
  %3290 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25112.BottleneckLayer = prim::GetAttr[name="input"](%3288)
  %3291 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25111.NoNorm = prim::GetAttr[name="LayerNorm"](%3290)
  %3292 : __torch__.torch.nn.modules.linear.___torch_mangle_25110.Linear = prim::GetAttr[name="dense"](%3290)
  %3293 : Tensor = prim::GetAttr[name="bias"](%3292)
  %3294 : Tensor = prim::GetAttr[name="weight"](%3292)
  %3295 : Float(512:1, 128:512) = aten::t(%3294), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.242 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3295), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.130 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.242, %3293, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3298 : Tensor = prim::GetAttr[name="bias"](%3291)
  %3299 : Tensor = prim::GetAttr[name="weight"](%3291)
  %3300 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.130, %3299), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.17 : Float(17:1664, 13:128, 128:1) = aten::add(%3300, %3298, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25114.NoNorm = prim::GetAttr[name="LayerNorm"](%3289)
  %3303 : __torch__.torch.nn.modules.linear.___torch_mangle_25113.Linear = prim::GetAttr[name="dense"](%3289)
  %3304 : Tensor = prim::GetAttr[name="bias"](%3303)
  %3305 : Tensor = prim::GetAttr[name="weight"](%3303)
  %3306 : Float(512:1, 128:512) = aten::t(%3305), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.243 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.243, %3304, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3309 : Tensor = prim::GetAttr[name="bias"](%3302)
  %3310 : Tensor = prim::GetAttr[name="weight"](%3302)
  %3311 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.131, %3310), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.312 : Float(17:1664, 13:128, 128:1) = aten::add(%3311, %3309, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3313 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.312, %residual_tensor.17)
  %3314 : Float(17:1664, 13:128, 128:1), %3315 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3313)
  %3316 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25099.MobileBertSelfOutput = prim::GetAttr[name="output"](%3287)
  %3317 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25096.MobileBertSelfAttention = prim::GetAttr[name="self"](%3287)
  %3318 : __torch__.torch.nn.modules.linear.___torch_mangle_25094.Linear = prim::GetAttr[name="value"](%3317)
  %3319 : __torch__.torch.nn.modules.linear.___torch_mangle_25093.Linear = prim::GetAttr[name="key"](%3317)
  %3320 : __torch__.torch.nn.modules.linear.___torch_mangle_25092.Linear = prim::GetAttr[name="query"](%3317)
  %3321 : Tensor = prim::GetAttr[name="bias"](%3320)
  %3322 : Tensor = prim::GetAttr[name="weight"](%3320)
  %3323 : Float(128:1, 128:128) = aten::t(%3322), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %output.244 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3314, %3323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %x.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.244, %3321, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1678:0
  %3326 : Tensor = prim::GetAttr[name="bias"](%3319)
  %3327 : Tensor = prim::GetAttr[name="weight"](%3319)
  %3328 : Float(128:1, 128:128) = aten::t(%3327), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %output.245 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3314, %3328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %x.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.245, %3326, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1678:0
  %3331 : Tensor = prim::GetAttr[name="bias"](%3318)
  %3332 : Tensor = prim::GetAttr[name="weight"](%3318)
  %3333 : Float(512:1, 128:512) = aten::t(%3332), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %output.246 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3333), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %x.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.246, %3331, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1678:0
  %3336 : int = aten::size(%x.97, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3337 : int = aten::size(%x.97, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3338 : int[] = prim::ListConstruct(%3336, %3337, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.98 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.97, %3338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3340 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %query_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.98, %3340), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3342 : int = aten::size(%x.99, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3343 : int = aten::size(%x.99, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3344 : int[] = prim::ListConstruct(%3342, %3343, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.100 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.99, %3344), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3346 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %key_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.100, %3346), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3348 : int = aten::size(%x.101, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3349 : int = aten::size(%x.101, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3350 : int[] = prim::ListConstruct(%3348, %3349, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.102 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.101, %3350), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3352 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %value_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.102, %3352), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3354 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.17, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.33 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.17, %3354), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.34 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.33, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.313 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.34, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.314 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.313, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.314, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.33 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.17, %value_layer.17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:280:0
  %3361 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %3362 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.33, %3361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3362, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %3364 : int = aten::size(%context_layer.34, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3365 : int = aten::size(%context_layer.34, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3366 : int[] = prim::ListConstruct(%3364, %3365, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %input.315 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.34, %3366), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:283:0
  %3368 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25098.NoNorm = prim::GetAttr[name="LayerNorm"](%3316)
  %3369 : __torch__.torch.nn.modules.linear.___torch_mangle_25097.Linear = prim::GetAttr[name="dense"](%3316)
  %3370 : Tensor = prim::GetAttr[name="bias"](%3369)
  %3371 : Tensor = prim::GetAttr[name="weight"](%3369)
  %3372 : Float(128:1, 128:128) = aten::t(%3371), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %output.247 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.315, %3372), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.247, %3370, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.132 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.81, %3315, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output # transformers/modeling_mobilebert.py:301:0
  %3376 : Tensor = prim::GetAttr[name="bias"](%3368)
  %3377 : Tensor = prim::GetAttr[name="weight"](%3368)
  %3378 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.132, %3377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.316 : Float(17:1664, 13:128, 128:1) = aten::add(%3378, %3376, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3380 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25121.FFNOutput = prim::GetAttr[name="output"](%3286)
  %3381 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25118.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3286)
  %3382 : __torch__.torch.nn.modules.linear.___torch_mangle_25117.Linear = prim::GetAttr[name="dense"](%3381)
  %3383 : Tensor = prim::GetAttr[name="bias"](%3382)
  %3384 : Tensor = prim::GetAttr[name="weight"](%3382)
  %3385 : Float(128:1, 512:128) = aten::t(%3384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.248 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.316, %3385), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.317 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.248, %3383, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.318 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3389 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25120.NoNorm = prim::GetAttr[name="LayerNorm"](%3380)
  %3390 : __torch__.torch.nn.modules.linear.___torch_mangle_25119.Linear = prim::GetAttr[name="dense"](%3380)
  %3391 : Tensor = prim::GetAttr[name="bias"](%3390)
  %3392 : Tensor = prim::GetAttr[name="weight"](%3390)
  %3393 : Float(512:1, 128:512) = aten::t(%3392), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.249 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.318, %3393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.249, %3391, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.133 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.82, %input.316, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3397 : Tensor = prim::GetAttr[name="bias"](%3389)
  %3398 : Tensor = prim::GetAttr[name="weight"](%3389)
  %3399 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.133, %3398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.319 : Float(17:1664, 13:128, 128:1) = aten::add(%3399, %3397, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3401 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25127.FFNOutput = prim::GetAttr[name="output"](%3284)
  %3402 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25124.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3284)
  %3403 : __torch__.torch.nn.modules.linear.___torch_mangle_25123.Linear = prim::GetAttr[name="dense"](%3402)
  %3404 : Tensor = prim::GetAttr[name="bias"](%3403)
  %3405 : Tensor = prim::GetAttr[name="weight"](%3403)
  %3406 : Float(128:1, 512:128) = aten::t(%3405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.250 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.319, %3406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.320 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.250, %3404, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.321 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3410 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25126.NoNorm = prim::GetAttr[name="LayerNorm"](%3401)
  %3411 : __torch__.torch.nn.modules.linear.___torch_mangle_25125.Linear = prim::GetAttr[name="dense"](%3401)
  %3412 : Tensor = prim::GetAttr[name="bias"](%3411)
  %3413 : Tensor = prim::GetAttr[name="weight"](%3411)
  %3414 : Float(512:1, 128:512) = aten::t(%3413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.251 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.321, %3414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.251, %3412, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.134 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.83, %input.319, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3418 : Tensor = prim::GetAttr[name="bias"](%3410)
  %3419 : Tensor = prim::GetAttr[name="weight"](%3410)
  %3420 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.134, %3419), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.322 : Float(17:1664, 13:128, 128:1) = aten::add(%3420, %3418, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3422 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25133.FFNOutput = prim::GetAttr[name="output"](%3282)
  %3423 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25130.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3282)
  %3424 : __torch__.torch.nn.modules.linear.___torch_mangle_25129.Linear = prim::GetAttr[name="dense"](%3423)
  %3425 : Tensor = prim::GetAttr[name="bias"](%3424)
  %3426 : Tensor = prim::GetAttr[name="weight"](%3424)
  %3427 : Float(128:1, 512:128) = aten::t(%3426), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.252 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.322, %3427), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.323 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.252, %3425, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.324 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3431 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25132.NoNorm = prim::GetAttr[name="LayerNorm"](%3422)
  %3432 : __torch__.torch.nn.modules.linear.___torch_mangle_25131.Linear = prim::GetAttr[name="dense"](%3422)
  %3433 : Tensor = prim::GetAttr[name="bias"](%3432)
  %3434 : Tensor = prim::GetAttr[name="weight"](%3432)
  %3435 : Float(512:1, 128:512) = aten::t(%3434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.253 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.324, %3435), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.84 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.253, %3433, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.135 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.84, %input.322, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3439 : Tensor = prim::GetAttr[name="bias"](%3431)
  %3440 : Tensor = prim::GetAttr[name="weight"](%3431)
  %3441 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.135, %3440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.325 : Float(17:1664, 13:128, 128:1) = aten::add(%3441, %3439, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3443 : __torch__.torch.nn.modules.linear.___torch_mangle_25101.Linear = prim::GetAttr[name="dense"](%3280)
  %3444 : Tensor = prim::GetAttr[name="bias"](%3443)
  %3445 : Tensor = prim::GetAttr[name="weight"](%3443)
  %3446 : Float(128:1, 512:128) = aten::t(%3445), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %output.254 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.325, %3446), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %input.326 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.254, %3444, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1678:0
  %input.327 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate # torch/nn/functional.py:1119:0
  %3450 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25108.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3279)
  %3451 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25104.NoNorm = prim::GetAttr[name="LayerNorm"](%3279)
  %3452 : __torch__.torch.nn.modules.linear.___torch_mangle_25103.Linear = prim::GetAttr[name="dense"](%3279)
  %3453 : Tensor = prim::GetAttr[name="bias"](%3452)
  %3454 : Tensor = prim::GetAttr[name="weight"](%3452)
  %3455 : Float(512:1, 128:512) = aten::t(%3454), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %output.255 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.327, %3455), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %layer_output.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.255, %3453, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.136 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.17, %input.325, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output # transformers/modeling_mobilebert.py:405:0
  %3459 : Tensor = prim::GetAttr[name="bias"](%3451)
  %3460 : Tensor = prim::GetAttr[name="weight"](%3451)
  %3461 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.136, %3460), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.328 : Float(17:1664, 13:128, 128:1) = aten::add(%3461, %3459, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3463 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25106.NoNorm = prim::GetAttr[name="LayerNorm"](%3450)
  %3464 : __torch__.torch.nn.modules.linear.___torch_mangle_25105.Linear = prim::GetAttr[name="dense"](%3450)
  %3465 : Tensor = prim::GetAttr[name="bias"](%3464)
  %3466 : Tensor = prim::GetAttr[name="weight"](%3464)
  %3467 : Float(128:1, 512:128) = aten::t(%3466), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.256 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.328, %3467), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.329 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.256, %3465, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.85 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.329, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.137 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.85, %input.311, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3472 : Tensor = prim::GetAttr[name="bias"](%3463)
  %3473 : Tensor = prim::GetAttr[name="weight"](%3463)
  %3474 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.137, %3473), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.330 : Float(17:6656, 13:512, 512:1) = aten::add(%3474, %3472, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3476 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25154.MobileBertOutput = prim::GetAttr[name="output"](%92)
  %3477 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25147.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%92)
  %3478 : __torch__.torch.nn.modules.container.___torch_mangle_25180.ModuleList = prim::GetAttr[name="ffn"](%92)
  %3479 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25179.FFNLayer = prim::GetAttr[name="2"](%3478)
  %3480 : __torch__.torch.nn.modules.container.___torch_mangle_25180.ModuleList = prim::GetAttr[name="ffn"](%92)
  %3481 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25173.FFNLayer = prim::GetAttr[name="1"](%3480)
  %3482 : __torch__.torch.nn.modules.container.___torch_mangle_25180.ModuleList = prim::GetAttr[name="ffn"](%92)
  %3483 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25167.FFNLayer = prim::GetAttr[name="0"](%3482)
  %3484 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25145.MobileBertAttention = prim::GetAttr[name="attention"](%92)
  %3485 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25161.Bottleneck = prim::GetAttr[name="bottleneck"](%92)
  %3486 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25160.BottleneckLayer = prim::GetAttr[name="attention"](%3485)
  %3487 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25157.BottleneckLayer = prim::GetAttr[name="input"](%3485)
  %3488 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25156.NoNorm = prim::GetAttr[name="LayerNorm"](%3487)
  %3489 : __torch__.torch.nn.modules.linear.___torch_mangle_25155.Linear = prim::GetAttr[name="dense"](%3487)
  %3490 : Tensor = prim::GetAttr[name="bias"](%3489)
  %3491 : Tensor = prim::GetAttr[name="weight"](%3489)
  %3492 : Float(512:1, 128:512) = aten::t(%3491), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.257 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3492), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.138 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.257, %3490, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3495 : Tensor = prim::GetAttr[name="bias"](%3488)
  %3496 : Tensor = prim::GetAttr[name="weight"](%3488)
  %3497 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.138, %3496), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add(%3497, %3495, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25159.NoNorm = prim::GetAttr[name="LayerNorm"](%3486)
  %3500 : __torch__.torch.nn.modules.linear.___torch_mangle_25158.Linear = prim::GetAttr[name="dense"](%3486)
  %3501 : Tensor = prim::GetAttr[name="bias"](%3500)
  %3502 : Tensor = prim::GetAttr[name="weight"](%3500)
  %3503 : Float(512:1, 128:512) = aten::t(%3502), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.258 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.258, %3501, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3506 : Tensor = prim::GetAttr[name="bias"](%3499)
  %3507 : Tensor = prim::GetAttr[name="weight"](%3499)
  %3508 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.139, %3507), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.331 : Float(17:1664, 13:128, 128:1) = aten::add(%3508, %3506, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3510 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.331, %residual_tensor.18)
  %3511 : Float(17:1664, 13:128, 128:1), %3512 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3510)
  %3513 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25144.MobileBertSelfOutput = prim::GetAttr[name="output"](%3484)
  %3514 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25141.MobileBertSelfAttention = prim::GetAttr[name="self"](%3484)
  %3515 : __torch__.torch.nn.modules.linear.___torch_mangle_25139.Linear = prim::GetAttr[name="value"](%3514)
  %3516 : __torch__.torch.nn.modules.linear.___torch_mangle_25138.Linear = prim::GetAttr[name="key"](%3514)
  %3517 : __torch__.torch.nn.modules.linear.___torch_mangle_25137.Linear = prim::GetAttr[name="query"](%3514)
  %3518 : Tensor = prim::GetAttr[name="bias"](%3517)
  %3519 : Tensor = prim::GetAttr[name="weight"](%3517)
  %3520 : Float(128:1, 128:128) = aten::t(%3519), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %output.259 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3511, %3520), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %x.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.259, %3518, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1678:0
  %3523 : Tensor = prim::GetAttr[name="bias"](%3516)
  %3524 : Tensor = prim::GetAttr[name="weight"](%3516)
  %3525 : Float(128:1, 128:128) = aten::t(%3524), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %output.260 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3511, %3525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %x.105 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.260, %3523, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1678:0
  %3528 : Tensor = prim::GetAttr[name="bias"](%3515)
  %3529 : Tensor = prim::GetAttr[name="weight"](%3515)
  %3530 : Float(512:1, 128:512) = aten::t(%3529), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %output.261 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3530), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %x.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.261, %3528, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1678:0
  %3533 : int = aten::size(%x.103, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3534 : int = aten::size(%x.103, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3535 : int[] = prim::ListConstruct(%3533, %3534, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.104 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.103, %3535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3537 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %query_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.104, %3537), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3539 : int = aten::size(%x.105, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3540 : int = aten::size(%x.105, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3541 : int[] = prim::ListConstruct(%3539, %3540, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.106 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.105, %3541), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3543 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %key_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.106, %3543), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3545 : int = aten::size(%x.107, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3546 : int = aten::size(%x.107, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3547 : int[] = prim::ListConstruct(%3545, %3546, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.108 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.107, %3547), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3549 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %value_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.108, %3549), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3551 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.18, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.35 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.18, %3551), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.36 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.35, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.332 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.36, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.333 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.332, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.333, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.35 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.18, %value_layer.18), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:280:0
  %3558 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %3559 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.35, %3558), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3559, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %3561 : int = aten::size(%context_layer.36, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3562 : int = aten::size(%context_layer.36, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3563 : int[] = prim::ListConstruct(%3561, %3562, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %input.334 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.36, %3563), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:283:0
  %3565 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25143.NoNorm = prim::GetAttr[name="LayerNorm"](%3513)
  %3566 : __torch__.torch.nn.modules.linear.___torch_mangle_25142.Linear = prim::GetAttr[name="dense"](%3513)
  %3567 : Tensor = prim::GetAttr[name="bias"](%3566)
  %3568 : Tensor = prim::GetAttr[name="weight"](%3566)
  %3569 : Float(128:1, 128:128) = aten::t(%3568), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %output.262 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.334, %3569), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.86 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.262, %3567, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.140 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.86, %3512, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output # transformers/modeling_mobilebert.py:301:0
  %3573 : Tensor = prim::GetAttr[name="bias"](%3565)
  %3574 : Tensor = prim::GetAttr[name="weight"](%3565)
  %3575 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.140, %3574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.335 : Float(17:1664, 13:128, 128:1) = aten::add(%3575, %3573, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3577 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25166.FFNOutput = prim::GetAttr[name="output"](%3483)
  %3578 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25163.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3483)
  %3579 : __torch__.torch.nn.modules.linear.___torch_mangle_25162.Linear = prim::GetAttr[name="dense"](%3578)
  %3580 : Tensor = prim::GetAttr[name="bias"](%3579)
  %3581 : Tensor = prim::GetAttr[name="weight"](%3579)
  %3582 : Float(128:1, 512:128) = aten::t(%3581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.263 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.335, %3582), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.336 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.263, %3580, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.337 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3586 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25165.NoNorm = prim::GetAttr[name="LayerNorm"](%3577)
  %3587 : __torch__.torch.nn.modules.linear.___torch_mangle_25164.Linear = prim::GetAttr[name="dense"](%3577)
  %3588 : Tensor = prim::GetAttr[name="bias"](%3587)
  %3589 : Tensor = prim::GetAttr[name="weight"](%3587)
  %3590 : Float(512:1, 128:512) = aten::t(%3589), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.264 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.337, %3590), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.264, %3588, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.141 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.87, %input.335, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3594 : Tensor = prim::GetAttr[name="bias"](%3586)
  %3595 : Tensor = prim::GetAttr[name="weight"](%3586)
  %3596 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.141, %3595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.338 : Float(17:1664, 13:128, 128:1) = aten::add(%3596, %3594, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3598 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25172.FFNOutput = prim::GetAttr[name="output"](%3481)
  %3599 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25169.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3481)
  %3600 : __torch__.torch.nn.modules.linear.___torch_mangle_25168.Linear = prim::GetAttr[name="dense"](%3599)
  %3601 : Tensor = prim::GetAttr[name="bias"](%3600)
  %3602 : Tensor = prim::GetAttr[name="weight"](%3600)
  %3603 : Float(128:1, 512:128) = aten::t(%3602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.265 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.338, %3603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.339 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.265, %3601, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.340 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3607 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25171.NoNorm = prim::GetAttr[name="LayerNorm"](%3598)
  %3608 : __torch__.torch.nn.modules.linear.___torch_mangle_25170.Linear = prim::GetAttr[name="dense"](%3598)
  %3609 : Tensor = prim::GetAttr[name="bias"](%3608)
  %3610 : Tensor = prim::GetAttr[name="weight"](%3608)
  %3611 : Float(512:1, 128:512) = aten::t(%3610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.266 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.340, %3611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.88 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.266, %3609, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.142 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.88, %input.338, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3615 : Tensor = prim::GetAttr[name="bias"](%3607)
  %3616 : Tensor = prim::GetAttr[name="weight"](%3607)
  %3617 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.142, %3616), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.341 : Float(17:1664, 13:128, 128:1) = aten::add(%3617, %3615, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3619 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25178.FFNOutput = prim::GetAttr[name="output"](%3479)
  %3620 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25175.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3479)
  %3621 : __torch__.torch.nn.modules.linear.___torch_mangle_25174.Linear = prim::GetAttr[name="dense"](%3620)
  %3622 : Tensor = prim::GetAttr[name="bias"](%3621)
  %3623 : Tensor = prim::GetAttr[name="weight"](%3621)
  %3624 : Float(128:1, 512:128) = aten::t(%3623), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.267 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.341, %3624), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.342 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.267, %3622, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.343 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3628 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25177.NoNorm = prim::GetAttr[name="LayerNorm"](%3619)
  %3629 : __torch__.torch.nn.modules.linear.___torch_mangle_25176.Linear = prim::GetAttr[name="dense"](%3619)
  %3630 : Tensor = prim::GetAttr[name="bias"](%3629)
  %3631 : Tensor = prim::GetAttr[name="weight"](%3629)
  %3632 : Float(512:1, 128:512) = aten::t(%3631), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.268 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.343, %3632), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.268, %3630, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.143 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.89, %input.341, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3636 : Tensor = prim::GetAttr[name="bias"](%3628)
  %3637 : Tensor = prim::GetAttr[name="weight"](%3628)
  %3638 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.143, %3637), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.344 : Float(17:1664, 13:128, 128:1) = aten::add(%3638, %3636, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3640 : __torch__.torch.nn.modules.linear.___torch_mangle_25146.Linear = prim::GetAttr[name="dense"](%3477)
  %3641 : Tensor = prim::GetAttr[name="bias"](%3640)
  %3642 : Tensor = prim::GetAttr[name="weight"](%3640)
  %3643 : Float(128:1, 512:128) = aten::t(%3642), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %output.269 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.344, %3643), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %input.345 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.269, %3641, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1678:0
  %input.346 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate # torch/nn/functional.py:1119:0
  %3647 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25153.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3476)
  %3648 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25149.NoNorm = prim::GetAttr[name="LayerNorm"](%3476)
  %3649 : __torch__.torch.nn.modules.linear.___torch_mangle_25148.Linear = prim::GetAttr[name="dense"](%3476)
  %3650 : Tensor = prim::GetAttr[name="bias"](%3649)
  %3651 : Tensor = prim::GetAttr[name="weight"](%3649)
  %3652 : Float(512:1, 128:512) = aten::t(%3651), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %output.270 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.346, %3652), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %layer_output.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.270, %3650, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.144 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.18, %input.344, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output # transformers/modeling_mobilebert.py:405:0
  %3656 : Tensor = prim::GetAttr[name="bias"](%3648)
  %3657 : Tensor = prim::GetAttr[name="weight"](%3648)
  %3658 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.144, %3657), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.347 : Float(17:1664, 13:128, 128:1) = aten::add(%3658, %3656, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3660 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25151.NoNorm = prim::GetAttr[name="LayerNorm"](%3647)
  %3661 : __torch__.torch.nn.modules.linear.___torch_mangle_25150.Linear = prim::GetAttr[name="dense"](%3647)
  %3662 : Tensor = prim::GetAttr[name="bias"](%3661)
  %3663 : Tensor = prim::GetAttr[name="weight"](%3661)
  %3664 : Float(128:1, 512:128) = aten::t(%3663), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.271 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.347, %3664), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.348 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.271, %3662, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.90 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.348, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.145 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.90, %input.330, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3669 : Tensor = prim::GetAttr[name="bias"](%3660)
  %3670 : Tensor = prim::GetAttr[name="weight"](%3660)
  %3671 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.145, %3670), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.349 : Float(17:6656, 13:512, 512:1) = aten::add(%3671, %3669, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3673 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25199.MobileBertOutput = prim::GetAttr[name="output"](%90)
  %3674 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25192.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%90)
  %3675 : __torch__.torch.nn.modules.container.___torch_mangle_25225.ModuleList = prim::GetAttr[name="ffn"](%90)
  %3676 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25224.FFNLayer = prim::GetAttr[name="2"](%3675)
  %3677 : __torch__.torch.nn.modules.container.___torch_mangle_25225.ModuleList = prim::GetAttr[name="ffn"](%90)
  %3678 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25218.FFNLayer = prim::GetAttr[name="1"](%3677)
  %3679 : __torch__.torch.nn.modules.container.___torch_mangle_25225.ModuleList = prim::GetAttr[name="ffn"](%90)
  %3680 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25212.FFNLayer = prim::GetAttr[name="0"](%3679)
  %3681 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25190.MobileBertAttention = prim::GetAttr[name="attention"](%90)
  %3682 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25206.Bottleneck = prim::GetAttr[name="bottleneck"](%90)
  %3683 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25205.BottleneckLayer = prim::GetAttr[name="attention"](%3682)
  %3684 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25202.BottleneckLayer = prim::GetAttr[name="input"](%3682)
  %3685 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25201.NoNorm = prim::GetAttr[name="LayerNorm"](%3684)
  %3686 : __torch__.torch.nn.modules.linear.___torch_mangle_25200.Linear = prim::GetAttr[name="dense"](%3684)
  %3687 : Tensor = prim::GetAttr[name="bias"](%3686)
  %3688 : Tensor = prim::GetAttr[name="weight"](%3686)
  %3689 : Float(512:1, 128:512) = aten::t(%3688), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.272 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3689), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.146 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.272, %3687, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3692 : Tensor = prim::GetAttr[name="bias"](%3685)
  %3693 : Tensor = prim::GetAttr[name="weight"](%3685)
  %3694 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.146, %3693), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add(%3694, %3692, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25204.NoNorm = prim::GetAttr[name="LayerNorm"](%3683)
  %3697 : __torch__.torch.nn.modules.linear.___torch_mangle_25203.Linear = prim::GetAttr[name="dense"](%3683)
  %3698 : Tensor = prim::GetAttr[name="bias"](%3697)
  %3699 : Tensor = prim::GetAttr[name="weight"](%3697)
  %3700 : Float(512:1, 128:512) = aten::t(%3699), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.273 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.147 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.273, %3698, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3703 : Tensor = prim::GetAttr[name="bias"](%3696)
  %3704 : Tensor = prim::GetAttr[name="weight"](%3696)
  %3705 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.147, %3704), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.350 : Float(17:1664, 13:128, 128:1) = aten::add(%3705, %3703, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3707 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.350, %residual_tensor.19)
  %3708 : Float(17:1664, 13:128, 128:1), %3709 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3707)
  %3710 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25189.MobileBertSelfOutput = prim::GetAttr[name="output"](%3681)
  %3711 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25186.MobileBertSelfAttention = prim::GetAttr[name="self"](%3681)
  %3712 : __torch__.torch.nn.modules.linear.___torch_mangle_25184.Linear = prim::GetAttr[name="value"](%3711)
  %3713 : __torch__.torch.nn.modules.linear.___torch_mangle_25183.Linear = prim::GetAttr[name="key"](%3711)
  %3714 : __torch__.torch.nn.modules.linear.___torch_mangle_25182.Linear = prim::GetAttr[name="query"](%3711)
  %3715 : Tensor = prim::GetAttr[name="bias"](%3714)
  %3716 : Tensor = prim::GetAttr[name="weight"](%3714)
  %3717 : Float(128:1, 128:128) = aten::t(%3716), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %output.274 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3708, %3717), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %x.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.274, %3715, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1678:0
  %3720 : Tensor = prim::GetAttr[name="bias"](%3713)
  %3721 : Tensor = prim::GetAttr[name="weight"](%3713)
  %3722 : Float(128:1, 128:128) = aten::t(%3721), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %output.275 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3708, %3722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %x.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.275, %3720, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1678:0
  %3725 : Tensor = prim::GetAttr[name="bias"](%3712)
  %3726 : Tensor = prim::GetAttr[name="weight"](%3712)
  %3727 : Float(512:1, 128:512) = aten::t(%3726), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %output.276 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3727), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %x.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.276, %3725, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1678:0
  %3730 : int = aten::size(%x.109, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3731 : int = aten::size(%x.109, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3732 : int[] = prim::ListConstruct(%3730, %3731, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.110 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.109, %3732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3734 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %query_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.110, %3734), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3736 : int = aten::size(%x.111, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3737 : int = aten::size(%x.111, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3738 : int[] = prim::ListConstruct(%3736, %3737, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.112 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.111, %3738), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3740 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %key_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.112, %3740), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3742 : int = aten::size(%x.113, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3743 : int = aten::size(%x.113, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3744 : int[] = prim::ListConstruct(%3742, %3743, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.114 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.113, %3744), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3746 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %value_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.114, %3746), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3748 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.19, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.37 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.19, %3748), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.38 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.37, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.351 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.38, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.352 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.351, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.352, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.37 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.19, %value_layer.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:280:0
  %3755 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %3756 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.37, %3755), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3756, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %3758 : int = aten::size(%context_layer.38, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3759 : int = aten::size(%context_layer.38, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3760 : int[] = prim::ListConstruct(%3758, %3759, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %input.353 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.38, %3760), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:283:0
  %3762 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25188.NoNorm = prim::GetAttr[name="LayerNorm"](%3710)
  %3763 : __torch__.torch.nn.modules.linear.___torch_mangle_25187.Linear = prim::GetAttr[name="dense"](%3710)
  %3764 : Tensor = prim::GetAttr[name="bias"](%3763)
  %3765 : Tensor = prim::GetAttr[name="weight"](%3763)
  %3766 : Float(128:1, 128:128) = aten::t(%3765), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %output.277 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.353, %3766), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.277, %3764, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.148 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.91, %3709, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output # transformers/modeling_mobilebert.py:301:0
  %3770 : Tensor = prim::GetAttr[name="bias"](%3762)
  %3771 : Tensor = prim::GetAttr[name="weight"](%3762)
  %3772 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.148, %3771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.354 : Float(17:1664, 13:128, 128:1) = aten::add(%3772, %3770, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3774 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25211.FFNOutput = prim::GetAttr[name="output"](%3680)
  %3775 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25208.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3680)
  %3776 : __torch__.torch.nn.modules.linear.___torch_mangle_25207.Linear = prim::GetAttr[name="dense"](%3775)
  %3777 : Tensor = prim::GetAttr[name="bias"](%3776)
  %3778 : Tensor = prim::GetAttr[name="weight"](%3776)
  %3779 : Float(128:1, 512:128) = aten::t(%3778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.278 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.354, %3779), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.355 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.278, %3777, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.356 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3783 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25210.NoNorm = prim::GetAttr[name="LayerNorm"](%3774)
  %3784 : __torch__.torch.nn.modules.linear.___torch_mangle_25209.Linear = prim::GetAttr[name="dense"](%3774)
  %3785 : Tensor = prim::GetAttr[name="bias"](%3784)
  %3786 : Tensor = prim::GetAttr[name="weight"](%3784)
  %3787 : Float(512:1, 128:512) = aten::t(%3786), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.279 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.356, %3787), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.92 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.279, %3785, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.149 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.92, %input.354, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3791 : Tensor = prim::GetAttr[name="bias"](%3783)
  %3792 : Tensor = prim::GetAttr[name="weight"](%3783)
  %3793 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.149, %3792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.357 : Float(17:1664, 13:128, 128:1) = aten::add(%3793, %3791, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3795 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25217.FFNOutput = prim::GetAttr[name="output"](%3678)
  %3796 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25214.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3678)
  %3797 : __torch__.torch.nn.modules.linear.___torch_mangle_25213.Linear = prim::GetAttr[name="dense"](%3796)
  %3798 : Tensor = prim::GetAttr[name="bias"](%3797)
  %3799 : Tensor = prim::GetAttr[name="weight"](%3797)
  %3800 : Float(128:1, 512:128) = aten::t(%3799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.280 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.357, %3800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.358 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.280, %3798, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.359 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3804 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25216.NoNorm = prim::GetAttr[name="LayerNorm"](%3795)
  %3805 : __torch__.torch.nn.modules.linear.___torch_mangle_25215.Linear = prim::GetAttr[name="dense"](%3795)
  %3806 : Tensor = prim::GetAttr[name="bias"](%3805)
  %3807 : Tensor = prim::GetAttr[name="weight"](%3805)
  %3808 : Float(512:1, 128:512) = aten::t(%3807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.281 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.359, %3808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.281, %3806, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.150 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.93, %input.357, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3812 : Tensor = prim::GetAttr[name="bias"](%3804)
  %3813 : Tensor = prim::GetAttr[name="weight"](%3804)
  %3814 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.150, %3813), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.360 : Float(17:1664, 13:128, 128:1) = aten::add(%3814, %3812, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3816 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25223.FFNOutput = prim::GetAttr[name="output"](%3676)
  %3817 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25220.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3676)
  %3818 : __torch__.torch.nn.modules.linear.___torch_mangle_25219.Linear = prim::GetAttr[name="dense"](%3817)
  %3819 : Tensor = prim::GetAttr[name="bias"](%3818)
  %3820 : Tensor = prim::GetAttr[name="weight"](%3818)
  %3821 : Float(128:1, 512:128) = aten::t(%3820), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.282 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.360, %3821), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.361 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.282, %3819, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.362 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3825 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25222.NoNorm = prim::GetAttr[name="LayerNorm"](%3816)
  %3826 : __torch__.torch.nn.modules.linear.___torch_mangle_25221.Linear = prim::GetAttr[name="dense"](%3816)
  %3827 : Tensor = prim::GetAttr[name="bias"](%3826)
  %3828 : Tensor = prim::GetAttr[name="weight"](%3826)
  %3829 : Float(512:1, 128:512) = aten::t(%3828), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.283 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.362, %3829), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.94 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.283, %3827, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.151 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.94, %input.360, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3833 : Tensor = prim::GetAttr[name="bias"](%3825)
  %3834 : Tensor = prim::GetAttr[name="weight"](%3825)
  %3835 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.151, %3834), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.363 : Float(17:1664, 13:128, 128:1) = aten::add(%3835, %3833, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3837 : __torch__.torch.nn.modules.linear.___torch_mangle_25191.Linear = prim::GetAttr[name="dense"](%3674)
  %3838 : Tensor = prim::GetAttr[name="bias"](%3837)
  %3839 : Tensor = prim::GetAttr[name="weight"](%3837)
  %3840 : Float(128:1, 512:128) = aten::t(%3839), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %output.284 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.363, %3840), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %input.364 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.284, %3838, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1678:0
  %input.365 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate # torch/nn/functional.py:1119:0
  %3844 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25198.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3673)
  %3845 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25194.NoNorm = prim::GetAttr[name="LayerNorm"](%3673)
  %3846 : __torch__.torch.nn.modules.linear.___torch_mangle_25193.Linear = prim::GetAttr[name="dense"](%3673)
  %3847 : Tensor = prim::GetAttr[name="bias"](%3846)
  %3848 : Tensor = prim::GetAttr[name="weight"](%3846)
  %3849 : Float(512:1, 128:512) = aten::t(%3848), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %output.285 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.365, %3849), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %layer_output.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.285, %3847, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.152 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.19, %input.363, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output # transformers/modeling_mobilebert.py:405:0
  %3853 : Tensor = prim::GetAttr[name="bias"](%3845)
  %3854 : Tensor = prim::GetAttr[name="weight"](%3845)
  %3855 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.152, %3854), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.366 : Float(17:1664, 13:128, 128:1) = aten::add(%3855, %3853, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3857 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25196.NoNorm = prim::GetAttr[name="LayerNorm"](%3844)
  %3858 : __torch__.torch.nn.modules.linear.___torch_mangle_25195.Linear = prim::GetAttr[name="dense"](%3844)
  %3859 : Tensor = prim::GetAttr[name="bias"](%3858)
  %3860 : Tensor = prim::GetAttr[name="weight"](%3858)
  %3861 : Float(128:1, 512:128) = aten::t(%3860), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.286 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.366, %3861), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.367 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.286, %3859, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.95 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.367, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.153 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.95, %input.349, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3866 : Tensor = prim::GetAttr[name="bias"](%3857)
  %3867 : Tensor = prim::GetAttr[name="weight"](%3857)
  %3868 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.153, %3867), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.368 : Float(17:6656, 13:512, 512:1) = aten::add(%3868, %3866, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3870 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25244.MobileBertOutput = prim::GetAttr[name="output"](%88)
  %3871 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25237.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%88)
  %3872 : __torch__.torch.nn.modules.container.___torch_mangle_25270.ModuleList = prim::GetAttr[name="ffn"](%88)
  %3873 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25269.FFNLayer = prim::GetAttr[name="2"](%3872)
  %3874 : __torch__.torch.nn.modules.container.___torch_mangle_25270.ModuleList = prim::GetAttr[name="ffn"](%88)
  %3875 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25263.FFNLayer = prim::GetAttr[name="1"](%3874)
  %3876 : __torch__.torch.nn.modules.container.___torch_mangle_25270.ModuleList = prim::GetAttr[name="ffn"](%88)
  %3877 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25257.FFNLayer = prim::GetAttr[name="0"](%3876)
  %3878 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25235.MobileBertAttention = prim::GetAttr[name="attention"](%88)
  %3879 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25251.Bottleneck = prim::GetAttr[name="bottleneck"](%88)
  %3880 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25250.BottleneckLayer = prim::GetAttr[name="attention"](%3879)
  %3881 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25247.BottleneckLayer = prim::GetAttr[name="input"](%3879)
  %3882 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25246.NoNorm = prim::GetAttr[name="LayerNorm"](%3881)
  %3883 : __torch__.torch.nn.modules.linear.___torch_mangle_25245.Linear = prim::GetAttr[name="dense"](%3881)
  %3884 : Tensor = prim::GetAttr[name="bias"](%3883)
  %3885 : Tensor = prim::GetAttr[name="weight"](%3883)
  %3886 : Float(512:1, 128:512) = aten::t(%3885), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.287 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3886), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.154 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.287, %3884, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3889 : Tensor = prim::GetAttr[name="bias"](%3882)
  %3890 : Tensor = prim::GetAttr[name="weight"](%3882)
  %3891 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.154, %3890), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%3891, %3889, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3893 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25249.NoNorm = prim::GetAttr[name="LayerNorm"](%3880)
  %3894 : __torch__.torch.nn.modules.linear.___torch_mangle_25248.Linear = prim::GetAttr[name="dense"](%3880)
  %3895 : Tensor = prim::GetAttr[name="bias"](%3894)
  %3896 : Tensor = prim::GetAttr[name="weight"](%3894)
  %3897 : Float(512:1, 128:512) = aten::t(%3896), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.288 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3897), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.155 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.288, %3895, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3900 : Tensor = prim::GetAttr[name="bias"](%3893)
  %3901 : Tensor = prim::GetAttr[name="weight"](%3893)
  %3902 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.155, %3901), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.369 : Float(17:1664, 13:128, 128:1) = aten::add(%3902, %3900, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3904 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.369, %residual_tensor.20)
  %3905 : Float(17:1664, 13:128, 128:1), %3906 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3904)
  %3907 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25234.MobileBertSelfOutput = prim::GetAttr[name="output"](%3878)
  %3908 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25231.MobileBertSelfAttention = prim::GetAttr[name="self"](%3878)
  %3909 : __torch__.torch.nn.modules.linear.___torch_mangle_25229.Linear = prim::GetAttr[name="value"](%3908)
  %3910 : __torch__.torch.nn.modules.linear.___torch_mangle_25228.Linear = prim::GetAttr[name="key"](%3908)
  %3911 : __torch__.torch.nn.modules.linear.___torch_mangle_25227.Linear = prim::GetAttr[name="query"](%3908)
  %3912 : Tensor = prim::GetAttr[name="bias"](%3911)
  %3913 : Tensor = prim::GetAttr[name="weight"](%3911)
  %3914 : Float(128:1, 128:128) = aten::t(%3913), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %output.289 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3905, %3914), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %x.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.289, %3912, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1678:0
  %3917 : Tensor = prim::GetAttr[name="bias"](%3910)
  %3918 : Tensor = prim::GetAttr[name="weight"](%3910)
  %3919 : Float(128:1, 128:128) = aten::t(%3918), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %output.290 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3905, %3919), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %x.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.290, %3917, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1678:0
  %3922 : Tensor = prim::GetAttr[name="bias"](%3909)
  %3923 : Tensor = prim::GetAttr[name="weight"](%3909)
  %3924 : Float(512:1, 128:512) = aten::t(%3923), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %output.291 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3924), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %x.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.291, %3922, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1678:0
  %3927 : int = aten::size(%x.115, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3928 : int = aten::size(%x.115, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3929 : int[] = prim::ListConstruct(%3927, %3928, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.116 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.115, %3929), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3931 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %query_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.116, %3931), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3933 : int = aten::size(%x.117, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3934 : int = aten::size(%x.117, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3935 : int[] = prim::ListConstruct(%3933, %3934, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.118 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.117, %3935), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3937 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %key_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.118, %3937), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3939 : int = aten::size(%x.119, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3940 : int = aten::size(%x.119, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3941 : int[] = prim::ListConstruct(%3939, %3940, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.120 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.119, %3941), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3943 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %value_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.120, %3943), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3945 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.20, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.39 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.20, %3945), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.40 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.39, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.370 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.40, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.371 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.370, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.371, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.39 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.20, %value_layer.20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:280:0
  %3952 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %3953 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.39, %3952), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3953, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %3955 : int = aten::size(%context_layer.40, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3956 : int = aten::size(%context_layer.40, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3957 : int[] = prim::ListConstruct(%3955, %3956, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %input.372 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.40, %3957), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:283:0
  %3959 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25233.NoNorm = prim::GetAttr[name="LayerNorm"](%3907)
  %3960 : __torch__.torch.nn.modules.linear.___torch_mangle_25232.Linear = prim::GetAttr[name="dense"](%3907)
  %3961 : Tensor = prim::GetAttr[name="bias"](%3960)
  %3962 : Tensor = prim::GetAttr[name="weight"](%3960)
  %3963 : Float(128:1, 128:128) = aten::t(%3962), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %output.292 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.372, %3963), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.96 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.292, %3961, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.156 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.96, %3906, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output # transformers/modeling_mobilebert.py:301:0
  %3967 : Tensor = prim::GetAttr[name="bias"](%3959)
  %3968 : Tensor = prim::GetAttr[name="weight"](%3959)
  %3969 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.156, %3968), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.373 : Float(17:1664, 13:128, 128:1) = aten::add(%3969, %3967, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3971 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25256.FFNOutput = prim::GetAttr[name="output"](%3877)
  %3972 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25253.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3877)
  %3973 : __torch__.torch.nn.modules.linear.___torch_mangle_25252.Linear = prim::GetAttr[name="dense"](%3972)
  %3974 : Tensor = prim::GetAttr[name="bias"](%3973)
  %3975 : Tensor = prim::GetAttr[name="weight"](%3973)
  %3976 : Float(128:1, 512:128) = aten::t(%3975), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.293 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.373, %3976), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.374 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.293, %3974, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.375 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3980 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25255.NoNorm = prim::GetAttr[name="LayerNorm"](%3971)
  %3981 : __torch__.torch.nn.modules.linear.___torch_mangle_25254.Linear = prim::GetAttr[name="dense"](%3971)
  %3982 : Tensor = prim::GetAttr[name="bias"](%3981)
  %3983 : Tensor = prim::GetAttr[name="weight"](%3981)
  %3984 : Float(512:1, 128:512) = aten::t(%3983), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.294 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.375, %3984), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.294, %3982, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.157 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.97, %input.373, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3988 : Tensor = prim::GetAttr[name="bias"](%3980)
  %3989 : Tensor = prim::GetAttr[name="weight"](%3980)
  %3990 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.157, %3989), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.376 : Float(17:1664, 13:128, 128:1) = aten::add(%3990, %3988, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3992 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25262.FFNOutput = prim::GetAttr[name="output"](%3875)
  %3993 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25259.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3875)
  %3994 : __torch__.torch.nn.modules.linear.___torch_mangle_25258.Linear = prim::GetAttr[name="dense"](%3993)
  %3995 : Tensor = prim::GetAttr[name="bias"](%3994)
  %3996 : Tensor = prim::GetAttr[name="weight"](%3994)
  %3997 : Float(128:1, 512:128) = aten::t(%3996), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.295 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.376, %3997), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.377 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.295, %3995, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.378 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4001 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25261.NoNorm = prim::GetAttr[name="LayerNorm"](%3992)
  %4002 : __torch__.torch.nn.modules.linear.___torch_mangle_25260.Linear = prim::GetAttr[name="dense"](%3992)
  %4003 : Tensor = prim::GetAttr[name="bias"](%4002)
  %4004 : Tensor = prim::GetAttr[name="weight"](%4002)
  %4005 : Float(512:1, 128:512) = aten::t(%4004), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.296 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.378, %4005), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.296, %4003, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.158 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.98, %input.376, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4009 : Tensor = prim::GetAttr[name="bias"](%4001)
  %4010 : Tensor = prim::GetAttr[name="weight"](%4001)
  %4011 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.158, %4010), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.379 : Float(17:1664, 13:128, 128:1) = aten::add(%4011, %4009, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4013 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25268.FFNOutput = prim::GetAttr[name="output"](%3873)
  %4014 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25265.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3873)
  %4015 : __torch__.torch.nn.modules.linear.___torch_mangle_25264.Linear = prim::GetAttr[name="dense"](%4014)
  %4016 : Tensor = prim::GetAttr[name="bias"](%4015)
  %4017 : Tensor = prim::GetAttr[name="weight"](%4015)
  %4018 : Float(128:1, 512:128) = aten::t(%4017), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.297 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.379, %4018), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.380 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.297, %4016, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.381 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4022 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25267.NoNorm = prim::GetAttr[name="LayerNorm"](%4013)
  %4023 : __torch__.torch.nn.modules.linear.___torch_mangle_25266.Linear = prim::GetAttr[name="dense"](%4013)
  %4024 : Tensor = prim::GetAttr[name="bias"](%4023)
  %4025 : Tensor = prim::GetAttr[name="weight"](%4023)
  %4026 : Float(512:1, 128:512) = aten::t(%4025), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.298 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.381, %4026), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.298, %4024, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.159 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.99, %input.379, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4030 : Tensor = prim::GetAttr[name="bias"](%4022)
  %4031 : Tensor = prim::GetAttr[name="weight"](%4022)
  %4032 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.159, %4031), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.382 : Float(17:1664, 13:128, 128:1) = aten::add(%4032, %4030, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4034 : __torch__.torch.nn.modules.linear.___torch_mangle_25236.Linear = prim::GetAttr[name="dense"](%3871)
  %4035 : Tensor = prim::GetAttr[name="bias"](%4034)
  %4036 : Tensor = prim::GetAttr[name="weight"](%4034)
  %4037 : Float(128:1, 512:128) = aten::t(%4036), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %output.299 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.382, %4037), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %input.383 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.299, %4035, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1678:0
  %input.384 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate # torch/nn/functional.py:1119:0
  %4041 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25243.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3870)
  %4042 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25239.NoNorm = prim::GetAttr[name="LayerNorm"](%3870)
  %4043 : __torch__.torch.nn.modules.linear.___torch_mangle_25238.Linear = prim::GetAttr[name="dense"](%3870)
  %4044 : Tensor = prim::GetAttr[name="bias"](%4043)
  %4045 : Tensor = prim::GetAttr[name="weight"](%4043)
  %4046 : Float(512:1, 128:512) = aten::t(%4045), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %output.300 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.384, %4046), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %layer_output.20 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.300, %4044, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.160 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.20, %input.382, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output # transformers/modeling_mobilebert.py:405:0
  %4050 : Tensor = prim::GetAttr[name="bias"](%4042)
  %4051 : Tensor = prim::GetAttr[name="weight"](%4042)
  %4052 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.160, %4051), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.385 : Float(17:1664, 13:128, 128:1) = aten::add(%4052, %4050, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4054 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25241.NoNorm = prim::GetAttr[name="LayerNorm"](%4041)
  %4055 : __torch__.torch.nn.modules.linear.___torch_mangle_25240.Linear = prim::GetAttr[name="dense"](%4041)
  %4056 : Tensor = prim::GetAttr[name="bias"](%4055)
  %4057 : Tensor = prim::GetAttr[name="weight"](%4055)
  %4058 : Float(128:1, 512:128) = aten::t(%4057), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.301 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.385, %4058), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.386 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.301, %4056, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.100 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.386, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.161 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.100, %input.368, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4063 : Tensor = prim::GetAttr[name="bias"](%4054)
  %4064 : Tensor = prim::GetAttr[name="weight"](%4054)
  %4065 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.161, %4064), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.387 : Float(17:6656, 13:512, 512:1) = aten::add(%4065, %4063, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4067 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25289.MobileBertOutput = prim::GetAttr[name="output"](%86)
  %4068 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25282.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%86)
  %4069 : __torch__.torch.nn.modules.container.___torch_mangle_25315.ModuleList = prim::GetAttr[name="ffn"](%86)
  %4070 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25314.FFNLayer = prim::GetAttr[name="2"](%4069)
  %4071 : __torch__.torch.nn.modules.container.___torch_mangle_25315.ModuleList = prim::GetAttr[name="ffn"](%86)
  %4072 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25308.FFNLayer = prim::GetAttr[name="1"](%4071)
  %4073 : __torch__.torch.nn.modules.container.___torch_mangle_25315.ModuleList = prim::GetAttr[name="ffn"](%86)
  %4074 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25302.FFNLayer = prim::GetAttr[name="0"](%4073)
  %4075 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25280.MobileBertAttention = prim::GetAttr[name="attention"](%86)
  %4076 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25296.Bottleneck = prim::GetAttr[name="bottleneck"](%86)
  %4077 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25295.BottleneckLayer = prim::GetAttr[name="attention"](%4076)
  %4078 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25292.BottleneckLayer = prim::GetAttr[name="input"](%4076)
  %4079 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25291.NoNorm = prim::GetAttr[name="LayerNorm"](%4078)
  %4080 : __torch__.torch.nn.modules.linear.___torch_mangle_25290.Linear = prim::GetAttr[name="dense"](%4078)
  %4081 : Tensor = prim::GetAttr[name="bias"](%4080)
  %4082 : Tensor = prim::GetAttr[name="weight"](%4080)
  %4083 : Float(512:1, 128:512) = aten::t(%4082), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.302 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4083), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.162 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.302, %4081, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4086 : Tensor = prim::GetAttr[name="bias"](%4079)
  %4087 : Tensor = prim::GetAttr[name="weight"](%4079)
  %4088 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.162, %4087), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%4088, %4086, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4090 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25294.NoNorm = prim::GetAttr[name="LayerNorm"](%4077)
  %4091 : __torch__.torch.nn.modules.linear.___torch_mangle_25293.Linear = prim::GetAttr[name="dense"](%4077)
  %4092 : Tensor = prim::GetAttr[name="bias"](%4091)
  %4093 : Tensor = prim::GetAttr[name="weight"](%4091)
  %4094 : Float(512:1, 128:512) = aten::t(%4093), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.303 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4094), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.163 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.303, %4092, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4097 : Tensor = prim::GetAttr[name="bias"](%4090)
  %4098 : Tensor = prim::GetAttr[name="weight"](%4090)
  %4099 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.163, %4098), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.388 : Float(17:1664, 13:128, 128:1) = aten::add(%4099, %4097, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4101 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.388, %residual_tensor.21)
  %4102 : Float(17:1664, 13:128, 128:1), %4103 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4101)
  %4104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25279.MobileBertSelfOutput = prim::GetAttr[name="output"](%4075)
  %4105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25276.MobileBertSelfAttention = prim::GetAttr[name="self"](%4075)
  %4106 : __torch__.torch.nn.modules.linear.___torch_mangle_25274.Linear = prim::GetAttr[name="value"](%4105)
  %4107 : __torch__.torch.nn.modules.linear.___torch_mangle_25273.Linear = prim::GetAttr[name="key"](%4105)
  %4108 : __torch__.torch.nn.modules.linear.___torch_mangle_25272.Linear = prim::GetAttr[name="query"](%4105)
  %4109 : Tensor = prim::GetAttr[name="bias"](%4108)
  %4110 : Tensor = prim::GetAttr[name="weight"](%4108)
  %4111 : Float(128:1, 128:128) = aten::t(%4110), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %output.304 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4102, %4111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %x.121 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.304, %4109, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1678:0
  %4114 : Tensor = prim::GetAttr[name="bias"](%4107)
  %4115 : Tensor = prim::GetAttr[name="weight"](%4107)
  %4116 : Float(128:1, 128:128) = aten::t(%4115), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %output.305 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4102, %4116), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %x.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.305, %4114, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1678:0
  %4119 : Tensor = prim::GetAttr[name="bias"](%4106)
  %4120 : Tensor = prim::GetAttr[name="weight"](%4106)
  %4121 : Float(512:1, 128:512) = aten::t(%4120), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %output.306 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4121), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %x.125 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.306, %4119, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1678:0
  %4124 : int = aten::size(%x.121, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4125 : int = aten::size(%x.121, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4126 : int[] = prim::ListConstruct(%4124, %4125, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.122 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.121, %4126), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4128 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %query_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.122, %4128), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4130 : int = aten::size(%x.123, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4131 : int = aten::size(%x.123, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4132 : int[] = prim::ListConstruct(%4130, %4131, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.124 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.123, %4132), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4134 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %key_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.124, %4134), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4136 : int = aten::size(%x.125, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4137 : int = aten::size(%x.125, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4138 : int[] = prim::ListConstruct(%4136, %4137, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.126 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.125, %4138), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4140 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %value_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.126, %4140), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4142 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.21, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.41 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.21, %4142), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.42 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.41, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.389 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.42, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.390 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.389, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.390, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.41 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.21, %value_layer.21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:280:0
  %4149 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %4150 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.41, %4149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4150, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %4152 : int = aten::size(%context_layer.42, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4153 : int = aten::size(%context_layer.42, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4154 : int[] = prim::ListConstruct(%4152, %4153, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %input.391 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.42, %4154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:283:0
  %4156 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25278.NoNorm = prim::GetAttr[name="LayerNorm"](%4104)
  %4157 : __torch__.torch.nn.modules.linear.___torch_mangle_25277.Linear = prim::GetAttr[name="dense"](%4104)
  %4158 : Tensor = prim::GetAttr[name="bias"](%4157)
  %4159 : Tensor = prim::GetAttr[name="weight"](%4157)
  %4160 : Float(128:1, 128:128) = aten::t(%4159), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %output.307 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.391, %4160), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.307, %4158, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.164 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.101, %4103, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output # transformers/modeling_mobilebert.py:301:0
  %4164 : Tensor = prim::GetAttr[name="bias"](%4156)
  %4165 : Tensor = prim::GetAttr[name="weight"](%4156)
  %4166 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.164, %4165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.392 : Float(17:1664, 13:128, 128:1) = aten::add(%4166, %4164, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4168 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25301.FFNOutput = prim::GetAttr[name="output"](%4074)
  %4169 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25298.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4074)
  %4170 : __torch__.torch.nn.modules.linear.___torch_mangle_25297.Linear = prim::GetAttr[name="dense"](%4169)
  %4171 : Tensor = prim::GetAttr[name="bias"](%4170)
  %4172 : Tensor = prim::GetAttr[name="weight"](%4170)
  %4173 : Float(128:1, 512:128) = aten::t(%4172), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.308 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.392, %4173), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.393 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.308, %4171, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.394 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4177 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25300.NoNorm = prim::GetAttr[name="LayerNorm"](%4168)
  %4178 : __torch__.torch.nn.modules.linear.___torch_mangle_25299.Linear = prim::GetAttr[name="dense"](%4168)
  %4179 : Tensor = prim::GetAttr[name="bias"](%4178)
  %4180 : Tensor = prim::GetAttr[name="weight"](%4178)
  %4181 : Float(512:1, 128:512) = aten::t(%4180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.309 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.394, %4181), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.102 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.309, %4179, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.165 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.102, %input.392, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4185 : Tensor = prim::GetAttr[name="bias"](%4177)
  %4186 : Tensor = prim::GetAttr[name="weight"](%4177)
  %4187 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.165, %4186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.395 : Float(17:1664, 13:128, 128:1) = aten::add(%4187, %4185, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4189 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25307.FFNOutput = prim::GetAttr[name="output"](%4072)
  %4190 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25304.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4072)
  %4191 : __torch__.torch.nn.modules.linear.___torch_mangle_25303.Linear = prim::GetAttr[name="dense"](%4190)
  %4192 : Tensor = prim::GetAttr[name="bias"](%4191)
  %4193 : Tensor = prim::GetAttr[name="weight"](%4191)
  %4194 : Float(128:1, 512:128) = aten::t(%4193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.310 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.395, %4194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.396 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.310, %4192, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.397 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4198 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25306.NoNorm = prim::GetAttr[name="LayerNorm"](%4189)
  %4199 : __torch__.torch.nn.modules.linear.___torch_mangle_25305.Linear = prim::GetAttr[name="dense"](%4189)
  %4200 : Tensor = prim::GetAttr[name="bias"](%4199)
  %4201 : Tensor = prim::GetAttr[name="weight"](%4199)
  %4202 : Float(512:1, 128:512) = aten::t(%4201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.311 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.397, %4202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.311, %4200, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.166 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.103, %input.395, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4206 : Tensor = prim::GetAttr[name="bias"](%4198)
  %4207 : Tensor = prim::GetAttr[name="weight"](%4198)
  %4208 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.166, %4207), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.398 : Float(17:1664, 13:128, 128:1) = aten::add(%4208, %4206, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4210 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25313.FFNOutput = prim::GetAttr[name="output"](%4070)
  %4211 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25310.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4070)
  %4212 : __torch__.torch.nn.modules.linear.___torch_mangle_25309.Linear = prim::GetAttr[name="dense"](%4211)
  %4213 : Tensor = prim::GetAttr[name="bias"](%4212)
  %4214 : Tensor = prim::GetAttr[name="weight"](%4212)
  %4215 : Float(128:1, 512:128) = aten::t(%4214), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.312 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.398, %4215), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.399 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.312, %4213, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.400 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4219 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25312.NoNorm = prim::GetAttr[name="LayerNorm"](%4210)
  %4220 : __torch__.torch.nn.modules.linear.___torch_mangle_25311.Linear = prim::GetAttr[name="dense"](%4210)
  %4221 : Tensor = prim::GetAttr[name="bias"](%4220)
  %4222 : Tensor = prim::GetAttr[name="weight"](%4220)
  %4223 : Float(512:1, 128:512) = aten::t(%4222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.313 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.400, %4223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.104 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.313, %4221, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.167 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.104, %input.398, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4227 : Tensor = prim::GetAttr[name="bias"](%4219)
  %4228 : Tensor = prim::GetAttr[name="weight"](%4219)
  %4229 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.167, %4228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.401 : Float(17:1664, 13:128, 128:1) = aten::add(%4229, %4227, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4231 : __torch__.torch.nn.modules.linear.___torch_mangle_25281.Linear = prim::GetAttr[name="dense"](%4068)
  %4232 : Tensor = prim::GetAttr[name="bias"](%4231)
  %4233 : Tensor = prim::GetAttr[name="weight"](%4231)
  %4234 : Float(128:1, 512:128) = aten::t(%4233), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %output.314 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.401, %4234), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %input.402 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.314, %4232, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1678:0
  %input.403 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate # torch/nn/functional.py:1119:0
  %4238 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25288.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4067)
  %4239 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25284.NoNorm = prim::GetAttr[name="LayerNorm"](%4067)
  %4240 : __torch__.torch.nn.modules.linear.___torch_mangle_25283.Linear = prim::GetAttr[name="dense"](%4067)
  %4241 : Tensor = prim::GetAttr[name="bias"](%4240)
  %4242 : Tensor = prim::GetAttr[name="weight"](%4240)
  %4243 : Float(512:1, 128:512) = aten::t(%4242), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %output.315 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.403, %4243), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %layer_output.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.315, %4241, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.168 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.21, %input.401, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output # transformers/modeling_mobilebert.py:405:0
  %4247 : Tensor = prim::GetAttr[name="bias"](%4239)
  %4248 : Tensor = prim::GetAttr[name="weight"](%4239)
  %4249 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.168, %4248), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.404 : Float(17:1664, 13:128, 128:1) = aten::add(%4249, %4247, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4251 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25286.NoNorm = prim::GetAttr[name="LayerNorm"](%4238)
  %4252 : __torch__.torch.nn.modules.linear.___torch_mangle_25285.Linear = prim::GetAttr[name="dense"](%4238)
  %4253 : Tensor = prim::GetAttr[name="bias"](%4252)
  %4254 : Tensor = prim::GetAttr[name="weight"](%4252)
  %4255 : Float(128:1, 512:128) = aten::t(%4254), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.316 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.404, %4255), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.405 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.316, %4253, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.105 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.405, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.169 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.105, %input.387, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4260 : Tensor = prim::GetAttr[name="bias"](%4251)
  %4261 : Tensor = prim::GetAttr[name="weight"](%4251)
  %4262 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.169, %4261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.406 : Float(17:6656, 13:512, 512:1) = aten::add(%4262, %4260, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4264 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25334.MobileBertOutput = prim::GetAttr[name="output"](%84)
  %4265 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25327.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%84)
  %4266 : __torch__.torch.nn.modules.container.___torch_mangle_25360.ModuleList = prim::GetAttr[name="ffn"](%84)
  %4267 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25359.FFNLayer = prim::GetAttr[name="2"](%4266)
  %4268 : __torch__.torch.nn.modules.container.___torch_mangle_25360.ModuleList = prim::GetAttr[name="ffn"](%84)
  %4269 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25353.FFNLayer = prim::GetAttr[name="1"](%4268)
  %4270 : __torch__.torch.nn.modules.container.___torch_mangle_25360.ModuleList = prim::GetAttr[name="ffn"](%84)
  %4271 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25347.FFNLayer = prim::GetAttr[name="0"](%4270)
  %4272 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25325.MobileBertAttention = prim::GetAttr[name="attention"](%84)
  %4273 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25341.Bottleneck = prim::GetAttr[name="bottleneck"](%84)
  %4274 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25340.BottleneckLayer = prim::GetAttr[name="attention"](%4273)
  %4275 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25337.BottleneckLayer = prim::GetAttr[name="input"](%4273)
  %4276 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25336.NoNorm = prim::GetAttr[name="LayerNorm"](%4275)
  %4277 : __torch__.torch.nn.modules.linear.___torch_mangle_25335.Linear = prim::GetAttr[name="dense"](%4275)
  %4278 : Tensor = prim::GetAttr[name="bias"](%4277)
  %4279 : Tensor = prim::GetAttr[name="weight"](%4277)
  %4280 : Float(512:1, 128:512) = aten::t(%4279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.317 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4280), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.170 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.317, %4278, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4283 : Tensor = prim::GetAttr[name="bias"](%4276)
  %4284 : Tensor = prim::GetAttr[name="weight"](%4276)
  %4285 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.170, %4284), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%4285, %4283, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4287 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25339.NoNorm = prim::GetAttr[name="LayerNorm"](%4274)
  %4288 : __torch__.torch.nn.modules.linear.___torch_mangle_25338.Linear = prim::GetAttr[name="dense"](%4274)
  %4289 : Tensor = prim::GetAttr[name="bias"](%4288)
  %4290 : Tensor = prim::GetAttr[name="weight"](%4288)
  %4291 : Float(512:1, 128:512) = aten::t(%4290), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.318 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4291), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.171 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.318, %4289, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4294 : Tensor = prim::GetAttr[name="bias"](%4287)
  %4295 : Tensor = prim::GetAttr[name="weight"](%4287)
  %4296 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.171, %4295), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.407 : Float(17:1664, 13:128, 128:1) = aten::add(%4296, %4294, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4298 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.407, %residual_tensor.22)
  %4299 : Float(17:1664, 13:128, 128:1), %4300 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4298)
  %4301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25324.MobileBertSelfOutput = prim::GetAttr[name="output"](%4272)
  %4302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25321.MobileBertSelfAttention = prim::GetAttr[name="self"](%4272)
  %4303 : __torch__.torch.nn.modules.linear.___torch_mangle_25319.Linear = prim::GetAttr[name="value"](%4302)
  %4304 : __torch__.torch.nn.modules.linear.___torch_mangle_25318.Linear = prim::GetAttr[name="key"](%4302)
  %4305 : __torch__.torch.nn.modules.linear.___torch_mangle_25317.Linear = prim::GetAttr[name="query"](%4302)
  %4306 : Tensor = prim::GetAttr[name="bias"](%4305)
  %4307 : Tensor = prim::GetAttr[name="weight"](%4305)
  %4308 : Float(128:1, 128:128) = aten::t(%4307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %output.319 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4299, %4308), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %x.127 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.319, %4306, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1678:0
  %4311 : Tensor = prim::GetAttr[name="bias"](%4304)
  %4312 : Tensor = prim::GetAttr[name="weight"](%4304)
  %4313 : Float(128:1, 128:128) = aten::t(%4312), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %output.320 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4299, %4313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %x.129 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.320, %4311, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1678:0
  %4316 : Tensor = prim::GetAttr[name="bias"](%4303)
  %4317 : Tensor = prim::GetAttr[name="weight"](%4303)
  %4318 : Float(512:1, 128:512) = aten::t(%4317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %output.321 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4318), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %x.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.321, %4316, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1678:0
  %4321 : int = aten::size(%x.127, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4322 : int = aten::size(%x.127, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4323 : int[] = prim::ListConstruct(%4321, %4322, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.128 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.127, %4323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4325 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %query_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.128, %4325), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4327 : int = aten::size(%x.129, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4328 : int = aten::size(%x.129, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4329 : int[] = prim::ListConstruct(%4327, %4328, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.130 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.129, %4329), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4331 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %key_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.130, %4331), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4333 : int = aten::size(%x.131, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4334 : int = aten::size(%x.131, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4335 : int[] = prim::ListConstruct(%4333, %4334, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.132 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.131, %4335), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4337 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %value_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.132, %4337), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4339 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.22, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.43 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.22, %4339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.44 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.43, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.408 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.44, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.409 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.408, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.409, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.43 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.22, %value_layer.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:280:0
  %4346 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %4347 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.43, %4346), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4347, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %4349 : int = aten::size(%context_layer.44, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4350 : int = aten::size(%context_layer.44, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4351 : int[] = prim::ListConstruct(%4349, %4350, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %input.410 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.44, %4351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:283:0
  %4353 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25323.NoNorm = prim::GetAttr[name="LayerNorm"](%4301)
  %4354 : __torch__.torch.nn.modules.linear.___torch_mangle_25322.Linear = prim::GetAttr[name="dense"](%4301)
  %4355 : Tensor = prim::GetAttr[name="bias"](%4354)
  %4356 : Tensor = prim::GetAttr[name="weight"](%4354)
  %4357 : Float(128:1, 128:128) = aten::t(%4356), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %output.322 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.410, %4357), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.322, %4355, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.172 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.106, %4300, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output # transformers/modeling_mobilebert.py:301:0
  %4361 : Tensor = prim::GetAttr[name="bias"](%4353)
  %4362 : Tensor = prim::GetAttr[name="weight"](%4353)
  %4363 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.172, %4362), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.411 : Float(17:1664, 13:128, 128:1) = aten::add(%4363, %4361, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4365 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25346.FFNOutput = prim::GetAttr[name="output"](%4271)
  %4366 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25343.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4271)
  %4367 : __torch__.torch.nn.modules.linear.___torch_mangle_25342.Linear = prim::GetAttr[name="dense"](%4366)
  %4368 : Tensor = prim::GetAttr[name="bias"](%4367)
  %4369 : Tensor = prim::GetAttr[name="weight"](%4367)
  %4370 : Float(128:1, 512:128) = aten::t(%4369), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.323 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.411, %4370), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.412 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.323, %4368, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.413 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4374 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25345.NoNorm = prim::GetAttr[name="LayerNorm"](%4365)
  %4375 : __torch__.torch.nn.modules.linear.___torch_mangle_25344.Linear = prim::GetAttr[name="dense"](%4365)
  %4376 : Tensor = prim::GetAttr[name="bias"](%4375)
  %4377 : Tensor = prim::GetAttr[name="weight"](%4375)
  %4378 : Float(512:1, 128:512) = aten::t(%4377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.324 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.413, %4378), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.324, %4376, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.173 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.107, %input.411, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4382 : Tensor = prim::GetAttr[name="bias"](%4374)
  %4383 : Tensor = prim::GetAttr[name="weight"](%4374)
  %4384 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.173, %4383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.414 : Float(17:1664, 13:128, 128:1) = aten::add(%4384, %4382, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4386 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25352.FFNOutput = prim::GetAttr[name="output"](%4269)
  %4387 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25349.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4269)
  %4388 : __torch__.torch.nn.modules.linear.___torch_mangle_25348.Linear = prim::GetAttr[name="dense"](%4387)
  %4389 : Tensor = prim::GetAttr[name="bias"](%4388)
  %4390 : Tensor = prim::GetAttr[name="weight"](%4388)
  %4391 : Float(128:1, 512:128) = aten::t(%4390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.325 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.414, %4391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.415 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.325, %4389, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.416 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4395 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25351.NoNorm = prim::GetAttr[name="LayerNorm"](%4386)
  %4396 : __torch__.torch.nn.modules.linear.___torch_mangle_25350.Linear = prim::GetAttr[name="dense"](%4386)
  %4397 : Tensor = prim::GetAttr[name="bias"](%4396)
  %4398 : Tensor = prim::GetAttr[name="weight"](%4396)
  %4399 : Float(512:1, 128:512) = aten::t(%4398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.326 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.416, %4399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.108 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.326, %4397, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.174 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.108, %input.414, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4403 : Tensor = prim::GetAttr[name="bias"](%4395)
  %4404 : Tensor = prim::GetAttr[name="weight"](%4395)
  %4405 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.174, %4404), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.417 : Float(17:1664, 13:128, 128:1) = aten::add(%4405, %4403, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4407 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25358.FFNOutput = prim::GetAttr[name="output"](%4267)
  %4408 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25355.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4267)
  %4409 : __torch__.torch.nn.modules.linear.___torch_mangle_25354.Linear = prim::GetAttr[name="dense"](%4408)
  %4410 : Tensor = prim::GetAttr[name="bias"](%4409)
  %4411 : Tensor = prim::GetAttr[name="weight"](%4409)
  %4412 : Float(128:1, 512:128) = aten::t(%4411), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.327 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.417, %4412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.418 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.327, %4410, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.419 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4416 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25357.NoNorm = prim::GetAttr[name="LayerNorm"](%4407)
  %4417 : __torch__.torch.nn.modules.linear.___torch_mangle_25356.Linear = prim::GetAttr[name="dense"](%4407)
  %4418 : Tensor = prim::GetAttr[name="bias"](%4417)
  %4419 : Tensor = prim::GetAttr[name="weight"](%4417)
  %4420 : Float(512:1, 128:512) = aten::t(%4419), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.328 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.419, %4420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.328, %4418, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.175 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.109, %input.417, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4424 : Tensor = prim::GetAttr[name="bias"](%4416)
  %4425 : Tensor = prim::GetAttr[name="weight"](%4416)
  %4426 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.175, %4425), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.420 : Float(17:1664, 13:128, 128:1) = aten::add(%4426, %4424, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4428 : __torch__.torch.nn.modules.linear.___torch_mangle_25326.Linear = prim::GetAttr[name="dense"](%4265)
  %4429 : Tensor = prim::GetAttr[name="bias"](%4428)
  %4430 : Tensor = prim::GetAttr[name="weight"](%4428)
  %4431 : Float(128:1, 512:128) = aten::t(%4430), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %output.329 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.420, %4431), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %input.421 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.329, %4429, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1678:0
  %input.422 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate # torch/nn/functional.py:1119:0
  %4435 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25333.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4264)
  %4436 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25329.NoNorm = prim::GetAttr[name="LayerNorm"](%4264)
  %4437 : __torch__.torch.nn.modules.linear.___torch_mangle_25328.Linear = prim::GetAttr[name="dense"](%4264)
  %4438 : Tensor = prim::GetAttr[name="bias"](%4437)
  %4439 : Tensor = prim::GetAttr[name="weight"](%4437)
  %4440 : Float(512:1, 128:512) = aten::t(%4439), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %output.330 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.422, %4440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %layer_output.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.330, %4438, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.176 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.22, %input.420, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output # transformers/modeling_mobilebert.py:405:0
  %4444 : Tensor = prim::GetAttr[name="bias"](%4436)
  %4445 : Tensor = prim::GetAttr[name="weight"](%4436)
  %4446 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.176, %4445), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.423 : Float(17:1664, 13:128, 128:1) = aten::add(%4446, %4444, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4448 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25331.NoNorm = prim::GetAttr[name="LayerNorm"](%4435)
  %4449 : __torch__.torch.nn.modules.linear.___torch_mangle_25330.Linear = prim::GetAttr[name="dense"](%4435)
  %4450 : Tensor = prim::GetAttr[name="bias"](%4449)
  %4451 : Tensor = prim::GetAttr[name="weight"](%4449)
  %4452 : Float(128:1, 512:128) = aten::t(%4451), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.331 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.423, %4452), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.424 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.331, %4450, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.110 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.424, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.177 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.110, %input.406, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4457 : Tensor = prim::GetAttr[name="bias"](%4448)
  %4458 : Tensor = prim::GetAttr[name="weight"](%4448)
  %4459 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.177, %4458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.425 : Float(17:6656, 13:512, 512:1) = aten::add(%4459, %4457, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4461 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25379.MobileBertOutput = prim::GetAttr[name="output"](%82)
  %4462 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25372.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%82)
  %4463 : __torch__.torch.nn.modules.container.___torch_mangle_25405.ModuleList = prim::GetAttr[name="ffn"](%82)
  %4464 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25404.FFNLayer = prim::GetAttr[name="2"](%4463)
  %4465 : __torch__.torch.nn.modules.container.___torch_mangle_25405.ModuleList = prim::GetAttr[name="ffn"](%82)
  %4466 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25398.FFNLayer = prim::GetAttr[name="1"](%4465)
  %4467 : __torch__.torch.nn.modules.container.___torch_mangle_25405.ModuleList = prim::GetAttr[name="ffn"](%82)
  %4468 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25392.FFNLayer = prim::GetAttr[name="0"](%4467)
  %4469 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25370.MobileBertAttention = prim::GetAttr[name="attention"](%82)
  %4470 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25386.Bottleneck = prim::GetAttr[name="bottleneck"](%82)
  %4471 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25385.BottleneckLayer = prim::GetAttr[name="attention"](%4470)
  %4472 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25382.BottleneckLayer = prim::GetAttr[name="input"](%4470)
  %4473 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25381.NoNorm = prim::GetAttr[name="LayerNorm"](%4472)
  %4474 : __torch__.torch.nn.modules.linear.___torch_mangle_25380.Linear = prim::GetAttr[name="dense"](%4472)
  %4475 : Tensor = prim::GetAttr[name="bias"](%4474)
  %4476 : Tensor = prim::GetAttr[name="weight"](%4474)
  %4477 : Float(512:1, 128:512) = aten::t(%4476), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.332 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4477), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.178 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.332, %4475, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4480 : Tensor = prim::GetAttr[name="bias"](%4473)
  %4481 : Tensor = prim::GetAttr[name="weight"](%4473)
  %4482 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.178, %4481), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%4482, %4480, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4484 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25384.NoNorm = prim::GetAttr[name="LayerNorm"](%4471)
  %4485 : __torch__.torch.nn.modules.linear.___torch_mangle_25383.Linear = prim::GetAttr[name="dense"](%4471)
  %4486 : Tensor = prim::GetAttr[name="bias"](%4485)
  %4487 : Tensor = prim::GetAttr[name="weight"](%4485)
  %4488 : Float(512:1, 128:512) = aten::t(%4487), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.333 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4488), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.179 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.333, %4486, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4491 : Tensor = prim::GetAttr[name="bias"](%4484)
  %4492 : Tensor = prim::GetAttr[name="weight"](%4484)
  %4493 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.179, %4492), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.426 : Float(17:1664, 13:128, 128:1) = aten::add(%4493, %4491, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4495 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.426, %residual_tensor.23)
  %4496 : Float(17:1664, 13:128, 128:1), %4497 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4495)
  %4498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25369.MobileBertSelfOutput = prim::GetAttr[name="output"](%4469)
  %4499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25366.MobileBertSelfAttention = prim::GetAttr[name="self"](%4469)
  %4500 : __torch__.torch.nn.modules.linear.___torch_mangle_25364.Linear = prim::GetAttr[name="value"](%4499)
  %4501 : __torch__.torch.nn.modules.linear.___torch_mangle_25363.Linear = prim::GetAttr[name="key"](%4499)
  %4502 : __torch__.torch.nn.modules.linear.___torch_mangle_25362.Linear = prim::GetAttr[name="query"](%4499)
  %4503 : Tensor = prim::GetAttr[name="bias"](%4502)
  %4504 : Tensor = prim::GetAttr[name="weight"](%4502)
  %4505 : Float(128:1, 128:128) = aten::t(%4504), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %output.334 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4496, %4505), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %x.133 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.334, %4503, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1678:0
  %4508 : Tensor = prim::GetAttr[name="bias"](%4501)
  %4509 : Tensor = prim::GetAttr[name="weight"](%4501)
  %4510 : Float(128:1, 128:128) = aten::t(%4509), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %output.335 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4496, %4510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %x.135 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.335, %4508, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1678:0
  %4513 : Tensor = prim::GetAttr[name="bias"](%4500)
  %4514 : Tensor = prim::GetAttr[name="weight"](%4500)
  %4515 : Float(512:1, 128:512) = aten::t(%4514), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %output.336 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4515), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %x.137 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.336, %4513, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1678:0
  %4518 : int = aten::size(%x.133, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4519 : int = aten::size(%x.133, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4520 : int[] = prim::ListConstruct(%4518, %4519, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.134 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.133, %4520), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4522 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %query_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.134, %4522), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4524 : int = aten::size(%x.135, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4525 : int = aten::size(%x.135, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4526 : int[] = prim::ListConstruct(%4524, %4525, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.136 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.135, %4526), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4528 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %key_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.136, %4528), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4530 : int = aten::size(%x.137, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4531 : int = aten::size(%x.137, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4532 : int[] = prim::ListConstruct(%4530, %4531, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.138 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.137, %4532), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4534 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %value_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.138, %4534), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4536 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.23, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.45 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.23, %4536), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.46 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.45, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.427 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.46, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.428 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.427, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.428, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.45 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.23, %value_layer.23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:280:0
  %4543 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %4544 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.45, %4543), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4544, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %4546 : int = aten::size(%context_layer.46, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4547 : int = aten::size(%context_layer.46, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4548 : int[] = prim::ListConstruct(%4546, %4547, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %input.429 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.46, %4548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:283:0
  %4550 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25368.NoNorm = prim::GetAttr[name="LayerNorm"](%4498)
  %4551 : __torch__.torch.nn.modules.linear.___torch_mangle_25367.Linear = prim::GetAttr[name="dense"](%4498)
  %4552 : Tensor = prim::GetAttr[name="bias"](%4551)
  %4553 : Tensor = prim::GetAttr[name="weight"](%4551)
  %4554 : Float(128:1, 128:128) = aten::t(%4553), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %output.337 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.429, %4554), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.337, %4552, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.180 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.111, %4497, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output # transformers/modeling_mobilebert.py:301:0
  %4558 : Tensor = prim::GetAttr[name="bias"](%4550)
  %4559 : Tensor = prim::GetAttr[name="weight"](%4550)
  %4560 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.180, %4559), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.430 : Float(17:1664, 13:128, 128:1) = aten::add(%4560, %4558, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4562 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25391.FFNOutput = prim::GetAttr[name="output"](%4468)
  %4563 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25388.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4468)
  %4564 : __torch__.torch.nn.modules.linear.___torch_mangle_25387.Linear = prim::GetAttr[name="dense"](%4563)
  %4565 : Tensor = prim::GetAttr[name="bias"](%4564)
  %4566 : Tensor = prim::GetAttr[name="weight"](%4564)
  %4567 : Float(128:1, 512:128) = aten::t(%4566), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.338 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.430, %4567), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.431 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.338, %4565, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.432 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.431), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4571 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25390.NoNorm = prim::GetAttr[name="LayerNorm"](%4562)
  %4572 : __torch__.torch.nn.modules.linear.___torch_mangle_25389.Linear = prim::GetAttr[name="dense"](%4562)
  %4573 : Tensor = prim::GetAttr[name="bias"](%4572)
  %4574 : Tensor = prim::GetAttr[name="weight"](%4572)
  %4575 : Float(512:1, 128:512) = aten::t(%4574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.339 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.432, %4575), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.112 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.339, %4573, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.181 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.112, %input.430, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4579 : Tensor = prim::GetAttr[name="bias"](%4571)
  %4580 : Tensor = prim::GetAttr[name="weight"](%4571)
  %4581 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.181, %4580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.433 : Float(17:1664, 13:128, 128:1) = aten::add(%4581, %4579, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4583 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25397.FFNOutput = prim::GetAttr[name="output"](%4466)
  %4584 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25394.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4466)
  %4585 : __torch__.torch.nn.modules.linear.___torch_mangle_25393.Linear = prim::GetAttr[name="dense"](%4584)
  %4586 : Tensor = prim::GetAttr[name="bias"](%4585)
  %4587 : Tensor = prim::GetAttr[name="weight"](%4585)
  %4588 : Float(128:1, 512:128) = aten::t(%4587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.340 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.433, %4588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.434 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.340, %4586, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.435 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4592 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25396.NoNorm = prim::GetAttr[name="LayerNorm"](%4583)
  %4593 : __torch__.torch.nn.modules.linear.___torch_mangle_25395.Linear = prim::GetAttr[name="dense"](%4583)
  %4594 : Tensor = prim::GetAttr[name="bias"](%4593)
  %4595 : Tensor = prim::GetAttr[name="weight"](%4593)
  %4596 : Float(512:1, 128:512) = aten::t(%4595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.341 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.435, %4596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.341, %4594, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.182 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.113, %input.433, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4600 : Tensor = prim::GetAttr[name="bias"](%4592)
  %4601 : Tensor = prim::GetAttr[name="weight"](%4592)
  %4602 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.182, %4601), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.436 : Float(17:1664, 13:128, 128:1) = aten::add(%4602, %4600, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4604 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25403.FFNOutput = prim::GetAttr[name="output"](%4464)
  %4605 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25400.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4464)
  %4606 : __torch__.torch.nn.modules.linear.___torch_mangle_25399.Linear = prim::GetAttr[name="dense"](%4605)
  %4607 : Tensor = prim::GetAttr[name="bias"](%4606)
  %4608 : Tensor = prim::GetAttr[name="weight"](%4606)
  %4609 : Float(128:1, 512:128) = aten::t(%4608), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.342 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.436, %4609), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.437 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.342, %4607, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.438 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4613 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25402.NoNorm = prim::GetAttr[name="LayerNorm"](%4604)
  %4614 : __torch__.torch.nn.modules.linear.___torch_mangle_25401.Linear = prim::GetAttr[name="dense"](%4604)
  %4615 : Tensor = prim::GetAttr[name="bias"](%4614)
  %4616 : Tensor = prim::GetAttr[name="weight"](%4614)
  %4617 : Float(512:1, 128:512) = aten::t(%4616), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.343 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.438, %4617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.343, %4615, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.183 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.114, %input.436, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4621 : Tensor = prim::GetAttr[name="bias"](%4613)
  %4622 : Tensor = prim::GetAttr[name="weight"](%4613)
  %4623 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.183, %4622), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.439 : Float(17:1664, 13:128, 128:1) = aten::add(%4623, %4621, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4625 : __torch__.torch.nn.modules.linear.___torch_mangle_25371.Linear = prim::GetAttr[name="dense"](%4462)
  %4626 : Tensor = prim::GetAttr[name="bias"](%4625)
  %4627 : Tensor = prim::GetAttr[name="weight"](%4625)
  %4628 : Float(128:1, 512:128) = aten::t(%4627), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %output.344 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.439, %4628), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %input.440 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.344, %4626, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1678:0
  %input.441 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate # torch/nn/functional.py:1119:0
  %4632 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25378.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4461)
  %4633 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25374.NoNorm = prim::GetAttr[name="LayerNorm"](%4461)
  %4634 : __torch__.torch.nn.modules.linear.___torch_mangle_25373.Linear = prim::GetAttr[name="dense"](%4461)
  %4635 : Tensor = prim::GetAttr[name="bias"](%4634)
  %4636 : Tensor = prim::GetAttr[name="weight"](%4634)
  %4637 : Float(512:1, 128:512) = aten::t(%4636), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %output.345 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.441, %4637), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %layer_output.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.345, %4635, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.184 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.23, %input.439, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output # transformers/modeling_mobilebert.py:405:0
  %4641 : Tensor = prim::GetAttr[name="bias"](%4633)
  %4642 : Tensor = prim::GetAttr[name="weight"](%4633)
  %4643 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.184, %4642), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.442 : Float(17:1664, 13:128, 128:1) = aten::add(%4643, %4641, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4645 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25376.NoNorm = prim::GetAttr[name="LayerNorm"](%4632)
  %4646 : __torch__.torch.nn.modules.linear.___torch_mangle_25375.Linear = prim::GetAttr[name="dense"](%4632)
  %4647 : Tensor = prim::GetAttr[name="bias"](%4646)
  %4648 : Tensor = prim::GetAttr[name="weight"](%4646)
  %4649 : Float(128:1, 512:128) = aten::t(%4648), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.346 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.442, %4649), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.443 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.346, %4647, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.115 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.443, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.185 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.115, %input.425, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4654 : Tensor = prim::GetAttr[name="bias"](%4645)
  %4655 : Tensor = prim::GetAttr[name="weight"](%4645)
  %4656 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.185, %4655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.444 : Float(17:6656, 13:512, 512:1) = aten::add(%4656, %4654, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4658 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25424.MobileBertOutput = prim::GetAttr[name="output"](%80)
  %4659 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25417.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%80)
  %4660 : __torch__.torch.nn.modules.container.___torch_mangle_25450.ModuleList = prim::GetAttr[name="ffn"](%80)
  %4661 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25449.FFNLayer = prim::GetAttr[name="2"](%4660)
  %4662 : __torch__.torch.nn.modules.container.___torch_mangle_25450.ModuleList = prim::GetAttr[name="ffn"](%80)
  %4663 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25443.FFNLayer = prim::GetAttr[name="1"](%4662)
  %4664 : __torch__.torch.nn.modules.container.___torch_mangle_25450.ModuleList = prim::GetAttr[name="ffn"](%80)
  %4665 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25437.FFNLayer = prim::GetAttr[name="0"](%4664)
  %4666 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25415.MobileBertAttention = prim::GetAttr[name="attention"](%80)
  %4667 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25431.Bottleneck = prim::GetAttr[name="bottleneck"](%80)
  %4668 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25430.BottleneckLayer = prim::GetAttr[name="attention"](%4667)
  %4669 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25427.BottleneckLayer = prim::GetAttr[name="input"](%4667)
  %4670 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25426.NoNorm = prim::GetAttr[name="LayerNorm"](%4669)
  %4671 : __torch__.torch.nn.modules.linear.___torch_mangle_25425.Linear = prim::GetAttr[name="dense"](%4669)
  %4672 : Tensor = prim::GetAttr[name="bias"](%4671)
  %4673 : Tensor = prim::GetAttr[name="weight"](%4671)
  %4674 : Float(512:1, 128:512) = aten::t(%4673), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.347 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4674), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.186 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.347, %4672, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4677 : Tensor = prim::GetAttr[name="bias"](%4670)
  %4678 : Tensor = prim::GetAttr[name="weight"](%4670)
  %4679 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.186, %4678), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor : Float(17:1664, 13:128, 128:1) = aten::add(%4679, %4677, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4681 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25429.NoNorm = prim::GetAttr[name="LayerNorm"](%4668)
  %4682 : __torch__.torch.nn.modules.linear.___torch_mangle_25428.Linear = prim::GetAttr[name="dense"](%4668)
  %4683 : Tensor = prim::GetAttr[name="bias"](%4682)
  %4684 : Tensor = prim::GetAttr[name="weight"](%4682)
  %4685 : Float(512:1, 128:512) = aten::t(%4684), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.348 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4685), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.187 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.348, %4683, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4688 : Tensor = prim::GetAttr[name="bias"](%4681)
  %4689 : Tensor = prim::GetAttr[name="weight"](%4681)
  %4690 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.187, %4689), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.445 : Float(17:1664, 13:128, 128:1) = aten::add(%4690, %4688, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4692 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.445, %residual_tensor)
  %4693 : Float(17:1664, 13:128, 128:1), %4694 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4692)
  %4695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25414.MobileBertSelfOutput = prim::GetAttr[name="output"](%4666)
  %4696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25411.MobileBertSelfAttention = prim::GetAttr[name="self"](%4666)
  %4697 : __torch__.torch.nn.modules.linear.___torch_mangle_25409.Linear = prim::GetAttr[name="value"](%4696)
  %4698 : __torch__.torch.nn.modules.linear.___torch_mangle_25408.Linear = prim::GetAttr[name="key"](%4696)
  %4699 : __torch__.torch.nn.modules.linear.___torch_mangle_25407.Linear = prim::GetAttr[name="query"](%4696)
  %4700 : Tensor = prim::GetAttr[name="bias"](%4699)
  %4701 : Tensor = prim::GetAttr[name="weight"](%4699)
  %4702 : Float(128:1, 128:128) = aten::t(%4701), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %output.349 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4693, %4702), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %x.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.349, %4700, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1678:0
  %4705 : Tensor = prim::GetAttr[name="bias"](%4698)
  %4706 : Tensor = prim::GetAttr[name="weight"](%4698)
  %4707 : Float(128:1, 128:128) = aten::t(%4706), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %output.350 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4693, %4707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %x.141 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.350, %4705, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1678:0
  %4710 : Tensor = prim::GetAttr[name="bias"](%4697)
  %4711 : Tensor = prim::GetAttr[name="weight"](%4697)
  %4712 : Float(512:1, 128:512) = aten::t(%4711), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %output.351 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4712), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %x.143 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.351, %4710, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1678:0
  %4715 : int = aten::size(%x.139, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4716 : int = aten::size(%x.139, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4717 : int[] = prim::ListConstruct(%4715, %4716, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.140 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.139, %4717), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4719 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %query_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.140, %4719), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4721 : int = aten::size(%x.141, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4722 : int = aten::size(%x.141, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4723 : int[] = prim::ListConstruct(%4721, %4722, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.142 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.141, %4723), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4725 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %key_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.142, %4725), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4727 : int = aten::size(%x.143, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4728 : int = aten::size(%x.143, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4729 : int[] = prim::ListConstruct(%4727, %4728, %26, %14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.143, %4729), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4731 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %value_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x, %4731), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4733 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer, %15, %13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer, %4733), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.47, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.446 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores, %attention_mask, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.447 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.446, %15, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # torch/nn/functional.py:1498:0
  %attention_probs : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.447, %11, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.47 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:280:0
  %4740 : int[] = prim::ListConstruct(%28, %22, %27, %21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %4741 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.47, %4740), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4741, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %4743 : int = aten::size(%context_layer, %28), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4744 : int = aten::size(%context_layer, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4745 : int[] = prim::ListConstruct(%4743, %4744, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %input.448 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer, %4745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:283:0
  %4747 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25413.NoNorm = prim::GetAttr[name="LayerNorm"](%4695)
  %4748 : __torch__.torch.nn.modules.linear.___torch_mangle_25412.Linear = prim::GetAttr[name="dense"](%4695)
  %4749 : Tensor = prim::GetAttr[name="bias"](%4748)
  %4750 : Tensor = prim::GetAttr[name="weight"](%4748)
  %4751 : Float(128:1, 128:128) = aten::t(%4750), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %output.352 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.448, %4751), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.116 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.352, %4749, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.188 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.116, %4694, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output # transformers/modeling_mobilebert.py:301:0
  %4755 : Tensor = prim::GetAttr[name="bias"](%4747)
  %4756 : Tensor = prim::GetAttr[name="weight"](%4747)
  %4757 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.188, %4756), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.449 : Float(17:1664, 13:128, 128:1) = aten::add(%4757, %4755, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4759 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25436.FFNOutput = prim::GetAttr[name="output"](%4665)
  %4760 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25433.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4665)
  %4761 : __torch__.torch.nn.modules.linear.___torch_mangle_25432.Linear = prim::GetAttr[name="dense"](%4760)
  %4762 : Tensor = prim::GetAttr[name="bias"](%4761)
  %4763 : Tensor = prim::GetAttr[name="weight"](%4761)
  %4764 : Float(128:1, 512:128) = aten::t(%4763), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.353 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.449, %4764), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.450 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.353, %4762, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.451 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4768 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25435.NoNorm = prim::GetAttr[name="LayerNorm"](%4759)
  %4769 : __torch__.torch.nn.modules.linear.___torch_mangle_25434.Linear = prim::GetAttr[name="dense"](%4759)
  %4770 : Tensor = prim::GetAttr[name="bias"](%4769)
  %4771 : Tensor = prim::GetAttr[name="weight"](%4769)
  %4772 : Float(512:1, 128:512) = aten::t(%4771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.354 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.451, %4772), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.354, %4770, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.189 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.117, %input.449, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4776 : Tensor = prim::GetAttr[name="bias"](%4768)
  %4777 : Tensor = prim::GetAttr[name="weight"](%4768)
  %4778 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.189, %4777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.452 : Float(17:1664, 13:128, 128:1) = aten::add(%4778, %4776, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4780 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25442.FFNOutput = prim::GetAttr[name="output"](%4663)
  %4781 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25439.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4663)
  %4782 : __torch__.torch.nn.modules.linear.___torch_mangle_25438.Linear = prim::GetAttr[name="dense"](%4781)
  %4783 : Tensor = prim::GetAttr[name="bias"](%4782)
  %4784 : Tensor = prim::GetAttr[name="weight"](%4782)
  %4785 : Float(128:1, 512:128) = aten::t(%4784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.355 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.452, %4785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.453 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.355, %4783, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.454 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4789 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25441.NoNorm = prim::GetAttr[name="LayerNorm"](%4780)
  %4790 : __torch__.torch.nn.modules.linear.___torch_mangle_25440.Linear = prim::GetAttr[name="dense"](%4780)
  %4791 : Tensor = prim::GetAttr[name="bias"](%4790)
  %4792 : Tensor = prim::GetAttr[name="weight"](%4790)
  %4793 : Float(512:1, 128:512) = aten::t(%4792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.356 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.454, %4793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.118 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.356, %4791, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.190 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.118, %input.452, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4797 : Tensor = prim::GetAttr[name="bias"](%4789)
  %4798 : Tensor = prim::GetAttr[name="weight"](%4789)
  %4799 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.190, %4798), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.455 : Float(17:1664, 13:128, 128:1) = aten::add(%4799, %4797, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4801 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25448.FFNOutput = prim::GetAttr[name="output"](%4661)
  %4802 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25445.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4661)
  %4803 : __torch__.torch.nn.modules.linear.___torch_mangle_25444.Linear = prim::GetAttr[name="dense"](%4802)
  %4804 : Tensor = prim::GetAttr[name="bias"](%4803)
  %4805 : Tensor = prim::GetAttr[name="weight"](%4803)
  %4806 : Float(128:1, 512:128) = aten::t(%4805), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.357 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.455, %4806), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.456 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.357, %4804, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.457 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4810 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25447.NoNorm = prim::GetAttr[name="LayerNorm"](%4801)
  %4811 : __torch__.torch.nn.modules.linear.___torch_mangle_25446.Linear = prim::GetAttr[name="dense"](%4801)
  %4812 : Tensor = prim::GetAttr[name="bias"](%4811)
  %4813 : Tensor = prim::GetAttr[name="weight"](%4811)
  %4814 : Float(512:1, 128:512) = aten::t(%4813), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.358 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.457, %4814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.358, %4812, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.191 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.119, %input.455, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4818 : Tensor = prim::GetAttr[name="bias"](%4810)
  %4819 : Tensor = prim::GetAttr[name="weight"](%4810)
  %4820 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.191, %4819), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.458 : Float(17:1664, 13:128, 128:1) = aten::add(%4820, %4818, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4822 : __torch__.torch.nn.modules.linear.___torch_mangle_25416.Linear = prim::GetAttr[name="dense"](%4659)
  %4823 : Tensor = prim::GetAttr[name="bias"](%4822)
  %4824 : Tensor = prim::GetAttr[name="weight"](%4822)
  %4825 : Float(128:1, 512:128) = aten::t(%4824), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %output.359 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.458, %4825), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %input.459 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.359, %4823, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1678:0
  %input.460 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate # torch/nn/functional.py:1119:0
  %4829 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25423.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4658)
  %4830 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25419.NoNorm = prim::GetAttr[name="LayerNorm"](%4658)
  %4831 : __torch__.torch.nn.modules.linear.___torch_mangle_25418.Linear = prim::GetAttr[name="dense"](%4658)
  %4832 : Tensor = prim::GetAttr[name="bias"](%4831)
  %4833 : Tensor = prim::GetAttr[name="weight"](%4831)
  %4834 : Float(512:1, 128:512) = aten::t(%4833), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %output.360 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.460, %4834), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %layer_output : Float(17:1664, 13:128, 128:1) = aten::add_(%output.360, %4832, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.192 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output, %input.458, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output # transformers/modeling_mobilebert.py:405:0
  %4838 : Tensor = prim::GetAttr[name="bias"](%4830)
  %4839 : Tensor = prim::GetAttr[name="weight"](%4830)
  %4840 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.192, %4839), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.461 : Float(17:1664, 13:128, 128:1) = aten::add(%4840, %4838, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4842 : __torch__.transformers.modeling_mobilebert.___torch_mangle_25421.NoNorm = prim::GetAttr[name="LayerNorm"](%4829)
  %4843 : __torch__.torch.nn.modules.linear.___torch_mangle_25420.Linear = prim::GetAttr[name="dense"](%4829)
  %4844 : Tensor = prim::GetAttr[name="bias"](%4843)
  %4845 : Tensor = prim::GetAttr[name="weight"](%4843)
  %4846 : Float(128:1, 512:128) = aten::t(%4845), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.361 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.461, %4846), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.462 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.361, %4844, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.462, %16, %24), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs, %input.444, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4851 : Tensor = prim::GetAttr[name="bias"](%4842)
  %4852 : Tensor = prim::GetAttr[name="weight"](%4842)
  %4853 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor, %4852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.463 : Float(17:6656, 13:512, 512:1) = aten::add(%4853, %4851, %27), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4855 : bool = prim::Constant[value=0](), scope: __module.dropout # torch/nn/functional.py:973:0
  %4856 : float = prim::Constant[value=0.](), scope: __module.dropout # torch/nn/functional.py:973:0
  %input : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.463, %4856, %4855), scope: __module.dropout # torch/nn/functional.py:973:0
  %4858 : int = prim::Constant[value=1](), scope: __module.classifier # torch/nn/functional.py:1678:0
  %4859 : Tensor = prim::GetAttr[name="bias"](%3)
  %4860 : Tensor = prim::GetAttr[name="weight"](%3)
  %4861 : Float(512:1, 2:512) = aten::t(%4860), scope: __module.classifier # torch/nn/functional.py:1676:0
  %output : Float(17:26, 13:2, 2:1) = aten::matmul(%input, %4861), scope: __module.classifier # torch/nn/functional.py:1676:0
  %4863 : Float(17:26, 13:2, 2:1) = aten::add_(%output, %4859, %4858), scope: __module.classifier # torch/nn/functional.py:1678:0
  %9 : (Float(17:26, 13:2, 2:1)) = prim::TupleConstruct(%4863)
  return (%9)
