graph(%self.1 : __torch__.transformers.modeling_mobilebert.MobileBertForNextSentencePrediction,
      %input_ids : Long(17:13, 13:1),
      %attention_mask.1 : Long(17:13, 13:1)):
  %3 : __torch__.transformers.modeling_mobilebert.MobileBertOnlyNSPHead = prim::GetAttr[name="cls"](%self.1)
  %4 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16696.MobileBertModel = prim::GetAttr[name="mobilebert"](%self.1)
  %8 : int = prim::Constant[value=128](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %9 : float = prim::Constant[value=0.10000000000000001](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %10 : Double() = prim::Constant[value={5.65685}](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %11 : int = prim::Constant[value=-2](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %12 : int = prim::Constant[value=32](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %13 : int = prim::Constant[value=-1](), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %14 : float = prim::Constant[value=0.](), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %15 : Double() = prim::Constant[value={-10000}](), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %16 : float = prim::Constant[value=1.](), scope: __module.mobilebert # torch/tensor.py:396:0
  %17 : None = prim::Constant(), scope: __module.mobilebert
  %18 : int = prim::Constant[value=6](), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %19 : int = prim::Constant[value=3](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %20 : int = prim::Constant[value=2](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %21 : int = prim::Constant[value=9223372036854775807](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %22 : bool = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %23 : Device = prim::Constant[value="cpu"](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %24 : int = prim::Constant[value=4](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %25 : int = prim::Constant[value=1](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %26 : int = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %27 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16695.MobileBertPooler = prim::GetAttr[name="pooler"](%4)
  %28 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16693.MobileBertEncoder = prim::GetAttr[name="encoder"](%4)
  %29 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15611.MobileBertEmbeddings = prim::GetAttr[name="embeddings"](%4)
  %30 : int = aten::size(%input_ids, %26), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %31 : int = aten::size(%input_ids, %25), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %32 : int[] = prim::ListConstruct(%30, %31), scope: __module.mobilebert
  %input.5 : Long(17:13, 13:1) = aten::zeros(%32, %24, %26, %23, %22), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %34 : Long(17:13, 13:1) = aten::slice(%attention_mask.1, %26, %26, %21, %25), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %35 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%34, %25), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %36 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%35, %20), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %extended_attention_mask : Long(17:13, 1:13, 1:13, 13:1) = aten::slice(%36, %19, %26, %21, %25), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %38 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%extended_attention_mask, %18, %22, %22, %17), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %39 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%38, %16, %25), scope: __module.mobilebert # torch/tensor.py:396:0
  %attention_mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%39, %15), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %41 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15609.NoNorm = prim::GetAttr[name="LayerNorm"](%29)
  %42 : __torch__.torch.nn.modules.sparse.___torch_mangle_15607.Embedding = prim::GetAttr[name="token_type_embeddings"](%29)
  %43 : __torch__.torch.nn.modules.sparse.___torch_mangle_15606.Embedding = prim::GetAttr[name="position_embeddings"](%29)
  %44 : __torch__.torch.nn.modules.linear.___torch_mangle_15608.Linear = prim::GetAttr[name="embedding_transformation"](%29)
  %45 : __torch__.torch.nn.modules.sparse.___torch_mangle_15605.Embedding = prim::GetAttr[name="word_embeddings"](%29)
  %46 : Tensor = prim::GetAttr[name="position_ids"](%29)
  %47 : int = aten::size(%input_ids, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:185:0
  %48 : Long(1:512, 512:1) = aten::slice(%46, %26, %26, %21, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %input.4 : Long(1:512, 13:1) = aten::slice(%48, %25, %26, %47, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %50 : Tensor = prim::GetAttr[name="weight"](%45)
  %inputs_embeds.1 : Float(17:1664, 13:128, 128:1) = aten::embedding(%50, %input_ids, %26, %22, %22), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %52 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %26, %26, %21, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %input.1 : Float(17:1664, 12:128, 128:1) = aten::slice(%52, %25, %25, %21, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %54 : int[] = prim::ListConstruct(%26, %26, %26, %25, %26, %26), scope: __module.mobilebert/__module.mobilebert.embeddings
  %55 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.1, %54, %26), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %56 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %26, %26, %21, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %input.2 : Float(17:1664, 12:128, 128:1) = aten::slice(%56, %25, %26, %13, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %58 : int[] = prim::ListConstruct(%26, %26, %25, %26, %26, %26), scope: __module.mobilebert/__module.mobilebert.embeddings
  %59 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.2, %58, %26), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %60 : Tensor[] = prim::ListConstruct(%55, %inputs_embeds.1, %59), scope: __module.mobilebert/__module.mobilebert.embeddings
  %input.3 : Float(17:4992, 13:384, 384:1) = aten::cat(%60, %20), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:207:0
  %62 : Tensor = prim::GetAttr[name="bias"](%44)
  %63 : Tensor = prim::GetAttr[name="weight"](%44)
  %64 : Float(384:1, 512:384) = aten::t(%63), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %output.1 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.3, %64), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %inputs_embeds : Float(17:6656, 13:512, 512:1) = aten::add_(%output.1, %62, %25), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1678:0
  %67 : Tensor = prim::GetAttr[name="weight"](%43)
  %position_embeddings : Float(1:6656, 13:512, 512:1) = aten::embedding(%67, %input.4, %13, %22, %22), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %69 : Tensor = prim::GetAttr[name="weight"](%42)
  %token_type_embeddings : Float(17:6656, 13:512, 512:1) = aten::embedding(%69, %input.5, %13, %22, %22), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %71 : Float(17:6656, 13:512, 512:1) = aten::add(%inputs_embeds, %position_embeddings, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %input_tensor.1 : Float(17:6656, 13:512, 512:1) = aten::add(%71, %token_type_embeddings, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %73 : Tensor = prim::GetAttr[name="bias"](%41)
  %74 : Tensor = prim::GetAttr[name="weight"](%41)
  %75 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.1, %74), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.6 : Float(17:6656, 13:512, 512:1) = aten::add(%75, %73, %25), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.7 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.6, %14, %22), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %78 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %79 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16691.MobileBertLayer = prim::GetAttr[name="23"](%78)
  %80 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %81 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16646.MobileBertLayer = prim::GetAttr[name="22"](%80)
  %82 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %83 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16601.MobileBertLayer = prim::GetAttr[name="21"](%82)
  %84 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %85 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16556.MobileBertLayer = prim::GetAttr[name="20"](%84)
  %86 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %87 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16511.MobileBertLayer = prim::GetAttr[name="19"](%86)
  %88 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %89 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16466.MobileBertLayer = prim::GetAttr[name="18"](%88)
  %90 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %91 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16421.MobileBertLayer = prim::GetAttr[name="17"](%90)
  %92 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %93 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16376.MobileBertLayer = prim::GetAttr[name="16"](%92)
  %94 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %95 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16331.MobileBertLayer = prim::GetAttr[name="15"](%94)
  %96 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %97 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16286.MobileBertLayer = prim::GetAttr[name="14"](%96)
  %98 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %99 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16241.MobileBertLayer = prim::GetAttr[name="13"](%98)
  %100 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %101 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16196.MobileBertLayer = prim::GetAttr[name="12"](%100)
  %102 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16151.MobileBertLayer = prim::GetAttr[name="11"](%102)
  %104 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16106.MobileBertLayer = prim::GetAttr[name="10"](%104)
  %106 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16061.MobileBertLayer = prim::GetAttr[name="9"](%106)
  %108 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %109 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16016.MobileBertLayer = prim::GetAttr[name="8"](%108)
  %110 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15971.MobileBertLayer = prim::GetAttr[name="7"](%110)
  %112 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %113 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15926.MobileBertLayer = prim::GetAttr[name="6"](%112)
  %114 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %115 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15881.MobileBertLayer = prim::GetAttr[name="5"](%114)
  %116 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %117 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15836.MobileBertLayer = prim::GetAttr[name="4"](%116)
  %118 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15791.MobileBertLayer = prim::GetAttr[name="3"](%118)
  %120 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %121 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15746.MobileBertLayer = prim::GetAttr[name="2"](%120)
  %122 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %123 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15701.MobileBertLayer = prim::GetAttr[name="1"](%122)
  %124 : __torch__.torch.nn.modules.container.___torch_mangle_16692.ModuleList = prim::GetAttr[name="layer"](%28)
  %125 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15656.MobileBertLayer = prim::GetAttr[name="0"](%124)
  %126 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15629.MobileBertOutput = prim::GetAttr[name="output"](%125)
  %127 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15622.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%125)
  %128 : __torch__.torch.nn.modules.container.___torch_mangle_15655.ModuleList = prim::GetAttr[name="ffn"](%125)
  %129 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15654.FFNLayer = prim::GetAttr[name="2"](%128)
  %130 : __torch__.torch.nn.modules.container.___torch_mangle_15655.ModuleList = prim::GetAttr[name="ffn"](%125)
  %131 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15648.FFNLayer = prim::GetAttr[name="1"](%130)
  %132 : __torch__.torch.nn.modules.container.___torch_mangle_15655.ModuleList = prim::GetAttr[name="ffn"](%125)
  %133 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15642.FFNLayer = prim::GetAttr[name="0"](%132)
  %134 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15620.MobileBertAttention = prim::GetAttr[name="attention"](%125)
  %135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15636.Bottleneck = prim::GetAttr[name="bottleneck"](%125)
  %136 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15635.BottleneckLayer = prim::GetAttr[name="attention"](%135)
  %137 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15632.BottleneckLayer = prim::GetAttr[name="input"](%135)
  %138 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15631.NoNorm = prim::GetAttr[name="LayerNorm"](%137)
  %139 : __torch__.torch.nn.modules.linear.___torch_mangle_15630.Linear = prim::GetAttr[name="dense"](%137)
  %140 : Tensor = prim::GetAttr[name="bias"](%139)
  %141 : Tensor = prim::GetAttr[name="weight"](%139)
  %142 : Float(512:1, 128:512) = aten::t(%141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.2 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %142), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.2, %140, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %145 : Tensor = prim::GetAttr[name="bias"](%138)
  %146 : Tensor = prim::GetAttr[name="weight"](%138)
  %147 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.2, %146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.1 : Float(17:1664, 13:128, 128:1) = aten::add(%147, %145, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %149 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15634.NoNorm = prim::GetAttr[name="LayerNorm"](%136)
  %150 : __torch__.torch.nn.modules.linear.___torch_mangle_15633.Linear = prim::GetAttr[name="dense"](%136)
  %151 : Tensor = prim::GetAttr[name="bias"](%150)
  %152 : Tensor = prim::GetAttr[name="weight"](%150)
  %153 : Float(512:1, 128:512) = aten::t(%152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.3 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %153), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.3, %151, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %156 : Tensor = prim::GetAttr[name="bias"](%149)
  %157 : Tensor = prim::GetAttr[name="weight"](%149)
  %158 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.3, %157), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.8 : Float(17:1664, 13:128, 128:1) = aten::add(%158, %156, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %160 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.8, %residual_tensor.1)
  %161 : Float(17:1664, 13:128, 128:1), %162 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%160)
  %163 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15619.MobileBertSelfOutput = prim::GetAttr[name="output"](%134)
  %164 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15616.MobileBertSelfAttention = prim::GetAttr[name="self"](%134)
  %165 : __torch__.torch.nn.modules.linear.___torch_mangle_15614.Linear = prim::GetAttr[name="value"](%164)
  %166 : __torch__.torch.nn.modules.linear.___torch_mangle_15613.Linear = prim::GetAttr[name="key"](%164)
  %167 : __torch__.torch.nn.modules.linear.___torch_mangle_15612.Linear = prim::GetAttr[name="query"](%164)
  %168 : Tensor = prim::GetAttr[name="bias"](%167)
  %169 : Tensor = prim::GetAttr[name="weight"](%167)
  %170 : Float(128:1, 128:128) = aten::t(%169), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %output.4 : Float(17:1664, 13:128, 128:1) = aten::matmul(%161, %170), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %x.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.4, %168, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %173 : Tensor = prim::GetAttr[name="bias"](%166)
  %174 : Tensor = prim::GetAttr[name="weight"](%166)
  %175 : Float(128:1, 128:128) = aten::t(%174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %output.5 : Float(17:1664, 13:128, 128:1) = aten::matmul(%161, %175), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %x.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.5, %173, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1678:0
  %178 : Tensor = prim::GetAttr[name="bias"](%165)
  %179 : Tensor = prim::GetAttr[name="weight"](%165)
  %180 : Float(512:1, 128:512) = aten::t(%179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %output.6 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %x.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.6, %178, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1678:0
  %183 : int = aten::size(%x.1, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %184 : int = aten::size(%x.1, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %185 : int[] = prim::ListConstruct(%183, %184, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.1, %185), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %187 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %query_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.2, %187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %189 : int = aten::size(%x.3, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %190 : int = aten::size(%x.3, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %191 : int[] = prim::ListConstruct(%189, %190, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.3, %191), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %193 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %key_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.4, %193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %195 : int = aten::size(%x.5, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %196 : int = aten::size(%x.5, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %197 : int[] = prim::ListConstruct(%195, %196, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.5, %197), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %199 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %value_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.6, %199), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %201 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.1, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.1, %201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.1, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.2, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.9, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.10, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.1 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:280:0
  %208 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %209 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.1, %208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%209, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %211 : int = aten::size(%context_layer.2, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %212 : int = aten::size(%context_layer.2, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %213 : int[] = prim::ListConstruct(%211, %212, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %input.11 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.2, %213), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %215 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15618.NoNorm = prim::GetAttr[name="LayerNorm"](%163)
  %216 : __torch__.torch.nn.modules.linear.___torch_mangle_15617.Linear = prim::GetAttr[name="dense"](%163)
  %217 : Tensor = prim::GetAttr[name="bias"](%216)
  %218 : Tensor = prim::GetAttr[name="weight"](%216)
  %219 : Float(128:1, 128:128) = aten::t(%218), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %output.7 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.11, %219), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.7, %217, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.1, %162, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output # transformers/modeling_mobilebert.py:301:0
  %223 : Tensor = prim::GetAttr[name="bias"](%215)
  %224 : Tensor = prim::GetAttr[name="weight"](%215)
  %225 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.4, %224), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.12 : Float(17:1664, 13:128, 128:1) = aten::add(%225, %223, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %227 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15641.FFNOutput = prim::GetAttr[name="output"](%133)
  %228 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15638.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%133)
  %229 : __torch__.torch.nn.modules.linear.___torch_mangle_15637.Linear = prim::GetAttr[name="dense"](%228)
  %230 : Tensor = prim::GetAttr[name="bias"](%229)
  %231 : Tensor = prim::GetAttr[name="weight"](%229)
  %232 : Float(128:1, 512:128) = aten::t(%231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.8 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.12, %232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.13 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.8, %230, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.14 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %236 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15640.NoNorm = prim::GetAttr[name="LayerNorm"](%227)
  %237 : __torch__.torch.nn.modules.linear.___torch_mangle_15639.Linear = prim::GetAttr[name="dense"](%227)
  %238 : Tensor = prim::GetAttr[name="bias"](%237)
  %239 : Tensor = prim::GetAttr[name="weight"](%237)
  %240 : Float(512:1, 128:512) = aten::t(%239), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.9 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.14, %240), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.9, %238, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.2, %input.12, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %244 : Tensor = prim::GetAttr[name="bias"](%236)
  %245 : Tensor = prim::GetAttr[name="weight"](%236)
  %246 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.5, %245), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.15 : Float(17:1664, 13:128, 128:1) = aten::add(%246, %244, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %248 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15647.FFNOutput = prim::GetAttr[name="output"](%131)
  %249 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15644.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%131)
  %250 : __torch__.torch.nn.modules.linear.___torch_mangle_15643.Linear = prim::GetAttr[name="dense"](%249)
  %251 : Tensor = prim::GetAttr[name="bias"](%250)
  %252 : Tensor = prim::GetAttr[name="weight"](%250)
  %253 : Float(128:1, 512:128) = aten::t(%252), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.10 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.15, %253), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.16 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.10, %251, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.17 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %257 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15646.NoNorm = prim::GetAttr[name="LayerNorm"](%248)
  %258 : __torch__.torch.nn.modules.linear.___torch_mangle_15645.Linear = prim::GetAttr[name="dense"](%248)
  %259 : Tensor = prim::GetAttr[name="bias"](%258)
  %260 : Tensor = prim::GetAttr[name="weight"](%258)
  %261 : Float(512:1, 128:512) = aten::t(%260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.11 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.17, %261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.11, %259, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.3, %input.15, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %265 : Tensor = prim::GetAttr[name="bias"](%257)
  %266 : Tensor = prim::GetAttr[name="weight"](%257)
  %267 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.6, %266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.18 : Float(17:1664, 13:128, 128:1) = aten::add(%267, %265, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %269 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15653.FFNOutput = prim::GetAttr[name="output"](%129)
  %270 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15650.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%129)
  %271 : __torch__.torch.nn.modules.linear.___torch_mangle_15649.Linear = prim::GetAttr[name="dense"](%270)
  %272 : Tensor = prim::GetAttr[name="bias"](%271)
  %273 : Tensor = prim::GetAttr[name="weight"](%271)
  %274 : Float(128:1, 512:128) = aten::t(%273), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.12 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.18, %274), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.19 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.12, %272, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.20 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %278 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15652.NoNorm = prim::GetAttr[name="LayerNorm"](%269)
  %279 : __torch__.torch.nn.modules.linear.___torch_mangle_15651.Linear = prim::GetAttr[name="dense"](%269)
  %280 : Tensor = prim::GetAttr[name="bias"](%279)
  %281 : Tensor = prim::GetAttr[name="weight"](%279)
  %282 : Float(512:1, 128:512) = aten::t(%281), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.13 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.20, %282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.13, %280, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.4, %input.18, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %286 : Tensor = prim::GetAttr[name="bias"](%278)
  %287 : Tensor = prim::GetAttr[name="weight"](%278)
  %288 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.7, %287), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.21 : Float(17:1664, 13:128, 128:1) = aten::add(%288, %286, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %290 : __torch__.torch.nn.modules.linear.___torch_mangle_15621.Linear = prim::GetAttr[name="dense"](%127)
  %291 : Tensor = prim::GetAttr[name="bias"](%290)
  %292 : Tensor = prim::GetAttr[name="weight"](%290)
  %293 : Float(128:1, 512:128) = aten::t(%292), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.14 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.21, %293), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.22 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.14, %291, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.23 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate # torch/nn/functional.py:1119:0
  %297 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15628.OutputBottleneck = prim::GetAttr[name="bottleneck"](%126)
  %298 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15624.NoNorm = prim::GetAttr[name="LayerNorm"](%126)
  %299 : __torch__.torch.nn.modules.linear.___torch_mangle_15623.Linear = prim::GetAttr[name="dense"](%126)
  %300 : Tensor = prim::GetAttr[name="bias"](%299)
  %301 : Tensor = prim::GetAttr[name="weight"](%299)
  %302 : Float(512:1, 128:512) = aten::t(%301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %output.15 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.23, %302), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %layer_output.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.15, %300, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.1, %input.21, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output # transformers/modeling_mobilebert.py:405:0
  %306 : Tensor = prim::GetAttr[name="bias"](%298)
  %307 : Tensor = prim::GetAttr[name="weight"](%298)
  %308 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.8, %307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.24 : Float(17:1664, 13:128, 128:1) = aten::add(%308, %306, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %310 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15626.NoNorm = prim::GetAttr[name="LayerNorm"](%297)
  %311 : __torch__.torch.nn.modules.linear.___torch_mangle_15625.Linear = prim::GetAttr[name="dense"](%297)
  %312 : Tensor = prim::GetAttr[name="bias"](%311)
  %313 : Tensor = prim::GetAttr[name="weight"](%311)
  %314 : Float(128:1, 512:128) = aten::t(%313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.16 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.24, %314), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.25 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.16, %312, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.5 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.25, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.9 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.5, %input.7, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %319 : Tensor = prim::GetAttr[name="bias"](%310)
  %320 : Tensor = prim::GetAttr[name="weight"](%310)
  %321 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.9, %320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.26 : Float(17:6656, 13:512, 512:1) = aten::add(%321, %319, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %323 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15674.MobileBertOutput = prim::GetAttr[name="output"](%123)
  %324 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15667.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%123)
  %325 : __torch__.torch.nn.modules.container.___torch_mangle_15700.ModuleList = prim::GetAttr[name="ffn"](%123)
  %326 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15699.FFNLayer = prim::GetAttr[name="2"](%325)
  %327 : __torch__.torch.nn.modules.container.___torch_mangle_15700.ModuleList = prim::GetAttr[name="ffn"](%123)
  %328 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15693.FFNLayer = prim::GetAttr[name="1"](%327)
  %329 : __torch__.torch.nn.modules.container.___torch_mangle_15700.ModuleList = prim::GetAttr[name="ffn"](%123)
  %330 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15687.FFNLayer = prim::GetAttr[name="0"](%329)
  %331 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15665.MobileBertAttention = prim::GetAttr[name="attention"](%123)
  %332 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15681.Bottleneck = prim::GetAttr[name="bottleneck"](%123)
  %333 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15680.BottleneckLayer = prim::GetAttr[name="attention"](%332)
  %334 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15677.BottleneckLayer = prim::GetAttr[name="input"](%332)
  %335 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15676.NoNorm = prim::GetAttr[name="LayerNorm"](%334)
  %336 : __torch__.torch.nn.modules.linear.___torch_mangle_15675.Linear = prim::GetAttr[name="dense"](%334)
  %337 : Tensor = prim::GetAttr[name="bias"](%336)
  %338 : Tensor = prim::GetAttr[name="weight"](%336)
  %339 : Float(512:1, 128:512) = aten::t(%338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.17 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.17, %337, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %342 : Tensor = prim::GetAttr[name="bias"](%335)
  %343 : Tensor = prim::GetAttr[name="weight"](%335)
  %344 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.10, %343), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add(%344, %342, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %346 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15679.NoNorm = prim::GetAttr[name="LayerNorm"](%333)
  %347 : __torch__.torch.nn.modules.linear.___torch_mangle_15678.Linear = prim::GetAttr[name="dense"](%333)
  %348 : Tensor = prim::GetAttr[name="bias"](%347)
  %349 : Tensor = prim::GetAttr[name="weight"](%347)
  %350 : Float(512:1, 128:512) = aten::t(%349), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.18 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %350), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.18, %348, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %353 : Tensor = prim::GetAttr[name="bias"](%346)
  %354 : Tensor = prim::GetAttr[name="weight"](%346)
  %355 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.11, %354), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.27 : Float(17:1664, 13:128, 128:1) = aten::add(%355, %353, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %357 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.27, %residual_tensor.2)
  %358 : Float(17:1664, 13:128, 128:1), %359 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%357)
  %360 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15664.MobileBertSelfOutput = prim::GetAttr[name="output"](%331)
  %361 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15661.MobileBertSelfAttention = prim::GetAttr[name="self"](%331)
  %362 : __torch__.torch.nn.modules.linear.___torch_mangle_15659.Linear = prim::GetAttr[name="value"](%361)
  %363 : __torch__.torch.nn.modules.linear.___torch_mangle_15658.Linear = prim::GetAttr[name="key"](%361)
  %364 : __torch__.torch.nn.modules.linear.___torch_mangle_15657.Linear = prim::GetAttr[name="query"](%361)
  %365 : Tensor = prim::GetAttr[name="bias"](%364)
  %366 : Tensor = prim::GetAttr[name="weight"](%364)
  %367 : Float(128:1, 128:128) = aten::t(%366), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %output.19 : Float(17:1664, 13:128, 128:1) = aten::matmul(%358, %367), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %x.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.19, %365, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1678:0
  %370 : Tensor = prim::GetAttr[name="bias"](%363)
  %371 : Tensor = prim::GetAttr[name="weight"](%363)
  %372 : Float(128:1, 128:128) = aten::t(%371), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %output.20 : Float(17:1664, 13:128, 128:1) = aten::matmul(%358, %372), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %x.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.20, %370, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1678:0
  %375 : Tensor = prim::GetAttr[name="bias"](%362)
  %376 : Tensor = prim::GetAttr[name="weight"](%362)
  %377 : Float(512:1, 128:512) = aten::t(%376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %output.21 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %x.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.21, %375, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1678:0
  %380 : int = aten::size(%x.7, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %381 : int = aten::size(%x.7, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %382 : int[] = prim::ListConstruct(%380, %381, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.7, %382), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %384 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %query_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.8, %384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %386 : int = aten::size(%x.9, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %387 : int = aten::size(%x.9, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %388 : int[] = prim::ListConstruct(%386, %387, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.9, %388), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %390 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %key_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.10, %390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %392 : int = aten::size(%x.11, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %393 : int = aten::size(%x.11, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %394 : int[] = prim::ListConstruct(%392, %393, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.11, %394), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %396 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %value_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.12, %396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %398 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.2, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.2, %398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.3, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.4, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.28, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.29, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.3 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.2, %value_layer.2), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:280:0
  %405 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %406 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.3, %405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%406, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %408 : int = aten::size(%context_layer.4, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %409 : int = aten::size(%context_layer.4, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %410 : int[] = prim::ListConstruct(%408, %409, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %input.30 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.4, %410), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:283:0
  %412 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15663.NoNorm = prim::GetAttr[name="LayerNorm"](%360)
  %413 : __torch__.torch.nn.modules.linear.___torch_mangle_15662.Linear = prim::GetAttr[name="dense"](%360)
  %414 : Tensor = prim::GetAttr[name="bias"](%413)
  %415 : Tensor = prim::GetAttr[name="weight"](%413)
  %416 : Float(128:1, 128:128) = aten::t(%415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %output.22 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.30, %416), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.22, %414, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.6, %359, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output # transformers/modeling_mobilebert.py:301:0
  %420 : Tensor = prim::GetAttr[name="bias"](%412)
  %421 : Tensor = prim::GetAttr[name="weight"](%412)
  %422 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.12, %421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.31 : Float(17:1664, 13:128, 128:1) = aten::add(%422, %420, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %424 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15686.FFNOutput = prim::GetAttr[name="output"](%330)
  %425 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15683.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%330)
  %426 : __torch__.torch.nn.modules.linear.___torch_mangle_15682.Linear = prim::GetAttr[name="dense"](%425)
  %427 : Tensor = prim::GetAttr[name="bias"](%426)
  %428 : Tensor = prim::GetAttr[name="weight"](%426)
  %429 : Float(128:1, 512:128) = aten::t(%428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.23 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.31, %429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.32 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.23, %427, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.33 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.32), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %433 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15685.NoNorm = prim::GetAttr[name="LayerNorm"](%424)
  %434 : __torch__.torch.nn.modules.linear.___torch_mangle_15684.Linear = prim::GetAttr[name="dense"](%424)
  %435 : Tensor = prim::GetAttr[name="bias"](%434)
  %436 : Tensor = prim::GetAttr[name="weight"](%434)
  %437 : Float(512:1, 128:512) = aten::t(%436), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.24 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.33, %437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.24, %435, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.7, %input.31, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %441 : Tensor = prim::GetAttr[name="bias"](%433)
  %442 : Tensor = prim::GetAttr[name="weight"](%433)
  %443 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.13, %442), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.34 : Float(17:1664, 13:128, 128:1) = aten::add(%443, %441, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %445 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15692.FFNOutput = prim::GetAttr[name="output"](%328)
  %446 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15689.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%328)
  %447 : __torch__.torch.nn.modules.linear.___torch_mangle_15688.Linear = prim::GetAttr[name="dense"](%446)
  %448 : Tensor = prim::GetAttr[name="bias"](%447)
  %449 : Tensor = prim::GetAttr[name="weight"](%447)
  %450 : Float(128:1, 512:128) = aten::t(%449), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.25 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.34, %450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.35 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.25, %448, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.36 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %454 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15691.NoNorm = prim::GetAttr[name="LayerNorm"](%445)
  %455 : __torch__.torch.nn.modules.linear.___torch_mangle_15690.Linear = prim::GetAttr[name="dense"](%445)
  %456 : Tensor = prim::GetAttr[name="bias"](%455)
  %457 : Tensor = prim::GetAttr[name="weight"](%455)
  %458 : Float(512:1, 128:512) = aten::t(%457), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.26 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.36, %458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.26, %456, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.8, %input.34, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %462 : Tensor = prim::GetAttr[name="bias"](%454)
  %463 : Tensor = prim::GetAttr[name="weight"](%454)
  %464 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.14, %463), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.37 : Float(17:1664, 13:128, 128:1) = aten::add(%464, %462, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %466 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15698.FFNOutput = prim::GetAttr[name="output"](%326)
  %467 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15695.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%326)
  %468 : __torch__.torch.nn.modules.linear.___torch_mangle_15694.Linear = prim::GetAttr[name="dense"](%467)
  %469 : Tensor = prim::GetAttr[name="bias"](%468)
  %470 : Tensor = prim::GetAttr[name="weight"](%468)
  %471 : Float(128:1, 512:128) = aten::t(%470), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.27 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.37, %471), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.38 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.27, %469, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.39 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.38), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %475 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15697.NoNorm = prim::GetAttr[name="LayerNorm"](%466)
  %476 : __torch__.torch.nn.modules.linear.___torch_mangle_15696.Linear = prim::GetAttr[name="dense"](%466)
  %477 : Tensor = prim::GetAttr[name="bias"](%476)
  %478 : Tensor = prim::GetAttr[name="weight"](%476)
  %479 : Float(512:1, 128:512) = aten::t(%478), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.28 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.39, %479), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.28, %477, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.9, %input.37, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %483 : Tensor = prim::GetAttr[name="bias"](%475)
  %484 : Tensor = prim::GetAttr[name="weight"](%475)
  %485 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.15, %484), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.40 : Float(17:1664, 13:128, 128:1) = aten::add(%485, %483, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %487 : __torch__.torch.nn.modules.linear.___torch_mangle_15666.Linear = prim::GetAttr[name="dense"](%324)
  %488 : Tensor = prim::GetAttr[name="bias"](%487)
  %489 : Tensor = prim::GetAttr[name="weight"](%487)
  %490 : Float(128:1, 512:128) = aten::t(%489), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.29 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.40, %490), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.41 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.29, %488, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.42 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.41), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate # torch/nn/functional.py:1119:0
  %494 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15673.OutputBottleneck = prim::GetAttr[name="bottleneck"](%323)
  %495 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15669.NoNorm = prim::GetAttr[name="LayerNorm"](%323)
  %496 : __torch__.torch.nn.modules.linear.___torch_mangle_15668.Linear = prim::GetAttr[name="dense"](%323)
  %497 : Tensor = prim::GetAttr[name="bias"](%496)
  %498 : Tensor = prim::GetAttr[name="weight"](%496)
  %499 : Float(512:1, 128:512) = aten::t(%498), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %output.30 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.42, %499), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %layer_output.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.30, %497, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.2, %input.40, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output # transformers/modeling_mobilebert.py:405:0
  %503 : Tensor = prim::GetAttr[name="bias"](%495)
  %504 : Tensor = prim::GetAttr[name="weight"](%495)
  %505 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.16, %504), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.43 : Float(17:1664, 13:128, 128:1) = aten::add(%505, %503, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %507 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15671.NoNorm = prim::GetAttr[name="LayerNorm"](%494)
  %508 : __torch__.torch.nn.modules.linear.___torch_mangle_15670.Linear = prim::GetAttr[name="dense"](%494)
  %509 : Tensor = prim::GetAttr[name="bias"](%508)
  %510 : Tensor = prim::GetAttr[name="weight"](%508)
  %511 : Float(128:1, 512:128) = aten::t(%510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.31 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.43, %511), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.44 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.31, %509, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.10 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.44, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.17 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.10, %input.26, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %516 : Tensor = prim::GetAttr[name="bias"](%507)
  %517 : Tensor = prim::GetAttr[name="weight"](%507)
  %518 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.17, %517), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.45 : Float(17:6656, 13:512, 512:1) = aten::add(%518, %516, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %520 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15719.MobileBertOutput = prim::GetAttr[name="output"](%121)
  %521 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15712.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%121)
  %522 : __torch__.torch.nn.modules.container.___torch_mangle_15745.ModuleList = prim::GetAttr[name="ffn"](%121)
  %523 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15744.FFNLayer = prim::GetAttr[name="2"](%522)
  %524 : __torch__.torch.nn.modules.container.___torch_mangle_15745.ModuleList = prim::GetAttr[name="ffn"](%121)
  %525 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15738.FFNLayer = prim::GetAttr[name="1"](%524)
  %526 : __torch__.torch.nn.modules.container.___torch_mangle_15745.ModuleList = prim::GetAttr[name="ffn"](%121)
  %527 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15732.FFNLayer = prim::GetAttr[name="0"](%526)
  %528 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15710.MobileBertAttention = prim::GetAttr[name="attention"](%121)
  %529 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15726.Bottleneck = prim::GetAttr[name="bottleneck"](%121)
  %530 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15725.BottleneckLayer = prim::GetAttr[name="attention"](%529)
  %531 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15722.BottleneckLayer = prim::GetAttr[name="input"](%529)
  %532 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15721.NoNorm = prim::GetAttr[name="LayerNorm"](%531)
  %533 : __torch__.torch.nn.modules.linear.___torch_mangle_15720.Linear = prim::GetAttr[name="dense"](%531)
  %534 : Tensor = prim::GetAttr[name="bias"](%533)
  %535 : Tensor = prim::GetAttr[name="weight"](%533)
  %536 : Float(512:1, 128:512) = aten::t(%535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.32 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %536), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.32, %534, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %539 : Tensor = prim::GetAttr[name="bias"](%532)
  %540 : Tensor = prim::GetAttr[name="weight"](%532)
  %541 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.18, %540), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add(%541, %539, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %543 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15724.NoNorm = prim::GetAttr[name="LayerNorm"](%530)
  %544 : __torch__.torch.nn.modules.linear.___torch_mangle_15723.Linear = prim::GetAttr[name="dense"](%530)
  %545 : Tensor = prim::GetAttr[name="bias"](%544)
  %546 : Tensor = prim::GetAttr[name="weight"](%544)
  %547 : Float(512:1, 128:512) = aten::t(%546), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.33 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %547), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.33, %545, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %550 : Tensor = prim::GetAttr[name="bias"](%543)
  %551 : Tensor = prim::GetAttr[name="weight"](%543)
  %552 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.19, %551), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.46 : Float(17:1664, 13:128, 128:1) = aten::add(%552, %550, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %554 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.46, %residual_tensor.3)
  %555 : Float(17:1664, 13:128, 128:1), %556 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%554)
  %557 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15709.MobileBertSelfOutput = prim::GetAttr[name="output"](%528)
  %558 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15706.MobileBertSelfAttention = prim::GetAttr[name="self"](%528)
  %559 : __torch__.torch.nn.modules.linear.___torch_mangle_15704.Linear = prim::GetAttr[name="value"](%558)
  %560 : __torch__.torch.nn.modules.linear.___torch_mangle_15703.Linear = prim::GetAttr[name="key"](%558)
  %561 : __torch__.torch.nn.modules.linear.___torch_mangle_15702.Linear = prim::GetAttr[name="query"](%558)
  %562 : Tensor = prim::GetAttr[name="bias"](%561)
  %563 : Tensor = prim::GetAttr[name="weight"](%561)
  %564 : Float(128:1, 128:128) = aten::t(%563), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %output.34 : Float(17:1664, 13:128, 128:1) = aten::matmul(%555, %564), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %x.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.34, %562, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1678:0
  %567 : Tensor = prim::GetAttr[name="bias"](%560)
  %568 : Tensor = prim::GetAttr[name="weight"](%560)
  %569 : Float(128:1, 128:128) = aten::t(%568), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %output.35 : Float(17:1664, 13:128, 128:1) = aten::matmul(%555, %569), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %x.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.35, %567, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1678:0
  %572 : Tensor = prim::GetAttr[name="bias"](%559)
  %573 : Tensor = prim::GetAttr[name="weight"](%559)
  %574 : Float(512:1, 128:512) = aten::t(%573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %output.36 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %x.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.36, %572, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1678:0
  %577 : int = aten::size(%x.13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %578 : int = aten::size(%x.13, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %579 : int[] = prim::ListConstruct(%577, %578, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.13, %579), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %581 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %query_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.14, %581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %583 : int = aten::size(%x.15, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %584 : int = aten::size(%x.15, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %585 : int[] = prim::ListConstruct(%583, %584, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.15, %585), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %587 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %key_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.16, %587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %589 : int = aten::size(%x.17, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %590 : int = aten::size(%x.17, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %591 : int[] = prim::ListConstruct(%589, %590, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.17, %591), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %593 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %value_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.18, %593), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %595 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.3, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.3, %595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.5, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.6, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.48 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.47, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.48, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.5 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.3, %value_layer.3), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:280:0
  %602 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %603 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.5, %602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%603, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %605 : int = aten::size(%context_layer.6, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %606 : int = aten::size(%context_layer.6, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %607 : int[] = prim::ListConstruct(%605, %606, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %input.49 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.6, %607), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:283:0
  %609 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15708.NoNorm = prim::GetAttr[name="LayerNorm"](%557)
  %610 : __torch__.torch.nn.modules.linear.___torch_mangle_15707.Linear = prim::GetAttr[name="dense"](%557)
  %611 : Tensor = prim::GetAttr[name="bias"](%610)
  %612 : Tensor = prim::GetAttr[name="weight"](%610)
  %613 : Float(128:1, 128:128) = aten::t(%612), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %output.37 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.49, %613), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.37, %611, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.11, %556, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output # transformers/modeling_mobilebert.py:301:0
  %617 : Tensor = prim::GetAttr[name="bias"](%609)
  %618 : Tensor = prim::GetAttr[name="weight"](%609)
  %619 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.20, %618), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.50 : Float(17:1664, 13:128, 128:1) = aten::add(%619, %617, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %621 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15731.FFNOutput = prim::GetAttr[name="output"](%527)
  %622 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15728.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%527)
  %623 : __torch__.torch.nn.modules.linear.___torch_mangle_15727.Linear = prim::GetAttr[name="dense"](%622)
  %624 : Tensor = prim::GetAttr[name="bias"](%623)
  %625 : Tensor = prim::GetAttr[name="weight"](%623)
  %626 : Float(128:1, 512:128) = aten::t(%625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.38 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.50, %626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.51 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.38, %624, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.52 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.51), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %630 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15730.NoNorm = prim::GetAttr[name="LayerNorm"](%621)
  %631 : __torch__.torch.nn.modules.linear.___torch_mangle_15729.Linear = prim::GetAttr[name="dense"](%621)
  %632 : Tensor = prim::GetAttr[name="bias"](%631)
  %633 : Tensor = prim::GetAttr[name="weight"](%631)
  %634 : Float(512:1, 128:512) = aten::t(%633), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.39 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.52, %634), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.39, %632, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.12, %input.50, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %638 : Tensor = prim::GetAttr[name="bias"](%630)
  %639 : Tensor = prim::GetAttr[name="weight"](%630)
  %640 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.21, %639), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.53 : Float(17:1664, 13:128, 128:1) = aten::add(%640, %638, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %642 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15737.FFNOutput = prim::GetAttr[name="output"](%525)
  %643 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15734.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%525)
  %644 : __torch__.torch.nn.modules.linear.___torch_mangle_15733.Linear = prim::GetAttr[name="dense"](%643)
  %645 : Tensor = prim::GetAttr[name="bias"](%644)
  %646 : Tensor = prim::GetAttr[name="weight"](%644)
  %647 : Float(128:1, 512:128) = aten::t(%646), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.40 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.53, %647), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.54 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.40, %645, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.55 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.54), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %651 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15736.NoNorm = prim::GetAttr[name="LayerNorm"](%642)
  %652 : __torch__.torch.nn.modules.linear.___torch_mangle_15735.Linear = prim::GetAttr[name="dense"](%642)
  %653 : Tensor = prim::GetAttr[name="bias"](%652)
  %654 : Tensor = prim::GetAttr[name="weight"](%652)
  %655 : Float(512:1, 128:512) = aten::t(%654), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.41 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.55, %655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.41, %653, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.13, %input.53, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %659 : Tensor = prim::GetAttr[name="bias"](%651)
  %660 : Tensor = prim::GetAttr[name="weight"](%651)
  %661 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.22, %660), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.56 : Float(17:1664, 13:128, 128:1) = aten::add(%661, %659, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %663 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15743.FFNOutput = prim::GetAttr[name="output"](%523)
  %664 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15740.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%523)
  %665 : __torch__.torch.nn.modules.linear.___torch_mangle_15739.Linear = prim::GetAttr[name="dense"](%664)
  %666 : Tensor = prim::GetAttr[name="bias"](%665)
  %667 : Tensor = prim::GetAttr[name="weight"](%665)
  %668 : Float(128:1, 512:128) = aten::t(%667), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.42 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.56, %668), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.57 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.42, %666, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.58 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.57), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %672 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15742.NoNorm = prim::GetAttr[name="LayerNorm"](%663)
  %673 : __torch__.torch.nn.modules.linear.___torch_mangle_15741.Linear = prim::GetAttr[name="dense"](%663)
  %674 : Tensor = prim::GetAttr[name="bias"](%673)
  %675 : Tensor = prim::GetAttr[name="weight"](%673)
  %676 : Float(512:1, 128:512) = aten::t(%675), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.43 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.58, %676), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.43, %674, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.14, %input.56, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %680 : Tensor = prim::GetAttr[name="bias"](%672)
  %681 : Tensor = prim::GetAttr[name="weight"](%672)
  %682 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.23, %681), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.59 : Float(17:1664, 13:128, 128:1) = aten::add(%682, %680, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %684 : __torch__.torch.nn.modules.linear.___torch_mangle_15711.Linear = prim::GetAttr[name="dense"](%521)
  %685 : Tensor = prim::GetAttr[name="bias"](%684)
  %686 : Tensor = prim::GetAttr[name="weight"](%684)
  %687 : Float(128:1, 512:128) = aten::t(%686), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.44 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.59, %687), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.60 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.44, %685, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.61 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.60), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate # torch/nn/functional.py:1119:0
  %691 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15718.OutputBottleneck = prim::GetAttr[name="bottleneck"](%520)
  %692 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15714.NoNorm = prim::GetAttr[name="LayerNorm"](%520)
  %693 : __torch__.torch.nn.modules.linear.___torch_mangle_15713.Linear = prim::GetAttr[name="dense"](%520)
  %694 : Tensor = prim::GetAttr[name="bias"](%693)
  %695 : Tensor = prim::GetAttr[name="weight"](%693)
  %696 : Float(512:1, 128:512) = aten::t(%695), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %output.45 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.61, %696), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %layer_output.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.45, %694, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.24 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.3, %input.59, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output # transformers/modeling_mobilebert.py:405:0
  %700 : Tensor = prim::GetAttr[name="bias"](%692)
  %701 : Tensor = prim::GetAttr[name="weight"](%692)
  %702 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.24, %701), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.62 : Float(17:1664, 13:128, 128:1) = aten::add(%702, %700, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %704 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15716.NoNorm = prim::GetAttr[name="LayerNorm"](%691)
  %705 : __torch__.torch.nn.modules.linear.___torch_mangle_15715.Linear = prim::GetAttr[name="dense"](%691)
  %706 : Tensor = prim::GetAttr[name="bias"](%705)
  %707 : Tensor = prim::GetAttr[name="weight"](%705)
  %708 : Float(128:1, 512:128) = aten::t(%707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.46 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.62, %708), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.63 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.46, %706, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.15 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.63, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.25 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.15, %input.45, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %713 : Tensor = prim::GetAttr[name="bias"](%704)
  %714 : Tensor = prim::GetAttr[name="weight"](%704)
  %715 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.25, %714), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.64 : Float(17:6656, 13:512, 512:1) = aten::add(%715, %713, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %717 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15764.MobileBertOutput = prim::GetAttr[name="output"](%119)
  %718 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15757.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%119)
  %719 : __torch__.torch.nn.modules.container.___torch_mangle_15790.ModuleList = prim::GetAttr[name="ffn"](%119)
  %720 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15789.FFNLayer = prim::GetAttr[name="2"](%719)
  %721 : __torch__.torch.nn.modules.container.___torch_mangle_15790.ModuleList = prim::GetAttr[name="ffn"](%119)
  %722 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15783.FFNLayer = prim::GetAttr[name="1"](%721)
  %723 : __torch__.torch.nn.modules.container.___torch_mangle_15790.ModuleList = prim::GetAttr[name="ffn"](%119)
  %724 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15777.FFNLayer = prim::GetAttr[name="0"](%723)
  %725 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15755.MobileBertAttention = prim::GetAttr[name="attention"](%119)
  %726 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15771.Bottleneck = prim::GetAttr[name="bottleneck"](%119)
  %727 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15770.BottleneckLayer = prim::GetAttr[name="attention"](%726)
  %728 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15767.BottleneckLayer = prim::GetAttr[name="input"](%726)
  %729 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15766.NoNorm = prim::GetAttr[name="LayerNorm"](%728)
  %730 : __torch__.torch.nn.modules.linear.___torch_mangle_15765.Linear = prim::GetAttr[name="dense"](%728)
  %731 : Tensor = prim::GetAttr[name="bias"](%730)
  %732 : Tensor = prim::GetAttr[name="weight"](%730)
  %733 : Float(512:1, 128:512) = aten::t(%732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.47 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %733), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.47, %731, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %736 : Tensor = prim::GetAttr[name="bias"](%729)
  %737 : Tensor = prim::GetAttr[name="weight"](%729)
  %738 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.26, %737), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%738, %736, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %740 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15769.NoNorm = prim::GetAttr[name="LayerNorm"](%727)
  %741 : __torch__.torch.nn.modules.linear.___torch_mangle_15768.Linear = prim::GetAttr[name="dense"](%727)
  %742 : Tensor = prim::GetAttr[name="bias"](%741)
  %743 : Tensor = prim::GetAttr[name="weight"](%741)
  %744 : Float(512:1, 128:512) = aten::t(%743), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.48 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %744), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.48, %742, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %747 : Tensor = prim::GetAttr[name="bias"](%740)
  %748 : Tensor = prim::GetAttr[name="weight"](%740)
  %749 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.27, %748), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.65 : Float(17:1664, 13:128, 128:1) = aten::add(%749, %747, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %751 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.65, %residual_tensor.4)
  %752 : Float(17:1664, 13:128, 128:1), %753 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%751)
  %754 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15754.MobileBertSelfOutput = prim::GetAttr[name="output"](%725)
  %755 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15751.MobileBertSelfAttention = prim::GetAttr[name="self"](%725)
  %756 : __torch__.torch.nn.modules.linear.___torch_mangle_15749.Linear = prim::GetAttr[name="value"](%755)
  %757 : __torch__.torch.nn.modules.linear.___torch_mangle_15748.Linear = prim::GetAttr[name="key"](%755)
  %758 : __torch__.torch.nn.modules.linear.___torch_mangle_15747.Linear = prim::GetAttr[name="query"](%755)
  %759 : Tensor = prim::GetAttr[name="bias"](%758)
  %760 : Tensor = prim::GetAttr[name="weight"](%758)
  %761 : Float(128:1, 128:128) = aten::t(%760), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %output.49 : Float(17:1664, 13:128, 128:1) = aten::matmul(%752, %761), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %x.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.49, %759, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1678:0
  %764 : Tensor = prim::GetAttr[name="bias"](%757)
  %765 : Tensor = prim::GetAttr[name="weight"](%757)
  %766 : Float(128:1, 128:128) = aten::t(%765), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %output.50 : Float(17:1664, 13:128, 128:1) = aten::matmul(%752, %766), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %x.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.50, %764, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1678:0
  %769 : Tensor = prim::GetAttr[name="bias"](%756)
  %770 : Tensor = prim::GetAttr[name="weight"](%756)
  %771 : Float(512:1, 128:512) = aten::t(%770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %output.51 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %x.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.51, %769, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1678:0
  %774 : int = aten::size(%x.19, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %775 : int = aten::size(%x.19, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %776 : int[] = prim::ListConstruct(%774, %775, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.19, %776), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %778 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %query_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.20, %778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %780 : int = aten::size(%x.21, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %781 : int = aten::size(%x.21, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %782 : int[] = prim::ListConstruct(%780, %781, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.21, %782), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %784 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %key_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.22, %784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %786 : int = aten::size(%x.23, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %787 : int = aten::size(%x.23, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %788 : int[] = prim::ListConstruct(%786, %787, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.23, %788), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %790 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %value_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.24, %790), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %792 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.4, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.4, %792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.7, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.66 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.8, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.67 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.66, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.67, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.7 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.4, %value_layer.4), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:280:0
  %799 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %800 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.7, %799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%800, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %802 : int = aten::size(%context_layer.8, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %803 : int = aten::size(%context_layer.8, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %804 : int[] = prim::ListConstruct(%802, %803, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %input.68 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.8, %804), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:283:0
  %806 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15753.NoNorm = prim::GetAttr[name="LayerNorm"](%754)
  %807 : __torch__.torch.nn.modules.linear.___torch_mangle_15752.Linear = prim::GetAttr[name="dense"](%754)
  %808 : Tensor = prim::GetAttr[name="bias"](%807)
  %809 : Tensor = prim::GetAttr[name="weight"](%807)
  %810 : Float(128:1, 128:128) = aten::t(%809), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %output.52 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.68, %810), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.52, %808, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.28 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.16, %753, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output # transformers/modeling_mobilebert.py:301:0
  %814 : Tensor = prim::GetAttr[name="bias"](%806)
  %815 : Tensor = prim::GetAttr[name="weight"](%806)
  %816 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.28, %815), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.69 : Float(17:1664, 13:128, 128:1) = aten::add(%816, %814, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %818 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15776.FFNOutput = prim::GetAttr[name="output"](%724)
  %819 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15773.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%724)
  %820 : __torch__.torch.nn.modules.linear.___torch_mangle_15772.Linear = prim::GetAttr[name="dense"](%819)
  %821 : Tensor = prim::GetAttr[name="bias"](%820)
  %822 : Tensor = prim::GetAttr[name="weight"](%820)
  %823 : Float(128:1, 512:128) = aten::t(%822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.53 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.69, %823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.70 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.53, %821, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.71 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.70), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %827 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15775.NoNorm = prim::GetAttr[name="LayerNorm"](%818)
  %828 : __torch__.torch.nn.modules.linear.___torch_mangle_15774.Linear = prim::GetAttr[name="dense"](%818)
  %829 : Tensor = prim::GetAttr[name="bias"](%828)
  %830 : Tensor = prim::GetAttr[name="weight"](%828)
  %831 : Float(512:1, 128:512) = aten::t(%830), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.54 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.71, %831), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.54, %829, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.29 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.17, %input.69, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %835 : Tensor = prim::GetAttr[name="bias"](%827)
  %836 : Tensor = prim::GetAttr[name="weight"](%827)
  %837 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.29, %836), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.72 : Float(17:1664, 13:128, 128:1) = aten::add(%837, %835, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %839 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15782.FFNOutput = prim::GetAttr[name="output"](%722)
  %840 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15779.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%722)
  %841 : __torch__.torch.nn.modules.linear.___torch_mangle_15778.Linear = prim::GetAttr[name="dense"](%840)
  %842 : Tensor = prim::GetAttr[name="bias"](%841)
  %843 : Tensor = prim::GetAttr[name="weight"](%841)
  %844 : Float(128:1, 512:128) = aten::t(%843), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.55 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.72, %844), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.73 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.55, %842, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.74 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.73), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %848 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15781.NoNorm = prim::GetAttr[name="LayerNorm"](%839)
  %849 : __torch__.torch.nn.modules.linear.___torch_mangle_15780.Linear = prim::GetAttr[name="dense"](%839)
  %850 : Tensor = prim::GetAttr[name="bias"](%849)
  %851 : Tensor = prim::GetAttr[name="weight"](%849)
  %852 : Float(512:1, 128:512) = aten::t(%851), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.56 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.74, %852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.56, %850, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.30 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.18, %input.72, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %856 : Tensor = prim::GetAttr[name="bias"](%848)
  %857 : Tensor = prim::GetAttr[name="weight"](%848)
  %858 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.30, %857), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.75 : Float(17:1664, 13:128, 128:1) = aten::add(%858, %856, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %860 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15788.FFNOutput = prim::GetAttr[name="output"](%720)
  %861 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15785.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%720)
  %862 : __torch__.torch.nn.modules.linear.___torch_mangle_15784.Linear = prim::GetAttr[name="dense"](%861)
  %863 : Tensor = prim::GetAttr[name="bias"](%862)
  %864 : Tensor = prim::GetAttr[name="weight"](%862)
  %865 : Float(128:1, 512:128) = aten::t(%864), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.57 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.75, %865), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.76 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.57, %863, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.77 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.76), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %869 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15787.NoNorm = prim::GetAttr[name="LayerNorm"](%860)
  %870 : __torch__.torch.nn.modules.linear.___torch_mangle_15786.Linear = prim::GetAttr[name="dense"](%860)
  %871 : Tensor = prim::GetAttr[name="bias"](%870)
  %872 : Tensor = prim::GetAttr[name="weight"](%870)
  %873 : Float(512:1, 128:512) = aten::t(%872), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.58 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.77, %873), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.58, %871, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.31 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.19, %input.75, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %877 : Tensor = prim::GetAttr[name="bias"](%869)
  %878 : Tensor = prim::GetAttr[name="weight"](%869)
  %879 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.31, %878), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.78 : Float(17:1664, 13:128, 128:1) = aten::add(%879, %877, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %881 : __torch__.torch.nn.modules.linear.___torch_mangle_15756.Linear = prim::GetAttr[name="dense"](%718)
  %882 : Tensor = prim::GetAttr[name="bias"](%881)
  %883 : Tensor = prim::GetAttr[name="weight"](%881)
  %884 : Float(128:1, 512:128) = aten::t(%883), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %output.59 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.78, %884), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %input.79 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.59, %882, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1678:0
  %input.80 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.79), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate # torch/nn/functional.py:1119:0
  %888 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15763.OutputBottleneck = prim::GetAttr[name="bottleneck"](%717)
  %889 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15759.NoNorm = prim::GetAttr[name="LayerNorm"](%717)
  %890 : __torch__.torch.nn.modules.linear.___torch_mangle_15758.Linear = prim::GetAttr[name="dense"](%717)
  %891 : Tensor = prim::GetAttr[name="bias"](%890)
  %892 : Tensor = prim::GetAttr[name="weight"](%890)
  %893 : Float(512:1, 128:512) = aten::t(%892), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %output.60 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.80, %893), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %layer_output.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.60, %891, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.32 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.4, %input.78, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output # transformers/modeling_mobilebert.py:405:0
  %897 : Tensor = prim::GetAttr[name="bias"](%889)
  %898 : Tensor = prim::GetAttr[name="weight"](%889)
  %899 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.32, %898), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.81 : Float(17:1664, 13:128, 128:1) = aten::add(%899, %897, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %901 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15761.NoNorm = prim::GetAttr[name="LayerNorm"](%888)
  %902 : __torch__.torch.nn.modules.linear.___torch_mangle_15760.Linear = prim::GetAttr[name="dense"](%888)
  %903 : Tensor = prim::GetAttr[name="bias"](%902)
  %904 : Tensor = prim::GetAttr[name="weight"](%902)
  %905 : Float(128:1, 512:128) = aten::t(%904), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.61 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.81, %905), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.82 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.61, %903, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.20 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.82, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.33 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.20, %input.64, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %910 : Tensor = prim::GetAttr[name="bias"](%901)
  %911 : Tensor = prim::GetAttr[name="weight"](%901)
  %912 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.33, %911), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.83 : Float(17:6656, 13:512, 512:1) = aten::add(%912, %910, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %914 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15809.MobileBertOutput = prim::GetAttr[name="output"](%117)
  %915 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15802.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%117)
  %916 : __torch__.torch.nn.modules.container.___torch_mangle_15835.ModuleList = prim::GetAttr[name="ffn"](%117)
  %917 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15834.FFNLayer = prim::GetAttr[name="2"](%916)
  %918 : __torch__.torch.nn.modules.container.___torch_mangle_15835.ModuleList = prim::GetAttr[name="ffn"](%117)
  %919 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15828.FFNLayer = prim::GetAttr[name="1"](%918)
  %920 : __torch__.torch.nn.modules.container.___torch_mangle_15835.ModuleList = prim::GetAttr[name="ffn"](%117)
  %921 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15822.FFNLayer = prim::GetAttr[name="0"](%920)
  %922 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15800.MobileBertAttention = prim::GetAttr[name="attention"](%117)
  %923 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15816.Bottleneck = prim::GetAttr[name="bottleneck"](%117)
  %924 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15815.BottleneckLayer = prim::GetAttr[name="attention"](%923)
  %925 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15812.BottleneckLayer = prim::GetAttr[name="input"](%923)
  %926 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15811.NoNorm = prim::GetAttr[name="LayerNorm"](%925)
  %927 : __torch__.torch.nn.modules.linear.___torch_mangle_15810.Linear = prim::GetAttr[name="dense"](%925)
  %928 : Tensor = prim::GetAttr[name="bias"](%927)
  %929 : Tensor = prim::GetAttr[name="weight"](%927)
  %930 : Float(512:1, 128:512) = aten::t(%929), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.62 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %930), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.62, %928, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %933 : Tensor = prim::GetAttr[name="bias"](%926)
  %934 : Tensor = prim::GetAttr[name="weight"](%926)
  %935 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.34, %934), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%935, %933, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %937 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15814.NoNorm = prim::GetAttr[name="LayerNorm"](%924)
  %938 : __torch__.torch.nn.modules.linear.___torch_mangle_15813.Linear = prim::GetAttr[name="dense"](%924)
  %939 : Tensor = prim::GetAttr[name="bias"](%938)
  %940 : Tensor = prim::GetAttr[name="weight"](%938)
  %941 : Float(512:1, 128:512) = aten::t(%940), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.63 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %941), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.63, %939, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %944 : Tensor = prim::GetAttr[name="bias"](%937)
  %945 : Tensor = prim::GetAttr[name="weight"](%937)
  %946 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.35, %945), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.84 : Float(17:1664, 13:128, 128:1) = aten::add(%946, %944, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %948 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.84, %residual_tensor.5)
  %949 : Float(17:1664, 13:128, 128:1), %950 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%948)
  %951 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15799.MobileBertSelfOutput = prim::GetAttr[name="output"](%922)
  %952 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15796.MobileBertSelfAttention = prim::GetAttr[name="self"](%922)
  %953 : __torch__.torch.nn.modules.linear.___torch_mangle_15794.Linear = prim::GetAttr[name="value"](%952)
  %954 : __torch__.torch.nn.modules.linear.___torch_mangle_15793.Linear = prim::GetAttr[name="key"](%952)
  %955 : __torch__.torch.nn.modules.linear.___torch_mangle_15792.Linear = prim::GetAttr[name="query"](%952)
  %956 : Tensor = prim::GetAttr[name="bias"](%955)
  %957 : Tensor = prim::GetAttr[name="weight"](%955)
  %958 : Float(128:1, 128:128) = aten::t(%957), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %output.64 : Float(17:1664, 13:128, 128:1) = aten::matmul(%949, %958), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %x.25 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.64, %956, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1678:0
  %961 : Tensor = prim::GetAttr[name="bias"](%954)
  %962 : Tensor = prim::GetAttr[name="weight"](%954)
  %963 : Float(128:1, 128:128) = aten::t(%962), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %output.65 : Float(17:1664, 13:128, 128:1) = aten::matmul(%949, %963), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %x.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.65, %961, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1678:0
  %966 : Tensor = prim::GetAttr[name="bias"](%953)
  %967 : Tensor = prim::GetAttr[name="weight"](%953)
  %968 : Float(512:1, 128:512) = aten::t(%967), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %output.66 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %968), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %x.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.66, %966, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1678:0
  %971 : int = aten::size(%x.25, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %972 : int = aten::size(%x.25, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %973 : int[] = prim::ListConstruct(%971, %972, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.25, %973), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %975 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %query_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.26, %975), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %977 : int = aten::size(%x.27, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %978 : int = aten::size(%x.27, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %979 : int[] = prim::ListConstruct(%977, %978, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.27, %979), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %981 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %key_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.28, %981), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %983 : int = aten::size(%x.29, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %984 : int = aten::size(%x.29, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %985 : int[] = prim::ListConstruct(%983, %984, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.29, %985), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %987 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %value_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.30, %987), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %989 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.5, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.5, %989), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.9, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.85 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.10, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.86 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.85, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.86, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.9 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.5, %value_layer.5), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:280:0
  %996 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %997 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.9, %996), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%997, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %999 : int = aten::size(%context_layer.10, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1000 : int = aten::size(%context_layer.10, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1001 : int[] = prim::ListConstruct(%999, %1000, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %input.87 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.10, %1001), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:283:0
  %1003 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15798.NoNorm = prim::GetAttr[name="LayerNorm"](%951)
  %1004 : __torch__.torch.nn.modules.linear.___torch_mangle_15797.Linear = prim::GetAttr[name="dense"](%951)
  %1005 : Tensor = prim::GetAttr[name="bias"](%1004)
  %1006 : Tensor = prim::GetAttr[name="weight"](%1004)
  %1007 : Float(128:1, 128:128) = aten::t(%1006), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %output.67 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.87, %1007), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.67, %1005, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.36 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.21, %950, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output # transformers/modeling_mobilebert.py:301:0
  %1011 : Tensor = prim::GetAttr[name="bias"](%1003)
  %1012 : Tensor = prim::GetAttr[name="weight"](%1003)
  %1013 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.36, %1012), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.88 : Float(17:1664, 13:128, 128:1) = aten::add(%1013, %1011, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1015 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15821.FFNOutput = prim::GetAttr[name="output"](%921)
  %1016 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15818.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%921)
  %1017 : __torch__.torch.nn.modules.linear.___torch_mangle_15817.Linear = prim::GetAttr[name="dense"](%1016)
  %1018 : Tensor = prim::GetAttr[name="bias"](%1017)
  %1019 : Tensor = prim::GetAttr[name="weight"](%1017)
  %1020 : Float(128:1, 512:128) = aten::t(%1019), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.68 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.88, %1020), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.89 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.68, %1018, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.90 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.89), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1024 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15820.NoNorm = prim::GetAttr[name="LayerNorm"](%1015)
  %1025 : __torch__.torch.nn.modules.linear.___torch_mangle_15819.Linear = prim::GetAttr[name="dense"](%1015)
  %1026 : Tensor = prim::GetAttr[name="bias"](%1025)
  %1027 : Tensor = prim::GetAttr[name="weight"](%1025)
  %1028 : Float(512:1, 128:512) = aten::t(%1027), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.69 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.90, %1028), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.69, %1026, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.37 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.22, %input.88, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1032 : Tensor = prim::GetAttr[name="bias"](%1024)
  %1033 : Tensor = prim::GetAttr[name="weight"](%1024)
  %1034 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.37, %1033), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.91 : Float(17:1664, 13:128, 128:1) = aten::add(%1034, %1032, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1036 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15827.FFNOutput = prim::GetAttr[name="output"](%919)
  %1037 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15824.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%919)
  %1038 : __torch__.torch.nn.modules.linear.___torch_mangle_15823.Linear = prim::GetAttr[name="dense"](%1037)
  %1039 : Tensor = prim::GetAttr[name="bias"](%1038)
  %1040 : Tensor = prim::GetAttr[name="weight"](%1038)
  %1041 : Float(128:1, 512:128) = aten::t(%1040), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.70 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.91, %1041), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.92 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.70, %1039, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.93 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.92), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1045 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15826.NoNorm = prim::GetAttr[name="LayerNorm"](%1036)
  %1046 : __torch__.torch.nn.modules.linear.___torch_mangle_15825.Linear = prim::GetAttr[name="dense"](%1036)
  %1047 : Tensor = prim::GetAttr[name="bias"](%1046)
  %1048 : Tensor = prim::GetAttr[name="weight"](%1046)
  %1049 : Float(512:1, 128:512) = aten::t(%1048), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.71 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.93, %1049), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.71, %1047, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.38 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.23, %input.91, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1053 : Tensor = prim::GetAttr[name="bias"](%1045)
  %1054 : Tensor = prim::GetAttr[name="weight"](%1045)
  %1055 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.38, %1054), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.94 : Float(17:1664, 13:128, 128:1) = aten::add(%1055, %1053, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1057 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15833.FFNOutput = prim::GetAttr[name="output"](%917)
  %1058 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15830.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%917)
  %1059 : __torch__.torch.nn.modules.linear.___torch_mangle_15829.Linear = prim::GetAttr[name="dense"](%1058)
  %1060 : Tensor = prim::GetAttr[name="bias"](%1059)
  %1061 : Tensor = prim::GetAttr[name="weight"](%1059)
  %1062 : Float(128:1, 512:128) = aten::t(%1061), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.72 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.94, %1062), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.95 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.72, %1060, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.96 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.95), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1066 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15832.NoNorm = prim::GetAttr[name="LayerNorm"](%1057)
  %1067 : __torch__.torch.nn.modules.linear.___torch_mangle_15831.Linear = prim::GetAttr[name="dense"](%1057)
  %1068 : Tensor = prim::GetAttr[name="bias"](%1067)
  %1069 : Tensor = prim::GetAttr[name="weight"](%1067)
  %1070 : Float(512:1, 128:512) = aten::t(%1069), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.73 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.96, %1070), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.24 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.73, %1068, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.39 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.24, %input.94, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1074 : Tensor = prim::GetAttr[name="bias"](%1066)
  %1075 : Tensor = prim::GetAttr[name="weight"](%1066)
  %1076 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.39, %1075), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.97 : Float(17:1664, 13:128, 128:1) = aten::add(%1076, %1074, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1078 : __torch__.torch.nn.modules.linear.___torch_mangle_15801.Linear = prim::GetAttr[name="dense"](%915)
  %1079 : Tensor = prim::GetAttr[name="bias"](%1078)
  %1080 : Tensor = prim::GetAttr[name="weight"](%1078)
  %1081 : Float(128:1, 512:128) = aten::t(%1080), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %output.74 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.97, %1081), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %input.98 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.74, %1079, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1678:0
  %input.99 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.98), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate # torch/nn/functional.py:1119:0
  %1085 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15808.OutputBottleneck = prim::GetAttr[name="bottleneck"](%914)
  %1086 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15804.NoNorm = prim::GetAttr[name="LayerNorm"](%914)
  %1087 : __torch__.torch.nn.modules.linear.___torch_mangle_15803.Linear = prim::GetAttr[name="dense"](%914)
  %1088 : Tensor = prim::GetAttr[name="bias"](%1087)
  %1089 : Tensor = prim::GetAttr[name="weight"](%1087)
  %1090 : Float(512:1, 128:512) = aten::t(%1089), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %output.75 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.99, %1090), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %layer_output.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.75, %1088, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.40 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.5, %input.97, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output # transformers/modeling_mobilebert.py:405:0
  %1094 : Tensor = prim::GetAttr[name="bias"](%1086)
  %1095 : Tensor = prim::GetAttr[name="weight"](%1086)
  %1096 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.40, %1095), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.100 : Float(17:1664, 13:128, 128:1) = aten::add(%1096, %1094, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1098 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15806.NoNorm = prim::GetAttr[name="LayerNorm"](%1085)
  %1099 : __torch__.torch.nn.modules.linear.___torch_mangle_15805.Linear = prim::GetAttr[name="dense"](%1085)
  %1100 : Tensor = prim::GetAttr[name="bias"](%1099)
  %1101 : Tensor = prim::GetAttr[name="weight"](%1099)
  %1102 : Float(128:1, 512:128) = aten::t(%1101), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.76 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.100, %1102), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.101 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.76, %1100, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.25 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.101, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.41 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.25, %input.83, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1107 : Tensor = prim::GetAttr[name="bias"](%1098)
  %1108 : Tensor = prim::GetAttr[name="weight"](%1098)
  %1109 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.41, %1108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.102 : Float(17:6656, 13:512, 512:1) = aten::add(%1109, %1107, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15854.MobileBertOutput = prim::GetAttr[name="output"](%115)
  %1112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15847.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%115)
  %1113 : __torch__.torch.nn.modules.container.___torch_mangle_15880.ModuleList = prim::GetAttr[name="ffn"](%115)
  %1114 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15879.FFNLayer = prim::GetAttr[name="2"](%1113)
  %1115 : __torch__.torch.nn.modules.container.___torch_mangle_15880.ModuleList = prim::GetAttr[name="ffn"](%115)
  %1116 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15873.FFNLayer = prim::GetAttr[name="1"](%1115)
  %1117 : __torch__.torch.nn.modules.container.___torch_mangle_15880.ModuleList = prim::GetAttr[name="ffn"](%115)
  %1118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15867.FFNLayer = prim::GetAttr[name="0"](%1117)
  %1119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15845.MobileBertAttention = prim::GetAttr[name="attention"](%115)
  %1120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15861.Bottleneck = prim::GetAttr[name="bottleneck"](%115)
  %1121 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15860.BottleneckLayer = prim::GetAttr[name="attention"](%1120)
  %1122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15857.BottleneckLayer = prim::GetAttr[name="input"](%1120)
  %1123 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15856.NoNorm = prim::GetAttr[name="LayerNorm"](%1122)
  %1124 : __torch__.torch.nn.modules.linear.___torch_mangle_15855.Linear = prim::GetAttr[name="dense"](%1122)
  %1125 : Tensor = prim::GetAttr[name="bias"](%1124)
  %1126 : Tensor = prim::GetAttr[name="weight"](%1124)
  %1127 : Float(512:1, 128:512) = aten::t(%1126), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.77 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.77, %1125, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1130 : Tensor = prim::GetAttr[name="bias"](%1123)
  %1131 : Tensor = prim::GetAttr[name="weight"](%1123)
  %1132 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.42, %1131), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%1132, %1130, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1134 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15859.NoNorm = prim::GetAttr[name="LayerNorm"](%1121)
  %1135 : __torch__.torch.nn.modules.linear.___torch_mangle_15858.Linear = prim::GetAttr[name="dense"](%1121)
  %1136 : Tensor = prim::GetAttr[name="bias"](%1135)
  %1137 : Tensor = prim::GetAttr[name="weight"](%1135)
  %1138 : Float(512:1, 128:512) = aten::t(%1137), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.78 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1138), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.78, %1136, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1141 : Tensor = prim::GetAttr[name="bias"](%1134)
  %1142 : Tensor = prim::GetAttr[name="weight"](%1134)
  %1143 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.43, %1142), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.103 : Float(17:1664, 13:128, 128:1) = aten::add(%1143, %1141, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1145 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.103, %residual_tensor.6)
  %1146 : Float(17:1664, 13:128, 128:1), %1147 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1145)
  %1148 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15844.MobileBertSelfOutput = prim::GetAttr[name="output"](%1119)
  %1149 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15841.MobileBertSelfAttention = prim::GetAttr[name="self"](%1119)
  %1150 : __torch__.torch.nn.modules.linear.___torch_mangle_15839.Linear = prim::GetAttr[name="value"](%1149)
  %1151 : __torch__.torch.nn.modules.linear.___torch_mangle_15838.Linear = prim::GetAttr[name="key"](%1149)
  %1152 : __torch__.torch.nn.modules.linear.___torch_mangle_15837.Linear = prim::GetAttr[name="query"](%1149)
  %1153 : Tensor = prim::GetAttr[name="bias"](%1152)
  %1154 : Tensor = prim::GetAttr[name="weight"](%1152)
  %1155 : Float(128:1, 128:128) = aten::t(%1154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %output.79 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1146, %1155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %x.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.79, %1153, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1678:0
  %1158 : Tensor = prim::GetAttr[name="bias"](%1151)
  %1159 : Tensor = prim::GetAttr[name="weight"](%1151)
  %1160 : Float(128:1, 128:128) = aten::t(%1159), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %output.80 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1146, %1160), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %x.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.80, %1158, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1678:0
  %1163 : Tensor = prim::GetAttr[name="bias"](%1150)
  %1164 : Tensor = prim::GetAttr[name="weight"](%1150)
  %1165 : Float(512:1, 128:512) = aten::t(%1164), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %output.81 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %x.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.81, %1163, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1678:0
  %1168 : int = aten::size(%x.31, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1169 : int = aten::size(%x.31, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1170 : int[] = prim::ListConstruct(%1168, %1169, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.31, %1170), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1172 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %query_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.32, %1172), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1174 : int = aten::size(%x.33, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1175 : int = aten::size(%x.33, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1176 : int[] = prim::ListConstruct(%1174, %1175, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.33, %1176), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1178 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %key_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.34, %1178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1180 : int = aten::size(%x.35, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1181 : int = aten::size(%x.35, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1182 : int[] = prim::ListConstruct(%1180, %1181, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.35, %1182), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1184 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %value_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.36, %1184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1186 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.6, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.6, %1186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.11, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.104 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.12, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.105 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.104, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.105, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.11 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.6, %value_layer.6), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:280:0
  %1193 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %1194 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.11, %1193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1194, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %1196 : int = aten::size(%context_layer.12, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1197 : int = aten::size(%context_layer.12, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1198 : int[] = prim::ListConstruct(%1196, %1197, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %input.106 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.12, %1198), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:283:0
  %1200 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15843.NoNorm = prim::GetAttr[name="LayerNorm"](%1148)
  %1201 : __torch__.torch.nn.modules.linear.___torch_mangle_15842.Linear = prim::GetAttr[name="dense"](%1148)
  %1202 : Tensor = prim::GetAttr[name="bias"](%1201)
  %1203 : Tensor = prim::GetAttr[name="weight"](%1201)
  %1204 : Float(128:1, 128:128) = aten::t(%1203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %output.82 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.106, %1204), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.82, %1202, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.44 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.26, %1147, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output # transformers/modeling_mobilebert.py:301:0
  %1208 : Tensor = prim::GetAttr[name="bias"](%1200)
  %1209 : Tensor = prim::GetAttr[name="weight"](%1200)
  %1210 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.44, %1209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.107 : Float(17:1664, 13:128, 128:1) = aten::add(%1210, %1208, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1212 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15866.FFNOutput = prim::GetAttr[name="output"](%1118)
  %1213 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15863.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1118)
  %1214 : __torch__.torch.nn.modules.linear.___torch_mangle_15862.Linear = prim::GetAttr[name="dense"](%1213)
  %1215 : Tensor = prim::GetAttr[name="bias"](%1214)
  %1216 : Tensor = prim::GetAttr[name="weight"](%1214)
  %1217 : Float(128:1, 512:128) = aten::t(%1216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.83 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.107, %1217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.108 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.83, %1215, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.109 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1221 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15865.NoNorm = prim::GetAttr[name="LayerNorm"](%1212)
  %1222 : __torch__.torch.nn.modules.linear.___torch_mangle_15864.Linear = prim::GetAttr[name="dense"](%1212)
  %1223 : Tensor = prim::GetAttr[name="bias"](%1222)
  %1224 : Tensor = prim::GetAttr[name="weight"](%1222)
  %1225 : Float(512:1, 128:512) = aten::t(%1224), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.84 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.109, %1225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.84, %1223, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.45 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.27, %input.107, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1229 : Tensor = prim::GetAttr[name="bias"](%1221)
  %1230 : Tensor = prim::GetAttr[name="weight"](%1221)
  %1231 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.45, %1230), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.110 : Float(17:1664, 13:128, 128:1) = aten::add(%1231, %1229, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1233 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15872.FFNOutput = prim::GetAttr[name="output"](%1116)
  %1234 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15869.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1116)
  %1235 : __torch__.torch.nn.modules.linear.___torch_mangle_15868.Linear = prim::GetAttr[name="dense"](%1234)
  %1236 : Tensor = prim::GetAttr[name="bias"](%1235)
  %1237 : Tensor = prim::GetAttr[name="weight"](%1235)
  %1238 : Float(128:1, 512:128) = aten::t(%1237), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.85 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.110, %1238), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.111 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.85, %1236, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.112 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1242 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15871.NoNorm = prim::GetAttr[name="LayerNorm"](%1233)
  %1243 : __torch__.torch.nn.modules.linear.___torch_mangle_15870.Linear = prim::GetAttr[name="dense"](%1233)
  %1244 : Tensor = prim::GetAttr[name="bias"](%1243)
  %1245 : Tensor = prim::GetAttr[name="weight"](%1243)
  %1246 : Float(512:1, 128:512) = aten::t(%1245), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.86 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.112, %1246), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.28 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.86, %1244, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.46 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.28, %input.110, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1250 : Tensor = prim::GetAttr[name="bias"](%1242)
  %1251 : Tensor = prim::GetAttr[name="weight"](%1242)
  %1252 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.46, %1251), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.113 : Float(17:1664, 13:128, 128:1) = aten::add(%1252, %1250, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1254 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15878.FFNOutput = prim::GetAttr[name="output"](%1114)
  %1255 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15875.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1114)
  %1256 : __torch__.torch.nn.modules.linear.___torch_mangle_15874.Linear = prim::GetAttr[name="dense"](%1255)
  %1257 : Tensor = prim::GetAttr[name="bias"](%1256)
  %1258 : Tensor = prim::GetAttr[name="weight"](%1256)
  %1259 : Float(128:1, 512:128) = aten::t(%1258), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.87 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.113, %1259), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.114 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.87, %1257, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.115 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.114), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1263 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15877.NoNorm = prim::GetAttr[name="LayerNorm"](%1254)
  %1264 : __torch__.torch.nn.modules.linear.___torch_mangle_15876.Linear = prim::GetAttr[name="dense"](%1254)
  %1265 : Tensor = prim::GetAttr[name="bias"](%1264)
  %1266 : Tensor = prim::GetAttr[name="weight"](%1264)
  %1267 : Float(512:1, 128:512) = aten::t(%1266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.88 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.115, %1267), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.88, %1265, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.47 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.29, %input.113, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1271 : Tensor = prim::GetAttr[name="bias"](%1263)
  %1272 : Tensor = prim::GetAttr[name="weight"](%1263)
  %1273 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.47, %1272), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.116 : Float(17:1664, 13:128, 128:1) = aten::add(%1273, %1271, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1275 : __torch__.torch.nn.modules.linear.___torch_mangle_15846.Linear = prim::GetAttr[name="dense"](%1112)
  %1276 : Tensor = prim::GetAttr[name="bias"](%1275)
  %1277 : Tensor = prim::GetAttr[name="weight"](%1275)
  %1278 : Float(128:1, 512:128) = aten::t(%1277), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %output.89 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.116, %1278), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %input.117 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.89, %1276, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1678:0
  %input.118 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.117), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate # torch/nn/functional.py:1119:0
  %1282 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15853.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1111)
  %1283 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15849.NoNorm = prim::GetAttr[name="LayerNorm"](%1111)
  %1284 : __torch__.torch.nn.modules.linear.___torch_mangle_15848.Linear = prim::GetAttr[name="dense"](%1111)
  %1285 : Tensor = prim::GetAttr[name="bias"](%1284)
  %1286 : Tensor = prim::GetAttr[name="weight"](%1284)
  %1287 : Float(512:1, 128:512) = aten::t(%1286), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %output.90 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.118, %1287), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %layer_output.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.90, %1285, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.48 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.6, %input.116, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output # transformers/modeling_mobilebert.py:405:0
  %1291 : Tensor = prim::GetAttr[name="bias"](%1283)
  %1292 : Tensor = prim::GetAttr[name="weight"](%1283)
  %1293 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.48, %1292), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.119 : Float(17:1664, 13:128, 128:1) = aten::add(%1293, %1291, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1295 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15851.NoNorm = prim::GetAttr[name="LayerNorm"](%1282)
  %1296 : __torch__.torch.nn.modules.linear.___torch_mangle_15850.Linear = prim::GetAttr[name="dense"](%1282)
  %1297 : Tensor = prim::GetAttr[name="bias"](%1296)
  %1298 : Tensor = prim::GetAttr[name="weight"](%1296)
  %1299 : Float(128:1, 512:128) = aten::t(%1298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.91 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.119, %1299), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.120 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.91, %1297, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.30 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.120, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.49 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.30, %input.102, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1304 : Tensor = prim::GetAttr[name="bias"](%1295)
  %1305 : Tensor = prim::GetAttr[name="weight"](%1295)
  %1306 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.49, %1305), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.121 : Float(17:6656, 13:512, 512:1) = aten::add(%1306, %1304, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1308 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15899.MobileBertOutput = prim::GetAttr[name="output"](%113)
  %1309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15892.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%113)
  %1310 : __torch__.torch.nn.modules.container.___torch_mangle_15925.ModuleList = prim::GetAttr[name="ffn"](%113)
  %1311 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15924.FFNLayer = prim::GetAttr[name="2"](%1310)
  %1312 : __torch__.torch.nn.modules.container.___torch_mangle_15925.ModuleList = prim::GetAttr[name="ffn"](%113)
  %1313 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15918.FFNLayer = prim::GetAttr[name="1"](%1312)
  %1314 : __torch__.torch.nn.modules.container.___torch_mangle_15925.ModuleList = prim::GetAttr[name="ffn"](%113)
  %1315 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15912.FFNLayer = prim::GetAttr[name="0"](%1314)
  %1316 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15890.MobileBertAttention = prim::GetAttr[name="attention"](%113)
  %1317 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15906.Bottleneck = prim::GetAttr[name="bottleneck"](%113)
  %1318 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15905.BottleneckLayer = prim::GetAttr[name="attention"](%1317)
  %1319 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15902.BottleneckLayer = prim::GetAttr[name="input"](%1317)
  %1320 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15901.NoNorm = prim::GetAttr[name="LayerNorm"](%1319)
  %1321 : __torch__.torch.nn.modules.linear.___torch_mangle_15900.Linear = prim::GetAttr[name="dense"](%1319)
  %1322 : Tensor = prim::GetAttr[name="bias"](%1321)
  %1323 : Tensor = prim::GetAttr[name="weight"](%1321)
  %1324 : Float(512:1, 128:512) = aten::t(%1323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.92 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1324), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.50 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.92, %1322, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1327 : Tensor = prim::GetAttr[name="bias"](%1320)
  %1328 : Tensor = prim::GetAttr[name="weight"](%1320)
  %1329 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.50, %1328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%1329, %1327, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1331 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15904.NoNorm = prim::GetAttr[name="LayerNorm"](%1318)
  %1332 : __torch__.torch.nn.modules.linear.___torch_mangle_15903.Linear = prim::GetAttr[name="dense"](%1318)
  %1333 : Tensor = prim::GetAttr[name="bias"](%1332)
  %1334 : Tensor = prim::GetAttr[name="weight"](%1332)
  %1335 : Float(512:1, 128:512) = aten::t(%1334), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.93 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1335), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.93, %1333, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1338 : Tensor = prim::GetAttr[name="bias"](%1331)
  %1339 : Tensor = prim::GetAttr[name="weight"](%1331)
  %1340 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.51, %1339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.122 : Float(17:1664, 13:128, 128:1) = aten::add(%1340, %1338, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1342 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.122, %residual_tensor.7)
  %1343 : Float(17:1664, 13:128, 128:1), %1344 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1342)
  %1345 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15889.MobileBertSelfOutput = prim::GetAttr[name="output"](%1316)
  %1346 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15886.MobileBertSelfAttention = prim::GetAttr[name="self"](%1316)
  %1347 : __torch__.torch.nn.modules.linear.___torch_mangle_15884.Linear = prim::GetAttr[name="value"](%1346)
  %1348 : __torch__.torch.nn.modules.linear.___torch_mangle_15883.Linear = prim::GetAttr[name="key"](%1346)
  %1349 : __torch__.torch.nn.modules.linear.___torch_mangle_15882.Linear = prim::GetAttr[name="query"](%1346)
  %1350 : Tensor = prim::GetAttr[name="bias"](%1349)
  %1351 : Tensor = prim::GetAttr[name="weight"](%1349)
  %1352 : Float(128:1, 128:128) = aten::t(%1351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %output.94 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1343, %1352), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %x.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.94, %1350, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1678:0
  %1355 : Tensor = prim::GetAttr[name="bias"](%1348)
  %1356 : Tensor = prim::GetAttr[name="weight"](%1348)
  %1357 : Float(128:1, 128:128) = aten::t(%1356), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %output.95 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1343, %1357), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %x.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.95, %1355, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1678:0
  %1360 : Tensor = prim::GetAttr[name="bias"](%1347)
  %1361 : Tensor = prim::GetAttr[name="weight"](%1347)
  %1362 : Float(512:1, 128:512) = aten::t(%1361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %output.96 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1362), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %x.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.96, %1360, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1678:0
  %1365 : int = aten::size(%x.37, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1366 : int = aten::size(%x.37, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1367 : int[] = prim::ListConstruct(%1365, %1366, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.37, %1367), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1369 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %query_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.38, %1369), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1371 : int = aten::size(%x.39, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1372 : int = aten::size(%x.39, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1373 : int[] = prim::ListConstruct(%1371, %1372, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.39, %1373), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1375 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %key_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.40, %1375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1377 : int = aten::size(%x.41, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1378 : int = aten::size(%x.41, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1379 : int[] = prim::ListConstruct(%1377, %1378, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.41, %1379), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1381 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %value_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.42, %1381), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1383 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.7, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.7, %1383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.13, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.123 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.14, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.124 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.123, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.124, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.13 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.7, %value_layer.7), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:280:0
  %1390 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %1391 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.13, %1390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1391, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %1393 : int = aten::size(%context_layer.14, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1394 : int = aten::size(%context_layer.14, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1395 : int[] = prim::ListConstruct(%1393, %1394, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %input.125 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.14, %1395), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:283:0
  %1397 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15888.NoNorm = prim::GetAttr[name="LayerNorm"](%1345)
  %1398 : __torch__.torch.nn.modules.linear.___torch_mangle_15887.Linear = prim::GetAttr[name="dense"](%1345)
  %1399 : Tensor = prim::GetAttr[name="bias"](%1398)
  %1400 : Tensor = prim::GetAttr[name="weight"](%1398)
  %1401 : Float(128:1, 128:128) = aten::t(%1400), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %output.97 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.125, %1401), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.97, %1399, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.52 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.31, %1344, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output # transformers/modeling_mobilebert.py:301:0
  %1405 : Tensor = prim::GetAttr[name="bias"](%1397)
  %1406 : Tensor = prim::GetAttr[name="weight"](%1397)
  %1407 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.52, %1406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.126 : Float(17:1664, 13:128, 128:1) = aten::add(%1407, %1405, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1409 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15911.FFNOutput = prim::GetAttr[name="output"](%1315)
  %1410 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15908.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1315)
  %1411 : __torch__.torch.nn.modules.linear.___torch_mangle_15907.Linear = prim::GetAttr[name="dense"](%1410)
  %1412 : Tensor = prim::GetAttr[name="bias"](%1411)
  %1413 : Tensor = prim::GetAttr[name="weight"](%1411)
  %1414 : Float(128:1, 512:128) = aten::t(%1413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.98 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.126, %1414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.127 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.98, %1412, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.128 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1418 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15910.NoNorm = prim::GetAttr[name="LayerNorm"](%1409)
  %1419 : __torch__.torch.nn.modules.linear.___torch_mangle_15909.Linear = prim::GetAttr[name="dense"](%1409)
  %1420 : Tensor = prim::GetAttr[name="bias"](%1419)
  %1421 : Tensor = prim::GetAttr[name="weight"](%1419)
  %1422 : Float(512:1, 128:512) = aten::t(%1421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.99 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.128, %1422), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.32 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.99, %1420, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.53 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.32, %input.126, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1426 : Tensor = prim::GetAttr[name="bias"](%1418)
  %1427 : Tensor = prim::GetAttr[name="weight"](%1418)
  %1428 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.53, %1427), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.129 : Float(17:1664, 13:128, 128:1) = aten::add(%1428, %1426, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1430 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15917.FFNOutput = prim::GetAttr[name="output"](%1313)
  %1431 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15914.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1313)
  %1432 : __torch__.torch.nn.modules.linear.___torch_mangle_15913.Linear = prim::GetAttr[name="dense"](%1431)
  %1433 : Tensor = prim::GetAttr[name="bias"](%1432)
  %1434 : Tensor = prim::GetAttr[name="weight"](%1432)
  %1435 : Float(128:1, 512:128) = aten::t(%1434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.100 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.129, %1435), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.130 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.100, %1433, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.131 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1439 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15916.NoNorm = prim::GetAttr[name="LayerNorm"](%1430)
  %1440 : __torch__.torch.nn.modules.linear.___torch_mangle_15915.Linear = prim::GetAttr[name="dense"](%1430)
  %1441 : Tensor = prim::GetAttr[name="bias"](%1440)
  %1442 : Tensor = prim::GetAttr[name="weight"](%1440)
  %1443 : Float(512:1, 128:512) = aten::t(%1442), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.101 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.131, %1443), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.101, %1441, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.54 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.33, %input.129, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1447 : Tensor = prim::GetAttr[name="bias"](%1439)
  %1448 : Tensor = prim::GetAttr[name="weight"](%1439)
  %1449 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.54, %1448), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.132 : Float(17:1664, 13:128, 128:1) = aten::add(%1449, %1447, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1451 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15923.FFNOutput = prim::GetAttr[name="output"](%1311)
  %1452 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15920.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1311)
  %1453 : __torch__.torch.nn.modules.linear.___torch_mangle_15919.Linear = prim::GetAttr[name="dense"](%1452)
  %1454 : Tensor = prim::GetAttr[name="bias"](%1453)
  %1455 : Tensor = prim::GetAttr[name="weight"](%1453)
  %1456 : Float(128:1, 512:128) = aten::t(%1455), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.102 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.132, %1456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.133 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.102, %1454, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.134 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1460 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15922.NoNorm = prim::GetAttr[name="LayerNorm"](%1451)
  %1461 : __torch__.torch.nn.modules.linear.___torch_mangle_15921.Linear = prim::GetAttr[name="dense"](%1451)
  %1462 : Tensor = prim::GetAttr[name="bias"](%1461)
  %1463 : Tensor = prim::GetAttr[name="weight"](%1461)
  %1464 : Float(512:1, 128:512) = aten::t(%1463), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.103 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.134, %1464), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.103, %1462, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.55 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.34, %input.132, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1468 : Tensor = prim::GetAttr[name="bias"](%1460)
  %1469 : Tensor = prim::GetAttr[name="weight"](%1460)
  %1470 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.55, %1469), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.135 : Float(17:1664, 13:128, 128:1) = aten::add(%1470, %1468, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1472 : __torch__.torch.nn.modules.linear.___torch_mangle_15891.Linear = prim::GetAttr[name="dense"](%1309)
  %1473 : Tensor = prim::GetAttr[name="bias"](%1472)
  %1474 : Tensor = prim::GetAttr[name="weight"](%1472)
  %1475 : Float(128:1, 512:128) = aten::t(%1474), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %output.104 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.135, %1475), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %input.136 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.104, %1473, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1678:0
  %input.137 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.136), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate # torch/nn/functional.py:1119:0
  %1479 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15898.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1308)
  %1480 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15894.NoNorm = prim::GetAttr[name="LayerNorm"](%1308)
  %1481 : __torch__.torch.nn.modules.linear.___torch_mangle_15893.Linear = prim::GetAttr[name="dense"](%1308)
  %1482 : Tensor = prim::GetAttr[name="bias"](%1481)
  %1483 : Tensor = prim::GetAttr[name="weight"](%1481)
  %1484 : Float(512:1, 128:512) = aten::t(%1483), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %output.105 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.137, %1484), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %layer_output.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.105, %1482, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.56 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.7, %input.135, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output # transformers/modeling_mobilebert.py:405:0
  %1488 : Tensor = prim::GetAttr[name="bias"](%1480)
  %1489 : Tensor = prim::GetAttr[name="weight"](%1480)
  %1490 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.56, %1489), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.138 : Float(17:1664, 13:128, 128:1) = aten::add(%1490, %1488, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1492 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15896.NoNorm = prim::GetAttr[name="LayerNorm"](%1479)
  %1493 : __torch__.torch.nn.modules.linear.___torch_mangle_15895.Linear = prim::GetAttr[name="dense"](%1479)
  %1494 : Tensor = prim::GetAttr[name="bias"](%1493)
  %1495 : Tensor = prim::GetAttr[name="weight"](%1493)
  %1496 : Float(128:1, 512:128) = aten::t(%1495), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.106 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.138, %1496), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.139 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.106, %1494, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.35 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.139, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.57 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.35, %input.121, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1501 : Tensor = prim::GetAttr[name="bias"](%1492)
  %1502 : Tensor = prim::GetAttr[name="weight"](%1492)
  %1503 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.57, %1502), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.140 : Float(17:6656, 13:512, 512:1) = aten::add(%1503, %1501, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1505 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15944.MobileBertOutput = prim::GetAttr[name="output"](%111)
  %1506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15937.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%111)
  %1507 : __torch__.torch.nn.modules.container.___torch_mangle_15970.ModuleList = prim::GetAttr[name="ffn"](%111)
  %1508 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15969.FFNLayer = prim::GetAttr[name="2"](%1507)
  %1509 : __torch__.torch.nn.modules.container.___torch_mangle_15970.ModuleList = prim::GetAttr[name="ffn"](%111)
  %1510 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15963.FFNLayer = prim::GetAttr[name="1"](%1509)
  %1511 : __torch__.torch.nn.modules.container.___torch_mangle_15970.ModuleList = prim::GetAttr[name="ffn"](%111)
  %1512 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15957.FFNLayer = prim::GetAttr[name="0"](%1511)
  %1513 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15935.MobileBertAttention = prim::GetAttr[name="attention"](%111)
  %1514 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15951.Bottleneck = prim::GetAttr[name="bottleneck"](%111)
  %1515 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15950.BottleneckLayer = prim::GetAttr[name="attention"](%1514)
  %1516 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15947.BottleneckLayer = prim::GetAttr[name="input"](%1514)
  %1517 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15946.NoNorm = prim::GetAttr[name="LayerNorm"](%1516)
  %1518 : __torch__.torch.nn.modules.linear.___torch_mangle_15945.Linear = prim::GetAttr[name="dense"](%1516)
  %1519 : Tensor = prim::GetAttr[name="bias"](%1518)
  %1520 : Tensor = prim::GetAttr[name="weight"](%1518)
  %1521 : Float(512:1, 128:512) = aten::t(%1520), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.107 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1521), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.107, %1519, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1524 : Tensor = prim::GetAttr[name="bias"](%1517)
  %1525 : Tensor = prim::GetAttr[name="weight"](%1517)
  %1526 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.58, %1525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%1526, %1524, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1528 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15949.NoNorm = prim::GetAttr[name="LayerNorm"](%1515)
  %1529 : __torch__.torch.nn.modules.linear.___torch_mangle_15948.Linear = prim::GetAttr[name="dense"](%1515)
  %1530 : Tensor = prim::GetAttr[name="bias"](%1529)
  %1531 : Tensor = prim::GetAttr[name="weight"](%1529)
  %1532 : Float(512:1, 128:512) = aten::t(%1531), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.108 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1532), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.108, %1530, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1535 : Tensor = prim::GetAttr[name="bias"](%1528)
  %1536 : Tensor = prim::GetAttr[name="weight"](%1528)
  %1537 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.59, %1536), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.141 : Float(17:1664, 13:128, 128:1) = aten::add(%1537, %1535, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1539 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.141, %residual_tensor.8)
  %1540 : Float(17:1664, 13:128, 128:1), %1541 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1539)
  %1542 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15934.MobileBertSelfOutput = prim::GetAttr[name="output"](%1513)
  %1543 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15931.MobileBertSelfAttention = prim::GetAttr[name="self"](%1513)
  %1544 : __torch__.torch.nn.modules.linear.___torch_mangle_15929.Linear = prim::GetAttr[name="value"](%1543)
  %1545 : __torch__.torch.nn.modules.linear.___torch_mangle_15928.Linear = prim::GetAttr[name="key"](%1543)
  %1546 : __torch__.torch.nn.modules.linear.___torch_mangle_15927.Linear = prim::GetAttr[name="query"](%1543)
  %1547 : Tensor = prim::GetAttr[name="bias"](%1546)
  %1548 : Tensor = prim::GetAttr[name="weight"](%1546)
  %1549 : Float(128:1, 128:128) = aten::t(%1548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %output.109 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1540, %1549), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %x.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.109, %1547, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1678:0
  %1552 : Tensor = prim::GetAttr[name="bias"](%1545)
  %1553 : Tensor = prim::GetAttr[name="weight"](%1545)
  %1554 : Float(128:1, 128:128) = aten::t(%1553), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %output.110 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1540, %1554), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %x.45 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.110, %1552, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1678:0
  %1557 : Tensor = prim::GetAttr[name="bias"](%1544)
  %1558 : Tensor = prim::GetAttr[name="weight"](%1544)
  %1559 : Float(512:1, 128:512) = aten::t(%1558), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %output.111 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1559), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %x.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.111, %1557, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1678:0
  %1562 : int = aten::size(%x.43, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1563 : int = aten::size(%x.43, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1564 : int[] = prim::ListConstruct(%1562, %1563, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.43, %1564), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1566 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %query_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.44, %1566), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1568 : int = aten::size(%x.45, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1569 : int = aten::size(%x.45, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1570 : int[] = prim::ListConstruct(%1568, %1569, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.45, %1570), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1572 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %key_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.46, %1572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1574 : int = aten::size(%x.47, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1575 : int = aten::size(%x.47, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1576 : int[] = prim::ListConstruct(%1574, %1575, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.48 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.47, %1576), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1578 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %value_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.48, %1578), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1580 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.8, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.8, %1580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.15, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.142 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.16, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.143 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.142, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.143, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.15 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.8, %value_layer.8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:280:0
  %1587 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %1588 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.15, %1587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1588, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %1590 : int = aten::size(%context_layer.16, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1591 : int = aten::size(%context_layer.16, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1592 : int[] = prim::ListConstruct(%1590, %1591, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %input.144 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.16, %1592), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:283:0
  %1594 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15933.NoNorm = prim::GetAttr[name="LayerNorm"](%1542)
  %1595 : __torch__.torch.nn.modules.linear.___torch_mangle_15932.Linear = prim::GetAttr[name="dense"](%1542)
  %1596 : Tensor = prim::GetAttr[name="bias"](%1595)
  %1597 : Tensor = prim::GetAttr[name="weight"](%1595)
  %1598 : Float(128:1, 128:128) = aten::t(%1597), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %output.112 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.144, %1598), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.36 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.112, %1596, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.60 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.36, %1541, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output # transformers/modeling_mobilebert.py:301:0
  %1602 : Tensor = prim::GetAttr[name="bias"](%1594)
  %1603 : Tensor = prim::GetAttr[name="weight"](%1594)
  %1604 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.60, %1603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.145 : Float(17:1664, 13:128, 128:1) = aten::add(%1604, %1602, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1606 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15956.FFNOutput = prim::GetAttr[name="output"](%1512)
  %1607 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15953.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1512)
  %1608 : __torch__.torch.nn.modules.linear.___torch_mangle_15952.Linear = prim::GetAttr[name="dense"](%1607)
  %1609 : Tensor = prim::GetAttr[name="bias"](%1608)
  %1610 : Tensor = prim::GetAttr[name="weight"](%1608)
  %1611 : Float(128:1, 512:128) = aten::t(%1610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.113 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.145, %1611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.146 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.113, %1609, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.147 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1615 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15955.NoNorm = prim::GetAttr[name="LayerNorm"](%1606)
  %1616 : __torch__.torch.nn.modules.linear.___torch_mangle_15954.Linear = prim::GetAttr[name="dense"](%1606)
  %1617 : Tensor = prim::GetAttr[name="bias"](%1616)
  %1618 : Tensor = prim::GetAttr[name="weight"](%1616)
  %1619 : Float(512:1, 128:512) = aten::t(%1618), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.114 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.147, %1619), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.114, %1617, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.61 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.37, %input.145, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1623 : Tensor = prim::GetAttr[name="bias"](%1615)
  %1624 : Tensor = prim::GetAttr[name="weight"](%1615)
  %1625 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.61, %1624), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.148 : Float(17:1664, 13:128, 128:1) = aten::add(%1625, %1623, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1627 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15962.FFNOutput = prim::GetAttr[name="output"](%1510)
  %1628 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15959.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1510)
  %1629 : __torch__.torch.nn.modules.linear.___torch_mangle_15958.Linear = prim::GetAttr[name="dense"](%1628)
  %1630 : Tensor = prim::GetAttr[name="bias"](%1629)
  %1631 : Tensor = prim::GetAttr[name="weight"](%1629)
  %1632 : Float(128:1, 512:128) = aten::t(%1631), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.115 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.148, %1632), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.149 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.115, %1630, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.150 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1636 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15961.NoNorm = prim::GetAttr[name="LayerNorm"](%1627)
  %1637 : __torch__.torch.nn.modules.linear.___torch_mangle_15960.Linear = prim::GetAttr[name="dense"](%1627)
  %1638 : Tensor = prim::GetAttr[name="bias"](%1637)
  %1639 : Tensor = prim::GetAttr[name="weight"](%1637)
  %1640 : Float(512:1, 128:512) = aten::t(%1639), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.116 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.150, %1640), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.38 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.116, %1638, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.62 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.38, %input.148, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1644 : Tensor = prim::GetAttr[name="bias"](%1636)
  %1645 : Tensor = prim::GetAttr[name="weight"](%1636)
  %1646 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.62, %1645), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.151 : Float(17:1664, 13:128, 128:1) = aten::add(%1646, %1644, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1648 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15968.FFNOutput = prim::GetAttr[name="output"](%1508)
  %1649 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15965.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1508)
  %1650 : __torch__.torch.nn.modules.linear.___torch_mangle_15964.Linear = prim::GetAttr[name="dense"](%1649)
  %1651 : Tensor = prim::GetAttr[name="bias"](%1650)
  %1652 : Tensor = prim::GetAttr[name="weight"](%1650)
  %1653 : Float(128:1, 512:128) = aten::t(%1652), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.117 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.151, %1653), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.152 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.117, %1651, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.153 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1657 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15967.NoNorm = prim::GetAttr[name="LayerNorm"](%1648)
  %1658 : __torch__.torch.nn.modules.linear.___torch_mangle_15966.Linear = prim::GetAttr[name="dense"](%1648)
  %1659 : Tensor = prim::GetAttr[name="bias"](%1658)
  %1660 : Tensor = prim::GetAttr[name="weight"](%1658)
  %1661 : Float(512:1, 128:512) = aten::t(%1660), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.118 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.153, %1661), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.118, %1659, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.63 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.39, %input.151, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1665 : Tensor = prim::GetAttr[name="bias"](%1657)
  %1666 : Tensor = prim::GetAttr[name="weight"](%1657)
  %1667 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.63, %1666), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.154 : Float(17:1664, 13:128, 128:1) = aten::add(%1667, %1665, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1669 : __torch__.torch.nn.modules.linear.___torch_mangle_15936.Linear = prim::GetAttr[name="dense"](%1506)
  %1670 : Tensor = prim::GetAttr[name="bias"](%1669)
  %1671 : Tensor = prim::GetAttr[name="weight"](%1669)
  %1672 : Float(128:1, 512:128) = aten::t(%1671), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %output.119 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.154, %1672), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %input.155 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.119, %1670, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1678:0
  %input.156 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate # torch/nn/functional.py:1119:0
  %1676 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15943.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1505)
  %1677 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15939.NoNorm = prim::GetAttr[name="LayerNorm"](%1505)
  %1678 : __torch__.torch.nn.modules.linear.___torch_mangle_15938.Linear = prim::GetAttr[name="dense"](%1505)
  %1679 : Tensor = prim::GetAttr[name="bias"](%1678)
  %1680 : Tensor = prim::GetAttr[name="weight"](%1678)
  %1681 : Float(512:1, 128:512) = aten::t(%1680), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %output.120 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.156, %1681), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %layer_output.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.120, %1679, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.64 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.8, %input.154, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output # transformers/modeling_mobilebert.py:405:0
  %1685 : Tensor = prim::GetAttr[name="bias"](%1677)
  %1686 : Tensor = prim::GetAttr[name="weight"](%1677)
  %1687 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.64, %1686), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.157 : Float(17:1664, 13:128, 128:1) = aten::add(%1687, %1685, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1689 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15941.NoNorm = prim::GetAttr[name="LayerNorm"](%1676)
  %1690 : __torch__.torch.nn.modules.linear.___torch_mangle_15940.Linear = prim::GetAttr[name="dense"](%1676)
  %1691 : Tensor = prim::GetAttr[name="bias"](%1690)
  %1692 : Tensor = prim::GetAttr[name="weight"](%1690)
  %1693 : Float(128:1, 512:128) = aten::t(%1692), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.121 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.157, %1693), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.158 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.121, %1691, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.40 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.158, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.65 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.40, %input.140, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1698 : Tensor = prim::GetAttr[name="bias"](%1689)
  %1699 : Tensor = prim::GetAttr[name="weight"](%1689)
  %1700 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.65, %1699), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.159 : Float(17:6656, 13:512, 512:1) = aten::add(%1700, %1698, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1702 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15989.MobileBertOutput = prim::GetAttr[name="output"](%109)
  %1703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15982.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%109)
  %1704 : __torch__.torch.nn.modules.container.___torch_mangle_16015.ModuleList = prim::GetAttr[name="ffn"](%109)
  %1705 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16014.FFNLayer = prim::GetAttr[name="2"](%1704)
  %1706 : __torch__.torch.nn.modules.container.___torch_mangle_16015.ModuleList = prim::GetAttr[name="ffn"](%109)
  %1707 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16008.FFNLayer = prim::GetAttr[name="1"](%1706)
  %1708 : __torch__.torch.nn.modules.container.___torch_mangle_16015.ModuleList = prim::GetAttr[name="ffn"](%109)
  %1709 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16002.FFNLayer = prim::GetAttr[name="0"](%1708)
  %1710 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15980.MobileBertAttention = prim::GetAttr[name="attention"](%109)
  %1711 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15996.Bottleneck = prim::GetAttr[name="bottleneck"](%109)
  %1712 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15995.BottleneckLayer = prim::GetAttr[name="attention"](%1711)
  %1713 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15992.BottleneckLayer = prim::GetAttr[name="input"](%1711)
  %1714 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15991.NoNorm = prim::GetAttr[name="LayerNorm"](%1713)
  %1715 : __torch__.torch.nn.modules.linear.___torch_mangle_15990.Linear = prim::GetAttr[name="dense"](%1713)
  %1716 : Tensor = prim::GetAttr[name="bias"](%1715)
  %1717 : Tensor = prim::GetAttr[name="weight"](%1715)
  %1718 : Float(512:1, 128:512) = aten::t(%1717), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.122 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1718), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.122, %1716, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1721 : Tensor = prim::GetAttr[name="bias"](%1714)
  %1722 : Tensor = prim::GetAttr[name="weight"](%1714)
  %1723 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.66, %1722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.9 : Float(17:1664, 13:128, 128:1) = aten::add(%1723, %1721, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1725 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15994.NoNorm = prim::GetAttr[name="LayerNorm"](%1712)
  %1726 : __torch__.torch.nn.modules.linear.___torch_mangle_15993.Linear = prim::GetAttr[name="dense"](%1712)
  %1727 : Tensor = prim::GetAttr[name="bias"](%1726)
  %1728 : Tensor = prim::GetAttr[name="weight"](%1726)
  %1729 : Float(512:1, 128:512) = aten::t(%1728), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.123 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1729), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.123, %1727, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1732 : Tensor = prim::GetAttr[name="bias"](%1725)
  %1733 : Tensor = prim::GetAttr[name="weight"](%1725)
  %1734 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.67, %1733), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.160 : Float(17:1664, 13:128, 128:1) = aten::add(%1734, %1732, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1736 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.160, %residual_tensor.9)
  %1737 : Float(17:1664, 13:128, 128:1), %1738 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1736)
  %1739 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15979.MobileBertSelfOutput = prim::GetAttr[name="output"](%1710)
  %1740 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15976.MobileBertSelfAttention = prim::GetAttr[name="self"](%1710)
  %1741 : __torch__.torch.nn.modules.linear.___torch_mangle_15974.Linear = prim::GetAttr[name="value"](%1740)
  %1742 : __torch__.torch.nn.modules.linear.___torch_mangle_15973.Linear = prim::GetAttr[name="key"](%1740)
  %1743 : __torch__.torch.nn.modules.linear.___torch_mangle_15972.Linear = prim::GetAttr[name="query"](%1740)
  %1744 : Tensor = prim::GetAttr[name="bias"](%1743)
  %1745 : Tensor = prim::GetAttr[name="weight"](%1743)
  %1746 : Float(128:1, 128:128) = aten::t(%1745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %output.124 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1737, %1746), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %x.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.124, %1744, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1678:0
  %1749 : Tensor = prim::GetAttr[name="bias"](%1742)
  %1750 : Tensor = prim::GetAttr[name="weight"](%1742)
  %1751 : Float(128:1, 128:128) = aten::t(%1750), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %output.125 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1737, %1751), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %x.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.125, %1749, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1678:0
  %1754 : Tensor = prim::GetAttr[name="bias"](%1741)
  %1755 : Tensor = prim::GetAttr[name="weight"](%1741)
  %1756 : Float(512:1, 128:512) = aten::t(%1755), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %output.126 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1756), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %x.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.126, %1754, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1678:0
  %1759 : int = aten::size(%x.49, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1760 : int = aten::size(%x.49, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1761 : int[] = prim::ListConstruct(%1759, %1760, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.50 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.49, %1761), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1763 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %query_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.50, %1763), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1765 : int = aten::size(%x.51, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1766 : int = aten::size(%x.51, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1767 : int[] = prim::ListConstruct(%1765, %1766, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.52 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.51, %1767), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1769 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %key_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.52, %1769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1771 : int = aten::size(%x.53, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1772 : int = aten::size(%x.53, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1773 : int[] = prim::ListConstruct(%1771, %1772, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.54 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.53, %1773), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1775 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %value_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.54, %1775), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1777 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.9, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.9, %1777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.17, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.161 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.18, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.162 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.161, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.162, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.17 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.9, %value_layer.9), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:280:0
  %1784 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %1785 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.17, %1784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1785, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %1787 : int = aten::size(%context_layer.18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1788 : int = aten::size(%context_layer.18, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1789 : int[] = prim::ListConstruct(%1787, %1788, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %input.163 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.18, %1789), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:283:0
  %1791 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15978.NoNorm = prim::GetAttr[name="LayerNorm"](%1739)
  %1792 : __torch__.torch.nn.modules.linear.___torch_mangle_15977.Linear = prim::GetAttr[name="dense"](%1739)
  %1793 : Tensor = prim::GetAttr[name="bias"](%1792)
  %1794 : Tensor = prim::GetAttr[name="weight"](%1792)
  %1795 : Float(128:1, 128:128) = aten::t(%1794), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %output.127 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.163, %1795), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.127, %1793, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.68 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.41, %1738, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output # transformers/modeling_mobilebert.py:301:0
  %1799 : Tensor = prim::GetAttr[name="bias"](%1791)
  %1800 : Tensor = prim::GetAttr[name="weight"](%1791)
  %1801 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.68, %1800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.164 : Float(17:1664, 13:128, 128:1) = aten::add(%1801, %1799, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1803 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16001.FFNOutput = prim::GetAttr[name="output"](%1709)
  %1804 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15998.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1709)
  %1805 : __torch__.torch.nn.modules.linear.___torch_mangle_15997.Linear = prim::GetAttr[name="dense"](%1804)
  %1806 : Tensor = prim::GetAttr[name="bias"](%1805)
  %1807 : Tensor = prim::GetAttr[name="weight"](%1805)
  %1808 : Float(128:1, 512:128) = aten::t(%1807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.128 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.164, %1808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.165 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.128, %1806, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.166 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1812 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16000.NoNorm = prim::GetAttr[name="LayerNorm"](%1803)
  %1813 : __torch__.torch.nn.modules.linear.___torch_mangle_15999.Linear = prim::GetAttr[name="dense"](%1803)
  %1814 : Tensor = prim::GetAttr[name="bias"](%1813)
  %1815 : Tensor = prim::GetAttr[name="weight"](%1813)
  %1816 : Float(512:1, 128:512) = aten::t(%1815), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.129 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.166, %1816), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.129, %1814, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.69 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.42, %input.164, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1820 : Tensor = prim::GetAttr[name="bias"](%1812)
  %1821 : Tensor = prim::GetAttr[name="weight"](%1812)
  %1822 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.69, %1821), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.167 : Float(17:1664, 13:128, 128:1) = aten::add(%1822, %1820, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1824 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16007.FFNOutput = prim::GetAttr[name="output"](%1707)
  %1825 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16004.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1707)
  %1826 : __torch__.torch.nn.modules.linear.___torch_mangle_16003.Linear = prim::GetAttr[name="dense"](%1825)
  %1827 : Tensor = prim::GetAttr[name="bias"](%1826)
  %1828 : Tensor = prim::GetAttr[name="weight"](%1826)
  %1829 : Float(128:1, 512:128) = aten::t(%1828), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.130 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.167, %1829), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.168 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.130, %1827, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.169 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1833 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16006.NoNorm = prim::GetAttr[name="LayerNorm"](%1824)
  %1834 : __torch__.torch.nn.modules.linear.___torch_mangle_16005.Linear = prim::GetAttr[name="dense"](%1824)
  %1835 : Tensor = prim::GetAttr[name="bias"](%1834)
  %1836 : Tensor = prim::GetAttr[name="weight"](%1834)
  %1837 : Float(512:1, 128:512) = aten::t(%1836), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.131 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.169, %1837), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.131, %1835, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.70 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.43, %input.167, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1841 : Tensor = prim::GetAttr[name="bias"](%1833)
  %1842 : Tensor = prim::GetAttr[name="weight"](%1833)
  %1843 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.70, %1842), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.170 : Float(17:1664, 13:128, 128:1) = aten::add(%1843, %1841, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1845 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16013.FFNOutput = prim::GetAttr[name="output"](%1705)
  %1846 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16010.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1705)
  %1847 : __torch__.torch.nn.modules.linear.___torch_mangle_16009.Linear = prim::GetAttr[name="dense"](%1846)
  %1848 : Tensor = prim::GetAttr[name="bias"](%1847)
  %1849 : Tensor = prim::GetAttr[name="weight"](%1847)
  %1850 : Float(128:1, 512:128) = aten::t(%1849), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.132 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.170, %1850), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.171 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.132, %1848, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.172 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1854 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16012.NoNorm = prim::GetAttr[name="LayerNorm"](%1845)
  %1855 : __torch__.torch.nn.modules.linear.___torch_mangle_16011.Linear = prim::GetAttr[name="dense"](%1845)
  %1856 : Tensor = prim::GetAttr[name="bias"](%1855)
  %1857 : Tensor = prim::GetAttr[name="weight"](%1855)
  %1858 : Float(512:1, 128:512) = aten::t(%1857), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.133 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.172, %1858), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.44 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.133, %1856, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.71 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.44, %input.170, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1862 : Tensor = prim::GetAttr[name="bias"](%1854)
  %1863 : Tensor = prim::GetAttr[name="weight"](%1854)
  %1864 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.71, %1863), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.173 : Float(17:1664, 13:128, 128:1) = aten::add(%1864, %1862, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1866 : __torch__.torch.nn.modules.linear.___torch_mangle_15981.Linear = prim::GetAttr[name="dense"](%1703)
  %1867 : Tensor = prim::GetAttr[name="bias"](%1866)
  %1868 : Tensor = prim::GetAttr[name="weight"](%1866)
  %1869 : Float(128:1, 512:128) = aten::t(%1868), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %output.134 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.173, %1869), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %input.174 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.134, %1867, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1678:0
  %input.175 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate # torch/nn/functional.py:1119:0
  %1873 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15988.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1702)
  %1874 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15984.NoNorm = prim::GetAttr[name="LayerNorm"](%1702)
  %1875 : __torch__.torch.nn.modules.linear.___torch_mangle_15983.Linear = prim::GetAttr[name="dense"](%1702)
  %1876 : Tensor = prim::GetAttr[name="bias"](%1875)
  %1877 : Tensor = prim::GetAttr[name="weight"](%1875)
  %1878 : Float(512:1, 128:512) = aten::t(%1877), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %output.135 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.175, %1878), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %layer_output.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.135, %1876, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.72 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.9, %input.173, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output # transformers/modeling_mobilebert.py:405:0
  %1882 : Tensor = prim::GetAttr[name="bias"](%1874)
  %1883 : Tensor = prim::GetAttr[name="weight"](%1874)
  %1884 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.72, %1883), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.176 : Float(17:1664, 13:128, 128:1) = aten::add(%1884, %1882, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1886 : __torch__.transformers.modeling_mobilebert.___torch_mangle_15986.NoNorm = prim::GetAttr[name="LayerNorm"](%1873)
  %1887 : __torch__.torch.nn.modules.linear.___torch_mangle_15985.Linear = prim::GetAttr[name="dense"](%1873)
  %1888 : Tensor = prim::GetAttr[name="bias"](%1887)
  %1889 : Tensor = prim::GetAttr[name="weight"](%1887)
  %1890 : Float(128:1, 512:128) = aten::t(%1889), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.136 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.176, %1890), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.177 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.136, %1888, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.45 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.177, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.73 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.45, %input.159, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1895 : Tensor = prim::GetAttr[name="bias"](%1886)
  %1896 : Tensor = prim::GetAttr[name="weight"](%1886)
  %1897 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.73, %1896), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.178 : Float(17:6656, 13:512, 512:1) = aten::add(%1897, %1895, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1899 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16034.MobileBertOutput = prim::GetAttr[name="output"](%107)
  %1900 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16027.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%107)
  %1901 : __torch__.torch.nn.modules.container.___torch_mangle_16060.ModuleList = prim::GetAttr[name="ffn"](%107)
  %1902 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16059.FFNLayer = prim::GetAttr[name="2"](%1901)
  %1903 : __torch__.torch.nn.modules.container.___torch_mangle_16060.ModuleList = prim::GetAttr[name="ffn"](%107)
  %1904 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16053.FFNLayer = prim::GetAttr[name="1"](%1903)
  %1905 : __torch__.torch.nn.modules.container.___torch_mangle_16060.ModuleList = prim::GetAttr[name="ffn"](%107)
  %1906 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16047.FFNLayer = prim::GetAttr[name="0"](%1905)
  %1907 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16025.MobileBertAttention = prim::GetAttr[name="attention"](%107)
  %1908 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16041.Bottleneck = prim::GetAttr[name="bottleneck"](%107)
  %1909 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16040.BottleneckLayer = prim::GetAttr[name="attention"](%1908)
  %1910 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16037.BottleneckLayer = prim::GetAttr[name="input"](%1908)
  %1911 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16036.NoNorm = prim::GetAttr[name="LayerNorm"](%1910)
  %1912 : __torch__.torch.nn.modules.linear.___torch_mangle_16035.Linear = prim::GetAttr[name="dense"](%1910)
  %1913 : Tensor = prim::GetAttr[name="bias"](%1912)
  %1914 : Tensor = prim::GetAttr[name="weight"](%1912)
  %1915 : Float(512:1, 128:512) = aten::t(%1914), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.137 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1915), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.137, %1913, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1918 : Tensor = prim::GetAttr[name="bias"](%1911)
  %1919 : Tensor = prim::GetAttr[name="weight"](%1911)
  %1920 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.74, %1919), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add(%1920, %1918, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1922 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16039.NoNorm = prim::GetAttr[name="LayerNorm"](%1909)
  %1923 : __torch__.torch.nn.modules.linear.___torch_mangle_16038.Linear = prim::GetAttr[name="dense"](%1909)
  %1924 : Tensor = prim::GetAttr[name="bias"](%1923)
  %1925 : Tensor = prim::GetAttr[name="weight"](%1923)
  %1926 : Float(512:1, 128:512) = aten::t(%1925), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.138 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1926), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.138, %1924, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1929 : Tensor = prim::GetAttr[name="bias"](%1922)
  %1930 : Tensor = prim::GetAttr[name="weight"](%1922)
  %1931 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.75, %1930), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.179 : Float(17:1664, 13:128, 128:1) = aten::add(%1931, %1929, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1933 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.179, %residual_tensor.10)
  %1934 : Float(17:1664, 13:128, 128:1), %1935 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1933)
  %1936 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16024.MobileBertSelfOutput = prim::GetAttr[name="output"](%1907)
  %1937 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16021.MobileBertSelfAttention = prim::GetAttr[name="self"](%1907)
  %1938 : __torch__.torch.nn.modules.linear.___torch_mangle_16019.Linear = prim::GetAttr[name="value"](%1937)
  %1939 : __torch__.torch.nn.modules.linear.___torch_mangle_16018.Linear = prim::GetAttr[name="key"](%1937)
  %1940 : __torch__.torch.nn.modules.linear.___torch_mangle_16017.Linear = prim::GetAttr[name="query"](%1937)
  %1941 : Tensor = prim::GetAttr[name="bias"](%1940)
  %1942 : Tensor = prim::GetAttr[name="weight"](%1940)
  %1943 : Float(128:1, 128:128) = aten::t(%1942), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %output.139 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1934, %1943), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %x.55 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.139, %1941, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1678:0
  %1946 : Tensor = prim::GetAttr[name="bias"](%1939)
  %1947 : Tensor = prim::GetAttr[name="weight"](%1939)
  %1948 : Float(128:1, 128:128) = aten::t(%1947), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %output.140 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1934, %1948), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %x.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.140, %1946, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1678:0
  %1951 : Tensor = prim::GetAttr[name="bias"](%1938)
  %1952 : Tensor = prim::GetAttr[name="weight"](%1938)
  %1953 : Float(512:1, 128:512) = aten::t(%1952), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %output.141 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1953), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %x.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.141, %1951, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1678:0
  %1956 : int = aten::size(%x.55, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1957 : int = aten::size(%x.55, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1958 : int[] = prim::ListConstruct(%1956, %1957, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.56 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.55, %1958), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1960 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %query_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.56, %1960), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1962 : int = aten::size(%x.57, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1963 : int = aten::size(%x.57, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1964 : int[] = prim::ListConstruct(%1962, %1963, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.58 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.57, %1964), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1966 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %key_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.58, %1966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1968 : int = aten::size(%x.59, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1969 : int = aten::size(%x.59, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1970 : int[] = prim::ListConstruct(%1968, %1969, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.60 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.59, %1970), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1972 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %value_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.60, %1972), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1974 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.10, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.10, %1974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.19, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.180 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.20, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.181 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.180, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.181, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.19 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.10, %value_layer.10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:280:0
  %1981 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %1982 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.19, %1981), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1982, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %1984 : int = aten::size(%context_layer.20, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1985 : int = aten::size(%context_layer.20, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1986 : int[] = prim::ListConstruct(%1984, %1985, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %input.182 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.20, %1986), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:283:0
  %1988 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16023.NoNorm = prim::GetAttr[name="LayerNorm"](%1936)
  %1989 : __torch__.torch.nn.modules.linear.___torch_mangle_16022.Linear = prim::GetAttr[name="dense"](%1936)
  %1990 : Tensor = prim::GetAttr[name="bias"](%1989)
  %1991 : Tensor = prim::GetAttr[name="weight"](%1989)
  %1992 : Float(128:1, 128:128) = aten::t(%1991), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %output.142 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.182, %1992), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.46 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.142, %1990, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.76 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.46, %1935, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output # transformers/modeling_mobilebert.py:301:0
  %1996 : Tensor = prim::GetAttr[name="bias"](%1988)
  %1997 : Tensor = prim::GetAttr[name="weight"](%1988)
  %1998 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.76, %1997), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.183 : Float(17:1664, 13:128, 128:1) = aten::add(%1998, %1996, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2000 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16046.FFNOutput = prim::GetAttr[name="output"](%1906)
  %2001 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16043.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1906)
  %2002 : __torch__.torch.nn.modules.linear.___torch_mangle_16042.Linear = prim::GetAttr[name="dense"](%2001)
  %2003 : Tensor = prim::GetAttr[name="bias"](%2002)
  %2004 : Tensor = prim::GetAttr[name="weight"](%2002)
  %2005 : Float(128:1, 512:128) = aten::t(%2004), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.143 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.183, %2005), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.184 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.143, %2003, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.185 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2009 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16045.NoNorm = prim::GetAttr[name="LayerNorm"](%2000)
  %2010 : __torch__.torch.nn.modules.linear.___torch_mangle_16044.Linear = prim::GetAttr[name="dense"](%2000)
  %2011 : Tensor = prim::GetAttr[name="bias"](%2010)
  %2012 : Tensor = prim::GetAttr[name="weight"](%2010)
  %2013 : Float(512:1, 128:512) = aten::t(%2012), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.144 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.185, %2013), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.144, %2011, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.77 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.47, %input.183, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2017 : Tensor = prim::GetAttr[name="bias"](%2009)
  %2018 : Tensor = prim::GetAttr[name="weight"](%2009)
  %2019 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.77, %2018), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.186 : Float(17:1664, 13:128, 128:1) = aten::add(%2019, %2017, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2021 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16052.FFNOutput = prim::GetAttr[name="output"](%1904)
  %2022 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16049.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1904)
  %2023 : __torch__.torch.nn.modules.linear.___torch_mangle_16048.Linear = prim::GetAttr[name="dense"](%2022)
  %2024 : Tensor = prim::GetAttr[name="bias"](%2023)
  %2025 : Tensor = prim::GetAttr[name="weight"](%2023)
  %2026 : Float(128:1, 512:128) = aten::t(%2025), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.145 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.186, %2026), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.187 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.145, %2024, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.188 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2030 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16051.NoNorm = prim::GetAttr[name="LayerNorm"](%2021)
  %2031 : __torch__.torch.nn.modules.linear.___torch_mangle_16050.Linear = prim::GetAttr[name="dense"](%2021)
  %2032 : Tensor = prim::GetAttr[name="bias"](%2031)
  %2033 : Tensor = prim::GetAttr[name="weight"](%2031)
  %2034 : Float(512:1, 128:512) = aten::t(%2033), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.146 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.188, %2034), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.48 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.146, %2032, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.78 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.48, %input.186, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2038 : Tensor = prim::GetAttr[name="bias"](%2030)
  %2039 : Tensor = prim::GetAttr[name="weight"](%2030)
  %2040 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.78, %2039), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.189 : Float(17:1664, 13:128, 128:1) = aten::add(%2040, %2038, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2042 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16058.FFNOutput = prim::GetAttr[name="output"](%1902)
  %2043 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16055.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1902)
  %2044 : __torch__.torch.nn.modules.linear.___torch_mangle_16054.Linear = prim::GetAttr[name="dense"](%2043)
  %2045 : Tensor = prim::GetAttr[name="bias"](%2044)
  %2046 : Tensor = prim::GetAttr[name="weight"](%2044)
  %2047 : Float(128:1, 512:128) = aten::t(%2046), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.147 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.189, %2047), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.190 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.147, %2045, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.191 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2051 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16057.NoNorm = prim::GetAttr[name="LayerNorm"](%2042)
  %2052 : __torch__.torch.nn.modules.linear.___torch_mangle_16056.Linear = prim::GetAttr[name="dense"](%2042)
  %2053 : Tensor = prim::GetAttr[name="bias"](%2052)
  %2054 : Tensor = prim::GetAttr[name="weight"](%2052)
  %2055 : Float(512:1, 128:512) = aten::t(%2054), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.148 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.191, %2055), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.148, %2053, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.79 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.49, %input.189, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2059 : Tensor = prim::GetAttr[name="bias"](%2051)
  %2060 : Tensor = prim::GetAttr[name="weight"](%2051)
  %2061 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.79, %2060), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.192 : Float(17:1664, 13:128, 128:1) = aten::add(%2061, %2059, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2063 : __torch__.torch.nn.modules.linear.___torch_mangle_16026.Linear = prim::GetAttr[name="dense"](%1900)
  %2064 : Tensor = prim::GetAttr[name="bias"](%2063)
  %2065 : Tensor = prim::GetAttr[name="weight"](%2063)
  %2066 : Float(128:1, 512:128) = aten::t(%2065), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %output.149 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.192, %2066), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %input.193 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.149, %2064, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1678:0
  %input.194 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate # torch/nn/functional.py:1119:0
  %2070 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16033.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1899)
  %2071 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16029.NoNorm = prim::GetAttr[name="LayerNorm"](%1899)
  %2072 : __torch__.torch.nn.modules.linear.___torch_mangle_16028.Linear = prim::GetAttr[name="dense"](%1899)
  %2073 : Tensor = prim::GetAttr[name="bias"](%2072)
  %2074 : Tensor = prim::GetAttr[name="weight"](%2072)
  %2075 : Float(512:1, 128:512) = aten::t(%2074), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %output.150 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.194, %2075), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %layer_output.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.150, %2073, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.80 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.10, %input.192, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output # transformers/modeling_mobilebert.py:405:0
  %2079 : Tensor = prim::GetAttr[name="bias"](%2071)
  %2080 : Tensor = prim::GetAttr[name="weight"](%2071)
  %2081 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.80, %2080), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.195 : Float(17:1664, 13:128, 128:1) = aten::add(%2081, %2079, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2083 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16031.NoNorm = prim::GetAttr[name="LayerNorm"](%2070)
  %2084 : __torch__.torch.nn.modules.linear.___torch_mangle_16030.Linear = prim::GetAttr[name="dense"](%2070)
  %2085 : Tensor = prim::GetAttr[name="bias"](%2084)
  %2086 : Tensor = prim::GetAttr[name="weight"](%2084)
  %2087 : Float(128:1, 512:128) = aten::t(%2086), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.151 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.195, %2087), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.196 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.151, %2085, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.50 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.196, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.81 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.50, %input.178, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2092 : Tensor = prim::GetAttr[name="bias"](%2083)
  %2093 : Tensor = prim::GetAttr[name="weight"](%2083)
  %2094 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.81, %2093), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.197 : Float(17:6656, 13:512, 512:1) = aten::add(%2094, %2092, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2096 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16079.MobileBertOutput = prim::GetAttr[name="output"](%105)
  %2097 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16072.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%105)
  %2098 : __torch__.torch.nn.modules.container.___torch_mangle_16105.ModuleList = prim::GetAttr[name="ffn"](%105)
  %2099 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16104.FFNLayer = prim::GetAttr[name="2"](%2098)
  %2100 : __torch__.torch.nn.modules.container.___torch_mangle_16105.ModuleList = prim::GetAttr[name="ffn"](%105)
  %2101 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16098.FFNLayer = prim::GetAttr[name="1"](%2100)
  %2102 : __torch__.torch.nn.modules.container.___torch_mangle_16105.ModuleList = prim::GetAttr[name="ffn"](%105)
  %2103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16092.FFNLayer = prim::GetAttr[name="0"](%2102)
  %2104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16070.MobileBertAttention = prim::GetAttr[name="attention"](%105)
  %2105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16086.Bottleneck = prim::GetAttr[name="bottleneck"](%105)
  %2106 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16085.BottleneckLayer = prim::GetAttr[name="attention"](%2105)
  %2107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16082.BottleneckLayer = prim::GetAttr[name="input"](%2105)
  %2108 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16081.NoNorm = prim::GetAttr[name="LayerNorm"](%2107)
  %2109 : __torch__.torch.nn.modules.linear.___torch_mangle_16080.Linear = prim::GetAttr[name="dense"](%2107)
  %2110 : Tensor = prim::GetAttr[name="bias"](%2109)
  %2111 : Tensor = prim::GetAttr[name="weight"](%2109)
  %2112 : Float(512:1, 128:512) = aten::t(%2111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.152 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2112), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.152, %2110, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2115 : Tensor = prim::GetAttr[name="bias"](%2108)
  %2116 : Tensor = prim::GetAttr[name="weight"](%2108)
  %2117 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.82, %2116), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add(%2117, %2115, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16084.NoNorm = prim::GetAttr[name="LayerNorm"](%2106)
  %2120 : __torch__.torch.nn.modules.linear.___torch_mangle_16083.Linear = prim::GetAttr[name="dense"](%2106)
  %2121 : Tensor = prim::GetAttr[name="bias"](%2120)
  %2122 : Tensor = prim::GetAttr[name="weight"](%2120)
  %2123 : Float(512:1, 128:512) = aten::t(%2122), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.153 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2123), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.153, %2121, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2126 : Tensor = prim::GetAttr[name="bias"](%2119)
  %2127 : Tensor = prim::GetAttr[name="weight"](%2119)
  %2128 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.83, %2127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.198 : Float(17:1664, 13:128, 128:1) = aten::add(%2128, %2126, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2130 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.198, %residual_tensor.11)
  %2131 : Float(17:1664, 13:128, 128:1), %2132 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2130)
  %2133 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16069.MobileBertSelfOutput = prim::GetAttr[name="output"](%2104)
  %2134 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16066.MobileBertSelfAttention = prim::GetAttr[name="self"](%2104)
  %2135 : __torch__.torch.nn.modules.linear.___torch_mangle_16064.Linear = prim::GetAttr[name="value"](%2134)
  %2136 : __torch__.torch.nn.modules.linear.___torch_mangle_16063.Linear = prim::GetAttr[name="key"](%2134)
  %2137 : __torch__.torch.nn.modules.linear.___torch_mangle_16062.Linear = prim::GetAttr[name="query"](%2134)
  %2138 : Tensor = prim::GetAttr[name="bias"](%2137)
  %2139 : Tensor = prim::GetAttr[name="weight"](%2137)
  %2140 : Float(128:1, 128:128) = aten::t(%2139), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %output.154 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2131, %2140), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %x.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.154, %2138, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1678:0
  %2143 : Tensor = prim::GetAttr[name="bias"](%2136)
  %2144 : Tensor = prim::GetAttr[name="weight"](%2136)
  %2145 : Float(128:1, 128:128) = aten::t(%2144), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %output.155 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2131, %2145), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %x.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.155, %2143, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1678:0
  %2148 : Tensor = prim::GetAttr[name="bias"](%2135)
  %2149 : Tensor = prim::GetAttr[name="weight"](%2135)
  %2150 : Float(512:1, 128:512) = aten::t(%2149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %output.156 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2150), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %x.65 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.156, %2148, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1678:0
  %2153 : int = aten::size(%x.61, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2154 : int = aten::size(%x.61, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2155 : int[] = prim::ListConstruct(%2153, %2154, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.62 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.61, %2155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2157 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %query_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.62, %2157), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2159 : int = aten::size(%x.63, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2160 : int = aten::size(%x.63, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2161 : int[] = prim::ListConstruct(%2159, %2160, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.64 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.63, %2161), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2163 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %key_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.64, %2163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2165 : int = aten::size(%x.65, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2166 : int = aten::size(%x.65, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2167 : int[] = prim::ListConstruct(%2165, %2166, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.66 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.65, %2167), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2169 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %value_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.66, %2169), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2171 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.11, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.11, %2171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.21, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.199 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.22, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.200 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.199, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.200, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.21 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.11, %value_layer.11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:280:0
  %2178 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %2179 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.21, %2178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2179, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %2181 : int = aten::size(%context_layer.22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2182 : int = aten::size(%context_layer.22, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2183 : int[] = prim::ListConstruct(%2181, %2182, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %input.201 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.22, %2183), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:283:0
  %2185 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16068.NoNorm = prim::GetAttr[name="LayerNorm"](%2133)
  %2186 : __torch__.torch.nn.modules.linear.___torch_mangle_16067.Linear = prim::GetAttr[name="dense"](%2133)
  %2187 : Tensor = prim::GetAttr[name="bias"](%2186)
  %2188 : Tensor = prim::GetAttr[name="weight"](%2186)
  %2189 : Float(128:1, 128:128) = aten::t(%2188), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %output.157 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.201, %2189), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.157, %2187, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.84 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.51, %2132, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output # transformers/modeling_mobilebert.py:301:0
  %2193 : Tensor = prim::GetAttr[name="bias"](%2185)
  %2194 : Tensor = prim::GetAttr[name="weight"](%2185)
  %2195 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.84, %2194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.202 : Float(17:1664, 13:128, 128:1) = aten::add(%2195, %2193, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2197 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16091.FFNOutput = prim::GetAttr[name="output"](%2103)
  %2198 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16088.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2103)
  %2199 : __torch__.torch.nn.modules.linear.___torch_mangle_16087.Linear = prim::GetAttr[name="dense"](%2198)
  %2200 : Tensor = prim::GetAttr[name="bias"](%2199)
  %2201 : Tensor = prim::GetAttr[name="weight"](%2199)
  %2202 : Float(128:1, 512:128) = aten::t(%2201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.158 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.202, %2202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.203 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.158, %2200, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.204 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2206 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16090.NoNorm = prim::GetAttr[name="LayerNorm"](%2197)
  %2207 : __torch__.torch.nn.modules.linear.___torch_mangle_16089.Linear = prim::GetAttr[name="dense"](%2197)
  %2208 : Tensor = prim::GetAttr[name="bias"](%2207)
  %2209 : Tensor = prim::GetAttr[name="weight"](%2207)
  %2210 : Float(512:1, 128:512) = aten::t(%2209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.159 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.204, %2210), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.52 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.159, %2208, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.85 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.52, %input.202, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2214 : Tensor = prim::GetAttr[name="bias"](%2206)
  %2215 : Tensor = prim::GetAttr[name="weight"](%2206)
  %2216 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.85, %2215), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.205 : Float(17:1664, 13:128, 128:1) = aten::add(%2216, %2214, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2218 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16097.FFNOutput = prim::GetAttr[name="output"](%2101)
  %2219 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16094.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2101)
  %2220 : __torch__.torch.nn.modules.linear.___torch_mangle_16093.Linear = prim::GetAttr[name="dense"](%2219)
  %2221 : Tensor = prim::GetAttr[name="bias"](%2220)
  %2222 : Tensor = prim::GetAttr[name="weight"](%2220)
  %2223 : Float(128:1, 512:128) = aten::t(%2222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.160 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.205, %2223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.206 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.160, %2221, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.207 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2227 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16096.NoNorm = prim::GetAttr[name="LayerNorm"](%2218)
  %2228 : __torch__.torch.nn.modules.linear.___torch_mangle_16095.Linear = prim::GetAttr[name="dense"](%2218)
  %2229 : Tensor = prim::GetAttr[name="bias"](%2228)
  %2230 : Tensor = prim::GetAttr[name="weight"](%2228)
  %2231 : Float(512:1, 128:512) = aten::t(%2230), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.161 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.207, %2231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.161, %2229, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.86 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.53, %input.205, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2235 : Tensor = prim::GetAttr[name="bias"](%2227)
  %2236 : Tensor = prim::GetAttr[name="weight"](%2227)
  %2237 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.86, %2236), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.208 : Float(17:1664, 13:128, 128:1) = aten::add(%2237, %2235, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2239 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16103.FFNOutput = prim::GetAttr[name="output"](%2099)
  %2240 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16100.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2099)
  %2241 : __torch__.torch.nn.modules.linear.___torch_mangle_16099.Linear = prim::GetAttr[name="dense"](%2240)
  %2242 : Tensor = prim::GetAttr[name="bias"](%2241)
  %2243 : Tensor = prim::GetAttr[name="weight"](%2241)
  %2244 : Float(128:1, 512:128) = aten::t(%2243), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.162 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.208, %2244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.209 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.162, %2242, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.210 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2248 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16102.NoNorm = prim::GetAttr[name="LayerNorm"](%2239)
  %2249 : __torch__.torch.nn.modules.linear.___torch_mangle_16101.Linear = prim::GetAttr[name="dense"](%2239)
  %2250 : Tensor = prim::GetAttr[name="bias"](%2249)
  %2251 : Tensor = prim::GetAttr[name="weight"](%2249)
  %2252 : Float(512:1, 128:512) = aten::t(%2251), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.163 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.210, %2252), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.54 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.163, %2250, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.87 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.54, %input.208, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2256 : Tensor = prim::GetAttr[name="bias"](%2248)
  %2257 : Tensor = prim::GetAttr[name="weight"](%2248)
  %2258 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.87, %2257), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.211 : Float(17:1664, 13:128, 128:1) = aten::add(%2258, %2256, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2260 : __torch__.torch.nn.modules.linear.___torch_mangle_16071.Linear = prim::GetAttr[name="dense"](%2097)
  %2261 : Tensor = prim::GetAttr[name="bias"](%2260)
  %2262 : Tensor = prim::GetAttr[name="weight"](%2260)
  %2263 : Float(128:1, 512:128) = aten::t(%2262), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %output.164 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.211, %2263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %input.212 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.164, %2261, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1678:0
  %input.213 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate # torch/nn/functional.py:1119:0
  %2267 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16078.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2096)
  %2268 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16074.NoNorm = prim::GetAttr[name="LayerNorm"](%2096)
  %2269 : __torch__.torch.nn.modules.linear.___torch_mangle_16073.Linear = prim::GetAttr[name="dense"](%2096)
  %2270 : Tensor = prim::GetAttr[name="bias"](%2269)
  %2271 : Tensor = prim::GetAttr[name="weight"](%2269)
  %2272 : Float(512:1, 128:512) = aten::t(%2271), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %output.165 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.213, %2272), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %layer_output.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.165, %2270, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.88 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.11, %input.211, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output # transformers/modeling_mobilebert.py:405:0
  %2276 : Tensor = prim::GetAttr[name="bias"](%2268)
  %2277 : Tensor = prim::GetAttr[name="weight"](%2268)
  %2278 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.88, %2277), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.214 : Float(17:1664, 13:128, 128:1) = aten::add(%2278, %2276, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2280 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16076.NoNorm = prim::GetAttr[name="LayerNorm"](%2267)
  %2281 : __torch__.torch.nn.modules.linear.___torch_mangle_16075.Linear = prim::GetAttr[name="dense"](%2267)
  %2282 : Tensor = prim::GetAttr[name="bias"](%2281)
  %2283 : Tensor = prim::GetAttr[name="weight"](%2281)
  %2284 : Float(128:1, 512:128) = aten::t(%2283), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.166 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.214, %2284), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.215 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.166, %2282, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.55 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.215, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.89 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.55, %input.197, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2289 : Tensor = prim::GetAttr[name="bias"](%2280)
  %2290 : Tensor = prim::GetAttr[name="weight"](%2280)
  %2291 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.89, %2290), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.216 : Float(17:6656, 13:512, 512:1) = aten::add(%2291, %2289, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2293 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16124.MobileBertOutput = prim::GetAttr[name="output"](%103)
  %2294 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16117.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%103)
  %2295 : __torch__.torch.nn.modules.container.___torch_mangle_16150.ModuleList = prim::GetAttr[name="ffn"](%103)
  %2296 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16149.FFNLayer = prim::GetAttr[name="2"](%2295)
  %2297 : __torch__.torch.nn.modules.container.___torch_mangle_16150.ModuleList = prim::GetAttr[name="ffn"](%103)
  %2298 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16143.FFNLayer = prim::GetAttr[name="1"](%2297)
  %2299 : __torch__.torch.nn.modules.container.___torch_mangle_16150.ModuleList = prim::GetAttr[name="ffn"](%103)
  %2300 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16137.FFNLayer = prim::GetAttr[name="0"](%2299)
  %2301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16115.MobileBertAttention = prim::GetAttr[name="attention"](%103)
  %2302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16131.Bottleneck = prim::GetAttr[name="bottleneck"](%103)
  %2303 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16130.BottleneckLayer = prim::GetAttr[name="attention"](%2302)
  %2304 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16127.BottleneckLayer = prim::GetAttr[name="input"](%2302)
  %2305 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16126.NoNorm = prim::GetAttr[name="LayerNorm"](%2304)
  %2306 : __torch__.torch.nn.modules.linear.___torch_mangle_16125.Linear = prim::GetAttr[name="dense"](%2304)
  %2307 : Tensor = prim::GetAttr[name="bias"](%2306)
  %2308 : Tensor = prim::GetAttr[name="weight"](%2306)
  %2309 : Float(512:1, 128:512) = aten::t(%2308), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.167 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2309), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.90 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.167, %2307, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2312 : Tensor = prim::GetAttr[name="bias"](%2305)
  %2313 : Tensor = prim::GetAttr[name="weight"](%2305)
  %2314 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.90, %2313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%2314, %2312, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2316 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16129.NoNorm = prim::GetAttr[name="LayerNorm"](%2303)
  %2317 : __torch__.torch.nn.modules.linear.___torch_mangle_16128.Linear = prim::GetAttr[name="dense"](%2303)
  %2318 : Tensor = prim::GetAttr[name="bias"](%2317)
  %2319 : Tensor = prim::GetAttr[name="weight"](%2317)
  %2320 : Float(512:1, 128:512) = aten::t(%2319), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.168 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.168, %2318, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2323 : Tensor = prim::GetAttr[name="bias"](%2316)
  %2324 : Tensor = prim::GetAttr[name="weight"](%2316)
  %2325 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.91, %2324), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.217 : Float(17:1664, 13:128, 128:1) = aten::add(%2325, %2323, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2327 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.217, %residual_tensor.12)
  %2328 : Float(17:1664, 13:128, 128:1), %2329 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2327)
  %2330 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16114.MobileBertSelfOutput = prim::GetAttr[name="output"](%2301)
  %2331 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16111.MobileBertSelfAttention = prim::GetAttr[name="self"](%2301)
  %2332 : __torch__.torch.nn.modules.linear.___torch_mangle_16109.Linear = prim::GetAttr[name="value"](%2331)
  %2333 : __torch__.torch.nn.modules.linear.___torch_mangle_16108.Linear = prim::GetAttr[name="key"](%2331)
  %2334 : __torch__.torch.nn.modules.linear.___torch_mangle_16107.Linear = prim::GetAttr[name="query"](%2331)
  %2335 : Tensor = prim::GetAttr[name="bias"](%2334)
  %2336 : Tensor = prim::GetAttr[name="weight"](%2334)
  %2337 : Float(128:1, 128:128) = aten::t(%2336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %output.169 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2328, %2337), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %x.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.169, %2335, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1678:0
  %2340 : Tensor = prim::GetAttr[name="bias"](%2333)
  %2341 : Tensor = prim::GetAttr[name="weight"](%2333)
  %2342 : Float(128:1, 128:128) = aten::t(%2341), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %output.170 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2328, %2342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %x.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.170, %2340, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1678:0
  %2345 : Tensor = prim::GetAttr[name="bias"](%2332)
  %2346 : Tensor = prim::GetAttr[name="weight"](%2332)
  %2347 : Float(512:1, 128:512) = aten::t(%2346), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %output.171 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2347), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %x.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.171, %2345, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1678:0
  %2350 : int = aten::size(%x.67, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2351 : int = aten::size(%x.67, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2352 : int[] = prim::ListConstruct(%2350, %2351, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.68 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.67, %2352), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2354 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %query_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.68, %2354), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2356 : int = aten::size(%x.69, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2357 : int = aten::size(%x.69, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2358 : int[] = prim::ListConstruct(%2356, %2357, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.70 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.69, %2358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2360 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %key_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.70, %2360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2362 : int = aten::size(%x.71, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2363 : int = aten::size(%x.71, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2364 : int[] = prim::ListConstruct(%2362, %2363, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.72 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.71, %2364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2366 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %value_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.72, %2366), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2368 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.12, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.12, %2368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.24 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.23, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.218 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.24, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.219 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.218, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.219, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.23 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.12, %value_layer.12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:280:0
  %2375 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %2376 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.23, %2375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2376, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %2378 : int = aten::size(%context_layer.24, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2379 : int = aten::size(%context_layer.24, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2380 : int[] = prim::ListConstruct(%2378, %2379, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %input.220 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.24, %2380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:283:0
  %2382 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16113.NoNorm = prim::GetAttr[name="LayerNorm"](%2330)
  %2383 : __torch__.torch.nn.modules.linear.___torch_mangle_16112.Linear = prim::GetAttr[name="dense"](%2330)
  %2384 : Tensor = prim::GetAttr[name="bias"](%2383)
  %2385 : Tensor = prim::GetAttr[name="weight"](%2383)
  %2386 : Float(128:1, 128:128) = aten::t(%2385), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %output.172 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.220, %2386), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.56 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.172, %2384, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.92 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.56, %2329, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output # transformers/modeling_mobilebert.py:301:0
  %2390 : Tensor = prim::GetAttr[name="bias"](%2382)
  %2391 : Tensor = prim::GetAttr[name="weight"](%2382)
  %2392 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.92, %2391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.221 : Float(17:1664, 13:128, 128:1) = aten::add(%2392, %2390, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2394 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16136.FFNOutput = prim::GetAttr[name="output"](%2300)
  %2395 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16133.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2300)
  %2396 : __torch__.torch.nn.modules.linear.___torch_mangle_16132.Linear = prim::GetAttr[name="dense"](%2395)
  %2397 : Tensor = prim::GetAttr[name="bias"](%2396)
  %2398 : Tensor = prim::GetAttr[name="weight"](%2396)
  %2399 : Float(128:1, 512:128) = aten::t(%2398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.173 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.221, %2399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.222 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.173, %2397, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.223 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2403 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16135.NoNorm = prim::GetAttr[name="LayerNorm"](%2394)
  %2404 : __torch__.torch.nn.modules.linear.___torch_mangle_16134.Linear = prim::GetAttr[name="dense"](%2394)
  %2405 : Tensor = prim::GetAttr[name="bias"](%2404)
  %2406 : Tensor = prim::GetAttr[name="weight"](%2404)
  %2407 : Float(512:1, 128:512) = aten::t(%2406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.174 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.223, %2407), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.174, %2405, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.93 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.57, %input.221, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2411 : Tensor = prim::GetAttr[name="bias"](%2403)
  %2412 : Tensor = prim::GetAttr[name="weight"](%2403)
  %2413 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.93, %2412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.224 : Float(17:1664, 13:128, 128:1) = aten::add(%2413, %2411, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2415 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16142.FFNOutput = prim::GetAttr[name="output"](%2298)
  %2416 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16139.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2298)
  %2417 : __torch__.torch.nn.modules.linear.___torch_mangle_16138.Linear = prim::GetAttr[name="dense"](%2416)
  %2418 : Tensor = prim::GetAttr[name="bias"](%2417)
  %2419 : Tensor = prim::GetAttr[name="weight"](%2417)
  %2420 : Float(128:1, 512:128) = aten::t(%2419), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.175 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.224, %2420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.225 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.175, %2418, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.226 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2424 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16141.NoNorm = prim::GetAttr[name="LayerNorm"](%2415)
  %2425 : __torch__.torch.nn.modules.linear.___torch_mangle_16140.Linear = prim::GetAttr[name="dense"](%2415)
  %2426 : Tensor = prim::GetAttr[name="bias"](%2425)
  %2427 : Tensor = prim::GetAttr[name="weight"](%2425)
  %2428 : Float(512:1, 128:512) = aten::t(%2427), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.176 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.226, %2428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.176, %2426, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.94 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.58, %input.224, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2432 : Tensor = prim::GetAttr[name="bias"](%2424)
  %2433 : Tensor = prim::GetAttr[name="weight"](%2424)
  %2434 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.94, %2433), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.227 : Float(17:1664, 13:128, 128:1) = aten::add(%2434, %2432, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2436 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16148.FFNOutput = prim::GetAttr[name="output"](%2296)
  %2437 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16145.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2296)
  %2438 : __torch__.torch.nn.modules.linear.___torch_mangle_16144.Linear = prim::GetAttr[name="dense"](%2437)
  %2439 : Tensor = prim::GetAttr[name="bias"](%2438)
  %2440 : Tensor = prim::GetAttr[name="weight"](%2438)
  %2441 : Float(128:1, 512:128) = aten::t(%2440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.177 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.227, %2441), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.228 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.177, %2439, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.229 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2445 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16147.NoNorm = prim::GetAttr[name="LayerNorm"](%2436)
  %2446 : __torch__.torch.nn.modules.linear.___torch_mangle_16146.Linear = prim::GetAttr[name="dense"](%2436)
  %2447 : Tensor = prim::GetAttr[name="bias"](%2446)
  %2448 : Tensor = prim::GetAttr[name="weight"](%2446)
  %2449 : Float(512:1, 128:512) = aten::t(%2448), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.178 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.229, %2449), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.178, %2447, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.95 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.59, %input.227, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2453 : Tensor = prim::GetAttr[name="bias"](%2445)
  %2454 : Tensor = prim::GetAttr[name="weight"](%2445)
  %2455 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.95, %2454), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.230 : Float(17:1664, 13:128, 128:1) = aten::add(%2455, %2453, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2457 : __torch__.torch.nn.modules.linear.___torch_mangle_16116.Linear = prim::GetAttr[name="dense"](%2294)
  %2458 : Tensor = prim::GetAttr[name="bias"](%2457)
  %2459 : Tensor = prim::GetAttr[name="weight"](%2457)
  %2460 : Float(128:1, 512:128) = aten::t(%2459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %output.179 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.230, %2460), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %input.231 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.179, %2458, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1678:0
  %input.232 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate # torch/nn/functional.py:1119:0
  %2464 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16123.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2293)
  %2465 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16119.NoNorm = prim::GetAttr[name="LayerNorm"](%2293)
  %2466 : __torch__.torch.nn.modules.linear.___torch_mangle_16118.Linear = prim::GetAttr[name="dense"](%2293)
  %2467 : Tensor = prim::GetAttr[name="bias"](%2466)
  %2468 : Tensor = prim::GetAttr[name="weight"](%2466)
  %2469 : Float(512:1, 128:512) = aten::t(%2468), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %output.180 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.232, %2469), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %layer_output.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.180, %2467, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.96 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.12, %input.230, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output # transformers/modeling_mobilebert.py:405:0
  %2473 : Tensor = prim::GetAttr[name="bias"](%2465)
  %2474 : Tensor = prim::GetAttr[name="weight"](%2465)
  %2475 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.96, %2474), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.233 : Float(17:1664, 13:128, 128:1) = aten::add(%2475, %2473, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2477 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16121.NoNorm = prim::GetAttr[name="LayerNorm"](%2464)
  %2478 : __torch__.torch.nn.modules.linear.___torch_mangle_16120.Linear = prim::GetAttr[name="dense"](%2464)
  %2479 : Tensor = prim::GetAttr[name="bias"](%2478)
  %2480 : Tensor = prim::GetAttr[name="weight"](%2478)
  %2481 : Float(128:1, 512:128) = aten::t(%2480), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.181 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.233, %2481), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.234 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.181, %2479, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.60 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.234, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.97 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.60, %input.216, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2486 : Tensor = prim::GetAttr[name="bias"](%2477)
  %2487 : Tensor = prim::GetAttr[name="weight"](%2477)
  %2488 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.97, %2487), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.235 : Float(17:6656, 13:512, 512:1) = aten::add(%2488, %2486, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2490 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16169.MobileBertOutput = prim::GetAttr[name="output"](%101)
  %2491 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16162.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%101)
  %2492 : __torch__.torch.nn.modules.container.___torch_mangle_16195.ModuleList = prim::GetAttr[name="ffn"](%101)
  %2493 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16194.FFNLayer = prim::GetAttr[name="2"](%2492)
  %2494 : __torch__.torch.nn.modules.container.___torch_mangle_16195.ModuleList = prim::GetAttr[name="ffn"](%101)
  %2495 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16188.FFNLayer = prim::GetAttr[name="1"](%2494)
  %2496 : __torch__.torch.nn.modules.container.___torch_mangle_16195.ModuleList = prim::GetAttr[name="ffn"](%101)
  %2497 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16182.FFNLayer = prim::GetAttr[name="0"](%2496)
  %2498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16160.MobileBertAttention = prim::GetAttr[name="attention"](%101)
  %2499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16176.Bottleneck = prim::GetAttr[name="bottleneck"](%101)
  %2500 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16175.BottleneckLayer = prim::GetAttr[name="attention"](%2499)
  %2501 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16172.BottleneckLayer = prim::GetAttr[name="input"](%2499)
  %2502 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16171.NoNorm = prim::GetAttr[name="LayerNorm"](%2501)
  %2503 : __torch__.torch.nn.modules.linear.___torch_mangle_16170.Linear = prim::GetAttr[name="dense"](%2501)
  %2504 : Tensor = prim::GetAttr[name="bias"](%2503)
  %2505 : Tensor = prim::GetAttr[name="weight"](%2503)
  %2506 : Float(512:1, 128:512) = aten::t(%2505), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.182 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2506), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.182, %2504, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2509 : Tensor = prim::GetAttr[name="bias"](%2502)
  %2510 : Tensor = prim::GetAttr[name="weight"](%2502)
  %2511 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.98, %2510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%2511, %2509, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2513 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16174.NoNorm = prim::GetAttr[name="LayerNorm"](%2500)
  %2514 : __torch__.torch.nn.modules.linear.___torch_mangle_16173.Linear = prim::GetAttr[name="dense"](%2500)
  %2515 : Tensor = prim::GetAttr[name="bias"](%2514)
  %2516 : Tensor = prim::GetAttr[name="weight"](%2514)
  %2517 : Float(512:1, 128:512) = aten::t(%2516), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.183 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2517), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.183, %2515, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2520 : Tensor = prim::GetAttr[name="bias"](%2513)
  %2521 : Tensor = prim::GetAttr[name="weight"](%2513)
  %2522 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.99, %2521), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.236 : Float(17:1664, 13:128, 128:1) = aten::add(%2522, %2520, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2524 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.236, %residual_tensor.13)
  %2525 : Float(17:1664, 13:128, 128:1), %2526 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2524)
  %2527 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16159.MobileBertSelfOutput = prim::GetAttr[name="output"](%2498)
  %2528 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16156.MobileBertSelfAttention = prim::GetAttr[name="self"](%2498)
  %2529 : __torch__.torch.nn.modules.linear.___torch_mangle_16154.Linear = prim::GetAttr[name="value"](%2528)
  %2530 : __torch__.torch.nn.modules.linear.___torch_mangle_16153.Linear = prim::GetAttr[name="key"](%2528)
  %2531 : __torch__.torch.nn.modules.linear.___torch_mangle_16152.Linear = prim::GetAttr[name="query"](%2528)
  %2532 : Tensor = prim::GetAttr[name="bias"](%2531)
  %2533 : Tensor = prim::GetAttr[name="weight"](%2531)
  %2534 : Float(128:1, 128:128) = aten::t(%2533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %output.184 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2525, %2534), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %x.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.184, %2532, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1678:0
  %2537 : Tensor = prim::GetAttr[name="bias"](%2530)
  %2538 : Tensor = prim::GetAttr[name="weight"](%2530)
  %2539 : Float(128:1, 128:128) = aten::t(%2538), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %output.185 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2525, %2539), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %x.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.185, %2537, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1678:0
  %2542 : Tensor = prim::GetAttr[name="bias"](%2529)
  %2543 : Tensor = prim::GetAttr[name="weight"](%2529)
  %2544 : Float(512:1, 128:512) = aten::t(%2543), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %output.186 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2544), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %x.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.186, %2542, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1678:0
  %2547 : int = aten::size(%x.73, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2548 : int = aten::size(%x.73, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2549 : int[] = prim::ListConstruct(%2547, %2548, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.74 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.73, %2549), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2551 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %query_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.74, %2551), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2553 : int = aten::size(%x.75, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2554 : int = aten::size(%x.75, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2555 : int[] = prim::ListConstruct(%2553, %2554, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.76 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.75, %2555), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2557 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %key_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.76, %2557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2559 : int = aten::size(%x.77, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2560 : int = aten::size(%x.77, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2561 : int[] = prim::ListConstruct(%2559, %2560, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.78 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.77, %2561), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2563 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %value_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.78, %2563), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2565 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.13, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.25 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.13, %2565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.26 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.25, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.237 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.26, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.238 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.237, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.238, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.25 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.13, %value_layer.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:280:0
  %2572 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %2573 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.25, %2572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2573, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %2575 : int = aten::size(%context_layer.26, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2576 : int = aten::size(%context_layer.26, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2577 : int[] = prim::ListConstruct(%2575, %2576, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %input.239 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.26, %2577), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:283:0
  %2579 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16158.NoNorm = prim::GetAttr[name="LayerNorm"](%2527)
  %2580 : __torch__.torch.nn.modules.linear.___torch_mangle_16157.Linear = prim::GetAttr[name="dense"](%2527)
  %2581 : Tensor = prim::GetAttr[name="bias"](%2580)
  %2582 : Tensor = prim::GetAttr[name="weight"](%2580)
  %2583 : Float(128:1, 128:128) = aten::t(%2582), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %output.187 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.239, %2583), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.187, %2581, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.100 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.61, %2526, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output # transformers/modeling_mobilebert.py:301:0
  %2587 : Tensor = prim::GetAttr[name="bias"](%2579)
  %2588 : Tensor = prim::GetAttr[name="weight"](%2579)
  %2589 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.100, %2588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.240 : Float(17:1664, 13:128, 128:1) = aten::add(%2589, %2587, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2591 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16181.FFNOutput = prim::GetAttr[name="output"](%2497)
  %2592 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16178.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2497)
  %2593 : __torch__.torch.nn.modules.linear.___torch_mangle_16177.Linear = prim::GetAttr[name="dense"](%2592)
  %2594 : Tensor = prim::GetAttr[name="bias"](%2593)
  %2595 : Tensor = prim::GetAttr[name="weight"](%2593)
  %2596 : Float(128:1, 512:128) = aten::t(%2595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.188 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.240, %2596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.241 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.188, %2594, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.242 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2600 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16180.NoNorm = prim::GetAttr[name="LayerNorm"](%2591)
  %2601 : __torch__.torch.nn.modules.linear.___torch_mangle_16179.Linear = prim::GetAttr[name="dense"](%2591)
  %2602 : Tensor = prim::GetAttr[name="bias"](%2601)
  %2603 : Tensor = prim::GetAttr[name="weight"](%2601)
  %2604 : Float(512:1, 128:512) = aten::t(%2603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.189 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.242, %2604), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.62 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.189, %2602, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.101 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.62, %input.240, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2608 : Tensor = prim::GetAttr[name="bias"](%2600)
  %2609 : Tensor = prim::GetAttr[name="weight"](%2600)
  %2610 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.101, %2609), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.243 : Float(17:1664, 13:128, 128:1) = aten::add(%2610, %2608, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2612 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16187.FFNOutput = prim::GetAttr[name="output"](%2495)
  %2613 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16184.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2495)
  %2614 : __torch__.torch.nn.modules.linear.___torch_mangle_16183.Linear = prim::GetAttr[name="dense"](%2613)
  %2615 : Tensor = prim::GetAttr[name="bias"](%2614)
  %2616 : Tensor = prim::GetAttr[name="weight"](%2614)
  %2617 : Float(128:1, 512:128) = aten::t(%2616), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.190 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.243, %2617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.244 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.190, %2615, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.245 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2621 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16186.NoNorm = prim::GetAttr[name="LayerNorm"](%2612)
  %2622 : __torch__.torch.nn.modules.linear.___torch_mangle_16185.Linear = prim::GetAttr[name="dense"](%2612)
  %2623 : Tensor = prim::GetAttr[name="bias"](%2622)
  %2624 : Tensor = prim::GetAttr[name="weight"](%2622)
  %2625 : Float(512:1, 128:512) = aten::t(%2624), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.191 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.245, %2625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.191, %2623, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.102 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.63, %input.243, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2629 : Tensor = prim::GetAttr[name="bias"](%2621)
  %2630 : Tensor = prim::GetAttr[name="weight"](%2621)
  %2631 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.102, %2630), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.246 : Float(17:1664, 13:128, 128:1) = aten::add(%2631, %2629, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2633 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16193.FFNOutput = prim::GetAttr[name="output"](%2493)
  %2634 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16190.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2493)
  %2635 : __torch__.torch.nn.modules.linear.___torch_mangle_16189.Linear = prim::GetAttr[name="dense"](%2634)
  %2636 : Tensor = prim::GetAttr[name="bias"](%2635)
  %2637 : Tensor = prim::GetAttr[name="weight"](%2635)
  %2638 : Float(128:1, 512:128) = aten::t(%2637), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.192 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.246, %2638), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.247 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.192, %2636, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.248 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2642 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16192.NoNorm = prim::GetAttr[name="LayerNorm"](%2633)
  %2643 : __torch__.torch.nn.modules.linear.___torch_mangle_16191.Linear = prim::GetAttr[name="dense"](%2633)
  %2644 : Tensor = prim::GetAttr[name="bias"](%2643)
  %2645 : Tensor = prim::GetAttr[name="weight"](%2643)
  %2646 : Float(512:1, 128:512) = aten::t(%2645), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.193 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.248, %2646), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.64 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.193, %2644, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.103 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.64, %input.246, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2650 : Tensor = prim::GetAttr[name="bias"](%2642)
  %2651 : Tensor = prim::GetAttr[name="weight"](%2642)
  %2652 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.103, %2651), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.249 : Float(17:1664, 13:128, 128:1) = aten::add(%2652, %2650, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2654 : __torch__.torch.nn.modules.linear.___torch_mangle_16161.Linear = prim::GetAttr[name="dense"](%2491)
  %2655 : Tensor = prim::GetAttr[name="bias"](%2654)
  %2656 : Tensor = prim::GetAttr[name="weight"](%2654)
  %2657 : Float(128:1, 512:128) = aten::t(%2656), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %output.194 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.249, %2657), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %input.250 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.194, %2655, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1678:0
  %input.251 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate # torch/nn/functional.py:1119:0
  %2661 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16168.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2490)
  %2662 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16164.NoNorm = prim::GetAttr[name="LayerNorm"](%2490)
  %2663 : __torch__.torch.nn.modules.linear.___torch_mangle_16163.Linear = prim::GetAttr[name="dense"](%2490)
  %2664 : Tensor = prim::GetAttr[name="bias"](%2663)
  %2665 : Tensor = prim::GetAttr[name="weight"](%2663)
  %2666 : Float(512:1, 128:512) = aten::t(%2665), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %output.195 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.251, %2666), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %layer_output.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.195, %2664, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.104 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.13, %input.249, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output # transformers/modeling_mobilebert.py:405:0
  %2670 : Tensor = prim::GetAttr[name="bias"](%2662)
  %2671 : Tensor = prim::GetAttr[name="weight"](%2662)
  %2672 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.104, %2671), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.252 : Float(17:1664, 13:128, 128:1) = aten::add(%2672, %2670, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2674 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16166.NoNorm = prim::GetAttr[name="LayerNorm"](%2661)
  %2675 : __torch__.torch.nn.modules.linear.___torch_mangle_16165.Linear = prim::GetAttr[name="dense"](%2661)
  %2676 : Tensor = prim::GetAttr[name="bias"](%2675)
  %2677 : Tensor = prim::GetAttr[name="weight"](%2675)
  %2678 : Float(128:1, 512:128) = aten::t(%2677), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.196 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.252, %2678), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.253 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.196, %2676, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.65 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.253, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.105 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.65, %input.235, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2683 : Tensor = prim::GetAttr[name="bias"](%2674)
  %2684 : Tensor = prim::GetAttr[name="weight"](%2674)
  %2685 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.105, %2684), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.254 : Float(17:6656, 13:512, 512:1) = aten::add(%2685, %2683, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2687 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16214.MobileBertOutput = prim::GetAttr[name="output"](%99)
  %2688 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16207.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%99)
  %2689 : __torch__.torch.nn.modules.container.___torch_mangle_16240.ModuleList = prim::GetAttr[name="ffn"](%99)
  %2690 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16239.FFNLayer = prim::GetAttr[name="2"](%2689)
  %2691 : __torch__.torch.nn.modules.container.___torch_mangle_16240.ModuleList = prim::GetAttr[name="ffn"](%99)
  %2692 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16233.FFNLayer = prim::GetAttr[name="1"](%2691)
  %2693 : __torch__.torch.nn.modules.container.___torch_mangle_16240.ModuleList = prim::GetAttr[name="ffn"](%99)
  %2694 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16227.FFNLayer = prim::GetAttr[name="0"](%2693)
  %2695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16205.MobileBertAttention = prim::GetAttr[name="attention"](%99)
  %2696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16221.Bottleneck = prim::GetAttr[name="bottleneck"](%99)
  %2697 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16220.BottleneckLayer = prim::GetAttr[name="attention"](%2696)
  %2698 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16217.BottleneckLayer = prim::GetAttr[name="input"](%2696)
  %2699 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16216.NoNorm = prim::GetAttr[name="LayerNorm"](%2698)
  %2700 : __torch__.torch.nn.modules.linear.___torch_mangle_16215.Linear = prim::GetAttr[name="dense"](%2698)
  %2701 : Tensor = prim::GetAttr[name="bias"](%2700)
  %2702 : Tensor = prim::GetAttr[name="weight"](%2700)
  %2703 : Float(512:1, 128:512) = aten::t(%2702), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.197 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2703), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.197, %2701, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2706 : Tensor = prim::GetAttr[name="bias"](%2699)
  %2707 : Tensor = prim::GetAttr[name="weight"](%2699)
  %2708 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.106, %2707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%2708, %2706, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2710 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16219.NoNorm = prim::GetAttr[name="LayerNorm"](%2697)
  %2711 : __torch__.torch.nn.modules.linear.___torch_mangle_16218.Linear = prim::GetAttr[name="dense"](%2697)
  %2712 : Tensor = prim::GetAttr[name="bias"](%2711)
  %2713 : Tensor = prim::GetAttr[name="weight"](%2711)
  %2714 : Float(512:1, 128:512) = aten::t(%2713), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.198 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2714), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.198, %2712, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2717 : Tensor = prim::GetAttr[name="bias"](%2710)
  %2718 : Tensor = prim::GetAttr[name="weight"](%2710)
  %2719 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.107, %2718), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.255 : Float(17:1664, 13:128, 128:1) = aten::add(%2719, %2717, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2721 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.255, %residual_tensor.14)
  %2722 : Float(17:1664, 13:128, 128:1), %2723 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2721)
  %2724 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16204.MobileBertSelfOutput = prim::GetAttr[name="output"](%2695)
  %2725 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16201.MobileBertSelfAttention = prim::GetAttr[name="self"](%2695)
  %2726 : __torch__.torch.nn.modules.linear.___torch_mangle_16199.Linear = prim::GetAttr[name="value"](%2725)
  %2727 : __torch__.torch.nn.modules.linear.___torch_mangle_16198.Linear = prim::GetAttr[name="key"](%2725)
  %2728 : __torch__.torch.nn.modules.linear.___torch_mangle_16197.Linear = prim::GetAttr[name="query"](%2725)
  %2729 : Tensor = prim::GetAttr[name="bias"](%2728)
  %2730 : Tensor = prim::GetAttr[name="weight"](%2728)
  %2731 : Float(128:1, 128:128) = aten::t(%2730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %output.199 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2722, %2731), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %x.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.199, %2729, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1678:0
  %2734 : Tensor = prim::GetAttr[name="bias"](%2727)
  %2735 : Tensor = prim::GetAttr[name="weight"](%2727)
  %2736 : Float(128:1, 128:128) = aten::t(%2735), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %output.200 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2722, %2736), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %x.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.200, %2734, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1678:0
  %2739 : Tensor = prim::GetAttr[name="bias"](%2726)
  %2740 : Tensor = prim::GetAttr[name="weight"](%2726)
  %2741 : Float(512:1, 128:512) = aten::t(%2740), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %output.201 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2741), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %x.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.201, %2739, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1678:0
  %2744 : int = aten::size(%x.79, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2745 : int = aten::size(%x.79, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2746 : int[] = prim::ListConstruct(%2744, %2745, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.80 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.79, %2746), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2748 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %query_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.80, %2748), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2750 : int = aten::size(%x.81, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2751 : int = aten::size(%x.81, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2752 : int[] = prim::ListConstruct(%2750, %2751, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.82 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.81, %2752), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2754 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %key_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.82, %2754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2756 : int = aten::size(%x.83, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2757 : int = aten::size(%x.83, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2758 : int[] = prim::ListConstruct(%2756, %2757, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.84 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.83, %2758), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2760 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %value_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.84, %2760), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2762 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.14, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.27 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.14, %2762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.27, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.256 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.28, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.257 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.256, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.257, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.27 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.14, %value_layer.14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:280:0
  %2769 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %2770 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.27, %2769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2770, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %2772 : int = aten::size(%context_layer.28, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2773 : int = aten::size(%context_layer.28, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2774 : int[] = prim::ListConstruct(%2772, %2773, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %input.258 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.28, %2774), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:283:0
  %2776 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16203.NoNorm = prim::GetAttr[name="LayerNorm"](%2724)
  %2777 : __torch__.torch.nn.modules.linear.___torch_mangle_16202.Linear = prim::GetAttr[name="dense"](%2724)
  %2778 : Tensor = prim::GetAttr[name="bias"](%2777)
  %2779 : Tensor = prim::GetAttr[name="weight"](%2777)
  %2780 : Float(128:1, 128:128) = aten::t(%2779), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %output.202 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.258, %2780), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.202, %2778, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.108 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.66, %2723, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output # transformers/modeling_mobilebert.py:301:0
  %2784 : Tensor = prim::GetAttr[name="bias"](%2776)
  %2785 : Tensor = prim::GetAttr[name="weight"](%2776)
  %2786 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.108, %2785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.259 : Float(17:1664, 13:128, 128:1) = aten::add(%2786, %2784, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2788 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16226.FFNOutput = prim::GetAttr[name="output"](%2694)
  %2789 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16223.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2694)
  %2790 : __torch__.torch.nn.modules.linear.___torch_mangle_16222.Linear = prim::GetAttr[name="dense"](%2789)
  %2791 : Tensor = prim::GetAttr[name="bias"](%2790)
  %2792 : Tensor = prim::GetAttr[name="weight"](%2790)
  %2793 : Float(128:1, 512:128) = aten::t(%2792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.203 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.259, %2793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.260 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.203, %2791, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.261 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2797 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16225.NoNorm = prim::GetAttr[name="LayerNorm"](%2788)
  %2798 : __torch__.torch.nn.modules.linear.___torch_mangle_16224.Linear = prim::GetAttr[name="dense"](%2788)
  %2799 : Tensor = prim::GetAttr[name="bias"](%2798)
  %2800 : Tensor = prim::GetAttr[name="weight"](%2798)
  %2801 : Float(512:1, 128:512) = aten::t(%2800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.204 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.261, %2801), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.204, %2799, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.109 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.67, %input.259, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2805 : Tensor = prim::GetAttr[name="bias"](%2797)
  %2806 : Tensor = prim::GetAttr[name="weight"](%2797)
  %2807 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.109, %2806), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.262 : Float(17:1664, 13:128, 128:1) = aten::add(%2807, %2805, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2809 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16232.FFNOutput = prim::GetAttr[name="output"](%2692)
  %2810 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16229.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2692)
  %2811 : __torch__.torch.nn.modules.linear.___torch_mangle_16228.Linear = prim::GetAttr[name="dense"](%2810)
  %2812 : Tensor = prim::GetAttr[name="bias"](%2811)
  %2813 : Tensor = prim::GetAttr[name="weight"](%2811)
  %2814 : Float(128:1, 512:128) = aten::t(%2813), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.205 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.262, %2814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.263 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.205, %2812, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.264 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2818 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16231.NoNorm = prim::GetAttr[name="LayerNorm"](%2809)
  %2819 : __torch__.torch.nn.modules.linear.___torch_mangle_16230.Linear = prim::GetAttr[name="dense"](%2809)
  %2820 : Tensor = prim::GetAttr[name="bias"](%2819)
  %2821 : Tensor = prim::GetAttr[name="weight"](%2819)
  %2822 : Float(512:1, 128:512) = aten::t(%2821), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.206 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.264, %2822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.68 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.206, %2820, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.110 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.68, %input.262, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2826 : Tensor = prim::GetAttr[name="bias"](%2818)
  %2827 : Tensor = prim::GetAttr[name="weight"](%2818)
  %2828 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.110, %2827), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.265 : Float(17:1664, 13:128, 128:1) = aten::add(%2828, %2826, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2830 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16238.FFNOutput = prim::GetAttr[name="output"](%2690)
  %2831 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16235.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2690)
  %2832 : __torch__.torch.nn.modules.linear.___torch_mangle_16234.Linear = prim::GetAttr[name="dense"](%2831)
  %2833 : Tensor = prim::GetAttr[name="bias"](%2832)
  %2834 : Tensor = prim::GetAttr[name="weight"](%2832)
  %2835 : Float(128:1, 512:128) = aten::t(%2834), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.207 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.265, %2835), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.266 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.207, %2833, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.267 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2839 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16237.NoNorm = prim::GetAttr[name="LayerNorm"](%2830)
  %2840 : __torch__.torch.nn.modules.linear.___torch_mangle_16236.Linear = prim::GetAttr[name="dense"](%2830)
  %2841 : Tensor = prim::GetAttr[name="bias"](%2840)
  %2842 : Tensor = prim::GetAttr[name="weight"](%2840)
  %2843 : Float(512:1, 128:512) = aten::t(%2842), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.208 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.267, %2843), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.208, %2841, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.111 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.69, %input.265, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2847 : Tensor = prim::GetAttr[name="bias"](%2839)
  %2848 : Tensor = prim::GetAttr[name="weight"](%2839)
  %2849 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.111, %2848), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.268 : Float(17:1664, 13:128, 128:1) = aten::add(%2849, %2847, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2851 : __torch__.torch.nn.modules.linear.___torch_mangle_16206.Linear = prim::GetAttr[name="dense"](%2688)
  %2852 : Tensor = prim::GetAttr[name="bias"](%2851)
  %2853 : Tensor = prim::GetAttr[name="weight"](%2851)
  %2854 : Float(128:1, 512:128) = aten::t(%2853), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %output.209 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.268, %2854), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %input.269 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.209, %2852, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1678:0
  %input.270 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate # torch/nn/functional.py:1119:0
  %2858 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16213.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2687)
  %2859 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16209.NoNorm = prim::GetAttr[name="LayerNorm"](%2687)
  %2860 : __torch__.torch.nn.modules.linear.___torch_mangle_16208.Linear = prim::GetAttr[name="dense"](%2687)
  %2861 : Tensor = prim::GetAttr[name="bias"](%2860)
  %2862 : Tensor = prim::GetAttr[name="weight"](%2860)
  %2863 : Float(512:1, 128:512) = aten::t(%2862), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %output.210 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.270, %2863), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %layer_output.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.210, %2861, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.112 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.14, %input.268, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output # transformers/modeling_mobilebert.py:405:0
  %2867 : Tensor = prim::GetAttr[name="bias"](%2859)
  %2868 : Tensor = prim::GetAttr[name="weight"](%2859)
  %2869 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.112, %2868), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.271 : Float(17:1664, 13:128, 128:1) = aten::add(%2869, %2867, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2871 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16211.NoNorm = prim::GetAttr[name="LayerNorm"](%2858)
  %2872 : __torch__.torch.nn.modules.linear.___torch_mangle_16210.Linear = prim::GetAttr[name="dense"](%2858)
  %2873 : Tensor = prim::GetAttr[name="bias"](%2872)
  %2874 : Tensor = prim::GetAttr[name="weight"](%2872)
  %2875 : Float(128:1, 512:128) = aten::t(%2874), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.211 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.271, %2875), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.272 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.211, %2873, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.70 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.272, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.113 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.70, %input.254, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2880 : Tensor = prim::GetAttr[name="bias"](%2871)
  %2881 : Tensor = prim::GetAttr[name="weight"](%2871)
  %2882 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.113, %2881), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.273 : Float(17:6656, 13:512, 512:1) = aten::add(%2882, %2880, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2884 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16259.MobileBertOutput = prim::GetAttr[name="output"](%97)
  %2885 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16252.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%97)
  %2886 : __torch__.torch.nn.modules.container.___torch_mangle_16285.ModuleList = prim::GetAttr[name="ffn"](%97)
  %2887 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16284.FFNLayer = prim::GetAttr[name="2"](%2886)
  %2888 : __torch__.torch.nn.modules.container.___torch_mangle_16285.ModuleList = prim::GetAttr[name="ffn"](%97)
  %2889 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16278.FFNLayer = prim::GetAttr[name="1"](%2888)
  %2890 : __torch__.torch.nn.modules.container.___torch_mangle_16285.ModuleList = prim::GetAttr[name="ffn"](%97)
  %2891 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16272.FFNLayer = prim::GetAttr[name="0"](%2890)
  %2892 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16250.MobileBertAttention = prim::GetAttr[name="attention"](%97)
  %2893 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16266.Bottleneck = prim::GetAttr[name="bottleneck"](%97)
  %2894 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16265.BottleneckLayer = prim::GetAttr[name="attention"](%2893)
  %2895 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16262.BottleneckLayer = prim::GetAttr[name="input"](%2893)
  %2896 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16261.NoNorm = prim::GetAttr[name="LayerNorm"](%2895)
  %2897 : __torch__.torch.nn.modules.linear.___torch_mangle_16260.Linear = prim::GetAttr[name="dense"](%2895)
  %2898 : Tensor = prim::GetAttr[name="bias"](%2897)
  %2899 : Tensor = prim::GetAttr[name="weight"](%2897)
  %2900 : Float(512:1, 128:512) = aten::t(%2899), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.212 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2900), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.212, %2898, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2903 : Tensor = prim::GetAttr[name="bias"](%2896)
  %2904 : Tensor = prim::GetAttr[name="weight"](%2896)
  %2905 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.114, %2904), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%2905, %2903, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2907 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16264.NoNorm = prim::GetAttr[name="LayerNorm"](%2894)
  %2908 : __torch__.torch.nn.modules.linear.___torch_mangle_16263.Linear = prim::GetAttr[name="dense"](%2894)
  %2909 : Tensor = prim::GetAttr[name="bias"](%2908)
  %2910 : Tensor = prim::GetAttr[name="weight"](%2908)
  %2911 : Float(512:1, 128:512) = aten::t(%2910), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.213 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2911), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.213, %2909, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2914 : Tensor = prim::GetAttr[name="bias"](%2907)
  %2915 : Tensor = prim::GetAttr[name="weight"](%2907)
  %2916 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.115, %2915), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.274 : Float(17:1664, 13:128, 128:1) = aten::add(%2916, %2914, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2918 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.274, %residual_tensor.15)
  %2919 : Float(17:1664, 13:128, 128:1), %2920 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2918)
  %2921 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16249.MobileBertSelfOutput = prim::GetAttr[name="output"](%2892)
  %2922 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16246.MobileBertSelfAttention = prim::GetAttr[name="self"](%2892)
  %2923 : __torch__.torch.nn.modules.linear.___torch_mangle_16244.Linear = prim::GetAttr[name="value"](%2922)
  %2924 : __torch__.torch.nn.modules.linear.___torch_mangle_16243.Linear = prim::GetAttr[name="key"](%2922)
  %2925 : __torch__.torch.nn.modules.linear.___torch_mangle_16242.Linear = prim::GetAttr[name="query"](%2922)
  %2926 : Tensor = prim::GetAttr[name="bias"](%2925)
  %2927 : Tensor = prim::GetAttr[name="weight"](%2925)
  %2928 : Float(128:1, 128:128) = aten::t(%2927), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %output.214 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2919, %2928), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %x.85 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.214, %2926, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1678:0
  %2931 : Tensor = prim::GetAttr[name="bias"](%2924)
  %2932 : Tensor = prim::GetAttr[name="weight"](%2924)
  %2933 : Float(128:1, 128:128) = aten::t(%2932), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %output.215 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2919, %2933), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %x.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.215, %2931, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1678:0
  %2936 : Tensor = prim::GetAttr[name="bias"](%2923)
  %2937 : Tensor = prim::GetAttr[name="weight"](%2923)
  %2938 : Float(512:1, 128:512) = aten::t(%2937), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %output.216 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2938), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %x.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.216, %2936, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1678:0
  %2941 : int = aten::size(%x.85, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2942 : int = aten::size(%x.85, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2943 : int[] = prim::ListConstruct(%2941, %2942, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.86 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.85, %2943), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2945 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %query_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.86, %2945), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2947 : int = aten::size(%x.87, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2948 : int = aten::size(%x.87, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2949 : int[] = prim::ListConstruct(%2947, %2948, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.88 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.87, %2949), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2951 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %key_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.88, %2951), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2953 : int = aten::size(%x.89, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2954 : int = aten::size(%x.89, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2955 : int[] = prim::ListConstruct(%2953, %2954, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.90 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.89, %2955), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2957 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %value_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.90, %2957), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2959 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.15, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.15, %2959), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.30 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.29, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.275 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.30, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.276 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.275, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.276, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.29 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.15, %value_layer.15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:280:0
  %2966 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %2967 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.29, %2966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2967, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %2969 : int = aten::size(%context_layer.30, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2970 : int = aten::size(%context_layer.30, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2971 : int[] = prim::ListConstruct(%2969, %2970, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %input.277 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.30, %2971), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:283:0
  %2973 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16248.NoNorm = prim::GetAttr[name="LayerNorm"](%2921)
  %2974 : __torch__.torch.nn.modules.linear.___torch_mangle_16247.Linear = prim::GetAttr[name="dense"](%2921)
  %2975 : Tensor = prim::GetAttr[name="bias"](%2974)
  %2976 : Tensor = prim::GetAttr[name="weight"](%2974)
  %2977 : Float(128:1, 128:128) = aten::t(%2976), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %output.217 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.277, %2977), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.217, %2975, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.116 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.71, %2920, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output # transformers/modeling_mobilebert.py:301:0
  %2981 : Tensor = prim::GetAttr[name="bias"](%2973)
  %2982 : Tensor = prim::GetAttr[name="weight"](%2973)
  %2983 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.116, %2982), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.278 : Float(17:1664, 13:128, 128:1) = aten::add(%2983, %2981, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2985 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16271.FFNOutput = prim::GetAttr[name="output"](%2891)
  %2986 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16268.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2891)
  %2987 : __torch__.torch.nn.modules.linear.___torch_mangle_16267.Linear = prim::GetAttr[name="dense"](%2986)
  %2988 : Tensor = prim::GetAttr[name="bias"](%2987)
  %2989 : Tensor = prim::GetAttr[name="weight"](%2987)
  %2990 : Float(128:1, 512:128) = aten::t(%2989), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.218 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.278, %2990), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.279 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.218, %2988, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.280 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2994 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16270.NoNorm = prim::GetAttr[name="LayerNorm"](%2985)
  %2995 : __torch__.torch.nn.modules.linear.___torch_mangle_16269.Linear = prim::GetAttr[name="dense"](%2985)
  %2996 : Tensor = prim::GetAttr[name="bias"](%2995)
  %2997 : Tensor = prim::GetAttr[name="weight"](%2995)
  %2998 : Float(512:1, 128:512) = aten::t(%2997), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.219 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.280, %2998), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.72 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.219, %2996, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.117 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.72, %input.278, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3002 : Tensor = prim::GetAttr[name="bias"](%2994)
  %3003 : Tensor = prim::GetAttr[name="weight"](%2994)
  %3004 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.117, %3003), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.281 : Float(17:1664, 13:128, 128:1) = aten::add(%3004, %3002, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3006 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16277.FFNOutput = prim::GetAttr[name="output"](%2889)
  %3007 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16274.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2889)
  %3008 : __torch__.torch.nn.modules.linear.___torch_mangle_16273.Linear = prim::GetAttr[name="dense"](%3007)
  %3009 : Tensor = prim::GetAttr[name="bias"](%3008)
  %3010 : Tensor = prim::GetAttr[name="weight"](%3008)
  %3011 : Float(128:1, 512:128) = aten::t(%3010), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.220 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.281, %3011), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.282 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.220, %3009, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.283 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3015 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16276.NoNorm = prim::GetAttr[name="LayerNorm"](%3006)
  %3016 : __torch__.torch.nn.modules.linear.___torch_mangle_16275.Linear = prim::GetAttr[name="dense"](%3006)
  %3017 : Tensor = prim::GetAttr[name="bias"](%3016)
  %3018 : Tensor = prim::GetAttr[name="weight"](%3016)
  %3019 : Float(512:1, 128:512) = aten::t(%3018), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.221 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.283, %3019), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.221, %3017, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.118 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.73, %input.281, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3023 : Tensor = prim::GetAttr[name="bias"](%3015)
  %3024 : Tensor = prim::GetAttr[name="weight"](%3015)
  %3025 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.118, %3024), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.284 : Float(17:1664, 13:128, 128:1) = aten::add(%3025, %3023, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3027 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16283.FFNOutput = prim::GetAttr[name="output"](%2887)
  %3028 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16280.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2887)
  %3029 : __torch__.torch.nn.modules.linear.___torch_mangle_16279.Linear = prim::GetAttr[name="dense"](%3028)
  %3030 : Tensor = prim::GetAttr[name="bias"](%3029)
  %3031 : Tensor = prim::GetAttr[name="weight"](%3029)
  %3032 : Float(128:1, 512:128) = aten::t(%3031), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.222 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.284, %3032), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.285 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.222, %3030, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.286 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3036 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16282.NoNorm = prim::GetAttr[name="LayerNorm"](%3027)
  %3037 : __torch__.torch.nn.modules.linear.___torch_mangle_16281.Linear = prim::GetAttr[name="dense"](%3027)
  %3038 : Tensor = prim::GetAttr[name="bias"](%3037)
  %3039 : Tensor = prim::GetAttr[name="weight"](%3037)
  %3040 : Float(512:1, 128:512) = aten::t(%3039), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.223 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.286, %3040), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.223, %3038, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.119 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.74, %input.284, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3044 : Tensor = prim::GetAttr[name="bias"](%3036)
  %3045 : Tensor = prim::GetAttr[name="weight"](%3036)
  %3046 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.119, %3045), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.287 : Float(17:1664, 13:128, 128:1) = aten::add(%3046, %3044, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3048 : __torch__.torch.nn.modules.linear.___torch_mangle_16251.Linear = prim::GetAttr[name="dense"](%2885)
  %3049 : Tensor = prim::GetAttr[name="bias"](%3048)
  %3050 : Tensor = prim::GetAttr[name="weight"](%3048)
  %3051 : Float(128:1, 512:128) = aten::t(%3050), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %output.224 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.287, %3051), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %input.288 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.224, %3049, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1678:0
  %input.289 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate # torch/nn/functional.py:1119:0
  %3055 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16258.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2884)
  %3056 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16254.NoNorm = prim::GetAttr[name="LayerNorm"](%2884)
  %3057 : __torch__.torch.nn.modules.linear.___torch_mangle_16253.Linear = prim::GetAttr[name="dense"](%2884)
  %3058 : Tensor = prim::GetAttr[name="bias"](%3057)
  %3059 : Tensor = prim::GetAttr[name="weight"](%3057)
  %3060 : Float(512:1, 128:512) = aten::t(%3059), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %output.225 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.289, %3060), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %layer_output.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.225, %3058, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.120 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.15, %input.287, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output # transformers/modeling_mobilebert.py:405:0
  %3064 : Tensor = prim::GetAttr[name="bias"](%3056)
  %3065 : Tensor = prim::GetAttr[name="weight"](%3056)
  %3066 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.120, %3065), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.290 : Float(17:1664, 13:128, 128:1) = aten::add(%3066, %3064, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3068 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16256.NoNorm = prim::GetAttr[name="LayerNorm"](%3055)
  %3069 : __torch__.torch.nn.modules.linear.___torch_mangle_16255.Linear = prim::GetAttr[name="dense"](%3055)
  %3070 : Tensor = prim::GetAttr[name="bias"](%3069)
  %3071 : Tensor = prim::GetAttr[name="weight"](%3069)
  %3072 : Float(128:1, 512:128) = aten::t(%3071), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.226 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.290, %3072), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.291 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.226, %3070, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.75 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.291, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.121 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.75, %input.273, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3077 : Tensor = prim::GetAttr[name="bias"](%3068)
  %3078 : Tensor = prim::GetAttr[name="weight"](%3068)
  %3079 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.121, %3078), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.292 : Float(17:6656, 13:512, 512:1) = aten::add(%3079, %3077, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3081 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16304.MobileBertOutput = prim::GetAttr[name="output"](%95)
  %3082 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16297.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%95)
  %3083 : __torch__.torch.nn.modules.container.___torch_mangle_16330.ModuleList = prim::GetAttr[name="ffn"](%95)
  %3084 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16329.FFNLayer = prim::GetAttr[name="2"](%3083)
  %3085 : __torch__.torch.nn.modules.container.___torch_mangle_16330.ModuleList = prim::GetAttr[name="ffn"](%95)
  %3086 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16323.FFNLayer = prim::GetAttr[name="1"](%3085)
  %3087 : __torch__.torch.nn.modules.container.___torch_mangle_16330.ModuleList = prim::GetAttr[name="ffn"](%95)
  %3088 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16317.FFNLayer = prim::GetAttr[name="0"](%3087)
  %3089 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16295.MobileBertAttention = prim::GetAttr[name="attention"](%95)
  %3090 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16311.Bottleneck = prim::GetAttr[name="bottleneck"](%95)
  %3091 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16310.BottleneckLayer = prim::GetAttr[name="attention"](%3090)
  %3092 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16307.BottleneckLayer = prim::GetAttr[name="input"](%3090)
  %3093 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16306.NoNorm = prim::GetAttr[name="LayerNorm"](%3092)
  %3094 : __torch__.torch.nn.modules.linear.___torch_mangle_16305.Linear = prim::GetAttr[name="dense"](%3092)
  %3095 : Tensor = prim::GetAttr[name="bias"](%3094)
  %3096 : Tensor = prim::GetAttr[name="weight"](%3094)
  %3097 : Float(512:1, 128:512) = aten::t(%3096), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.227 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3097), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.122 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.227, %3095, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3100 : Tensor = prim::GetAttr[name="bias"](%3093)
  %3101 : Tensor = prim::GetAttr[name="weight"](%3093)
  %3102 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.122, %3101), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%3102, %3100, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16309.NoNorm = prim::GetAttr[name="LayerNorm"](%3091)
  %3105 : __torch__.torch.nn.modules.linear.___torch_mangle_16308.Linear = prim::GetAttr[name="dense"](%3091)
  %3106 : Tensor = prim::GetAttr[name="bias"](%3105)
  %3107 : Tensor = prim::GetAttr[name="weight"](%3105)
  %3108 : Float(512:1, 128:512) = aten::t(%3107), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.228 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.228, %3106, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3111 : Tensor = prim::GetAttr[name="bias"](%3104)
  %3112 : Tensor = prim::GetAttr[name="weight"](%3104)
  %3113 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.123, %3112), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.293 : Float(17:1664, 13:128, 128:1) = aten::add(%3113, %3111, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3115 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.293, %residual_tensor.16)
  %3116 : Float(17:1664, 13:128, 128:1), %3117 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3115)
  %3118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16294.MobileBertSelfOutput = prim::GetAttr[name="output"](%3089)
  %3119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16291.MobileBertSelfAttention = prim::GetAttr[name="self"](%3089)
  %3120 : __torch__.torch.nn.modules.linear.___torch_mangle_16289.Linear = prim::GetAttr[name="value"](%3119)
  %3121 : __torch__.torch.nn.modules.linear.___torch_mangle_16288.Linear = prim::GetAttr[name="key"](%3119)
  %3122 : __torch__.torch.nn.modules.linear.___torch_mangle_16287.Linear = prim::GetAttr[name="query"](%3119)
  %3123 : Tensor = prim::GetAttr[name="bias"](%3122)
  %3124 : Tensor = prim::GetAttr[name="weight"](%3122)
  %3125 : Float(128:1, 128:128) = aten::t(%3124), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %output.229 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3116, %3125), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %x.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.229, %3123, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1678:0
  %3128 : Tensor = prim::GetAttr[name="bias"](%3121)
  %3129 : Tensor = prim::GetAttr[name="weight"](%3121)
  %3130 : Float(128:1, 128:128) = aten::t(%3129), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %output.230 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3116, %3130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %x.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.230, %3128, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1678:0
  %3133 : Tensor = prim::GetAttr[name="bias"](%3120)
  %3134 : Tensor = prim::GetAttr[name="weight"](%3120)
  %3135 : Float(512:1, 128:512) = aten::t(%3134), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %output.231 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3135), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %x.95 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.231, %3133, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1678:0
  %3138 : int = aten::size(%x.91, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3139 : int = aten::size(%x.91, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3140 : int[] = prim::ListConstruct(%3138, %3139, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.92 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.91, %3140), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3142 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %query_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.92, %3142), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3144 : int = aten::size(%x.93, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3145 : int = aten::size(%x.93, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3146 : int[] = prim::ListConstruct(%3144, %3145, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.94 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.93, %3146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3148 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %key_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.94, %3148), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3150 : int = aten::size(%x.95, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3151 : int = aten::size(%x.95, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3152 : int[] = prim::ListConstruct(%3150, %3151, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.96 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.95, %3152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3154 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %value_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.96, %3154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3156 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.16, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.31 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.16, %3156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.32 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.31, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.294 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.32, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.295 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.294, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.295, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.31 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.16, %value_layer.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:280:0
  %3163 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %3164 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.31, %3163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3164, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %3166 : int = aten::size(%context_layer.32, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3167 : int = aten::size(%context_layer.32, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3168 : int[] = prim::ListConstruct(%3166, %3167, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %input.296 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.32, %3168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:283:0
  %3170 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16293.NoNorm = prim::GetAttr[name="LayerNorm"](%3118)
  %3171 : __torch__.torch.nn.modules.linear.___torch_mangle_16292.Linear = prim::GetAttr[name="dense"](%3118)
  %3172 : Tensor = prim::GetAttr[name="bias"](%3171)
  %3173 : Tensor = prim::GetAttr[name="weight"](%3171)
  %3174 : Float(128:1, 128:128) = aten::t(%3173), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %output.232 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.296, %3174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.76 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.232, %3172, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.124 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.76, %3117, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output # transformers/modeling_mobilebert.py:301:0
  %3178 : Tensor = prim::GetAttr[name="bias"](%3170)
  %3179 : Tensor = prim::GetAttr[name="weight"](%3170)
  %3180 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.124, %3179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.297 : Float(17:1664, 13:128, 128:1) = aten::add(%3180, %3178, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3182 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16316.FFNOutput = prim::GetAttr[name="output"](%3088)
  %3183 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16313.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3088)
  %3184 : __torch__.torch.nn.modules.linear.___torch_mangle_16312.Linear = prim::GetAttr[name="dense"](%3183)
  %3185 : Tensor = prim::GetAttr[name="bias"](%3184)
  %3186 : Tensor = prim::GetAttr[name="weight"](%3184)
  %3187 : Float(128:1, 512:128) = aten::t(%3186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.233 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.297, %3187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.298 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.233, %3185, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.299 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3191 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16315.NoNorm = prim::GetAttr[name="LayerNorm"](%3182)
  %3192 : __torch__.torch.nn.modules.linear.___torch_mangle_16314.Linear = prim::GetAttr[name="dense"](%3182)
  %3193 : Tensor = prim::GetAttr[name="bias"](%3192)
  %3194 : Tensor = prim::GetAttr[name="weight"](%3192)
  %3195 : Float(512:1, 128:512) = aten::t(%3194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.234 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.299, %3195), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.234, %3193, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.125 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.77, %input.297, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3199 : Tensor = prim::GetAttr[name="bias"](%3191)
  %3200 : Tensor = prim::GetAttr[name="weight"](%3191)
  %3201 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.125, %3200), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.300 : Float(17:1664, 13:128, 128:1) = aten::add(%3201, %3199, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3203 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16322.FFNOutput = prim::GetAttr[name="output"](%3086)
  %3204 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16319.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3086)
  %3205 : __torch__.torch.nn.modules.linear.___torch_mangle_16318.Linear = prim::GetAttr[name="dense"](%3204)
  %3206 : Tensor = prim::GetAttr[name="bias"](%3205)
  %3207 : Tensor = prim::GetAttr[name="weight"](%3205)
  %3208 : Float(128:1, 512:128) = aten::t(%3207), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.235 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.300, %3208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.301 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.235, %3206, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.302 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3212 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16321.NoNorm = prim::GetAttr[name="LayerNorm"](%3203)
  %3213 : __torch__.torch.nn.modules.linear.___torch_mangle_16320.Linear = prim::GetAttr[name="dense"](%3203)
  %3214 : Tensor = prim::GetAttr[name="bias"](%3213)
  %3215 : Tensor = prim::GetAttr[name="weight"](%3213)
  %3216 : Float(512:1, 128:512) = aten::t(%3215), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.236 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.302, %3216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.78 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.236, %3214, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.126 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.78, %input.300, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3220 : Tensor = prim::GetAttr[name="bias"](%3212)
  %3221 : Tensor = prim::GetAttr[name="weight"](%3212)
  %3222 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.126, %3221), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.303 : Float(17:1664, 13:128, 128:1) = aten::add(%3222, %3220, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3224 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16328.FFNOutput = prim::GetAttr[name="output"](%3084)
  %3225 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16325.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3084)
  %3226 : __torch__.torch.nn.modules.linear.___torch_mangle_16324.Linear = prim::GetAttr[name="dense"](%3225)
  %3227 : Tensor = prim::GetAttr[name="bias"](%3226)
  %3228 : Tensor = prim::GetAttr[name="weight"](%3226)
  %3229 : Float(128:1, 512:128) = aten::t(%3228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.237 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.303, %3229), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.304 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.237, %3227, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.305 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3233 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16327.NoNorm = prim::GetAttr[name="LayerNorm"](%3224)
  %3234 : __torch__.torch.nn.modules.linear.___torch_mangle_16326.Linear = prim::GetAttr[name="dense"](%3224)
  %3235 : Tensor = prim::GetAttr[name="bias"](%3234)
  %3236 : Tensor = prim::GetAttr[name="weight"](%3234)
  %3237 : Float(512:1, 128:512) = aten::t(%3236), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.238 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.305, %3237), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.238, %3235, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.127 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.79, %input.303, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3241 : Tensor = prim::GetAttr[name="bias"](%3233)
  %3242 : Tensor = prim::GetAttr[name="weight"](%3233)
  %3243 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.127, %3242), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.306 : Float(17:1664, 13:128, 128:1) = aten::add(%3243, %3241, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3245 : __torch__.torch.nn.modules.linear.___torch_mangle_16296.Linear = prim::GetAttr[name="dense"](%3082)
  %3246 : Tensor = prim::GetAttr[name="bias"](%3245)
  %3247 : Tensor = prim::GetAttr[name="weight"](%3245)
  %3248 : Float(128:1, 512:128) = aten::t(%3247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %output.239 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.306, %3248), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %input.307 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.239, %3246, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1678:0
  %input.308 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate # torch/nn/functional.py:1119:0
  %3252 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16303.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3081)
  %3253 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16299.NoNorm = prim::GetAttr[name="LayerNorm"](%3081)
  %3254 : __torch__.torch.nn.modules.linear.___torch_mangle_16298.Linear = prim::GetAttr[name="dense"](%3081)
  %3255 : Tensor = prim::GetAttr[name="bias"](%3254)
  %3256 : Tensor = prim::GetAttr[name="weight"](%3254)
  %3257 : Float(512:1, 128:512) = aten::t(%3256), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %output.240 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.308, %3257), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %layer_output.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.240, %3255, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.128 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.16, %input.306, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output # transformers/modeling_mobilebert.py:405:0
  %3261 : Tensor = prim::GetAttr[name="bias"](%3253)
  %3262 : Tensor = prim::GetAttr[name="weight"](%3253)
  %3263 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.128, %3262), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.309 : Float(17:1664, 13:128, 128:1) = aten::add(%3263, %3261, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3265 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16301.NoNorm = prim::GetAttr[name="LayerNorm"](%3252)
  %3266 : __torch__.torch.nn.modules.linear.___torch_mangle_16300.Linear = prim::GetAttr[name="dense"](%3252)
  %3267 : Tensor = prim::GetAttr[name="bias"](%3266)
  %3268 : Tensor = prim::GetAttr[name="weight"](%3266)
  %3269 : Float(128:1, 512:128) = aten::t(%3268), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.241 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.309, %3269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.310 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.241, %3267, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.80 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.310, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.129 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.80, %input.292, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3274 : Tensor = prim::GetAttr[name="bias"](%3265)
  %3275 : Tensor = prim::GetAttr[name="weight"](%3265)
  %3276 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.129, %3275), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.311 : Float(17:6656, 13:512, 512:1) = aten::add(%3276, %3274, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3278 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16349.MobileBertOutput = prim::GetAttr[name="output"](%93)
  %3279 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16342.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%93)
  %3280 : __torch__.torch.nn.modules.container.___torch_mangle_16375.ModuleList = prim::GetAttr[name="ffn"](%93)
  %3281 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16374.FFNLayer = prim::GetAttr[name="2"](%3280)
  %3282 : __torch__.torch.nn.modules.container.___torch_mangle_16375.ModuleList = prim::GetAttr[name="ffn"](%93)
  %3283 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16368.FFNLayer = prim::GetAttr[name="1"](%3282)
  %3284 : __torch__.torch.nn.modules.container.___torch_mangle_16375.ModuleList = prim::GetAttr[name="ffn"](%93)
  %3285 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16362.FFNLayer = prim::GetAttr[name="0"](%3284)
  %3286 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16340.MobileBertAttention = prim::GetAttr[name="attention"](%93)
  %3287 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16356.Bottleneck = prim::GetAttr[name="bottleneck"](%93)
  %3288 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16355.BottleneckLayer = prim::GetAttr[name="attention"](%3287)
  %3289 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16352.BottleneckLayer = prim::GetAttr[name="input"](%3287)
  %3290 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16351.NoNorm = prim::GetAttr[name="LayerNorm"](%3289)
  %3291 : __torch__.torch.nn.modules.linear.___torch_mangle_16350.Linear = prim::GetAttr[name="dense"](%3289)
  %3292 : Tensor = prim::GetAttr[name="bias"](%3291)
  %3293 : Tensor = prim::GetAttr[name="weight"](%3291)
  %3294 : Float(512:1, 128:512) = aten::t(%3293), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.242 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3294), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.130 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.242, %3292, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3297 : Tensor = prim::GetAttr[name="bias"](%3290)
  %3298 : Tensor = prim::GetAttr[name="weight"](%3290)
  %3299 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.130, %3298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.17 : Float(17:1664, 13:128, 128:1) = aten::add(%3299, %3297, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16354.NoNorm = prim::GetAttr[name="LayerNorm"](%3288)
  %3302 : __torch__.torch.nn.modules.linear.___torch_mangle_16353.Linear = prim::GetAttr[name="dense"](%3288)
  %3303 : Tensor = prim::GetAttr[name="bias"](%3302)
  %3304 : Tensor = prim::GetAttr[name="weight"](%3302)
  %3305 : Float(512:1, 128:512) = aten::t(%3304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.243 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3305), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.243, %3303, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3308 : Tensor = prim::GetAttr[name="bias"](%3301)
  %3309 : Tensor = prim::GetAttr[name="weight"](%3301)
  %3310 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.131, %3309), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.312 : Float(17:1664, 13:128, 128:1) = aten::add(%3310, %3308, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3312 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.312, %residual_tensor.17)
  %3313 : Float(17:1664, 13:128, 128:1), %3314 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3312)
  %3315 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16339.MobileBertSelfOutput = prim::GetAttr[name="output"](%3286)
  %3316 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16336.MobileBertSelfAttention = prim::GetAttr[name="self"](%3286)
  %3317 : __torch__.torch.nn.modules.linear.___torch_mangle_16334.Linear = prim::GetAttr[name="value"](%3316)
  %3318 : __torch__.torch.nn.modules.linear.___torch_mangle_16333.Linear = prim::GetAttr[name="key"](%3316)
  %3319 : __torch__.torch.nn.modules.linear.___torch_mangle_16332.Linear = prim::GetAttr[name="query"](%3316)
  %3320 : Tensor = prim::GetAttr[name="bias"](%3319)
  %3321 : Tensor = prim::GetAttr[name="weight"](%3319)
  %3322 : Float(128:1, 128:128) = aten::t(%3321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %output.244 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3313, %3322), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %x.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.244, %3320, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1678:0
  %3325 : Tensor = prim::GetAttr[name="bias"](%3318)
  %3326 : Tensor = prim::GetAttr[name="weight"](%3318)
  %3327 : Float(128:1, 128:128) = aten::t(%3326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %output.245 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3313, %3327), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %x.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.245, %3325, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1678:0
  %3330 : Tensor = prim::GetAttr[name="bias"](%3317)
  %3331 : Tensor = prim::GetAttr[name="weight"](%3317)
  %3332 : Float(512:1, 128:512) = aten::t(%3331), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %output.246 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3332), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %x.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.246, %3330, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1678:0
  %3335 : int = aten::size(%x.97, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3336 : int = aten::size(%x.97, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3337 : int[] = prim::ListConstruct(%3335, %3336, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.98 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.97, %3337), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3339 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %query_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.98, %3339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3341 : int = aten::size(%x.99, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3342 : int = aten::size(%x.99, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3343 : int[] = prim::ListConstruct(%3341, %3342, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.100 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.99, %3343), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3345 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %key_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.100, %3345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3347 : int = aten::size(%x.101, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3348 : int = aten::size(%x.101, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3349 : int[] = prim::ListConstruct(%3347, %3348, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.102 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.101, %3349), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3351 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %value_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.102, %3351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3353 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.17, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.33 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.17, %3353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.34 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.33, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.313 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.34, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.314 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.313, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.314, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.33 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.17, %value_layer.17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:280:0
  %3360 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %3361 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.33, %3360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3361, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %3363 : int = aten::size(%context_layer.34, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3364 : int = aten::size(%context_layer.34, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3365 : int[] = prim::ListConstruct(%3363, %3364, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %input.315 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.34, %3365), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:283:0
  %3367 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16338.NoNorm = prim::GetAttr[name="LayerNorm"](%3315)
  %3368 : __torch__.torch.nn.modules.linear.___torch_mangle_16337.Linear = prim::GetAttr[name="dense"](%3315)
  %3369 : Tensor = prim::GetAttr[name="bias"](%3368)
  %3370 : Tensor = prim::GetAttr[name="weight"](%3368)
  %3371 : Float(128:1, 128:128) = aten::t(%3370), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %output.247 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.315, %3371), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.247, %3369, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.132 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.81, %3314, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output # transformers/modeling_mobilebert.py:301:0
  %3375 : Tensor = prim::GetAttr[name="bias"](%3367)
  %3376 : Tensor = prim::GetAttr[name="weight"](%3367)
  %3377 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.132, %3376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.316 : Float(17:1664, 13:128, 128:1) = aten::add(%3377, %3375, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3379 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16361.FFNOutput = prim::GetAttr[name="output"](%3285)
  %3380 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16358.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3285)
  %3381 : __torch__.torch.nn.modules.linear.___torch_mangle_16357.Linear = prim::GetAttr[name="dense"](%3380)
  %3382 : Tensor = prim::GetAttr[name="bias"](%3381)
  %3383 : Tensor = prim::GetAttr[name="weight"](%3381)
  %3384 : Float(128:1, 512:128) = aten::t(%3383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.248 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.316, %3384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.317 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.248, %3382, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.318 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3388 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16360.NoNorm = prim::GetAttr[name="LayerNorm"](%3379)
  %3389 : __torch__.torch.nn.modules.linear.___torch_mangle_16359.Linear = prim::GetAttr[name="dense"](%3379)
  %3390 : Tensor = prim::GetAttr[name="bias"](%3389)
  %3391 : Tensor = prim::GetAttr[name="weight"](%3389)
  %3392 : Float(512:1, 128:512) = aten::t(%3391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.249 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.318, %3392), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.249, %3390, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.133 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.82, %input.316, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3396 : Tensor = prim::GetAttr[name="bias"](%3388)
  %3397 : Tensor = prim::GetAttr[name="weight"](%3388)
  %3398 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.133, %3397), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.319 : Float(17:1664, 13:128, 128:1) = aten::add(%3398, %3396, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3400 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16367.FFNOutput = prim::GetAttr[name="output"](%3283)
  %3401 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16364.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3283)
  %3402 : __torch__.torch.nn.modules.linear.___torch_mangle_16363.Linear = prim::GetAttr[name="dense"](%3401)
  %3403 : Tensor = prim::GetAttr[name="bias"](%3402)
  %3404 : Tensor = prim::GetAttr[name="weight"](%3402)
  %3405 : Float(128:1, 512:128) = aten::t(%3404), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.250 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.319, %3405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.320 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.250, %3403, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.321 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3409 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16366.NoNorm = prim::GetAttr[name="LayerNorm"](%3400)
  %3410 : __torch__.torch.nn.modules.linear.___torch_mangle_16365.Linear = prim::GetAttr[name="dense"](%3400)
  %3411 : Tensor = prim::GetAttr[name="bias"](%3410)
  %3412 : Tensor = prim::GetAttr[name="weight"](%3410)
  %3413 : Float(512:1, 128:512) = aten::t(%3412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.251 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.321, %3413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.251, %3411, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.134 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.83, %input.319, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3417 : Tensor = prim::GetAttr[name="bias"](%3409)
  %3418 : Tensor = prim::GetAttr[name="weight"](%3409)
  %3419 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.134, %3418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.322 : Float(17:1664, 13:128, 128:1) = aten::add(%3419, %3417, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3421 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16373.FFNOutput = prim::GetAttr[name="output"](%3281)
  %3422 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16370.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3281)
  %3423 : __torch__.torch.nn.modules.linear.___torch_mangle_16369.Linear = prim::GetAttr[name="dense"](%3422)
  %3424 : Tensor = prim::GetAttr[name="bias"](%3423)
  %3425 : Tensor = prim::GetAttr[name="weight"](%3423)
  %3426 : Float(128:1, 512:128) = aten::t(%3425), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.252 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.322, %3426), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.323 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.252, %3424, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.324 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3430 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16372.NoNorm = prim::GetAttr[name="LayerNorm"](%3421)
  %3431 : __torch__.torch.nn.modules.linear.___torch_mangle_16371.Linear = prim::GetAttr[name="dense"](%3421)
  %3432 : Tensor = prim::GetAttr[name="bias"](%3431)
  %3433 : Tensor = prim::GetAttr[name="weight"](%3431)
  %3434 : Float(512:1, 128:512) = aten::t(%3433), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.253 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.324, %3434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.84 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.253, %3432, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.135 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.84, %input.322, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3438 : Tensor = prim::GetAttr[name="bias"](%3430)
  %3439 : Tensor = prim::GetAttr[name="weight"](%3430)
  %3440 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.135, %3439), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.325 : Float(17:1664, 13:128, 128:1) = aten::add(%3440, %3438, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3442 : __torch__.torch.nn.modules.linear.___torch_mangle_16341.Linear = prim::GetAttr[name="dense"](%3279)
  %3443 : Tensor = prim::GetAttr[name="bias"](%3442)
  %3444 : Tensor = prim::GetAttr[name="weight"](%3442)
  %3445 : Float(128:1, 512:128) = aten::t(%3444), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %output.254 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.325, %3445), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %input.326 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.254, %3443, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1678:0
  %input.327 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate # torch/nn/functional.py:1119:0
  %3449 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16348.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3278)
  %3450 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16344.NoNorm = prim::GetAttr[name="LayerNorm"](%3278)
  %3451 : __torch__.torch.nn.modules.linear.___torch_mangle_16343.Linear = prim::GetAttr[name="dense"](%3278)
  %3452 : Tensor = prim::GetAttr[name="bias"](%3451)
  %3453 : Tensor = prim::GetAttr[name="weight"](%3451)
  %3454 : Float(512:1, 128:512) = aten::t(%3453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %output.255 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.327, %3454), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %layer_output.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.255, %3452, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.136 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.17, %input.325, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output # transformers/modeling_mobilebert.py:405:0
  %3458 : Tensor = prim::GetAttr[name="bias"](%3450)
  %3459 : Tensor = prim::GetAttr[name="weight"](%3450)
  %3460 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.136, %3459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.328 : Float(17:1664, 13:128, 128:1) = aten::add(%3460, %3458, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3462 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16346.NoNorm = prim::GetAttr[name="LayerNorm"](%3449)
  %3463 : __torch__.torch.nn.modules.linear.___torch_mangle_16345.Linear = prim::GetAttr[name="dense"](%3449)
  %3464 : Tensor = prim::GetAttr[name="bias"](%3463)
  %3465 : Tensor = prim::GetAttr[name="weight"](%3463)
  %3466 : Float(128:1, 512:128) = aten::t(%3465), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.256 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.328, %3466), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.329 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.256, %3464, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.85 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.329, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.137 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.85, %input.311, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3471 : Tensor = prim::GetAttr[name="bias"](%3462)
  %3472 : Tensor = prim::GetAttr[name="weight"](%3462)
  %3473 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.137, %3472), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.330 : Float(17:6656, 13:512, 512:1) = aten::add(%3473, %3471, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3475 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16394.MobileBertOutput = prim::GetAttr[name="output"](%91)
  %3476 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16387.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%91)
  %3477 : __torch__.torch.nn.modules.container.___torch_mangle_16420.ModuleList = prim::GetAttr[name="ffn"](%91)
  %3478 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16419.FFNLayer = prim::GetAttr[name="2"](%3477)
  %3479 : __torch__.torch.nn.modules.container.___torch_mangle_16420.ModuleList = prim::GetAttr[name="ffn"](%91)
  %3480 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16413.FFNLayer = prim::GetAttr[name="1"](%3479)
  %3481 : __torch__.torch.nn.modules.container.___torch_mangle_16420.ModuleList = prim::GetAttr[name="ffn"](%91)
  %3482 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16407.FFNLayer = prim::GetAttr[name="0"](%3481)
  %3483 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16385.MobileBertAttention = prim::GetAttr[name="attention"](%91)
  %3484 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16401.Bottleneck = prim::GetAttr[name="bottleneck"](%91)
  %3485 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16400.BottleneckLayer = prim::GetAttr[name="attention"](%3484)
  %3486 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16397.BottleneckLayer = prim::GetAttr[name="input"](%3484)
  %3487 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16396.NoNorm = prim::GetAttr[name="LayerNorm"](%3486)
  %3488 : __torch__.torch.nn.modules.linear.___torch_mangle_16395.Linear = prim::GetAttr[name="dense"](%3486)
  %3489 : Tensor = prim::GetAttr[name="bias"](%3488)
  %3490 : Tensor = prim::GetAttr[name="weight"](%3488)
  %3491 : Float(512:1, 128:512) = aten::t(%3490), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.257 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3491), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.138 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.257, %3489, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3494 : Tensor = prim::GetAttr[name="bias"](%3487)
  %3495 : Tensor = prim::GetAttr[name="weight"](%3487)
  %3496 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.138, %3495), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add(%3496, %3494, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16399.NoNorm = prim::GetAttr[name="LayerNorm"](%3485)
  %3499 : __torch__.torch.nn.modules.linear.___torch_mangle_16398.Linear = prim::GetAttr[name="dense"](%3485)
  %3500 : Tensor = prim::GetAttr[name="bias"](%3499)
  %3501 : Tensor = prim::GetAttr[name="weight"](%3499)
  %3502 : Float(512:1, 128:512) = aten::t(%3501), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.258 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3502), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.258, %3500, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3505 : Tensor = prim::GetAttr[name="bias"](%3498)
  %3506 : Tensor = prim::GetAttr[name="weight"](%3498)
  %3507 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.139, %3506), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.331 : Float(17:1664, 13:128, 128:1) = aten::add(%3507, %3505, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3509 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.331, %residual_tensor.18)
  %3510 : Float(17:1664, 13:128, 128:1), %3511 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3509)
  %3512 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16384.MobileBertSelfOutput = prim::GetAttr[name="output"](%3483)
  %3513 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16381.MobileBertSelfAttention = prim::GetAttr[name="self"](%3483)
  %3514 : __torch__.torch.nn.modules.linear.___torch_mangle_16379.Linear = prim::GetAttr[name="value"](%3513)
  %3515 : __torch__.torch.nn.modules.linear.___torch_mangle_16378.Linear = prim::GetAttr[name="key"](%3513)
  %3516 : __torch__.torch.nn.modules.linear.___torch_mangle_16377.Linear = prim::GetAttr[name="query"](%3513)
  %3517 : Tensor = prim::GetAttr[name="bias"](%3516)
  %3518 : Tensor = prim::GetAttr[name="weight"](%3516)
  %3519 : Float(128:1, 128:128) = aten::t(%3518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %output.259 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3510, %3519), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %x.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.259, %3517, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1678:0
  %3522 : Tensor = prim::GetAttr[name="bias"](%3515)
  %3523 : Tensor = prim::GetAttr[name="weight"](%3515)
  %3524 : Float(128:1, 128:128) = aten::t(%3523), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %output.260 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3510, %3524), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %x.105 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.260, %3522, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1678:0
  %3527 : Tensor = prim::GetAttr[name="bias"](%3514)
  %3528 : Tensor = prim::GetAttr[name="weight"](%3514)
  %3529 : Float(512:1, 128:512) = aten::t(%3528), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %output.261 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3529), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %x.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.261, %3527, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1678:0
  %3532 : int = aten::size(%x.103, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3533 : int = aten::size(%x.103, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3534 : int[] = prim::ListConstruct(%3532, %3533, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.104 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.103, %3534), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3536 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %query_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.104, %3536), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3538 : int = aten::size(%x.105, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3539 : int = aten::size(%x.105, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3540 : int[] = prim::ListConstruct(%3538, %3539, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.106 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.105, %3540), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3542 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %key_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.106, %3542), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3544 : int = aten::size(%x.107, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3545 : int = aten::size(%x.107, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3546 : int[] = prim::ListConstruct(%3544, %3545, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.108 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.107, %3546), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3548 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %value_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.108, %3548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3550 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.18, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.35 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.18, %3550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.36 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.35, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.332 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.36, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.333 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.332, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.333, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.35 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.18, %value_layer.18), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:280:0
  %3557 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %3558 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.35, %3557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3558, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %3560 : int = aten::size(%context_layer.36, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3561 : int = aten::size(%context_layer.36, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3562 : int[] = prim::ListConstruct(%3560, %3561, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %input.334 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.36, %3562), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:283:0
  %3564 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16383.NoNorm = prim::GetAttr[name="LayerNorm"](%3512)
  %3565 : __torch__.torch.nn.modules.linear.___torch_mangle_16382.Linear = prim::GetAttr[name="dense"](%3512)
  %3566 : Tensor = prim::GetAttr[name="bias"](%3565)
  %3567 : Tensor = prim::GetAttr[name="weight"](%3565)
  %3568 : Float(128:1, 128:128) = aten::t(%3567), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %output.262 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.334, %3568), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.86 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.262, %3566, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.140 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.86, %3511, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output # transformers/modeling_mobilebert.py:301:0
  %3572 : Tensor = prim::GetAttr[name="bias"](%3564)
  %3573 : Tensor = prim::GetAttr[name="weight"](%3564)
  %3574 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.140, %3573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.335 : Float(17:1664, 13:128, 128:1) = aten::add(%3574, %3572, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3576 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16406.FFNOutput = prim::GetAttr[name="output"](%3482)
  %3577 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16403.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3482)
  %3578 : __torch__.torch.nn.modules.linear.___torch_mangle_16402.Linear = prim::GetAttr[name="dense"](%3577)
  %3579 : Tensor = prim::GetAttr[name="bias"](%3578)
  %3580 : Tensor = prim::GetAttr[name="weight"](%3578)
  %3581 : Float(128:1, 512:128) = aten::t(%3580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.263 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.335, %3581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.336 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.263, %3579, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.337 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3585 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16405.NoNorm = prim::GetAttr[name="LayerNorm"](%3576)
  %3586 : __torch__.torch.nn.modules.linear.___torch_mangle_16404.Linear = prim::GetAttr[name="dense"](%3576)
  %3587 : Tensor = prim::GetAttr[name="bias"](%3586)
  %3588 : Tensor = prim::GetAttr[name="weight"](%3586)
  %3589 : Float(512:1, 128:512) = aten::t(%3588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.264 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.337, %3589), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.264, %3587, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.141 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.87, %input.335, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3593 : Tensor = prim::GetAttr[name="bias"](%3585)
  %3594 : Tensor = prim::GetAttr[name="weight"](%3585)
  %3595 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.141, %3594), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.338 : Float(17:1664, 13:128, 128:1) = aten::add(%3595, %3593, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3597 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16412.FFNOutput = prim::GetAttr[name="output"](%3480)
  %3598 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16409.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3480)
  %3599 : __torch__.torch.nn.modules.linear.___torch_mangle_16408.Linear = prim::GetAttr[name="dense"](%3598)
  %3600 : Tensor = prim::GetAttr[name="bias"](%3599)
  %3601 : Tensor = prim::GetAttr[name="weight"](%3599)
  %3602 : Float(128:1, 512:128) = aten::t(%3601), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.265 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.338, %3602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.339 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.265, %3600, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.340 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3606 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16411.NoNorm = prim::GetAttr[name="LayerNorm"](%3597)
  %3607 : __torch__.torch.nn.modules.linear.___torch_mangle_16410.Linear = prim::GetAttr[name="dense"](%3597)
  %3608 : Tensor = prim::GetAttr[name="bias"](%3607)
  %3609 : Tensor = prim::GetAttr[name="weight"](%3607)
  %3610 : Float(512:1, 128:512) = aten::t(%3609), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.266 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.340, %3610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.88 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.266, %3608, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.142 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.88, %input.338, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3614 : Tensor = prim::GetAttr[name="bias"](%3606)
  %3615 : Tensor = prim::GetAttr[name="weight"](%3606)
  %3616 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.142, %3615), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.341 : Float(17:1664, 13:128, 128:1) = aten::add(%3616, %3614, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3618 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16418.FFNOutput = prim::GetAttr[name="output"](%3478)
  %3619 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16415.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3478)
  %3620 : __torch__.torch.nn.modules.linear.___torch_mangle_16414.Linear = prim::GetAttr[name="dense"](%3619)
  %3621 : Tensor = prim::GetAttr[name="bias"](%3620)
  %3622 : Tensor = prim::GetAttr[name="weight"](%3620)
  %3623 : Float(128:1, 512:128) = aten::t(%3622), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.267 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.341, %3623), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.342 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.267, %3621, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.343 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3627 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16417.NoNorm = prim::GetAttr[name="LayerNorm"](%3618)
  %3628 : __torch__.torch.nn.modules.linear.___torch_mangle_16416.Linear = prim::GetAttr[name="dense"](%3618)
  %3629 : Tensor = prim::GetAttr[name="bias"](%3628)
  %3630 : Tensor = prim::GetAttr[name="weight"](%3628)
  %3631 : Float(512:1, 128:512) = aten::t(%3630), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.268 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.343, %3631), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.268, %3629, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.143 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.89, %input.341, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3635 : Tensor = prim::GetAttr[name="bias"](%3627)
  %3636 : Tensor = prim::GetAttr[name="weight"](%3627)
  %3637 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.143, %3636), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.344 : Float(17:1664, 13:128, 128:1) = aten::add(%3637, %3635, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3639 : __torch__.torch.nn.modules.linear.___torch_mangle_16386.Linear = prim::GetAttr[name="dense"](%3476)
  %3640 : Tensor = prim::GetAttr[name="bias"](%3639)
  %3641 : Tensor = prim::GetAttr[name="weight"](%3639)
  %3642 : Float(128:1, 512:128) = aten::t(%3641), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %output.269 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.344, %3642), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %input.345 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.269, %3640, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1678:0
  %input.346 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate # torch/nn/functional.py:1119:0
  %3646 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16393.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3475)
  %3647 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16389.NoNorm = prim::GetAttr[name="LayerNorm"](%3475)
  %3648 : __torch__.torch.nn.modules.linear.___torch_mangle_16388.Linear = prim::GetAttr[name="dense"](%3475)
  %3649 : Tensor = prim::GetAttr[name="bias"](%3648)
  %3650 : Tensor = prim::GetAttr[name="weight"](%3648)
  %3651 : Float(512:1, 128:512) = aten::t(%3650), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %output.270 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.346, %3651), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %layer_output.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.270, %3649, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.144 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.18, %input.344, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output # transformers/modeling_mobilebert.py:405:0
  %3655 : Tensor = prim::GetAttr[name="bias"](%3647)
  %3656 : Tensor = prim::GetAttr[name="weight"](%3647)
  %3657 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.144, %3656), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.347 : Float(17:1664, 13:128, 128:1) = aten::add(%3657, %3655, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3659 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16391.NoNorm = prim::GetAttr[name="LayerNorm"](%3646)
  %3660 : __torch__.torch.nn.modules.linear.___torch_mangle_16390.Linear = prim::GetAttr[name="dense"](%3646)
  %3661 : Tensor = prim::GetAttr[name="bias"](%3660)
  %3662 : Tensor = prim::GetAttr[name="weight"](%3660)
  %3663 : Float(128:1, 512:128) = aten::t(%3662), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.271 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.347, %3663), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.348 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.271, %3661, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.90 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.348, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.145 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.90, %input.330, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3668 : Tensor = prim::GetAttr[name="bias"](%3659)
  %3669 : Tensor = prim::GetAttr[name="weight"](%3659)
  %3670 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.145, %3669), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.349 : Float(17:6656, 13:512, 512:1) = aten::add(%3670, %3668, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3672 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16439.MobileBertOutput = prim::GetAttr[name="output"](%89)
  %3673 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16432.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%89)
  %3674 : __torch__.torch.nn.modules.container.___torch_mangle_16465.ModuleList = prim::GetAttr[name="ffn"](%89)
  %3675 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16464.FFNLayer = prim::GetAttr[name="2"](%3674)
  %3676 : __torch__.torch.nn.modules.container.___torch_mangle_16465.ModuleList = prim::GetAttr[name="ffn"](%89)
  %3677 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16458.FFNLayer = prim::GetAttr[name="1"](%3676)
  %3678 : __torch__.torch.nn.modules.container.___torch_mangle_16465.ModuleList = prim::GetAttr[name="ffn"](%89)
  %3679 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16452.FFNLayer = prim::GetAttr[name="0"](%3678)
  %3680 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16430.MobileBertAttention = prim::GetAttr[name="attention"](%89)
  %3681 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16446.Bottleneck = prim::GetAttr[name="bottleneck"](%89)
  %3682 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16445.BottleneckLayer = prim::GetAttr[name="attention"](%3681)
  %3683 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16442.BottleneckLayer = prim::GetAttr[name="input"](%3681)
  %3684 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16441.NoNorm = prim::GetAttr[name="LayerNorm"](%3683)
  %3685 : __torch__.torch.nn.modules.linear.___torch_mangle_16440.Linear = prim::GetAttr[name="dense"](%3683)
  %3686 : Tensor = prim::GetAttr[name="bias"](%3685)
  %3687 : Tensor = prim::GetAttr[name="weight"](%3685)
  %3688 : Float(512:1, 128:512) = aten::t(%3687), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.272 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3688), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.146 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.272, %3686, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3691 : Tensor = prim::GetAttr[name="bias"](%3684)
  %3692 : Tensor = prim::GetAttr[name="weight"](%3684)
  %3693 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.146, %3692), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add(%3693, %3691, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16444.NoNorm = prim::GetAttr[name="LayerNorm"](%3682)
  %3696 : __torch__.torch.nn.modules.linear.___torch_mangle_16443.Linear = prim::GetAttr[name="dense"](%3682)
  %3697 : Tensor = prim::GetAttr[name="bias"](%3696)
  %3698 : Tensor = prim::GetAttr[name="weight"](%3696)
  %3699 : Float(512:1, 128:512) = aten::t(%3698), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.273 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3699), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.147 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.273, %3697, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3702 : Tensor = prim::GetAttr[name="bias"](%3695)
  %3703 : Tensor = prim::GetAttr[name="weight"](%3695)
  %3704 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.147, %3703), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.350 : Float(17:1664, 13:128, 128:1) = aten::add(%3704, %3702, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3706 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.350, %residual_tensor.19)
  %3707 : Float(17:1664, 13:128, 128:1), %3708 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3706)
  %3709 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16429.MobileBertSelfOutput = prim::GetAttr[name="output"](%3680)
  %3710 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16426.MobileBertSelfAttention = prim::GetAttr[name="self"](%3680)
  %3711 : __torch__.torch.nn.modules.linear.___torch_mangle_16424.Linear = prim::GetAttr[name="value"](%3710)
  %3712 : __torch__.torch.nn.modules.linear.___torch_mangle_16423.Linear = prim::GetAttr[name="key"](%3710)
  %3713 : __torch__.torch.nn.modules.linear.___torch_mangle_16422.Linear = prim::GetAttr[name="query"](%3710)
  %3714 : Tensor = prim::GetAttr[name="bias"](%3713)
  %3715 : Tensor = prim::GetAttr[name="weight"](%3713)
  %3716 : Float(128:1, 128:128) = aten::t(%3715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %output.274 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3707, %3716), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %x.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.274, %3714, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1678:0
  %3719 : Tensor = prim::GetAttr[name="bias"](%3712)
  %3720 : Tensor = prim::GetAttr[name="weight"](%3712)
  %3721 : Float(128:1, 128:128) = aten::t(%3720), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %output.275 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3707, %3721), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %x.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.275, %3719, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1678:0
  %3724 : Tensor = prim::GetAttr[name="bias"](%3711)
  %3725 : Tensor = prim::GetAttr[name="weight"](%3711)
  %3726 : Float(512:1, 128:512) = aten::t(%3725), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %output.276 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3726), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %x.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.276, %3724, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1678:0
  %3729 : int = aten::size(%x.109, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3730 : int = aten::size(%x.109, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3731 : int[] = prim::ListConstruct(%3729, %3730, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.110 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.109, %3731), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3733 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %query_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.110, %3733), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3735 : int = aten::size(%x.111, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3736 : int = aten::size(%x.111, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3737 : int[] = prim::ListConstruct(%3735, %3736, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.112 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.111, %3737), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3739 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %key_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.112, %3739), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3741 : int = aten::size(%x.113, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3742 : int = aten::size(%x.113, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3743 : int[] = prim::ListConstruct(%3741, %3742, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.114 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.113, %3743), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3745 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %value_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.114, %3745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3747 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.19, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.37 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.19, %3747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.38 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.37, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.351 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.38, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.352 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.351, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.352, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.37 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.19, %value_layer.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:280:0
  %3754 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %3755 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.37, %3754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3755, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %3757 : int = aten::size(%context_layer.38, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3758 : int = aten::size(%context_layer.38, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3759 : int[] = prim::ListConstruct(%3757, %3758, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %input.353 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.38, %3759), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:283:0
  %3761 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16428.NoNorm = prim::GetAttr[name="LayerNorm"](%3709)
  %3762 : __torch__.torch.nn.modules.linear.___torch_mangle_16427.Linear = prim::GetAttr[name="dense"](%3709)
  %3763 : Tensor = prim::GetAttr[name="bias"](%3762)
  %3764 : Tensor = prim::GetAttr[name="weight"](%3762)
  %3765 : Float(128:1, 128:128) = aten::t(%3764), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %output.277 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.353, %3765), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.277, %3763, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.148 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.91, %3708, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output # transformers/modeling_mobilebert.py:301:0
  %3769 : Tensor = prim::GetAttr[name="bias"](%3761)
  %3770 : Tensor = prim::GetAttr[name="weight"](%3761)
  %3771 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.148, %3770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.354 : Float(17:1664, 13:128, 128:1) = aten::add(%3771, %3769, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3773 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16451.FFNOutput = prim::GetAttr[name="output"](%3679)
  %3774 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16448.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3679)
  %3775 : __torch__.torch.nn.modules.linear.___torch_mangle_16447.Linear = prim::GetAttr[name="dense"](%3774)
  %3776 : Tensor = prim::GetAttr[name="bias"](%3775)
  %3777 : Tensor = prim::GetAttr[name="weight"](%3775)
  %3778 : Float(128:1, 512:128) = aten::t(%3777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.278 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.354, %3778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.355 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.278, %3776, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.356 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3782 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16450.NoNorm = prim::GetAttr[name="LayerNorm"](%3773)
  %3783 : __torch__.torch.nn.modules.linear.___torch_mangle_16449.Linear = prim::GetAttr[name="dense"](%3773)
  %3784 : Tensor = prim::GetAttr[name="bias"](%3783)
  %3785 : Tensor = prim::GetAttr[name="weight"](%3783)
  %3786 : Float(512:1, 128:512) = aten::t(%3785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.279 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.356, %3786), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.92 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.279, %3784, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.149 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.92, %input.354, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3790 : Tensor = prim::GetAttr[name="bias"](%3782)
  %3791 : Tensor = prim::GetAttr[name="weight"](%3782)
  %3792 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.149, %3791), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.357 : Float(17:1664, 13:128, 128:1) = aten::add(%3792, %3790, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3794 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16457.FFNOutput = prim::GetAttr[name="output"](%3677)
  %3795 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16454.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3677)
  %3796 : __torch__.torch.nn.modules.linear.___torch_mangle_16453.Linear = prim::GetAttr[name="dense"](%3795)
  %3797 : Tensor = prim::GetAttr[name="bias"](%3796)
  %3798 : Tensor = prim::GetAttr[name="weight"](%3796)
  %3799 : Float(128:1, 512:128) = aten::t(%3798), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.280 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.357, %3799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.358 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.280, %3797, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.359 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3803 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16456.NoNorm = prim::GetAttr[name="LayerNorm"](%3794)
  %3804 : __torch__.torch.nn.modules.linear.___torch_mangle_16455.Linear = prim::GetAttr[name="dense"](%3794)
  %3805 : Tensor = prim::GetAttr[name="bias"](%3804)
  %3806 : Tensor = prim::GetAttr[name="weight"](%3804)
  %3807 : Float(512:1, 128:512) = aten::t(%3806), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.281 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.359, %3807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.281, %3805, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.150 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.93, %input.357, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3811 : Tensor = prim::GetAttr[name="bias"](%3803)
  %3812 : Tensor = prim::GetAttr[name="weight"](%3803)
  %3813 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.150, %3812), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.360 : Float(17:1664, 13:128, 128:1) = aten::add(%3813, %3811, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3815 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16463.FFNOutput = prim::GetAttr[name="output"](%3675)
  %3816 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16460.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3675)
  %3817 : __torch__.torch.nn.modules.linear.___torch_mangle_16459.Linear = prim::GetAttr[name="dense"](%3816)
  %3818 : Tensor = prim::GetAttr[name="bias"](%3817)
  %3819 : Tensor = prim::GetAttr[name="weight"](%3817)
  %3820 : Float(128:1, 512:128) = aten::t(%3819), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.282 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.360, %3820), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.361 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.282, %3818, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.362 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3824 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16462.NoNorm = prim::GetAttr[name="LayerNorm"](%3815)
  %3825 : __torch__.torch.nn.modules.linear.___torch_mangle_16461.Linear = prim::GetAttr[name="dense"](%3815)
  %3826 : Tensor = prim::GetAttr[name="bias"](%3825)
  %3827 : Tensor = prim::GetAttr[name="weight"](%3825)
  %3828 : Float(512:1, 128:512) = aten::t(%3827), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.283 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.362, %3828), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.94 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.283, %3826, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.151 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.94, %input.360, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3832 : Tensor = prim::GetAttr[name="bias"](%3824)
  %3833 : Tensor = prim::GetAttr[name="weight"](%3824)
  %3834 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.151, %3833), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.363 : Float(17:1664, 13:128, 128:1) = aten::add(%3834, %3832, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3836 : __torch__.torch.nn.modules.linear.___torch_mangle_16431.Linear = prim::GetAttr[name="dense"](%3673)
  %3837 : Tensor = prim::GetAttr[name="bias"](%3836)
  %3838 : Tensor = prim::GetAttr[name="weight"](%3836)
  %3839 : Float(128:1, 512:128) = aten::t(%3838), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %output.284 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.363, %3839), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %input.364 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.284, %3837, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1678:0
  %input.365 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate # torch/nn/functional.py:1119:0
  %3843 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16438.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3672)
  %3844 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16434.NoNorm = prim::GetAttr[name="LayerNorm"](%3672)
  %3845 : __torch__.torch.nn.modules.linear.___torch_mangle_16433.Linear = prim::GetAttr[name="dense"](%3672)
  %3846 : Tensor = prim::GetAttr[name="bias"](%3845)
  %3847 : Tensor = prim::GetAttr[name="weight"](%3845)
  %3848 : Float(512:1, 128:512) = aten::t(%3847), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %output.285 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.365, %3848), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %layer_output.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.285, %3846, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.152 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.19, %input.363, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output # transformers/modeling_mobilebert.py:405:0
  %3852 : Tensor = prim::GetAttr[name="bias"](%3844)
  %3853 : Tensor = prim::GetAttr[name="weight"](%3844)
  %3854 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.152, %3853), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.366 : Float(17:1664, 13:128, 128:1) = aten::add(%3854, %3852, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3856 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16436.NoNorm = prim::GetAttr[name="LayerNorm"](%3843)
  %3857 : __torch__.torch.nn.modules.linear.___torch_mangle_16435.Linear = prim::GetAttr[name="dense"](%3843)
  %3858 : Tensor = prim::GetAttr[name="bias"](%3857)
  %3859 : Tensor = prim::GetAttr[name="weight"](%3857)
  %3860 : Float(128:1, 512:128) = aten::t(%3859), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.286 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.366, %3860), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.367 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.286, %3858, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.95 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.367, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.153 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.95, %input.349, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3865 : Tensor = prim::GetAttr[name="bias"](%3856)
  %3866 : Tensor = prim::GetAttr[name="weight"](%3856)
  %3867 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.153, %3866), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.368 : Float(17:6656, 13:512, 512:1) = aten::add(%3867, %3865, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3869 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16484.MobileBertOutput = prim::GetAttr[name="output"](%87)
  %3870 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16477.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%87)
  %3871 : __torch__.torch.nn.modules.container.___torch_mangle_16510.ModuleList = prim::GetAttr[name="ffn"](%87)
  %3872 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16509.FFNLayer = prim::GetAttr[name="2"](%3871)
  %3873 : __torch__.torch.nn.modules.container.___torch_mangle_16510.ModuleList = prim::GetAttr[name="ffn"](%87)
  %3874 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16503.FFNLayer = prim::GetAttr[name="1"](%3873)
  %3875 : __torch__.torch.nn.modules.container.___torch_mangle_16510.ModuleList = prim::GetAttr[name="ffn"](%87)
  %3876 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16497.FFNLayer = prim::GetAttr[name="0"](%3875)
  %3877 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16475.MobileBertAttention = prim::GetAttr[name="attention"](%87)
  %3878 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16491.Bottleneck = prim::GetAttr[name="bottleneck"](%87)
  %3879 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16490.BottleneckLayer = prim::GetAttr[name="attention"](%3878)
  %3880 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16487.BottleneckLayer = prim::GetAttr[name="input"](%3878)
  %3881 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16486.NoNorm = prim::GetAttr[name="LayerNorm"](%3880)
  %3882 : __torch__.torch.nn.modules.linear.___torch_mangle_16485.Linear = prim::GetAttr[name="dense"](%3880)
  %3883 : Tensor = prim::GetAttr[name="bias"](%3882)
  %3884 : Tensor = prim::GetAttr[name="weight"](%3882)
  %3885 : Float(512:1, 128:512) = aten::t(%3884), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.287 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3885), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.154 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.287, %3883, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3888 : Tensor = prim::GetAttr[name="bias"](%3881)
  %3889 : Tensor = prim::GetAttr[name="weight"](%3881)
  %3890 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.154, %3889), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%3890, %3888, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3892 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16489.NoNorm = prim::GetAttr[name="LayerNorm"](%3879)
  %3893 : __torch__.torch.nn.modules.linear.___torch_mangle_16488.Linear = prim::GetAttr[name="dense"](%3879)
  %3894 : Tensor = prim::GetAttr[name="bias"](%3893)
  %3895 : Tensor = prim::GetAttr[name="weight"](%3893)
  %3896 : Float(512:1, 128:512) = aten::t(%3895), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.288 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3896), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.155 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.288, %3894, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3899 : Tensor = prim::GetAttr[name="bias"](%3892)
  %3900 : Tensor = prim::GetAttr[name="weight"](%3892)
  %3901 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.155, %3900), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.369 : Float(17:1664, 13:128, 128:1) = aten::add(%3901, %3899, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3903 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.369, %residual_tensor.20)
  %3904 : Float(17:1664, 13:128, 128:1), %3905 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3903)
  %3906 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16474.MobileBertSelfOutput = prim::GetAttr[name="output"](%3877)
  %3907 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16471.MobileBertSelfAttention = prim::GetAttr[name="self"](%3877)
  %3908 : __torch__.torch.nn.modules.linear.___torch_mangle_16469.Linear = prim::GetAttr[name="value"](%3907)
  %3909 : __torch__.torch.nn.modules.linear.___torch_mangle_16468.Linear = prim::GetAttr[name="key"](%3907)
  %3910 : __torch__.torch.nn.modules.linear.___torch_mangle_16467.Linear = prim::GetAttr[name="query"](%3907)
  %3911 : Tensor = prim::GetAttr[name="bias"](%3910)
  %3912 : Tensor = prim::GetAttr[name="weight"](%3910)
  %3913 : Float(128:1, 128:128) = aten::t(%3912), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %output.289 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3904, %3913), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %x.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.289, %3911, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1678:0
  %3916 : Tensor = prim::GetAttr[name="bias"](%3909)
  %3917 : Tensor = prim::GetAttr[name="weight"](%3909)
  %3918 : Float(128:1, 128:128) = aten::t(%3917), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %output.290 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3904, %3918), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %x.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.290, %3916, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1678:0
  %3921 : Tensor = prim::GetAttr[name="bias"](%3908)
  %3922 : Tensor = prim::GetAttr[name="weight"](%3908)
  %3923 : Float(512:1, 128:512) = aten::t(%3922), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %output.291 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3923), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %x.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.291, %3921, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1678:0
  %3926 : int = aten::size(%x.115, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3927 : int = aten::size(%x.115, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3928 : int[] = prim::ListConstruct(%3926, %3927, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.116 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.115, %3928), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3930 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %query_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.116, %3930), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3932 : int = aten::size(%x.117, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3933 : int = aten::size(%x.117, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3934 : int[] = prim::ListConstruct(%3932, %3933, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.118 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.117, %3934), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3936 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %key_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.118, %3936), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3938 : int = aten::size(%x.119, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3939 : int = aten::size(%x.119, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3940 : int[] = prim::ListConstruct(%3938, %3939, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.120 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.119, %3940), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3942 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %value_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.120, %3942), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3944 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.20, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.39 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.20, %3944), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.40 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.39, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.370 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.40, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.371 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.370, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.371, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.39 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.20, %value_layer.20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:280:0
  %3951 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %3952 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.39, %3951), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3952, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %3954 : int = aten::size(%context_layer.40, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3955 : int = aten::size(%context_layer.40, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3956 : int[] = prim::ListConstruct(%3954, %3955, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %input.372 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.40, %3956), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:283:0
  %3958 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16473.NoNorm = prim::GetAttr[name="LayerNorm"](%3906)
  %3959 : __torch__.torch.nn.modules.linear.___torch_mangle_16472.Linear = prim::GetAttr[name="dense"](%3906)
  %3960 : Tensor = prim::GetAttr[name="bias"](%3959)
  %3961 : Tensor = prim::GetAttr[name="weight"](%3959)
  %3962 : Float(128:1, 128:128) = aten::t(%3961), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %output.292 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.372, %3962), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.96 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.292, %3960, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.156 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.96, %3905, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output # transformers/modeling_mobilebert.py:301:0
  %3966 : Tensor = prim::GetAttr[name="bias"](%3958)
  %3967 : Tensor = prim::GetAttr[name="weight"](%3958)
  %3968 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.156, %3967), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.373 : Float(17:1664, 13:128, 128:1) = aten::add(%3968, %3966, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3970 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16496.FFNOutput = prim::GetAttr[name="output"](%3876)
  %3971 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16493.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3876)
  %3972 : __torch__.torch.nn.modules.linear.___torch_mangle_16492.Linear = prim::GetAttr[name="dense"](%3971)
  %3973 : Tensor = prim::GetAttr[name="bias"](%3972)
  %3974 : Tensor = prim::GetAttr[name="weight"](%3972)
  %3975 : Float(128:1, 512:128) = aten::t(%3974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.293 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.373, %3975), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.374 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.293, %3973, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.375 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3979 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16495.NoNorm = prim::GetAttr[name="LayerNorm"](%3970)
  %3980 : __torch__.torch.nn.modules.linear.___torch_mangle_16494.Linear = prim::GetAttr[name="dense"](%3970)
  %3981 : Tensor = prim::GetAttr[name="bias"](%3980)
  %3982 : Tensor = prim::GetAttr[name="weight"](%3980)
  %3983 : Float(512:1, 128:512) = aten::t(%3982), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.294 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.375, %3983), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.294, %3981, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.157 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.97, %input.373, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3987 : Tensor = prim::GetAttr[name="bias"](%3979)
  %3988 : Tensor = prim::GetAttr[name="weight"](%3979)
  %3989 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.157, %3988), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.376 : Float(17:1664, 13:128, 128:1) = aten::add(%3989, %3987, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3991 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16502.FFNOutput = prim::GetAttr[name="output"](%3874)
  %3992 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16499.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3874)
  %3993 : __torch__.torch.nn.modules.linear.___torch_mangle_16498.Linear = prim::GetAttr[name="dense"](%3992)
  %3994 : Tensor = prim::GetAttr[name="bias"](%3993)
  %3995 : Tensor = prim::GetAttr[name="weight"](%3993)
  %3996 : Float(128:1, 512:128) = aten::t(%3995), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.295 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.376, %3996), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.377 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.295, %3994, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.378 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4000 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16501.NoNorm = prim::GetAttr[name="LayerNorm"](%3991)
  %4001 : __torch__.torch.nn.modules.linear.___torch_mangle_16500.Linear = prim::GetAttr[name="dense"](%3991)
  %4002 : Tensor = prim::GetAttr[name="bias"](%4001)
  %4003 : Tensor = prim::GetAttr[name="weight"](%4001)
  %4004 : Float(512:1, 128:512) = aten::t(%4003), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.296 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.378, %4004), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.296, %4002, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.158 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.98, %input.376, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4008 : Tensor = prim::GetAttr[name="bias"](%4000)
  %4009 : Tensor = prim::GetAttr[name="weight"](%4000)
  %4010 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.158, %4009), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.379 : Float(17:1664, 13:128, 128:1) = aten::add(%4010, %4008, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4012 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16508.FFNOutput = prim::GetAttr[name="output"](%3872)
  %4013 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16505.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3872)
  %4014 : __torch__.torch.nn.modules.linear.___torch_mangle_16504.Linear = prim::GetAttr[name="dense"](%4013)
  %4015 : Tensor = prim::GetAttr[name="bias"](%4014)
  %4016 : Tensor = prim::GetAttr[name="weight"](%4014)
  %4017 : Float(128:1, 512:128) = aten::t(%4016), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.297 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.379, %4017), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.380 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.297, %4015, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.381 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4021 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16507.NoNorm = prim::GetAttr[name="LayerNorm"](%4012)
  %4022 : __torch__.torch.nn.modules.linear.___torch_mangle_16506.Linear = prim::GetAttr[name="dense"](%4012)
  %4023 : Tensor = prim::GetAttr[name="bias"](%4022)
  %4024 : Tensor = prim::GetAttr[name="weight"](%4022)
  %4025 : Float(512:1, 128:512) = aten::t(%4024), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.298 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.381, %4025), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.298, %4023, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.159 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.99, %input.379, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4029 : Tensor = prim::GetAttr[name="bias"](%4021)
  %4030 : Tensor = prim::GetAttr[name="weight"](%4021)
  %4031 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.159, %4030), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.382 : Float(17:1664, 13:128, 128:1) = aten::add(%4031, %4029, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4033 : __torch__.torch.nn.modules.linear.___torch_mangle_16476.Linear = prim::GetAttr[name="dense"](%3870)
  %4034 : Tensor = prim::GetAttr[name="bias"](%4033)
  %4035 : Tensor = prim::GetAttr[name="weight"](%4033)
  %4036 : Float(128:1, 512:128) = aten::t(%4035), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %output.299 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.382, %4036), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %input.383 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.299, %4034, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1678:0
  %input.384 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate # torch/nn/functional.py:1119:0
  %4040 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16483.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3869)
  %4041 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16479.NoNorm = prim::GetAttr[name="LayerNorm"](%3869)
  %4042 : __torch__.torch.nn.modules.linear.___torch_mangle_16478.Linear = prim::GetAttr[name="dense"](%3869)
  %4043 : Tensor = prim::GetAttr[name="bias"](%4042)
  %4044 : Tensor = prim::GetAttr[name="weight"](%4042)
  %4045 : Float(512:1, 128:512) = aten::t(%4044), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %output.300 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.384, %4045), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %layer_output.20 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.300, %4043, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.160 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.20, %input.382, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output # transformers/modeling_mobilebert.py:405:0
  %4049 : Tensor = prim::GetAttr[name="bias"](%4041)
  %4050 : Tensor = prim::GetAttr[name="weight"](%4041)
  %4051 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.160, %4050), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.385 : Float(17:1664, 13:128, 128:1) = aten::add(%4051, %4049, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4053 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16481.NoNorm = prim::GetAttr[name="LayerNorm"](%4040)
  %4054 : __torch__.torch.nn.modules.linear.___torch_mangle_16480.Linear = prim::GetAttr[name="dense"](%4040)
  %4055 : Tensor = prim::GetAttr[name="bias"](%4054)
  %4056 : Tensor = prim::GetAttr[name="weight"](%4054)
  %4057 : Float(128:1, 512:128) = aten::t(%4056), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.301 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.385, %4057), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.386 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.301, %4055, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.100 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.386, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.161 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.100, %input.368, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4062 : Tensor = prim::GetAttr[name="bias"](%4053)
  %4063 : Tensor = prim::GetAttr[name="weight"](%4053)
  %4064 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.161, %4063), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.387 : Float(17:6656, 13:512, 512:1) = aten::add(%4064, %4062, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4066 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16529.MobileBertOutput = prim::GetAttr[name="output"](%85)
  %4067 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16522.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%85)
  %4068 : __torch__.torch.nn.modules.container.___torch_mangle_16555.ModuleList = prim::GetAttr[name="ffn"](%85)
  %4069 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16554.FFNLayer = prim::GetAttr[name="2"](%4068)
  %4070 : __torch__.torch.nn.modules.container.___torch_mangle_16555.ModuleList = prim::GetAttr[name="ffn"](%85)
  %4071 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16548.FFNLayer = prim::GetAttr[name="1"](%4070)
  %4072 : __torch__.torch.nn.modules.container.___torch_mangle_16555.ModuleList = prim::GetAttr[name="ffn"](%85)
  %4073 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16542.FFNLayer = prim::GetAttr[name="0"](%4072)
  %4074 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16520.MobileBertAttention = prim::GetAttr[name="attention"](%85)
  %4075 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16536.Bottleneck = prim::GetAttr[name="bottleneck"](%85)
  %4076 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16535.BottleneckLayer = prim::GetAttr[name="attention"](%4075)
  %4077 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16532.BottleneckLayer = prim::GetAttr[name="input"](%4075)
  %4078 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16531.NoNorm = prim::GetAttr[name="LayerNorm"](%4077)
  %4079 : __torch__.torch.nn.modules.linear.___torch_mangle_16530.Linear = prim::GetAttr[name="dense"](%4077)
  %4080 : Tensor = prim::GetAttr[name="bias"](%4079)
  %4081 : Tensor = prim::GetAttr[name="weight"](%4079)
  %4082 : Float(512:1, 128:512) = aten::t(%4081), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.302 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4082), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.162 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.302, %4080, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4085 : Tensor = prim::GetAttr[name="bias"](%4078)
  %4086 : Tensor = prim::GetAttr[name="weight"](%4078)
  %4087 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.162, %4086), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%4087, %4085, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4089 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16534.NoNorm = prim::GetAttr[name="LayerNorm"](%4076)
  %4090 : __torch__.torch.nn.modules.linear.___torch_mangle_16533.Linear = prim::GetAttr[name="dense"](%4076)
  %4091 : Tensor = prim::GetAttr[name="bias"](%4090)
  %4092 : Tensor = prim::GetAttr[name="weight"](%4090)
  %4093 : Float(512:1, 128:512) = aten::t(%4092), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.303 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4093), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.163 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.303, %4091, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4096 : Tensor = prim::GetAttr[name="bias"](%4089)
  %4097 : Tensor = prim::GetAttr[name="weight"](%4089)
  %4098 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.163, %4097), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.388 : Float(17:1664, 13:128, 128:1) = aten::add(%4098, %4096, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4100 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.388, %residual_tensor.21)
  %4101 : Float(17:1664, 13:128, 128:1), %4102 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4100)
  %4103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16519.MobileBertSelfOutput = prim::GetAttr[name="output"](%4074)
  %4104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16516.MobileBertSelfAttention = prim::GetAttr[name="self"](%4074)
  %4105 : __torch__.torch.nn.modules.linear.___torch_mangle_16514.Linear = prim::GetAttr[name="value"](%4104)
  %4106 : __torch__.torch.nn.modules.linear.___torch_mangle_16513.Linear = prim::GetAttr[name="key"](%4104)
  %4107 : __torch__.torch.nn.modules.linear.___torch_mangle_16512.Linear = prim::GetAttr[name="query"](%4104)
  %4108 : Tensor = prim::GetAttr[name="bias"](%4107)
  %4109 : Tensor = prim::GetAttr[name="weight"](%4107)
  %4110 : Float(128:1, 128:128) = aten::t(%4109), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %output.304 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4101, %4110), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %x.121 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.304, %4108, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1678:0
  %4113 : Tensor = prim::GetAttr[name="bias"](%4106)
  %4114 : Tensor = prim::GetAttr[name="weight"](%4106)
  %4115 : Float(128:1, 128:128) = aten::t(%4114), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %output.305 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4101, %4115), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %x.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.305, %4113, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1678:0
  %4118 : Tensor = prim::GetAttr[name="bias"](%4105)
  %4119 : Tensor = prim::GetAttr[name="weight"](%4105)
  %4120 : Float(512:1, 128:512) = aten::t(%4119), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %output.306 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4120), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %x.125 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.306, %4118, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1678:0
  %4123 : int = aten::size(%x.121, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4124 : int = aten::size(%x.121, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4125 : int[] = prim::ListConstruct(%4123, %4124, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.122 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.121, %4125), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4127 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %query_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.122, %4127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4129 : int = aten::size(%x.123, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4130 : int = aten::size(%x.123, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4131 : int[] = prim::ListConstruct(%4129, %4130, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.124 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.123, %4131), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4133 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %key_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.124, %4133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4135 : int = aten::size(%x.125, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4136 : int = aten::size(%x.125, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4137 : int[] = prim::ListConstruct(%4135, %4136, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.126 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.125, %4137), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4139 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %value_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.126, %4139), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4141 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.21, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.41 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.21, %4141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.42 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.41, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.389 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.42, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.390 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.389, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.390, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.41 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.21, %value_layer.21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:280:0
  %4148 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %4149 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.41, %4148), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4149, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %4151 : int = aten::size(%context_layer.42, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4152 : int = aten::size(%context_layer.42, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4153 : int[] = prim::ListConstruct(%4151, %4152, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %input.391 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.42, %4153), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:283:0
  %4155 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16518.NoNorm = prim::GetAttr[name="LayerNorm"](%4103)
  %4156 : __torch__.torch.nn.modules.linear.___torch_mangle_16517.Linear = prim::GetAttr[name="dense"](%4103)
  %4157 : Tensor = prim::GetAttr[name="bias"](%4156)
  %4158 : Tensor = prim::GetAttr[name="weight"](%4156)
  %4159 : Float(128:1, 128:128) = aten::t(%4158), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %output.307 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.391, %4159), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.307, %4157, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.164 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.101, %4102, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output # transformers/modeling_mobilebert.py:301:0
  %4163 : Tensor = prim::GetAttr[name="bias"](%4155)
  %4164 : Tensor = prim::GetAttr[name="weight"](%4155)
  %4165 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.164, %4164), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.392 : Float(17:1664, 13:128, 128:1) = aten::add(%4165, %4163, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4167 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16541.FFNOutput = prim::GetAttr[name="output"](%4073)
  %4168 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16538.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4073)
  %4169 : __torch__.torch.nn.modules.linear.___torch_mangle_16537.Linear = prim::GetAttr[name="dense"](%4168)
  %4170 : Tensor = prim::GetAttr[name="bias"](%4169)
  %4171 : Tensor = prim::GetAttr[name="weight"](%4169)
  %4172 : Float(128:1, 512:128) = aten::t(%4171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.308 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.392, %4172), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.393 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.308, %4170, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.394 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4176 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16540.NoNorm = prim::GetAttr[name="LayerNorm"](%4167)
  %4177 : __torch__.torch.nn.modules.linear.___torch_mangle_16539.Linear = prim::GetAttr[name="dense"](%4167)
  %4178 : Tensor = prim::GetAttr[name="bias"](%4177)
  %4179 : Tensor = prim::GetAttr[name="weight"](%4177)
  %4180 : Float(512:1, 128:512) = aten::t(%4179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.309 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.394, %4180), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.102 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.309, %4178, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.165 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.102, %input.392, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4184 : Tensor = prim::GetAttr[name="bias"](%4176)
  %4185 : Tensor = prim::GetAttr[name="weight"](%4176)
  %4186 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.165, %4185), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.395 : Float(17:1664, 13:128, 128:1) = aten::add(%4186, %4184, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4188 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16547.FFNOutput = prim::GetAttr[name="output"](%4071)
  %4189 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16544.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4071)
  %4190 : __torch__.torch.nn.modules.linear.___torch_mangle_16543.Linear = prim::GetAttr[name="dense"](%4189)
  %4191 : Tensor = prim::GetAttr[name="bias"](%4190)
  %4192 : Tensor = prim::GetAttr[name="weight"](%4190)
  %4193 : Float(128:1, 512:128) = aten::t(%4192), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.310 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.395, %4193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.396 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.310, %4191, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.397 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4197 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16546.NoNorm = prim::GetAttr[name="LayerNorm"](%4188)
  %4198 : __torch__.torch.nn.modules.linear.___torch_mangle_16545.Linear = prim::GetAttr[name="dense"](%4188)
  %4199 : Tensor = prim::GetAttr[name="bias"](%4198)
  %4200 : Tensor = prim::GetAttr[name="weight"](%4198)
  %4201 : Float(512:1, 128:512) = aten::t(%4200), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.311 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.397, %4201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.311, %4199, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.166 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.103, %input.395, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4205 : Tensor = prim::GetAttr[name="bias"](%4197)
  %4206 : Tensor = prim::GetAttr[name="weight"](%4197)
  %4207 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.166, %4206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.398 : Float(17:1664, 13:128, 128:1) = aten::add(%4207, %4205, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4209 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16553.FFNOutput = prim::GetAttr[name="output"](%4069)
  %4210 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16550.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4069)
  %4211 : __torch__.torch.nn.modules.linear.___torch_mangle_16549.Linear = prim::GetAttr[name="dense"](%4210)
  %4212 : Tensor = prim::GetAttr[name="bias"](%4211)
  %4213 : Tensor = prim::GetAttr[name="weight"](%4211)
  %4214 : Float(128:1, 512:128) = aten::t(%4213), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.312 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.398, %4214), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.399 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.312, %4212, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.400 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4218 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16552.NoNorm = prim::GetAttr[name="LayerNorm"](%4209)
  %4219 : __torch__.torch.nn.modules.linear.___torch_mangle_16551.Linear = prim::GetAttr[name="dense"](%4209)
  %4220 : Tensor = prim::GetAttr[name="bias"](%4219)
  %4221 : Tensor = prim::GetAttr[name="weight"](%4219)
  %4222 : Float(512:1, 128:512) = aten::t(%4221), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.313 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.400, %4222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.104 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.313, %4220, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.167 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.104, %input.398, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4226 : Tensor = prim::GetAttr[name="bias"](%4218)
  %4227 : Tensor = prim::GetAttr[name="weight"](%4218)
  %4228 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.167, %4227), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.401 : Float(17:1664, 13:128, 128:1) = aten::add(%4228, %4226, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4230 : __torch__.torch.nn.modules.linear.___torch_mangle_16521.Linear = prim::GetAttr[name="dense"](%4067)
  %4231 : Tensor = prim::GetAttr[name="bias"](%4230)
  %4232 : Tensor = prim::GetAttr[name="weight"](%4230)
  %4233 : Float(128:1, 512:128) = aten::t(%4232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %output.314 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.401, %4233), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %input.402 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.314, %4231, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1678:0
  %input.403 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate # torch/nn/functional.py:1119:0
  %4237 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16528.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4066)
  %4238 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16524.NoNorm = prim::GetAttr[name="LayerNorm"](%4066)
  %4239 : __torch__.torch.nn.modules.linear.___torch_mangle_16523.Linear = prim::GetAttr[name="dense"](%4066)
  %4240 : Tensor = prim::GetAttr[name="bias"](%4239)
  %4241 : Tensor = prim::GetAttr[name="weight"](%4239)
  %4242 : Float(512:1, 128:512) = aten::t(%4241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %output.315 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.403, %4242), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %layer_output.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.315, %4240, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.168 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.21, %input.401, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output # transformers/modeling_mobilebert.py:405:0
  %4246 : Tensor = prim::GetAttr[name="bias"](%4238)
  %4247 : Tensor = prim::GetAttr[name="weight"](%4238)
  %4248 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.168, %4247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.404 : Float(17:1664, 13:128, 128:1) = aten::add(%4248, %4246, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4250 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16526.NoNorm = prim::GetAttr[name="LayerNorm"](%4237)
  %4251 : __torch__.torch.nn.modules.linear.___torch_mangle_16525.Linear = prim::GetAttr[name="dense"](%4237)
  %4252 : Tensor = prim::GetAttr[name="bias"](%4251)
  %4253 : Tensor = prim::GetAttr[name="weight"](%4251)
  %4254 : Float(128:1, 512:128) = aten::t(%4253), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.316 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.404, %4254), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.405 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.316, %4252, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.105 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.405, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.169 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.105, %input.387, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4259 : Tensor = prim::GetAttr[name="bias"](%4250)
  %4260 : Tensor = prim::GetAttr[name="weight"](%4250)
  %4261 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.169, %4260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.406 : Float(17:6656, 13:512, 512:1) = aten::add(%4261, %4259, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4263 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16574.MobileBertOutput = prim::GetAttr[name="output"](%83)
  %4264 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16567.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%83)
  %4265 : __torch__.torch.nn.modules.container.___torch_mangle_16600.ModuleList = prim::GetAttr[name="ffn"](%83)
  %4266 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16599.FFNLayer = prim::GetAttr[name="2"](%4265)
  %4267 : __torch__.torch.nn.modules.container.___torch_mangle_16600.ModuleList = prim::GetAttr[name="ffn"](%83)
  %4268 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16593.FFNLayer = prim::GetAttr[name="1"](%4267)
  %4269 : __torch__.torch.nn.modules.container.___torch_mangle_16600.ModuleList = prim::GetAttr[name="ffn"](%83)
  %4270 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16587.FFNLayer = prim::GetAttr[name="0"](%4269)
  %4271 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16565.MobileBertAttention = prim::GetAttr[name="attention"](%83)
  %4272 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16581.Bottleneck = prim::GetAttr[name="bottleneck"](%83)
  %4273 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16580.BottleneckLayer = prim::GetAttr[name="attention"](%4272)
  %4274 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16577.BottleneckLayer = prim::GetAttr[name="input"](%4272)
  %4275 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16576.NoNorm = prim::GetAttr[name="LayerNorm"](%4274)
  %4276 : __torch__.torch.nn.modules.linear.___torch_mangle_16575.Linear = prim::GetAttr[name="dense"](%4274)
  %4277 : Tensor = prim::GetAttr[name="bias"](%4276)
  %4278 : Tensor = prim::GetAttr[name="weight"](%4276)
  %4279 : Float(512:1, 128:512) = aten::t(%4278), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.317 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.170 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.317, %4277, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4282 : Tensor = prim::GetAttr[name="bias"](%4275)
  %4283 : Tensor = prim::GetAttr[name="weight"](%4275)
  %4284 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.170, %4283), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%4284, %4282, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4286 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16579.NoNorm = prim::GetAttr[name="LayerNorm"](%4273)
  %4287 : __torch__.torch.nn.modules.linear.___torch_mangle_16578.Linear = prim::GetAttr[name="dense"](%4273)
  %4288 : Tensor = prim::GetAttr[name="bias"](%4287)
  %4289 : Tensor = prim::GetAttr[name="weight"](%4287)
  %4290 : Float(512:1, 128:512) = aten::t(%4289), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.318 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4290), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.171 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.318, %4288, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4293 : Tensor = prim::GetAttr[name="bias"](%4286)
  %4294 : Tensor = prim::GetAttr[name="weight"](%4286)
  %4295 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.171, %4294), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.407 : Float(17:1664, 13:128, 128:1) = aten::add(%4295, %4293, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4297 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.407, %residual_tensor.22)
  %4298 : Float(17:1664, 13:128, 128:1), %4299 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4297)
  %4300 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16564.MobileBertSelfOutput = prim::GetAttr[name="output"](%4271)
  %4301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16561.MobileBertSelfAttention = prim::GetAttr[name="self"](%4271)
  %4302 : __torch__.torch.nn.modules.linear.___torch_mangle_16559.Linear = prim::GetAttr[name="value"](%4301)
  %4303 : __torch__.torch.nn.modules.linear.___torch_mangle_16558.Linear = prim::GetAttr[name="key"](%4301)
  %4304 : __torch__.torch.nn.modules.linear.___torch_mangle_16557.Linear = prim::GetAttr[name="query"](%4301)
  %4305 : Tensor = prim::GetAttr[name="bias"](%4304)
  %4306 : Tensor = prim::GetAttr[name="weight"](%4304)
  %4307 : Float(128:1, 128:128) = aten::t(%4306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %output.319 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4298, %4307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %x.127 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.319, %4305, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1678:0
  %4310 : Tensor = prim::GetAttr[name="bias"](%4303)
  %4311 : Tensor = prim::GetAttr[name="weight"](%4303)
  %4312 : Float(128:1, 128:128) = aten::t(%4311), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %output.320 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4298, %4312), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %x.129 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.320, %4310, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1678:0
  %4315 : Tensor = prim::GetAttr[name="bias"](%4302)
  %4316 : Tensor = prim::GetAttr[name="weight"](%4302)
  %4317 : Float(512:1, 128:512) = aten::t(%4316), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %output.321 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %x.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.321, %4315, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1678:0
  %4320 : int = aten::size(%x.127, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4321 : int = aten::size(%x.127, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4322 : int[] = prim::ListConstruct(%4320, %4321, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.128 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.127, %4322), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4324 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %query_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.128, %4324), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4326 : int = aten::size(%x.129, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4327 : int = aten::size(%x.129, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4328 : int[] = prim::ListConstruct(%4326, %4327, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.130 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.129, %4328), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4330 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %key_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.130, %4330), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4332 : int = aten::size(%x.131, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4333 : int = aten::size(%x.131, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4334 : int[] = prim::ListConstruct(%4332, %4333, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.132 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.131, %4334), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4336 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %value_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.132, %4336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4338 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.22, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.43 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.22, %4338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.44 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.43, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.408 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.44, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.409 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.408, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.409, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.43 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.22, %value_layer.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:280:0
  %4345 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %4346 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.43, %4345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4346, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %4348 : int = aten::size(%context_layer.44, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4349 : int = aten::size(%context_layer.44, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4350 : int[] = prim::ListConstruct(%4348, %4349, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %input.410 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.44, %4350), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:283:0
  %4352 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16563.NoNorm = prim::GetAttr[name="LayerNorm"](%4300)
  %4353 : __torch__.torch.nn.modules.linear.___torch_mangle_16562.Linear = prim::GetAttr[name="dense"](%4300)
  %4354 : Tensor = prim::GetAttr[name="bias"](%4353)
  %4355 : Tensor = prim::GetAttr[name="weight"](%4353)
  %4356 : Float(128:1, 128:128) = aten::t(%4355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %output.322 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.410, %4356), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.322, %4354, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.172 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.106, %4299, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output # transformers/modeling_mobilebert.py:301:0
  %4360 : Tensor = prim::GetAttr[name="bias"](%4352)
  %4361 : Tensor = prim::GetAttr[name="weight"](%4352)
  %4362 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.172, %4361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.411 : Float(17:1664, 13:128, 128:1) = aten::add(%4362, %4360, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4364 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16586.FFNOutput = prim::GetAttr[name="output"](%4270)
  %4365 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16583.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4270)
  %4366 : __torch__.torch.nn.modules.linear.___torch_mangle_16582.Linear = prim::GetAttr[name="dense"](%4365)
  %4367 : Tensor = prim::GetAttr[name="bias"](%4366)
  %4368 : Tensor = prim::GetAttr[name="weight"](%4366)
  %4369 : Float(128:1, 512:128) = aten::t(%4368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.323 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.411, %4369), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.412 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.323, %4367, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.413 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4373 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16585.NoNorm = prim::GetAttr[name="LayerNorm"](%4364)
  %4374 : __torch__.torch.nn.modules.linear.___torch_mangle_16584.Linear = prim::GetAttr[name="dense"](%4364)
  %4375 : Tensor = prim::GetAttr[name="bias"](%4374)
  %4376 : Tensor = prim::GetAttr[name="weight"](%4374)
  %4377 : Float(512:1, 128:512) = aten::t(%4376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.324 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.413, %4377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.324, %4375, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.173 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.107, %input.411, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4381 : Tensor = prim::GetAttr[name="bias"](%4373)
  %4382 : Tensor = prim::GetAttr[name="weight"](%4373)
  %4383 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.173, %4382), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.414 : Float(17:1664, 13:128, 128:1) = aten::add(%4383, %4381, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4385 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16592.FFNOutput = prim::GetAttr[name="output"](%4268)
  %4386 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16589.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4268)
  %4387 : __torch__.torch.nn.modules.linear.___torch_mangle_16588.Linear = prim::GetAttr[name="dense"](%4386)
  %4388 : Tensor = prim::GetAttr[name="bias"](%4387)
  %4389 : Tensor = prim::GetAttr[name="weight"](%4387)
  %4390 : Float(128:1, 512:128) = aten::t(%4389), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.325 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.414, %4390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.415 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.325, %4388, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.416 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4394 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16591.NoNorm = prim::GetAttr[name="LayerNorm"](%4385)
  %4395 : __torch__.torch.nn.modules.linear.___torch_mangle_16590.Linear = prim::GetAttr[name="dense"](%4385)
  %4396 : Tensor = prim::GetAttr[name="bias"](%4395)
  %4397 : Tensor = prim::GetAttr[name="weight"](%4395)
  %4398 : Float(512:1, 128:512) = aten::t(%4397), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.326 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.416, %4398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.108 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.326, %4396, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.174 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.108, %input.414, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4402 : Tensor = prim::GetAttr[name="bias"](%4394)
  %4403 : Tensor = prim::GetAttr[name="weight"](%4394)
  %4404 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.174, %4403), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.417 : Float(17:1664, 13:128, 128:1) = aten::add(%4404, %4402, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4406 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16598.FFNOutput = prim::GetAttr[name="output"](%4266)
  %4407 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16595.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4266)
  %4408 : __torch__.torch.nn.modules.linear.___torch_mangle_16594.Linear = prim::GetAttr[name="dense"](%4407)
  %4409 : Tensor = prim::GetAttr[name="bias"](%4408)
  %4410 : Tensor = prim::GetAttr[name="weight"](%4408)
  %4411 : Float(128:1, 512:128) = aten::t(%4410), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.327 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.417, %4411), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.418 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.327, %4409, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.419 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4415 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16597.NoNorm = prim::GetAttr[name="LayerNorm"](%4406)
  %4416 : __torch__.torch.nn.modules.linear.___torch_mangle_16596.Linear = prim::GetAttr[name="dense"](%4406)
  %4417 : Tensor = prim::GetAttr[name="bias"](%4416)
  %4418 : Tensor = prim::GetAttr[name="weight"](%4416)
  %4419 : Float(512:1, 128:512) = aten::t(%4418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.328 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.419, %4419), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.328, %4417, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.175 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.109, %input.417, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4423 : Tensor = prim::GetAttr[name="bias"](%4415)
  %4424 : Tensor = prim::GetAttr[name="weight"](%4415)
  %4425 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.175, %4424), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.420 : Float(17:1664, 13:128, 128:1) = aten::add(%4425, %4423, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4427 : __torch__.torch.nn.modules.linear.___torch_mangle_16566.Linear = prim::GetAttr[name="dense"](%4264)
  %4428 : Tensor = prim::GetAttr[name="bias"](%4427)
  %4429 : Tensor = prim::GetAttr[name="weight"](%4427)
  %4430 : Float(128:1, 512:128) = aten::t(%4429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %output.329 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.420, %4430), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %input.421 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.329, %4428, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1678:0
  %input.422 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate # torch/nn/functional.py:1119:0
  %4434 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16573.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4263)
  %4435 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16569.NoNorm = prim::GetAttr[name="LayerNorm"](%4263)
  %4436 : __torch__.torch.nn.modules.linear.___torch_mangle_16568.Linear = prim::GetAttr[name="dense"](%4263)
  %4437 : Tensor = prim::GetAttr[name="bias"](%4436)
  %4438 : Tensor = prim::GetAttr[name="weight"](%4436)
  %4439 : Float(512:1, 128:512) = aten::t(%4438), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %output.330 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.422, %4439), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %layer_output.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.330, %4437, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.176 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.22, %input.420, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output # transformers/modeling_mobilebert.py:405:0
  %4443 : Tensor = prim::GetAttr[name="bias"](%4435)
  %4444 : Tensor = prim::GetAttr[name="weight"](%4435)
  %4445 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.176, %4444), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.423 : Float(17:1664, 13:128, 128:1) = aten::add(%4445, %4443, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4447 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16571.NoNorm = prim::GetAttr[name="LayerNorm"](%4434)
  %4448 : __torch__.torch.nn.modules.linear.___torch_mangle_16570.Linear = prim::GetAttr[name="dense"](%4434)
  %4449 : Tensor = prim::GetAttr[name="bias"](%4448)
  %4450 : Tensor = prim::GetAttr[name="weight"](%4448)
  %4451 : Float(128:1, 512:128) = aten::t(%4450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.331 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.423, %4451), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.424 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.331, %4449, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.110 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.424, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.177 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.110, %input.406, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4456 : Tensor = prim::GetAttr[name="bias"](%4447)
  %4457 : Tensor = prim::GetAttr[name="weight"](%4447)
  %4458 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.177, %4457), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.425 : Float(17:6656, 13:512, 512:1) = aten::add(%4458, %4456, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4460 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16619.MobileBertOutput = prim::GetAttr[name="output"](%81)
  %4461 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16612.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%81)
  %4462 : __torch__.torch.nn.modules.container.___torch_mangle_16645.ModuleList = prim::GetAttr[name="ffn"](%81)
  %4463 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16644.FFNLayer = prim::GetAttr[name="2"](%4462)
  %4464 : __torch__.torch.nn.modules.container.___torch_mangle_16645.ModuleList = prim::GetAttr[name="ffn"](%81)
  %4465 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16638.FFNLayer = prim::GetAttr[name="1"](%4464)
  %4466 : __torch__.torch.nn.modules.container.___torch_mangle_16645.ModuleList = prim::GetAttr[name="ffn"](%81)
  %4467 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16632.FFNLayer = prim::GetAttr[name="0"](%4466)
  %4468 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16610.MobileBertAttention = prim::GetAttr[name="attention"](%81)
  %4469 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16626.Bottleneck = prim::GetAttr[name="bottleneck"](%81)
  %4470 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16625.BottleneckLayer = prim::GetAttr[name="attention"](%4469)
  %4471 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16622.BottleneckLayer = prim::GetAttr[name="input"](%4469)
  %4472 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16621.NoNorm = prim::GetAttr[name="LayerNorm"](%4471)
  %4473 : __torch__.torch.nn.modules.linear.___torch_mangle_16620.Linear = prim::GetAttr[name="dense"](%4471)
  %4474 : Tensor = prim::GetAttr[name="bias"](%4473)
  %4475 : Tensor = prim::GetAttr[name="weight"](%4473)
  %4476 : Float(512:1, 128:512) = aten::t(%4475), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.332 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4476), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.178 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.332, %4474, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4479 : Tensor = prim::GetAttr[name="bias"](%4472)
  %4480 : Tensor = prim::GetAttr[name="weight"](%4472)
  %4481 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.178, %4480), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%4481, %4479, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4483 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16624.NoNorm = prim::GetAttr[name="LayerNorm"](%4470)
  %4484 : __torch__.torch.nn.modules.linear.___torch_mangle_16623.Linear = prim::GetAttr[name="dense"](%4470)
  %4485 : Tensor = prim::GetAttr[name="bias"](%4484)
  %4486 : Tensor = prim::GetAttr[name="weight"](%4484)
  %4487 : Float(512:1, 128:512) = aten::t(%4486), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.333 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4487), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.179 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.333, %4485, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4490 : Tensor = prim::GetAttr[name="bias"](%4483)
  %4491 : Tensor = prim::GetAttr[name="weight"](%4483)
  %4492 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.179, %4491), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.426 : Float(17:1664, 13:128, 128:1) = aten::add(%4492, %4490, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4494 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.426, %residual_tensor.23)
  %4495 : Float(17:1664, 13:128, 128:1), %4496 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4494)
  %4497 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16609.MobileBertSelfOutput = prim::GetAttr[name="output"](%4468)
  %4498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16606.MobileBertSelfAttention = prim::GetAttr[name="self"](%4468)
  %4499 : __torch__.torch.nn.modules.linear.___torch_mangle_16604.Linear = prim::GetAttr[name="value"](%4498)
  %4500 : __torch__.torch.nn.modules.linear.___torch_mangle_16603.Linear = prim::GetAttr[name="key"](%4498)
  %4501 : __torch__.torch.nn.modules.linear.___torch_mangle_16602.Linear = prim::GetAttr[name="query"](%4498)
  %4502 : Tensor = prim::GetAttr[name="bias"](%4501)
  %4503 : Tensor = prim::GetAttr[name="weight"](%4501)
  %4504 : Float(128:1, 128:128) = aten::t(%4503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %output.334 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4495, %4504), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %x.133 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.334, %4502, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1678:0
  %4507 : Tensor = prim::GetAttr[name="bias"](%4500)
  %4508 : Tensor = prim::GetAttr[name="weight"](%4500)
  %4509 : Float(128:1, 128:128) = aten::t(%4508), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %output.335 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4495, %4509), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %x.135 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.335, %4507, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1678:0
  %4512 : Tensor = prim::GetAttr[name="bias"](%4499)
  %4513 : Tensor = prim::GetAttr[name="weight"](%4499)
  %4514 : Float(512:1, 128:512) = aten::t(%4513), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %output.336 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4514), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %x.137 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.336, %4512, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1678:0
  %4517 : int = aten::size(%x.133, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4518 : int = aten::size(%x.133, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4519 : int[] = prim::ListConstruct(%4517, %4518, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.134 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.133, %4519), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4521 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %query_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.134, %4521), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4523 : int = aten::size(%x.135, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4524 : int = aten::size(%x.135, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4525 : int[] = prim::ListConstruct(%4523, %4524, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.136 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.135, %4525), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4527 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %key_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.136, %4527), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4529 : int = aten::size(%x.137, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4530 : int = aten::size(%x.137, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4531 : int[] = prim::ListConstruct(%4529, %4530, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.138 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.137, %4531), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4533 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %value_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.138, %4533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4535 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.23, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.45 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.23, %4535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.46 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.45, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.427 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.46, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.428 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.427, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.428, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.45 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.23, %value_layer.23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:280:0
  %4542 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %4543 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.45, %4542), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4543, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %4545 : int = aten::size(%context_layer.46, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4546 : int = aten::size(%context_layer.46, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4547 : int[] = prim::ListConstruct(%4545, %4546, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %input.429 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.46, %4547), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:283:0
  %4549 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16608.NoNorm = prim::GetAttr[name="LayerNorm"](%4497)
  %4550 : __torch__.torch.nn.modules.linear.___torch_mangle_16607.Linear = prim::GetAttr[name="dense"](%4497)
  %4551 : Tensor = prim::GetAttr[name="bias"](%4550)
  %4552 : Tensor = prim::GetAttr[name="weight"](%4550)
  %4553 : Float(128:1, 128:128) = aten::t(%4552), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %output.337 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.429, %4553), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.337, %4551, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.180 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.111, %4496, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output # transformers/modeling_mobilebert.py:301:0
  %4557 : Tensor = prim::GetAttr[name="bias"](%4549)
  %4558 : Tensor = prim::GetAttr[name="weight"](%4549)
  %4559 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.180, %4558), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.430 : Float(17:1664, 13:128, 128:1) = aten::add(%4559, %4557, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4561 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16631.FFNOutput = prim::GetAttr[name="output"](%4467)
  %4562 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16628.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4467)
  %4563 : __torch__.torch.nn.modules.linear.___torch_mangle_16627.Linear = prim::GetAttr[name="dense"](%4562)
  %4564 : Tensor = prim::GetAttr[name="bias"](%4563)
  %4565 : Tensor = prim::GetAttr[name="weight"](%4563)
  %4566 : Float(128:1, 512:128) = aten::t(%4565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.338 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.430, %4566), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.431 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.338, %4564, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.432 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.431), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4570 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16630.NoNorm = prim::GetAttr[name="LayerNorm"](%4561)
  %4571 : __torch__.torch.nn.modules.linear.___torch_mangle_16629.Linear = prim::GetAttr[name="dense"](%4561)
  %4572 : Tensor = prim::GetAttr[name="bias"](%4571)
  %4573 : Tensor = prim::GetAttr[name="weight"](%4571)
  %4574 : Float(512:1, 128:512) = aten::t(%4573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.339 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.432, %4574), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.112 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.339, %4572, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.181 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.112, %input.430, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4578 : Tensor = prim::GetAttr[name="bias"](%4570)
  %4579 : Tensor = prim::GetAttr[name="weight"](%4570)
  %4580 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.181, %4579), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.433 : Float(17:1664, 13:128, 128:1) = aten::add(%4580, %4578, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4582 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16637.FFNOutput = prim::GetAttr[name="output"](%4465)
  %4583 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16634.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4465)
  %4584 : __torch__.torch.nn.modules.linear.___torch_mangle_16633.Linear = prim::GetAttr[name="dense"](%4583)
  %4585 : Tensor = prim::GetAttr[name="bias"](%4584)
  %4586 : Tensor = prim::GetAttr[name="weight"](%4584)
  %4587 : Float(128:1, 512:128) = aten::t(%4586), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.340 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.433, %4587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.434 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.340, %4585, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.435 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4591 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16636.NoNorm = prim::GetAttr[name="LayerNorm"](%4582)
  %4592 : __torch__.torch.nn.modules.linear.___torch_mangle_16635.Linear = prim::GetAttr[name="dense"](%4582)
  %4593 : Tensor = prim::GetAttr[name="bias"](%4592)
  %4594 : Tensor = prim::GetAttr[name="weight"](%4592)
  %4595 : Float(512:1, 128:512) = aten::t(%4594), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.341 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.435, %4595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.341, %4593, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.182 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.113, %input.433, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4599 : Tensor = prim::GetAttr[name="bias"](%4591)
  %4600 : Tensor = prim::GetAttr[name="weight"](%4591)
  %4601 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.182, %4600), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.436 : Float(17:1664, 13:128, 128:1) = aten::add(%4601, %4599, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4603 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16643.FFNOutput = prim::GetAttr[name="output"](%4463)
  %4604 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16640.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4463)
  %4605 : __torch__.torch.nn.modules.linear.___torch_mangle_16639.Linear = prim::GetAttr[name="dense"](%4604)
  %4606 : Tensor = prim::GetAttr[name="bias"](%4605)
  %4607 : Tensor = prim::GetAttr[name="weight"](%4605)
  %4608 : Float(128:1, 512:128) = aten::t(%4607), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.342 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.436, %4608), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.437 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.342, %4606, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.438 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4612 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16642.NoNorm = prim::GetAttr[name="LayerNorm"](%4603)
  %4613 : __torch__.torch.nn.modules.linear.___torch_mangle_16641.Linear = prim::GetAttr[name="dense"](%4603)
  %4614 : Tensor = prim::GetAttr[name="bias"](%4613)
  %4615 : Tensor = prim::GetAttr[name="weight"](%4613)
  %4616 : Float(512:1, 128:512) = aten::t(%4615), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.343 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.438, %4616), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.343, %4614, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.183 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.114, %input.436, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4620 : Tensor = prim::GetAttr[name="bias"](%4612)
  %4621 : Tensor = prim::GetAttr[name="weight"](%4612)
  %4622 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.183, %4621), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.439 : Float(17:1664, 13:128, 128:1) = aten::add(%4622, %4620, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4624 : __torch__.torch.nn.modules.linear.___torch_mangle_16611.Linear = prim::GetAttr[name="dense"](%4461)
  %4625 : Tensor = prim::GetAttr[name="bias"](%4624)
  %4626 : Tensor = prim::GetAttr[name="weight"](%4624)
  %4627 : Float(128:1, 512:128) = aten::t(%4626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %output.344 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.439, %4627), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %input.440 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.344, %4625, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1678:0
  %input.441 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate # torch/nn/functional.py:1119:0
  %4631 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16618.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4460)
  %4632 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16614.NoNorm = prim::GetAttr[name="LayerNorm"](%4460)
  %4633 : __torch__.torch.nn.modules.linear.___torch_mangle_16613.Linear = prim::GetAttr[name="dense"](%4460)
  %4634 : Tensor = prim::GetAttr[name="bias"](%4633)
  %4635 : Tensor = prim::GetAttr[name="weight"](%4633)
  %4636 : Float(512:1, 128:512) = aten::t(%4635), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %output.345 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.441, %4636), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %layer_output.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.345, %4634, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.184 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.23, %input.439, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output # transformers/modeling_mobilebert.py:405:0
  %4640 : Tensor = prim::GetAttr[name="bias"](%4632)
  %4641 : Tensor = prim::GetAttr[name="weight"](%4632)
  %4642 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.184, %4641), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.442 : Float(17:1664, 13:128, 128:1) = aten::add(%4642, %4640, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4644 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16616.NoNorm = prim::GetAttr[name="LayerNorm"](%4631)
  %4645 : __torch__.torch.nn.modules.linear.___torch_mangle_16615.Linear = prim::GetAttr[name="dense"](%4631)
  %4646 : Tensor = prim::GetAttr[name="bias"](%4645)
  %4647 : Tensor = prim::GetAttr[name="weight"](%4645)
  %4648 : Float(128:1, 512:128) = aten::t(%4647), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.346 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.442, %4648), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.443 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.346, %4646, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.115 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.443, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.185 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.115, %input.425, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4653 : Tensor = prim::GetAttr[name="bias"](%4644)
  %4654 : Tensor = prim::GetAttr[name="weight"](%4644)
  %4655 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.185, %4654), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.444 : Float(17:6656, 13:512, 512:1) = aten::add(%4655, %4653, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4657 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16664.MobileBertOutput = prim::GetAttr[name="output"](%79)
  %4658 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16657.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%79)
  %4659 : __torch__.torch.nn.modules.container.___torch_mangle_16690.ModuleList = prim::GetAttr[name="ffn"](%79)
  %4660 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16689.FFNLayer = prim::GetAttr[name="2"](%4659)
  %4661 : __torch__.torch.nn.modules.container.___torch_mangle_16690.ModuleList = prim::GetAttr[name="ffn"](%79)
  %4662 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16683.FFNLayer = prim::GetAttr[name="1"](%4661)
  %4663 : __torch__.torch.nn.modules.container.___torch_mangle_16690.ModuleList = prim::GetAttr[name="ffn"](%79)
  %4664 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16677.FFNLayer = prim::GetAttr[name="0"](%4663)
  %4665 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16655.MobileBertAttention = prim::GetAttr[name="attention"](%79)
  %4666 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16671.Bottleneck = prim::GetAttr[name="bottleneck"](%79)
  %4667 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16670.BottleneckLayer = prim::GetAttr[name="attention"](%4666)
  %4668 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16667.BottleneckLayer = prim::GetAttr[name="input"](%4666)
  %4669 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16666.NoNorm = prim::GetAttr[name="LayerNorm"](%4668)
  %4670 : __torch__.torch.nn.modules.linear.___torch_mangle_16665.Linear = prim::GetAttr[name="dense"](%4668)
  %4671 : Tensor = prim::GetAttr[name="bias"](%4670)
  %4672 : Tensor = prim::GetAttr[name="weight"](%4670)
  %4673 : Float(512:1, 128:512) = aten::t(%4672), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.347 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4673), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.186 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.347, %4671, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4676 : Tensor = prim::GetAttr[name="bias"](%4669)
  %4677 : Tensor = prim::GetAttr[name="weight"](%4669)
  %4678 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.186, %4677), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor : Float(17:1664, 13:128, 128:1) = aten::add(%4678, %4676, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4680 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16669.NoNorm = prim::GetAttr[name="LayerNorm"](%4667)
  %4681 : __torch__.torch.nn.modules.linear.___torch_mangle_16668.Linear = prim::GetAttr[name="dense"](%4667)
  %4682 : Tensor = prim::GetAttr[name="bias"](%4681)
  %4683 : Tensor = prim::GetAttr[name="weight"](%4681)
  %4684 : Float(512:1, 128:512) = aten::t(%4683), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.348 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4684), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.187 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.348, %4682, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4687 : Tensor = prim::GetAttr[name="bias"](%4680)
  %4688 : Tensor = prim::GetAttr[name="weight"](%4680)
  %4689 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.187, %4688), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.445 : Float(17:1664, 13:128, 128:1) = aten::add(%4689, %4687, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4691 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.445, %residual_tensor)
  %4692 : Float(17:1664, 13:128, 128:1), %4693 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4691)
  %4694 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16654.MobileBertSelfOutput = prim::GetAttr[name="output"](%4665)
  %4695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16651.MobileBertSelfAttention = prim::GetAttr[name="self"](%4665)
  %4696 : __torch__.torch.nn.modules.linear.___torch_mangle_16649.Linear = prim::GetAttr[name="value"](%4695)
  %4697 : __torch__.torch.nn.modules.linear.___torch_mangle_16648.Linear = prim::GetAttr[name="key"](%4695)
  %4698 : __torch__.torch.nn.modules.linear.___torch_mangle_16647.Linear = prim::GetAttr[name="query"](%4695)
  %4699 : Tensor = prim::GetAttr[name="bias"](%4698)
  %4700 : Tensor = prim::GetAttr[name="weight"](%4698)
  %4701 : Float(128:1, 128:128) = aten::t(%4700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %output.349 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4692, %4701), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %x.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.349, %4699, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1678:0
  %4704 : Tensor = prim::GetAttr[name="bias"](%4697)
  %4705 : Tensor = prim::GetAttr[name="weight"](%4697)
  %4706 : Float(128:1, 128:128) = aten::t(%4705), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %output.350 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4692, %4706), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %x.141 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.350, %4704, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1678:0
  %4709 : Tensor = prim::GetAttr[name="bias"](%4696)
  %4710 : Tensor = prim::GetAttr[name="weight"](%4696)
  %4711 : Float(512:1, 128:512) = aten::t(%4710), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %output.351 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4711), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %x.143 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.351, %4709, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1678:0
  %4714 : int = aten::size(%x.139, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4715 : int = aten::size(%x.139, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4716 : int[] = prim::ListConstruct(%4714, %4715, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.140 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.139, %4716), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4718 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %query_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.140, %4718), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4720 : int = aten::size(%x.141, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4721 : int = aten::size(%x.141, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4722 : int[] = prim::ListConstruct(%4720, %4721, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.142 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.141, %4722), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4724 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %key_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.142, %4724), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4726 : int = aten::size(%x.143, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4727 : int = aten::size(%x.143, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4728 : int[] = prim::ListConstruct(%4726, %4727, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.143, %4728), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4730 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %value_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x, %4730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4732 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer, %4732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.47, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.446 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.447 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.446, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # torch/nn/functional.py:1498:0
  %attention_probs : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.447, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.47 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:280:0
  %4739 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %4740 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.47, %4739), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4740, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %4742 : int = aten::size(%context_layer, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4743 : int = aten::size(%context_layer, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4744 : int[] = prim::ListConstruct(%4742, %4743, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %input.448 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer, %4744), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:283:0
  %4746 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16653.NoNorm = prim::GetAttr[name="LayerNorm"](%4694)
  %4747 : __torch__.torch.nn.modules.linear.___torch_mangle_16652.Linear = prim::GetAttr[name="dense"](%4694)
  %4748 : Tensor = prim::GetAttr[name="bias"](%4747)
  %4749 : Tensor = prim::GetAttr[name="weight"](%4747)
  %4750 : Float(128:1, 128:128) = aten::t(%4749), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %output.352 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.448, %4750), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.116 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.352, %4748, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.188 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.116, %4693, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output # transformers/modeling_mobilebert.py:301:0
  %4754 : Tensor = prim::GetAttr[name="bias"](%4746)
  %4755 : Tensor = prim::GetAttr[name="weight"](%4746)
  %4756 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.188, %4755), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.449 : Float(17:1664, 13:128, 128:1) = aten::add(%4756, %4754, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4758 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16676.FFNOutput = prim::GetAttr[name="output"](%4664)
  %4759 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16673.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4664)
  %4760 : __torch__.torch.nn.modules.linear.___torch_mangle_16672.Linear = prim::GetAttr[name="dense"](%4759)
  %4761 : Tensor = prim::GetAttr[name="bias"](%4760)
  %4762 : Tensor = prim::GetAttr[name="weight"](%4760)
  %4763 : Float(128:1, 512:128) = aten::t(%4762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.353 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.449, %4763), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.450 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.353, %4761, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.451 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4767 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16675.NoNorm = prim::GetAttr[name="LayerNorm"](%4758)
  %4768 : __torch__.torch.nn.modules.linear.___torch_mangle_16674.Linear = prim::GetAttr[name="dense"](%4758)
  %4769 : Tensor = prim::GetAttr[name="bias"](%4768)
  %4770 : Tensor = prim::GetAttr[name="weight"](%4768)
  %4771 : Float(512:1, 128:512) = aten::t(%4770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.354 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.451, %4771), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.354, %4769, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.189 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.117, %input.449, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4775 : Tensor = prim::GetAttr[name="bias"](%4767)
  %4776 : Tensor = prim::GetAttr[name="weight"](%4767)
  %4777 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.189, %4776), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.452 : Float(17:1664, 13:128, 128:1) = aten::add(%4777, %4775, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4779 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16682.FFNOutput = prim::GetAttr[name="output"](%4662)
  %4780 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16679.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4662)
  %4781 : __torch__.torch.nn.modules.linear.___torch_mangle_16678.Linear = prim::GetAttr[name="dense"](%4780)
  %4782 : Tensor = prim::GetAttr[name="bias"](%4781)
  %4783 : Tensor = prim::GetAttr[name="weight"](%4781)
  %4784 : Float(128:1, 512:128) = aten::t(%4783), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.355 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.452, %4784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.453 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.355, %4782, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.454 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4788 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16681.NoNorm = prim::GetAttr[name="LayerNorm"](%4779)
  %4789 : __torch__.torch.nn.modules.linear.___torch_mangle_16680.Linear = prim::GetAttr[name="dense"](%4779)
  %4790 : Tensor = prim::GetAttr[name="bias"](%4789)
  %4791 : Tensor = prim::GetAttr[name="weight"](%4789)
  %4792 : Float(512:1, 128:512) = aten::t(%4791), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.356 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.454, %4792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.118 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.356, %4790, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.190 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.118, %input.452, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4796 : Tensor = prim::GetAttr[name="bias"](%4788)
  %4797 : Tensor = prim::GetAttr[name="weight"](%4788)
  %4798 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.190, %4797), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.455 : Float(17:1664, 13:128, 128:1) = aten::add(%4798, %4796, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4800 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16688.FFNOutput = prim::GetAttr[name="output"](%4660)
  %4801 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16685.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4660)
  %4802 : __torch__.torch.nn.modules.linear.___torch_mangle_16684.Linear = prim::GetAttr[name="dense"](%4801)
  %4803 : Tensor = prim::GetAttr[name="bias"](%4802)
  %4804 : Tensor = prim::GetAttr[name="weight"](%4802)
  %4805 : Float(128:1, 512:128) = aten::t(%4804), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.357 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.455, %4805), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.456 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.357, %4803, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.457 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4809 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16687.NoNorm = prim::GetAttr[name="LayerNorm"](%4800)
  %4810 : __torch__.torch.nn.modules.linear.___torch_mangle_16686.Linear = prim::GetAttr[name="dense"](%4800)
  %4811 : Tensor = prim::GetAttr[name="bias"](%4810)
  %4812 : Tensor = prim::GetAttr[name="weight"](%4810)
  %4813 : Float(512:1, 128:512) = aten::t(%4812), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.358 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.457, %4813), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.358, %4811, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.191 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.119, %input.455, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4817 : Tensor = prim::GetAttr[name="bias"](%4809)
  %4818 : Tensor = prim::GetAttr[name="weight"](%4809)
  %4819 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.191, %4818), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.458 : Float(17:1664, 13:128, 128:1) = aten::add(%4819, %4817, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4821 : __torch__.torch.nn.modules.linear.___torch_mangle_16656.Linear = prim::GetAttr[name="dense"](%4658)
  %4822 : Tensor = prim::GetAttr[name="bias"](%4821)
  %4823 : Tensor = prim::GetAttr[name="weight"](%4821)
  %4824 : Float(128:1, 512:128) = aten::t(%4823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %output.359 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.458, %4824), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %input.459 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.359, %4822, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1678:0
  %input.460 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate # torch/nn/functional.py:1119:0
  %4828 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16663.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4657)
  %4829 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16659.NoNorm = prim::GetAttr[name="LayerNorm"](%4657)
  %4830 : __torch__.torch.nn.modules.linear.___torch_mangle_16658.Linear = prim::GetAttr[name="dense"](%4657)
  %4831 : Tensor = prim::GetAttr[name="bias"](%4830)
  %4832 : Tensor = prim::GetAttr[name="weight"](%4830)
  %4833 : Float(512:1, 128:512) = aten::t(%4832), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %output.360 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.460, %4833), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %layer_output : Float(17:1664, 13:128, 128:1) = aten::add_(%output.360, %4831, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.192 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output, %input.458, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output # transformers/modeling_mobilebert.py:405:0
  %4837 : Tensor = prim::GetAttr[name="bias"](%4829)
  %4838 : Tensor = prim::GetAttr[name="weight"](%4829)
  %4839 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.192, %4838), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.461 : Float(17:1664, 13:128, 128:1) = aten::add(%4839, %4837, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4841 : __torch__.transformers.modeling_mobilebert.___torch_mangle_16661.NoNorm = prim::GetAttr[name="LayerNorm"](%4828)
  %4842 : __torch__.torch.nn.modules.linear.___torch_mangle_16660.Linear = prim::GetAttr[name="dense"](%4828)
  %4843 : Tensor = prim::GetAttr[name="bias"](%4842)
  %4844 : Tensor = prim::GetAttr[name="weight"](%4842)
  %4845 : Float(128:1, 512:128) = aten::t(%4844), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.461, %4845), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.462 : Float(17:6656, 13:512, 512:1) = aten::add_(%output, %4843, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.462, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs, %input.444, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4850 : Tensor = prim::GetAttr[name="bias"](%4841)
  %4851 : Tensor = prim::GetAttr[name="weight"](%4841)
  %4852 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor, %4851), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %hidden_states : Float(17:6656, 13:512, 512:1) = aten::add(%4852, %4850, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4854 : __torch__.torch.nn.modules.linear.___torch_mangle_16694.Linear = prim::GetAttr[name="dense"](%27)
  %4855 : Float(17:6656, 13:512, 512:1) = aten::slice(%hidden_states, %26, %26, %21, %25), scope: __module.mobilebert/__module.mobilebert.pooler # transformers/modeling_mobilebert.py:603:0
  %input.463 : Float(17:6656, 512:1) = aten::select(%4855, %25, %26), scope: __module.mobilebert/__module.mobilebert.pooler # transformers/modeling_mobilebert.py:603:0
  %4857 : Tensor = prim::GetAttr[name="bias"](%4854)
  %4858 : Tensor = prim::GetAttr[name="weight"](%4854)
  %4859 : Float(512:1, 512:512) = aten::t(%4858), scope: __module.mobilebert/__module.mobilebert.pooler/__module.mobilebert.pooler.dense # torch/nn/functional.py:1674:0
  %pooled_output : Float(17:512, 512:1) = aten::addmm(%4857, %input.463, %4859, %25, %25), scope: __module.mobilebert/__module.mobilebert.pooler/__module.mobilebert.pooler.dense # torch/nn/functional.py:1674:0
  %input : Float(17:512, 512:1) = aten::tanh(%pooled_output), scope: __module.mobilebert/__module.mobilebert.pooler # transformers/modeling_mobilebert.py:608:0
  %4862 : int = prim::Constant[value=1](), scope: __module.cls/__module.cls.seq_relationship # torch/nn/functional.py:1674:0
  %4863 : __torch__.torch.nn.modules.linear.___torch_mangle_16697.Linear = prim::GetAttr[name="seq_relationship"](%3)
  %4864 : Tensor = prim::GetAttr[name="bias"](%4863)
  %4865 : Tensor = prim::GetAttr[name="weight"](%4863)
  %4866 : Float(512:1, 2:512) = aten::t(%4865), scope: __module.cls/__module.cls.seq_relationship # torch/nn/functional.py:1674:0
  %4867 : Float(17:2, 2:1) = aten::addmm(%4864, %input, %4866, %4862, %4862), scope: __module.cls/__module.cls.seq_relationship # torch/nn/functional.py:1674:0
  %7 : (Float(17:2, 2:1)) = prim::TupleConstruct(%4867)
  return (%7)
