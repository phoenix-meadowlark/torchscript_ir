graph(%self.1 : __torch__.transformers.modeling_mobilebert.MobileBertForMaskedLM,
      %input_ids : Long(17:13, 13:1),
      %attention_mask.1 : Long(17:13, 13:1)):
  %3 : __torch__.transformers.modeling_mobilebert.MobileBertOnlyMLMHead = prim::GetAttr[name="cls"](%self.1)
  %4 : __torch__.transformers.modeling_mobilebert.MobileBertModel = prim::GetAttr[name="mobilebert"](%self.1)
  %8 : int = prim::Constant[value=128](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %9 : float = prim::Constant[value=0.10000000000000001](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %10 : Double() = prim::Constant[value={5.65685}](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %11 : int = prim::Constant[value=-2](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %12 : int = prim::Constant[value=32](), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %13 : int = prim::Constant[value=-1](), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %14 : float = prim::Constant[value=0.](), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %15 : Double() = prim::Constant[value={-10000}](), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %16 : float = prim::Constant[value=1.](), scope: __module.mobilebert # torch/tensor.py:396:0
  %17 : None = prim::Constant(), scope: __module.mobilebert
  %18 : int = prim::Constant[value=6](), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %19 : int = prim::Constant[value=3](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %20 : int = prim::Constant[value=2](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %21 : int = prim::Constant[value=9223372036854775807](), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %22 : bool = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %23 : Device = prim::Constant[value="cpu"](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %24 : int = prim::Constant[value=4](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %25 : int = prim::Constant[value=1](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %26 : int = prim::Constant[value=0](), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %27 : __torch__.transformers.modeling_mobilebert.MobileBertEncoder = prim::GetAttr[name="encoder"](%4)
  %28 : __torch__.transformers.modeling_mobilebert.MobileBertEmbeddings = prim::GetAttr[name="embeddings"](%4)
  %29 : int = aten::size(%input_ids, %26), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %30 : int = aten::size(%input_ids, %25), scope: __module.mobilebert # transformers/modeling_mobilebert.py:871:0
  %31 : int[] = prim::ListConstruct(%29, %30), scope: __module.mobilebert
  %input.5 : Long(17:13, 13:1) = aten::zeros(%31, %24, %26, %23, %22), scope: __module.mobilebert # transformers/modeling_mobilebert.py:882:0
  %33 : Long(17:13, 13:1) = aten::slice(%attention_mask.1, %26, %26, %21, %25), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %34 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%33, %25), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %35 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%34, %20), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %extended_attention_mask : Long(17:13, 1:13, 1:13, 13:1) = aten::slice(%35, %19, %26, %21, %25), scope: __module.mobilebert # transformers/modeling_utils.py:244:0
  %37 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%extended_attention_mask, %18, %22, %22, %17), scope: __module.mobilebert # transformers/modeling_utils.py:257:0
  %38 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%37, %16, %25), scope: __module.mobilebert # torch/tensor.py:396:0
  %attention_mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%38, %15), scope: __module.mobilebert # transformers/modeling_utils.py:258:0
  %40 : __torch__.transformers.modeling_mobilebert.NoNorm = prim::GetAttr[name="LayerNorm"](%28)
  %41 : __torch__.torch.nn.modules.sparse.___torch_mangle_11242.Embedding = prim::GetAttr[name="token_type_embeddings"](%28)
  %42 : __torch__.torch.nn.modules.sparse.___torch_mangle_11241.Embedding = prim::GetAttr[name="position_embeddings"](%28)
  %43 : __torch__.torch.nn.modules.linear.___torch_mangle_11243.Linear = prim::GetAttr[name="embedding_transformation"](%28)
  %44 : __torch__.torch.nn.modules.sparse.___torch_mangle_11240.Embedding = prim::GetAttr[name="word_embeddings"](%28)
  %45 : Tensor = prim::GetAttr[name="position_ids"](%28)
  %46 : int = aten::size(%input_ids, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:185:0
  %47 : Long(1:512, 512:1) = aten::slice(%45, %26, %26, %21, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %input.4 : Long(1:512, 13:1) = aten::slice(%47, %25, %26, %46, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:192:0
  %49 : Tensor = prim::GetAttr[name="weight"](%44)
  %inputs_embeds.1 : Float(17:1664, 13:128, 128:1) = aten::embedding(%49, %input_ids, %26, %22, %22), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.word_embeddings # torch/nn/functional.py:1814:0
  %51 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %26, %26, %21, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %input.1 : Float(17:1664, 12:128, 128:1) = aten::slice(%51, %25, %25, %21, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:209:0
  %53 : int[] = prim::ListConstruct(%26, %26, %26, %25, %26, %26), scope: __module.mobilebert/__module.mobilebert.embeddings
  %54 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.1, %53, %26), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %55 : Float(17:1664, 13:128, 128:1) = aten::slice(%inputs_embeds.1, %26, %26, %21, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %input.2 : Float(17:1664, 12:128, 128:1) = aten::slice(%55, %25, %26, %13, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:211:0
  %57 : int[] = prim::ListConstruct(%26, %26, %25, %26, %26, %26), scope: __module.mobilebert/__module.mobilebert.embeddings
  %58 : Float(17:1664, 13:128, 128:1) = aten::constant_pad_nd(%input.2, %57, %26), scope: __module.mobilebert/__module.mobilebert.embeddings # torch/nn/functional.py:3552:0
  %59 : Tensor[] = prim::ListConstruct(%54, %inputs_embeds.1, %58), scope: __module.mobilebert/__module.mobilebert.embeddings
  %input.3 : Float(17:4992, 13:384, 384:1) = aten::cat(%59, %20), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:207:0
  %61 : Tensor = prim::GetAttr[name="bias"](%43)
  %62 : Tensor = prim::GetAttr[name="weight"](%43)
  %63 : Float(384:1, 512:384) = aten::t(%62), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %output.1 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.3, %63), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1676:0
  %inputs_embeds : Float(17:6656, 13:512, 512:1) = aten::add_(%output.1, %61, %25), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.embedding_transformation # torch/nn/functional.py:1678:0
  %66 : Tensor = prim::GetAttr[name="weight"](%42)
  %position_embeddings : Float(1:6656, 13:512, 512:1) = aten::embedding(%66, %input.4, %13, %22, %22), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.position_embeddings # torch/nn/functional.py:1814:0
  %68 : Tensor = prim::GetAttr[name="weight"](%41)
  %token_type_embeddings : Float(17:6656, 13:512, 512:1) = aten::embedding(%68, %input.5, %13, %22, %22), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.token_type_embeddings # torch/nn/functional.py:1814:0
  %70 : Float(17:6656, 13:512, 512:1) = aten::add(%inputs_embeds, %position_embeddings, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %input_tensor.1 : Float(17:6656, 13:512, 512:1) = aten::add(%70, %token_type_embeddings, %25), scope: __module.mobilebert/__module.mobilebert.embeddings # transformers/modeling_mobilebert.py:222:0
  %72 : Tensor = prim::GetAttr[name="bias"](%40)
  %73 : Tensor = prim::GetAttr[name="weight"](%40)
  %74 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.1, %73), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.6 : Float(17:6656, 13:512, 512:1) = aten::add(%74, %72, %25), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.7 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.6, %14, %22), scope: __module.mobilebert/__module.mobilebert.embeddings/__module.mobilebert.embeddings.dropout # torch/nn/functional.py:973:0
  %77 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %78 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12313.MobileBertLayer = prim::GetAttr[name="23"](%77)
  %79 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %80 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12268.MobileBertLayer = prim::GetAttr[name="22"](%79)
  %81 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %82 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12223.MobileBertLayer = prim::GetAttr[name="21"](%81)
  %83 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %84 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12178.MobileBertLayer = prim::GetAttr[name="20"](%83)
  %85 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %86 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12133.MobileBertLayer = prim::GetAttr[name="19"](%85)
  %87 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %88 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12088.MobileBertLayer = prim::GetAttr[name="18"](%87)
  %89 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %90 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12043.MobileBertLayer = prim::GetAttr[name="17"](%89)
  %91 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %92 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11998.MobileBertLayer = prim::GetAttr[name="16"](%91)
  %93 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %94 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11953.MobileBertLayer = prim::GetAttr[name="15"](%93)
  %95 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %96 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11908.MobileBertLayer = prim::GetAttr[name="14"](%95)
  %97 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %98 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11863.MobileBertLayer = prim::GetAttr[name="13"](%97)
  %99 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %100 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11818.MobileBertLayer = prim::GetAttr[name="12"](%99)
  %101 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %102 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11773.MobileBertLayer = prim::GetAttr[name="11"](%101)
  %103 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11728.MobileBertLayer = prim::GetAttr[name="10"](%103)
  %105 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %106 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11683.MobileBertLayer = prim::GetAttr[name="9"](%105)
  %107 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %108 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11638.MobileBertLayer = prim::GetAttr[name="8"](%107)
  %109 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %110 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11593.MobileBertLayer = prim::GetAttr[name="7"](%109)
  %111 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %112 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11548.MobileBertLayer = prim::GetAttr[name="6"](%111)
  %113 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %114 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11503.MobileBertLayer = prim::GetAttr[name="5"](%113)
  %115 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %116 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11458.MobileBertLayer = prim::GetAttr[name="4"](%115)
  %117 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11413.MobileBertLayer = prim::GetAttr[name="3"](%117)
  %119 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11368.MobileBertLayer = prim::GetAttr[name="2"](%119)
  %121 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11323.MobileBertLayer = prim::GetAttr[name="1"](%121)
  %123 : __torch__.torch.nn.modules.container.___torch_mangle_12314.ModuleList = prim::GetAttr[name="layer"](%27)
  %124 : __torch__.transformers.modeling_mobilebert.MobileBertLayer = prim::GetAttr[name="0"](%123)
  %125 : __torch__.transformers.modeling_mobilebert.MobileBertOutput = prim::GetAttr[name="output"](%124)
  %126 : __torch__.transformers.modeling_mobilebert.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%124)
  %127 : __torch__.torch.nn.modules.container.___torch_mangle_11278.ModuleList = prim::GetAttr[name="ffn"](%124)
  %128 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11277.FFNLayer = prim::GetAttr[name="2"](%127)
  %129 : __torch__.torch.nn.modules.container.___torch_mangle_11278.ModuleList = prim::GetAttr[name="ffn"](%124)
  %130 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11271.FFNLayer = prim::GetAttr[name="1"](%129)
  %131 : __torch__.torch.nn.modules.container.___torch_mangle_11278.ModuleList = prim::GetAttr[name="ffn"](%124)
  %132 : __torch__.transformers.modeling_mobilebert.FFNLayer = prim::GetAttr[name="0"](%131)
  %133 : __torch__.transformers.modeling_mobilebert.MobileBertAttention = prim::GetAttr[name="attention"](%124)
  %134 : __torch__.transformers.modeling_mobilebert.Bottleneck = prim::GetAttr[name="bottleneck"](%124)
  %135 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11261.BottleneckLayer = prim::GetAttr[name="attention"](%134)
  %136 : __torch__.transformers.modeling_mobilebert.BottleneckLayer = prim::GetAttr[name="input"](%134)
  %137 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11258.NoNorm = prim::GetAttr[name="LayerNorm"](%136)
  %138 : __torch__.torch.nn.modules.linear.___torch_mangle_11257.Linear = prim::GetAttr[name="dense"](%136)
  %139 : Tensor = prim::GetAttr[name="bias"](%138)
  %140 : Tensor = prim::GetAttr[name="weight"](%138)
  %141 : Float(512:1, 128:512) = aten::t(%140), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.2 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.2, %139, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %144 : Tensor = prim::GetAttr[name="bias"](%137)
  %145 : Tensor = prim::GetAttr[name="weight"](%137)
  %146 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.2, %145), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.1 : Float(17:1664, 13:128, 128:1) = aten::add(%146, %144, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.input/__module.mobilebert.encoder.layer.0.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %148 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11260.NoNorm = prim::GetAttr[name="LayerNorm"](%135)
  %149 : __torch__.torch.nn.modules.linear.___torch_mangle_11259.Linear = prim::GetAttr[name="dense"](%135)
  %150 : Tensor = prim::GetAttr[name="bias"](%149)
  %151 : Tensor = prim::GetAttr[name="weight"](%149)
  %152 : Float(512:1, 128:512) = aten::t(%151), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.3 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.3, %150, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %155 : Tensor = prim::GetAttr[name="bias"](%148)
  %156 : Tensor = prim::GetAttr[name="weight"](%148)
  %157 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.3, %156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.8 : Float(17:1664, 13:128, 128:1) = aten::add(%157, %155, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.bottleneck/__module.mobilebert.encoder.layer.0.bottleneck.attention/__module.mobilebert.encoder.layer.0.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %159 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.8, %residual_tensor.1)
  %160 : Float(17:1664, 13:128, 128:1), %161 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%159)
  %162 : __torch__.transformers.modeling_mobilebert.MobileBertSelfOutput = prim::GetAttr[name="output"](%133)
  %163 : __torch__.transformers.modeling_mobilebert.MobileBertSelfAttention = prim::GetAttr[name="self"](%133)
  %164 : __torch__.torch.nn.modules.linear.___torch_mangle_11247.Linear = prim::GetAttr[name="value"](%163)
  %165 : __torch__.torch.nn.modules.linear.___torch_mangle_11246.Linear = prim::GetAttr[name="key"](%163)
  %166 : __torch__.torch.nn.modules.linear.___torch_mangle_11245.Linear = prim::GetAttr[name="query"](%163)
  %167 : Tensor = prim::GetAttr[name="bias"](%166)
  %168 : Tensor = prim::GetAttr[name="weight"](%166)
  %169 : Float(128:1, 128:128) = aten::t(%168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %output.4 : Float(17:1664, 13:128, 128:1) = aten::matmul(%160, %169), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1676:0
  %x.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.4, %167, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.query # torch/nn/functional.py:1678:0
  %172 : Tensor = prim::GetAttr[name="bias"](%165)
  %173 : Tensor = prim::GetAttr[name="weight"](%165)
  %174 : Float(128:1, 128:128) = aten::t(%173), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %output.5 : Float(17:1664, 13:128, 128:1) = aten::matmul(%160, %174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1676:0
  %x.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.5, %172, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.key # torch/nn/functional.py:1678:0
  %177 : Tensor = prim::GetAttr[name="bias"](%164)
  %178 : Tensor = prim::GetAttr[name="weight"](%164)
  %179 : Float(512:1, 128:512) = aten::t(%178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %output.6 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.7, %179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1676:0
  %x.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.6, %177, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.value # torch/nn/functional.py:1678:0
  %182 : int = aten::size(%x.1, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %183 : int = aten::size(%x.1, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %184 : int[] = prim::ListConstruct(%182, %183, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.1, %184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %186 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %query_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.2, %186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %188 : int = aten::size(%x.3, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %189 : int = aten::size(%x.3, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %190 : int[] = prim::ListConstruct(%188, %189, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.3, %190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %192 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %key_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.4, %192), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %194 : int = aten::size(%x.5, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %195 : int = aten::size(%x.5, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:243:0
  %196 : int[] = prim::ListConstruct(%194, %195, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %x.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.5, %196), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:244:0
  %198 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %value_layer.1 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.6, %198), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:245:0
  %200 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.1, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.1, %200), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.1, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.2, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.9, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.1 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.10, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self/__module.mobilebert.encoder.layer.0.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.1 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.1, %value_layer.1), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:280:0
  %207 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %208 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.1, %207), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.2 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%208, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:281:0
  %210 : int = aten::size(%context_layer.2, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %211 : int = aten::size(%context_layer.2, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:282:0
  %212 : int[] = prim::ListConstruct(%210, %211, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self
  %input.11 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.2, %212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.self # transformers/modeling_mobilebert.py:283:0
  %214 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11250.NoNorm = prim::GetAttr[name="LayerNorm"](%162)
  %215 : __torch__.torch.nn.modules.linear.___torch_mangle_11249.Linear = prim::GetAttr[name="dense"](%162)
  %216 : Tensor = prim::GetAttr[name="bias"](%215)
  %217 : Tensor = prim::GetAttr[name="weight"](%215)
  %218 : Float(128:1, 128:128) = aten::t(%217), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %output.7 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.11, %218), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.7, %216, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.1, %161, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output # transformers/modeling_mobilebert.py:301:0
  %222 : Tensor = prim::GetAttr[name="bias"](%214)
  %223 : Tensor = prim::GetAttr[name="weight"](%214)
  %224 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.4, %223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.12 : Float(17:1664, 13:128, 128:1) = aten::add(%224, %222, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.attention/__module.mobilebert.encoder.layer.0.attention.output/__module.mobilebert.encoder.layer.0.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %226 : __torch__.transformers.modeling_mobilebert.FFNOutput = prim::GetAttr[name="output"](%132)
  %227 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11263.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%132)
  %228 : __torch__.torch.nn.modules.linear.___torch_mangle_11262.Linear = prim::GetAttr[name="dense"](%227)
  %229 : Tensor = prim::GetAttr[name="bias"](%228)
  %230 : Tensor = prim::GetAttr[name="weight"](%228)
  %231 : Float(128:1, 512:128) = aten::t(%230), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.8 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.12, %231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.13 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.8, %229, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate/__module.mobilebert.encoder.layer.0.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.14 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %235 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11265.NoNorm = prim::GetAttr[name="LayerNorm"](%226)
  %236 : __torch__.torch.nn.modules.linear.___torch_mangle_11264.Linear = prim::GetAttr[name="dense"](%226)
  %237 : Tensor = prim::GetAttr[name="bias"](%236)
  %238 : Tensor = prim::GetAttr[name="weight"](%236)
  %239 : Float(512:1, 128:512) = aten::t(%238), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.9 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.14, %239), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.9, %237, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.2, %input.12, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %243 : Tensor = prim::GetAttr[name="bias"](%235)
  %244 : Tensor = prim::GetAttr[name="weight"](%235)
  %245 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.5, %244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.15 : Float(17:1664, 13:128, 128:1) = aten::add(%245, %243, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.0/__module.mobilebert.encoder.layer.0.ffn.0.output/__module.mobilebert.encoder.layer.0.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %247 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11270.FFNOutput = prim::GetAttr[name="output"](%130)
  %248 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11267.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%130)
  %249 : __torch__.torch.nn.modules.linear.___torch_mangle_11266.Linear = prim::GetAttr[name="dense"](%248)
  %250 : Tensor = prim::GetAttr[name="bias"](%249)
  %251 : Tensor = prim::GetAttr[name="weight"](%249)
  %252 : Float(128:1, 512:128) = aten::t(%251), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.10 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.15, %252), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.16 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.10, %250, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate/__module.mobilebert.encoder.layer.0.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.17 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %256 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11269.NoNorm = prim::GetAttr[name="LayerNorm"](%247)
  %257 : __torch__.torch.nn.modules.linear.___torch_mangle_11268.Linear = prim::GetAttr[name="dense"](%247)
  %258 : Tensor = prim::GetAttr[name="bias"](%257)
  %259 : Tensor = prim::GetAttr[name="weight"](%257)
  %260 : Float(512:1, 128:512) = aten::t(%259), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.11 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.17, %260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.11, %258, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.3, %input.15, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %264 : Tensor = prim::GetAttr[name="bias"](%256)
  %265 : Tensor = prim::GetAttr[name="weight"](%256)
  %266 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.6, %265), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.18 : Float(17:1664, 13:128, 128:1) = aten::add(%266, %264, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.1/__module.mobilebert.encoder.layer.0.ffn.1.output/__module.mobilebert.encoder.layer.0.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %268 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11276.FFNOutput = prim::GetAttr[name="output"](%128)
  %269 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11273.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%128)
  %270 : __torch__.torch.nn.modules.linear.___torch_mangle_11272.Linear = prim::GetAttr[name="dense"](%269)
  %271 : Tensor = prim::GetAttr[name="bias"](%270)
  %272 : Tensor = prim::GetAttr[name="weight"](%270)
  %273 : Float(128:1, 512:128) = aten::t(%272), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.12 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.18, %273), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.19 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.12, %271, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate/__module.mobilebert.encoder.layer.0.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.20 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %277 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11275.NoNorm = prim::GetAttr[name="LayerNorm"](%268)
  %278 : __torch__.torch.nn.modules.linear.___torch_mangle_11274.Linear = prim::GetAttr[name="dense"](%268)
  %279 : Tensor = prim::GetAttr[name="bias"](%278)
  %280 : Tensor = prim::GetAttr[name="weight"](%278)
  %281 : Float(512:1, 128:512) = aten::t(%280), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.13 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.20, %281), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.13, %279, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.4, %input.18, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %285 : Tensor = prim::GetAttr[name="bias"](%277)
  %286 : Tensor = prim::GetAttr[name="weight"](%277)
  %287 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.7, %286), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.21 : Float(17:1664, 13:128, 128:1) = aten::add(%287, %285, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.ffn.2/__module.mobilebert.encoder.layer.0.ffn.2.output/__module.mobilebert.encoder.layer.0.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %289 : __torch__.torch.nn.modules.linear.___torch_mangle_11251.Linear = prim::GetAttr[name="dense"](%126)
  %290 : Tensor = prim::GetAttr[name="bias"](%289)
  %291 : Tensor = prim::GetAttr[name="weight"](%289)
  %292 : Float(128:1, 512:128) = aten::t(%291), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.14 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.21, %292), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.22 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.14, %290, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate/__module.mobilebert.encoder.layer.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.23 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.intermediate # torch/nn/functional.py:1119:0
  %296 : __torch__.transformers.modeling_mobilebert.OutputBottleneck = prim::GetAttr[name="bottleneck"](%125)
  %297 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11253.NoNorm = prim::GetAttr[name="LayerNorm"](%125)
  %298 : __torch__.torch.nn.modules.linear.___torch_mangle_11252.Linear = prim::GetAttr[name="dense"](%125)
  %299 : Tensor = prim::GetAttr[name="bias"](%298)
  %300 : Tensor = prim::GetAttr[name="weight"](%298)
  %301 : Float(512:1, 128:512) = aten::t(%300), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %output.15 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.23, %301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1676:0
  %layer_output.1 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.15, %299, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.1, %input.21, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output # transformers/modeling_mobilebert.py:405:0
  %305 : Tensor = prim::GetAttr[name="bias"](%297)
  %306 : Tensor = prim::GetAttr[name="weight"](%297)
  %307 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.8, %306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.24 : Float(17:1664, 13:128, 128:1) = aten::add(%307, %305, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %309 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11255.NoNorm = prim::GetAttr[name="LayerNorm"](%296)
  %310 : __torch__.torch.nn.modules.linear.___torch_mangle_11254.Linear = prim::GetAttr[name="dense"](%296)
  %311 : Tensor = prim::GetAttr[name="bias"](%310)
  %312 : Tensor = prim::GetAttr[name="weight"](%310)
  %313 : Float(128:1, 512:128) = aten::t(%312), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.16 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.24, %313), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.25 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.16, %311, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.5 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.25, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.9 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.5, %input.7, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %318 : Tensor = prim::GetAttr[name="bias"](%309)
  %319 : Tensor = prim::GetAttr[name="weight"](%309)
  %320 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.9, %319), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.26 : Float(17:6656, 13:512, 512:1) = aten::add(%320, %318, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.0/__module.mobilebert.encoder.layer.0.output/__module.mobilebert.encoder.layer.0.output.bottleneck/__module.mobilebert.encoder.layer.0.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %322 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11296.MobileBertOutput = prim::GetAttr[name="output"](%122)
  %323 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11289.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%122)
  %324 : __torch__.torch.nn.modules.container.___torch_mangle_11322.ModuleList = prim::GetAttr[name="ffn"](%122)
  %325 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11321.FFNLayer = prim::GetAttr[name="2"](%324)
  %326 : __torch__.torch.nn.modules.container.___torch_mangle_11322.ModuleList = prim::GetAttr[name="ffn"](%122)
  %327 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11315.FFNLayer = prim::GetAttr[name="1"](%326)
  %328 : __torch__.torch.nn.modules.container.___torch_mangle_11322.ModuleList = prim::GetAttr[name="ffn"](%122)
  %329 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11309.FFNLayer = prim::GetAttr[name="0"](%328)
  %330 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11287.MobileBertAttention = prim::GetAttr[name="attention"](%122)
  %331 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11303.Bottleneck = prim::GetAttr[name="bottleneck"](%122)
  %332 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11302.BottleneckLayer = prim::GetAttr[name="attention"](%331)
  %333 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11299.BottleneckLayer = prim::GetAttr[name="input"](%331)
  %334 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11298.NoNorm = prim::GetAttr[name="LayerNorm"](%333)
  %335 : __torch__.torch.nn.modules.linear.___torch_mangle_11297.Linear = prim::GetAttr[name="dense"](%333)
  %336 : Tensor = prim::GetAttr[name="bias"](%335)
  %337 : Tensor = prim::GetAttr[name="weight"](%335)
  %338 : Float(512:1, 128:512) = aten::t(%337), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.17 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.17, %336, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %341 : Tensor = prim::GetAttr[name="bias"](%334)
  %342 : Tensor = prim::GetAttr[name="weight"](%334)
  %343 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.10, %342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.2 : Float(17:1664, 13:128, 128:1) = aten::add(%343, %341, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.input/__module.mobilebert.encoder.layer.1.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %345 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11301.NoNorm = prim::GetAttr[name="LayerNorm"](%332)
  %346 : __torch__.torch.nn.modules.linear.___torch_mangle_11300.Linear = prim::GetAttr[name="dense"](%332)
  %347 : Tensor = prim::GetAttr[name="bias"](%346)
  %348 : Tensor = prim::GetAttr[name="weight"](%346)
  %349 : Float(512:1, 128:512) = aten::t(%348), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.18 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %349), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.18, %347, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %352 : Tensor = prim::GetAttr[name="bias"](%345)
  %353 : Tensor = prim::GetAttr[name="weight"](%345)
  %354 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.11, %353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.27 : Float(17:1664, 13:128, 128:1) = aten::add(%354, %352, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.bottleneck/__module.mobilebert.encoder.layer.1.bottleneck.attention/__module.mobilebert.encoder.layer.1.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %356 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.27, %residual_tensor.2)
  %357 : Float(17:1664, 13:128, 128:1), %358 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%356)
  %359 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11286.MobileBertSelfOutput = prim::GetAttr[name="output"](%330)
  %360 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11283.MobileBertSelfAttention = prim::GetAttr[name="self"](%330)
  %361 : __torch__.torch.nn.modules.linear.___torch_mangle_11281.Linear = prim::GetAttr[name="value"](%360)
  %362 : __torch__.torch.nn.modules.linear.___torch_mangle_11280.Linear = prim::GetAttr[name="key"](%360)
  %363 : __torch__.torch.nn.modules.linear.___torch_mangle_11279.Linear = prim::GetAttr[name="query"](%360)
  %364 : Tensor = prim::GetAttr[name="bias"](%363)
  %365 : Tensor = prim::GetAttr[name="weight"](%363)
  %366 : Float(128:1, 128:128) = aten::t(%365), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %output.19 : Float(17:1664, 13:128, 128:1) = aten::matmul(%357, %366), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1676:0
  %x.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.19, %364, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.query # torch/nn/functional.py:1678:0
  %369 : Tensor = prim::GetAttr[name="bias"](%362)
  %370 : Tensor = prim::GetAttr[name="weight"](%362)
  %371 : Float(128:1, 128:128) = aten::t(%370), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %output.20 : Float(17:1664, 13:128, 128:1) = aten::matmul(%357, %371), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1676:0
  %x.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.20, %369, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.key # torch/nn/functional.py:1678:0
  %374 : Tensor = prim::GetAttr[name="bias"](%361)
  %375 : Tensor = prim::GetAttr[name="weight"](%361)
  %376 : Float(512:1, 128:512) = aten::t(%375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %output.21 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.26, %376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1676:0
  %x.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.21, %374, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.value # torch/nn/functional.py:1678:0
  %379 : int = aten::size(%x.7, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %380 : int = aten::size(%x.7, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %381 : int[] = prim::ListConstruct(%379, %380, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.7, %381), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %383 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %query_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.8, %383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %385 : int = aten::size(%x.9, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %386 : int = aten::size(%x.9, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %387 : int[] = prim::ListConstruct(%385, %386, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.9, %387), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %389 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %key_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.10, %389), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %391 : int = aten::size(%x.11, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %392 : int = aten::size(%x.11, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:243:0
  %393 : int[] = prim::ListConstruct(%391, %392, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %x.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.11, %393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:244:0
  %395 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %value_layer.2 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.12, %395), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:245:0
  %397 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.2, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.2, %397), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.3, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.4, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.28, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.2 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.29, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self/__module.mobilebert.encoder.layer.1.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.3 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.2, %value_layer.2), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:280:0
  %404 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %405 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.3, %404), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.4 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%405, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:281:0
  %407 : int = aten::size(%context_layer.4, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %408 : int = aten::size(%context_layer.4, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:282:0
  %409 : int[] = prim::ListConstruct(%407, %408, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self
  %input.30 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.4, %409), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.self # transformers/modeling_mobilebert.py:283:0
  %411 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11285.NoNorm = prim::GetAttr[name="LayerNorm"](%359)
  %412 : __torch__.torch.nn.modules.linear.___torch_mangle_11284.Linear = prim::GetAttr[name="dense"](%359)
  %413 : Tensor = prim::GetAttr[name="bias"](%412)
  %414 : Tensor = prim::GetAttr[name="weight"](%412)
  %415 : Float(128:1, 128:128) = aten::t(%414), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %output.22 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.30, %415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.22, %413, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.6, %358, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output # transformers/modeling_mobilebert.py:301:0
  %419 : Tensor = prim::GetAttr[name="bias"](%411)
  %420 : Tensor = prim::GetAttr[name="weight"](%411)
  %421 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.12, %420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.31 : Float(17:1664, 13:128, 128:1) = aten::add(%421, %419, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.attention/__module.mobilebert.encoder.layer.1.attention.output/__module.mobilebert.encoder.layer.1.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %423 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11308.FFNOutput = prim::GetAttr[name="output"](%329)
  %424 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11305.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%329)
  %425 : __torch__.torch.nn.modules.linear.___torch_mangle_11304.Linear = prim::GetAttr[name="dense"](%424)
  %426 : Tensor = prim::GetAttr[name="bias"](%425)
  %427 : Tensor = prim::GetAttr[name="weight"](%425)
  %428 : Float(128:1, 512:128) = aten::t(%427), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.23 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.31, %428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.32 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.23, %426, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate/__module.mobilebert.encoder.layer.1.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.33 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.32), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %432 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11307.NoNorm = prim::GetAttr[name="LayerNorm"](%423)
  %433 : __torch__.torch.nn.modules.linear.___torch_mangle_11306.Linear = prim::GetAttr[name="dense"](%423)
  %434 : Tensor = prim::GetAttr[name="bias"](%433)
  %435 : Tensor = prim::GetAttr[name="weight"](%433)
  %436 : Float(512:1, 128:512) = aten::t(%435), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.24 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.33, %436), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.24, %434, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.7, %input.31, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %440 : Tensor = prim::GetAttr[name="bias"](%432)
  %441 : Tensor = prim::GetAttr[name="weight"](%432)
  %442 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.13, %441), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.34 : Float(17:1664, 13:128, 128:1) = aten::add(%442, %440, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.0/__module.mobilebert.encoder.layer.1.ffn.0.output/__module.mobilebert.encoder.layer.1.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %444 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11314.FFNOutput = prim::GetAttr[name="output"](%327)
  %445 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11311.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%327)
  %446 : __torch__.torch.nn.modules.linear.___torch_mangle_11310.Linear = prim::GetAttr[name="dense"](%445)
  %447 : Tensor = prim::GetAttr[name="bias"](%446)
  %448 : Tensor = prim::GetAttr[name="weight"](%446)
  %449 : Float(128:1, 512:128) = aten::t(%448), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.25 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.34, %449), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.35 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.25, %447, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate/__module.mobilebert.encoder.layer.1.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.36 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.35), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %453 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11313.NoNorm = prim::GetAttr[name="LayerNorm"](%444)
  %454 : __torch__.torch.nn.modules.linear.___torch_mangle_11312.Linear = prim::GetAttr[name="dense"](%444)
  %455 : Tensor = prim::GetAttr[name="bias"](%454)
  %456 : Tensor = prim::GetAttr[name="weight"](%454)
  %457 : Float(512:1, 128:512) = aten::t(%456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.26 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.36, %457), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.26, %455, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.8, %input.34, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %461 : Tensor = prim::GetAttr[name="bias"](%453)
  %462 : Tensor = prim::GetAttr[name="weight"](%453)
  %463 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.14, %462), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.37 : Float(17:1664, 13:128, 128:1) = aten::add(%463, %461, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.1/__module.mobilebert.encoder.layer.1.ffn.1.output/__module.mobilebert.encoder.layer.1.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %465 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11320.FFNOutput = prim::GetAttr[name="output"](%325)
  %466 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11317.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%325)
  %467 : __torch__.torch.nn.modules.linear.___torch_mangle_11316.Linear = prim::GetAttr[name="dense"](%466)
  %468 : Tensor = prim::GetAttr[name="bias"](%467)
  %469 : Tensor = prim::GetAttr[name="weight"](%467)
  %470 : Float(128:1, 512:128) = aten::t(%469), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.27 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.37, %470), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.38 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.27, %468, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate/__module.mobilebert.encoder.layer.1.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.39 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.38), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %474 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11319.NoNorm = prim::GetAttr[name="LayerNorm"](%465)
  %475 : __torch__.torch.nn.modules.linear.___torch_mangle_11318.Linear = prim::GetAttr[name="dense"](%465)
  %476 : Tensor = prim::GetAttr[name="bias"](%475)
  %477 : Tensor = prim::GetAttr[name="weight"](%475)
  %478 : Float(512:1, 128:512) = aten::t(%477), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.28 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.39, %478), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.28, %476, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.9, %input.37, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %482 : Tensor = prim::GetAttr[name="bias"](%474)
  %483 : Tensor = prim::GetAttr[name="weight"](%474)
  %484 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.15, %483), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.40 : Float(17:1664, 13:128, 128:1) = aten::add(%484, %482, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.ffn.2/__module.mobilebert.encoder.layer.1.ffn.2.output/__module.mobilebert.encoder.layer.1.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %486 : __torch__.torch.nn.modules.linear.___torch_mangle_11288.Linear = prim::GetAttr[name="dense"](%323)
  %487 : Tensor = prim::GetAttr[name="bias"](%486)
  %488 : Tensor = prim::GetAttr[name="weight"](%486)
  %489 : Float(128:1, 512:128) = aten::t(%488), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.29 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.40, %489), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.41 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.29, %487, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate/__module.mobilebert.encoder.layer.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.42 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.41), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.intermediate # torch/nn/functional.py:1119:0
  %493 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11295.OutputBottleneck = prim::GetAttr[name="bottleneck"](%322)
  %494 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11291.NoNorm = prim::GetAttr[name="LayerNorm"](%322)
  %495 : __torch__.torch.nn.modules.linear.___torch_mangle_11290.Linear = prim::GetAttr[name="dense"](%322)
  %496 : Tensor = prim::GetAttr[name="bias"](%495)
  %497 : Tensor = prim::GetAttr[name="weight"](%495)
  %498 : Float(512:1, 128:512) = aten::t(%497), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %output.30 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.42, %498), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1676:0
  %layer_output.2 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.30, %496, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.2, %input.40, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output # transformers/modeling_mobilebert.py:405:0
  %502 : Tensor = prim::GetAttr[name="bias"](%494)
  %503 : Tensor = prim::GetAttr[name="weight"](%494)
  %504 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.16, %503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.43 : Float(17:1664, 13:128, 128:1) = aten::add(%504, %502, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %506 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11293.NoNorm = prim::GetAttr[name="LayerNorm"](%493)
  %507 : __torch__.torch.nn.modules.linear.___torch_mangle_11292.Linear = prim::GetAttr[name="dense"](%493)
  %508 : Tensor = prim::GetAttr[name="bias"](%507)
  %509 : Tensor = prim::GetAttr[name="weight"](%507)
  %510 : Float(128:1, 512:128) = aten::t(%509), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.31 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.43, %510), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.44 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.31, %508, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.10 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.44, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.17 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.10, %input.26, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %515 : Tensor = prim::GetAttr[name="bias"](%506)
  %516 : Tensor = prim::GetAttr[name="weight"](%506)
  %517 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.17, %516), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.45 : Float(17:6656, 13:512, 512:1) = aten::add(%517, %515, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.1/__module.mobilebert.encoder.layer.1.output/__module.mobilebert.encoder.layer.1.output.bottleneck/__module.mobilebert.encoder.layer.1.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %519 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11341.MobileBertOutput = prim::GetAttr[name="output"](%120)
  %520 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11334.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%120)
  %521 : __torch__.torch.nn.modules.container.___torch_mangle_11367.ModuleList = prim::GetAttr[name="ffn"](%120)
  %522 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11366.FFNLayer = prim::GetAttr[name="2"](%521)
  %523 : __torch__.torch.nn.modules.container.___torch_mangle_11367.ModuleList = prim::GetAttr[name="ffn"](%120)
  %524 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11360.FFNLayer = prim::GetAttr[name="1"](%523)
  %525 : __torch__.torch.nn.modules.container.___torch_mangle_11367.ModuleList = prim::GetAttr[name="ffn"](%120)
  %526 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11354.FFNLayer = prim::GetAttr[name="0"](%525)
  %527 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11332.MobileBertAttention = prim::GetAttr[name="attention"](%120)
  %528 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11348.Bottleneck = prim::GetAttr[name="bottleneck"](%120)
  %529 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11347.BottleneckLayer = prim::GetAttr[name="attention"](%528)
  %530 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11344.BottleneckLayer = prim::GetAttr[name="input"](%528)
  %531 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11343.NoNorm = prim::GetAttr[name="LayerNorm"](%530)
  %532 : __torch__.torch.nn.modules.linear.___torch_mangle_11342.Linear = prim::GetAttr[name="dense"](%530)
  %533 : Tensor = prim::GetAttr[name="bias"](%532)
  %534 : Tensor = prim::GetAttr[name="weight"](%532)
  %535 : Float(512:1, 128:512) = aten::t(%534), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.32 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.32, %533, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %538 : Tensor = prim::GetAttr[name="bias"](%531)
  %539 : Tensor = prim::GetAttr[name="weight"](%531)
  %540 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.18, %539), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.3 : Float(17:1664, 13:128, 128:1) = aten::add(%540, %538, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.input/__module.mobilebert.encoder.layer.2.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %542 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11346.NoNorm = prim::GetAttr[name="LayerNorm"](%529)
  %543 : __torch__.torch.nn.modules.linear.___torch_mangle_11345.Linear = prim::GetAttr[name="dense"](%529)
  %544 : Tensor = prim::GetAttr[name="bias"](%543)
  %545 : Tensor = prim::GetAttr[name="weight"](%543)
  %546 : Float(512:1, 128:512) = aten::t(%545), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.33 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %546), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.33, %544, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %549 : Tensor = prim::GetAttr[name="bias"](%542)
  %550 : Tensor = prim::GetAttr[name="weight"](%542)
  %551 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.19, %550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.46 : Float(17:1664, 13:128, 128:1) = aten::add(%551, %549, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.bottleneck/__module.mobilebert.encoder.layer.2.bottleneck.attention/__module.mobilebert.encoder.layer.2.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %553 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.46, %residual_tensor.3)
  %554 : Float(17:1664, 13:128, 128:1), %555 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%553)
  %556 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11331.MobileBertSelfOutput = prim::GetAttr[name="output"](%527)
  %557 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11328.MobileBertSelfAttention = prim::GetAttr[name="self"](%527)
  %558 : __torch__.torch.nn.modules.linear.___torch_mangle_11326.Linear = prim::GetAttr[name="value"](%557)
  %559 : __torch__.torch.nn.modules.linear.___torch_mangle_11325.Linear = prim::GetAttr[name="key"](%557)
  %560 : __torch__.torch.nn.modules.linear.___torch_mangle_11324.Linear = prim::GetAttr[name="query"](%557)
  %561 : Tensor = prim::GetAttr[name="bias"](%560)
  %562 : Tensor = prim::GetAttr[name="weight"](%560)
  %563 : Float(128:1, 128:128) = aten::t(%562), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %output.34 : Float(17:1664, 13:128, 128:1) = aten::matmul(%554, %563), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1676:0
  %x.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.34, %561, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.query # torch/nn/functional.py:1678:0
  %566 : Tensor = prim::GetAttr[name="bias"](%559)
  %567 : Tensor = prim::GetAttr[name="weight"](%559)
  %568 : Float(128:1, 128:128) = aten::t(%567), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %output.35 : Float(17:1664, 13:128, 128:1) = aten::matmul(%554, %568), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1676:0
  %x.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.35, %566, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.key # torch/nn/functional.py:1678:0
  %571 : Tensor = prim::GetAttr[name="bias"](%558)
  %572 : Tensor = prim::GetAttr[name="weight"](%558)
  %573 : Float(512:1, 128:512) = aten::t(%572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %output.36 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.45, %573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1676:0
  %x.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.36, %571, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.value # torch/nn/functional.py:1678:0
  %576 : int = aten::size(%x.13, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %577 : int = aten::size(%x.13, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %578 : int[] = prim::ListConstruct(%576, %577, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.13, %578), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %580 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %query_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.14, %580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %582 : int = aten::size(%x.15, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %583 : int = aten::size(%x.15, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %584 : int[] = prim::ListConstruct(%582, %583, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.15, %584), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %586 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %key_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.16, %586), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %588 : int = aten::size(%x.17, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %589 : int = aten::size(%x.17, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:243:0
  %590 : int[] = prim::ListConstruct(%588, %589, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %x.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.17, %590), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:244:0
  %592 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %value_layer.3 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.18, %592), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:245:0
  %594 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.3, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.3, %594), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.5, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.6, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.48 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.47, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.3 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.48, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self/__module.mobilebert.encoder.layer.2.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.5 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.3, %value_layer.3), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:280:0
  %601 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %602 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.5, %601), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.6 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%602, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:281:0
  %604 : int = aten::size(%context_layer.6, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %605 : int = aten::size(%context_layer.6, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:282:0
  %606 : int[] = prim::ListConstruct(%604, %605, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self
  %input.49 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.6, %606), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.self # transformers/modeling_mobilebert.py:283:0
  %608 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11330.NoNorm = prim::GetAttr[name="LayerNorm"](%556)
  %609 : __torch__.torch.nn.modules.linear.___torch_mangle_11329.Linear = prim::GetAttr[name="dense"](%556)
  %610 : Tensor = prim::GetAttr[name="bias"](%609)
  %611 : Tensor = prim::GetAttr[name="weight"](%609)
  %612 : Float(128:1, 128:128) = aten::t(%611), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %output.37 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.49, %612), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.37, %610, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.11, %555, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output # transformers/modeling_mobilebert.py:301:0
  %616 : Tensor = prim::GetAttr[name="bias"](%608)
  %617 : Tensor = prim::GetAttr[name="weight"](%608)
  %618 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.20, %617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.50 : Float(17:1664, 13:128, 128:1) = aten::add(%618, %616, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.attention/__module.mobilebert.encoder.layer.2.attention.output/__module.mobilebert.encoder.layer.2.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %620 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11353.FFNOutput = prim::GetAttr[name="output"](%526)
  %621 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11350.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%526)
  %622 : __torch__.torch.nn.modules.linear.___torch_mangle_11349.Linear = prim::GetAttr[name="dense"](%621)
  %623 : Tensor = prim::GetAttr[name="bias"](%622)
  %624 : Tensor = prim::GetAttr[name="weight"](%622)
  %625 : Float(128:1, 512:128) = aten::t(%624), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.38 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.50, %625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.51 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.38, %623, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate/__module.mobilebert.encoder.layer.2.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.52 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.51), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %629 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11352.NoNorm = prim::GetAttr[name="LayerNorm"](%620)
  %630 : __torch__.torch.nn.modules.linear.___torch_mangle_11351.Linear = prim::GetAttr[name="dense"](%620)
  %631 : Tensor = prim::GetAttr[name="bias"](%630)
  %632 : Tensor = prim::GetAttr[name="weight"](%630)
  %633 : Float(512:1, 128:512) = aten::t(%632), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.39 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.52, %633), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.39, %631, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.12, %input.50, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %637 : Tensor = prim::GetAttr[name="bias"](%629)
  %638 : Tensor = prim::GetAttr[name="weight"](%629)
  %639 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.21, %638), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.53 : Float(17:1664, 13:128, 128:1) = aten::add(%639, %637, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.0/__module.mobilebert.encoder.layer.2.ffn.0.output/__module.mobilebert.encoder.layer.2.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %641 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11359.FFNOutput = prim::GetAttr[name="output"](%524)
  %642 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11356.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%524)
  %643 : __torch__.torch.nn.modules.linear.___torch_mangle_11355.Linear = prim::GetAttr[name="dense"](%642)
  %644 : Tensor = prim::GetAttr[name="bias"](%643)
  %645 : Tensor = prim::GetAttr[name="weight"](%643)
  %646 : Float(128:1, 512:128) = aten::t(%645), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.40 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.53, %646), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.54 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.40, %644, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate/__module.mobilebert.encoder.layer.2.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.55 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.54), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %650 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11358.NoNorm = prim::GetAttr[name="LayerNorm"](%641)
  %651 : __torch__.torch.nn.modules.linear.___torch_mangle_11357.Linear = prim::GetAttr[name="dense"](%641)
  %652 : Tensor = prim::GetAttr[name="bias"](%651)
  %653 : Tensor = prim::GetAttr[name="weight"](%651)
  %654 : Float(512:1, 128:512) = aten::t(%653), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.41 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.55, %654), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.41, %652, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.13, %input.53, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %658 : Tensor = prim::GetAttr[name="bias"](%650)
  %659 : Tensor = prim::GetAttr[name="weight"](%650)
  %660 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.22, %659), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.56 : Float(17:1664, 13:128, 128:1) = aten::add(%660, %658, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.1/__module.mobilebert.encoder.layer.2.ffn.1.output/__module.mobilebert.encoder.layer.2.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %662 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11365.FFNOutput = prim::GetAttr[name="output"](%522)
  %663 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11362.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%522)
  %664 : __torch__.torch.nn.modules.linear.___torch_mangle_11361.Linear = prim::GetAttr[name="dense"](%663)
  %665 : Tensor = prim::GetAttr[name="bias"](%664)
  %666 : Tensor = prim::GetAttr[name="weight"](%664)
  %667 : Float(128:1, 512:128) = aten::t(%666), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.42 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.56, %667), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.57 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.42, %665, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate/__module.mobilebert.encoder.layer.2.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.58 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.57), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %671 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11364.NoNorm = prim::GetAttr[name="LayerNorm"](%662)
  %672 : __torch__.torch.nn.modules.linear.___torch_mangle_11363.Linear = prim::GetAttr[name="dense"](%662)
  %673 : Tensor = prim::GetAttr[name="bias"](%672)
  %674 : Tensor = prim::GetAttr[name="weight"](%672)
  %675 : Float(512:1, 128:512) = aten::t(%674), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.43 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.58, %675), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.43, %673, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.14, %input.56, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %679 : Tensor = prim::GetAttr[name="bias"](%671)
  %680 : Tensor = prim::GetAttr[name="weight"](%671)
  %681 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.23, %680), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.59 : Float(17:1664, 13:128, 128:1) = aten::add(%681, %679, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.ffn.2/__module.mobilebert.encoder.layer.2.ffn.2.output/__module.mobilebert.encoder.layer.2.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %683 : __torch__.torch.nn.modules.linear.___torch_mangle_11333.Linear = prim::GetAttr[name="dense"](%520)
  %684 : Tensor = prim::GetAttr[name="bias"](%683)
  %685 : Tensor = prim::GetAttr[name="weight"](%683)
  %686 : Float(128:1, 512:128) = aten::t(%685), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.44 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.59, %686), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.60 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.44, %684, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate/__module.mobilebert.encoder.layer.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.61 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.60), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.intermediate # torch/nn/functional.py:1119:0
  %690 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11340.OutputBottleneck = prim::GetAttr[name="bottleneck"](%519)
  %691 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11336.NoNorm = prim::GetAttr[name="LayerNorm"](%519)
  %692 : __torch__.torch.nn.modules.linear.___torch_mangle_11335.Linear = prim::GetAttr[name="dense"](%519)
  %693 : Tensor = prim::GetAttr[name="bias"](%692)
  %694 : Tensor = prim::GetAttr[name="weight"](%692)
  %695 : Float(512:1, 128:512) = aten::t(%694), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %output.45 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.61, %695), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1676:0
  %layer_output.3 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.45, %693, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.24 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.3, %input.59, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output # transformers/modeling_mobilebert.py:405:0
  %699 : Tensor = prim::GetAttr[name="bias"](%691)
  %700 : Tensor = prim::GetAttr[name="weight"](%691)
  %701 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.24, %700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.62 : Float(17:1664, 13:128, 128:1) = aten::add(%701, %699, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %703 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11338.NoNorm = prim::GetAttr[name="LayerNorm"](%690)
  %704 : __torch__.torch.nn.modules.linear.___torch_mangle_11337.Linear = prim::GetAttr[name="dense"](%690)
  %705 : Tensor = prim::GetAttr[name="bias"](%704)
  %706 : Tensor = prim::GetAttr[name="weight"](%704)
  %707 : Float(128:1, 512:128) = aten::t(%706), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.46 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.62, %707), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.63 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.46, %705, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.15 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.63, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.25 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.15, %input.45, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %712 : Tensor = prim::GetAttr[name="bias"](%703)
  %713 : Tensor = prim::GetAttr[name="weight"](%703)
  %714 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.25, %713), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.64 : Float(17:6656, 13:512, 512:1) = aten::add(%714, %712, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.2/__module.mobilebert.encoder.layer.2.output/__module.mobilebert.encoder.layer.2.output.bottleneck/__module.mobilebert.encoder.layer.2.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %716 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11386.MobileBertOutput = prim::GetAttr[name="output"](%118)
  %717 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11379.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%118)
  %718 : __torch__.torch.nn.modules.container.___torch_mangle_11412.ModuleList = prim::GetAttr[name="ffn"](%118)
  %719 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11411.FFNLayer = prim::GetAttr[name="2"](%718)
  %720 : __torch__.torch.nn.modules.container.___torch_mangle_11412.ModuleList = prim::GetAttr[name="ffn"](%118)
  %721 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11405.FFNLayer = prim::GetAttr[name="1"](%720)
  %722 : __torch__.torch.nn.modules.container.___torch_mangle_11412.ModuleList = prim::GetAttr[name="ffn"](%118)
  %723 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11399.FFNLayer = prim::GetAttr[name="0"](%722)
  %724 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11377.MobileBertAttention = prim::GetAttr[name="attention"](%118)
  %725 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11393.Bottleneck = prim::GetAttr[name="bottleneck"](%118)
  %726 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11392.BottleneckLayer = prim::GetAttr[name="attention"](%725)
  %727 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11389.BottleneckLayer = prim::GetAttr[name="input"](%725)
  %728 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11388.NoNorm = prim::GetAttr[name="LayerNorm"](%727)
  %729 : __torch__.torch.nn.modules.linear.___torch_mangle_11387.Linear = prim::GetAttr[name="dense"](%727)
  %730 : Tensor = prim::GetAttr[name="bias"](%729)
  %731 : Tensor = prim::GetAttr[name="weight"](%729)
  %732 : Float(512:1, 128:512) = aten::t(%731), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.47 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.47, %730, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %735 : Tensor = prim::GetAttr[name="bias"](%728)
  %736 : Tensor = prim::GetAttr[name="weight"](%728)
  %737 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.26, %736), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.4 : Float(17:1664, 13:128, 128:1) = aten::add(%737, %735, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.input/__module.mobilebert.encoder.layer.3.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %739 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11391.NoNorm = prim::GetAttr[name="LayerNorm"](%726)
  %740 : __torch__.torch.nn.modules.linear.___torch_mangle_11390.Linear = prim::GetAttr[name="dense"](%726)
  %741 : Tensor = prim::GetAttr[name="bias"](%740)
  %742 : Tensor = prim::GetAttr[name="weight"](%740)
  %743 : Float(512:1, 128:512) = aten::t(%742), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.48 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %743), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.48, %741, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %746 : Tensor = prim::GetAttr[name="bias"](%739)
  %747 : Tensor = prim::GetAttr[name="weight"](%739)
  %748 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.27, %747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.65 : Float(17:1664, 13:128, 128:1) = aten::add(%748, %746, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.bottleneck/__module.mobilebert.encoder.layer.3.bottleneck.attention/__module.mobilebert.encoder.layer.3.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %750 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.65, %residual_tensor.4)
  %751 : Float(17:1664, 13:128, 128:1), %752 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%750)
  %753 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11376.MobileBertSelfOutput = prim::GetAttr[name="output"](%724)
  %754 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11373.MobileBertSelfAttention = prim::GetAttr[name="self"](%724)
  %755 : __torch__.torch.nn.modules.linear.___torch_mangle_11371.Linear = prim::GetAttr[name="value"](%754)
  %756 : __torch__.torch.nn.modules.linear.___torch_mangle_11370.Linear = prim::GetAttr[name="key"](%754)
  %757 : __torch__.torch.nn.modules.linear.___torch_mangle_11369.Linear = prim::GetAttr[name="query"](%754)
  %758 : Tensor = prim::GetAttr[name="bias"](%757)
  %759 : Tensor = prim::GetAttr[name="weight"](%757)
  %760 : Float(128:1, 128:128) = aten::t(%759), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %output.49 : Float(17:1664, 13:128, 128:1) = aten::matmul(%751, %760), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1676:0
  %x.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.49, %758, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.query # torch/nn/functional.py:1678:0
  %763 : Tensor = prim::GetAttr[name="bias"](%756)
  %764 : Tensor = prim::GetAttr[name="weight"](%756)
  %765 : Float(128:1, 128:128) = aten::t(%764), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %output.50 : Float(17:1664, 13:128, 128:1) = aten::matmul(%751, %765), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1676:0
  %x.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.50, %763, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.key # torch/nn/functional.py:1678:0
  %768 : Tensor = prim::GetAttr[name="bias"](%755)
  %769 : Tensor = prim::GetAttr[name="weight"](%755)
  %770 : Float(512:1, 128:512) = aten::t(%769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %output.51 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.64, %770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1676:0
  %x.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.51, %768, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.value # torch/nn/functional.py:1678:0
  %773 : int = aten::size(%x.19, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %774 : int = aten::size(%x.19, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %775 : int[] = prim::ListConstruct(%773, %774, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.19, %775), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %777 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %query_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.20, %777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %779 : int = aten::size(%x.21, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %780 : int = aten::size(%x.21, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %781 : int[] = prim::ListConstruct(%779, %780, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.21, %781), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %783 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %key_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.22, %783), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %785 : int = aten::size(%x.23, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %786 : int = aten::size(%x.23, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:243:0
  %787 : int[] = prim::ListConstruct(%785, %786, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %x.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.23, %787), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:244:0
  %789 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %value_layer.4 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.24, %789), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:245:0
  %791 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.4, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.4, %791), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.7, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.66 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.8, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.67 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.66, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.4 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.67, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self/__module.mobilebert.encoder.layer.3.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.7 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.4, %value_layer.4), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:280:0
  %798 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %799 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.7, %798), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.8 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%799, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:281:0
  %801 : int = aten::size(%context_layer.8, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %802 : int = aten::size(%context_layer.8, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:282:0
  %803 : int[] = prim::ListConstruct(%801, %802, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self
  %input.68 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.8, %803), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.self # transformers/modeling_mobilebert.py:283:0
  %805 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11375.NoNorm = prim::GetAttr[name="LayerNorm"](%753)
  %806 : __torch__.torch.nn.modules.linear.___torch_mangle_11374.Linear = prim::GetAttr[name="dense"](%753)
  %807 : Tensor = prim::GetAttr[name="bias"](%806)
  %808 : Tensor = prim::GetAttr[name="weight"](%806)
  %809 : Float(128:1, 128:128) = aten::t(%808), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %output.52 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.68, %809), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.52, %807, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.28 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.16, %752, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output # transformers/modeling_mobilebert.py:301:0
  %813 : Tensor = prim::GetAttr[name="bias"](%805)
  %814 : Tensor = prim::GetAttr[name="weight"](%805)
  %815 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.28, %814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.69 : Float(17:1664, 13:128, 128:1) = aten::add(%815, %813, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.attention/__module.mobilebert.encoder.layer.3.attention.output/__module.mobilebert.encoder.layer.3.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %817 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11398.FFNOutput = prim::GetAttr[name="output"](%723)
  %818 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11395.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%723)
  %819 : __torch__.torch.nn.modules.linear.___torch_mangle_11394.Linear = prim::GetAttr[name="dense"](%818)
  %820 : Tensor = prim::GetAttr[name="bias"](%819)
  %821 : Tensor = prim::GetAttr[name="weight"](%819)
  %822 : Float(128:1, 512:128) = aten::t(%821), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.53 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.69, %822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.70 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.53, %820, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate/__module.mobilebert.encoder.layer.3.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.71 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.70), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %826 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11397.NoNorm = prim::GetAttr[name="LayerNorm"](%817)
  %827 : __torch__.torch.nn.modules.linear.___torch_mangle_11396.Linear = prim::GetAttr[name="dense"](%817)
  %828 : Tensor = prim::GetAttr[name="bias"](%827)
  %829 : Tensor = prim::GetAttr[name="weight"](%827)
  %830 : Float(512:1, 128:512) = aten::t(%829), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.54 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.71, %830), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.54, %828, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.29 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.17, %input.69, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %834 : Tensor = prim::GetAttr[name="bias"](%826)
  %835 : Tensor = prim::GetAttr[name="weight"](%826)
  %836 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.29, %835), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.72 : Float(17:1664, 13:128, 128:1) = aten::add(%836, %834, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.0/__module.mobilebert.encoder.layer.3.ffn.0.output/__module.mobilebert.encoder.layer.3.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %838 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11404.FFNOutput = prim::GetAttr[name="output"](%721)
  %839 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11401.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%721)
  %840 : __torch__.torch.nn.modules.linear.___torch_mangle_11400.Linear = prim::GetAttr[name="dense"](%839)
  %841 : Tensor = prim::GetAttr[name="bias"](%840)
  %842 : Tensor = prim::GetAttr[name="weight"](%840)
  %843 : Float(128:1, 512:128) = aten::t(%842), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.55 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.72, %843), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.73 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.55, %841, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate/__module.mobilebert.encoder.layer.3.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.74 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.73), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %847 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11403.NoNorm = prim::GetAttr[name="LayerNorm"](%838)
  %848 : __torch__.torch.nn.modules.linear.___torch_mangle_11402.Linear = prim::GetAttr[name="dense"](%838)
  %849 : Tensor = prim::GetAttr[name="bias"](%848)
  %850 : Tensor = prim::GetAttr[name="weight"](%848)
  %851 : Float(512:1, 128:512) = aten::t(%850), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.56 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.74, %851), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.56, %849, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.30 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.18, %input.72, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %855 : Tensor = prim::GetAttr[name="bias"](%847)
  %856 : Tensor = prim::GetAttr[name="weight"](%847)
  %857 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.30, %856), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.75 : Float(17:1664, 13:128, 128:1) = aten::add(%857, %855, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.1/__module.mobilebert.encoder.layer.3.ffn.1.output/__module.mobilebert.encoder.layer.3.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %859 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11410.FFNOutput = prim::GetAttr[name="output"](%719)
  %860 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11407.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%719)
  %861 : __torch__.torch.nn.modules.linear.___torch_mangle_11406.Linear = prim::GetAttr[name="dense"](%860)
  %862 : Tensor = prim::GetAttr[name="bias"](%861)
  %863 : Tensor = prim::GetAttr[name="weight"](%861)
  %864 : Float(128:1, 512:128) = aten::t(%863), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.57 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.75, %864), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.76 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.57, %862, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate/__module.mobilebert.encoder.layer.3.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.77 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.76), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %868 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11409.NoNorm = prim::GetAttr[name="LayerNorm"](%859)
  %869 : __torch__.torch.nn.modules.linear.___torch_mangle_11408.Linear = prim::GetAttr[name="dense"](%859)
  %870 : Tensor = prim::GetAttr[name="bias"](%869)
  %871 : Tensor = prim::GetAttr[name="weight"](%869)
  %872 : Float(512:1, 128:512) = aten::t(%871), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.58 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.77, %872), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.58, %870, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.31 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.19, %input.75, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %876 : Tensor = prim::GetAttr[name="bias"](%868)
  %877 : Tensor = prim::GetAttr[name="weight"](%868)
  %878 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.31, %877), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.78 : Float(17:1664, 13:128, 128:1) = aten::add(%878, %876, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.ffn.2/__module.mobilebert.encoder.layer.3.ffn.2.output/__module.mobilebert.encoder.layer.3.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %880 : __torch__.torch.nn.modules.linear.___torch_mangle_11378.Linear = prim::GetAttr[name="dense"](%717)
  %881 : Tensor = prim::GetAttr[name="bias"](%880)
  %882 : Tensor = prim::GetAttr[name="weight"](%880)
  %883 : Float(128:1, 512:128) = aten::t(%882), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %output.59 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.78, %883), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1676:0
  %input.79 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.59, %881, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate/__module.mobilebert.encoder.layer.3.intermediate.dense # torch/nn/functional.py:1678:0
  %input.80 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.79), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.intermediate # torch/nn/functional.py:1119:0
  %887 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11385.OutputBottleneck = prim::GetAttr[name="bottleneck"](%716)
  %888 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11381.NoNorm = prim::GetAttr[name="LayerNorm"](%716)
  %889 : __torch__.torch.nn.modules.linear.___torch_mangle_11380.Linear = prim::GetAttr[name="dense"](%716)
  %890 : Tensor = prim::GetAttr[name="bias"](%889)
  %891 : Tensor = prim::GetAttr[name="weight"](%889)
  %892 : Float(512:1, 128:512) = aten::t(%891), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %output.60 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.80, %892), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1676:0
  %layer_output.4 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.60, %890, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.32 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.4, %input.78, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output # transformers/modeling_mobilebert.py:405:0
  %896 : Tensor = prim::GetAttr[name="bias"](%888)
  %897 : Tensor = prim::GetAttr[name="weight"](%888)
  %898 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.32, %897), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.81 : Float(17:1664, 13:128, 128:1) = aten::add(%898, %896, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %900 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11383.NoNorm = prim::GetAttr[name="LayerNorm"](%887)
  %901 : __torch__.torch.nn.modules.linear.___torch_mangle_11382.Linear = prim::GetAttr[name="dense"](%887)
  %902 : Tensor = prim::GetAttr[name="bias"](%901)
  %903 : Tensor = prim::GetAttr[name="weight"](%901)
  %904 : Float(128:1, 512:128) = aten::t(%903), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.61 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.81, %904), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.82 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.61, %902, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.20 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.82, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.33 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.20, %input.64, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %909 : Tensor = prim::GetAttr[name="bias"](%900)
  %910 : Tensor = prim::GetAttr[name="weight"](%900)
  %911 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.33, %910), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.83 : Float(17:6656, 13:512, 512:1) = aten::add(%911, %909, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.3/__module.mobilebert.encoder.layer.3.output/__module.mobilebert.encoder.layer.3.output.bottleneck/__module.mobilebert.encoder.layer.3.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %913 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11431.MobileBertOutput = prim::GetAttr[name="output"](%116)
  %914 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11424.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%116)
  %915 : __torch__.torch.nn.modules.container.___torch_mangle_11457.ModuleList = prim::GetAttr[name="ffn"](%116)
  %916 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11456.FFNLayer = prim::GetAttr[name="2"](%915)
  %917 : __torch__.torch.nn.modules.container.___torch_mangle_11457.ModuleList = prim::GetAttr[name="ffn"](%116)
  %918 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11450.FFNLayer = prim::GetAttr[name="1"](%917)
  %919 : __torch__.torch.nn.modules.container.___torch_mangle_11457.ModuleList = prim::GetAttr[name="ffn"](%116)
  %920 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11444.FFNLayer = prim::GetAttr[name="0"](%919)
  %921 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11422.MobileBertAttention = prim::GetAttr[name="attention"](%116)
  %922 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11438.Bottleneck = prim::GetAttr[name="bottleneck"](%116)
  %923 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11437.BottleneckLayer = prim::GetAttr[name="attention"](%922)
  %924 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11434.BottleneckLayer = prim::GetAttr[name="input"](%922)
  %925 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11433.NoNorm = prim::GetAttr[name="LayerNorm"](%924)
  %926 : __torch__.torch.nn.modules.linear.___torch_mangle_11432.Linear = prim::GetAttr[name="dense"](%924)
  %927 : Tensor = prim::GetAttr[name="bias"](%926)
  %928 : Tensor = prim::GetAttr[name="weight"](%926)
  %929 : Float(512:1, 128:512) = aten::t(%928), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.62 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %929), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.62, %927, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %932 : Tensor = prim::GetAttr[name="bias"](%925)
  %933 : Tensor = prim::GetAttr[name="weight"](%925)
  %934 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.34, %933), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.5 : Float(17:1664, 13:128, 128:1) = aten::add(%934, %932, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.input/__module.mobilebert.encoder.layer.4.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %936 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11436.NoNorm = prim::GetAttr[name="LayerNorm"](%923)
  %937 : __torch__.torch.nn.modules.linear.___torch_mangle_11435.Linear = prim::GetAttr[name="dense"](%923)
  %938 : Tensor = prim::GetAttr[name="bias"](%937)
  %939 : Tensor = prim::GetAttr[name="weight"](%937)
  %940 : Float(512:1, 128:512) = aten::t(%939), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.63 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %940), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.63, %938, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %943 : Tensor = prim::GetAttr[name="bias"](%936)
  %944 : Tensor = prim::GetAttr[name="weight"](%936)
  %945 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.35, %944), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.84 : Float(17:1664, 13:128, 128:1) = aten::add(%945, %943, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.bottleneck/__module.mobilebert.encoder.layer.4.bottleneck.attention/__module.mobilebert.encoder.layer.4.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %947 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.84, %residual_tensor.5)
  %948 : Float(17:1664, 13:128, 128:1), %949 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%947)
  %950 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11421.MobileBertSelfOutput = prim::GetAttr[name="output"](%921)
  %951 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11418.MobileBertSelfAttention = prim::GetAttr[name="self"](%921)
  %952 : __torch__.torch.nn.modules.linear.___torch_mangle_11416.Linear = prim::GetAttr[name="value"](%951)
  %953 : __torch__.torch.nn.modules.linear.___torch_mangle_11415.Linear = prim::GetAttr[name="key"](%951)
  %954 : __torch__.torch.nn.modules.linear.___torch_mangle_11414.Linear = prim::GetAttr[name="query"](%951)
  %955 : Tensor = prim::GetAttr[name="bias"](%954)
  %956 : Tensor = prim::GetAttr[name="weight"](%954)
  %957 : Float(128:1, 128:128) = aten::t(%956), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %output.64 : Float(17:1664, 13:128, 128:1) = aten::matmul(%948, %957), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1676:0
  %x.25 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.64, %955, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.query # torch/nn/functional.py:1678:0
  %960 : Tensor = prim::GetAttr[name="bias"](%953)
  %961 : Tensor = prim::GetAttr[name="weight"](%953)
  %962 : Float(128:1, 128:128) = aten::t(%961), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %output.65 : Float(17:1664, 13:128, 128:1) = aten::matmul(%948, %962), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1676:0
  %x.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.65, %960, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.key # torch/nn/functional.py:1678:0
  %965 : Tensor = prim::GetAttr[name="bias"](%952)
  %966 : Tensor = prim::GetAttr[name="weight"](%952)
  %967 : Float(512:1, 128:512) = aten::t(%966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %output.66 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.83, %967), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1676:0
  %x.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.66, %965, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.value # torch/nn/functional.py:1678:0
  %970 : int = aten::size(%x.25, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %971 : int = aten::size(%x.25, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %972 : int[] = prim::ListConstruct(%970, %971, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.25, %972), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %974 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %query_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.26, %974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %976 : int = aten::size(%x.27, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %977 : int = aten::size(%x.27, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %978 : int[] = prim::ListConstruct(%976, %977, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.27, %978), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %980 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %key_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.28, %980), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %982 : int = aten::size(%x.29, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %983 : int = aten::size(%x.29, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:243:0
  %984 : int[] = prim::ListConstruct(%982, %983, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %x.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.29, %984), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:244:0
  %986 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %value_layer.5 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.30, %986), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:245:0
  %988 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.5, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.5, %988), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.9, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.85 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.10, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.86 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.85, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.5 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.86, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self/__module.mobilebert.encoder.layer.4.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.9 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.5, %value_layer.5), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:280:0
  %995 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %996 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.9, %995), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.10 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%996, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:281:0
  %998 : int = aten::size(%context_layer.10, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %999 : int = aten::size(%context_layer.10, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:282:0
  %1000 : int[] = prim::ListConstruct(%998, %999, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self
  %input.87 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.10, %1000), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.self # transformers/modeling_mobilebert.py:283:0
  %1002 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11420.NoNorm = prim::GetAttr[name="LayerNorm"](%950)
  %1003 : __torch__.torch.nn.modules.linear.___torch_mangle_11419.Linear = prim::GetAttr[name="dense"](%950)
  %1004 : Tensor = prim::GetAttr[name="bias"](%1003)
  %1005 : Tensor = prim::GetAttr[name="weight"](%1003)
  %1006 : Float(128:1, 128:128) = aten::t(%1005), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %output.67 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.87, %1006), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.67, %1004, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.36 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.21, %949, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output # transformers/modeling_mobilebert.py:301:0
  %1010 : Tensor = prim::GetAttr[name="bias"](%1002)
  %1011 : Tensor = prim::GetAttr[name="weight"](%1002)
  %1012 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.36, %1011), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.88 : Float(17:1664, 13:128, 128:1) = aten::add(%1012, %1010, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.attention/__module.mobilebert.encoder.layer.4.attention.output/__module.mobilebert.encoder.layer.4.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1014 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11443.FFNOutput = prim::GetAttr[name="output"](%920)
  %1015 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11440.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%920)
  %1016 : __torch__.torch.nn.modules.linear.___torch_mangle_11439.Linear = prim::GetAttr[name="dense"](%1015)
  %1017 : Tensor = prim::GetAttr[name="bias"](%1016)
  %1018 : Tensor = prim::GetAttr[name="weight"](%1016)
  %1019 : Float(128:1, 512:128) = aten::t(%1018), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.68 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.88, %1019), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.89 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.68, %1017, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate/__module.mobilebert.encoder.layer.4.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.90 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.89), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1023 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11442.NoNorm = prim::GetAttr[name="LayerNorm"](%1014)
  %1024 : __torch__.torch.nn.modules.linear.___torch_mangle_11441.Linear = prim::GetAttr[name="dense"](%1014)
  %1025 : Tensor = prim::GetAttr[name="bias"](%1024)
  %1026 : Tensor = prim::GetAttr[name="weight"](%1024)
  %1027 : Float(512:1, 128:512) = aten::t(%1026), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.69 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.90, %1027), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.69, %1025, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.37 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.22, %input.88, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1031 : Tensor = prim::GetAttr[name="bias"](%1023)
  %1032 : Tensor = prim::GetAttr[name="weight"](%1023)
  %1033 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.37, %1032), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.91 : Float(17:1664, 13:128, 128:1) = aten::add(%1033, %1031, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.0/__module.mobilebert.encoder.layer.4.ffn.0.output/__module.mobilebert.encoder.layer.4.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1035 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11449.FFNOutput = prim::GetAttr[name="output"](%918)
  %1036 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11446.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%918)
  %1037 : __torch__.torch.nn.modules.linear.___torch_mangle_11445.Linear = prim::GetAttr[name="dense"](%1036)
  %1038 : Tensor = prim::GetAttr[name="bias"](%1037)
  %1039 : Tensor = prim::GetAttr[name="weight"](%1037)
  %1040 : Float(128:1, 512:128) = aten::t(%1039), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.70 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.91, %1040), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.92 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.70, %1038, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate/__module.mobilebert.encoder.layer.4.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.93 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.92), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1044 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11448.NoNorm = prim::GetAttr[name="LayerNorm"](%1035)
  %1045 : __torch__.torch.nn.modules.linear.___torch_mangle_11447.Linear = prim::GetAttr[name="dense"](%1035)
  %1046 : Tensor = prim::GetAttr[name="bias"](%1045)
  %1047 : Tensor = prim::GetAttr[name="weight"](%1045)
  %1048 : Float(512:1, 128:512) = aten::t(%1047), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.71 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.93, %1048), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.71, %1046, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.38 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.23, %input.91, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1052 : Tensor = prim::GetAttr[name="bias"](%1044)
  %1053 : Tensor = prim::GetAttr[name="weight"](%1044)
  %1054 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.38, %1053), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.94 : Float(17:1664, 13:128, 128:1) = aten::add(%1054, %1052, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.1/__module.mobilebert.encoder.layer.4.ffn.1.output/__module.mobilebert.encoder.layer.4.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1056 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11455.FFNOutput = prim::GetAttr[name="output"](%916)
  %1057 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11452.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%916)
  %1058 : __torch__.torch.nn.modules.linear.___torch_mangle_11451.Linear = prim::GetAttr[name="dense"](%1057)
  %1059 : Tensor = prim::GetAttr[name="bias"](%1058)
  %1060 : Tensor = prim::GetAttr[name="weight"](%1058)
  %1061 : Float(128:1, 512:128) = aten::t(%1060), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.72 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.94, %1061), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.95 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.72, %1059, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate/__module.mobilebert.encoder.layer.4.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.96 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.95), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1065 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11454.NoNorm = prim::GetAttr[name="LayerNorm"](%1056)
  %1066 : __torch__.torch.nn.modules.linear.___torch_mangle_11453.Linear = prim::GetAttr[name="dense"](%1056)
  %1067 : Tensor = prim::GetAttr[name="bias"](%1066)
  %1068 : Tensor = prim::GetAttr[name="weight"](%1066)
  %1069 : Float(512:1, 128:512) = aten::t(%1068), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.73 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.96, %1069), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.24 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.73, %1067, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.39 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.24, %input.94, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1073 : Tensor = prim::GetAttr[name="bias"](%1065)
  %1074 : Tensor = prim::GetAttr[name="weight"](%1065)
  %1075 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.39, %1074), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.97 : Float(17:1664, 13:128, 128:1) = aten::add(%1075, %1073, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.ffn.2/__module.mobilebert.encoder.layer.4.ffn.2.output/__module.mobilebert.encoder.layer.4.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1077 : __torch__.torch.nn.modules.linear.___torch_mangle_11423.Linear = prim::GetAttr[name="dense"](%914)
  %1078 : Tensor = prim::GetAttr[name="bias"](%1077)
  %1079 : Tensor = prim::GetAttr[name="weight"](%1077)
  %1080 : Float(128:1, 512:128) = aten::t(%1079), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %output.74 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.97, %1080), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1676:0
  %input.98 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.74, %1078, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate/__module.mobilebert.encoder.layer.4.intermediate.dense # torch/nn/functional.py:1678:0
  %input.99 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.98), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.intermediate # torch/nn/functional.py:1119:0
  %1084 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11430.OutputBottleneck = prim::GetAttr[name="bottleneck"](%913)
  %1085 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11426.NoNorm = prim::GetAttr[name="LayerNorm"](%913)
  %1086 : __torch__.torch.nn.modules.linear.___torch_mangle_11425.Linear = prim::GetAttr[name="dense"](%913)
  %1087 : Tensor = prim::GetAttr[name="bias"](%1086)
  %1088 : Tensor = prim::GetAttr[name="weight"](%1086)
  %1089 : Float(512:1, 128:512) = aten::t(%1088), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %output.75 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.99, %1089), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1676:0
  %layer_output.5 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.75, %1087, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.40 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.5, %input.97, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output # transformers/modeling_mobilebert.py:405:0
  %1093 : Tensor = prim::GetAttr[name="bias"](%1085)
  %1094 : Tensor = prim::GetAttr[name="weight"](%1085)
  %1095 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.40, %1094), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.100 : Float(17:1664, 13:128, 128:1) = aten::add(%1095, %1093, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1097 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11428.NoNorm = prim::GetAttr[name="LayerNorm"](%1084)
  %1098 : __torch__.torch.nn.modules.linear.___torch_mangle_11427.Linear = prim::GetAttr[name="dense"](%1084)
  %1099 : Tensor = prim::GetAttr[name="bias"](%1098)
  %1100 : Tensor = prim::GetAttr[name="weight"](%1098)
  %1101 : Float(128:1, 512:128) = aten::t(%1100), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.76 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.100, %1101), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.101 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.76, %1099, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.25 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.101, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.41 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.25, %input.83, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1106 : Tensor = prim::GetAttr[name="bias"](%1097)
  %1107 : Tensor = prim::GetAttr[name="weight"](%1097)
  %1108 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.41, %1107), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.102 : Float(17:6656, 13:512, 512:1) = aten::add(%1108, %1106, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.4/__module.mobilebert.encoder.layer.4.output/__module.mobilebert.encoder.layer.4.output.bottleneck/__module.mobilebert.encoder.layer.4.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1110 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11476.MobileBertOutput = prim::GetAttr[name="output"](%114)
  %1111 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11469.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%114)
  %1112 : __torch__.torch.nn.modules.container.___torch_mangle_11502.ModuleList = prim::GetAttr[name="ffn"](%114)
  %1113 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11501.FFNLayer = prim::GetAttr[name="2"](%1112)
  %1114 : __torch__.torch.nn.modules.container.___torch_mangle_11502.ModuleList = prim::GetAttr[name="ffn"](%114)
  %1115 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11495.FFNLayer = prim::GetAttr[name="1"](%1114)
  %1116 : __torch__.torch.nn.modules.container.___torch_mangle_11502.ModuleList = prim::GetAttr[name="ffn"](%114)
  %1117 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11489.FFNLayer = prim::GetAttr[name="0"](%1116)
  %1118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11467.MobileBertAttention = prim::GetAttr[name="attention"](%114)
  %1119 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11483.Bottleneck = prim::GetAttr[name="bottleneck"](%114)
  %1120 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11482.BottleneckLayer = prim::GetAttr[name="attention"](%1119)
  %1121 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11479.BottleneckLayer = prim::GetAttr[name="input"](%1119)
  %1122 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11478.NoNorm = prim::GetAttr[name="LayerNorm"](%1121)
  %1123 : __torch__.torch.nn.modules.linear.___torch_mangle_11477.Linear = prim::GetAttr[name="dense"](%1121)
  %1124 : Tensor = prim::GetAttr[name="bias"](%1123)
  %1125 : Tensor = prim::GetAttr[name="weight"](%1123)
  %1126 : Float(512:1, 128:512) = aten::t(%1125), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.77 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1126), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.77, %1124, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1129 : Tensor = prim::GetAttr[name="bias"](%1122)
  %1130 : Tensor = prim::GetAttr[name="weight"](%1122)
  %1131 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.42, %1130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.6 : Float(17:1664, 13:128, 128:1) = aten::add(%1131, %1129, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.input/__module.mobilebert.encoder.layer.5.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1133 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11481.NoNorm = prim::GetAttr[name="LayerNorm"](%1120)
  %1134 : __torch__.torch.nn.modules.linear.___torch_mangle_11480.Linear = prim::GetAttr[name="dense"](%1120)
  %1135 : Tensor = prim::GetAttr[name="bias"](%1134)
  %1136 : Tensor = prim::GetAttr[name="weight"](%1134)
  %1137 : Float(512:1, 128:512) = aten::t(%1136), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.78 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1137), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.78, %1135, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1140 : Tensor = prim::GetAttr[name="bias"](%1133)
  %1141 : Tensor = prim::GetAttr[name="weight"](%1133)
  %1142 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.43, %1141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.103 : Float(17:1664, 13:128, 128:1) = aten::add(%1142, %1140, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.bottleneck/__module.mobilebert.encoder.layer.5.bottleneck.attention/__module.mobilebert.encoder.layer.5.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1144 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.103, %residual_tensor.6)
  %1145 : Float(17:1664, 13:128, 128:1), %1146 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1144)
  %1147 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11466.MobileBertSelfOutput = prim::GetAttr[name="output"](%1118)
  %1148 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11463.MobileBertSelfAttention = prim::GetAttr[name="self"](%1118)
  %1149 : __torch__.torch.nn.modules.linear.___torch_mangle_11461.Linear = prim::GetAttr[name="value"](%1148)
  %1150 : __torch__.torch.nn.modules.linear.___torch_mangle_11460.Linear = prim::GetAttr[name="key"](%1148)
  %1151 : __torch__.torch.nn.modules.linear.___torch_mangle_11459.Linear = prim::GetAttr[name="query"](%1148)
  %1152 : Tensor = prim::GetAttr[name="bias"](%1151)
  %1153 : Tensor = prim::GetAttr[name="weight"](%1151)
  %1154 : Float(128:1, 128:128) = aten::t(%1153), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %output.79 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1145, %1154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1676:0
  %x.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.79, %1152, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.query # torch/nn/functional.py:1678:0
  %1157 : Tensor = prim::GetAttr[name="bias"](%1150)
  %1158 : Tensor = prim::GetAttr[name="weight"](%1150)
  %1159 : Float(128:1, 128:128) = aten::t(%1158), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %output.80 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1145, %1159), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1676:0
  %x.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.80, %1157, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.key # torch/nn/functional.py:1678:0
  %1162 : Tensor = prim::GetAttr[name="bias"](%1149)
  %1163 : Tensor = prim::GetAttr[name="weight"](%1149)
  %1164 : Float(512:1, 128:512) = aten::t(%1163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %output.81 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.102, %1164), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1676:0
  %x.35 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.81, %1162, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.value # torch/nn/functional.py:1678:0
  %1167 : int = aten::size(%x.31, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1168 : int = aten::size(%x.31, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1169 : int[] = prim::ListConstruct(%1167, %1168, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.31, %1169), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1171 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %query_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.32, %1171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1173 : int = aten::size(%x.33, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1174 : int = aten::size(%x.33, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1175 : int[] = prim::ListConstruct(%1173, %1174, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.33, %1175), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1177 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %key_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.34, %1177), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1179 : int = aten::size(%x.35, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1180 : int = aten::size(%x.35, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:243:0
  %1181 : int[] = prim::ListConstruct(%1179, %1180, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %x.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.35, %1181), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:244:0
  %1183 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %value_layer.6 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.36, %1183), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:245:0
  %1185 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.6, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.6, %1185), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.11, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.104 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.12, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.105 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.104, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.6 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.105, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self/__module.mobilebert.encoder.layer.5.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.11 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.6, %value_layer.6), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:280:0
  %1192 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %1193 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.11, %1192), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.12 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1193, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:281:0
  %1195 : int = aten::size(%context_layer.12, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1196 : int = aten::size(%context_layer.12, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:282:0
  %1197 : int[] = prim::ListConstruct(%1195, %1196, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self
  %input.106 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.12, %1197), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.self # transformers/modeling_mobilebert.py:283:0
  %1199 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11465.NoNorm = prim::GetAttr[name="LayerNorm"](%1147)
  %1200 : __torch__.torch.nn.modules.linear.___torch_mangle_11464.Linear = prim::GetAttr[name="dense"](%1147)
  %1201 : Tensor = prim::GetAttr[name="bias"](%1200)
  %1202 : Tensor = prim::GetAttr[name="weight"](%1200)
  %1203 : Float(128:1, 128:128) = aten::t(%1202), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %output.82 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.106, %1203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.26 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.82, %1201, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.44 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.26, %1146, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output # transformers/modeling_mobilebert.py:301:0
  %1207 : Tensor = prim::GetAttr[name="bias"](%1199)
  %1208 : Tensor = prim::GetAttr[name="weight"](%1199)
  %1209 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.44, %1208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.107 : Float(17:1664, 13:128, 128:1) = aten::add(%1209, %1207, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.attention/__module.mobilebert.encoder.layer.5.attention.output/__module.mobilebert.encoder.layer.5.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1211 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11488.FFNOutput = prim::GetAttr[name="output"](%1117)
  %1212 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11485.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1117)
  %1213 : __torch__.torch.nn.modules.linear.___torch_mangle_11484.Linear = prim::GetAttr[name="dense"](%1212)
  %1214 : Tensor = prim::GetAttr[name="bias"](%1213)
  %1215 : Tensor = prim::GetAttr[name="weight"](%1213)
  %1216 : Float(128:1, 512:128) = aten::t(%1215), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.83 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.107, %1216), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.108 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.83, %1214, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate/__module.mobilebert.encoder.layer.5.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.109 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1220 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11487.NoNorm = prim::GetAttr[name="LayerNorm"](%1211)
  %1221 : __torch__.torch.nn.modules.linear.___torch_mangle_11486.Linear = prim::GetAttr[name="dense"](%1211)
  %1222 : Tensor = prim::GetAttr[name="bias"](%1221)
  %1223 : Tensor = prim::GetAttr[name="weight"](%1221)
  %1224 : Float(512:1, 128:512) = aten::t(%1223), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.84 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.109, %1224), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.27 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.84, %1222, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.45 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.27, %input.107, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1228 : Tensor = prim::GetAttr[name="bias"](%1220)
  %1229 : Tensor = prim::GetAttr[name="weight"](%1220)
  %1230 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.45, %1229), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.110 : Float(17:1664, 13:128, 128:1) = aten::add(%1230, %1228, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.0/__module.mobilebert.encoder.layer.5.ffn.0.output/__module.mobilebert.encoder.layer.5.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1232 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11494.FFNOutput = prim::GetAttr[name="output"](%1115)
  %1233 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11491.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1115)
  %1234 : __torch__.torch.nn.modules.linear.___torch_mangle_11490.Linear = prim::GetAttr[name="dense"](%1233)
  %1235 : Tensor = prim::GetAttr[name="bias"](%1234)
  %1236 : Tensor = prim::GetAttr[name="weight"](%1234)
  %1237 : Float(128:1, 512:128) = aten::t(%1236), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.85 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.110, %1237), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.111 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.85, %1235, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate/__module.mobilebert.encoder.layer.5.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.112 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1241 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11493.NoNorm = prim::GetAttr[name="LayerNorm"](%1232)
  %1242 : __torch__.torch.nn.modules.linear.___torch_mangle_11492.Linear = prim::GetAttr[name="dense"](%1232)
  %1243 : Tensor = prim::GetAttr[name="bias"](%1242)
  %1244 : Tensor = prim::GetAttr[name="weight"](%1242)
  %1245 : Float(512:1, 128:512) = aten::t(%1244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.86 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.112, %1245), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.28 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.86, %1243, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.46 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.28, %input.110, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1249 : Tensor = prim::GetAttr[name="bias"](%1241)
  %1250 : Tensor = prim::GetAttr[name="weight"](%1241)
  %1251 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.46, %1250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.113 : Float(17:1664, 13:128, 128:1) = aten::add(%1251, %1249, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.1/__module.mobilebert.encoder.layer.5.ffn.1.output/__module.mobilebert.encoder.layer.5.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1253 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11500.FFNOutput = prim::GetAttr[name="output"](%1113)
  %1254 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11497.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1113)
  %1255 : __torch__.torch.nn.modules.linear.___torch_mangle_11496.Linear = prim::GetAttr[name="dense"](%1254)
  %1256 : Tensor = prim::GetAttr[name="bias"](%1255)
  %1257 : Tensor = prim::GetAttr[name="weight"](%1255)
  %1258 : Float(128:1, 512:128) = aten::t(%1257), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.87 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.113, %1258), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.114 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.87, %1256, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate/__module.mobilebert.encoder.layer.5.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.115 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.114), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1262 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11499.NoNorm = prim::GetAttr[name="LayerNorm"](%1253)
  %1263 : __torch__.torch.nn.modules.linear.___torch_mangle_11498.Linear = prim::GetAttr[name="dense"](%1253)
  %1264 : Tensor = prim::GetAttr[name="bias"](%1263)
  %1265 : Tensor = prim::GetAttr[name="weight"](%1263)
  %1266 : Float(512:1, 128:512) = aten::t(%1265), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.88 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.115, %1266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.29 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.88, %1264, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.47 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.29, %input.113, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1270 : Tensor = prim::GetAttr[name="bias"](%1262)
  %1271 : Tensor = prim::GetAttr[name="weight"](%1262)
  %1272 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.47, %1271), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.116 : Float(17:1664, 13:128, 128:1) = aten::add(%1272, %1270, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.ffn.2/__module.mobilebert.encoder.layer.5.ffn.2.output/__module.mobilebert.encoder.layer.5.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1274 : __torch__.torch.nn.modules.linear.___torch_mangle_11468.Linear = prim::GetAttr[name="dense"](%1111)
  %1275 : Tensor = prim::GetAttr[name="bias"](%1274)
  %1276 : Tensor = prim::GetAttr[name="weight"](%1274)
  %1277 : Float(128:1, 512:128) = aten::t(%1276), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %output.89 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.116, %1277), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1676:0
  %input.117 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.89, %1275, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate/__module.mobilebert.encoder.layer.5.intermediate.dense # torch/nn/functional.py:1678:0
  %input.118 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.117), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.intermediate # torch/nn/functional.py:1119:0
  %1281 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11475.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1110)
  %1282 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11471.NoNorm = prim::GetAttr[name="LayerNorm"](%1110)
  %1283 : __torch__.torch.nn.modules.linear.___torch_mangle_11470.Linear = prim::GetAttr[name="dense"](%1110)
  %1284 : Tensor = prim::GetAttr[name="bias"](%1283)
  %1285 : Tensor = prim::GetAttr[name="weight"](%1283)
  %1286 : Float(512:1, 128:512) = aten::t(%1285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %output.90 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.118, %1286), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1676:0
  %layer_output.6 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.90, %1284, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.48 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.6, %input.116, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output # transformers/modeling_mobilebert.py:405:0
  %1290 : Tensor = prim::GetAttr[name="bias"](%1282)
  %1291 : Tensor = prim::GetAttr[name="weight"](%1282)
  %1292 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.48, %1291), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.119 : Float(17:1664, 13:128, 128:1) = aten::add(%1292, %1290, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1294 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11473.NoNorm = prim::GetAttr[name="LayerNorm"](%1281)
  %1295 : __torch__.torch.nn.modules.linear.___torch_mangle_11472.Linear = prim::GetAttr[name="dense"](%1281)
  %1296 : Tensor = prim::GetAttr[name="bias"](%1295)
  %1297 : Tensor = prim::GetAttr[name="weight"](%1295)
  %1298 : Float(128:1, 512:128) = aten::t(%1297), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.91 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.119, %1298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.120 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.91, %1296, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.30 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.120, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.49 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.30, %input.102, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1303 : Tensor = prim::GetAttr[name="bias"](%1294)
  %1304 : Tensor = prim::GetAttr[name="weight"](%1294)
  %1305 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.49, %1304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.121 : Float(17:6656, 13:512, 512:1) = aten::add(%1305, %1303, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.5/__module.mobilebert.encoder.layer.5.output/__module.mobilebert.encoder.layer.5.output.bottleneck/__module.mobilebert.encoder.layer.5.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1307 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11521.MobileBertOutput = prim::GetAttr[name="output"](%112)
  %1308 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11514.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%112)
  %1309 : __torch__.torch.nn.modules.container.___torch_mangle_11547.ModuleList = prim::GetAttr[name="ffn"](%112)
  %1310 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11546.FFNLayer = prim::GetAttr[name="2"](%1309)
  %1311 : __torch__.torch.nn.modules.container.___torch_mangle_11547.ModuleList = prim::GetAttr[name="ffn"](%112)
  %1312 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11540.FFNLayer = prim::GetAttr[name="1"](%1311)
  %1313 : __torch__.torch.nn.modules.container.___torch_mangle_11547.ModuleList = prim::GetAttr[name="ffn"](%112)
  %1314 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11534.FFNLayer = prim::GetAttr[name="0"](%1313)
  %1315 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11512.MobileBertAttention = prim::GetAttr[name="attention"](%112)
  %1316 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11528.Bottleneck = prim::GetAttr[name="bottleneck"](%112)
  %1317 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11527.BottleneckLayer = prim::GetAttr[name="attention"](%1316)
  %1318 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11524.BottleneckLayer = prim::GetAttr[name="input"](%1316)
  %1319 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11523.NoNorm = prim::GetAttr[name="LayerNorm"](%1318)
  %1320 : __torch__.torch.nn.modules.linear.___torch_mangle_11522.Linear = prim::GetAttr[name="dense"](%1318)
  %1321 : Tensor = prim::GetAttr[name="bias"](%1320)
  %1322 : Tensor = prim::GetAttr[name="weight"](%1320)
  %1323 : Float(512:1, 128:512) = aten::t(%1322), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.92 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.50 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.92, %1321, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1326 : Tensor = prim::GetAttr[name="bias"](%1319)
  %1327 : Tensor = prim::GetAttr[name="weight"](%1319)
  %1328 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.50, %1327), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.7 : Float(17:1664, 13:128, 128:1) = aten::add(%1328, %1326, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.input/__module.mobilebert.encoder.layer.6.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1330 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11526.NoNorm = prim::GetAttr[name="LayerNorm"](%1317)
  %1331 : __torch__.torch.nn.modules.linear.___torch_mangle_11525.Linear = prim::GetAttr[name="dense"](%1317)
  %1332 : Tensor = prim::GetAttr[name="bias"](%1331)
  %1333 : Tensor = prim::GetAttr[name="weight"](%1331)
  %1334 : Float(512:1, 128:512) = aten::t(%1333), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.93 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1334), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.93, %1332, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1337 : Tensor = prim::GetAttr[name="bias"](%1330)
  %1338 : Tensor = prim::GetAttr[name="weight"](%1330)
  %1339 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.51, %1338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.122 : Float(17:1664, 13:128, 128:1) = aten::add(%1339, %1337, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.bottleneck/__module.mobilebert.encoder.layer.6.bottleneck.attention/__module.mobilebert.encoder.layer.6.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1341 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.122, %residual_tensor.7)
  %1342 : Float(17:1664, 13:128, 128:1), %1343 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1341)
  %1344 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11511.MobileBertSelfOutput = prim::GetAttr[name="output"](%1315)
  %1345 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11508.MobileBertSelfAttention = prim::GetAttr[name="self"](%1315)
  %1346 : __torch__.torch.nn.modules.linear.___torch_mangle_11506.Linear = prim::GetAttr[name="value"](%1345)
  %1347 : __torch__.torch.nn.modules.linear.___torch_mangle_11505.Linear = prim::GetAttr[name="key"](%1345)
  %1348 : __torch__.torch.nn.modules.linear.___torch_mangle_11504.Linear = prim::GetAttr[name="query"](%1345)
  %1349 : Tensor = prim::GetAttr[name="bias"](%1348)
  %1350 : Tensor = prim::GetAttr[name="weight"](%1348)
  %1351 : Float(128:1, 128:128) = aten::t(%1350), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %output.94 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1342, %1351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1676:0
  %x.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.94, %1349, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.query # torch/nn/functional.py:1678:0
  %1354 : Tensor = prim::GetAttr[name="bias"](%1347)
  %1355 : Tensor = prim::GetAttr[name="weight"](%1347)
  %1356 : Float(128:1, 128:128) = aten::t(%1355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %output.95 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1342, %1356), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1676:0
  %x.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.95, %1354, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.key # torch/nn/functional.py:1678:0
  %1359 : Tensor = prim::GetAttr[name="bias"](%1346)
  %1360 : Tensor = prim::GetAttr[name="weight"](%1346)
  %1361 : Float(512:1, 128:512) = aten::t(%1360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %output.96 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.121, %1361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1676:0
  %x.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.96, %1359, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.value # torch/nn/functional.py:1678:0
  %1364 : int = aten::size(%x.37, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1365 : int = aten::size(%x.37, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1366 : int[] = prim::ListConstruct(%1364, %1365, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.37, %1366), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1368 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %query_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.38, %1368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1370 : int = aten::size(%x.39, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1371 : int = aten::size(%x.39, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1372 : int[] = prim::ListConstruct(%1370, %1371, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.39, %1372), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1374 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %key_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.40, %1374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1376 : int = aten::size(%x.41, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1377 : int = aten::size(%x.41, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:243:0
  %1378 : int[] = prim::ListConstruct(%1376, %1377, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %x.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.41, %1378), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:244:0
  %1380 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %value_layer.7 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.42, %1380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:245:0
  %1382 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.7, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.7, %1382), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.13, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.123 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.14, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.124 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.123, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.7 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.124, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self/__module.mobilebert.encoder.layer.6.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.13 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.7, %value_layer.7), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:280:0
  %1389 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %1390 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.13, %1389), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.14 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1390, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:281:0
  %1392 : int = aten::size(%context_layer.14, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1393 : int = aten::size(%context_layer.14, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:282:0
  %1394 : int[] = prim::ListConstruct(%1392, %1393, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self
  %input.125 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.14, %1394), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.self # transformers/modeling_mobilebert.py:283:0
  %1396 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11510.NoNorm = prim::GetAttr[name="LayerNorm"](%1344)
  %1397 : __torch__.torch.nn.modules.linear.___torch_mangle_11509.Linear = prim::GetAttr[name="dense"](%1344)
  %1398 : Tensor = prim::GetAttr[name="bias"](%1397)
  %1399 : Tensor = prim::GetAttr[name="weight"](%1397)
  %1400 : Float(128:1, 128:128) = aten::t(%1399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %output.97 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.125, %1400), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.31 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.97, %1398, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.52 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.31, %1343, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output # transformers/modeling_mobilebert.py:301:0
  %1404 : Tensor = prim::GetAttr[name="bias"](%1396)
  %1405 : Tensor = prim::GetAttr[name="weight"](%1396)
  %1406 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.52, %1405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.126 : Float(17:1664, 13:128, 128:1) = aten::add(%1406, %1404, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.attention/__module.mobilebert.encoder.layer.6.attention.output/__module.mobilebert.encoder.layer.6.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1408 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11533.FFNOutput = prim::GetAttr[name="output"](%1314)
  %1409 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11530.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1314)
  %1410 : __torch__.torch.nn.modules.linear.___torch_mangle_11529.Linear = prim::GetAttr[name="dense"](%1409)
  %1411 : Tensor = prim::GetAttr[name="bias"](%1410)
  %1412 : Tensor = prim::GetAttr[name="weight"](%1410)
  %1413 : Float(128:1, 512:128) = aten::t(%1412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.98 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.126, %1413), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.127 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.98, %1411, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate/__module.mobilebert.encoder.layer.6.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.128 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.127), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1417 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11532.NoNorm = prim::GetAttr[name="LayerNorm"](%1408)
  %1418 : __torch__.torch.nn.modules.linear.___torch_mangle_11531.Linear = prim::GetAttr[name="dense"](%1408)
  %1419 : Tensor = prim::GetAttr[name="bias"](%1418)
  %1420 : Tensor = prim::GetAttr[name="weight"](%1418)
  %1421 : Float(512:1, 128:512) = aten::t(%1420), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.99 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.128, %1421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.32 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.99, %1419, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.53 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.32, %input.126, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1425 : Tensor = prim::GetAttr[name="bias"](%1417)
  %1426 : Tensor = prim::GetAttr[name="weight"](%1417)
  %1427 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.53, %1426), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.129 : Float(17:1664, 13:128, 128:1) = aten::add(%1427, %1425, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.0/__module.mobilebert.encoder.layer.6.ffn.0.output/__module.mobilebert.encoder.layer.6.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1429 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11539.FFNOutput = prim::GetAttr[name="output"](%1312)
  %1430 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11536.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1312)
  %1431 : __torch__.torch.nn.modules.linear.___torch_mangle_11535.Linear = prim::GetAttr[name="dense"](%1430)
  %1432 : Tensor = prim::GetAttr[name="bias"](%1431)
  %1433 : Tensor = prim::GetAttr[name="weight"](%1431)
  %1434 : Float(128:1, 512:128) = aten::t(%1433), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.100 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.129, %1434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.130 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.100, %1432, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate/__module.mobilebert.encoder.layer.6.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.131 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1438 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11538.NoNorm = prim::GetAttr[name="LayerNorm"](%1429)
  %1439 : __torch__.torch.nn.modules.linear.___torch_mangle_11537.Linear = prim::GetAttr[name="dense"](%1429)
  %1440 : Tensor = prim::GetAttr[name="bias"](%1439)
  %1441 : Tensor = prim::GetAttr[name="weight"](%1439)
  %1442 : Float(512:1, 128:512) = aten::t(%1441), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.101 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.131, %1442), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.33 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.101, %1440, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.54 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.33, %input.129, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1446 : Tensor = prim::GetAttr[name="bias"](%1438)
  %1447 : Tensor = prim::GetAttr[name="weight"](%1438)
  %1448 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.54, %1447), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.132 : Float(17:1664, 13:128, 128:1) = aten::add(%1448, %1446, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.1/__module.mobilebert.encoder.layer.6.ffn.1.output/__module.mobilebert.encoder.layer.6.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1450 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11545.FFNOutput = prim::GetAttr[name="output"](%1310)
  %1451 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11542.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1310)
  %1452 : __torch__.torch.nn.modules.linear.___torch_mangle_11541.Linear = prim::GetAttr[name="dense"](%1451)
  %1453 : Tensor = prim::GetAttr[name="bias"](%1452)
  %1454 : Tensor = prim::GetAttr[name="weight"](%1452)
  %1455 : Float(128:1, 512:128) = aten::t(%1454), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.102 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.132, %1455), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.133 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.102, %1453, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate/__module.mobilebert.encoder.layer.6.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.134 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1459 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11544.NoNorm = prim::GetAttr[name="LayerNorm"](%1450)
  %1460 : __torch__.torch.nn.modules.linear.___torch_mangle_11543.Linear = prim::GetAttr[name="dense"](%1450)
  %1461 : Tensor = prim::GetAttr[name="bias"](%1460)
  %1462 : Tensor = prim::GetAttr[name="weight"](%1460)
  %1463 : Float(512:1, 128:512) = aten::t(%1462), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.103 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.134, %1463), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.34 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.103, %1461, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.55 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.34, %input.132, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1467 : Tensor = prim::GetAttr[name="bias"](%1459)
  %1468 : Tensor = prim::GetAttr[name="weight"](%1459)
  %1469 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.55, %1468), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.135 : Float(17:1664, 13:128, 128:1) = aten::add(%1469, %1467, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.ffn.2/__module.mobilebert.encoder.layer.6.ffn.2.output/__module.mobilebert.encoder.layer.6.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1471 : __torch__.torch.nn.modules.linear.___torch_mangle_11513.Linear = prim::GetAttr[name="dense"](%1308)
  %1472 : Tensor = prim::GetAttr[name="bias"](%1471)
  %1473 : Tensor = prim::GetAttr[name="weight"](%1471)
  %1474 : Float(128:1, 512:128) = aten::t(%1473), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %output.104 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.135, %1474), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1676:0
  %input.136 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.104, %1472, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate/__module.mobilebert.encoder.layer.6.intermediate.dense # torch/nn/functional.py:1678:0
  %input.137 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.136), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.intermediate # torch/nn/functional.py:1119:0
  %1478 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11520.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1307)
  %1479 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11516.NoNorm = prim::GetAttr[name="LayerNorm"](%1307)
  %1480 : __torch__.torch.nn.modules.linear.___torch_mangle_11515.Linear = prim::GetAttr[name="dense"](%1307)
  %1481 : Tensor = prim::GetAttr[name="bias"](%1480)
  %1482 : Tensor = prim::GetAttr[name="weight"](%1480)
  %1483 : Float(512:1, 128:512) = aten::t(%1482), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %output.105 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.137, %1483), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1676:0
  %layer_output.7 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.105, %1481, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.56 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.7, %input.135, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output # transformers/modeling_mobilebert.py:405:0
  %1487 : Tensor = prim::GetAttr[name="bias"](%1479)
  %1488 : Tensor = prim::GetAttr[name="weight"](%1479)
  %1489 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.56, %1488), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.138 : Float(17:1664, 13:128, 128:1) = aten::add(%1489, %1487, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1491 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11518.NoNorm = prim::GetAttr[name="LayerNorm"](%1478)
  %1492 : __torch__.torch.nn.modules.linear.___torch_mangle_11517.Linear = prim::GetAttr[name="dense"](%1478)
  %1493 : Tensor = prim::GetAttr[name="bias"](%1492)
  %1494 : Tensor = prim::GetAttr[name="weight"](%1492)
  %1495 : Float(128:1, 512:128) = aten::t(%1494), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.106 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.138, %1495), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.139 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.106, %1493, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.35 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.139, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.57 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.35, %input.121, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1500 : Tensor = prim::GetAttr[name="bias"](%1491)
  %1501 : Tensor = prim::GetAttr[name="weight"](%1491)
  %1502 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.57, %1501), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.140 : Float(17:6656, 13:512, 512:1) = aten::add(%1502, %1500, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.6/__module.mobilebert.encoder.layer.6.output/__module.mobilebert.encoder.layer.6.output.bottleneck/__module.mobilebert.encoder.layer.6.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1504 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11566.MobileBertOutput = prim::GetAttr[name="output"](%110)
  %1505 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11559.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%110)
  %1506 : __torch__.torch.nn.modules.container.___torch_mangle_11592.ModuleList = prim::GetAttr[name="ffn"](%110)
  %1507 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11591.FFNLayer = prim::GetAttr[name="2"](%1506)
  %1508 : __torch__.torch.nn.modules.container.___torch_mangle_11592.ModuleList = prim::GetAttr[name="ffn"](%110)
  %1509 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11585.FFNLayer = prim::GetAttr[name="1"](%1508)
  %1510 : __torch__.torch.nn.modules.container.___torch_mangle_11592.ModuleList = prim::GetAttr[name="ffn"](%110)
  %1511 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11579.FFNLayer = prim::GetAttr[name="0"](%1510)
  %1512 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11557.MobileBertAttention = prim::GetAttr[name="attention"](%110)
  %1513 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11573.Bottleneck = prim::GetAttr[name="bottleneck"](%110)
  %1514 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11572.BottleneckLayer = prim::GetAttr[name="attention"](%1513)
  %1515 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11569.BottleneckLayer = prim::GetAttr[name="input"](%1513)
  %1516 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11568.NoNorm = prim::GetAttr[name="LayerNorm"](%1515)
  %1517 : __torch__.torch.nn.modules.linear.___torch_mangle_11567.Linear = prim::GetAttr[name="dense"](%1515)
  %1518 : Tensor = prim::GetAttr[name="bias"](%1517)
  %1519 : Tensor = prim::GetAttr[name="weight"](%1517)
  %1520 : Float(512:1, 128:512) = aten::t(%1519), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.107 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1520), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.107, %1518, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1523 : Tensor = prim::GetAttr[name="bias"](%1516)
  %1524 : Tensor = prim::GetAttr[name="weight"](%1516)
  %1525 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.58, %1524), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.8 : Float(17:1664, 13:128, 128:1) = aten::add(%1525, %1523, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.input/__module.mobilebert.encoder.layer.7.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1527 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11571.NoNorm = prim::GetAttr[name="LayerNorm"](%1514)
  %1528 : __torch__.torch.nn.modules.linear.___torch_mangle_11570.Linear = prim::GetAttr[name="dense"](%1514)
  %1529 : Tensor = prim::GetAttr[name="bias"](%1528)
  %1530 : Tensor = prim::GetAttr[name="weight"](%1528)
  %1531 : Float(512:1, 128:512) = aten::t(%1530), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.108 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1531), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.108, %1529, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1534 : Tensor = prim::GetAttr[name="bias"](%1527)
  %1535 : Tensor = prim::GetAttr[name="weight"](%1527)
  %1536 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.59, %1535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.141 : Float(17:1664, 13:128, 128:1) = aten::add(%1536, %1534, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.bottleneck/__module.mobilebert.encoder.layer.7.bottleneck.attention/__module.mobilebert.encoder.layer.7.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1538 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.141, %residual_tensor.8)
  %1539 : Float(17:1664, 13:128, 128:1), %1540 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1538)
  %1541 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11556.MobileBertSelfOutput = prim::GetAttr[name="output"](%1512)
  %1542 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11553.MobileBertSelfAttention = prim::GetAttr[name="self"](%1512)
  %1543 : __torch__.torch.nn.modules.linear.___torch_mangle_11551.Linear = prim::GetAttr[name="value"](%1542)
  %1544 : __torch__.torch.nn.modules.linear.___torch_mangle_11550.Linear = prim::GetAttr[name="key"](%1542)
  %1545 : __torch__.torch.nn.modules.linear.___torch_mangle_11549.Linear = prim::GetAttr[name="query"](%1542)
  %1546 : Tensor = prim::GetAttr[name="bias"](%1545)
  %1547 : Tensor = prim::GetAttr[name="weight"](%1545)
  %1548 : Float(128:1, 128:128) = aten::t(%1547), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %output.109 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1539, %1548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1676:0
  %x.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.109, %1546, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.query # torch/nn/functional.py:1678:0
  %1551 : Tensor = prim::GetAttr[name="bias"](%1544)
  %1552 : Tensor = prim::GetAttr[name="weight"](%1544)
  %1553 : Float(128:1, 128:128) = aten::t(%1552), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %output.110 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1539, %1553), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1676:0
  %x.45 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.110, %1551, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.key # torch/nn/functional.py:1678:0
  %1556 : Tensor = prim::GetAttr[name="bias"](%1543)
  %1557 : Tensor = prim::GetAttr[name="weight"](%1543)
  %1558 : Float(512:1, 128:512) = aten::t(%1557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %output.111 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.140, %1558), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1676:0
  %x.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.111, %1556, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.value # torch/nn/functional.py:1678:0
  %1561 : int = aten::size(%x.43, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1562 : int = aten::size(%x.43, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1563 : int[] = prim::ListConstruct(%1561, %1562, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.43, %1563), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1565 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %query_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.44, %1565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1567 : int = aten::size(%x.45, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1568 : int = aten::size(%x.45, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1569 : int[] = prim::ListConstruct(%1567, %1568, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.45, %1569), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1571 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %key_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.46, %1571), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1573 : int = aten::size(%x.47, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1574 : int = aten::size(%x.47, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:243:0
  %1575 : int[] = prim::ListConstruct(%1573, %1574, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %x.48 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.47, %1575), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:244:0
  %1577 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %value_layer.8 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.48, %1577), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:245:0
  %1579 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.8, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.8, %1579), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.15, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.142 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.16, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.143 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.142, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.8 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.143, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self/__module.mobilebert.encoder.layer.7.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.15 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.8, %value_layer.8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:280:0
  %1586 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %1587 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.15, %1586), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.16 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1587, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:281:0
  %1589 : int = aten::size(%context_layer.16, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1590 : int = aten::size(%context_layer.16, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:282:0
  %1591 : int[] = prim::ListConstruct(%1589, %1590, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self
  %input.144 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.16, %1591), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.self # transformers/modeling_mobilebert.py:283:0
  %1593 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11555.NoNorm = prim::GetAttr[name="LayerNorm"](%1541)
  %1594 : __torch__.torch.nn.modules.linear.___torch_mangle_11554.Linear = prim::GetAttr[name="dense"](%1541)
  %1595 : Tensor = prim::GetAttr[name="bias"](%1594)
  %1596 : Tensor = prim::GetAttr[name="weight"](%1594)
  %1597 : Float(128:1, 128:128) = aten::t(%1596), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %output.112 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.144, %1597), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.36 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.112, %1595, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.60 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.36, %1540, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output # transformers/modeling_mobilebert.py:301:0
  %1601 : Tensor = prim::GetAttr[name="bias"](%1593)
  %1602 : Tensor = prim::GetAttr[name="weight"](%1593)
  %1603 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.60, %1602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.145 : Float(17:1664, 13:128, 128:1) = aten::add(%1603, %1601, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.attention/__module.mobilebert.encoder.layer.7.attention.output/__module.mobilebert.encoder.layer.7.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1605 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11578.FFNOutput = prim::GetAttr[name="output"](%1511)
  %1606 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11575.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1511)
  %1607 : __torch__.torch.nn.modules.linear.___torch_mangle_11574.Linear = prim::GetAttr[name="dense"](%1606)
  %1608 : Tensor = prim::GetAttr[name="bias"](%1607)
  %1609 : Tensor = prim::GetAttr[name="weight"](%1607)
  %1610 : Float(128:1, 512:128) = aten::t(%1609), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.113 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.145, %1610), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.146 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.113, %1608, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate/__module.mobilebert.encoder.layer.7.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.147 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.146), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1614 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11577.NoNorm = prim::GetAttr[name="LayerNorm"](%1605)
  %1615 : __torch__.torch.nn.modules.linear.___torch_mangle_11576.Linear = prim::GetAttr[name="dense"](%1605)
  %1616 : Tensor = prim::GetAttr[name="bias"](%1615)
  %1617 : Tensor = prim::GetAttr[name="weight"](%1615)
  %1618 : Float(512:1, 128:512) = aten::t(%1617), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.114 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.147, %1618), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.37 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.114, %1616, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.61 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.37, %input.145, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1622 : Tensor = prim::GetAttr[name="bias"](%1614)
  %1623 : Tensor = prim::GetAttr[name="weight"](%1614)
  %1624 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.61, %1623), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.148 : Float(17:1664, 13:128, 128:1) = aten::add(%1624, %1622, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.0/__module.mobilebert.encoder.layer.7.ffn.0.output/__module.mobilebert.encoder.layer.7.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1626 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11584.FFNOutput = prim::GetAttr[name="output"](%1509)
  %1627 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11581.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1509)
  %1628 : __torch__.torch.nn.modules.linear.___torch_mangle_11580.Linear = prim::GetAttr[name="dense"](%1627)
  %1629 : Tensor = prim::GetAttr[name="bias"](%1628)
  %1630 : Tensor = prim::GetAttr[name="weight"](%1628)
  %1631 : Float(128:1, 512:128) = aten::t(%1630), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.115 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.148, %1631), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.149 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.115, %1629, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate/__module.mobilebert.encoder.layer.7.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.150 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1635 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11583.NoNorm = prim::GetAttr[name="LayerNorm"](%1626)
  %1636 : __torch__.torch.nn.modules.linear.___torch_mangle_11582.Linear = prim::GetAttr[name="dense"](%1626)
  %1637 : Tensor = prim::GetAttr[name="bias"](%1636)
  %1638 : Tensor = prim::GetAttr[name="weight"](%1636)
  %1639 : Float(512:1, 128:512) = aten::t(%1638), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.116 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.150, %1639), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.38 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.116, %1637, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.62 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.38, %input.148, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1643 : Tensor = prim::GetAttr[name="bias"](%1635)
  %1644 : Tensor = prim::GetAttr[name="weight"](%1635)
  %1645 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.62, %1644), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.151 : Float(17:1664, 13:128, 128:1) = aten::add(%1645, %1643, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.1/__module.mobilebert.encoder.layer.7.ffn.1.output/__module.mobilebert.encoder.layer.7.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1647 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11590.FFNOutput = prim::GetAttr[name="output"](%1507)
  %1648 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11587.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1507)
  %1649 : __torch__.torch.nn.modules.linear.___torch_mangle_11586.Linear = prim::GetAttr[name="dense"](%1648)
  %1650 : Tensor = prim::GetAttr[name="bias"](%1649)
  %1651 : Tensor = prim::GetAttr[name="weight"](%1649)
  %1652 : Float(128:1, 512:128) = aten::t(%1651), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.117 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.151, %1652), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.152 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.117, %1650, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate/__module.mobilebert.encoder.layer.7.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.153 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1656 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11589.NoNorm = prim::GetAttr[name="LayerNorm"](%1647)
  %1657 : __torch__.torch.nn.modules.linear.___torch_mangle_11588.Linear = prim::GetAttr[name="dense"](%1647)
  %1658 : Tensor = prim::GetAttr[name="bias"](%1657)
  %1659 : Tensor = prim::GetAttr[name="weight"](%1657)
  %1660 : Float(512:1, 128:512) = aten::t(%1659), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.118 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.153, %1660), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.39 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.118, %1658, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.63 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.39, %input.151, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1664 : Tensor = prim::GetAttr[name="bias"](%1656)
  %1665 : Tensor = prim::GetAttr[name="weight"](%1656)
  %1666 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.63, %1665), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.154 : Float(17:1664, 13:128, 128:1) = aten::add(%1666, %1664, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.ffn.2/__module.mobilebert.encoder.layer.7.ffn.2.output/__module.mobilebert.encoder.layer.7.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1668 : __torch__.torch.nn.modules.linear.___torch_mangle_11558.Linear = prim::GetAttr[name="dense"](%1505)
  %1669 : Tensor = prim::GetAttr[name="bias"](%1668)
  %1670 : Tensor = prim::GetAttr[name="weight"](%1668)
  %1671 : Float(128:1, 512:128) = aten::t(%1670), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %output.119 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.154, %1671), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1676:0
  %input.155 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.119, %1669, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate/__module.mobilebert.encoder.layer.7.intermediate.dense # torch/nn/functional.py:1678:0
  %input.156 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.intermediate # torch/nn/functional.py:1119:0
  %1675 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11565.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1504)
  %1676 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11561.NoNorm = prim::GetAttr[name="LayerNorm"](%1504)
  %1677 : __torch__.torch.nn.modules.linear.___torch_mangle_11560.Linear = prim::GetAttr[name="dense"](%1504)
  %1678 : Tensor = prim::GetAttr[name="bias"](%1677)
  %1679 : Tensor = prim::GetAttr[name="weight"](%1677)
  %1680 : Float(512:1, 128:512) = aten::t(%1679), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %output.120 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.156, %1680), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1676:0
  %layer_output.8 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.120, %1678, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.64 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.8, %input.154, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output # transformers/modeling_mobilebert.py:405:0
  %1684 : Tensor = prim::GetAttr[name="bias"](%1676)
  %1685 : Tensor = prim::GetAttr[name="weight"](%1676)
  %1686 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.64, %1685), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.157 : Float(17:1664, 13:128, 128:1) = aten::add(%1686, %1684, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1688 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11563.NoNorm = prim::GetAttr[name="LayerNorm"](%1675)
  %1689 : __torch__.torch.nn.modules.linear.___torch_mangle_11562.Linear = prim::GetAttr[name="dense"](%1675)
  %1690 : Tensor = prim::GetAttr[name="bias"](%1689)
  %1691 : Tensor = prim::GetAttr[name="weight"](%1689)
  %1692 : Float(128:1, 512:128) = aten::t(%1691), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.121 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.157, %1692), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.158 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.121, %1690, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.40 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.158, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.65 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.40, %input.140, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1697 : Tensor = prim::GetAttr[name="bias"](%1688)
  %1698 : Tensor = prim::GetAttr[name="weight"](%1688)
  %1699 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.65, %1698), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.159 : Float(17:6656, 13:512, 512:1) = aten::add(%1699, %1697, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.7/__module.mobilebert.encoder.layer.7.output/__module.mobilebert.encoder.layer.7.output.bottleneck/__module.mobilebert.encoder.layer.7.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1701 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11611.MobileBertOutput = prim::GetAttr[name="output"](%108)
  %1702 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11604.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%108)
  %1703 : __torch__.torch.nn.modules.container.___torch_mangle_11637.ModuleList = prim::GetAttr[name="ffn"](%108)
  %1704 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11636.FFNLayer = prim::GetAttr[name="2"](%1703)
  %1705 : __torch__.torch.nn.modules.container.___torch_mangle_11637.ModuleList = prim::GetAttr[name="ffn"](%108)
  %1706 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11630.FFNLayer = prim::GetAttr[name="1"](%1705)
  %1707 : __torch__.torch.nn.modules.container.___torch_mangle_11637.ModuleList = prim::GetAttr[name="ffn"](%108)
  %1708 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11624.FFNLayer = prim::GetAttr[name="0"](%1707)
  %1709 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11602.MobileBertAttention = prim::GetAttr[name="attention"](%108)
  %1710 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11618.Bottleneck = prim::GetAttr[name="bottleneck"](%108)
  %1711 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11617.BottleneckLayer = prim::GetAttr[name="attention"](%1710)
  %1712 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11614.BottleneckLayer = prim::GetAttr[name="input"](%1710)
  %1713 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11613.NoNorm = prim::GetAttr[name="LayerNorm"](%1712)
  %1714 : __torch__.torch.nn.modules.linear.___torch_mangle_11612.Linear = prim::GetAttr[name="dense"](%1712)
  %1715 : Tensor = prim::GetAttr[name="bias"](%1714)
  %1716 : Tensor = prim::GetAttr[name="weight"](%1714)
  %1717 : Float(512:1, 128:512) = aten::t(%1716), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.122 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1717), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.122, %1715, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1720 : Tensor = prim::GetAttr[name="bias"](%1713)
  %1721 : Tensor = prim::GetAttr[name="weight"](%1713)
  %1722 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.66, %1721), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.9 : Float(17:1664, 13:128, 128:1) = aten::add(%1722, %1720, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.input/__module.mobilebert.encoder.layer.8.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1724 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11616.NoNorm = prim::GetAttr[name="LayerNorm"](%1711)
  %1725 : __torch__.torch.nn.modules.linear.___torch_mangle_11615.Linear = prim::GetAttr[name="dense"](%1711)
  %1726 : Tensor = prim::GetAttr[name="bias"](%1725)
  %1727 : Tensor = prim::GetAttr[name="weight"](%1725)
  %1728 : Float(512:1, 128:512) = aten::t(%1727), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.123 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1728), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.123, %1726, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1731 : Tensor = prim::GetAttr[name="bias"](%1724)
  %1732 : Tensor = prim::GetAttr[name="weight"](%1724)
  %1733 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.67, %1732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.160 : Float(17:1664, 13:128, 128:1) = aten::add(%1733, %1731, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.bottleneck/__module.mobilebert.encoder.layer.8.bottleneck.attention/__module.mobilebert.encoder.layer.8.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1735 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.160, %residual_tensor.9)
  %1736 : Float(17:1664, 13:128, 128:1), %1737 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1735)
  %1738 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11601.MobileBertSelfOutput = prim::GetAttr[name="output"](%1709)
  %1739 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11598.MobileBertSelfAttention = prim::GetAttr[name="self"](%1709)
  %1740 : __torch__.torch.nn.modules.linear.___torch_mangle_11596.Linear = prim::GetAttr[name="value"](%1739)
  %1741 : __torch__.torch.nn.modules.linear.___torch_mangle_11595.Linear = prim::GetAttr[name="key"](%1739)
  %1742 : __torch__.torch.nn.modules.linear.___torch_mangle_11594.Linear = prim::GetAttr[name="query"](%1739)
  %1743 : Tensor = prim::GetAttr[name="bias"](%1742)
  %1744 : Tensor = prim::GetAttr[name="weight"](%1742)
  %1745 : Float(128:1, 128:128) = aten::t(%1744), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %output.124 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1736, %1745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1676:0
  %x.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.124, %1743, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.query # torch/nn/functional.py:1678:0
  %1748 : Tensor = prim::GetAttr[name="bias"](%1741)
  %1749 : Tensor = prim::GetAttr[name="weight"](%1741)
  %1750 : Float(128:1, 128:128) = aten::t(%1749), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %output.125 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1736, %1750), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1676:0
  %x.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.125, %1748, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.key # torch/nn/functional.py:1678:0
  %1753 : Tensor = prim::GetAttr[name="bias"](%1740)
  %1754 : Tensor = prim::GetAttr[name="weight"](%1740)
  %1755 : Float(512:1, 128:512) = aten::t(%1754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %output.126 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.159, %1755), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1676:0
  %x.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.126, %1753, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.value # torch/nn/functional.py:1678:0
  %1758 : int = aten::size(%x.49, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1759 : int = aten::size(%x.49, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1760 : int[] = prim::ListConstruct(%1758, %1759, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.50 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.49, %1760), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1762 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %query_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.50, %1762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1764 : int = aten::size(%x.51, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1765 : int = aten::size(%x.51, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1766 : int[] = prim::ListConstruct(%1764, %1765, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.52 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.51, %1766), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1768 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %key_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.52, %1768), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1770 : int = aten::size(%x.53, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1771 : int = aten::size(%x.53, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:243:0
  %1772 : int[] = prim::ListConstruct(%1770, %1771, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %x.54 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.53, %1772), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:244:0
  %1774 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %value_layer.9 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.54, %1774), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:245:0
  %1776 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.9, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.9, %1776), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.17, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.161 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.18, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.162 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.161, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.9 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.162, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self/__module.mobilebert.encoder.layer.8.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.17 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.9, %value_layer.9), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:280:0
  %1783 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %1784 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.17, %1783), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.18 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1784, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:281:0
  %1786 : int = aten::size(%context_layer.18, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1787 : int = aten::size(%context_layer.18, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:282:0
  %1788 : int[] = prim::ListConstruct(%1786, %1787, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self
  %input.163 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.18, %1788), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.self # transformers/modeling_mobilebert.py:283:0
  %1790 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11600.NoNorm = prim::GetAttr[name="LayerNorm"](%1738)
  %1791 : __torch__.torch.nn.modules.linear.___torch_mangle_11599.Linear = prim::GetAttr[name="dense"](%1738)
  %1792 : Tensor = prim::GetAttr[name="bias"](%1791)
  %1793 : Tensor = prim::GetAttr[name="weight"](%1791)
  %1794 : Float(128:1, 128:128) = aten::t(%1793), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %output.127 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.163, %1794), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.41 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.127, %1792, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.68 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.41, %1737, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output # transformers/modeling_mobilebert.py:301:0
  %1798 : Tensor = prim::GetAttr[name="bias"](%1790)
  %1799 : Tensor = prim::GetAttr[name="weight"](%1790)
  %1800 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.68, %1799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.164 : Float(17:1664, 13:128, 128:1) = aten::add(%1800, %1798, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.attention/__module.mobilebert.encoder.layer.8.attention.output/__module.mobilebert.encoder.layer.8.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1802 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11623.FFNOutput = prim::GetAttr[name="output"](%1708)
  %1803 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11620.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1708)
  %1804 : __torch__.torch.nn.modules.linear.___torch_mangle_11619.Linear = prim::GetAttr[name="dense"](%1803)
  %1805 : Tensor = prim::GetAttr[name="bias"](%1804)
  %1806 : Tensor = prim::GetAttr[name="weight"](%1804)
  %1807 : Float(128:1, 512:128) = aten::t(%1806), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.128 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.164, %1807), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.165 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.128, %1805, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate/__module.mobilebert.encoder.layer.8.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.166 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.165), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %1811 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11622.NoNorm = prim::GetAttr[name="LayerNorm"](%1802)
  %1812 : __torch__.torch.nn.modules.linear.___torch_mangle_11621.Linear = prim::GetAttr[name="dense"](%1802)
  %1813 : Tensor = prim::GetAttr[name="bias"](%1812)
  %1814 : Tensor = prim::GetAttr[name="weight"](%1812)
  %1815 : Float(512:1, 128:512) = aten::t(%1814), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.129 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.166, %1815), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.42 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.129, %1813, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.69 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.42, %input.164, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %1819 : Tensor = prim::GetAttr[name="bias"](%1811)
  %1820 : Tensor = prim::GetAttr[name="weight"](%1811)
  %1821 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.69, %1820), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.167 : Float(17:1664, 13:128, 128:1) = aten::add(%1821, %1819, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.0/__module.mobilebert.encoder.layer.8.ffn.0.output/__module.mobilebert.encoder.layer.8.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1823 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11629.FFNOutput = prim::GetAttr[name="output"](%1706)
  %1824 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11626.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1706)
  %1825 : __torch__.torch.nn.modules.linear.___torch_mangle_11625.Linear = prim::GetAttr[name="dense"](%1824)
  %1826 : Tensor = prim::GetAttr[name="bias"](%1825)
  %1827 : Tensor = prim::GetAttr[name="weight"](%1825)
  %1828 : Float(128:1, 512:128) = aten::t(%1827), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.130 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.167, %1828), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.168 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.130, %1826, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate/__module.mobilebert.encoder.layer.8.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.169 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %1832 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11628.NoNorm = prim::GetAttr[name="LayerNorm"](%1823)
  %1833 : __torch__.torch.nn.modules.linear.___torch_mangle_11627.Linear = prim::GetAttr[name="dense"](%1823)
  %1834 : Tensor = prim::GetAttr[name="bias"](%1833)
  %1835 : Tensor = prim::GetAttr[name="weight"](%1833)
  %1836 : Float(512:1, 128:512) = aten::t(%1835), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.131 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.169, %1836), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.43 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.131, %1834, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.70 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.43, %input.167, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %1840 : Tensor = prim::GetAttr[name="bias"](%1832)
  %1841 : Tensor = prim::GetAttr[name="weight"](%1832)
  %1842 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.70, %1841), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.170 : Float(17:1664, 13:128, 128:1) = aten::add(%1842, %1840, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.1/__module.mobilebert.encoder.layer.8.ffn.1.output/__module.mobilebert.encoder.layer.8.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1844 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11635.FFNOutput = prim::GetAttr[name="output"](%1704)
  %1845 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11632.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1704)
  %1846 : __torch__.torch.nn.modules.linear.___torch_mangle_11631.Linear = prim::GetAttr[name="dense"](%1845)
  %1847 : Tensor = prim::GetAttr[name="bias"](%1846)
  %1848 : Tensor = prim::GetAttr[name="weight"](%1846)
  %1849 : Float(128:1, 512:128) = aten::t(%1848), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.132 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.170, %1849), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.171 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.132, %1847, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate/__module.mobilebert.encoder.layer.8.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.172 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %1853 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11634.NoNorm = prim::GetAttr[name="LayerNorm"](%1844)
  %1854 : __torch__.torch.nn.modules.linear.___torch_mangle_11633.Linear = prim::GetAttr[name="dense"](%1844)
  %1855 : Tensor = prim::GetAttr[name="bias"](%1854)
  %1856 : Tensor = prim::GetAttr[name="weight"](%1854)
  %1857 : Float(512:1, 128:512) = aten::t(%1856), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.133 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.172, %1857), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.44 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.133, %1855, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.71 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.44, %input.170, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %1861 : Tensor = prim::GetAttr[name="bias"](%1853)
  %1862 : Tensor = prim::GetAttr[name="weight"](%1853)
  %1863 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.71, %1862), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.173 : Float(17:1664, 13:128, 128:1) = aten::add(%1863, %1861, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.ffn.2/__module.mobilebert.encoder.layer.8.ffn.2.output/__module.mobilebert.encoder.layer.8.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1865 : __torch__.torch.nn.modules.linear.___torch_mangle_11603.Linear = prim::GetAttr[name="dense"](%1702)
  %1866 : Tensor = prim::GetAttr[name="bias"](%1865)
  %1867 : Tensor = prim::GetAttr[name="weight"](%1865)
  %1868 : Float(128:1, 512:128) = aten::t(%1867), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %output.134 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.173, %1868), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1676:0
  %input.174 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.134, %1866, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate/__module.mobilebert.encoder.layer.8.intermediate.dense # torch/nn/functional.py:1678:0
  %input.175 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.174), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.intermediate # torch/nn/functional.py:1119:0
  %1872 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11610.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1701)
  %1873 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11606.NoNorm = prim::GetAttr[name="LayerNorm"](%1701)
  %1874 : __torch__.torch.nn.modules.linear.___torch_mangle_11605.Linear = prim::GetAttr[name="dense"](%1701)
  %1875 : Tensor = prim::GetAttr[name="bias"](%1874)
  %1876 : Tensor = prim::GetAttr[name="weight"](%1874)
  %1877 : Float(512:1, 128:512) = aten::t(%1876), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %output.135 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.175, %1877), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1676:0
  %layer_output.9 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.135, %1875, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.72 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.9, %input.173, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output # transformers/modeling_mobilebert.py:405:0
  %1881 : Tensor = prim::GetAttr[name="bias"](%1873)
  %1882 : Tensor = prim::GetAttr[name="weight"](%1873)
  %1883 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.72, %1882), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.176 : Float(17:1664, 13:128, 128:1) = aten::add(%1883, %1881, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1885 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11608.NoNorm = prim::GetAttr[name="LayerNorm"](%1872)
  %1886 : __torch__.torch.nn.modules.linear.___torch_mangle_11607.Linear = prim::GetAttr[name="dense"](%1872)
  %1887 : Tensor = prim::GetAttr[name="bias"](%1886)
  %1888 : Tensor = prim::GetAttr[name="weight"](%1886)
  %1889 : Float(128:1, 512:128) = aten::t(%1888), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.136 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.176, %1889), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.177 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.136, %1887, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.45 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.177, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.73 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.45, %input.159, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %1894 : Tensor = prim::GetAttr[name="bias"](%1885)
  %1895 : Tensor = prim::GetAttr[name="weight"](%1885)
  %1896 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.73, %1895), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.178 : Float(17:6656, 13:512, 512:1) = aten::add(%1896, %1894, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.8/__module.mobilebert.encoder.layer.8.output/__module.mobilebert.encoder.layer.8.output.bottleneck/__module.mobilebert.encoder.layer.8.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1898 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11656.MobileBertOutput = prim::GetAttr[name="output"](%106)
  %1899 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11649.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%106)
  %1900 : __torch__.torch.nn.modules.container.___torch_mangle_11682.ModuleList = prim::GetAttr[name="ffn"](%106)
  %1901 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11681.FFNLayer = prim::GetAttr[name="2"](%1900)
  %1902 : __torch__.torch.nn.modules.container.___torch_mangle_11682.ModuleList = prim::GetAttr[name="ffn"](%106)
  %1903 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11675.FFNLayer = prim::GetAttr[name="1"](%1902)
  %1904 : __torch__.torch.nn.modules.container.___torch_mangle_11682.ModuleList = prim::GetAttr[name="ffn"](%106)
  %1905 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11669.FFNLayer = prim::GetAttr[name="0"](%1904)
  %1906 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11647.MobileBertAttention = prim::GetAttr[name="attention"](%106)
  %1907 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11663.Bottleneck = prim::GetAttr[name="bottleneck"](%106)
  %1908 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11662.BottleneckLayer = prim::GetAttr[name="attention"](%1907)
  %1909 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11659.BottleneckLayer = prim::GetAttr[name="input"](%1907)
  %1910 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11658.NoNorm = prim::GetAttr[name="LayerNorm"](%1909)
  %1911 : __torch__.torch.nn.modules.linear.___torch_mangle_11657.Linear = prim::GetAttr[name="dense"](%1909)
  %1912 : Tensor = prim::GetAttr[name="bias"](%1911)
  %1913 : Tensor = prim::GetAttr[name="weight"](%1911)
  %1914 : Float(512:1, 128:512) = aten::t(%1913), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.137 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1914), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.137, %1912, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %1917 : Tensor = prim::GetAttr[name="bias"](%1910)
  %1918 : Tensor = prim::GetAttr[name="weight"](%1910)
  %1919 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.74, %1918), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.10 : Float(17:1664, 13:128, 128:1) = aten::add(%1919, %1917, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.input/__module.mobilebert.encoder.layer.9.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1921 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11661.NoNorm = prim::GetAttr[name="LayerNorm"](%1908)
  %1922 : __torch__.torch.nn.modules.linear.___torch_mangle_11660.Linear = prim::GetAttr[name="dense"](%1908)
  %1923 : Tensor = prim::GetAttr[name="bias"](%1922)
  %1924 : Tensor = prim::GetAttr[name="weight"](%1922)
  %1925 : Float(512:1, 128:512) = aten::t(%1924), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.138 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1925), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.138, %1923, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %1928 : Tensor = prim::GetAttr[name="bias"](%1921)
  %1929 : Tensor = prim::GetAttr[name="weight"](%1921)
  %1930 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.75, %1929), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.179 : Float(17:1664, 13:128, 128:1) = aten::add(%1930, %1928, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.bottleneck/__module.mobilebert.encoder.layer.9.bottleneck.attention/__module.mobilebert.encoder.layer.9.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1932 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.179, %residual_tensor.10)
  %1933 : Float(17:1664, 13:128, 128:1), %1934 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%1932)
  %1935 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11646.MobileBertSelfOutput = prim::GetAttr[name="output"](%1906)
  %1936 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11643.MobileBertSelfAttention = prim::GetAttr[name="self"](%1906)
  %1937 : __torch__.torch.nn.modules.linear.___torch_mangle_11641.Linear = prim::GetAttr[name="value"](%1936)
  %1938 : __torch__.torch.nn.modules.linear.___torch_mangle_11640.Linear = prim::GetAttr[name="key"](%1936)
  %1939 : __torch__.torch.nn.modules.linear.___torch_mangle_11639.Linear = prim::GetAttr[name="query"](%1936)
  %1940 : Tensor = prim::GetAttr[name="bias"](%1939)
  %1941 : Tensor = prim::GetAttr[name="weight"](%1939)
  %1942 : Float(128:1, 128:128) = aten::t(%1941), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %output.139 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1933, %1942), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1676:0
  %x.55 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.139, %1940, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.query # torch/nn/functional.py:1678:0
  %1945 : Tensor = prim::GetAttr[name="bias"](%1938)
  %1946 : Tensor = prim::GetAttr[name="weight"](%1938)
  %1947 : Float(128:1, 128:128) = aten::t(%1946), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %output.140 : Float(17:1664, 13:128, 128:1) = aten::matmul(%1933, %1947), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1676:0
  %x.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.140, %1945, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.key # torch/nn/functional.py:1678:0
  %1950 : Tensor = prim::GetAttr[name="bias"](%1937)
  %1951 : Tensor = prim::GetAttr[name="weight"](%1937)
  %1952 : Float(512:1, 128:512) = aten::t(%1951), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %output.141 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.178, %1952), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1676:0
  %x.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.141, %1950, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.value # torch/nn/functional.py:1678:0
  %1955 : int = aten::size(%x.55, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1956 : int = aten::size(%x.55, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1957 : int[] = prim::ListConstruct(%1955, %1956, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.56 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.55, %1957), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1959 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %query_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.56, %1959), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1961 : int = aten::size(%x.57, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1962 : int = aten::size(%x.57, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1963 : int[] = prim::ListConstruct(%1961, %1962, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.58 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.57, %1963), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1965 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %key_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.58, %1965), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1967 : int = aten::size(%x.59, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1968 : int = aten::size(%x.59, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:243:0
  %1969 : int[] = prim::ListConstruct(%1967, %1968, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %x.60 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.59, %1969), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:244:0
  %1971 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %value_layer.10 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.60, %1971), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:245:0
  %1973 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.10, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.10, %1973), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.19, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.180 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.20, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.181 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.180, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.10 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.181, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self/__module.mobilebert.encoder.layer.9.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.19 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.10, %value_layer.10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:280:0
  %1980 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %1981 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.19, %1980), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.20 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%1981, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:281:0
  %1983 : int = aten::size(%context_layer.20, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1984 : int = aten::size(%context_layer.20, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:282:0
  %1985 : int[] = prim::ListConstruct(%1983, %1984, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self
  %input.182 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.20, %1985), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.self # transformers/modeling_mobilebert.py:283:0
  %1987 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11645.NoNorm = prim::GetAttr[name="LayerNorm"](%1935)
  %1988 : __torch__.torch.nn.modules.linear.___torch_mangle_11644.Linear = prim::GetAttr[name="dense"](%1935)
  %1989 : Tensor = prim::GetAttr[name="bias"](%1988)
  %1990 : Tensor = prim::GetAttr[name="weight"](%1988)
  %1991 : Float(128:1, 128:128) = aten::t(%1990), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %output.142 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.182, %1991), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.46 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.142, %1989, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.76 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.46, %1934, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output # transformers/modeling_mobilebert.py:301:0
  %1995 : Tensor = prim::GetAttr[name="bias"](%1987)
  %1996 : Tensor = prim::GetAttr[name="weight"](%1987)
  %1997 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.76, %1996), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.183 : Float(17:1664, 13:128, 128:1) = aten::add(%1997, %1995, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.attention/__module.mobilebert.encoder.layer.9.attention.output/__module.mobilebert.encoder.layer.9.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %1999 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11668.FFNOutput = prim::GetAttr[name="output"](%1905)
  %2000 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11665.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1905)
  %2001 : __torch__.torch.nn.modules.linear.___torch_mangle_11664.Linear = prim::GetAttr[name="dense"](%2000)
  %2002 : Tensor = prim::GetAttr[name="bias"](%2001)
  %2003 : Tensor = prim::GetAttr[name="weight"](%2001)
  %2004 : Float(128:1, 512:128) = aten::t(%2003), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.143 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.183, %2004), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.184 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.143, %2002, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate/__module.mobilebert.encoder.layer.9.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.185 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2008 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11667.NoNorm = prim::GetAttr[name="LayerNorm"](%1999)
  %2009 : __torch__.torch.nn.modules.linear.___torch_mangle_11666.Linear = prim::GetAttr[name="dense"](%1999)
  %2010 : Tensor = prim::GetAttr[name="bias"](%2009)
  %2011 : Tensor = prim::GetAttr[name="weight"](%2009)
  %2012 : Float(512:1, 128:512) = aten::t(%2011), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.144 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.185, %2012), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.47 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.144, %2010, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.77 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.47, %input.183, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2016 : Tensor = prim::GetAttr[name="bias"](%2008)
  %2017 : Tensor = prim::GetAttr[name="weight"](%2008)
  %2018 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.77, %2017), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.186 : Float(17:1664, 13:128, 128:1) = aten::add(%2018, %2016, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.0/__module.mobilebert.encoder.layer.9.ffn.0.output/__module.mobilebert.encoder.layer.9.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2020 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11674.FFNOutput = prim::GetAttr[name="output"](%1903)
  %2021 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11671.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1903)
  %2022 : __torch__.torch.nn.modules.linear.___torch_mangle_11670.Linear = prim::GetAttr[name="dense"](%2021)
  %2023 : Tensor = prim::GetAttr[name="bias"](%2022)
  %2024 : Tensor = prim::GetAttr[name="weight"](%2022)
  %2025 : Float(128:1, 512:128) = aten::t(%2024), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.145 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.186, %2025), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.187 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.145, %2023, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate/__module.mobilebert.encoder.layer.9.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.188 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2029 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11673.NoNorm = prim::GetAttr[name="LayerNorm"](%2020)
  %2030 : __torch__.torch.nn.modules.linear.___torch_mangle_11672.Linear = prim::GetAttr[name="dense"](%2020)
  %2031 : Tensor = prim::GetAttr[name="bias"](%2030)
  %2032 : Tensor = prim::GetAttr[name="weight"](%2030)
  %2033 : Float(512:1, 128:512) = aten::t(%2032), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.146 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.188, %2033), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.48 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.146, %2031, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.78 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.48, %input.186, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2037 : Tensor = prim::GetAttr[name="bias"](%2029)
  %2038 : Tensor = prim::GetAttr[name="weight"](%2029)
  %2039 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.78, %2038), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.189 : Float(17:1664, 13:128, 128:1) = aten::add(%2039, %2037, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.1/__module.mobilebert.encoder.layer.9.ffn.1.output/__module.mobilebert.encoder.layer.9.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2041 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11680.FFNOutput = prim::GetAttr[name="output"](%1901)
  %2042 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11677.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%1901)
  %2043 : __torch__.torch.nn.modules.linear.___torch_mangle_11676.Linear = prim::GetAttr[name="dense"](%2042)
  %2044 : Tensor = prim::GetAttr[name="bias"](%2043)
  %2045 : Tensor = prim::GetAttr[name="weight"](%2043)
  %2046 : Float(128:1, 512:128) = aten::t(%2045), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.147 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.189, %2046), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.190 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.147, %2044, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate/__module.mobilebert.encoder.layer.9.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.191 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.190), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2050 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11679.NoNorm = prim::GetAttr[name="LayerNorm"](%2041)
  %2051 : __torch__.torch.nn.modules.linear.___torch_mangle_11678.Linear = prim::GetAttr[name="dense"](%2041)
  %2052 : Tensor = prim::GetAttr[name="bias"](%2051)
  %2053 : Tensor = prim::GetAttr[name="weight"](%2051)
  %2054 : Float(512:1, 128:512) = aten::t(%2053), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.148 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.191, %2054), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.49 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.148, %2052, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.79 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.49, %input.189, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2058 : Tensor = prim::GetAttr[name="bias"](%2050)
  %2059 : Tensor = prim::GetAttr[name="weight"](%2050)
  %2060 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.79, %2059), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.192 : Float(17:1664, 13:128, 128:1) = aten::add(%2060, %2058, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.ffn.2/__module.mobilebert.encoder.layer.9.ffn.2.output/__module.mobilebert.encoder.layer.9.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2062 : __torch__.torch.nn.modules.linear.___torch_mangle_11648.Linear = prim::GetAttr[name="dense"](%1899)
  %2063 : Tensor = prim::GetAttr[name="bias"](%2062)
  %2064 : Tensor = prim::GetAttr[name="weight"](%2062)
  %2065 : Float(128:1, 512:128) = aten::t(%2064), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %output.149 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.192, %2065), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1676:0
  %input.193 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.149, %2063, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate/__module.mobilebert.encoder.layer.9.intermediate.dense # torch/nn/functional.py:1678:0
  %input.194 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.intermediate # torch/nn/functional.py:1119:0
  %2069 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11655.OutputBottleneck = prim::GetAttr[name="bottleneck"](%1898)
  %2070 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11651.NoNorm = prim::GetAttr[name="LayerNorm"](%1898)
  %2071 : __torch__.torch.nn.modules.linear.___torch_mangle_11650.Linear = prim::GetAttr[name="dense"](%1898)
  %2072 : Tensor = prim::GetAttr[name="bias"](%2071)
  %2073 : Tensor = prim::GetAttr[name="weight"](%2071)
  %2074 : Float(512:1, 128:512) = aten::t(%2073), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %output.150 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.194, %2074), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1676:0
  %layer_output.10 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.150, %2072, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.80 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.10, %input.192, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output # transformers/modeling_mobilebert.py:405:0
  %2078 : Tensor = prim::GetAttr[name="bias"](%2070)
  %2079 : Tensor = prim::GetAttr[name="weight"](%2070)
  %2080 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.80, %2079), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.195 : Float(17:1664, 13:128, 128:1) = aten::add(%2080, %2078, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2082 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11653.NoNorm = prim::GetAttr[name="LayerNorm"](%2069)
  %2083 : __torch__.torch.nn.modules.linear.___torch_mangle_11652.Linear = prim::GetAttr[name="dense"](%2069)
  %2084 : Tensor = prim::GetAttr[name="bias"](%2083)
  %2085 : Tensor = prim::GetAttr[name="weight"](%2083)
  %2086 : Float(128:1, 512:128) = aten::t(%2085), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.151 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.195, %2086), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.196 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.151, %2084, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.50 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.196, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.81 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.50, %input.178, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2091 : Tensor = prim::GetAttr[name="bias"](%2082)
  %2092 : Tensor = prim::GetAttr[name="weight"](%2082)
  %2093 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.81, %2092), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.197 : Float(17:6656, 13:512, 512:1) = aten::add(%2093, %2091, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.9/__module.mobilebert.encoder.layer.9.output/__module.mobilebert.encoder.layer.9.output.bottleneck/__module.mobilebert.encoder.layer.9.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2095 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11701.MobileBertOutput = prim::GetAttr[name="output"](%104)
  %2096 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11694.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%104)
  %2097 : __torch__.torch.nn.modules.container.___torch_mangle_11727.ModuleList = prim::GetAttr[name="ffn"](%104)
  %2098 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11726.FFNLayer = prim::GetAttr[name="2"](%2097)
  %2099 : __torch__.torch.nn.modules.container.___torch_mangle_11727.ModuleList = prim::GetAttr[name="ffn"](%104)
  %2100 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11720.FFNLayer = prim::GetAttr[name="1"](%2099)
  %2101 : __torch__.torch.nn.modules.container.___torch_mangle_11727.ModuleList = prim::GetAttr[name="ffn"](%104)
  %2102 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11714.FFNLayer = prim::GetAttr[name="0"](%2101)
  %2103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11692.MobileBertAttention = prim::GetAttr[name="attention"](%104)
  %2104 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11708.Bottleneck = prim::GetAttr[name="bottleneck"](%104)
  %2105 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11707.BottleneckLayer = prim::GetAttr[name="attention"](%2104)
  %2106 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11704.BottleneckLayer = prim::GetAttr[name="input"](%2104)
  %2107 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11703.NoNorm = prim::GetAttr[name="LayerNorm"](%2106)
  %2108 : __torch__.torch.nn.modules.linear.___torch_mangle_11702.Linear = prim::GetAttr[name="dense"](%2106)
  %2109 : Tensor = prim::GetAttr[name="bias"](%2108)
  %2110 : Tensor = prim::GetAttr[name="weight"](%2108)
  %2111 : Float(512:1, 128:512) = aten::t(%2110), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.152 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.152, %2109, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2114 : Tensor = prim::GetAttr[name="bias"](%2107)
  %2115 : Tensor = prim::GetAttr[name="weight"](%2107)
  %2116 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.82, %2115), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.11 : Float(17:1664, 13:128, 128:1) = aten::add(%2116, %2114, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.input/__module.mobilebert.encoder.layer.10.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11706.NoNorm = prim::GetAttr[name="LayerNorm"](%2105)
  %2119 : __torch__.torch.nn.modules.linear.___torch_mangle_11705.Linear = prim::GetAttr[name="dense"](%2105)
  %2120 : Tensor = prim::GetAttr[name="bias"](%2119)
  %2121 : Tensor = prim::GetAttr[name="weight"](%2119)
  %2122 : Float(512:1, 128:512) = aten::t(%2121), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.153 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2122), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.153, %2120, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2125 : Tensor = prim::GetAttr[name="bias"](%2118)
  %2126 : Tensor = prim::GetAttr[name="weight"](%2118)
  %2127 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.83, %2126), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.198 : Float(17:1664, 13:128, 128:1) = aten::add(%2127, %2125, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.bottleneck/__module.mobilebert.encoder.layer.10.bottleneck.attention/__module.mobilebert.encoder.layer.10.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2129 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.198, %residual_tensor.11)
  %2130 : Float(17:1664, 13:128, 128:1), %2131 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2129)
  %2132 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11691.MobileBertSelfOutput = prim::GetAttr[name="output"](%2103)
  %2133 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11688.MobileBertSelfAttention = prim::GetAttr[name="self"](%2103)
  %2134 : __torch__.torch.nn.modules.linear.___torch_mangle_11686.Linear = prim::GetAttr[name="value"](%2133)
  %2135 : __torch__.torch.nn.modules.linear.___torch_mangle_11685.Linear = prim::GetAttr[name="key"](%2133)
  %2136 : __torch__.torch.nn.modules.linear.___torch_mangle_11684.Linear = prim::GetAttr[name="query"](%2133)
  %2137 : Tensor = prim::GetAttr[name="bias"](%2136)
  %2138 : Tensor = prim::GetAttr[name="weight"](%2136)
  %2139 : Float(128:1, 128:128) = aten::t(%2138), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %output.154 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2130, %2139), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1676:0
  %x.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.154, %2137, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.query # torch/nn/functional.py:1678:0
  %2142 : Tensor = prim::GetAttr[name="bias"](%2135)
  %2143 : Tensor = prim::GetAttr[name="weight"](%2135)
  %2144 : Float(128:1, 128:128) = aten::t(%2143), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %output.155 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2130, %2144), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1676:0
  %x.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.155, %2142, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.key # torch/nn/functional.py:1678:0
  %2147 : Tensor = prim::GetAttr[name="bias"](%2134)
  %2148 : Tensor = prim::GetAttr[name="weight"](%2134)
  %2149 : Float(512:1, 128:512) = aten::t(%2148), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %output.156 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.197, %2149), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1676:0
  %x.65 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.156, %2147, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.value # torch/nn/functional.py:1678:0
  %2152 : int = aten::size(%x.61, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2153 : int = aten::size(%x.61, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2154 : int[] = prim::ListConstruct(%2152, %2153, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.62 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.61, %2154), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2156 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %query_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.62, %2156), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2158 : int = aten::size(%x.63, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2159 : int = aten::size(%x.63, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2160 : int[] = prim::ListConstruct(%2158, %2159, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.64 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.63, %2160), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2162 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %key_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.64, %2162), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2164 : int = aten::size(%x.65, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2165 : int = aten::size(%x.65, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:243:0
  %2166 : int[] = prim::ListConstruct(%2164, %2165, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %x.66 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.65, %2166), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:244:0
  %2168 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %value_layer.11 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.66, %2168), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:245:0
  %2170 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.11, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.11, %2170), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.21, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.199 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.22, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.200 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.199, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.11 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.200, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self/__module.mobilebert.encoder.layer.10.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.21 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.11, %value_layer.11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:280:0
  %2177 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %2178 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.21, %2177), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.22 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2178, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:281:0
  %2180 : int = aten::size(%context_layer.22, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2181 : int = aten::size(%context_layer.22, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:282:0
  %2182 : int[] = prim::ListConstruct(%2180, %2181, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self
  %input.201 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.22, %2182), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.self # transformers/modeling_mobilebert.py:283:0
  %2184 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11690.NoNorm = prim::GetAttr[name="LayerNorm"](%2132)
  %2185 : __torch__.torch.nn.modules.linear.___torch_mangle_11689.Linear = prim::GetAttr[name="dense"](%2132)
  %2186 : Tensor = prim::GetAttr[name="bias"](%2185)
  %2187 : Tensor = prim::GetAttr[name="weight"](%2185)
  %2188 : Float(128:1, 128:128) = aten::t(%2187), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %output.157 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.201, %2188), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.51 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.157, %2186, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.84 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.51, %2131, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output # transformers/modeling_mobilebert.py:301:0
  %2192 : Tensor = prim::GetAttr[name="bias"](%2184)
  %2193 : Tensor = prim::GetAttr[name="weight"](%2184)
  %2194 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.84, %2193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.202 : Float(17:1664, 13:128, 128:1) = aten::add(%2194, %2192, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.attention/__module.mobilebert.encoder.layer.10.attention.output/__module.mobilebert.encoder.layer.10.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2196 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11713.FFNOutput = prim::GetAttr[name="output"](%2102)
  %2197 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11710.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2102)
  %2198 : __torch__.torch.nn.modules.linear.___torch_mangle_11709.Linear = prim::GetAttr[name="dense"](%2197)
  %2199 : Tensor = prim::GetAttr[name="bias"](%2198)
  %2200 : Tensor = prim::GetAttr[name="weight"](%2198)
  %2201 : Float(128:1, 512:128) = aten::t(%2200), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.158 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.202, %2201), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.203 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.158, %2199, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate/__module.mobilebert.encoder.layer.10.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.204 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.203), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2205 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11712.NoNorm = prim::GetAttr[name="LayerNorm"](%2196)
  %2206 : __torch__.torch.nn.modules.linear.___torch_mangle_11711.Linear = prim::GetAttr[name="dense"](%2196)
  %2207 : Tensor = prim::GetAttr[name="bias"](%2206)
  %2208 : Tensor = prim::GetAttr[name="weight"](%2206)
  %2209 : Float(512:1, 128:512) = aten::t(%2208), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.159 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.204, %2209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.52 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.159, %2207, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.85 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.52, %input.202, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2213 : Tensor = prim::GetAttr[name="bias"](%2205)
  %2214 : Tensor = prim::GetAttr[name="weight"](%2205)
  %2215 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.85, %2214), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.205 : Float(17:1664, 13:128, 128:1) = aten::add(%2215, %2213, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.0/__module.mobilebert.encoder.layer.10.ffn.0.output/__module.mobilebert.encoder.layer.10.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2217 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11719.FFNOutput = prim::GetAttr[name="output"](%2100)
  %2218 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11716.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2100)
  %2219 : __torch__.torch.nn.modules.linear.___torch_mangle_11715.Linear = prim::GetAttr[name="dense"](%2218)
  %2220 : Tensor = prim::GetAttr[name="bias"](%2219)
  %2221 : Tensor = prim::GetAttr[name="weight"](%2219)
  %2222 : Float(128:1, 512:128) = aten::t(%2221), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.160 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.205, %2222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.206 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.160, %2220, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate/__module.mobilebert.encoder.layer.10.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.207 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2226 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11718.NoNorm = prim::GetAttr[name="LayerNorm"](%2217)
  %2227 : __torch__.torch.nn.modules.linear.___torch_mangle_11717.Linear = prim::GetAttr[name="dense"](%2217)
  %2228 : Tensor = prim::GetAttr[name="bias"](%2227)
  %2229 : Tensor = prim::GetAttr[name="weight"](%2227)
  %2230 : Float(512:1, 128:512) = aten::t(%2229), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.161 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.207, %2230), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.53 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.161, %2228, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.86 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.53, %input.205, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2234 : Tensor = prim::GetAttr[name="bias"](%2226)
  %2235 : Tensor = prim::GetAttr[name="weight"](%2226)
  %2236 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.86, %2235), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.208 : Float(17:1664, 13:128, 128:1) = aten::add(%2236, %2234, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.1/__module.mobilebert.encoder.layer.10.ffn.1.output/__module.mobilebert.encoder.layer.10.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2238 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11725.FFNOutput = prim::GetAttr[name="output"](%2098)
  %2239 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11722.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2098)
  %2240 : __torch__.torch.nn.modules.linear.___torch_mangle_11721.Linear = prim::GetAttr[name="dense"](%2239)
  %2241 : Tensor = prim::GetAttr[name="bias"](%2240)
  %2242 : Tensor = prim::GetAttr[name="weight"](%2240)
  %2243 : Float(128:1, 512:128) = aten::t(%2242), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.162 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.208, %2243), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.209 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.162, %2241, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate/__module.mobilebert.encoder.layer.10.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.210 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.209), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2247 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11724.NoNorm = prim::GetAttr[name="LayerNorm"](%2238)
  %2248 : __torch__.torch.nn.modules.linear.___torch_mangle_11723.Linear = prim::GetAttr[name="dense"](%2238)
  %2249 : Tensor = prim::GetAttr[name="bias"](%2248)
  %2250 : Tensor = prim::GetAttr[name="weight"](%2248)
  %2251 : Float(512:1, 128:512) = aten::t(%2250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.163 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.210, %2251), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.54 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.163, %2249, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.87 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.54, %input.208, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2255 : Tensor = prim::GetAttr[name="bias"](%2247)
  %2256 : Tensor = prim::GetAttr[name="weight"](%2247)
  %2257 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.87, %2256), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.211 : Float(17:1664, 13:128, 128:1) = aten::add(%2257, %2255, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.ffn.2/__module.mobilebert.encoder.layer.10.ffn.2.output/__module.mobilebert.encoder.layer.10.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2259 : __torch__.torch.nn.modules.linear.___torch_mangle_11693.Linear = prim::GetAttr[name="dense"](%2096)
  %2260 : Tensor = prim::GetAttr[name="bias"](%2259)
  %2261 : Tensor = prim::GetAttr[name="weight"](%2259)
  %2262 : Float(128:1, 512:128) = aten::t(%2261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %output.164 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.211, %2262), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1676:0
  %input.212 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.164, %2260, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate/__module.mobilebert.encoder.layer.10.intermediate.dense # torch/nn/functional.py:1678:0
  %input.213 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.intermediate # torch/nn/functional.py:1119:0
  %2266 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11700.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2095)
  %2267 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11696.NoNorm = prim::GetAttr[name="LayerNorm"](%2095)
  %2268 : __torch__.torch.nn.modules.linear.___torch_mangle_11695.Linear = prim::GetAttr[name="dense"](%2095)
  %2269 : Tensor = prim::GetAttr[name="bias"](%2268)
  %2270 : Tensor = prim::GetAttr[name="weight"](%2268)
  %2271 : Float(512:1, 128:512) = aten::t(%2270), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %output.165 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.213, %2271), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1676:0
  %layer_output.11 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.165, %2269, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.88 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.11, %input.211, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output # transformers/modeling_mobilebert.py:405:0
  %2275 : Tensor = prim::GetAttr[name="bias"](%2267)
  %2276 : Tensor = prim::GetAttr[name="weight"](%2267)
  %2277 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.88, %2276), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.214 : Float(17:1664, 13:128, 128:1) = aten::add(%2277, %2275, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2279 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11698.NoNorm = prim::GetAttr[name="LayerNorm"](%2266)
  %2280 : __torch__.torch.nn.modules.linear.___torch_mangle_11697.Linear = prim::GetAttr[name="dense"](%2266)
  %2281 : Tensor = prim::GetAttr[name="bias"](%2280)
  %2282 : Tensor = prim::GetAttr[name="weight"](%2280)
  %2283 : Float(128:1, 512:128) = aten::t(%2282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.166 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.214, %2283), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.215 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.166, %2281, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.55 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.215, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.89 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.55, %input.197, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2288 : Tensor = prim::GetAttr[name="bias"](%2279)
  %2289 : Tensor = prim::GetAttr[name="weight"](%2279)
  %2290 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.89, %2289), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.216 : Float(17:6656, 13:512, 512:1) = aten::add(%2290, %2288, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.10/__module.mobilebert.encoder.layer.10.output/__module.mobilebert.encoder.layer.10.output.bottleneck/__module.mobilebert.encoder.layer.10.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2292 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11746.MobileBertOutput = prim::GetAttr[name="output"](%102)
  %2293 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11739.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%102)
  %2294 : __torch__.torch.nn.modules.container.___torch_mangle_11772.ModuleList = prim::GetAttr[name="ffn"](%102)
  %2295 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11771.FFNLayer = prim::GetAttr[name="2"](%2294)
  %2296 : __torch__.torch.nn.modules.container.___torch_mangle_11772.ModuleList = prim::GetAttr[name="ffn"](%102)
  %2297 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11765.FFNLayer = prim::GetAttr[name="1"](%2296)
  %2298 : __torch__.torch.nn.modules.container.___torch_mangle_11772.ModuleList = prim::GetAttr[name="ffn"](%102)
  %2299 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11759.FFNLayer = prim::GetAttr[name="0"](%2298)
  %2300 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11737.MobileBertAttention = prim::GetAttr[name="attention"](%102)
  %2301 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11753.Bottleneck = prim::GetAttr[name="bottleneck"](%102)
  %2302 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11752.BottleneckLayer = prim::GetAttr[name="attention"](%2301)
  %2303 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11749.BottleneckLayer = prim::GetAttr[name="input"](%2301)
  %2304 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11748.NoNorm = prim::GetAttr[name="LayerNorm"](%2303)
  %2305 : __torch__.torch.nn.modules.linear.___torch_mangle_11747.Linear = prim::GetAttr[name="dense"](%2303)
  %2306 : Tensor = prim::GetAttr[name="bias"](%2305)
  %2307 : Tensor = prim::GetAttr[name="weight"](%2305)
  %2308 : Float(512:1, 128:512) = aten::t(%2307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.167 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2308), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.90 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.167, %2306, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2311 : Tensor = prim::GetAttr[name="bias"](%2304)
  %2312 : Tensor = prim::GetAttr[name="weight"](%2304)
  %2313 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.90, %2312), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.12 : Float(17:1664, 13:128, 128:1) = aten::add(%2313, %2311, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.input/__module.mobilebert.encoder.layer.11.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2315 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11751.NoNorm = prim::GetAttr[name="LayerNorm"](%2302)
  %2316 : __torch__.torch.nn.modules.linear.___torch_mangle_11750.Linear = prim::GetAttr[name="dense"](%2302)
  %2317 : Tensor = prim::GetAttr[name="bias"](%2316)
  %2318 : Tensor = prim::GetAttr[name="weight"](%2316)
  %2319 : Float(512:1, 128:512) = aten::t(%2318), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.168 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2319), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.168, %2317, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2322 : Tensor = prim::GetAttr[name="bias"](%2315)
  %2323 : Tensor = prim::GetAttr[name="weight"](%2315)
  %2324 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.91, %2323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.217 : Float(17:1664, 13:128, 128:1) = aten::add(%2324, %2322, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.bottleneck/__module.mobilebert.encoder.layer.11.bottleneck.attention/__module.mobilebert.encoder.layer.11.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2326 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.217, %residual_tensor.12)
  %2327 : Float(17:1664, 13:128, 128:1), %2328 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2326)
  %2329 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11736.MobileBertSelfOutput = prim::GetAttr[name="output"](%2300)
  %2330 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11733.MobileBertSelfAttention = prim::GetAttr[name="self"](%2300)
  %2331 : __torch__.torch.nn.modules.linear.___torch_mangle_11731.Linear = prim::GetAttr[name="value"](%2330)
  %2332 : __torch__.torch.nn.modules.linear.___torch_mangle_11730.Linear = prim::GetAttr[name="key"](%2330)
  %2333 : __torch__.torch.nn.modules.linear.___torch_mangle_11729.Linear = prim::GetAttr[name="query"](%2330)
  %2334 : Tensor = prim::GetAttr[name="bias"](%2333)
  %2335 : Tensor = prim::GetAttr[name="weight"](%2333)
  %2336 : Float(128:1, 128:128) = aten::t(%2335), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %output.169 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2327, %2336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1676:0
  %x.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.169, %2334, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.query # torch/nn/functional.py:1678:0
  %2339 : Tensor = prim::GetAttr[name="bias"](%2332)
  %2340 : Tensor = prim::GetAttr[name="weight"](%2332)
  %2341 : Float(128:1, 128:128) = aten::t(%2340), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %output.170 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2327, %2341), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1676:0
  %x.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.170, %2339, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.key # torch/nn/functional.py:1678:0
  %2344 : Tensor = prim::GetAttr[name="bias"](%2331)
  %2345 : Tensor = prim::GetAttr[name="weight"](%2331)
  %2346 : Float(512:1, 128:512) = aten::t(%2345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %output.171 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.216, %2346), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1676:0
  %x.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.171, %2344, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.value # torch/nn/functional.py:1678:0
  %2349 : int = aten::size(%x.67, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2350 : int = aten::size(%x.67, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2351 : int[] = prim::ListConstruct(%2349, %2350, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.68 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.67, %2351), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2353 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %query_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.68, %2353), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2355 : int = aten::size(%x.69, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2356 : int = aten::size(%x.69, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2357 : int[] = prim::ListConstruct(%2355, %2356, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.70 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.69, %2357), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2359 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %key_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.70, %2359), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2361 : int = aten::size(%x.71, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2362 : int = aten::size(%x.71, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:243:0
  %2363 : int[] = prim::ListConstruct(%2361, %2362, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %x.72 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.71, %2363), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:244:0
  %2365 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %value_layer.12 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.72, %2365), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:245:0
  %2367 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.12, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.12, %2367), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.24 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.23, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.218 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.24, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.219 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.218, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.12 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.219, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self/__module.mobilebert.encoder.layer.11.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.23 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.12, %value_layer.12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:280:0
  %2374 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %2375 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.23, %2374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.24 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2375, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:281:0
  %2377 : int = aten::size(%context_layer.24, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2378 : int = aten::size(%context_layer.24, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:282:0
  %2379 : int[] = prim::ListConstruct(%2377, %2378, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self
  %input.220 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.24, %2379), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.self # transformers/modeling_mobilebert.py:283:0
  %2381 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11735.NoNorm = prim::GetAttr[name="LayerNorm"](%2329)
  %2382 : __torch__.torch.nn.modules.linear.___torch_mangle_11734.Linear = prim::GetAttr[name="dense"](%2329)
  %2383 : Tensor = prim::GetAttr[name="bias"](%2382)
  %2384 : Tensor = prim::GetAttr[name="weight"](%2382)
  %2385 : Float(128:1, 128:128) = aten::t(%2384), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %output.172 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.220, %2385), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.56 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.172, %2383, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.92 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.56, %2328, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output # transformers/modeling_mobilebert.py:301:0
  %2389 : Tensor = prim::GetAttr[name="bias"](%2381)
  %2390 : Tensor = prim::GetAttr[name="weight"](%2381)
  %2391 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.92, %2390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.221 : Float(17:1664, 13:128, 128:1) = aten::add(%2391, %2389, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.attention/__module.mobilebert.encoder.layer.11.attention.output/__module.mobilebert.encoder.layer.11.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2393 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11758.FFNOutput = prim::GetAttr[name="output"](%2299)
  %2394 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11755.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2299)
  %2395 : __torch__.torch.nn.modules.linear.___torch_mangle_11754.Linear = prim::GetAttr[name="dense"](%2394)
  %2396 : Tensor = prim::GetAttr[name="bias"](%2395)
  %2397 : Tensor = prim::GetAttr[name="weight"](%2395)
  %2398 : Float(128:1, 512:128) = aten::t(%2397), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.173 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.221, %2398), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.222 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.173, %2396, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate/__module.mobilebert.encoder.layer.11.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.223 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.222), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2402 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11757.NoNorm = prim::GetAttr[name="LayerNorm"](%2393)
  %2403 : __torch__.torch.nn.modules.linear.___torch_mangle_11756.Linear = prim::GetAttr[name="dense"](%2393)
  %2404 : Tensor = prim::GetAttr[name="bias"](%2403)
  %2405 : Tensor = prim::GetAttr[name="weight"](%2403)
  %2406 : Float(512:1, 128:512) = aten::t(%2405), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.174 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.223, %2406), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.57 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.174, %2404, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.93 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.57, %input.221, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2410 : Tensor = prim::GetAttr[name="bias"](%2402)
  %2411 : Tensor = prim::GetAttr[name="weight"](%2402)
  %2412 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.93, %2411), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.224 : Float(17:1664, 13:128, 128:1) = aten::add(%2412, %2410, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.0/__module.mobilebert.encoder.layer.11.ffn.0.output/__module.mobilebert.encoder.layer.11.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2414 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11764.FFNOutput = prim::GetAttr[name="output"](%2297)
  %2415 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11761.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2297)
  %2416 : __torch__.torch.nn.modules.linear.___torch_mangle_11760.Linear = prim::GetAttr[name="dense"](%2415)
  %2417 : Tensor = prim::GetAttr[name="bias"](%2416)
  %2418 : Tensor = prim::GetAttr[name="weight"](%2416)
  %2419 : Float(128:1, 512:128) = aten::t(%2418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.175 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.224, %2419), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.225 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.175, %2417, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate/__module.mobilebert.encoder.layer.11.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.226 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.225), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2423 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11763.NoNorm = prim::GetAttr[name="LayerNorm"](%2414)
  %2424 : __torch__.torch.nn.modules.linear.___torch_mangle_11762.Linear = prim::GetAttr[name="dense"](%2414)
  %2425 : Tensor = prim::GetAttr[name="bias"](%2424)
  %2426 : Tensor = prim::GetAttr[name="weight"](%2424)
  %2427 : Float(512:1, 128:512) = aten::t(%2426), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.176 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.226, %2427), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.58 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.176, %2425, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.94 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.58, %input.224, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2431 : Tensor = prim::GetAttr[name="bias"](%2423)
  %2432 : Tensor = prim::GetAttr[name="weight"](%2423)
  %2433 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.94, %2432), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.227 : Float(17:1664, 13:128, 128:1) = aten::add(%2433, %2431, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.1/__module.mobilebert.encoder.layer.11.ffn.1.output/__module.mobilebert.encoder.layer.11.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2435 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11770.FFNOutput = prim::GetAttr[name="output"](%2295)
  %2436 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11767.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2295)
  %2437 : __torch__.torch.nn.modules.linear.___torch_mangle_11766.Linear = prim::GetAttr[name="dense"](%2436)
  %2438 : Tensor = prim::GetAttr[name="bias"](%2437)
  %2439 : Tensor = prim::GetAttr[name="weight"](%2437)
  %2440 : Float(128:1, 512:128) = aten::t(%2439), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.177 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.227, %2440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.228 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.177, %2438, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate/__module.mobilebert.encoder.layer.11.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.229 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2444 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11769.NoNorm = prim::GetAttr[name="LayerNorm"](%2435)
  %2445 : __torch__.torch.nn.modules.linear.___torch_mangle_11768.Linear = prim::GetAttr[name="dense"](%2435)
  %2446 : Tensor = prim::GetAttr[name="bias"](%2445)
  %2447 : Tensor = prim::GetAttr[name="weight"](%2445)
  %2448 : Float(512:1, 128:512) = aten::t(%2447), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.178 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.229, %2448), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.59 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.178, %2446, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.95 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.59, %input.227, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2452 : Tensor = prim::GetAttr[name="bias"](%2444)
  %2453 : Tensor = prim::GetAttr[name="weight"](%2444)
  %2454 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.95, %2453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.230 : Float(17:1664, 13:128, 128:1) = aten::add(%2454, %2452, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.ffn.2/__module.mobilebert.encoder.layer.11.ffn.2.output/__module.mobilebert.encoder.layer.11.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2456 : __torch__.torch.nn.modules.linear.___torch_mangle_11738.Linear = prim::GetAttr[name="dense"](%2293)
  %2457 : Tensor = prim::GetAttr[name="bias"](%2456)
  %2458 : Tensor = prim::GetAttr[name="weight"](%2456)
  %2459 : Float(128:1, 512:128) = aten::t(%2458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %output.179 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.230, %2459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1676:0
  %input.231 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.179, %2457, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate/__module.mobilebert.encoder.layer.11.intermediate.dense # torch/nn/functional.py:1678:0
  %input.232 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.intermediate # torch/nn/functional.py:1119:0
  %2463 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11745.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2292)
  %2464 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11741.NoNorm = prim::GetAttr[name="LayerNorm"](%2292)
  %2465 : __torch__.torch.nn.modules.linear.___torch_mangle_11740.Linear = prim::GetAttr[name="dense"](%2292)
  %2466 : Tensor = prim::GetAttr[name="bias"](%2465)
  %2467 : Tensor = prim::GetAttr[name="weight"](%2465)
  %2468 : Float(512:1, 128:512) = aten::t(%2467), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %output.180 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.232, %2468), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1676:0
  %layer_output.12 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.180, %2466, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.96 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.12, %input.230, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output # transformers/modeling_mobilebert.py:405:0
  %2472 : Tensor = prim::GetAttr[name="bias"](%2464)
  %2473 : Tensor = prim::GetAttr[name="weight"](%2464)
  %2474 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.96, %2473), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.233 : Float(17:1664, 13:128, 128:1) = aten::add(%2474, %2472, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2476 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11743.NoNorm = prim::GetAttr[name="LayerNorm"](%2463)
  %2477 : __torch__.torch.nn.modules.linear.___torch_mangle_11742.Linear = prim::GetAttr[name="dense"](%2463)
  %2478 : Tensor = prim::GetAttr[name="bias"](%2477)
  %2479 : Tensor = prim::GetAttr[name="weight"](%2477)
  %2480 : Float(128:1, 512:128) = aten::t(%2479), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.181 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.233, %2480), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.234 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.181, %2478, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.60 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.234, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.97 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.60, %input.216, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2485 : Tensor = prim::GetAttr[name="bias"](%2476)
  %2486 : Tensor = prim::GetAttr[name="weight"](%2476)
  %2487 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.97, %2486), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.235 : Float(17:6656, 13:512, 512:1) = aten::add(%2487, %2485, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.11/__module.mobilebert.encoder.layer.11.output/__module.mobilebert.encoder.layer.11.output.bottleneck/__module.mobilebert.encoder.layer.11.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2489 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11791.MobileBertOutput = prim::GetAttr[name="output"](%100)
  %2490 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11784.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%100)
  %2491 : __torch__.torch.nn.modules.container.___torch_mangle_11817.ModuleList = prim::GetAttr[name="ffn"](%100)
  %2492 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11816.FFNLayer = prim::GetAttr[name="2"](%2491)
  %2493 : __torch__.torch.nn.modules.container.___torch_mangle_11817.ModuleList = prim::GetAttr[name="ffn"](%100)
  %2494 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11810.FFNLayer = prim::GetAttr[name="1"](%2493)
  %2495 : __torch__.torch.nn.modules.container.___torch_mangle_11817.ModuleList = prim::GetAttr[name="ffn"](%100)
  %2496 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11804.FFNLayer = prim::GetAttr[name="0"](%2495)
  %2497 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11782.MobileBertAttention = prim::GetAttr[name="attention"](%100)
  %2498 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11798.Bottleneck = prim::GetAttr[name="bottleneck"](%100)
  %2499 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11797.BottleneckLayer = prim::GetAttr[name="attention"](%2498)
  %2500 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11794.BottleneckLayer = prim::GetAttr[name="input"](%2498)
  %2501 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11793.NoNorm = prim::GetAttr[name="LayerNorm"](%2500)
  %2502 : __torch__.torch.nn.modules.linear.___torch_mangle_11792.Linear = prim::GetAttr[name="dense"](%2500)
  %2503 : Tensor = prim::GetAttr[name="bias"](%2502)
  %2504 : Tensor = prim::GetAttr[name="weight"](%2502)
  %2505 : Float(512:1, 128:512) = aten::t(%2504), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.182 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2505), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.182, %2503, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2508 : Tensor = prim::GetAttr[name="bias"](%2501)
  %2509 : Tensor = prim::GetAttr[name="weight"](%2501)
  %2510 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.98, %2509), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.13 : Float(17:1664, 13:128, 128:1) = aten::add(%2510, %2508, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.input/__module.mobilebert.encoder.layer.12.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2512 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11796.NoNorm = prim::GetAttr[name="LayerNorm"](%2499)
  %2513 : __torch__.torch.nn.modules.linear.___torch_mangle_11795.Linear = prim::GetAttr[name="dense"](%2499)
  %2514 : Tensor = prim::GetAttr[name="bias"](%2513)
  %2515 : Tensor = prim::GetAttr[name="weight"](%2513)
  %2516 : Float(512:1, 128:512) = aten::t(%2515), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.183 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2516), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.183, %2514, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2519 : Tensor = prim::GetAttr[name="bias"](%2512)
  %2520 : Tensor = prim::GetAttr[name="weight"](%2512)
  %2521 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.99, %2520), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.236 : Float(17:1664, 13:128, 128:1) = aten::add(%2521, %2519, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.bottleneck/__module.mobilebert.encoder.layer.12.bottleneck.attention/__module.mobilebert.encoder.layer.12.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2523 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.236, %residual_tensor.13)
  %2524 : Float(17:1664, 13:128, 128:1), %2525 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2523)
  %2526 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11781.MobileBertSelfOutput = prim::GetAttr[name="output"](%2497)
  %2527 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11778.MobileBertSelfAttention = prim::GetAttr[name="self"](%2497)
  %2528 : __torch__.torch.nn.modules.linear.___torch_mangle_11776.Linear = prim::GetAttr[name="value"](%2527)
  %2529 : __torch__.torch.nn.modules.linear.___torch_mangle_11775.Linear = prim::GetAttr[name="key"](%2527)
  %2530 : __torch__.torch.nn.modules.linear.___torch_mangle_11774.Linear = prim::GetAttr[name="query"](%2527)
  %2531 : Tensor = prim::GetAttr[name="bias"](%2530)
  %2532 : Tensor = prim::GetAttr[name="weight"](%2530)
  %2533 : Float(128:1, 128:128) = aten::t(%2532), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %output.184 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2524, %2533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1676:0
  %x.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.184, %2531, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.query # torch/nn/functional.py:1678:0
  %2536 : Tensor = prim::GetAttr[name="bias"](%2529)
  %2537 : Tensor = prim::GetAttr[name="weight"](%2529)
  %2538 : Float(128:1, 128:128) = aten::t(%2537), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %output.185 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2524, %2538), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1676:0
  %x.75 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.185, %2536, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.key # torch/nn/functional.py:1678:0
  %2541 : Tensor = prim::GetAttr[name="bias"](%2528)
  %2542 : Tensor = prim::GetAttr[name="weight"](%2528)
  %2543 : Float(512:1, 128:512) = aten::t(%2542), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %output.186 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.235, %2543), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1676:0
  %x.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.186, %2541, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.value # torch/nn/functional.py:1678:0
  %2546 : int = aten::size(%x.73, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2547 : int = aten::size(%x.73, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2548 : int[] = prim::ListConstruct(%2546, %2547, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.74 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.73, %2548), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2550 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %query_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.74, %2550), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2552 : int = aten::size(%x.75, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2553 : int = aten::size(%x.75, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2554 : int[] = prim::ListConstruct(%2552, %2553, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.76 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.75, %2554), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2556 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %key_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.76, %2556), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2558 : int = aten::size(%x.77, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2559 : int = aten::size(%x.77, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:243:0
  %2560 : int[] = prim::ListConstruct(%2558, %2559, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %x.78 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.77, %2560), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:244:0
  %2562 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %value_layer.13 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.78, %2562), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:245:0
  %2564 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.13, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.25 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.13, %2564), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.26 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.25, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.237 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.26, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.238 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.237, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.13 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.238, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self/__module.mobilebert.encoder.layer.12.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.25 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.13, %value_layer.13), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:280:0
  %2571 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %2572 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.25, %2571), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.26 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2572, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:281:0
  %2574 : int = aten::size(%context_layer.26, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2575 : int = aten::size(%context_layer.26, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:282:0
  %2576 : int[] = prim::ListConstruct(%2574, %2575, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self
  %input.239 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.26, %2576), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.self # transformers/modeling_mobilebert.py:283:0
  %2578 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11780.NoNorm = prim::GetAttr[name="LayerNorm"](%2526)
  %2579 : __torch__.torch.nn.modules.linear.___torch_mangle_11779.Linear = prim::GetAttr[name="dense"](%2526)
  %2580 : Tensor = prim::GetAttr[name="bias"](%2579)
  %2581 : Tensor = prim::GetAttr[name="weight"](%2579)
  %2582 : Float(128:1, 128:128) = aten::t(%2581), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %output.187 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.239, %2582), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.61 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.187, %2580, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.100 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.61, %2525, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output # transformers/modeling_mobilebert.py:301:0
  %2586 : Tensor = prim::GetAttr[name="bias"](%2578)
  %2587 : Tensor = prim::GetAttr[name="weight"](%2578)
  %2588 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.100, %2587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.240 : Float(17:1664, 13:128, 128:1) = aten::add(%2588, %2586, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.attention/__module.mobilebert.encoder.layer.12.attention.output/__module.mobilebert.encoder.layer.12.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2590 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11803.FFNOutput = prim::GetAttr[name="output"](%2496)
  %2591 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11800.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2496)
  %2592 : __torch__.torch.nn.modules.linear.___torch_mangle_11799.Linear = prim::GetAttr[name="dense"](%2591)
  %2593 : Tensor = prim::GetAttr[name="bias"](%2592)
  %2594 : Tensor = prim::GetAttr[name="weight"](%2592)
  %2595 : Float(128:1, 512:128) = aten::t(%2594), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.188 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.240, %2595), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.241 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.188, %2593, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate/__module.mobilebert.encoder.layer.12.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.242 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2599 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11802.NoNorm = prim::GetAttr[name="LayerNorm"](%2590)
  %2600 : __torch__.torch.nn.modules.linear.___torch_mangle_11801.Linear = prim::GetAttr[name="dense"](%2590)
  %2601 : Tensor = prim::GetAttr[name="bias"](%2600)
  %2602 : Tensor = prim::GetAttr[name="weight"](%2600)
  %2603 : Float(512:1, 128:512) = aten::t(%2602), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.189 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.242, %2603), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.62 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.189, %2601, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.101 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.62, %input.240, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2607 : Tensor = prim::GetAttr[name="bias"](%2599)
  %2608 : Tensor = prim::GetAttr[name="weight"](%2599)
  %2609 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.101, %2608), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.243 : Float(17:1664, 13:128, 128:1) = aten::add(%2609, %2607, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.0/__module.mobilebert.encoder.layer.12.ffn.0.output/__module.mobilebert.encoder.layer.12.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2611 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11809.FFNOutput = prim::GetAttr[name="output"](%2494)
  %2612 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11806.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2494)
  %2613 : __torch__.torch.nn.modules.linear.___torch_mangle_11805.Linear = prim::GetAttr[name="dense"](%2612)
  %2614 : Tensor = prim::GetAttr[name="bias"](%2613)
  %2615 : Tensor = prim::GetAttr[name="weight"](%2613)
  %2616 : Float(128:1, 512:128) = aten::t(%2615), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.190 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.243, %2616), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.244 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.190, %2614, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate/__module.mobilebert.encoder.layer.12.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.245 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.244), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2620 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11808.NoNorm = prim::GetAttr[name="LayerNorm"](%2611)
  %2621 : __torch__.torch.nn.modules.linear.___torch_mangle_11807.Linear = prim::GetAttr[name="dense"](%2611)
  %2622 : Tensor = prim::GetAttr[name="bias"](%2621)
  %2623 : Tensor = prim::GetAttr[name="weight"](%2621)
  %2624 : Float(512:1, 128:512) = aten::t(%2623), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.191 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.245, %2624), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.63 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.191, %2622, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.102 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.63, %input.243, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2628 : Tensor = prim::GetAttr[name="bias"](%2620)
  %2629 : Tensor = prim::GetAttr[name="weight"](%2620)
  %2630 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.102, %2629), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.246 : Float(17:1664, 13:128, 128:1) = aten::add(%2630, %2628, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.1/__module.mobilebert.encoder.layer.12.ffn.1.output/__module.mobilebert.encoder.layer.12.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2632 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11815.FFNOutput = prim::GetAttr[name="output"](%2492)
  %2633 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11812.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2492)
  %2634 : __torch__.torch.nn.modules.linear.___torch_mangle_11811.Linear = prim::GetAttr[name="dense"](%2633)
  %2635 : Tensor = prim::GetAttr[name="bias"](%2634)
  %2636 : Tensor = prim::GetAttr[name="weight"](%2634)
  %2637 : Float(128:1, 512:128) = aten::t(%2636), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.192 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.246, %2637), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.247 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.192, %2635, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate/__module.mobilebert.encoder.layer.12.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.248 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2641 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11814.NoNorm = prim::GetAttr[name="LayerNorm"](%2632)
  %2642 : __torch__.torch.nn.modules.linear.___torch_mangle_11813.Linear = prim::GetAttr[name="dense"](%2632)
  %2643 : Tensor = prim::GetAttr[name="bias"](%2642)
  %2644 : Tensor = prim::GetAttr[name="weight"](%2642)
  %2645 : Float(512:1, 128:512) = aten::t(%2644), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.193 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.248, %2645), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.64 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.193, %2643, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.103 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.64, %input.246, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2649 : Tensor = prim::GetAttr[name="bias"](%2641)
  %2650 : Tensor = prim::GetAttr[name="weight"](%2641)
  %2651 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.103, %2650), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.249 : Float(17:1664, 13:128, 128:1) = aten::add(%2651, %2649, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.ffn.2/__module.mobilebert.encoder.layer.12.ffn.2.output/__module.mobilebert.encoder.layer.12.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2653 : __torch__.torch.nn.modules.linear.___torch_mangle_11783.Linear = prim::GetAttr[name="dense"](%2490)
  %2654 : Tensor = prim::GetAttr[name="bias"](%2653)
  %2655 : Tensor = prim::GetAttr[name="weight"](%2653)
  %2656 : Float(128:1, 512:128) = aten::t(%2655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %output.194 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.249, %2656), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1676:0
  %input.250 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.194, %2654, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate/__module.mobilebert.encoder.layer.12.intermediate.dense # torch/nn/functional.py:1678:0
  %input.251 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.250), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.intermediate # torch/nn/functional.py:1119:0
  %2660 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11790.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2489)
  %2661 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11786.NoNorm = prim::GetAttr[name="LayerNorm"](%2489)
  %2662 : __torch__.torch.nn.modules.linear.___torch_mangle_11785.Linear = prim::GetAttr[name="dense"](%2489)
  %2663 : Tensor = prim::GetAttr[name="bias"](%2662)
  %2664 : Tensor = prim::GetAttr[name="weight"](%2662)
  %2665 : Float(512:1, 128:512) = aten::t(%2664), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %output.195 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.251, %2665), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1676:0
  %layer_output.13 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.195, %2663, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.104 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.13, %input.249, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output # transformers/modeling_mobilebert.py:405:0
  %2669 : Tensor = prim::GetAttr[name="bias"](%2661)
  %2670 : Tensor = prim::GetAttr[name="weight"](%2661)
  %2671 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.104, %2670), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.252 : Float(17:1664, 13:128, 128:1) = aten::add(%2671, %2669, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2673 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11788.NoNorm = prim::GetAttr[name="LayerNorm"](%2660)
  %2674 : __torch__.torch.nn.modules.linear.___torch_mangle_11787.Linear = prim::GetAttr[name="dense"](%2660)
  %2675 : Tensor = prim::GetAttr[name="bias"](%2674)
  %2676 : Tensor = prim::GetAttr[name="weight"](%2674)
  %2677 : Float(128:1, 512:128) = aten::t(%2676), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.196 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.252, %2677), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.253 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.196, %2675, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.65 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.253, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.105 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.65, %input.235, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2682 : Tensor = prim::GetAttr[name="bias"](%2673)
  %2683 : Tensor = prim::GetAttr[name="weight"](%2673)
  %2684 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.105, %2683), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.254 : Float(17:6656, 13:512, 512:1) = aten::add(%2684, %2682, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.12/__module.mobilebert.encoder.layer.12.output/__module.mobilebert.encoder.layer.12.output.bottleneck/__module.mobilebert.encoder.layer.12.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2686 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11836.MobileBertOutput = prim::GetAttr[name="output"](%98)
  %2687 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11829.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%98)
  %2688 : __torch__.torch.nn.modules.container.___torch_mangle_11862.ModuleList = prim::GetAttr[name="ffn"](%98)
  %2689 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11861.FFNLayer = prim::GetAttr[name="2"](%2688)
  %2690 : __torch__.torch.nn.modules.container.___torch_mangle_11862.ModuleList = prim::GetAttr[name="ffn"](%98)
  %2691 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11855.FFNLayer = prim::GetAttr[name="1"](%2690)
  %2692 : __torch__.torch.nn.modules.container.___torch_mangle_11862.ModuleList = prim::GetAttr[name="ffn"](%98)
  %2693 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11849.FFNLayer = prim::GetAttr[name="0"](%2692)
  %2694 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11827.MobileBertAttention = prim::GetAttr[name="attention"](%98)
  %2695 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11843.Bottleneck = prim::GetAttr[name="bottleneck"](%98)
  %2696 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11842.BottleneckLayer = prim::GetAttr[name="attention"](%2695)
  %2697 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11839.BottleneckLayer = prim::GetAttr[name="input"](%2695)
  %2698 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11838.NoNorm = prim::GetAttr[name="LayerNorm"](%2697)
  %2699 : __torch__.torch.nn.modules.linear.___torch_mangle_11837.Linear = prim::GetAttr[name="dense"](%2697)
  %2700 : Tensor = prim::GetAttr[name="bias"](%2699)
  %2701 : Tensor = prim::GetAttr[name="weight"](%2699)
  %2702 : Float(512:1, 128:512) = aten::t(%2701), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.197 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2702), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.197, %2700, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2705 : Tensor = prim::GetAttr[name="bias"](%2698)
  %2706 : Tensor = prim::GetAttr[name="weight"](%2698)
  %2707 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.106, %2706), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.14 : Float(17:1664, 13:128, 128:1) = aten::add(%2707, %2705, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.input/__module.mobilebert.encoder.layer.13.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2709 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11841.NoNorm = prim::GetAttr[name="LayerNorm"](%2696)
  %2710 : __torch__.torch.nn.modules.linear.___torch_mangle_11840.Linear = prim::GetAttr[name="dense"](%2696)
  %2711 : Tensor = prim::GetAttr[name="bias"](%2710)
  %2712 : Tensor = prim::GetAttr[name="weight"](%2710)
  %2713 : Float(512:1, 128:512) = aten::t(%2712), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.198 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2713), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.198, %2711, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2716 : Tensor = prim::GetAttr[name="bias"](%2709)
  %2717 : Tensor = prim::GetAttr[name="weight"](%2709)
  %2718 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.107, %2717), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.255 : Float(17:1664, 13:128, 128:1) = aten::add(%2718, %2716, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.bottleneck/__module.mobilebert.encoder.layer.13.bottleneck.attention/__module.mobilebert.encoder.layer.13.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2720 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.255, %residual_tensor.14)
  %2721 : Float(17:1664, 13:128, 128:1), %2722 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2720)
  %2723 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11826.MobileBertSelfOutput = prim::GetAttr[name="output"](%2694)
  %2724 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11823.MobileBertSelfAttention = prim::GetAttr[name="self"](%2694)
  %2725 : __torch__.torch.nn.modules.linear.___torch_mangle_11821.Linear = prim::GetAttr[name="value"](%2724)
  %2726 : __torch__.torch.nn.modules.linear.___torch_mangle_11820.Linear = prim::GetAttr[name="key"](%2724)
  %2727 : __torch__.torch.nn.modules.linear.___torch_mangle_11819.Linear = prim::GetAttr[name="query"](%2724)
  %2728 : Tensor = prim::GetAttr[name="bias"](%2727)
  %2729 : Tensor = prim::GetAttr[name="weight"](%2727)
  %2730 : Float(128:1, 128:128) = aten::t(%2729), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %output.199 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2721, %2730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1676:0
  %x.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.199, %2728, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.query # torch/nn/functional.py:1678:0
  %2733 : Tensor = prim::GetAttr[name="bias"](%2726)
  %2734 : Tensor = prim::GetAttr[name="weight"](%2726)
  %2735 : Float(128:1, 128:128) = aten::t(%2734), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %output.200 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2721, %2735), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1676:0
  %x.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.200, %2733, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.key # torch/nn/functional.py:1678:0
  %2738 : Tensor = prim::GetAttr[name="bias"](%2725)
  %2739 : Tensor = prim::GetAttr[name="weight"](%2725)
  %2740 : Float(512:1, 128:512) = aten::t(%2739), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %output.201 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.254, %2740), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1676:0
  %x.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.201, %2738, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.value # torch/nn/functional.py:1678:0
  %2743 : int = aten::size(%x.79, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2744 : int = aten::size(%x.79, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2745 : int[] = prim::ListConstruct(%2743, %2744, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.80 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.79, %2745), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2747 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %query_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.80, %2747), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2749 : int = aten::size(%x.81, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2750 : int = aten::size(%x.81, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2751 : int[] = prim::ListConstruct(%2749, %2750, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.82 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.81, %2751), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2753 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %key_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.82, %2753), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2755 : int = aten::size(%x.83, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2756 : int = aten::size(%x.83, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:243:0
  %2757 : int[] = prim::ListConstruct(%2755, %2756, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %x.84 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.83, %2757), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:244:0
  %2759 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %value_layer.14 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.84, %2759), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:245:0
  %2761 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.14, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.27 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.14, %2761), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.28 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.27, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.256 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.28, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.257 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.256, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.14 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.257, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self/__module.mobilebert.encoder.layer.13.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.27 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.14, %value_layer.14), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:280:0
  %2768 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %2769 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.27, %2768), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.28 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2769, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:281:0
  %2771 : int = aten::size(%context_layer.28, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2772 : int = aten::size(%context_layer.28, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:282:0
  %2773 : int[] = prim::ListConstruct(%2771, %2772, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self
  %input.258 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.28, %2773), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.self # transformers/modeling_mobilebert.py:283:0
  %2775 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11825.NoNorm = prim::GetAttr[name="LayerNorm"](%2723)
  %2776 : __torch__.torch.nn.modules.linear.___torch_mangle_11824.Linear = prim::GetAttr[name="dense"](%2723)
  %2777 : Tensor = prim::GetAttr[name="bias"](%2776)
  %2778 : Tensor = prim::GetAttr[name="weight"](%2776)
  %2779 : Float(128:1, 128:128) = aten::t(%2778), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %output.202 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.258, %2779), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.66 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.202, %2777, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.108 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.66, %2722, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output # transformers/modeling_mobilebert.py:301:0
  %2783 : Tensor = prim::GetAttr[name="bias"](%2775)
  %2784 : Tensor = prim::GetAttr[name="weight"](%2775)
  %2785 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.108, %2784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.259 : Float(17:1664, 13:128, 128:1) = aten::add(%2785, %2783, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.attention/__module.mobilebert.encoder.layer.13.attention.output/__module.mobilebert.encoder.layer.13.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2787 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11848.FFNOutput = prim::GetAttr[name="output"](%2693)
  %2788 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11845.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2693)
  %2789 : __torch__.torch.nn.modules.linear.___torch_mangle_11844.Linear = prim::GetAttr[name="dense"](%2788)
  %2790 : Tensor = prim::GetAttr[name="bias"](%2789)
  %2791 : Tensor = prim::GetAttr[name="weight"](%2789)
  %2792 : Float(128:1, 512:128) = aten::t(%2791), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.203 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.259, %2792), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.260 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.203, %2790, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate/__module.mobilebert.encoder.layer.13.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.261 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.260), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2796 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11847.NoNorm = prim::GetAttr[name="LayerNorm"](%2787)
  %2797 : __torch__.torch.nn.modules.linear.___torch_mangle_11846.Linear = prim::GetAttr[name="dense"](%2787)
  %2798 : Tensor = prim::GetAttr[name="bias"](%2797)
  %2799 : Tensor = prim::GetAttr[name="weight"](%2797)
  %2800 : Float(512:1, 128:512) = aten::t(%2799), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.204 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.261, %2800), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.67 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.204, %2798, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.109 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.67, %input.259, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %2804 : Tensor = prim::GetAttr[name="bias"](%2796)
  %2805 : Tensor = prim::GetAttr[name="weight"](%2796)
  %2806 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.109, %2805), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.262 : Float(17:1664, 13:128, 128:1) = aten::add(%2806, %2804, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.0/__module.mobilebert.encoder.layer.13.ffn.0.output/__module.mobilebert.encoder.layer.13.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2808 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11854.FFNOutput = prim::GetAttr[name="output"](%2691)
  %2809 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11851.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2691)
  %2810 : __torch__.torch.nn.modules.linear.___torch_mangle_11850.Linear = prim::GetAttr[name="dense"](%2809)
  %2811 : Tensor = prim::GetAttr[name="bias"](%2810)
  %2812 : Tensor = prim::GetAttr[name="weight"](%2810)
  %2813 : Float(128:1, 512:128) = aten::t(%2812), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.205 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.262, %2813), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.263 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.205, %2811, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate/__module.mobilebert.encoder.layer.13.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.264 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.263), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %2817 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11853.NoNorm = prim::GetAttr[name="LayerNorm"](%2808)
  %2818 : __torch__.torch.nn.modules.linear.___torch_mangle_11852.Linear = prim::GetAttr[name="dense"](%2808)
  %2819 : Tensor = prim::GetAttr[name="bias"](%2818)
  %2820 : Tensor = prim::GetAttr[name="weight"](%2818)
  %2821 : Float(512:1, 128:512) = aten::t(%2820), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.206 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.264, %2821), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.68 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.206, %2819, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.110 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.68, %input.262, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %2825 : Tensor = prim::GetAttr[name="bias"](%2817)
  %2826 : Tensor = prim::GetAttr[name="weight"](%2817)
  %2827 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.110, %2826), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.265 : Float(17:1664, 13:128, 128:1) = aten::add(%2827, %2825, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.1/__module.mobilebert.encoder.layer.13.ffn.1.output/__module.mobilebert.encoder.layer.13.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2829 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11860.FFNOutput = prim::GetAttr[name="output"](%2689)
  %2830 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11857.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2689)
  %2831 : __torch__.torch.nn.modules.linear.___torch_mangle_11856.Linear = prim::GetAttr[name="dense"](%2830)
  %2832 : Tensor = prim::GetAttr[name="bias"](%2831)
  %2833 : Tensor = prim::GetAttr[name="weight"](%2831)
  %2834 : Float(128:1, 512:128) = aten::t(%2833), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.207 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.265, %2834), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.266 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.207, %2832, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate/__module.mobilebert.encoder.layer.13.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.267 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.266), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %2838 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11859.NoNorm = prim::GetAttr[name="LayerNorm"](%2829)
  %2839 : __torch__.torch.nn.modules.linear.___torch_mangle_11858.Linear = prim::GetAttr[name="dense"](%2829)
  %2840 : Tensor = prim::GetAttr[name="bias"](%2839)
  %2841 : Tensor = prim::GetAttr[name="weight"](%2839)
  %2842 : Float(512:1, 128:512) = aten::t(%2841), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.208 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.267, %2842), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.69 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.208, %2840, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.111 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.69, %input.265, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %2846 : Tensor = prim::GetAttr[name="bias"](%2838)
  %2847 : Tensor = prim::GetAttr[name="weight"](%2838)
  %2848 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.111, %2847), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.268 : Float(17:1664, 13:128, 128:1) = aten::add(%2848, %2846, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.ffn.2/__module.mobilebert.encoder.layer.13.ffn.2.output/__module.mobilebert.encoder.layer.13.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2850 : __torch__.torch.nn.modules.linear.___torch_mangle_11828.Linear = prim::GetAttr[name="dense"](%2687)
  %2851 : Tensor = prim::GetAttr[name="bias"](%2850)
  %2852 : Tensor = prim::GetAttr[name="weight"](%2850)
  %2853 : Float(128:1, 512:128) = aten::t(%2852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %output.209 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.268, %2853), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1676:0
  %input.269 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.209, %2851, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate/__module.mobilebert.encoder.layer.13.intermediate.dense # torch/nn/functional.py:1678:0
  %input.270 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.269), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.intermediate # torch/nn/functional.py:1119:0
  %2857 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11835.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2686)
  %2858 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11831.NoNorm = prim::GetAttr[name="LayerNorm"](%2686)
  %2859 : __torch__.torch.nn.modules.linear.___torch_mangle_11830.Linear = prim::GetAttr[name="dense"](%2686)
  %2860 : Tensor = prim::GetAttr[name="bias"](%2859)
  %2861 : Tensor = prim::GetAttr[name="weight"](%2859)
  %2862 : Float(512:1, 128:512) = aten::t(%2861), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %output.210 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.270, %2862), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1676:0
  %layer_output.14 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.210, %2860, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.112 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.14, %input.268, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output # transformers/modeling_mobilebert.py:405:0
  %2866 : Tensor = prim::GetAttr[name="bias"](%2858)
  %2867 : Tensor = prim::GetAttr[name="weight"](%2858)
  %2868 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.112, %2867), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.271 : Float(17:1664, 13:128, 128:1) = aten::add(%2868, %2866, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2870 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11833.NoNorm = prim::GetAttr[name="LayerNorm"](%2857)
  %2871 : __torch__.torch.nn.modules.linear.___torch_mangle_11832.Linear = prim::GetAttr[name="dense"](%2857)
  %2872 : Tensor = prim::GetAttr[name="bias"](%2871)
  %2873 : Tensor = prim::GetAttr[name="weight"](%2871)
  %2874 : Float(128:1, 512:128) = aten::t(%2873), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.211 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.271, %2874), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.272 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.211, %2872, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.70 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.272, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.113 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.70, %input.254, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %2879 : Tensor = prim::GetAttr[name="bias"](%2870)
  %2880 : Tensor = prim::GetAttr[name="weight"](%2870)
  %2881 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.113, %2880), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.273 : Float(17:6656, 13:512, 512:1) = aten::add(%2881, %2879, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.13/__module.mobilebert.encoder.layer.13.output/__module.mobilebert.encoder.layer.13.output.bottleneck/__module.mobilebert.encoder.layer.13.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2883 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11881.MobileBertOutput = prim::GetAttr[name="output"](%96)
  %2884 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11874.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%96)
  %2885 : __torch__.torch.nn.modules.container.___torch_mangle_11907.ModuleList = prim::GetAttr[name="ffn"](%96)
  %2886 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11906.FFNLayer = prim::GetAttr[name="2"](%2885)
  %2887 : __torch__.torch.nn.modules.container.___torch_mangle_11907.ModuleList = prim::GetAttr[name="ffn"](%96)
  %2888 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11900.FFNLayer = prim::GetAttr[name="1"](%2887)
  %2889 : __torch__.torch.nn.modules.container.___torch_mangle_11907.ModuleList = prim::GetAttr[name="ffn"](%96)
  %2890 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11894.FFNLayer = prim::GetAttr[name="0"](%2889)
  %2891 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11872.MobileBertAttention = prim::GetAttr[name="attention"](%96)
  %2892 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11888.Bottleneck = prim::GetAttr[name="bottleneck"](%96)
  %2893 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11887.BottleneckLayer = prim::GetAttr[name="attention"](%2892)
  %2894 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11884.BottleneckLayer = prim::GetAttr[name="input"](%2892)
  %2895 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11883.NoNorm = prim::GetAttr[name="LayerNorm"](%2894)
  %2896 : __torch__.torch.nn.modules.linear.___torch_mangle_11882.Linear = prim::GetAttr[name="dense"](%2894)
  %2897 : Tensor = prim::GetAttr[name="bias"](%2896)
  %2898 : Tensor = prim::GetAttr[name="weight"](%2896)
  %2899 : Float(512:1, 128:512) = aten::t(%2898), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.212 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2899), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.212, %2897, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %2902 : Tensor = prim::GetAttr[name="bias"](%2895)
  %2903 : Tensor = prim::GetAttr[name="weight"](%2895)
  %2904 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.114, %2903), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.15 : Float(17:1664, 13:128, 128:1) = aten::add(%2904, %2902, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.input/__module.mobilebert.encoder.layer.14.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2906 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11886.NoNorm = prim::GetAttr[name="LayerNorm"](%2893)
  %2907 : __torch__.torch.nn.modules.linear.___torch_mangle_11885.Linear = prim::GetAttr[name="dense"](%2893)
  %2908 : Tensor = prim::GetAttr[name="bias"](%2907)
  %2909 : Tensor = prim::GetAttr[name="weight"](%2907)
  %2910 : Float(512:1, 128:512) = aten::t(%2909), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.213 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2910), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.213, %2908, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %2913 : Tensor = prim::GetAttr[name="bias"](%2906)
  %2914 : Tensor = prim::GetAttr[name="weight"](%2906)
  %2915 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.115, %2914), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.274 : Float(17:1664, 13:128, 128:1) = aten::add(%2915, %2913, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.bottleneck/__module.mobilebert.encoder.layer.14.bottleneck.attention/__module.mobilebert.encoder.layer.14.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2917 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.274, %residual_tensor.15)
  %2918 : Float(17:1664, 13:128, 128:1), %2919 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%2917)
  %2920 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11871.MobileBertSelfOutput = prim::GetAttr[name="output"](%2891)
  %2921 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11868.MobileBertSelfAttention = prim::GetAttr[name="self"](%2891)
  %2922 : __torch__.torch.nn.modules.linear.___torch_mangle_11866.Linear = prim::GetAttr[name="value"](%2921)
  %2923 : __torch__.torch.nn.modules.linear.___torch_mangle_11865.Linear = prim::GetAttr[name="key"](%2921)
  %2924 : __torch__.torch.nn.modules.linear.___torch_mangle_11864.Linear = prim::GetAttr[name="query"](%2921)
  %2925 : Tensor = prim::GetAttr[name="bias"](%2924)
  %2926 : Tensor = prim::GetAttr[name="weight"](%2924)
  %2927 : Float(128:1, 128:128) = aten::t(%2926), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %output.214 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2918, %2927), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1676:0
  %x.85 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.214, %2925, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.query # torch/nn/functional.py:1678:0
  %2930 : Tensor = prim::GetAttr[name="bias"](%2923)
  %2931 : Tensor = prim::GetAttr[name="weight"](%2923)
  %2932 : Float(128:1, 128:128) = aten::t(%2931), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %output.215 : Float(17:1664, 13:128, 128:1) = aten::matmul(%2918, %2932), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1676:0
  %x.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.215, %2930, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.key # torch/nn/functional.py:1678:0
  %2935 : Tensor = prim::GetAttr[name="bias"](%2922)
  %2936 : Tensor = prim::GetAttr[name="weight"](%2922)
  %2937 : Float(512:1, 128:512) = aten::t(%2936), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %output.216 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.273, %2937), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1676:0
  %x.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.216, %2935, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.value # torch/nn/functional.py:1678:0
  %2940 : int = aten::size(%x.85, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2941 : int = aten::size(%x.85, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2942 : int[] = prim::ListConstruct(%2940, %2941, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.86 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.85, %2942), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2944 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %query_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.86, %2944), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2946 : int = aten::size(%x.87, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2947 : int = aten::size(%x.87, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2948 : int[] = prim::ListConstruct(%2946, %2947, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.88 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.87, %2948), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2950 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %key_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.88, %2950), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2952 : int = aten::size(%x.89, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2953 : int = aten::size(%x.89, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:243:0
  %2954 : int[] = prim::ListConstruct(%2952, %2953, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %x.90 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.89, %2954), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:244:0
  %2956 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %value_layer.15 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.90, %2956), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:245:0
  %2958 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.15, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.29 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.15, %2958), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.30 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.29, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.275 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.30, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.276 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.275, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.15 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.276, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self/__module.mobilebert.encoder.layer.14.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.29 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.15, %value_layer.15), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:280:0
  %2965 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %2966 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.29, %2965), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.30 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%2966, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:281:0
  %2968 : int = aten::size(%context_layer.30, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2969 : int = aten::size(%context_layer.30, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:282:0
  %2970 : int[] = prim::ListConstruct(%2968, %2969, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self
  %input.277 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.30, %2970), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.self # transformers/modeling_mobilebert.py:283:0
  %2972 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11870.NoNorm = prim::GetAttr[name="LayerNorm"](%2920)
  %2973 : __torch__.torch.nn.modules.linear.___torch_mangle_11869.Linear = prim::GetAttr[name="dense"](%2920)
  %2974 : Tensor = prim::GetAttr[name="bias"](%2973)
  %2975 : Tensor = prim::GetAttr[name="weight"](%2973)
  %2976 : Float(128:1, 128:128) = aten::t(%2975), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %output.217 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.277, %2976), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.71 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.217, %2974, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.116 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.71, %2919, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output # transformers/modeling_mobilebert.py:301:0
  %2980 : Tensor = prim::GetAttr[name="bias"](%2972)
  %2981 : Tensor = prim::GetAttr[name="weight"](%2972)
  %2982 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.116, %2981), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.278 : Float(17:1664, 13:128, 128:1) = aten::add(%2982, %2980, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.attention/__module.mobilebert.encoder.layer.14.attention.output/__module.mobilebert.encoder.layer.14.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %2984 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11893.FFNOutput = prim::GetAttr[name="output"](%2890)
  %2985 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11890.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2890)
  %2986 : __torch__.torch.nn.modules.linear.___torch_mangle_11889.Linear = prim::GetAttr[name="dense"](%2985)
  %2987 : Tensor = prim::GetAttr[name="bias"](%2986)
  %2988 : Tensor = prim::GetAttr[name="weight"](%2986)
  %2989 : Float(128:1, 512:128) = aten::t(%2988), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.218 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.278, %2989), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.279 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.218, %2987, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate/__module.mobilebert.encoder.layer.14.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.280 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.279), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %2993 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11892.NoNorm = prim::GetAttr[name="LayerNorm"](%2984)
  %2994 : __torch__.torch.nn.modules.linear.___torch_mangle_11891.Linear = prim::GetAttr[name="dense"](%2984)
  %2995 : Tensor = prim::GetAttr[name="bias"](%2994)
  %2996 : Tensor = prim::GetAttr[name="weight"](%2994)
  %2997 : Float(512:1, 128:512) = aten::t(%2996), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.219 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.280, %2997), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.72 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.219, %2995, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.117 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.72, %input.278, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3001 : Tensor = prim::GetAttr[name="bias"](%2993)
  %3002 : Tensor = prim::GetAttr[name="weight"](%2993)
  %3003 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.117, %3002), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.281 : Float(17:1664, 13:128, 128:1) = aten::add(%3003, %3001, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.0/__module.mobilebert.encoder.layer.14.ffn.0.output/__module.mobilebert.encoder.layer.14.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3005 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11899.FFNOutput = prim::GetAttr[name="output"](%2888)
  %3006 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11896.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2888)
  %3007 : __torch__.torch.nn.modules.linear.___torch_mangle_11895.Linear = prim::GetAttr[name="dense"](%3006)
  %3008 : Tensor = prim::GetAttr[name="bias"](%3007)
  %3009 : Tensor = prim::GetAttr[name="weight"](%3007)
  %3010 : Float(128:1, 512:128) = aten::t(%3009), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.220 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.281, %3010), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.282 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.220, %3008, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate/__module.mobilebert.encoder.layer.14.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.283 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3014 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11898.NoNorm = prim::GetAttr[name="LayerNorm"](%3005)
  %3015 : __torch__.torch.nn.modules.linear.___torch_mangle_11897.Linear = prim::GetAttr[name="dense"](%3005)
  %3016 : Tensor = prim::GetAttr[name="bias"](%3015)
  %3017 : Tensor = prim::GetAttr[name="weight"](%3015)
  %3018 : Float(512:1, 128:512) = aten::t(%3017), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.221 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.283, %3018), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.73 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.221, %3016, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.118 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.73, %input.281, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3022 : Tensor = prim::GetAttr[name="bias"](%3014)
  %3023 : Tensor = prim::GetAttr[name="weight"](%3014)
  %3024 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.118, %3023), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.284 : Float(17:1664, 13:128, 128:1) = aten::add(%3024, %3022, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.1/__module.mobilebert.encoder.layer.14.ffn.1.output/__module.mobilebert.encoder.layer.14.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3026 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11905.FFNOutput = prim::GetAttr[name="output"](%2886)
  %3027 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11902.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%2886)
  %3028 : __torch__.torch.nn.modules.linear.___torch_mangle_11901.Linear = prim::GetAttr[name="dense"](%3027)
  %3029 : Tensor = prim::GetAttr[name="bias"](%3028)
  %3030 : Tensor = prim::GetAttr[name="weight"](%3028)
  %3031 : Float(128:1, 512:128) = aten::t(%3030), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.222 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.284, %3031), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.285 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.222, %3029, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate/__module.mobilebert.encoder.layer.14.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.286 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.285), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3035 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11904.NoNorm = prim::GetAttr[name="LayerNorm"](%3026)
  %3036 : __torch__.torch.nn.modules.linear.___torch_mangle_11903.Linear = prim::GetAttr[name="dense"](%3026)
  %3037 : Tensor = prim::GetAttr[name="bias"](%3036)
  %3038 : Tensor = prim::GetAttr[name="weight"](%3036)
  %3039 : Float(512:1, 128:512) = aten::t(%3038), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.223 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.286, %3039), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.74 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.223, %3037, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.119 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.74, %input.284, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3043 : Tensor = prim::GetAttr[name="bias"](%3035)
  %3044 : Tensor = prim::GetAttr[name="weight"](%3035)
  %3045 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.119, %3044), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.287 : Float(17:1664, 13:128, 128:1) = aten::add(%3045, %3043, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.ffn.2/__module.mobilebert.encoder.layer.14.ffn.2.output/__module.mobilebert.encoder.layer.14.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3047 : __torch__.torch.nn.modules.linear.___torch_mangle_11873.Linear = prim::GetAttr[name="dense"](%2884)
  %3048 : Tensor = prim::GetAttr[name="bias"](%3047)
  %3049 : Tensor = prim::GetAttr[name="weight"](%3047)
  %3050 : Float(128:1, 512:128) = aten::t(%3049), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %output.224 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.287, %3050), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1676:0
  %input.288 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.224, %3048, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate/__module.mobilebert.encoder.layer.14.intermediate.dense # torch/nn/functional.py:1678:0
  %input.289 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.intermediate # torch/nn/functional.py:1119:0
  %3054 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11880.OutputBottleneck = prim::GetAttr[name="bottleneck"](%2883)
  %3055 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11876.NoNorm = prim::GetAttr[name="LayerNorm"](%2883)
  %3056 : __torch__.torch.nn.modules.linear.___torch_mangle_11875.Linear = prim::GetAttr[name="dense"](%2883)
  %3057 : Tensor = prim::GetAttr[name="bias"](%3056)
  %3058 : Tensor = prim::GetAttr[name="weight"](%3056)
  %3059 : Float(512:1, 128:512) = aten::t(%3058), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %output.225 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.289, %3059), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1676:0
  %layer_output.15 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.225, %3057, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.120 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.15, %input.287, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output # transformers/modeling_mobilebert.py:405:0
  %3063 : Tensor = prim::GetAttr[name="bias"](%3055)
  %3064 : Tensor = prim::GetAttr[name="weight"](%3055)
  %3065 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.120, %3064), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.290 : Float(17:1664, 13:128, 128:1) = aten::add(%3065, %3063, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3067 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11878.NoNorm = prim::GetAttr[name="LayerNorm"](%3054)
  %3068 : __torch__.torch.nn.modules.linear.___torch_mangle_11877.Linear = prim::GetAttr[name="dense"](%3054)
  %3069 : Tensor = prim::GetAttr[name="bias"](%3068)
  %3070 : Tensor = prim::GetAttr[name="weight"](%3068)
  %3071 : Float(128:1, 512:128) = aten::t(%3070), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.226 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.290, %3071), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.291 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.226, %3069, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.75 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.291, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.121 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.75, %input.273, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3076 : Tensor = prim::GetAttr[name="bias"](%3067)
  %3077 : Tensor = prim::GetAttr[name="weight"](%3067)
  %3078 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.121, %3077), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.292 : Float(17:6656, 13:512, 512:1) = aten::add(%3078, %3076, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.14/__module.mobilebert.encoder.layer.14.output/__module.mobilebert.encoder.layer.14.output.bottleneck/__module.mobilebert.encoder.layer.14.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3080 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11926.MobileBertOutput = prim::GetAttr[name="output"](%94)
  %3081 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11919.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%94)
  %3082 : __torch__.torch.nn.modules.container.___torch_mangle_11952.ModuleList = prim::GetAttr[name="ffn"](%94)
  %3083 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11951.FFNLayer = prim::GetAttr[name="2"](%3082)
  %3084 : __torch__.torch.nn.modules.container.___torch_mangle_11952.ModuleList = prim::GetAttr[name="ffn"](%94)
  %3085 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11945.FFNLayer = prim::GetAttr[name="1"](%3084)
  %3086 : __torch__.torch.nn.modules.container.___torch_mangle_11952.ModuleList = prim::GetAttr[name="ffn"](%94)
  %3087 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11939.FFNLayer = prim::GetAttr[name="0"](%3086)
  %3088 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11917.MobileBertAttention = prim::GetAttr[name="attention"](%94)
  %3089 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11933.Bottleneck = prim::GetAttr[name="bottleneck"](%94)
  %3090 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11932.BottleneckLayer = prim::GetAttr[name="attention"](%3089)
  %3091 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11929.BottleneckLayer = prim::GetAttr[name="input"](%3089)
  %3092 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11928.NoNorm = prim::GetAttr[name="LayerNorm"](%3091)
  %3093 : __torch__.torch.nn.modules.linear.___torch_mangle_11927.Linear = prim::GetAttr[name="dense"](%3091)
  %3094 : Tensor = prim::GetAttr[name="bias"](%3093)
  %3095 : Tensor = prim::GetAttr[name="weight"](%3093)
  %3096 : Float(512:1, 128:512) = aten::t(%3095), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.227 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3096), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.122 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.227, %3094, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3099 : Tensor = prim::GetAttr[name="bias"](%3092)
  %3100 : Tensor = prim::GetAttr[name="weight"](%3092)
  %3101 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.122, %3100), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.16 : Float(17:1664, 13:128, 128:1) = aten::add(%3101, %3099, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.input/__module.mobilebert.encoder.layer.15.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11931.NoNorm = prim::GetAttr[name="LayerNorm"](%3090)
  %3104 : __torch__.torch.nn.modules.linear.___torch_mangle_11930.Linear = prim::GetAttr[name="dense"](%3090)
  %3105 : Tensor = prim::GetAttr[name="bias"](%3104)
  %3106 : Tensor = prim::GetAttr[name="weight"](%3104)
  %3107 : Float(512:1, 128:512) = aten::t(%3106), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.228 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3107), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.228, %3105, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3110 : Tensor = prim::GetAttr[name="bias"](%3103)
  %3111 : Tensor = prim::GetAttr[name="weight"](%3103)
  %3112 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.123, %3111), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.293 : Float(17:1664, 13:128, 128:1) = aten::add(%3112, %3110, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.bottleneck/__module.mobilebert.encoder.layer.15.bottleneck.attention/__module.mobilebert.encoder.layer.15.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3114 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.293, %residual_tensor.16)
  %3115 : Float(17:1664, 13:128, 128:1), %3116 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3114)
  %3117 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11916.MobileBertSelfOutput = prim::GetAttr[name="output"](%3088)
  %3118 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11913.MobileBertSelfAttention = prim::GetAttr[name="self"](%3088)
  %3119 : __torch__.torch.nn.modules.linear.___torch_mangle_11911.Linear = prim::GetAttr[name="value"](%3118)
  %3120 : __torch__.torch.nn.modules.linear.___torch_mangle_11910.Linear = prim::GetAttr[name="key"](%3118)
  %3121 : __torch__.torch.nn.modules.linear.___torch_mangle_11909.Linear = prim::GetAttr[name="query"](%3118)
  %3122 : Tensor = prim::GetAttr[name="bias"](%3121)
  %3123 : Tensor = prim::GetAttr[name="weight"](%3121)
  %3124 : Float(128:1, 128:128) = aten::t(%3123), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %output.229 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3115, %3124), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1676:0
  %x.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.229, %3122, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.query # torch/nn/functional.py:1678:0
  %3127 : Tensor = prim::GetAttr[name="bias"](%3120)
  %3128 : Tensor = prim::GetAttr[name="weight"](%3120)
  %3129 : Float(128:1, 128:128) = aten::t(%3128), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %output.230 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3115, %3129), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1676:0
  %x.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.230, %3127, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.key # torch/nn/functional.py:1678:0
  %3132 : Tensor = prim::GetAttr[name="bias"](%3119)
  %3133 : Tensor = prim::GetAttr[name="weight"](%3119)
  %3134 : Float(512:1, 128:512) = aten::t(%3133), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %output.231 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.292, %3134), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1676:0
  %x.95 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.231, %3132, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.value # torch/nn/functional.py:1678:0
  %3137 : int = aten::size(%x.91, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3138 : int = aten::size(%x.91, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3139 : int[] = prim::ListConstruct(%3137, %3138, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.92 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.91, %3139), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3141 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %query_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.92, %3141), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3143 : int = aten::size(%x.93, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3144 : int = aten::size(%x.93, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3145 : int[] = prim::ListConstruct(%3143, %3144, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.94 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.93, %3145), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3147 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %key_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.94, %3147), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3149 : int = aten::size(%x.95, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3150 : int = aten::size(%x.95, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:243:0
  %3151 : int[] = prim::ListConstruct(%3149, %3150, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %x.96 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.95, %3151), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:244:0
  %3153 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %value_layer.16 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.96, %3153), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:245:0
  %3155 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.16, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.31 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.16, %3155), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.32 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.31, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.294 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.32, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.295 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.294, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.16 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.295, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self/__module.mobilebert.encoder.layer.15.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.31 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.16, %value_layer.16), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:280:0
  %3162 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %3163 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.31, %3162), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.32 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3163, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:281:0
  %3165 : int = aten::size(%context_layer.32, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3166 : int = aten::size(%context_layer.32, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:282:0
  %3167 : int[] = prim::ListConstruct(%3165, %3166, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self
  %input.296 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.32, %3167), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.self # transformers/modeling_mobilebert.py:283:0
  %3169 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11915.NoNorm = prim::GetAttr[name="LayerNorm"](%3117)
  %3170 : __torch__.torch.nn.modules.linear.___torch_mangle_11914.Linear = prim::GetAttr[name="dense"](%3117)
  %3171 : Tensor = prim::GetAttr[name="bias"](%3170)
  %3172 : Tensor = prim::GetAttr[name="weight"](%3170)
  %3173 : Float(128:1, 128:128) = aten::t(%3172), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %output.232 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.296, %3173), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.76 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.232, %3171, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.124 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.76, %3116, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output # transformers/modeling_mobilebert.py:301:0
  %3177 : Tensor = prim::GetAttr[name="bias"](%3169)
  %3178 : Tensor = prim::GetAttr[name="weight"](%3169)
  %3179 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.124, %3178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.297 : Float(17:1664, 13:128, 128:1) = aten::add(%3179, %3177, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.attention/__module.mobilebert.encoder.layer.15.attention.output/__module.mobilebert.encoder.layer.15.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3181 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11938.FFNOutput = prim::GetAttr[name="output"](%3087)
  %3182 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11935.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3087)
  %3183 : __torch__.torch.nn.modules.linear.___torch_mangle_11934.Linear = prim::GetAttr[name="dense"](%3182)
  %3184 : Tensor = prim::GetAttr[name="bias"](%3183)
  %3185 : Tensor = prim::GetAttr[name="weight"](%3183)
  %3186 : Float(128:1, 512:128) = aten::t(%3185), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.233 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.297, %3186), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.298 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.233, %3184, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate/__module.mobilebert.encoder.layer.15.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.299 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.298), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3190 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11937.NoNorm = prim::GetAttr[name="LayerNorm"](%3181)
  %3191 : __torch__.torch.nn.modules.linear.___torch_mangle_11936.Linear = prim::GetAttr[name="dense"](%3181)
  %3192 : Tensor = prim::GetAttr[name="bias"](%3191)
  %3193 : Tensor = prim::GetAttr[name="weight"](%3191)
  %3194 : Float(512:1, 128:512) = aten::t(%3193), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.234 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.299, %3194), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.77 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.234, %3192, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.125 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.77, %input.297, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3198 : Tensor = prim::GetAttr[name="bias"](%3190)
  %3199 : Tensor = prim::GetAttr[name="weight"](%3190)
  %3200 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.125, %3199), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.300 : Float(17:1664, 13:128, 128:1) = aten::add(%3200, %3198, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.0/__module.mobilebert.encoder.layer.15.ffn.0.output/__module.mobilebert.encoder.layer.15.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3202 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11944.FFNOutput = prim::GetAttr[name="output"](%3085)
  %3203 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11941.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3085)
  %3204 : __torch__.torch.nn.modules.linear.___torch_mangle_11940.Linear = prim::GetAttr[name="dense"](%3203)
  %3205 : Tensor = prim::GetAttr[name="bias"](%3204)
  %3206 : Tensor = prim::GetAttr[name="weight"](%3204)
  %3207 : Float(128:1, 512:128) = aten::t(%3206), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.235 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.300, %3207), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.301 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.235, %3205, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate/__module.mobilebert.encoder.layer.15.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.302 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.301), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3211 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11943.NoNorm = prim::GetAttr[name="LayerNorm"](%3202)
  %3212 : __torch__.torch.nn.modules.linear.___torch_mangle_11942.Linear = prim::GetAttr[name="dense"](%3202)
  %3213 : Tensor = prim::GetAttr[name="bias"](%3212)
  %3214 : Tensor = prim::GetAttr[name="weight"](%3212)
  %3215 : Float(512:1, 128:512) = aten::t(%3214), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.236 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.302, %3215), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.78 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.236, %3213, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.126 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.78, %input.300, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3219 : Tensor = prim::GetAttr[name="bias"](%3211)
  %3220 : Tensor = prim::GetAttr[name="weight"](%3211)
  %3221 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.126, %3220), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.303 : Float(17:1664, 13:128, 128:1) = aten::add(%3221, %3219, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.1/__module.mobilebert.encoder.layer.15.ffn.1.output/__module.mobilebert.encoder.layer.15.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3223 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11950.FFNOutput = prim::GetAttr[name="output"](%3083)
  %3224 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11947.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3083)
  %3225 : __torch__.torch.nn.modules.linear.___torch_mangle_11946.Linear = prim::GetAttr[name="dense"](%3224)
  %3226 : Tensor = prim::GetAttr[name="bias"](%3225)
  %3227 : Tensor = prim::GetAttr[name="weight"](%3225)
  %3228 : Float(128:1, 512:128) = aten::t(%3227), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.237 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.303, %3228), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.304 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.237, %3226, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate/__module.mobilebert.encoder.layer.15.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.305 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3232 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11949.NoNorm = prim::GetAttr[name="LayerNorm"](%3223)
  %3233 : __torch__.torch.nn.modules.linear.___torch_mangle_11948.Linear = prim::GetAttr[name="dense"](%3223)
  %3234 : Tensor = prim::GetAttr[name="bias"](%3233)
  %3235 : Tensor = prim::GetAttr[name="weight"](%3233)
  %3236 : Float(512:1, 128:512) = aten::t(%3235), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.238 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.305, %3236), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.79 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.238, %3234, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.127 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.79, %input.303, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3240 : Tensor = prim::GetAttr[name="bias"](%3232)
  %3241 : Tensor = prim::GetAttr[name="weight"](%3232)
  %3242 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.127, %3241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.306 : Float(17:1664, 13:128, 128:1) = aten::add(%3242, %3240, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.ffn.2/__module.mobilebert.encoder.layer.15.ffn.2.output/__module.mobilebert.encoder.layer.15.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3244 : __torch__.torch.nn.modules.linear.___torch_mangle_11918.Linear = prim::GetAttr[name="dense"](%3081)
  %3245 : Tensor = prim::GetAttr[name="bias"](%3244)
  %3246 : Tensor = prim::GetAttr[name="weight"](%3244)
  %3247 : Float(128:1, 512:128) = aten::t(%3246), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %output.239 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.306, %3247), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1676:0
  %input.307 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.239, %3245, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate/__module.mobilebert.encoder.layer.15.intermediate.dense # torch/nn/functional.py:1678:0
  %input.308 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.307), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.intermediate # torch/nn/functional.py:1119:0
  %3251 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11925.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3080)
  %3252 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11921.NoNorm = prim::GetAttr[name="LayerNorm"](%3080)
  %3253 : __torch__.torch.nn.modules.linear.___torch_mangle_11920.Linear = prim::GetAttr[name="dense"](%3080)
  %3254 : Tensor = prim::GetAttr[name="bias"](%3253)
  %3255 : Tensor = prim::GetAttr[name="weight"](%3253)
  %3256 : Float(512:1, 128:512) = aten::t(%3255), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %output.240 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.308, %3256), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1676:0
  %layer_output.16 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.240, %3254, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.128 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.16, %input.306, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output # transformers/modeling_mobilebert.py:405:0
  %3260 : Tensor = prim::GetAttr[name="bias"](%3252)
  %3261 : Tensor = prim::GetAttr[name="weight"](%3252)
  %3262 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.128, %3261), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.309 : Float(17:1664, 13:128, 128:1) = aten::add(%3262, %3260, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3264 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11923.NoNorm = prim::GetAttr[name="LayerNorm"](%3251)
  %3265 : __torch__.torch.nn.modules.linear.___torch_mangle_11922.Linear = prim::GetAttr[name="dense"](%3251)
  %3266 : Tensor = prim::GetAttr[name="bias"](%3265)
  %3267 : Tensor = prim::GetAttr[name="weight"](%3265)
  %3268 : Float(128:1, 512:128) = aten::t(%3267), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.241 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.309, %3268), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.310 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.241, %3266, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.80 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.310, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.129 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.80, %input.292, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3273 : Tensor = prim::GetAttr[name="bias"](%3264)
  %3274 : Tensor = prim::GetAttr[name="weight"](%3264)
  %3275 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.129, %3274), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.311 : Float(17:6656, 13:512, 512:1) = aten::add(%3275, %3273, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.15/__module.mobilebert.encoder.layer.15.output/__module.mobilebert.encoder.layer.15.output.bottleneck/__module.mobilebert.encoder.layer.15.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3277 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11971.MobileBertOutput = prim::GetAttr[name="output"](%92)
  %3278 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11964.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%92)
  %3279 : __torch__.torch.nn.modules.container.___torch_mangle_11997.ModuleList = prim::GetAttr[name="ffn"](%92)
  %3280 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11996.FFNLayer = prim::GetAttr[name="2"](%3279)
  %3281 : __torch__.torch.nn.modules.container.___torch_mangle_11997.ModuleList = prim::GetAttr[name="ffn"](%92)
  %3282 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11990.FFNLayer = prim::GetAttr[name="1"](%3281)
  %3283 : __torch__.torch.nn.modules.container.___torch_mangle_11997.ModuleList = prim::GetAttr[name="ffn"](%92)
  %3284 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11984.FFNLayer = prim::GetAttr[name="0"](%3283)
  %3285 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11962.MobileBertAttention = prim::GetAttr[name="attention"](%92)
  %3286 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11978.Bottleneck = prim::GetAttr[name="bottleneck"](%92)
  %3287 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11977.BottleneckLayer = prim::GetAttr[name="attention"](%3286)
  %3288 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11974.BottleneckLayer = prim::GetAttr[name="input"](%3286)
  %3289 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11973.NoNorm = prim::GetAttr[name="LayerNorm"](%3288)
  %3290 : __torch__.torch.nn.modules.linear.___torch_mangle_11972.Linear = prim::GetAttr[name="dense"](%3288)
  %3291 : Tensor = prim::GetAttr[name="bias"](%3290)
  %3292 : Tensor = prim::GetAttr[name="weight"](%3290)
  %3293 : Float(512:1, 128:512) = aten::t(%3292), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.242 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3293), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.130 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.242, %3291, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3296 : Tensor = prim::GetAttr[name="bias"](%3289)
  %3297 : Tensor = prim::GetAttr[name="weight"](%3289)
  %3298 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.130, %3297), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.17 : Float(17:1664, 13:128, 128:1) = aten::add(%3298, %3296, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.input/__module.mobilebert.encoder.layer.16.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3300 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11976.NoNorm = prim::GetAttr[name="LayerNorm"](%3287)
  %3301 : __torch__.torch.nn.modules.linear.___torch_mangle_11975.Linear = prim::GetAttr[name="dense"](%3287)
  %3302 : Tensor = prim::GetAttr[name="bias"](%3301)
  %3303 : Tensor = prim::GetAttr[name="weight"](%3301)
  %3304 : Float(512:1, 128:512) = aten::t(%3303), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.243 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3304), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.243, %3302, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3307 : Tensor = prim::GetAttr[name="bias"](%3300)
  %3308 : Tensor = prim::GetAttr[name="weight"](%3300)
  %3309 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.131, %3308), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.312 : Float(17:1664, 13:128, 128:1) = aten::add(%3309, %3307, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.bottleneck/__module.mobilebert.encoder.layer.16.bottleneck.attention/__module.mobilebert.encoder.layer.16.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3311 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.312, %residual_tensor.17)
  %3312 : Float(17:1664, 13:128, 128:1), %3313 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3311)
  %3314 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11961.MobileBertSelfOutput = prim::GetAttr[name="output"](%3285)
  %3315 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11958.MobileBertSelfAttention = prim::GetAttr[name="self"](%3285)
  %3316 : __torch__.torch.nn.modules.linear.___torch_mangle_11956.Linear = prim::GetAttr[name="value"](%3315)
  %3317 : __torch__.torch.nn.modules.linear.___torch_mangle_11955.Linear = prim::GetAttr[name="key"](%3315)
  %3318 : __torch__.torch.nn.modules.linear.___torch_mangle_11954.Linear = prim::GetAttr[name="query"](%3315)
  %3319 : Tensor = prim::GetAttr[name="bias"](%3318)
  %3320 : Tensor = prim::GetAttr[name="weight"](%3318)
  %3321 : Float(128:1, 128:128) = aten::t(%3320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %output.244 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3312, %3321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1676:0
  %x.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.244, %3319, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.query # torch/nn/functional.py:1678:0
  %3324 : Tensor = prim::GetAttr[name="bias"](%3317)
  %3325 : Tensor = prim::GetAttr[name="weight"](%3317)
  %3326 : Float(128:1, 128:128) = aten::t(%3325), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %output.245 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3312, %3326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1676:0
  %x.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.245, %3324, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.key # torch/nn/functional.py:1678:0
  %3329 : Tensor = prim::GetAttr[name="bias"](%3316)
  %3330 : Tensor = prim::GetAttr[name="weight"](%3316)
  %3331 : Float(512:1, 128:512) = aten::t(%3330), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %output.246 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.311, %3331), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1676:0
  %x.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.246, %3329, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.value # torch/nn/functional.py:1678:0
  %3334 : int = aten::size(%x.97, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3335 : int = aten::size(%x.97, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3336 : int[] = prim::ListConstruct(%3334, %3335, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.98 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.97, %3336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3338 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %query_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.98, %3338), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3340 : int = aten::size(%x.99, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3341 : int = aten::size(%x.99, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3342 : int[] = prim::ListConstruct(%3340, %3341, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.100 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.99, %3342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3344 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %key_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.100, %3344), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3346 : int = aten::size(%x.101, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3347 : int = aten::size(%x.101, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:243:0
  %3348 : int[] = prim::ListConstruct(%3346, %3347, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %x.102 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.101, %3348), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:244:0
  %3350 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %value_layer.17 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.102, %3350), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:245:0
  %3352 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.17, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.33 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.17, %3352), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.34 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.33, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.313 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.34, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.314 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.313, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.17 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.314, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self/__module.mobilebert.encoder.layer.16.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.33 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.17, %value_layer.17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:280:0
  %3359 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %3360 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.33, %3359), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.34 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3360, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:281:0
  %3362 : int = aten::size(%context_layer.34, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3363 : int = aten::size(%context_layer.34, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:282:0
  %3364 : int[] = prim::ListConstruct(%3362, %3363, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self
  %input.315 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.34, %3364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.self # transformers/modeling_mobilebert.py:283:0
  %3366 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11960.NoNorm = prim::GetAttr[name="LayerNorm"](%3314)
  %3367 : __torch__.torch.nn.modules.linear.___torch_mangle_11959.Linear = prim::GetAttr[name="dense"](%3314)
  %3368 : Tensor = prim::GetAttr[name="bias"](%3367)
  %3369 : Tensor = prim::GetAttr[name="weight"](%3367)
  %3370 : Float(128:1, 128:128) = aten::t(%3369), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %output.247 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.315, %3370), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.81 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.247, %3368, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.132 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.81, %3313, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output # transformers/modeling_mobilebert.py:301:0
  %3374 : Tensor = prim::GetAttr[name="bias"](%3366)
  %3375 : Tensor = prim::GetAttr[name="weight"](%3366)
  %3376 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.132, %3375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.316 : Float(17:1664, 13:128, 128:1) = aten::add(%3376, %3374, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.attention/__module.mobilebert.encoder.layer.16.attention.output/__module.mobilebert.encoder.layer.16.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3378 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11983.FFNOutput = prim::GetAttr[name="output"](%3284)
  %3379 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11980.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3284)
  %3380 : __torch__.torch.nn.modules.linear.___torch_mangle_11979.Linear = prim::GetAttr[name="dense"](%3379)
  %3381 : Tensor = prim::GetAttr[name="bias"](%3380)
  %3382 : Tensor = prim::GetAttr[name="weight"](%3380)
  %3383 : Float(128:1, 512:128) = aten::t(%3382), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.248 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.316, %3383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.317 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.248, %3381, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate/__module.mobilebert.encoder.layer.16.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.318 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.317), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3387 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11982.NoNorm = prim::GetAttr[name="LayerNorm"](%3378)
  %3388 : __torch__.torch.nn.modules.linear.___torch_mangle_11981.Linear = prim::GetAttr[name="dense"](%3378)
  %3389 : Tensor = prim::GetAttr[name="bias"](%3388)
  %3390 : Tensor = prim::GetAttr[name="weight"](%3388)
  %3391 : Float(512:1, 128:512) = aten::t(%3390), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.249 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.318, %3391), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.82 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.249, %3389, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.133 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.82, %input.316, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3395 : Tensor = prim::GetAttr[name="bias"](%3387)
  %3396 : Tensor = prim::GetAttr[name="weight"](%3387)
  %3397 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.133, %3396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.319 : Float(17:1664, 13:128, 128:1) = aten::add(%3397, %3395, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.0/__module.mobilebert.encoder.layer.16.ffn.0.output/__module.mobilebert.encoder.layer.16.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3399 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11989.FFNOutput = prim::GetAttr[name="output"](%3282)
  %3400 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11986.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3282)
  %3401 : __torch__.torch.nn.modules.linear.___torch_mangle_11985.Linear = prim::GetAttr[name="dense"](%3400)
  %3402 : Tensor = prim::GetAttr[name="bias"](%3401)
  %3403 : Tensor = prim::GetAttr[name="weight"](%3401)
  %3404 : Float(128:1, 512:128) = aten::t(%3403), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.250 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.319, %3404), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.320 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.250, %3402, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate/__module.mobilebert.encoder.layer.16.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.321 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.320), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3408 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11988.NoNorm = prim::GetAttr[name="LayerNorm"](%3399)
  %3409 : __torch__.torch.nn.modules.linear.___torch_mangle_11987.Linear = prim::GetAttr[name="dense"](%3399)
  %3410 : Tensor = prim::GetAttr[name="bias"](%3409)
  %3411 : Tensor = prim::GetAttr[name="weight"](%3409)
  %3412 : Float(512:1, 128:512) = aten::t(%3411), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.251 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.321, %3412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.83 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.251, %3410, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.134 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.83, %input.319, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3416 : Tensor = prim::GetAttr[name="bias"](%3408)
  %3417 : Tensor = prim::GetAttr[name="weight"](%3408)
  %3418 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.134, %3417), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.322 : Float(17:1664, 13:128, 128:1) = aten::add(%3418, %3416, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.1/__module.mobilebert.encoder.layer.16.ffn.1.output/__module.mobilebert.encoder.layer.16.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3420 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11995.FFNOutput = prim::GetAttr[name="output"](%3280)
  %3421 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11992.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3280)
  %3422 : __torch__.torch.nn.modules.linear.___torch_mangle_11991.Linear = prim::GetAttr[name="dense"](%3421)
  %3423 : Tensor = prim::GetAttr[name="bias"](%3422)
  %3424 : Tensor = prim::GetAttr[name="weight"](%3422)
  %3425 : Float(128:1, 512:128) = aten::t(%3424), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.252 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.322, %3425), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.323 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.252, %3423, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate/__module.mobilebert.encoder.layer.16.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.324 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3429 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11994.NoNorm = prim::GetAttr[name="LayerNorm"](%3420)
  %3430 : __torch__.torch.nn.modules.linear.___torch_mangle_11993.Linear = prim::GetAttr[name="dense"](%3420)
  %3431 : Tensor = prim::GetAttr[name="bias"](%3430)
  %3432 : Tensor = prim::GetAttr[name="weight"](%3430)
  %3433 : Float(512:1, 128:512) = aten::t(%3432), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.253 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.324, %3433), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.84 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.253, %3431, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.135 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.84, %input.322, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3437 : Tensor = prim::GetAttr[name="bias"](%3429)
  %3438 : Tensor = prim::GetAttr[name="weight"](%3429)
  %3439 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.135, %3438), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.325 : Float(17:1664, 13:128, 128:1) = aten::add(%3439, %3437, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.ffn.2/__module.mobilebert.encoder.layer.16.ffn.2.output/__module.mobilebert.encoder.layer.16.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3441 : __torch__.torch.nn.modules.linear.___torch_mangle_11963.Linear = prim::GetAttr[name="dense"](%3278)
  %3442 : Tensor = prim::GetAttr[name="bias"](%3441)
  %3443 : Tensor = prim::GetAttr[name="weight"](%3441)
  %3444 : Float(128:1, 512:128) = aten::t(%3443), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %output.254 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.325, %3444), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1676:0
  %input.326 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.254, %3442, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate/__module.mobilebert.encoder.layer.16.intermediate.dense # torch/nn/functional.py:1678:0
  %input.327 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.326), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.intermediate # torch/nn/functional.py:1119:0
  %3448 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11970.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3277)
  %3449 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11966.NoNorm = prim::GetAttr[name="LayerNorm"](%3277)
  %3450 : __torch__.torch.nn.modules.linear.___torch_mangle_11965.Linear = prim::GetAttr[name="dense"](%3277)
  %3451 : Tensor = prim::GetAttr[name="bias"](%3450)
  %3452 : Tensor = prim::GetAttr[name="weight"](%3450)
  %3453 : Float(512:1, 128:512) = aten::t(%3452), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %output.255 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.327, %3453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1676:0
  %layer_output.17 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.255, %3451, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.136 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.17, %input.325, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output # transformers/modeling_mobilebert.py:405:0
  %3457 : Tensor = prim::GetAttr[name="bias"](%3449)
  %3458 : Tensor = prim::GetAttr[name="weight"](%3449)
  %3459 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.136, %3458), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.328 : Float(17:1664, 13:128, 128:1) = aten::add(%3459, %3457, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3461 : __torch__.transformers.modeling_mobilebert.___torch_mangle_11968.NoNorm = prim::GetAttr[name="LayerNorm"](%3448)
  %3462 : __torch__.torch.nn.modules.linear.___torch_mangle_11967.Linear = prim::GetAttr[name="dense"](%3448)
  %3463 : Tensor = prim::GetAttr[name="bias"](%3462)
  %3464 : Tensor = prim::GetAttr[name="weight"](%3462)
  %3465 : Float(128:1, 512:128) = aten::t(%3464), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.256 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.328, %3465), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.329 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.256, %3463, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.85 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.329, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.137 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.85, %input.311, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3470 : Tensor = prim::GetAttr[name="bias"](%3461)
  %3471 : Tensor = prim::GetAttr[name="weight"](%3461)
  %3472 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.137, %3471), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.330 : Float(17:6656, 13:512, 512:1) = aten::add(%3472, %3470, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.16/__module.mobilebert.encoder.layer.16.output/__module.mobilebert.encoder.layer.16.output.bottleneck/__module.mobilebert.encoder.layer.16.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3474 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12016.MobileBertOutput = prim::GetAttr[name="output"](%90)
  %3475 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12009.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%90)
  %3476 : __torch__.torch.nn.modules.container.___torch_mangle_12042.ModuleList = prim::GetAttr[name="ffn"](%90)
  %3477 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12041.FFNLayer = prim::GetAttr[name="2"](%3476)
  %3478 : __torch__.torch.nn.modules.container.___torch_mangle_12042.ModuleList = prim::GetAttr[name="ffn"](%90)
  %3479 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12035.FFNLayer = prim::GetAttr[name="1"](%3478)
  %3480 : __torch__.torch.nn.modules.container.___torch_mangle_12042.ModuleList = prim::GetAttr[name="ffn"](%90)
  %3481 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12029.FFNLayer = prim::GetAttr[name="0"](%3480)
  %3482 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12007.MobileBertAttention = prim::GetAttr[name="attention"](%90)
  %3483 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12023.Bottleneck = prim::GetAttr[name="bottleneck"](%90)
  %3484 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12022.BottleneckLayer = prim::GetAttr[name="attention"](%3483)
  %3485 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12019.BottleneckLayer = prim::GetAttr[name="input"](%3483)
  %3486 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12018.NoNorm = prim::GetAttr[name="LayerNorm"](%3485)
  %3487 : __torch__.torch.nn.modules.linear.___torch_mangle_12017.Linear = prim::GetAttr[name="dense"](%3485)
  %3488 : Tensor = prim::GetAttr[name="bias"](%3487)
  %3489 : Tensor = prim::GetAttr[name="weight"](%3487)
  %3490 : Float(512:1, 128:512) = aten::t(%3489), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.257 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3490), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.138 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.257, %3488, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3493 : Tensor = prim::GetAttr[name="bias"](%3486)
  %3494 : Tensor = prim::GetAttr[name="weight"](%3486)
  %3495 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.138, %3494), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.18 : Float(17:1664, 13:128, 128:1) = aten::add(%3495, %3493, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.input/__module.mobilebert.encoder.layer.17.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3497 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12021.NoNorm = prim::GetAttr[name="LayerNorm"](%3484)
  %3498 : __torch__.torch.nn.modules.linear.___torch_mangle_12020.Linear = prim::GetAttr[name="dense"](%3484)
  %3499 : Tensor = prim::GetAttr[name="bias"](%3498)
  %3500 : Tensor = prim::GetAttr[name="weight"](%3498)
  %3501 : Float(512:1, 128:512) = aten::t(%3500), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.258 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3501), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.258, %3499, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3504 : Tensor = prim::GetAttr[name="bias"](%3497)
  %3505 : Tensor = prim::GetAttr[name="weight"](%3497)
  %3506 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.139, %3505), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.331 : Float(17:1664, 13:128, 128:1) = aten::add(%3506, %3504, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.bottleneck/__module.mobilebert.encoder.layer.17.bottleneck.attention/__module.mobilebert.encoder.layer.17.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3508 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.331, %residual_tensor.18)
  %3509 : Float(17:1664, 13:128, 128:1), %3510 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3508)
  %3511 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12006.MobileBertSelfOutput = prim::GetAttr[name="output"](%3482)
  %3512 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12003.MobileBertSelfAttention = prim::GetAttr[name="self"](%3482)
  %3513 : __torch__.torch.nn.modules.linear.___torch_mangle_12001.Linear = prim::GetAttr[name="value"](%3512)
  %3514 : __torch__.torch.nn.modules.linear.___torch_mangle_12000.Linear = prim::GetAttr[name="key"](%3512)
  %3515 : __torch__.torch.nn.modules.linear.___torch_mangle_11999.Linear = prim::GetAttr[name="query"](%3512)
  %3516 : Tensor = prim::GetAttr[name="bias"](%3515)
  %3517 : Tensor = prim::GetAttr[name="weight"](%3515)
  %3518 : Float(128:1, 128:128) = aten::t(%3517), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %output.259 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3509, %3518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1676:0
  %x.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.259, %3516, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.query # torch/nn/functional.py:1678:0
  %3521 : Tensor = prim::GetAttr[name="bias"](%3514)
  %3522 : Tensor = prim::GetAttr[name="weight"](%3514)
  %3523 : Float(128:1, 128:128) = aten::t(%3522), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %output.260 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3509, %3523), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1676:0
  %x.105 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.260, %3521, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.key # torch/nn/functional.py:1678:0
  %3526 : Tensor = prim::GetAttr[name="bias"](%3513)
  %3527 : Tensor = prim::GetAttr[name="weight"](%3513)
  %3528 : Float(512:1, 128:512) = aten::t(%3527), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %output.261 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.330, %3528), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1676:0
  %x.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.261, %3526, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.value # torch/nn/functional.py:1678:0
  %3531 : int = aten::size(%x.103, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3532 : int = aten::size(%x.103, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3533 : int[] = prim::ListConstruct(%3531, %3532, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.104 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.103, %3533), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3535 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %query_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.104, %3535), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3537 : int = aten::size(%x.105, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3538 : int = aten::size(%x.105, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3539 : int[] = prim::ListConstruct(%3537, %3538, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.106 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.105, %3539), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3541 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %key_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.106, %3541), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3543 : int = aten::size(%x.107, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3544 : int = aten::size(%x.107, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:243:0
  %3545 : int[] = prim::ListConstruct(%3543, %3544, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %x.108 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.107, %3545), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:244:0
  %3547 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %value_layer.18 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.108, %3547), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:245:0
  %3549 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.18, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.35 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.18, %3549), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.36 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.35, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.332 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.36, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.333 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.332, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.18 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.333, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self/__module.mobilebert.encoder.layer.17.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.35 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.18, %value_layer.18), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:280:0
  %3556 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %3557 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.35, %3556), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.36 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3557, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:281:0
  %3559 : int = aten::size(%context_layer.36, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3560 : int = aten::size(%context_layer.36, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:282:0
  %3561 : int[] = prim::ListConstruct(%3559, %3560, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self
  %input.334 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.36, %3561), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.self # transformers/modeling_mobilebert.py:283:0
  %3563 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12005.NoNorm = prim::GetAttr[name="LayerNorm"](%3511)
  %3564 : __torch__.torch.nn.modules.linear.___torch_mangle_12004.Linear = prim::GetAttr[name="dense"](%3511)
  %3565 : Tensor = prim::GetAttr[name="bias"](%3564)
  %3566 : Tensor = prim::GetAttr[name="weight"](%3564)
  %3567 : Float(128:1, 128:128) = aten::t(%3566), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %output.262 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.334, %3567), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.86 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.262, %3565, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.140 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.86, %3510, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output # transformers/modeling_mobilebert.py:301:0
  %3571 : Tensor = prim::GetAttr[name="bias"](%3563)
  %3572 : Tensor = prim::GetAttr[name="weight"](%3563)
  %3573 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.140, %3572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.335 : Float(17:1664, 13:128, 128:1) = aten::add(%3573, %3571, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.attention/__module.mobilebert.encoder.layer.17.attention.output/__module.mobilebert.encoder.layer.17.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3575 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12028.FFNOutput = prim::GetAttr[name="output"](%3481)
  %3576 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12025.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3481)
  %3577 : __torch__.torch.nn.modules.linear.___torch_mangle_12024.Linear = prim::GetAttr[name="dense"](%3576)
  %3578 : Tensor = prim::GetAttr[name="bias"](%3577)
  %3579 : Tensor = prim::GetAttr[name="weight"](%3577)
  %3580 : Float(128:1, 512:128) = aten::t(%3579), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.263 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.335, %3580), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.336 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.263, %3578, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate/__module.mobilebert.encoder.layer.17.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.337 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.336), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3584 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12027.NoNorm = prim::GetAttr[name="LayerNorm"](%3575)
  %3585 : __torch__.torch.nn.modules.linear.___torch_mangle_12026.Linear = prim::GetAttr[name="dense"](%3575)
  %3586 : Tensor = prim::GetAttr[name="bias"](%3585)
  %3587 : Tensor = prim::GetAttr[name="weight"](%3585)
  %3588 : Float(512:1, 128:512) = aten::t(%3587), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.264 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.337, %3588), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.87 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.264, %3586, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.141 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.87, %input.335, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3592 : Tensor = prim::GetAttr[name="bias"](%3584)
  %3593 : Tensor = prim::GetAttr[name="weight"](%3584)
  %3594 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.141, %3593), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.338 : Float(17:1664, 13:128, 128:1) = aten::add(%3594, %3592, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.0/__module.mobilebert.encoder.layer.17.ffn.0.output/__module.mobilebert.encoder.layer.17.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3596 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12034.FFNOutput = prim::GetAttr[name="output"](%3479)
  %3597 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12031.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3479)
  %3598 : __torch__.torch.nn.modules.linear.___torch_mangle_12030.Linear = prim::GetAttr[name="dense"](%3597)
  %3599 : Tensor = prim::GetAttr[name="bias"](%3598)
  %3600 : Tensor = prim::GetAttr[name="weight"](%3598)
  %3601 : Float(128:1, 512:128) = aten::t(%3600), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.265 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.338, %3601), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.339 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.265, %3599, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate/__module.mobilebert.encoder.layer.17.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.340 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.339), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3605 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12033.NoNorm = prim::GetAttr[name="LayerNorm"](%3596)
  %3606 : __torch__.torch.nn.modules.linear.___torch_mangle_12032.Linear = prim::GetAttr[name="dense"](%3596)
  %3607 : Tensor = prim::GetAttr[name="bias"](%3606)
  %3608 : Tensor = prim::GetAttr[name="weight"](%3606)
  %3609 : Float(512:1, 128:512) = aten::t(%3608), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.266 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.340, %3609), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.88 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.266, %3607, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.142 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.88, %input.338, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3613 : Tensor = prim::GetAttr[name="bias"](%3605)
  %3614 : Tensor = prim::GetAttr[name="weight"](%3605)
  %3615 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.142, %3614), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.341 : Float(17:1664, 13:128, 128:1) = aten::add(%3615, %3613, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.1/__module.mobilebert.encoder.layer.17.ffn.1.output/__module.mobilebert.encoder.layer.17.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3617 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12040.FFNOutput = prim::GetAttr[name="output"](%3477)
  %3618 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12037.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3477)
  %3619 : __torch__.torch.nn.modules.linear.___torch_mangle_12036.Linear = prim::GetAttr[name="dense"](%3618)
  %3620 : Tensor = prim::GetAttr[name="bias"](%3619)
  %3621 : Tensor = prim::GetAttr[name="weight"](%3619)
  %3622 : Float(128:1, 512:128) = aten::t(%3621), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.267 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.341, %3622), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.342 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.267, %3620, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate/__module.mobilebert.encoder.layer.17.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.343 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.342), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3626 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12039.NoNorm = prim::GetAttr[name="LayerNorm"](%3617)
  %3627 : __torch__.torch.nn.modules.linear.___torch_mangle_12038.Linear = prim::GetAttr[name="dense"](%3617)
  %3628 : Tensor = prim::GetAttr[name="bias"](%3627)
  %3629 : Tensor = prim::GetAttr[name="weight"](%3627)
  %3630 : Float(512:1, 128:512) = aten::t(%3629), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.268 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.343, %3630), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.89 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.268, %3628, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.143 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.89, %input.341, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3634 : Tensor = prim::GetAttr[name="bias"](%3626)
  %3635 : Tensor = prim::GetAttr[name="weight"](%3626)
  %3636 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.143, %3635), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.344 : Float(17:1664, 13:128, 128:1) = aten::add(%3636, %3634, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.ffn.2/__module.mobilebert.encoder.layer.17.ffn.2.output/__module.mobilebert.encoder.layer.17.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3638 : __torch__.torch.nn.modules.linear.___torch_mangle_12008.Linear = prim::GetAttr[name="dense"](%3475)
  %3639 : Tensor = prim::GetAttr[name="bias"](%3638)
  %3640 : Tensor = prim::GetAttr[name="weight"](%3638)
  %3641 : Float(128:1, 512:128) = aten::t(%3640), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %output.269 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.344, %3641), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1676:0
  %input.345 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.269, %3639, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate/__module.mobilebert.encoder.layer.17.intermediate.dense # torch/nn/functional.py:1678:0
  %input.346 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.345), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.intermediate # torch/nn/functional.py:1119:0
  %3645 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12015.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3474)
  %3646 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12011.NoNorm = prim::GetAttr[name="LayerNorm"](%3474)
  %3647 : __torch__.torch.nn.modules.linear.___torch_mangle_12010.Linear = prim::GetAttr[name="dense"](%3474)
  %3648 : Tensor = prim::GetAttr[name="bias"](%3647)
  %3649 : Tensor = prim::GetAttr[name="weight"](%3647)
  %3650 : Float(512:1, 128:512) = aten::t(%3649), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %output.270 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.346, %3650), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1676:0
  %layer_output.18 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.270, %3648, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.144 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.18, %input.344, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output # transformers/modeling_mobilebert.py:405:0
  %3654 : Tensor = prim::GetAttr[name="bias"](%3646)
  %3655 : Tensor = prim::GetAttr[name="weight"](%3646)
  %3656 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.144, %3655), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.347 : Float(17:1664, 13:128, 128:1) = aten::add(%3656, %3654, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3658 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12013.NoNorm = prim::GetAttr[name="LayerNorm"](%3645)
  %3659 : __torch__.torch.nn.modules.linear.___torch_mangle_12012.Linear = prim::GetAttr[name="dense"](%3645)
  %3660 : Tensor = prim::GetAttr[name="bias"](%3659)
  %3661 : Tensor = prim::GetAttr[name="weight"](%3659)
  %3662 : Float(128:1, 512:128) = aten::t(%3661), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.271 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.347, %3662), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.348 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.271, %3660, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.90 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.348, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.145 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.90, %input.330, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3667 : Tensor = prim::GetAttr[name="bias"](%3658)
  %3668 : Tensor = prim::GetAttr[name="weight"](%3658)
  %3669 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.145, %3668), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.349 : Float(17:6656, 13:512, 512:1) = aten::add(%3669, %3667, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.17/__module.mobilebert.encoder.layer.17.output/__module.mobilebert.encoder.layer.17.output.bottleneck/__module.mobilebert.encoder.layer.17.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3671 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12061.MobileBertOutput = prim::GetAttr[name="output"](%88)
  %3672 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12054.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%88)
  %3673 : __torch__.torch.nn.modules.container.___torch_mangle_12087.ModuleList = prim::GetAttr[name="ffn"](%88)
  %3674 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12086.FFNLayer = prim::GetAttr[name="2"](%3673)
  %3675 : __torch__.torch.nn.modules.container.___torch_mangle_12087.ModuleList = prim::GetAttr[name="ffn"](%88)
  %3676 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12080.FFNLayer = prim::GetAttr[name="1"](%3675)
  %3677 : __torch__.torch.nn.modules.container.___torch_mangle_12087.ModuleList = prim::GetAttr[name="ffn"](%88)
  %3678 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12074.FFNLayer = prim::GetAttr[name="0"](%3677)
  %3679 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12052.MobileBertAttention = prim::GetAttr[name="attention"](%88)
  %3680 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12068.Bottleneck = prim::GetAttr[name="bottleneck"](%88)
  %3681 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12067.BottleneckLayer = prim::GetAttr[name="attention"](%3680)
  %3682 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12064.BottleneckLayer = prim::GetAttr[name="input"](%3680)
  %3683 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12063.NoNorm = prim::GetAttr[name="LayerNorm"](%3682)
  %3684 : __torch__.torch.nn.modules.linear.___torch_mangle_12062.Linear = prim::GetAttr[name="dense"](%3682)
  %3685 : Tensor = prim::GetAttr[name="bias"](%3684)
  %3686 : Tensor = prim::GetAttr[name="weight"](%3684)
  %3687 : Float(512:1, 128:512) = aten::t(%3686), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.272 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3687), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.146 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.272, %3685, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3690 : Tensor = prim::GetAttr[name="bias"](%3683)
  %3691 : Tensor = prim::GetAttr[name="weight"](%3683)
  %3692 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.146, %3691), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.19 : Float(17:1664, 13:128, 128:1) = aten::add(%3692, %3690, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.input/__module.mobilebert.encoder.layer.18.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3694 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12066.NoNorm = prim::GetAttr[name="LayerNorm"](%3681)
  %3695 : __torch__.torch.nn.modules.linear.___torch_mangle_12065.Linear = prim::GetAttr[name="dense"](%3681)
  %3696 : Tensor = prim::GetAttr[name="bias"](%3695)
  %3697 : Tensor = prim::GetAttr[name="weight"](%3695)
  %3698 : Float(512:1, 128:512) = aten::t(%3697), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.273 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3698), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.147 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.273, %3696, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3701 : Tensor = prim::GetAttr[name="bias"](%3694)
  %3702 : Tensor = prim::GetAttr[name="weight"](%3694)
  %3703 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.147, %3702), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.350 : Float(17:1664, 13:128, 128:1) = aten::add(%3703, %3701, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.bottleneck/__module.mobilebert.encoder.layer.18.bottleneck.attention/__module.mobilebert.encoder.layer.18.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3705 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.350, %residual_tensor.19)
  %3706 : Float(17:1664, 13:128, 128:1), %3707 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3705)
  %3708 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12051.MobileBertSelfOutput = prim::GetAttr[name="output"](%3679)
  %3709 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12048.MobileBertSelfAttention = prim::GetAttr[name="self"](%3679)
  %3710 : __torch__.torch.nn.modules.linear.___torch_mangle_12046.Linear = prim::GetAttr[name="value"](%3709)
  %3711 : __torch__.torch.nn.modules.linear.___torch_mangle_12045.Linear = prim::GetAttr[name="key"](%3709)
  %3712 : __torch__.torch.nn.modules.linear.___torch_mangle_12044.Linear = prim::GetAttr[name="query"](%3709)
  %3713 : Tensor = prim::GetAttr[name="bias"](%3712)
  %3714 : Tensor = prim::GetAttr[name="weight"](%3712)
  %3715 : Float(128:1, 128:128) = aten::t(%3714), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %output.274 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3706, %3715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1676:0
  %x.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.274, %3713, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.query # torch/nn/functional.py:1678:0
  %3718 : Tensor = prim::GetAttr[name="bias"](%3711)
  %3719 : Tensor = prim::GetAttr[name="weight"](%3711)
  %3720 : Float(128:1, 128:128) = aten::t(%3719), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %output.275 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3706, %3720), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1676:0
  %x.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.275, %3718, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.key # torch/nn/functional.py:1678:0
  %3723 : Tensor = prim::GetAttr[name="bias"](%3710)
  %3724 : Tensor = prim::GetAttr[name="weight"](%3710)
  %3725 : Float(512:1, 128:512) = aten::t(%3724), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %output.276 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.349, %3725), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1676:0
  %x.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.276, %3723, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.value # torch/nn/functional.py:1678:0
  %3728 : int = aten::size(%x.109, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3729 : int = aten::size(%x.109, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3730 : int[] = prim::ListConstruct(%3728, %3729, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.110 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.109, %3730), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3732 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %query_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.110, %3732), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3734 : int = aten::size(%x.111, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3735 : int = aten::size(%x.111, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3736 : int[] = prim::ListConstruct(%3734, %3735, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.112 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.111, %3736), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3738 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %key_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.112, %3738), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3740 : int = aten::size(%x.113, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3741 : int = aten::size(%x.113, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:243:0
  %3742 : int[] = prim::ListConstruct(%3740, %3741, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %x.114 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.113, %3742), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:244:0
  %3744 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %value_layer.19 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.114, %3744), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:245:0
  %3746 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.19, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.37 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.19, %3746), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.38 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.37, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.351 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.38, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.352 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.351, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.19 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.352, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self/__module.mobilebert.encoder.layer.18.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.37 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.19, %value_layer.19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:280:0
  %3753 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %3754 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.37, %3753), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.38 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3754, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:281:0
  %3756 : int = aten::size(%context_layer.38, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3757 : int = aten::size(%context_layer.38, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:282:0
  %3758 : int[] = prim::ListConstruct(%3756, %3757, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self
  %input.353 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.38, %3758), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.self # transformers/modeling_mobilebert.py:283:0
  %3760 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12050.NoNorm = prim::GetAttr[name="LayerNorm"](%3708)
  %3761 : __torch__.torch.nn.modules.linear.___torch_mangle_12049.Linear = prim::GetAttr[name="dense"](%3708)
  %3762 : Tensor = prim::GetAttr[name="bias"](%3761)
  %3763 : Tensor = prim::GetAttr[name="weight"](%3761)
  %3764 : Float(128:1, 128:128) = aten::t(%3763), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %output.277 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.353, %3764), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.91 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.277, %3762, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.148 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.91, %3707, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output # transformers/modeling_mobilebert.py:301:0
  %3768 : Tensor = prim::GetAttr[name="bias"](%3760)
  %3769 : Tensor = prim::GetAttr[name="weight"](%3760)
  %3770 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.148, %3769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.354 : Float(17:1664, 13:128, 128:1) = aten::add(%3770, %3768, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.attention/__module.mobilebert.encoder.layer.18.attention.output/__module.mobilebert.encoder.layer.18.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3772 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12073.FFNOutput = prim::GetAttr[name="output"](%3678)
  %3773 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12070.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3678)
  %3774 : __torch__.torch.nn.modules.linear.___torch_mangle_12069.Linear = prim::GetAttr[name="dense"](%3773)
  %3775 : Tensor = prim::GetAttr[name="bias"](%3774)
  %3776 : Tensor = prim::GetAttr[name="weight"](%3774)
  %3777 : Float(128:1, 512:128) = aten::t(%3776), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.278 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.354, %3777), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.355 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.278, %3775, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate/__module.mobilebert.encoder.layer.18.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.356 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3781 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12072.NoNorm = prim::GetAttr[name="LayerNorm"](%3772)
  %3782 : __torch__.torch.nn.modules.linear.___torch_mangle_12071.Linear = prim::GetAttr[name="dense"](%3772)
  %3783 : Tensor = prim::GetAttr[name="bias"](%3782)
  %3784 : Tensor = prim::GetAttr[name="weight"](%3782)
  %3785 : Float(512:1, 128:512) = aten::t(%3784), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.279 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.356, %3785), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.92 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.279, %3783, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.149 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.92, %input.354, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3789 : Tensor = prim::GetAttr[name="bias"](%3781)
  %3790 : Tensor = prim::GetAttr[name="weight"](%3781)
  %3791 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.149, %3790), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.357 : Float(17:1664, 13:128, 128:1) = aten::add(%3791, %3789, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.0/__module.mobilebert.encoder.layer.18.ffn.0.output/__module.mobilebert.encoder.layer.18.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3793 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12079.FFNOutput = prim::GetAttr[name="output"](%3676)
  %3794 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12076.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3676)
  %3795 : __torch__.torch.nn.modules.linear.___torch_mangle_12075.Linear = prim::GetAttr[name="dense"](%3794)
  %3796 : Tensor = prim::GetAttr[name="bias"](%3795)
  %3797 : Tensor = prim::GetAttr[name="weight"](%3795)
  %3798 : Float(128:1, 512:128) = aten::t(%3797), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.280 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.357, %3798), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.358 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.280, %3796, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate/__module.mobilebert.encoder.layer.18.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.359 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.358), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3802 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12078.NoNorm = prim::GetAttr[name="LayerNorm"](%3793)
  %3803 : __torch__.torch.nn.modules.linear.___torch_mangle_12077.Linear = prim::GetAttr[name="dense"](%3793)
  %3804 : Tensor = prim::GetAttr[name="bias"](%3803)
  %3805 : Tensor = prim::GetAttr[name="weight"](%3803)
  %3806 : Float(512:1, 128:512) = aten::t(%3805), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.281 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.359, %3806), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.93 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.281, %3804, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.150 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.93, %input.357, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %3810 : Tensor = prim::GetAttr[name="bias"](%3802)
  %3811 : Tensor = prim::GetAttr[name="weight"](%3802)
  %3812 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.150, %3811), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.360 : Float(17:1664, 13:128, 128:1) = aten::add(%3812, %3810, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.1/__module.mobilebert.encoder.layer.18.ffn.1.output/__module.mobilebert.encoder.layer.18.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3814 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12085.FFNOutput = prim::GetAttr[name="output"](%3674)
  %3815 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12082.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3674)
  %3816 : __torch__.torch.nn.modules.linear.___torch_mangle_12081.Linear = prim::GetAttr[name="dense"](%3815)
  %3817 : Tensor = prim::GetAttr[name="bias"](%3816)
  %3818 : Tensor = prim::GetAttr[name="weight"](%3816)
  %3819 : Float(128:1, 512:128) = aten::t(%3818), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.282 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.360, %3819), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.361 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.282, %3817, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate/__module.mobilebert.encoder.layer.18.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.362 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.361), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %3823 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12084.NoNorm = prim::GetAttr[name="LayerNorm"](%3814)
  %3824 : __torch__.torch.nn.modules.linear.___torch_mangle_12083.Linear = prim::GetAttr[name="dense"](%3814)
  %3825 : Tensor = prim::GetAttr[name="bias"](%3824)
  %3826 : Tensor = prim::GetAttr[name="weight"](%3824)
  %3827 : Float(512:1, 128:512) = aten::t(%3826), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.283 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.362, %3827), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.94 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.283, %3825, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.151 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.94, %input.360, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %3831 : Tensor = prim::GetAttr[name="bias"](%3823)
  %3832 : Tensor = prim::GetAttr[name="weight"](%3823)
  %3833 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.151, %3832), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.363 : Float(17:1664, 13:128, 128:1) = aten::add(%3833, %3831, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.ffn.2/__module.mobilebert.encoder.layer.18.ffn.2.output/__module.mobilebert.encoder.layer.18.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3835 : __torch__.torch.nn.modules.linear.___torch_mangle_12053.Linear = prim::GetAttr[name="dense"](%3672)
  %3836 : Tensor = prim::GetAttr[name="bias"](%3835)
  %3837 : Tensor = prim::GetAttr[name="weight"](%3835)
  %3838 : Float(128:1, 512:128) = aten::t(%3837), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %output.284 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.363, %3838), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1676:0
  %input.364 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.284, %3836, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate/__module.mobilebert.encoder.layer.18.intermediate.dense # torch/nn/functional.py:1678:0
  %input.365 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.364), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.intermediate # torch/nn/functional.py:1119:0
  %3842 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12060.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3671)
  %3843 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12056.NoNorm = prim::GetAttr[name="LayerNorm"](%3671)
  %3844 : __torch__.torch.nn.modules.linear.___torch_mangle_12055.Linear = prim::GetAttr[name="dense"](%3671)
  %3845 : Tensor = prim::GetAttr[name="bias"](%3844)
  %3846 : Tensor = prim::GetAttr[name="weight"](%3844)
  %3847 : Float(512:1, 128:512) = aten::t(%3846), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %output.285 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.365, %3847), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1676:0
  %layer_output.19 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.285, %3845, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.152 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.19, %input.363, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output # transformers/modeling_mobilebert.py:405:0
  %3851 : Tensor = prim::GetAttr[name="bias"](%3843)
  %3852 : Tensor = prim::GetAttr[name="weight"](%3843)
  %3853 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.152, %3852), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.366 : Float(17:1664, 13:128, 128:1) = aten::add(%3853, %3851, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3855 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12058.NoNorm = prim::GetAttr[name="LayerNorm"](%3842)
  %3856 : __torch__.torch.nn.modules.linear.___torch_mangle_12057.Linear = prim::GetAttr[name="dense"](%3842)
  %3857 : Tensor = prim::GetAttr[name="bias"](%3856)
  %3858 : Tensor = prim::GetAttr[name="weight"](%3856)
  %3859 : Float(128:1, 512:128) = aten::t(%3858), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.286 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.366, %3859), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.367 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.286, %3857, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.95 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.367, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.153 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.95, %input.349, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %3864 : Tensor = prim::GetAttr[name="bias"](%3855)
  %3865 : Tensor = prim::GetAttr[name="weight"](%3855)
  %3866 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.153, %3865), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.368 : Float(17:6656, 13:512, 512:1) = aten::add(%3866, %3864, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.18/__module.mobilebert.encoder.layer.18.output/__module.mobilebert.encoder.layer.18.output.bottleneck/__module.mobilebert.encoder.layer.18.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3868 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12106.MobileBertOutput = prim::GetAttr[name="output"](%86)
  %3869 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12099.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%86)
  %3870 : __torch__.torch.nn.modules.container.___torch_mangle_12132.ModuleList = prim::GetAttr[name="ffn"](%86)
  %3871 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12131.FFNLayer = prim::GetAttr[name="2"](%3870)
  %3872 : __torch__.torch.nn.modules.container.___torch_mangle_12132.ModuleList = prim::GetAttr[name="ffn"](%86)
  %3873 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12125.FFNLayer = prim::GetAttr[name="1"](%3872)
  %3874 : __torch__.torch.nn.modules.container.___torch_mangle_12132.ModuleList = prim::GetAttr[name="ffn"](%86)
  %3875 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12119.FFNLayer = prim::GetAttr[name="0"](%3874)
  %3876 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12097.MobileBertAttention = prim::GetAttr[name="attention"](%86)
  %3877 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12113.Bottleneck = prim::GetAttr[name="bottleneck"](%86)
  %3878 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12112.BottleneckLayer = prim::GetAttr[name="attention"](%3877)
  %3879 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12109.BottleneckLayer = prim::GetAttr[name="input"](%3877)
  %3880 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12108.NoNorm = prim::GetAttr[name="LayerNorm"](%3879)
  %3881 : __torch__.torch.nn.modules.linear.___torch_mangle_12107.Linear = prim::GetAttr[name="dense"](%3879)
  %3882 : Tensor = prim::GetAttr[name="bias"](%3881)
  %3883 : Tensor = prim::GetAttr[name="weight"](%3881)
  %3884 : Float(512:1, 128:512) = aten::t(%3883), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.287 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3884), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.154 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.287, %3882, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %3887 : Tensor = prim::GetAttr[name="bias"](%3880)
  %3888 : Tensor = prim::GetAttr[name="weight"](%3880)
  %3889 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.154, %3888), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.20 : Float(17:1664, 13:128, 128:1) = aten::add(%3889, %3887, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.input/__module.mobilebert.encoder.layer.19.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3891 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12111.NoNorm = prim::GetAttr[name="LayerNorm"](%3878)
  %3892 : __torch__.torch.nn.modules.linear.___torch_mangle_12110.Linear = prim::GetAttr[name="dense"](%3878)
  %3893 : Tensor = prim::GetAttr[name="bias"](%3892)
  %3894 : Tensor = prim::GetAttr[name="weight"](%3892)
  %3895 : Float(512:1, 128:512) = aten::t(%3894), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.288 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3895), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.155 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.288, %3893, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %3898 : Tensor = prim::GetAttr[name="bias"](%3891)
  %3899 : Tensor = prim::GetAttr[name="weight"](%3891)
  %3900 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.155, %3899), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.369 : Float(17:1664, 13:128, 128:1) = aten::add(%3900, %3898, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.bottleneck/__module.mobilebert.encoder.layer.19.bottleneck.attention/__module.mobilebert.encoder.layer.19.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3902 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.369, %residual_tensor.20)
  %3903 : Float(17:1664, 13:128, 128:1), %3904 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%3902)
  %3905 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12096.MobileBertSelfOutput = prim::GetAttr[name="output"](%3876)
  %3906 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12093.MobileBertSelfAttention = prim::GetAttr[name="self"](%3876)
  %3907 : __torch__.torch.nn.modules.linear.___torch_mangle_12091.Linear = prim::GetAttr[name="value"](%3906)
  %3908 : __torch__.torch.nn.modules.linear.___torch_mangle_12090.Linear = prim::GetAttr[name="key"](%3906)
  %3909 : __torch__.torch.nn.modules.linear.___torch_mangle_12089.Linear = prim::GetAttr[name="query"](%3906)
  %3910 : Tensor = prim::GetAttr[name="bias"](%3909)
  %3911 : Tensor = prim::GetAttr[name="weight"](%3909)
  %3912 : Float(128:1, 128:128) = aten::t(%3911), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %output.289 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3903, %3912), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1676:0
  %x.115 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.289, %3910, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.query # torch/nn/functional.py:1678:0
  %3915 : Tensor = prim::GetAttr[name="bias"](%3908)
  %3916 : Tensor = prim::GetAttr[name="weight"](%3908)
  %3917 : Float(128:1, 128:128) = aten::t(%3916), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %output.290 : Float(17:1664, 13:128, 128:1) = aten::matmul(%3903, %3917), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1676:0
  %x.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.290, %3915, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.key # torch/nn/functional.py:1678:0
  %3920 : Tensor = prim::GetAttr[name="bias"](%3907)
  %3921 : Tensor = prim::GetAttr[name="weight"](%3907)
  %3922 : Float(512:1, 128:512) = aten::t(%3921), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %output.291 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.368, %3922), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1676:0
  %x.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.291, %3920, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.value # torch/nn/functional.py:1678:0
  %3925 : int = aten::size(%x.115, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3926 : int = aten::size(%x.115, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3927 : int[] = prim::ListConstruct(%3925, %3926, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.116 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.115, %3927), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3929 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %query_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.116, %3929), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3931 : int = aten::size(%x.117, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3932 : int = aten::size(%x.117, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3933 : int[] = prim::ListConstruct(%3931, %3932, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.118 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.117, %3933), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3935 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %key_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.118, %3935), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3937 : int = aten::size(%x.119, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3938 : int = aten::size(%x.119, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:243:0
  %3939 : int[] = prim::ListConstruct(%3937, %3938, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %x.120 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.119, %3939), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:244:0
  %3941 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %value_layer.20 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.120, %3941), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:245:0
  %3943 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.20, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.39 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.20, %3943), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.40 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.39, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.370 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.40, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.371 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.370, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.20 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.371, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self/__module.mobilebert.encoder.layer.19.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.39 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.20, %value_layer.20), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:280:0
  %3950 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %3951 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.39, %3950), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.40 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%3951, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:281:0
  %3953 : int = aten::size(%context_layer.40, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3954 : int = aten::size(%context_layer.40, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:282:0
  %3955 : int[] = prim::ListConstruct(%3953, %3954, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self
  %input.372 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.40, %3955), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.self # transformers/modeling_mobilebert.py:283:0
  %3957 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12095.NoNorm = prim::GetAttr[name="LayerNorm"](%3905)
  %3958 : __torch__.torch.nn.modules.linear.___torch_mangle_12094.Linear = prim::GetAttr[name="dense"](%3905)
  %3959 : Tensor = prim::GetAttr[name="bias"](%3958)
  %3960 : Tensor = prim::GetAttr[name="weight"](%3958)
  %3961 : Float(128:1, 128:128) = aten::t(%3960), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %output.292 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.372, %3961), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.96 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.292, %3959, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.156 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.96, %3904, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output # transformers/modeling_mobilebert.py:301:0
  %3965 : Tensor = prim::GetAttr[name="bias"](%3957)
  %3966 : Tensor = prim::GetAttr[name="weight"](%3957)
  %3967 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.156, %3966), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.373 : Float(17:1664, 13:128, 128:1) = aten::add(%3967, %3965, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.attention/__module.mobilebert.encoder.layer.19.attention.output/__module.mobilebert.encoder.layer.19.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3969 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12118.FFNOutput = prim::GetAttr[name="output"](%3875)
  %3970 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12115.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3875)
  %3971 : __torch__.torch.nn.modules.linear.___torch_mangle_12114.Linear = prim::GetAttr[name="dense"](%3970)
  %3972 : Tensor = prim::GetAttr[name="bias"](%3971)
  %3973 : Tensor = prim::GetAttr[name="weight"](%3971)
  %3974 : Float(128:1, 512:128) = aten::t(%3973), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.293 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.373, %3974), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.374 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.293, %3972, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate/__module.mobilebert.encoder.layer.19.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.375 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.374), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %3978 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12117.NoNorm = prim::GetAttr[name="LayerNorm"](%3969)
  %3979 : __torch__.torch.nn.modules.linear.___torch_mangle_12116.Linear = prim::GetAttr[name="dense"](%3969)
  %3980 : Tensor = prim::GetAttr[name="bias"](%3979)
  %3981 : Tensor = prim::GetAttr[name="weight"](%3979)
  %3982 : Float(512:1, 128:512) = aten::t(%3981), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.294 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.375, %3982), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.97 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.294, %3980, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.157 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.97, %input.373, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %3986 : Tensor = prim::GetAttr[name="bias"](%3978)
  %3987 : Tensor = prim::GetAttr[name="weight"](%3978)
  %3988 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.157, %3987), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.376 : Float(17:1664, 13:128, 128:1) = aten::add(%3988, %3986, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.0/__module.mobilebert.encoder.layer.19.ffn.0.output/__module.mobilebert.encoder.layer.19.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %3990 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12124.FFNOutput = prim::GetAttr[name="output"](%3873)
  %3991 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12121.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3873)
  %3992 : __torch__.torch.nn.modules.linear.___torch_mangle_12120.Linear = prim::GetAttr[name="dense"](%3991)
  %3993 : Tensor = prim::GetAttr[name="bias"](%3992)
  %3994 : Tensor = prim::GetAttr[name="weight"](%3992)
  %3995 : Float(128:1, 512:128) = aten::t(%3994), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.295 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.376, %3995), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.377 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.295, %3993, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate/__module.mobilebert.encoder.layer.19.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.378 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.377), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %3999 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12123.NoNorm = prim::GetAttr[name="LayerNorm"](%3990)
  %4000 : __torch__.torch.nn.modules.linear.___torch_mangle_12122.Linear = prim::GetAttr[name="dense"](%3990)
  %4001 : Tensor = prim::GetAttr[name="bias"](%4000)
  %4002 : Tensor = prim::GetAttr[name="weight"](%4000)
  %4003 : Float(512:1, 128:512) = aten::t(%4002), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.296 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.378, %4003), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.98 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.296, %4001, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.158 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.98, %input.376, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4007 : Tensor = prim::GetAttr[name="bias"](%3999)
  %4008 : Tensor = prim::GetAttr[name="weight"](%3999)
  %4009 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.158, %4008), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.379 : Float(17:1664, 13:128, 128:1) = aten::add(%4009, %4007, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.1/__module.mobilebert.encoder.layer.19.ffn.1.output/__module.mobilebert.encoder.layer.19.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4011 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12130.FFNOutput = prim::GetAttr[name="output"](%3871)
  %4012 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12127.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%3871)
  %4013 : __torch__.torch.nn.modules.linear.___torch_mangle_12126.Linear = prim::GetAttr[name="dense"](%4012)
  %4014 : Tensor = prim::GetAttr[name="bias"](%4013)
  %4015 : Tensor = prim::GetAttr[name="weight"](%4013)
  %4016 : Float(128:1, 512:128) = aten::t(%4015), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.297 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.379, %4016), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.380 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.297, %4014, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate/__module.mobilebert.encoder.layer.19.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.381 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.380), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4020 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12129.NoNorm = prim::GetAttr[name="LayerNorm"](%4011)
  %4021 : __torch__.torch.nn.modules.linear.___torch_mangle_12128.Linear = prim::GetAttr[name="dense"](%4011)
  %4022 : Tensor = prim::GetAttr[name="bias"](%4021)
  %4023 : Tensor = prim::GetAttr[name="weight"](%4021)
  %4024 : Float(512:1, 128:512) = aten::t(%4023), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.298 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.381, %4024), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.99 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.298, %4022, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.159 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.99, %input.379, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4028 : Tensor = prim::GetAttr[name="bias"](%4020)
  %4029 : Tensor = prim::GetAttr[name="weight"](%4020)
  %4030 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.159, %4029), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.382 : Float(17:1664, 13:128, 128:1) = aten::add(%4030, %4028, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.ffn.2/__module.mobilebert.encoder.layer.19.ffn.2.output/__module.mobilebert.encoder.layer.19.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4032 : __torch__.torch.nn.modules.linear.___torch_mangle_12098.Linear = prim::GetAttr[name="dense"](%3869)
  %4033 : Tensor = prim::GetAttr[name="bias"](%4032)
  %4034 : Tensor = prim::GetAttr[name="weight"](%4032)
  %4035 : Float(128:1, 512:128) = aten::t(%4034), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %output.299 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.382, %4035), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1676:0
  %input.383 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.299, %4033, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate/__module.mobilebert.encoder.layer.19.intermediate.dense # torch/nn/functional.py:1678:0
  %input.384 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.383), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.intermediate # torch/nn/functional.py:1119:0
  %4039 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12105.OutputBottleneck = prim::GetAttr[name="bottleneck"](%3868)
  %4040 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12101.NoNorm = prim::GetAttr[name="LayerNorm"](%3868)
  %4041 : __torch__.torch.nn.modules.linear.___torch_mangle_12100.Linear = prim::GetAttr[name="dense"](%3868)
  %4042 : Tensor = prim::GetAttr[name="bias"](%4041)
  %4043 : Tensor = prim::GetAttr[name="weight"](%4041)
  %4044 : Float(512:1, 128:512) = aten::t(%4043), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %output.300 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.384, %4044), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1676:0
  %layer_output.20 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.300, %4042, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.160 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.20, %input.382, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output # transformers/modeling_mobilebert.py:405:0
  %4048 : Tensor = prim::GetAttr[name="bias"](%4040)
  %4049 : Tensor = prim::GetAttr[name="weight"](%4040)
  %4050 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.160, %4049), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.385 : Float(17:1664, 13:128, 128:1) = aten::add(%4050, %4048, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4052 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12103.NoNorm = prim::GetAttr[name="LayerNorm"](%4039)
  %4053 : __torch__.torch.nn.modules.linear.___torch_mangle_12102.Linear = prim::GetAttr[name="dense"](%4039)
  %4054 : Tensor = prim::GetAttr[name="bias"](%4053)
  %4055 : Tensor = prim::GetAttr[name="weight"](%4053)
  %4056 : Float(128:1, 512:128) = aten::t(%4055), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.301 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.385, %4056), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.386 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.301, %4054, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.100 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.386, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.161 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.100, %input.368, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4061 : Tensor = prim::GetAttr[name="bias"](%4052)
  %4062 : Tensor = prim::GetAttr[name="weight"](%4052)
  %4063 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.161, %4062), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.387 : Float(17:6656, 13:512, 512:1) = aten::add(%4063, %4061, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.19/__module.mobilebert.encoder.layer.19.output/__module.mobilebert.encoder.layer.19.output.bottleneck/__module.mobilebert.encoder.layer.19.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4065 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12151.MobileBertOutput = prim::GetAttr[name="output"](%84)
  %4066 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12144.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%84)
  %4067 : __torch__.torch.nn.modules.container.___torch_mangle_12177.ModuleList = prim::GetAttr[name="ffn"](%84)
  %4068 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12176.FFNLayer = prim::GetAttr[name="2"](%4067)
  %4069 : __torch__.torch.nn.modules.container.___torch_mangle_12177.ModuleList = prim::GetAttr[name="ffn"](%84)
  %4070 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12170.FFNLayer = prim::GetAttr[name="1"](%4069)
  %4071 : __torch__.torch.nn.modules.container.___torch_mangle_12177.ModuleList = prim::GetAttr[name="ffn"](%84)
  %4072 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12164.FFNLayer = prim::GetAttr[name="0"](%4071)
  %4073 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12142.MobileBertAttention = prim::GetAttr[name="attention"](%84)
  %4074 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12158.Bottleneck = prim::GetAttr[name="bottleneck"](%84)
  %4075 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12157.BottleneckLayer = prim::GetAttr[name="attention"](%4074)
  %4076 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12154.BottleneckLayer = prim::GetAttr[name="input"](%4074)
  %4077 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12153.NoNorm = prim::GetAttr[name="LayerNorm"](%4076)
  %4078 : __torch__.torch.nn.modules.linear.___torch_mangle_12152.Linear = prim::GetAttr[name="dense"](%4076)
  %4079 : Tensor = prim::GetAttr[name="bias"](%4078)
  %4080 : Tensor = prim::GetAttr[name="weight"](%4078)
  %4081 : Float(512:1, 128:512) = aten::t(%4080), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.302 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4081), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.162 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.302, %4079, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4084 : Tensor = prim::GetAttr[name="bias"](%4077)
  %4085 : Tensor = prim::GetAttr[name="weight"](%4077)
  %4086 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.162, %4085), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.21 : Float(17:1664, 13:128, 128:1) = aten::add(%4086, %4084, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.input/__module.mobilebert.encoder.layer.20.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4088 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12156.NoNorm = prim::GetAttr[name="LayerNorm"](%4075)
  %4089 : __torch__.torch.nn.modules.linear.___torch_mangle_12155.Linear = prim::GetAttr[name="dense"](%4075)
  %4090 : Tensor = prim::GetAttr[name="bias"](%4089)
  %4091 : Tensor = prim::GetAttr[name="weight"](%4089)
  %4092 : Float(512:1, 128:512) = aten::t(%4091), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.303 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4092), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.163 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.303, %4090, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4095 : Tensor = prim::GetAttr[name="bias"](%4088)
  %4096 : Tensor = prim::GetAttr[name="weight"](%4088)
  %4097 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.163, %4096), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.388 : Float(17:1664, 13:128, 128:1) = aten::add(%4097, %4095, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.bottleneck/__module.mobilebert.encoder.layer.20.bottleneck.attention/__module.mobilebert.encoder.layer.20.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4099 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.388, %residual_tensor.21)
  %4100 : Float(17:1664, 13:128, 128:1), %4101 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4099)
  %4102 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12141.MobileBertSelfOutput = prim::GetAttr[name="output"](%4073)
  %4103 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12138.MobileBertSelfAttention = prim::GetAttr[name="self"](%4073)
  %4104 : __torch__.torch.nn.modules.linear.___torch_mangle_12136.Linear = prim::GetAttr[name="value"](%4103)
  %4105 : __torch__.torch.nn.modules.linear.___torch_mangle_12135.Linear = prim::GetAttr[name="key"](%4103)
  %4106 : __torch__.torch.nn.modules.linear.___torch_mangle_12134.Linear = prim::GetAttr[name="query"](%4103)
  %4107 : Tensor = prim::GetAttr[name="bias"](%4106)
  %4108 : Tensor = prim::GetAttr[name="weight"](%4106)
  %4109 : Float(128:1, 128:128) = aten::t(%4108), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %output.304 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4100, %4109), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1676:0
  %x.121 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.304, %4107, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.query # torch/nn/functional.py:1678:0
  %4112 : Tensor = prim::GetAttr[name="bias"](%4105)
  %4113 : Tensor = prim::GetAttr[name="weight"](%4105)
  %4114 : Float(128:1, 128:128) = aten::t(%4113), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %output.305 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4100, %4114), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1676:0
  %x.123 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.305, %4112, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.key # torch/nn/functional.py:1678:0
  %4117 : Tensor = prim::GetAttr[name="bias"](%4104)
  %4118 : Tensor = prim::GetAttr[name="weight"](%4104)
  %4119 : Float(512:1, 128:512) = aten::t(%4118), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %output.306 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.387, %4119), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1676:0
  %x.125 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.306, %4117, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.value # torch/nn/functional.py:1678:0
  %4122 : int = aten::size(%x.121, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4123 : int = aten::size(%x.121, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4124 : int[] = prim::ListConstruct(%4122, %4123, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.122 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.121, %4124), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4126 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %query_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.122, %4126), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4128 : int = aten::size(%x.123, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4129 : int = aten::size(%x.123, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4130 : int[] = prim::ListConstruct(%4128, %4129, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.124 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.123, %4130), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4132 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %key_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.124, %4132), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4134 : int = aten::size(%x.125, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4135 : int = aten::size(%x.125, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:243:0
  %4136 : int[] = prim::ListConstruct(%4134, %4135, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %x.126 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.125, %4136), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:244:0
  %4138 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %value_layer.21 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.126, %4138), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:245:0
  %4140 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.21, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.41 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.21, %4140), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.42 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.41, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.389 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.42, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.390 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.389, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.21 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.390, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self/__module.mobilebert.encoder.layer.20.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.41 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.21, %value_layer.21), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:280:0
  %4147 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %4148 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.41, %4147), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.42 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4148, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:281:0
  %4150 : int = aten::size(%context_layer.42, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4151 : int = aten::size(%context_layer.42, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:282:0
  %4152 : int[] = prim::ListConstruct(%4150, %4151, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self
  %input.391 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.42, %4152), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.self # transformers/modeling_mobilebert.py:283:0
  %4154 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12140.NoNorm = prim::GetAttr[name="LayerNorm"](%4102)
  %4155 : __torch__.torch.nn.modules.linear.___torch_mangle_12139.Linear = prim::GetAttr[name="dense"](%4102)
  %4156 : Tensor = prim::GetAttr[name="bias"](%4155)
  %4157 : Tensor = prim::GetAttr[name="weight"](%4155)
  %4158 : Float(128:1, 128:128) = aten::t(%4157), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %output.307 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.391, %4158), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.101 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.307, %4156, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.164 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.101, %4101, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output # transformers/modeling_mobilebert.py:301:0
  %4162 : Tensor = prim::GetAttr[name="bias"](%4154)
  %4163 : Tensor = prim::GetAttr[name="weight"](%4154)
  %4164 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.164, %4163), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.392 : Float(17:1664, 13:128, 128:1) = aten::add(%4164, %4162, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.attention/__module.mobilebert.encoder.layer.20.attention.output/__module.mobilebert.encoder.layer.20.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4166 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12163.FFNOutput = prim::GetAttr[name="output"](%4072)
  %4167 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12160.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4072)
  %4168 : __torch__.torch.nn.modules.linear.___torch_mangle_12159.Linear = prim::GetAttr[name="dense"](%4167)
  %4169 : Tensor = prim::GetAttr[name="bias"](%4168)
  %4170 : Tensor = prim::GetAttr[name="weight"](%4168)
  %4171 : Float(128:1, 512:128) = aten::t(%4170), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.308 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.392, %4171), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.393 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.308, %4169, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate/__module.mobilebert.encoder.layer.20.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.394 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.393), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4175 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12162.NoNorm = prim::GetAttr[name="LayerNorm"](%4166)
  %4176 : __torch__.torch.nn.modules.linear.___torch_mangle_12161.Linear = prim::GetAttr[name="dense"](%4166)
  %4177 : Tensor = prim::GetAttr[name="bias"](%4176)
  %4178 : Tensor = prim::GetAttr[name="weight"](%4176)
  %4179 : Float(512:1, 128:512) = aten::t(%4178), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.309 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.394, %4179), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.102 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.309, %4177, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.165 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.102, %input.392, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4183 : Tensor = prim::GetAttr[name="bias"](%4175)
  %4184 : Tensor = prim::GetAttr[name="weight"](%4175)
  %4185 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.165, %4184), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.395 : Float(17:1664, 13:128, 128:1) = aten::add(%4185, %4183, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.0/__module.mobilebert.encoder.layer.20.ffn.0.output/__module.mobilebert.encoder.layer.20.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4187 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12169.FFNOutput = prim::GetAttr[name="output"](%4070)
  %4188 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12166.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4070)
  %4189 : __torch__.torch.nn.modules.linear.___torch_mangle_12165.Linear = prim::GetAttr[name="dense"](%4188)
  %4190 : Tensor = prim::GetAttr[name="bias"](%4189)
  %4191 : Tensor = prim::GetAttr[name="weight"](%4189)
  %4192 : Float(128:1, 512:128) = aten::t(%4191), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.310 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.395, %4192), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.396 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.310, %4190, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate/__module.mobilebert.encoder.layer.20.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.397 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4196 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12168.NoNorm = prim::GetAttr[name="LayerNorm"](%4187)
  %4197 : __torch__.torch.nn.modules.linear.___torch_mangle_12167.Linear = prim::GetAttr[name="dense"](%4187)
  %4198 : Tensor = prim::GetAttr[name="bias"](%4197)
  %4199 : Tensor = prim::GetAttr[name="weight"](%4197)
  %4200 : Float(512:1, 128:512) = aten::t(%4199), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.311 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.397, %4200), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.103 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.311, %4198, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.166 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.103, %input.395, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4204 : Tensor = prim::GetAttr[name="bias"](%4196)
  %4205 : Tensor = prim::GetAttr[name="weight"](%4196)
  %4206 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.166, %4205), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.398 : Float(17:1664, 13:128, 128:1) = aten::add(%4206, %4204, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.1/__module.mobilebert.encoder.layer.20.ffn.1.output/__module.mobilebert.encoder.layer.20.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4208 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12175.FFNOutput = prim::GetAttr[name="output"](%4068)
  %4209 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12172.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4068)
  %4210 : __torch__.torch.nn.modules.linear.___torch_mangle_12171.Linear = prim::GetAttr[name="dense"](%4209)
  %4211 : Tensor = prim::GetAttr[name="bias"](%4210)
  %4212 : Tensor = prim::GetAttr[name="weight"](%4210)
  %4213 : Float(128:1, 512:128) = aten::t(%4212), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.312 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.398, %4213), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.399 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.312, %4211, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate/__module.mobilebert.encoder.layer.20.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.400 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.399), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4217 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12174.NoNorm = prim::GetAttr[name="LayerNorm"](%4208)
  %4218 : __torch__.torch.nn.modules.linear.___torch_mangle_12173.Linear = prim::GetAttr[name="dense"](%4208)
  %4219 : Tensor = prim::GetAttr[name="bias"](%4218)
  %4220 : Tensor = prim::GetAttr[name="weight"](%4218)
  %4221 : Float(512:1, 128:512) = aten::t(%4220), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.313 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.400, %4221), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.104 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.313, %4219, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.167 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.104, %input.398, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4225 : Tensor = prim::GetAttr[name="bias"](%4217)
  %4226 : Tensor = prim::GetAttr[name="weight"](%4217)
  %4227 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.167, %4226), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.401 : Float(17:1664, 13:128, 128:1) = aten::add(%4227, %4225, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.ffn.2/__module.mobilebert.encoder.layer.20.ffn.2.output/__module.mobilebert.encoder.layer.20.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4229 : __torch__.torch.nn.modules.linear.___torch_mangle_12143.Linear = prim::GetAttr[name="dense"](%4066)
  %4230 : Tensor = prim::GetAttr[name="bias"](%4229)
  %4231 : Tensor = prim::GetAttr[name="weight"](%4229)
  %4232 : Float(128:1, 512:128) = aten::t(%4231), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %output.314 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.401, %4232), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1676:0
  %input.402 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.314, %4230, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate/__module.mobilebert.encoder.layer.20.intermediate.dense # torch/nn/functional.py:1678:0
  %input.403 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.intermediate # torch/nn/functional.py:1119:0
  %4236 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12150.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4065)
  %4237 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12146.NoNorm = prim::GetAttr[name="LayerNorm"](%4065)
  %4238 : __torch__.torch.nn.modules.linear.___torch_mangle_12145.Linear = prim::GetAttr[name="dense"](%4065)
  %4239 : Tensor = prim::GetAttr[name="bias"](%4238)
  %4240 : Tensor = prim::GetAttr[name="weight"](%4238)
  %4241 : Float(512:1, 128:512) = aten::t(%4240), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %output.315 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.403, %4241), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1676:0
  %layer_output.21 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.315, %4239, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.168 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.21, %input.401, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output # transformers/modeling_mobilebert.py:405:0
  %4245 : Tensor = prim::GetAttr[name="bias"](%4237)
  %4246 : Tensor = prim::GetAttr[name="weight"](%4237)
  %4247 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.168, %4246), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.404 : Float(17:1664, 13:128, 128:1) = aten::add(%4247, %4245, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4249 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12148.NoNorm = prim::GetAttr[name="LayerNorm"](%4236)
  %4250 : __torch__.torch.nn.modules.linear.___torch_mangle_12147.Linear = prim::GetAttr[name="dense"](%4236)
  %4251 : Tensor = prim::GetAttr[name="bias"](%4250)
  %4252 : Tensor = prim::GetAttr[name="weight"](%4250)
  %4253 : Float(128:1, 512:128) = aten::t(%4252), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.316 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.404, %4253), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.405 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.316, %4251, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.105 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.405, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.169 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.105, %input.387, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4258 : Tensor = prim::GetAttr[name="bias"](%4249)
  %4259 : Tensor = prim::GetAttr[name="weight"](%4249)
  %4260 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.169, %4259), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.406 : Float(17:6656, 13:512, 512:1) = aten::add(%4260, %4258, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.20/__module.mobilebert.encoder.layer.20.output/__module.mobilebert.encoder.layer.20.output.bottleneck/__module.mobilebert.encoder.layer.20.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4262 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12196.MobileBertOutput = prim::GetAttr[name="output"](%82)
  %4263 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12189.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%82)
  %4264 : __torch__.torch.nn.modules.container.___torch_mangle_12222.ModuleList = prim::GetAttr[name="ffn"](%82)
  %4265 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12221.FFNLayer = prim::GetAttr[name="2"](%4264)
  %4266 : __torch__.torch.nn.modules.container.___torch_mangle_12222.ModuleList = prim::GetAttr[name="ffn"](%82)
  %4267 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12215.FFNLayer = prim::GetAttr[name="1"](%4266)
  %4268 : __torch__.torch.nn.modules.container.___torch_mangle_12222.ModuleList = prim::GetAttr[name="ffn"](%82)
  %4269 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12209.FFNLayer = prim::GetAttr[name="0"](%4268)
  %4270 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12187.MobileBertAttention = prim::GetAttr[name="attention"](%82)
  %4271 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12203.Bottleneck = prim::GetAttr[name="bottleneck"](%82)
  %4272 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12202.BottleneckLayer = prim::GetAttr[name="attention"](%4271)
  %4273 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12199.BottleneckLayer = prim::GetAttr[name="input"](%4271)
  %4274 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12198.NoNorm = prim::GetAttr[name="LayerNorm"](%4273)
  %4275 : __torch__.torch.nn.modules.linear.___torch_mangle_12197.Linear = prim::GetAttr[name="dense"](%4273)
  %4276 : Tensor = prim::GetAttr[name="bias"](%4275)
  %4277 : Tensor = prim::GetAttr[name="weight"](%4275)
  %4278 : Float(512:1, 128:512) = aten::t(%4277), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.317 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4278), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.170 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.317, %4276, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4281 : Tensor = prim::GetAttr[name="bias"](%4274)
  %4282 : Tensor = prim::GetAttr[name="weight"](%4274)
  %4283 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.170, %4282), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.22 : Float(17:1664, 13:128, 128:1) = aten::add(%4283, %4281, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.input/__module.mobilebert.encoder.layer.21.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4285 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12201.NoNorm = prim::GetAttr[name="LayerNorm"](%4272)
  %4286 : __torch__.torch.nn.modules.linear.___torch_mangle_12200.Linear = prim::GetAttr[name="dense"](%4272)
  %4287 : Tensor = prim::GetAttr[name="bias"](%4286)
  %4288 : Tensor = prim::GetAttr[name="weight"](%4286)
  %4289 : Float(512:1, 128:512) = aten::t(%4288), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.318 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4289), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.171 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.318, %4287, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4292 : Tensor = prim::GetAttr[name="bias"](%4285)
  %4293 : Tensor = prim::GetAttr[name="weight"](%4285)
  %4294 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.171, %4293), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.407 : Float(17:1664, 13:128, 128:1) = aten::add(%4294, %4292, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.bottleneck/__module.mobilebert.encoder.layer.21.bottleneck.attention/__module.mobilebert.encoder.layer.21.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4296 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.407, %residual_tensor.22)
  %4297 : Float(17:1664, 13:128, 128:1), %4298 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4296)
  %4299 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12186.MobileBertSelfOutput = prim::GetAttr[name="output"](%4270)
  %4300 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12183.MobileBertSelfAttention = prim::GetAttr[name="self"](%4270)
  %4301 : __torch__.torch.nn.modules.linear.___torch_mangle_12181.Linear = prim::GetAttr[name="value"](%4300)
  %4302 : __torch__.torch.nn.modules.linear.___torch_mangle_12180.Linear = prim::GetAttr[name="key"](%4300)
  %4303 : __torch__.torch.nn.modules.linear.___torch_mangle_12179.Linear = prim::GetAttr[name="query"](%4300)
  %4304 : Tensor = prim::GetAttr[name="bias"](%4303)
  %4305 : Tensor = prim::GetAttr[name="weight"](%4303)
  %4306 : Float(128:1, 128:128) = aten::t(%4305), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %output.319 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4297, %4306), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1676:0
  %x.127 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.319, %4304, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.query # torch/nn/functional.py:1678:0
  %4309 : Tensor = prim::GetAttr[name="bias"](%4302)
  %4310 : Tensor = prim::GetAttr[name="weight"](%4302)
  %4311 : Float(128:1, 128:128) = aten::t(%4310), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %output.320 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4297, %4311), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1676:0
  %x.129 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.320, %4309, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.key # torch/nn/functional.py:1678:0
  %4314 : Tensor = prim::GetAttr[name="bias"](%4301)
  %4315 : Tensor = prim::GetAttr[name="weight"](%4301)
  %4316 : Float(512:1, 128:512) = aten::t(%4315), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %output.321 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.406, %4316), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1676:0
  %x.131 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.321, %4314, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.value # torch/nn/functional.py:1678:0
  %4319 : int = aten::size(%x.127, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4320 : int = aten::size(%x.127, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4321 : int[] = prim::ListConstruct(%4319, %4320, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.128 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.127, %4321), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4323 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %query_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.128, %4323), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4325 : int = aten::size(%x.129, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4326 : int = aten::size(%x.129, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4327 : int[] = prim::ListConstruct(%4325, %4326, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.130 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.129, %4327), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4329 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %key_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.130, %4329), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4331 : int = aten::size(%x.131, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4332 : int = aten::size(%x.131, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:243:0
  %4333 : int[] = prim::ListConstruct(%4331, %4332, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %x.132 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.131, %4333), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:244:0
  %4335 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %value_layer.22 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.132, %4335), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:245:0
  %4337 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.22, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.43 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.22, %4337), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.44 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.43, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.408 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.44, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.409 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.408, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.22 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.409, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self/__module.mobilebert.encoder.layer.21.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.43 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.22, %value_layer.22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:280:0
  %4344 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %4345 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.43, %4344), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.44 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4345, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:281:0
  %4347 : int = aten::size(%context_layer.44, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4348 : int = aten::size(%context_layer.44, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:282:0
  %4349 : int[] = prim::ListConstruct(%4347, %4348, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self
  %input.410 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.44, %4349), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.self # transformers/modeling_mobilebert.py:283:0
  %4351 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12185.NoNorm = prim::GetAttr[name="LayerNorm"](%4299)
  %4352 : __torch__.torch.nn.modules.linear.___torch_mangle_12184.Linear = prim::GetAttr[name="dense"](%4299)
  %4353 : Tensor = prim::GetAttr[name="bias"](%4352)
  %4354 : Tensor = prim::GetAttr[name="weight"](%4352)
  %4355 : Float(128:1, 128:128) = aten::t(%4354), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %output.322 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.410, %4355), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.106 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.322, %4353, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.172 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.106, %4298, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output # transformers/modeling_mobilebert.py:301:0
  %4359 : Tensor = prim::GetAttr[name="bias"](%4351)
  %4360 : Tensor = prim::GetAttr[name="weight"](%4351)
  %4361 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.172, %4360), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.411 : Float(17:1664, 13:128, 128:1) = aten::add(%4361, %4359, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.attention/__module.mobilebert.encoder.layer.21.attention.output/__module.mobilebert.encoder.layer.21.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4363 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12208.FFNOutput = prim::GetAttr[name="output"](%4269)
  %4364 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12205.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4269)
  %4365 : __torch__.torch.nn.modules.linear.___torch_mangle_12204.Linear = prim::GetAttr[name="dense"](%4364)
  %4366 : Tensor = prim::GetAttr[name="bias"](%4365)
  %4367 : Tensor = prim::GetAttr[name="weight"](%4365)
  %4368 : Float(128:1, 512:128) = aten::t(%4367), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.323 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.411, %4368), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.412 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.323, %4366, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate/__module.mobilebert.encoder.layer.21.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.413 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.412), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4372 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12207.NoNorm = prim::GetAttr[name="LayerNorm"](%4363)
  %4373 : __torch__.torch.nn.modules.linear.___torch_mangle_12206.Linear = prim::GetAttr[name="dense"](%4363)
  %4374 : Tensor = prim::GetAttr[name="bias"](%4373)
  %4375 : Tensor = prim::GetAttr[name="weight"](%4373)
  %4376 : Float(512:1, 128:512) = aten::t(%4375), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.324 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.413, %4376), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.107 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.324, %4374, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.173 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.107, %input.411, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4380 : Tensor = prim::GetAttr[name="bias"](%4372)
  %4381 : Tensor = prim::GetAttr[name="weight"](%4372)
  %4382 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.173, %4381), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.414 : Float(17:1664, 13:128, 128:1) = aten::add(%4382, %4380, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.0/__module.mobilebert.encoder.layer.21.ffn.0.output/__module.mobilebert.encoder.layer.21.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4384 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12214.FFNOutput = prim::GetAttr[name="output"](%4267)
  %4385 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12211.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4267)
  %4386 : __torch__.torch.nn.modules.linear.___torch_mangle_12210.Linear = prim::GetAttr[name="dense"](%4385)
  %4387 : Tensor = prim::GetAttr[name="bias"](%4386)
  %4388 : Tensor = prim::GetAttr[name="weight"](%4386)
  %4389 : Float(128:1, 512:128) = aten::t(%4388), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.325 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.414, %4389), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.415 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.325, %4387, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate/__module.mobilebert.encoder.layer.21.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.416 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.415), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4393 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12213.NoNorm = prim::GetAttr[name="LayerNorm"](%4384)
  %4394 : __torch__.torch.nn.modules.linear.___torch_mangle_12212.Linear = prim::GetAttr[name="dense"](%4384)
  %4395 : Tensor = prim::GetAttr[name="bias"](%4394)
  %4396 : Tensor = prim::GetAttr[name="weight"](%4394)
  %4397 : Float(512:1, 128:512) = aten::t(%4396), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.326 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.416, %4397), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.108 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.326, %4395, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.174 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.108, %input.414, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4401 : Tensor = prim::GetAttr[name="bias"](%4393)
  %4402 : Tensor = prim::GetAttr[name="weight"](%4393)
  %4403 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.174, %4402), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.417 : Float(17:1664, 13:128, 128:1) = aten::add(%4403, %4401, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.1/__module.mobilebert.encoder.layer.21.ffn.1.output/__module.mobilebert.encoder.layer.21.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4405 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12220.FFNOutput = prim::GetAttr[name="output"](%4265)
  %4406 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12217.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4265)
  %4407 : __torch__.torch.nn.modules.linear.___torch_mangle_12216.Linear = prim::GetAttr[name="dense"](%4406)
  %4408 : Tensor = prim::GetAttr[name="bias"](%4407)
  %4409 : Tensor = prim::GetAttr[name="weight"](%4407)
  %4410 : Float(128:1, 512:128) = aten::t(%4409), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.327 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.417, %4410), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.418 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.327, %4408, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate/__module.mobilebert.encoder.layer.21.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.419 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4414 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12219.NoNorm = prim::GetAttr[name="LayerNorm"](%4405)
  %4415 : __torch__.torch.nn.modules.linear.___torch_mangle_12218.Linear = prim::GetAttr[name="dense"](%4405)
  %4416 : Tensor = prim::GetAttr[name="bias"](%4415)
  %4417 : Tensor = prim::GetAttr[name="weight"](%4415)
  %4418 : Float(512:1, 128:512) = aten::t(%4417), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.328 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.419, %4418), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.109 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.328, %4416, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.175 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.109, %input.417, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4422 : Tensor = prim::GetAttr[name="bias"](%4414)
  %4423 : Tensor = prim::GetAttr[name="weight"](%4414)
  %4424 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.175, %4423), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.420 : Float(17:1664, 13:128, 128:1) = aten::add(%4424, %4422, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.ffn.2/__module.mobilebert.encoder.layer.21.ffn.2.output/__module.mobilebert.encoder.layer.21.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4426 : __torch__.torch.nn.modules.linear.___torch_mangle_12188.Linear = prim::GetAttr[name="dense"](%4263)
  %4427 : Tensor = prim::GetAttr[name="bias"](%4426)
  %4428 : Tensor = prim::GetAttr[name="weight"](%4426)
  %4429 : Float(128:1, 512:128) = aten::t(%4428), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %output.329 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.420, %4429), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1676:0
  %input.421 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.329, %4427, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate/__module.mobilebert.encoder.layer.21.intermediate.dense # torch/nn/functional.py:1678:0
  %input.422 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.421), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.intermediate # torch/nn/functional.py:1119:0
  %4433 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12195.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4262)
  %4434 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12191.NoNorm = prim::GetAttr[name="LayerNorm"](%4262)
  %4435 : __torch__.torch.nn.modules.linear.___torch_mangle_12190.Linear = prim::GetAttr[name="dense"](%4262)
  %4436 : Tensor = prim::GetAttr[name="bias"](%4435)
  %4437 : Tensor = prim::GetAttr[name="weight"](%4435)
  %4438 : Float(512:1, 128:512) = aten::t(%4437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %output.330 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.422, %4438), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1676:0
  %layer_output.22 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.330, %4436, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.176 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.22, %input.420, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output # transformers/modeling_mobilebert.py:405:0
  %4442 : Tensor = prim::GetAttr[name="bias"](%4434)
  %4443 : Tensor = prim::GetAttr[name="weight"](%4434)
  %4444 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.176, %4443), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.423 : Float(17:1664, 13:128, 128:1) = aten::add(%4444, %4442, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4446 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12193.NoNorm = prim::GetAttr[name="LayerNorm"](%4433)
  %4447 : __torch__.torch.nn.modules.linear.___torch_mangle_12192.Linear = prim::GetAttr[name="dense"](%4433)
  %4448 : Tensor = prim::GetAttr[name="bias"](%4447)
  %4449 : Tensor = prim::GetAttr[name="weight"](%4447)
  %4450 : Float(128:1, 512:128) = aten::t(%4449), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.331 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.423, %4450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.424 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.331, %4448, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.110 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.424, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.177 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.110, %input.406, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4455 : Tensor = prim::GetAttr[name="bias"](%4446)
  %4456 : Tensor = prim::GetAttr[name="weight"](%4446)
  %4457 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.177, %4456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.425 : Float(17:6656, 13:512, 512:1) = aten::add(%4457, %4455, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.21/__module.mobilebert.encoder.layer.21.output/__module.mobilebert.encoder.layer.21.output.bottleneck/__module.mobilebert.encoder.layer.21.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4459 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12241.MobileBertOutput = prim::GetAttr[name="output"](%80)
  %4460 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12234.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%80)
  %4461 : __torch__.torch.nn.modules.container.___torch_mangle_12267.ModuleList = prim::GetAttr[name="ffn"](%80)
  %4462 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12266.FFNLayer = prim::GetAttr[name="2"](%4461)
  %4463 : __torch__.torch.nn.modules.container.___torch_mangle_12267.ModuleList = prim::GetAttr[name="ffn"](%80)
  %4464 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12260.FFNLayer = prim::GetAttr[name="1"](%4463)
  %4465 : __torch__.torch.nn.modules.container.___torch_mangle_12267.ModuleList = prim::GetAttr[name="ffn"](%80)
  %4466 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12254.FFNLayer = prim::GetAttr[name="0"](%4465)
  %4467 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12232.MobileBertAttention = prim::GetAttr[name="attention"](%80)
  %4468 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12248.Bottleneck = prim::GetAttr[name="bottleneck"](%80)
  %4469 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12247.BottleneckLayer = prim::GetAttr[name="attention"](%4468)
  %4470 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12244.BottleneckLayer = prim::GetAttr[name="input"](%4468)
  %4471 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12243.NoNorm = prim::GetAttr[name="LayerNorm"](%4470)
  %4472 : __torch__.torch.nn.modules.linear.___torch_mangle_12242.Linear = prim::GetAttr[name="dense"](%4470)
  %4473 : Tensor = prim::GetAttr[name="bias"](%4472)
  %4474 : Tensor = prim::GetAttr[name="weight"](%4472)
  %4475 : Float(512:1, 128:512) = aten::t(%4474), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.332 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4475), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.178 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.332, %4473, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4478 : Tensor = prim::GetAttr[name="bias"](%4471)
  %4479 : Tensor = prim::GetAttr[name="weight"](%4471)
  %4480 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.178, %4479), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor.23 : Float(17:1664, 13:128, 128:1) = aten::add(%4480, %4478, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.input/__module.mobilebert.encoder.layer.22.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4482 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12246.NoNorm = prim::GetAttr[name="LayerNorm"](%4469)
  %4483 : __torch__.torch.nn.modules.linear.___torch_mangle_12245.Linear = prim::GetAttr[name="dense"](%4469)
  %4484 : Tensor = prim::GetAttr[name="bias"](%4483)
  %4485 : Tensor = prim::GetAttr[name="weight"](%4483)
  %4486 : Float(512:1, 128:512) = aten::t(%4485), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.333 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4486), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.179 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.333, %4484, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4489 : Tensor = prim::GetAttr[name="bias"](%4482)
  %4490 : Tensor = prim::GetAttr[name="weight"](%4482)
  %4491 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.179, %4490), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.426 : Float(17:1664, 13:128, 128:1) = aten::add(%4491, %4489, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.bottleneck/__module.mobilebert.encoder.layer.22.bottleneck.attention/__module.mobilebert.encoder.layer.22.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4493 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.426, %residual_tensor.23)
  %4494 : Float(17:1664, 13:128, 128:1), %4495 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4493)
  %4496 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12231.MobileBertSelfOutput = prim::GetAttr[name="output"](%4467)
  %4497 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12228.MobileBertSelfAttention = prim::GetAttr[name="self"](%4467)
  %4498 : __torch__.torch.nn.modules.linear.___torch_mangle_12226.Linear = prim::GetAttr[name="value"](%4497)
  %4499 : __torch__.torch.nn.modules.linear.___torch_mangle_12225.Linear = prim::GetAttr[name="key"](%4497)
  %4500 : __torch__.torch.nn.modules.linear.___torch_mangle_12224.Linear = prim::GetAttr[name="query"](%4497)
  %4501 : Tensor = prim::GetAttr[name="bias"](%4500)
  %4502 : Tensor = prim::GetAttr[name="weight"](%4500)
  %4503 : Float(128:1, 128:128) = aten::t(%4502), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %output.334 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4494, %4503), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1676:0
  %x.133 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.334, %4501, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.query # torch/nn/functional.py:1678:0
  %4506 : Tensor = prim::GetAttr[name="bias"](%4499)
  %4507 : Tensor = prim::GetAttr[name="weight"](%4499)
  %4508 : Float(128:1, 128:128) = aten::t(%4507), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %output.335 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4494, %4508), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1676:0
  %x.135 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.335, %4506, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.key # torch/nn/functional.py:1678:0
  %4511 : Tensor = prim::GetAttr[name="bias"](%4498)
  %4512 : Tensor = prim::GetAttr[name="weight"](%4498)
  %4513 : Float(512:1, 128:512) = aten::t(%4512), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %output.336 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.425, %4513), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1676:0
  %x.137 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.336, %4511, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.value # torch/nn/functional.py:1678:0
  %4516 : int = aten::size(%x.133, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4517 : int = aten::size(%x.133, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4518 : int[] = prim::ListConstruct(%4516, %4517, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.134 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.133, %4518), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4520 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %query_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.134, %4520), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4522 : int = aten::size(%x.135, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4523 : int = aten::size(%x.135, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4524 : int[] = prim::ListConstruct(%4522, %4523, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.136 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.135, %4524), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4526 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %key_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.136, %4526), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4528 : int = aten::size(%x.137, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4529 : int = aten::size(%x.137, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:243:0
  %4530 : int[] = prim::ListConstruct(%4528, %4529, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %x.138 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.137, %4530), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:244:0
  %4532 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %value_layer.23 : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.138, %4532), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:245:0
  %4534 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer.23, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.45 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer.23, %4534), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.46 : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.45, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.427 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores.46, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.428 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.427, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # torch/nn/functional.py:1498:0
  %attention_probs.23 : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.428, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self/__module.mobilebert.encoder.layer.22.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.45 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs.23, %value_layer.23), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:280:0
  %4541 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %4542 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.45, %4541), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer.46 : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4542, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:281:0
  %4544 : int = aten::size(%context_layer.46, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4545 : int = aten::size(%context_layer.46, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:282:0
  %4546 : int[] = prim::ListConstruct(%4544, %4545, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self
  %input.429 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer.46, %4546), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.self # transformers/modeling_mobilebert.py:283:0
  %4548 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12230.NoNorm = prim::GetAttr[name="LayerNorm"](%4496)
  %4549 : __torch__.torch.nn.modules.linear.___torch_mangle_12229.Linear = prim::GetAttr[name="dense"](%4496)
  %4550 : Tensor = prim::GetAttr[name="bias"](%4549)
  %4551 : Tensor = prim::GetAttr[name="weight"](%4549)
  %4552 : Float(128:1, 128:128) = aten::t(%4551), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %output.337 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.429, %4552), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.111 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.337, %4550, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.180 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.111, %4495, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output # transformers/modeling_mobilebert.py:301:0
  %4556 : Tensor = prim::GetAttr[name="bias"](%4548)
  %4557 : Tensor = prim::GetAttr[name="weight"](%4548)
  %4558 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.180, %4557), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.430 : Float(17:1664, 13:128, 128:1) = aten::add(%4558, %4556, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.attention/__module.mobilebert.encoder.layer.22.attention.output/__module.mobilebert.encoder.layer.22.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4560 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12253.FFNOutput = prim::GetAttr[name="output"](%4466)
  %4561 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12250.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4466)
  %4562 : __torch__.torch.nn.modules.linear.___torch_mangle_12249.Linear = prim::GetAttr[name="dense"](%4561)
  %4563 : Tensor = prim::GetAttr[name="bias"](%4562)
  %4564 : Tensor = prim::GetAttr[name="weight"](%4562)
  %4565 : Float(128:1, 512:128) = aten::t(%4564), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.338 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.430, %4565), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.431 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.338, %4563, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate/__module.mobilebert.encoder.layer.22.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.432 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.431), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4569 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12252.NoNorm = prim::GetAttr[name="LayerNorm"](%4560)
  %4570 : __torch__.torch.nn.modules.linear.___torch_mangle_12251.Linear = prim::GetAttr[name="dense"](%4560)
  %4571 : Tensor = prim::GetAttr[name="bias"](%4570)
  %4572 : Tensor = prim::GetAttr[name="weight"](%4570)
  %4573 : Float(512:1, 128:512) = aten::t(%4572), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.339 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.432, %4573), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.112 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.339, %4571, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.181 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.112, %input.430, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4577 : Tensor = prim::GetAttr[name="bias"](%4569)
  %4578 : Tensor = prim::GetAttr[name="weight"](%4569)
  %4579 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.181, %4578), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.433 : Float(17:1664, 13:128, 128:1) = aten::add(%4579, %4577, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.0/__module.mobilebert.encoder.layer.22.ffn.0.output/__module.mobilebert.encoder.layer.22.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4581 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12259.FFNOutput = prim::GetAttr[name="output"](%4464)
  %4582 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12256.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4464)
  %4583 : __torch__.torch.nn.modules.linear.___torch_mangle_12255.Linear = prim::GetAttr[name="dense"](%4582)
  %4584 : Tensor = prim::GetAttr[name="bias"](%4583)
  %4585 : Tensor = prim::GetAttr[name="weight"](%4583)
  %4586 : Float(128:1, 512:128) = aten::t(%4585), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.340 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.433, %4586), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.434 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.340, %4584, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate/__module.mobilebert.encoder.layer.22.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.435 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.434), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4590 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12258.NoNorm = prim::GetAttr[name="LayerNorm"](%4581)
  %4591 : __torch__.torch.nn.modules.linear.___torch_mangle_12257.Linear = prim::GetAttr[name="dense"](%4581)
  %4592 : Tensor = prim::GetAttr[name="bias"](%4591)
  %4593 : Tensor = prim::GetAttr[name="weight"](%4591)
  %4594 : Float(512:1, 128:512) = aten::t(%4593), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.341 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.435, %4594), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.113 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.341, %4592, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.182 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.113, %input.433, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4598 : Tensor = prim::GetAttr[name="bias"](%4590)
  %4599 : Tensor = prim::GetAttr[name="weight"](%4590)
  %4600 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.182, %4599), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.436 : Float(17:1664, 13:128, 128:1) = aten::add(%4600, %4598, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.1/__module.mobilebert.encoder.layer.22.ffn.1.output/__module.mobilebert.encoder.layer.22.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4602 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12265.FFNOutput = prim::GetAttr[name="output"](%4462)
  %4603 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12262.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4462)
  %4604 : __torch__.torch.nn.modules.linear.___torch_mangle_12261.Linear = prim::GetAttr[name="dense"](%4603)
  %4605 : Tensor = prim::GetAttr[name="bias"](%4604)
  %4606 : Tensor = prim::GetAttr[name="weight"](%4604)
  %4607 : Float(128:1, 512:128) = aten::t(%4606), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.342 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.436, %4607), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.437 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.342, %4605, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate/__module.mobilebert.encoder.layer.22.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.438 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.437), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4611 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12264.NoNorm = prim::GetAttr[name="LayerNorm"](%4602)
  %4612 : __torch__.torch.nn.modules.linear.___torch_mangle_12263.Linear = prim::GetAttr[name="dense"](%4602)
  %4613 : Tensor = prim::GetAttr[name="bias"](%4612)
  %4614 : Tensor = prim::GetAttr[name="weight"](%4612)
  %4615 : Float(512:1, 128:512) = aten::t(%4614), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.343 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.438, %4615), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.114 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.343, %4613, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.183 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.114, %input.436, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4619 : Tensor = prim::GetAttr[name="bias"](%4611)
  %4620 : Tensor = prim::GetAttr[name="weight"](%4611)
  %4621 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.183, %4620), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.439 : Float(17:1664, 13:128, 128:1) = aten::add(%4621, %4619, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.ffn.2/__module.mobilebert.encoder.layer.22.ffn.2.output/__module.mobilebert.encoder.layer.22.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4623 : __torch__.torch.nn.modules.linear.___torch_mangle_12233.Linear = prim::GetAttr[name="dense"](%4460)
  %4624 : Tensor = prim::GetAttr[name="bias"](%4623)
  %4625 : Tensor = prim::GetAttr[name="weight"](%4623)
  %4626 : Float(128:1, 512:128) = aten::t(%4625), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %output.344 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.439, %4626), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1676:0
  %input.440 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.344, %4624, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate/__module.mobilebert.encoder.layer.22.intermediate.dense # torch/nn/functional.py:1678:0
  %input.441 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.440), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.intermediate # torch/nn/functional.py:1119:0
  %4630 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12240.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4459)
  %4631 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12236.NoNorm = prim::GetAttr[name="LayerNorm"](%4459)
  %4632 : __torch__.torch.nn.modules.linear.___torch_mangle_12235.Linear = prim::GetAttr[name="dense"](%4459)
  %4633 : Tensor = prim::GetAttr[name="bias"](%4632)
  %4634 : Tensor = prim::GetAttr[name="weight"](%4632)
  %4635 : Float(512:1, 128:512) = aten::t(%4634), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %output.345 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.441, %4635), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1676:0
  %layer_output.23 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.345, %4633, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.184 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output.23, %input.439, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output # transformers/modeling_mobilebert.py:405:0
  %4639 : Tensor = prim::GetAttr[name="bias"](%4631)
  %4640 : Tensor = prim::GetAttr[name="weight"](%4631)
  %4641 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.184, %4640), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.442 : Float(17:1664, 13:128, 128:1) = aten::add(%4641, %4639, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4643 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12238.NoNorm = prim::GetAttr[name="LayerNorm"](%4630)
  %4644 : __torch__.torch.nn.modules.linear.___torch_mangle_12237.Linear = prim::GetAttr[name="dense"](%4630)
  %4645 : Tensor = prim::GetAttr[name="bias"](%4644)
  %4646 : Tensor = prim::GetAttr[name="weight"](%4644)
  %4647 : Float(128:1, 512:128) = aten::t(%4646), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.346 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.442, %4647), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.443 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.346, %4645, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs.115 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.443, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor.185 : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs.115, %input.425, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4652 : Tensor = prim::GetAttr[name="bias"](%4643)
  %4653 : Tensor = prim::GetAttr[name="weight"](%4643)
  %4654 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor.185, %4653), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.444 : Float(17:6656, 13:512, 512:1) = aten::add(%4654, %4652, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.22/__module.mobilebert.encoder.layer.22.output/__module.mobilebert.encoder.layer.22.output.bottleneck/__module.mobilebert.encoder.layer.22.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4656 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12286.MobileBertOutput = prim::GetAttr[name="output"](%78)
  %4657 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12279.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%78)
  %4658 : __torch__.torch.nn.modules.container.___torch_mangle_12312.ModuleList = prim::GetAttr[name="ffn"](%78)
  %4659 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12311.FFNLayer = prim::GetAttr[name="2"](%4658)
  %4660 : __torch__.torch.nn.modules.container.___torch_mangle_12312.ModuleList = prim::GetAttr[name="ffn"](%78)
  %4661 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12305.FFNLayer = prim::GetAttr[name="1"](%4660)
  %4662 : __torch__.torch.nn.modules.container.___torch_mangle_12312.ModuleList = prim::GetAttr[name="ffn"](%78)
  %4663 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12299.FFNLayer = prim::GetAttr[name="0"](%4662)
  %4664 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12277.MobileBertAttention = prim::GetAttr[name="attention"](%78)
  %4665 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12293.Bottleneck = prim::GetAttr[name="bottleneck"](%78)
  %4666 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12292.BottleneckLayer = prim::GetAttr[name="attention"](%4665)
  %4667 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12289.BottleneckLayer = prim::GetAttr[name="input"](%4665)
  %4668 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12288.NoNorm = prim::GetAttr[name="LayerNorm"](%4667)
  %4669 : __torch__.torch.nn.modules.linear.___torch_mangle_12287.Linear = prim::GetAttr[name="dense"](%4667)
  %4670 : Tensor = prim::GetAttr[name="bias"](%4669)
  %4671 : Tensor = prim::GetAttr[name="weight"](%4669)
  %4672 : Float(512:1, 128:512) = aten::t(%4671), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %output.347 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4672), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1676:0
  %input_tensor.186 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.347, %4670, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.dense # torch/nn/functional.py:1678:0
  %4675 : Tensor = prim::GetAttr[name="bias"](%4668)
  %4676 : Tensor = prim::GetAttr[name="weight"](%4668)
  %4677 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.186, %4676), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %residual_tensor : Float(17:1664, 13:128, 128:1) = aten::add(%4677, %4675, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.input/__module.mobilebert.encoder.layer.23.bottleneck.input.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4679 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12291.NoNorm = prim::GetAttr[name="LayerNorm"](%4666)
  %4680 : __torch__.torch.nn.modules.linear.___torch_mangle_12290.Linear = prim::GetAttr[name="dense"](%4666)
  %4681 : Tensor = prim::GetAttr[name="bias"](%4680)
  %4682 : Tensor = prim::GetAttr[name="weight"](%4680)
  %4683 : Float(512:1, 128:512) = aten::t(%4682), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %output.348 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4683), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1676:0
  %input_tensor.187 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.348, %4681, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.dense # torch/nn/functional.py:1678:0
  %4686 : Tensor = prim::GetAttr[name="bias"](%4679)
  %4687 : Tensor = prim::GetAttr[name="weight"](%4679)
  %4688 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.187, %4687), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.445 : Float(17:1664, 13:128, 128:1) = aten::add(%4688, %4686, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.bottleneck/__module.mobilebert.encoder.layer.23.bottleneck.attention/__module.mobilebert.encoder.layer.23.bottleneck.attention.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4690 : (Float(17:1664, 13:128, 128:1), Float(17:1664, 13:128, 128:1)) = prim::TupleConstruct(%input.445, %residual_tensor)
  %4691 : Float(17:1664, 13:128, 128:1), %4692 : Float(17:1664, 13:128, 128:1) = prim::TupleUnpack(%4690)
  %4693 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12276.MobileBertSelfOutput = prim::GetAttr[name="output"](%4664)
  %4694 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12273.MobileBertSelfAttention = prim::GetAttr[name="self"](%4664)
  %4695 : __torch__.torch.nn.modules.linear.___torch_mangle_12271.Linear = prim::GetAttr[name="value"](%4694)
  %4696 : __torch__.torch.nn.modules.linear.___torch_mangle_12270.Linear = prim::GetAttr[name="key"](%4694)
  %4697 : __torch__.torch.nn.modules.linear.___torch_mangle_12269.Linear = prim::GetAttr[name="query"](%4694)
  %4698 : Tensor = prim::GetAttr[name="bias"](%4697)
  %4699 : Tensor = prim::GetAttr[name="weight"](%4697)
  %4700 : Float(128:1, 128:128) = aten::t(%4699), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %output.349 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4691, %4700), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1676:0
  %x.139 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.349, %4698, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.query # torch/nn/functional.py:1678:0
  %4703 : Tensor = prim::GetAttr[name="bias"](%4696)
  %4704 : Tensor = prim::GetAttr[name="weight"](%4696)
  %4705 : Float(128:1, 128:128) = aten::t(%4704), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %output.350 : Float(17:1664, 13:128, 128:1) = aten::matmul(%4691, %4705), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1676:0
  %x.141 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.350, %4703, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.key # torch/nn/functional.py:1678:0
  %4708 : Tensor = prim::GetAttr[name="bias"](%4695)
  %4709 : Tensor = prim::GetAttr[name="weight"](%4695)
  %4710 : Float(512:1, 128:512) = aten::t(%4709), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %output.351 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.444, %4710), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1676:0
  %x.143 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.351, %4708, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.value # torch/nn/functional.py:1678:0
  %4713 : int = aten::size(%x.139, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4714 : int = aten::size(%x.139, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4715 : int[] = prim::ListConstruct(%4713, %4714, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.140 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.139, %4715), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4717 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %query_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.140, %4717), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4719 : int = aten::size(%x.141, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4720 : int = aten::size(%x.141, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4721 : int[] = prim::ListConstruct(%4719, %4720, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x.142 : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.141, %4721), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4723 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %key_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x.142, %4723), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4725 : int = aten::size(%x.143, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4726 : int = aten::size(%x.143, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:243:0
  %4727 : int[] = prim::ListConstruct(%4725, %4726, %24, %12), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %x : Float(17:1664, 13:128, 4:32, 32:1) = aten::view(%x.143, %4727), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:244:0
  %4729 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %value_layer : Float(17:1664, 4:32, 13:128, 32:1) = aten::permute(%x, %4729), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:245:0
  %4731 : Float(17:1664, 4:32, 32:1, 13:128) = aten::transpose(%key_layer, %13, %11), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores.47 : Float(17:676, 4:169, 13:13, 13:1) = aten::matmul(%query_layer, %4731), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:267:0
  %attention_scores : Float(17:676, 4:169, 13:13, 13:1) = aten::div(%attention_scores.47, %10), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:268:0
  %input.446 : Float(17:676, 4:169, 13:13, 13:1) = aten::add(%attention_scores, %attention_mask, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:271:0
  %input.447 : Float(17:676, 4:169, 13:13, 13:1) = aten::softmax(%input.446, %13, %17), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # torch/nn/functional.py:1498:0
  %attention_probs : Float(17:676, 4:169, 13:13, 13:1) = aten::dropout(%input.447, %9, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self/__module.mobilebert.encoder.layer.23.attention.self.dropout # torch/nn/functional.py:973:0
  %context_layer.47 : Float(17:1664, 4:416, 13:32, 32:1) = aten::matmul(%attention_probs, %value_layer), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:280:0
  %4738 : int[] = prim::ListConstruct(%26, %20, %25, %19), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %4739 : Float(17:1664, 13:32, 4:416, 32:1) = aten::permute(%context_layer.47, %4738), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %context_layer : Float(17:1664, 13:128, 4:32, 32:1) = aten::contiguous(%4739, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:281:0
  %4741 : int = aten::size(%context_layer, %26), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4742 : int = aten::size(%context_layer, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:282:0
  %4743 : int[] = prim::ListConstruct(%4741, %4742, %8), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self
  %input.448 : Float(17:1664, 13:128, 128:1) = aten::view(%context_layer, %4743), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.self # transformers/modeling_mobilebert.py:283:0
  %4745 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12275.NoNorm = prim::GetAttr[name="LayerNorm"](%4693)
  %4746 : __torch__.torch.nn.modules.linear.___torch_mangle_12274.Linear = prim::GetAttr[name="dense"](%4693)
  %4747 : Tensor = prim::GetAttr[name="bias"](%4746)
  %4748 : Tensor = prim::GetAttr[name="weight"](%4746)
  %4749 : Float(128:1, 128:128) = aten::t(%4748), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %output.352 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.448, %4749), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.116 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.352, %4747, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.188 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.116, %4692, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output # transformers/modeling_mobilebert.py:301:0
  %4753 : Tensor = prim::GetAttr[name="bias"](%4745)
  %4754 : Tensor = prim::GetAttr[name="weight"](%4745)
  %4755 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.188, %4754), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.449 : Float(17:1664, 13:128, 128:1) = aten::add(%4755, %4753, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.attention/__module.mobilebert.encoder.layer.23.attention.output/__module.mobilebert.encoder.layer.23.attention.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4757 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12298.FFNOutput = prim::GetAttr[name="output"](%4663)
  %4758 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12295.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4663)
  %4759 : __torch__.torch.nn.modules.linear.___torch_mangle_12294.Linear = prim::GetAttr[name="dense"](%4758)
  %4760 : Tensor = prim::GetAttr[name="bias"](%4759)
  %4761 : Tensor = prim::GetAttr[name="weight"](%4759)
  %4762 : Float(128:1, 512:128) = aten::t(%4761), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %output.353 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.449, %4762), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1676:0
  %input.450 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.353, %4760, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate/__module.mobilebert.encoder.layer.23.ffn.0.intermediate.dense # torch/nn/functional.py:1678:0
  %input.451 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.450), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.intermediate # torch/nn/functional.py:1119:0
  %4766 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12297.NoNorm = prim::GetAttr[name="LayerNorm"](%4757)
  %4767 : __torch__.torch.nn.modules.linear.___torch_mangle_12296.Linear = prim::GetAttr[name="dense"](%4757)
  %4768 : Tensor = prim::GetAttr[name="bias"](%4767)
  %4769 : Tensor = prim::GetAttr[name="weight"](%4767)
  %4770 : Float(512:1, 128:512) = aten::t(%4769), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %output.354 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.451, %4770), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.117 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.354, %4768, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.189 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.117, %input.449, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output # transformers/modeling_mobilebert.py:466:0
  %4774 : Tensor = prim::GetAttr[name="bias"](%4766)
  %4775 : Tensor = prim::GetAttr[name="weight"](%4766)
  %4776 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.189, %4775), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.452 : Float(17:1664, 13:128, 128:1) = aten::add(%4776, %4774, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.0/__module.mobilebert.encoder.layer.23.ffn.0.output/__module.mobilebert.encoder.layer.23.ffn.0.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4778 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12304.FFNOutput = prim::GetAttr[name="output"](%4661)
  %4779 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12301.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4661)
  %4780 : __torch__.torch.nn.modules.linear.___torch_mangle_12300.Linear = prim::GetAttr[name="dense"](%4779)
  %4781 : Tensor = prim::GetAttr[name="bias"](%4780)
  %4782 : Tensor = prim::GetAttr[name="weight"](%4780)
  %4783 : Float(128:1, 512:128) = aten::t(%4782), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %output.355 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.452, %4783), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1676:0
  %input.453 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.355, %4781, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate/__module.mobilebert.encoder.layer.23.ffn.1.intermediate.dense # torch/nn/functional.py:1678:0
  %input.454 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.453), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.intermediate # torch/nn/functional.py:1119:0
  %4787 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12303.NoNorm = prim::GetAttr[name="LayerNorm"](%4778)
  %4788 : __torch__.torch.nn.modules.linear.___torch_mangle_12302.Linear = prim::GetAttr[name="dense"](%4778)
  %4789 : Tensor = prim::GetAttr[name="bias"](%4788)
  %4790 : Tensor = prim::GetAttr[name="weight"](%4788)
  %4791 : Float(512:1, 128:512) = aten::t(%4790), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %output.356 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.454, %4791), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.118 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.356, %4789, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.190 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.118, %input.452, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output # transformers/modeling_mobilebert.py:466:0
  %4795 : Tensor = prim::GetAttr[name="bias"](%4787)
  %4796 : Tensor = prim::GetAttr[name="weight"](%4787)
  %4797 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.190, %4796), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.455 : Float(17:1664, 13:128, 128:1) = aten::add(%4797, %4795, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.1/__module.mobilebert.encoder.layer.23.ffn.1.output/__module.mobilebert.encoder.layer.23.ffn.1.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4799 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12310.FFNOutput = prim::GetAttr[name="output"](%4659)
  %4800 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12307.MobileBertIntermediate = prim::GetAttr[name="intermediate"](%4659)
  %4801 : __torch__.torch.nn.modules.linear.___torch_mangle_12306.Linear = prim::GetAttr[name="dense"](%4800)
  %4802 : Tensor = prim::GetAttr[name="bias"](%4801)
  %4803 : Tensor = prim::GetAttr[name="weight"](%4801)
  %4804 : Float(128:1, 512:128) = aten::t(%4803), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %output.357 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.455, %4804), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1676:0
  %input.456 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.357, %4802, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate/__module.mobilebert.encoder.layer.23.ffn.2.intermediate.dense # torch/nn/functional.py:1678:0
  %input.457 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.456), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.intermediate # torch/nn/functional.py:1119:0
  %4808 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12309.NoNorm = prim::GetAttr[name="LayerNorm"](%4799)
  %4809 : __torch__.torch.nn.modules.linear.___torch_mangle_12308.Linear = prim::GetAttr[name="dense"](%4799)
  %4810 : Tensor = prim::GetAttr[name="bias"](%4809)
  %4811 : Tensor = prim::GetAttr[name="weight"](%4809)
  %4812 : Float(512:1, 128:512) = aten::t(%4811), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %output.358 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.457, %4812), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1676:0
  %layer_outputs.119 : Float(17:1664, 13:128, 128:1) = aten::add_(%output.358, %4810, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.191 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_outputs.119, %input.455, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output # transformers/modeling_mobilebert.py:466:0
  %4816 : Tensor = prim::GetAttr[name="bias"](%4808)
  %4817 : Tensor = prim::GetAttr[name="weight"](%4808)
  %4818 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.191, %4817), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.458 : Float(17:1664, 13:128, 128:1) = aten::add(%4818, %4816, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.ffn.2/__module.mobilebert.encoder.layer.23.ffn.2.output/__module.mobilebert.encoder.layer.23.ffn.2.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4820 : __torch__.torch.nn.modules.linear.___torch_mangle_12278.Linear = prim::GetAttr[name="dense"](%4657)
  %4821 : Tensor = prim::GetAttr[name="bias"](%4820)
  %4822 : Tensor = prim::GetAttr[name="weight"](%4820)
  %4823 : Float(128:1, 512:128) = aten::t(%4822), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %output.359 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.458, %4823), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1676:0
  %input.459 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.359, %4821, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate/__module.mobilebert.encoder.layer.23.intermediate.dense # torch/nn/functional.py:1678:0
  %input.460 : Float(17:6656, 13:512, 512:1) = aten::relu(%input.459), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.intermediate # torch/nn/functional.py:1119:0
  %4827 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12285.OutputBottleneck = prim::GetAttr[name="bottleneck"](%4656)
  %4828 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12281.NoNorm = prim::GetAttr[name="LayerNorm"](%4656)
  %4829 : __torch__.torch.nn.modules.linear.___torch_mangle_12280.Linear = prim::GetAttr[name="dense"](%4656)
  %4830 : Tensor = prim::GetAttr[name="bias"](%4829)
  %4831 : Tensor = prim::GetAttr[name="weight"](%4829)
  %4832 : Float(512:1, 128:512) = aten::t(%4831), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %output.360 : Float(17:1664, 13:128, 128:1) = aten::matmul(%input.460, %4832), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1676:0
  %layer_output : Float(17:1664, 13:128, 128:1) = aten::add_(%output.360, %4830, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.dense # torch/nn/functional.py:1678:0
  %input_tensor.192 : Float(17:1664, 13:128, 128:1) = aten::add(%layer_output, %input.458, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output # transformers/modeling_mobilebert.py:405:0
  %4836 : Tensor = prim::GetAttr[name="bias"](%4828)
  %4837 : Tensor = prim::GetAttr[name="weight"](%4828)
  %4838 : Float(17:1664, 13:128, 128:1) = aten::mul(%input_tensor.192, %4837), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.461 : Float(17:1664, 13:128, 128:1) = aten::add(%4838, %4836, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4840 : __torch__.transformers.modeling_mobilebert.___torch_mangle_12283.NoNorm = prim::GetAttr[name="LayerNorm"](%4827)
  %4841 : __torch__.torch.nn.modules.linear.___torch_mangle_12282.Linear = prim::GetAttr[name="dense"](%4827)
  %4842 : Tensor = prim::GetAttr[name="bias"](%4841)
  %4843 : Tensor = prim::GetAttr[name="weight"](%4841)
  %4844 : Float(128:1, 512:128) = aten::t(%4843), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %output.361 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.461, %4844), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1676:0
  %input.462 : Float(17:6656, 13:512, 512:1) = aten::add_(%output.361, %4842, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dense # torch/nn/functional.py:1678:0
  %layer_outputs : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.462, %14, %22), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.dropout # torch/nn/functional.py:973:0
  %input_tensor : Float(17:6656, 13:512, 512:1) = aten::add(%layer_outputs, %input.444, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck # transformers/modeling_mobilebert.py:384:0
  %4849 : Tensor = prim::GetAttr[name="bias"](%4840)
  %4850 : Tensor = prim::GetAttr[name="weight"](%4840)
  %4851 : Float(17:6656, 13:512, 512:1) = aten::mul(%input_tensor, %4850), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %input.463 : Float(17:6656, 13:512, 512:1) = aten::add(%4851, %4849, %25), scope: __module.mobilebert/__module.mobilebert.encoder/__module.mobilebert.encoder.layer.23/__module.mobilebert.encoder.layer.23.output/__module.mobilebert.encoder.layer.23.output.bottleneck/__module.mobilebert.encoder.layer.23.output.bottleneck.LayerNorm # transformers/modeling_mobilebert.py:154:0
  %4853 : int = prim::Constant[value=512](), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm # torch/nn/functional.py:2048:0
  %4854 : float = prim::Constant[value=9.9999999999999998e-13](), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm # torch/nn/functional.py:2048:0
  %4855 : bool = prim::Constant[value=1](), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm # torch/nn/functional.py:2048:0
  %4856 : int = prim::Constant[value=1](), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.dense # torch/nn/functional.py:1678:0
  %4857 : int = prim::Constant[value=0](), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:643:0
  %4858 : __torch__.transformers.modeling_mobilebert.MobileBertLMPredictionHead = prim::GetAttr[name="predictions"](%3)
  %4859 : Tensor = prim::GetAttr[name="bias"](%4858)
  %4860 : __torch__.torch.nn.modules.linear.___torch_mangle_12317.Linear = prim::GetAttr[name="dense"](%4858)
  %4861 : Tensor = prim::GetAttr[name="weight"](%4860)
  %4862 : __torch__.torch.nn.modules.linear.___torch_mangle_12318.Linear = prim::GetAttr[name="decoder"](%4858)
  %4863 : Tensor = prim::GetAttr[name="weight"](%4862)
  %4864 : __torch__.transformers.modeling_mobilebert.MobileBertPredictionHeadTransform = prim::GetAttr[name="transform"](%4858)
  %4865 : __torch__.torch.nn.modules.normalization.___torch_mangle_12316.LayerNorm = prim::GetAttr[name="LayerNorm"](%4864)
  %4866 : __torch__.torch.nn.modules.linear.___torch_mangle_12315.Linear = prim::GetAttr[name="dense"](%4864)
  %4867 : Tensor = prim::GetAttr[name="bias"](%4866)
  %4868 : Tensor = prim::GetAttr[name="weight"](%4866)
  %4869 : Float(512:1, 512:512) = aten::t(%4868), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.dense # torch/nn/functional.py:1676:0
  %output : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.463, %4869), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.dense # torch/nn/functional.py:1676:0
  %input.464 : Float(17:6656, 13:512, 512:1) = aten::add_(%output, %4867, %4856), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.dense # torch/nn/functional.py:1678:0
  %input : Float(17:6656, 13:512, 512:1) = aten::relu(%input.464), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform # torch/nn/functional.py:1119:0
  %4873 : Tensor = prim::GetAttr[name="bias"](%4865)
  %4874 : Tensor = prim::GetAttr[name="weight"](%4865)
  %4875 : int[] = prim::ListConstruct(%4853), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm
  %hidden_states.1 : Float(17:6656, 13:512, 512:1) = aten::layer_norm(%input, %4875, %4874, %4873, %4854, %4855), scope: __module.cls/__module.cls.predictions/__module.cls.predictions.transform/__module.cls.predictions.transform.LayerNorm # torch/nn/functional.py:2048:0
  %4877 : Float(128:1, 30522:128) = aten::t(%4863), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:643:0
  %4878 : Tensor[] = prim::ListConstruct(%4877, %4861), scope: __module.cls/__module.cls.predictions
  %4879 : Float(512:30522, 30522:1) = aten::cat(%4878, %4857), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:643:0
  %hidden_states : Float(17:396786, 13:30522, 30522:1) = aten::matmul(%hidden_states.1, %4879), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:643:0
  %4881 : Float(17:396786, 13:30522, 30522:1) = aten::add_(%hidden_states, %4859, %4856), scope: __module.cls/__module.cls.predictions # transformers/modeling_mobilebert.py:644:0
  %7 : (Float(17:396786, 13:30522, 30522:1)) = prim::TupleConstruct(%4881)
  return (%7)
