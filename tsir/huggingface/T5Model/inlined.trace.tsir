graph(%self.1 : __torch__.transformers.modeling_t5.T5Model,
      %input_ids : Long(17:13, 13:1),
      %attention_mask.1 : Long(17:13, 13:1)):
  %3 : __torch__.transformers.modeling_t5.___torch_mangle_34488.T5Stack = prim::GetAttr[name="decoder"](%self.1)
  %4 : __torch__.transformers.modeling_t5.___torch_mangle_34488.T5Stack = prim::GetAttr[name="decoder"](%self.1)
  %5 : __torch__.torch.nn.modules.sparse.___torch_mangle_34332.Embedding = prim::GetAttr[name="embed_tokens"](%4)
  %6 : __torch__.transformers.modeling_t5.___torch_mangle_34331.T5Stack = prim::GetAttr[name="encoder"](%self.1)
  %7 : __torch__.torch.nn.modules.sparse.___torch_mangle_34223.Embedding = prim::GetAttr[name="shared"](%self.1)
  %8 : Tensor = prim::GetAttr[name="weight"](%7)
  %44 : int = prim::Constant[value=8](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %45 : int = prim::Constant[value=64](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %46 : int = prim::Constant[value=4](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:291:0
  %47 : Device = prim::Constant[value="cpu"](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:291:0
  %48 : Long() = prim::Constant[value={16}](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:270:0
  %49 : Long() = prim::Constant[value={0}](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:270:0
  %50 : Long() = prim::Constant[value={8}](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %51 : Double() = prim::Constant[value={2.77259}](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %52 : int = prim::Constant[value=15](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:284:0
  %53 : int = prim::Constant[value=512](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %54 : bool = prim::Constant[value=1](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %55 : Double() = prim::Constant[value={1e-06}](), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %56 : float = prim::Constant[value=0.10000000000000001](), scope: __module.encoder/__module.encoder.dropout # torch/nn/functional.py:973:0
  %57 : Double() = prim::Constant[value={-10000}](), scope: __module.encoder # transformers/modeling_utils.py:258:0
  %58 : float = prim::Constant[value=1.](), scope: __module.encoder # torch/tensor.py:396:0
  %59 : None = prim::Constant(), scope: __module.encoder
  %60 : int = prim::Constant[value=6](), scope: __module.encoder # transformers/modeling_utils.py:257:0
  %61 : int = prim::Constant[value=3](), scope: __module.encoder # transformers/modeling_utils.py:244:0
  %62 : int = prim::Constant[value=2](), scope: __module.encoder # transformers/modeling_utils.py:244:0
  %63 : int = prim::Constant[value=9223372036854775807](), scope: __module.encoder # transformers/modeling_utils.py:244:0
  %64 : int = prim::Constant[value=0](), scope: __module.encoder # transformers/modeling_utils.py:244:0
  %65 : bool = prim::Constant[value=0](), scope: __module.encoder/__module.decoder.embed_tokens # torch/nn/functional.py:1814:0
  %66 : int = prim::Constant[value=-1](), scope: __module.encoder # transformers/modeling_t5.py:694:0
  %67 : int = prim::Constant[value=1](), scope: __module.encoder # transformers/modeling_t5.py:693:0
  %68 : __torch__.transformers.modeling_t5.___torch_mangle_34329.T5LayerNorm = prim::GetAttr[name="final_layer_norm"](%6)
  %69 : __torch__.torch.nn.modules.container.___torch_mangle_34328.ModuleList = prim::GetAttr[name="block"](%6)
  %70 : __torch__.transformers.modeling_t5.___torch_mangle_34327.T5Block = prim::GetAttr[name="5"](%69)
  %71 : __torch__.torch.nn.modules.container.___torch_mangle_34328.ModuleList = prim::GetAttr[name="block"](%6)
  %72 : __torch__.transformers.modeling_t5.___torch_mangle_34310.T5Block = prim::GetAttr[name="4"](%71)
  %73 : __torch__.torch.nn.modules.container.___torch_mangle_34328.ModuleList = prim::GetAttr[name="block"](%6)
  %74 : __torch__.transformers.modeling_t5.___torch_mangle_34293.T5Block = prim::GetAttr[name="3"](%73)
  %75 : __torch__.torch.nn.modules.container.___torch_mangle_34328.ModuleList = prim::GetAttr[name="block"](%6)
  %76 : __torch__.transformers.modeling_t5.___torch_mangle_34276.T5Block = prim::GetAttr[name="2"](%75)
  %77 : __torch__.torch.nn.modules.container.___torch_mangle_34328.ModuleList = prim::GetAttr[name="block"](%6)
  %78 : __torch__.transformers.modeling_t5.___torch_mangle_34259.T5Block = prim::GetAttr[name="1"](%77)
  %79 : __torch__.torch.nn.modules.container.___torch_mangle_34328.ModuleList = prim::GetAttr[name="block"](%6)
  %80 : __torch__.transformers.modeling_t5.___torch_mangle_34242.T5Block = prim::GetAttr[name="0"](%79)
  %81 : int = aten::size(%input_ids, %67), scope: __module.encoder # transformers/modeling_t5.py:693:0
  %82 : int[] = prim::ListConstruct(%66, %81), scope: __module.encoder
  %input.1 : Long(17:13, 13:1) = aten::view(%input_ids, %82), scope: __module.encoder # transformers/modeling_t5.py:694:0
  %input.2 : Float(17:6656, 13:512, 512:1) = aten::embedding(%8, %input.1, %66, %65, %65), scope: __module.encoder/__module.decoder.embed_tokens # torch/nn/functional.py:1814:0
  %85 : Long(17:13, 13:1) = aten::slice(%attention_mask.1, %64, %64, %63, %67), scope: __module.encoder # transformers/modeling_utils.py:244:0
  %86 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%85, %67), scope: __module.encoder # transformers/modeling_utils.py:244:0
  %87 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%86, %62), scope: __module.encoder # transformers/modeling_utils.py:244:0
  %extended_attention_mask.1 : Long(17:13, 1:13, 1:13, 13:1) = aten::slice(%87, %61, %64, %63, %67), scope: __module.encoder # transformers/modeling_utils.py:244:0
  %89 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%extended_attention_mask.1, %60, %65, %65, %59), scope: __module.encoder # transformers/modeling_utils.py:257:0
  %90 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%89, %58, %67), scope: __module.encoder # torch/tensor.py:396:0
  %mask.1 : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%90, %57), scope: __module.encoder # transformers/modeling_utils.py:258:0
  %x.1 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.2, %56, %65), scope: __module.encoder/__module.encoder.dropout # torch/nn/functional.py:973:0
  %93 : __torch__.torch.nn.modules.container.___torch_mangle_34241.ModuleList = prim::GetAttr[name="layer"](%80)
  %94 : __torch__.transformers.modeling_t5.___torch_mangle_34240.T5LayerFF = prim::GetAttr[name="1"](%93)
  %95 : __torch__.torch.nn.modules.container.___torch_mangle_34241.ModuleList = prim::GetAttr[name="layer"](%80)
  %96 : __torch__.transformers.modeling_t5.___torch_mangle_34233.T5LayerSelfAttention = prim::GetAttr[name="0"](%95)
  %97 : __torch__.transformers.modeling_t5.___torch_mangle_34230.T5Attention = prim::GetAttr[name="SelfAttention"](%96)
  %98 : __torch__.transformers.modeling_t5.___torch_mangle_34231.T5LayerNorm = prim::GetAttr[name="layer_norm"](%96)
  %99 : Tensor = prim::GetAttr[name="weight"](%98)
  %x.2 : Float(17:6656, 13:512, 512:1) = aten::to(%x.1, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %101 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.2, %62), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %102 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm
  %variance.1 : Float(17:13, 13:1, 1:1) = aten::mean(%101, %102, %54, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %104 : Float(17:13, 13:1, 1:1) = aten::add(%variance.1, %55, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %105 : Float(17:13, 13:1, 1:1) = aten::sqrt(%104), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.3 : Float(17:6656, 13:512, 512:1) = aten::div(%x.2, %105), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.3 : Float(17:6656, 13:512, 512:1) = aten::mul(%99, %x.3), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %108 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.3, %x.2)
  %109 : Float(17:6656, 13:512, 512:1), %110 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%108)
  %111 : __torch__.torch.nn.modules.linear.___torch_mangle_34228.Linear = prim::GetAttr[name="o"](%97)
  %112 : __torch__.torch.nn.modules.sparse.___torch_mangle_34229.Embedding = prim::GetAttr[name="relative_attention_bias"](%97)
  %113 : __torch__.torch.nn.modules.linear.___torch_mangle_34227.Linear = prim::GetAttr[name="v"](%97)
  %114 : __torch__.torch.nn.modules.linear.___torch_mangle_34226.Linear = prim::GetAttr[name="k"](%97)
  %115 : __torch__.torch.nn.modules.linear.___torch_mangle_34225.Linear = prim::GetAttr[name="q"](%97)
  %116 : int = aten::size(%109, %64), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %117 : int = aten::size(%109, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %118 : Tensor = prim::GetAttr[name="weight"](%115)
  %119 : Float(512:1, 512:512) = aten::t(%118), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention/__module.encoder.block.0.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.4 : Float(17:6656, 13:512, 512:1) = aten::matmul(%109, %119), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention/__module.encoder.block.0.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %121 : int[] = prim::ListConstruct(%116, %66, %44, %45), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention
  %122 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.4, %121), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.1 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%122, %67, %62), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %124 : Tensor = prim::GetAttr[name="weight"](%114)
  %125 : Float(512:1, 512:512) = aten::t(%124), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention/__module.encoder.block.0.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.5 : Float(17:6656, 13:512, 512:1) = aten::matmul(%109, %125), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention/__module.encoder.block.0.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %127 : int[] = prim::ListConstruct(%116, %66, %44, %45), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention
  %128 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.5, %127), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.1 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%128, %67, %62), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %130 : Tensor = prim::GetAttr[name="weight"](%113)
  %131 : Float(512:1, 512:512) = aten::t(%130), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention/__module.encoder.block.0.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.6 : Float(17:6656, 13:512, 512:1) = aten::matmul(%109, %131), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention/__module.encoder.block.0.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %133 : int[] = prim::ListConstruct(%116, %66, %44, %45), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention
  %134 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.6, %133), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.1 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%134, %67, %62), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %136 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.1, %61, %62), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.1 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.1, %136), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %138 : Long(13:1) = aten::arange(%117, %46, %64, %47, %65), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:291:0
  %139 : Long(13:1) = aten::slice(%138, %64, %64, %63, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:291:0
  %context_position.1 : Long(13:1, 1:1) = aten::unsqueeze(%139, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:291:0
  %141 : Long(13:1) = aten::arange(%117, %46, %64, %47, %65), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:292:0
  %142 : Long(1:13, 13:1) = aten::unsqueeze(%141, %64), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:292:0
  %memory_position.1 : Long(1:13, 13:1) = aten::slice(%142, %67, %64, %63, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:292:0
  %relative_position.1 : Long(13:13, 13:1) = aten::sub(%memory_position.1, %context_position.1, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:293:0
  %n.1 : Long(13:13, 13:1) = aten::neg(%relative_position.1), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:267:0
  %146 : Bool(13:13, 13:1) = aten::lt(%n.1, %64), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # torch/tensor.py:22:0
  %147 : Long(13:13, 13:1) = aten::to(%146, %46, %65, %65, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:270:0
  %148 : Long(13:13, 13:1) = aten::mul(%147, %48), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:270:0
  %ret : Long(13:13, 13:1) = aten::add(%148, %49, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:270:0
  %n.2 : Long(13:13, 13:1) = aten::abs(%n.1), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:271:0
  %is_small.1 : Bool(13:13, 13:1) = aten::lt(%n.2, %44), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # torch/tensor.py:22:0
  %152 : Float(13:13, 13:1) = aten::to(%n.2, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %153 : Float(13:13, 13:1) = aten::div(%152, %50), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %154 : Float(13:13, 13:1) = aten::log(%153), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %155 : Float(13:13, 13:1) = aten::div(%154, %51), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %156 : Float(13:13, 13:1) = aten::mul(%155, %50), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %157 : Long(13:13, 13:1) = aten::to(%156, %46, %65, %65, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:281:0
  %val_if_large.1 : Long(13:13, 13:1) = aten::add(%157, %50, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:281:0
  %159 : Long(13:13, 13:1) = aten::full_like(%val_if_large.1, %52, %46, %64, %47, %65, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:284:0
  %val_if_large.2 : Long(13:13, 13:1) = aten::min(%val_if_large.1, %159), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:284:0
  %161 : Long(13:13, 13:1) = aten::where(%is_small.1, %n.2, %val_if_large.2), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:286:0
  %rp_bucket.1 : Long(13:13, 13:1) = aten::add_(%ret, %161, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:286:0
  %input.4 : Long(13:13, 13:1) = aten::to(%rp_bucket.1, %46, %64, %47, %65, %65, %65, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:299:0
  %164 : Tensor = prim::GetAttr[name="weight"](%112)
  %values.1 : Float(13:104, 13:8, 8:1) = aten::embedding(%164, %input.4, %66, %65, %65), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention/__module.encoder.block.0.layer.0.SelfAttention.relative_attention_bias # torch/nn/functional.py:1814:0
  %166 : int[] = prim::ListConstruct(%62, %64, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention
  %167 : Float(8:1, 13:104, 13:8) = aten::permute(%values.1, %166), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:301:0
  %position_bias.1 : Float(1:8, 8:1, 13:104, 13:8) = aten::unsqueeze(%167, %64), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:301:0
  %position_bias.2 : Float(17:1352, 8:1, 13:104, 13:8) = aten::add(%position_bias.1, %mask.1, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:387:0
  %scores.2 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.1, %position_bias.2, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.5 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.2, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %172 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.5, %66, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.1 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%172, %56, %65), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.7 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.1, %v.1), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %175 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.7, %67, %62), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %176 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%175, %64), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %177 : int[] = prim::ListConstruct(%116, %66, %53), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention
  %input.7 : Float(17:6656, 13:512, 512:1) = aten::view(%176, %177), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %179 : Tensor = prim::GetAttr[name="weight"](%111)
  %180 : Float(512:1, 512:512) = aten::t(%179), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention/__module.encoder.block.0.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.8 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.7, %180), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.SelfAttention/__module.encoder.block.0.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %182 : (Float(17:6656, 13:512, 512:1), Float(17:1352, 8:1, 13:104, 13:8)) = prim::TupleConstruct(%input.8, %position_bias.2)
  %183 : Float(17:6656, 13:512, 512:1), %184 : Float(17:1352, 8:1, 13:104, 13:8) = prim::TupleUnpack(%182)
  %y.1 : Float(17:6656, 13:512, 512:1) = aten::dropout(%183, %56, %65), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0/__module.encoder.block.0.layer.0.dropout # torch/nn/functional.py:973:0
  %x.8 : Float(17:6656, 13:512, 512:1) = aten::add(%110, %y.1, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.0 # transformers/modeling_t5.py:439:0
  %187 : (Float(17:6656, 13:512, 512:1), Float(17:1352, 8:1, 13:104, 13:8)) = prim::TupleConstruct(%x.8, %184)
  %188 : Float(17:6656, 13:512, 512:1), %189 : Float(17:1352, 8:1, 13:104, 13:8) = prim::TupleUnpack(%187)
  %190 : __torch__.transformers.modeling_t5.___torch_mangle_34237.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%94)
  %191 : __torch__.transformers.modeling_t5.___torch_mangle_34238.T5LayerNorm = prim::GetAttr[name="layer_norm"](%94)
  %192 : Tensor = prim::GetAttr[name="weight"](%191)
  %x.9 : Float(17:6656, 13:512, 512:1) = aten::to(%188, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %194 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.9, %62), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %195 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.layer_norm
  %variance.2 : Float(17:13, 13:1, 1:1) = aten::mean(%194, %195, %54, %59), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %197 : Float(17:13, 13:1, 1:1) = aten::add(%variance.2, %55, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %198 : Float(17:13, 13:1, 1:1) = aten::sqrt(%197), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.10 : Float(17:6656, 13:512, 512:1) = aten::div(%x.9, %198), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.9 : Float(17:6656, 13:512, 512:1) = aten::mul(%192, %x.10), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %201 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.9, %x.9)
  %202 : Float(17:6656, 13:512, 512:1), %203 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%201)
  %204 : __torch__.torch.nn.modules.linear.___torch_mangle_34235.Linear = prim::GetAttr[name="wo"](%190)
  %205 : __torch__.torch.nn.modules.linear.___torch_mangle_34234.Linear = prim::GetAttr[name="wi"](%190)
  %206 : Tensor = prim::GetAttr[name="weight"](%205)
  %207 : Float(512:1, 2048:512) = aten::t(%206), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.DenseReluDense/__module.encoder.block.0.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.10 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%202, %207), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.DenseReluDense/__module.encoder.block.0.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.11 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.10), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.DenseReluDense # torch/nn/functional.py:1119:0
  %input.12 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.11, %56, %65), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.DenseReluDense/__module.encoder.block.0.layer.1.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %211 : Tensor = prim::GetAttr[name="weight"](%204)
  %212 : Float(2048:1, 512:2048) = aten::t(%211), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.DenseReluDense/__module.encoder.block.0.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.13 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.12, %212), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.DenseReluDense/__module.encoder.block.0.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.2 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.13, %56, %65), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1/__module.encoder.block.0.layer.1.dropout # torch/nn/functional.py:973:0
  %x.11 : Float(17:6656, 13:512, 512:1) = aten::add(%203, %y.2, %67), scope: __module.encoder/__module.encoder.block.0/__module.encoder.block.0.layer.1 # transformers/modeling_t5.py:200:0
  %216 : (Float(17:6656, 13:512, 512:1), Float(17:1352, 8:1, 13:104, 13:8)) = prim::TupleConstruct(%x.11, %189)
  %217 : Float(17:6656, 13:512, 512:1), %218 : Float(17:1352, 8:1, 13:104, 13:8) = prim::TupleUnpack(%216)
  %219 : __torch__.torch.nn.modules.container.___torch_mangle_34258.ModuleList = prim::GetAttr[name="layer"](%78)
  %220 : __torch__.transformers.modeling_t5.___torch_mangle_34257.T5LayerFF = prim::GetAttr[name="1"](%219)
  %221 : __torch__.torch.nn.modules.container.___torch_mangle_34258.ModuleList = prim::GetAttr[name="layer"](%78)
  %222 : __torch__.transformers.modeling_t5.___torch_mangle_34250.T5LayerSelfAttention = prim::GetAttr[name="0"](%221)
  %223 : __torch__.transformers.modeling_t5.___torch_mangle_34247.T5Attention = prim::GetAttr[name="SelfAttention"](%222)
  %224 : __torch__.transformers.modeling_t5.___torch_mangle_34248.T5LayerNorm = prim::GetAttr[name="layer_norm"](%222)
  %225 : Tensor = prim::GetAttr[name="weight"](%224)
  %x.12 : Float(17:6656, 13:512, 512:1) = aten::to(%217, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %227 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.12, %62), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %228 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.layer_norm
  %variance.3 : Float(17:13, 13:1, 1:1) = aten::mean(%227, %228, %54, %59), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %230 : Float(17:13, 13:1, 1:1) = aten::add(%variance.3, %55, %67), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %231 : Float(17:13, 13:1, 1:1) = aten::sqrt(%230), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.13 : Float(17:6656, 13:512, 512:1) = aten::div(%x.12, %231), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.14 : Float(17:6656, 13:512, 512:1) = aten::mul(%225, %x.13), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %234 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.14, %x.12)
  %235 : Float(17:6656, 13:512, 512:1), %236 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%234)
  %237 : __torch__.torch.nn.modules.linear.___torch_mangle_34246.Linear = prim::GetAttr[name="o"](%223)
  %238 : __torch__.torch.nn.modules.linear.___torch_mangle_34245.Linear = prim::GetAttr[name="v"](%223)
  %239 : __torch__.torch.nn.modules.linear.___torch_mangle_34244.Linear = prim::GetAttr[name="k"](%223)
  %240 : __torch__.torch.nn.modules.linear.___torch_mangle_34243.Linear = prim::GetAttr[name="q"](%223)
  %241 : int = aten::size(%235, %64), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %242 : Tensor = prim::GetAttr[name="weight"](%240)
  %243 : Float(512:1, 512:512) = aten::t(%242), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention/__module.encoder.block.1.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.14 : Float(17:6656, 13:512, 512:1) = aten::matmul(%235, %243), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention/__module.encoder.block.1.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %245 : int[] = prim::ListConstruct(%241, %66, %44, %45), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention
  %246 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.14, %245), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.2 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%246, %67, %62), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %248 : Tensor = prim::GetAttr[name="weight"](%239)
  %249 : Float(512:1, 512:512) = aten::t(%248), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention/__module.encoder.block.1.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.15 : Float(17:6656, 13:512, 512:1) = aten::matmul(%235, %249), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention/__module.encoder.block.1.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %251 : int[] = prim::ListConstruct(%241, %66, %44, %45), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention
  %252 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.15, %251), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.2 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%252, %67, %62), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %254 : Tensor = prim::GetAttr[name="weight"](%238)
  %255 : Float(512:1, 512:512) = aten::t(%254), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention/__module.encoder.block.1.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.16 : Float(17:6656, 13:512, 512:1) = aten::matmul(%235, %255), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention/__module.encoder.block.1.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %257 : int[] = prim::ListConstruct(%241, %66, %44, %45), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention
  %258 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.16, %257), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.2 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%258, %67, %62), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %260 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.2, %61, %62), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.3 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.2, %260), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.4 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.3, %218, %67), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.15 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.4, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %264 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.15, %66, %59), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.2 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%264, %56, %65), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.17 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.2, %v.2), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %267 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.17, %67, %62), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %268 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%267, %64), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %269 : int[] = prim::ListConstruct(%241, %66, %53), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention
  %input.17 : Float(17:6656, 13:512, 512:1) = aten::view(%268, %269), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %271 : Tensor = prim::GetAttr[name="weight"](%237)
  %272 : Float(512:1, 512:512) = aten::t(%271), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention/__module.encoder.block.1.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.18 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.17, %272), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.SelfAttention/__module.encoder.block.1.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %y.3 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.18, %56, %65), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0/__module.encoder.block.1.layer.0.dropout # torch/nn/functional.py:973:0
  %x.18 : Float(17:6656, 13:512, 512:1) = aten::add(%236, %y.3, %67), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.0 # transformers/modeling_t5.py:439:0
  %276 : __torch__.transformers.modeling_t5.___torch_mangle_34254.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%220)
  %277 : __torch__.transformers.modeling_t5.___torch_mangle_34255.T5LayerNorm = prim::GetAttr[name="layer_norm"](%220)
  %278 : Tensor = prim::GetAttr[name="weight"](%277)
  %x.19 : Float(17:6656, 13:512, 512:1) = aten::to(%x.18, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %280 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.19, %62), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %281 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.layer_norm
  %variance.4 : Float(17:13, 13:1, 1:1) = aten::mean(%280, %281, %54, %59), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %283 : Float(17:13, 13:1, 1:1) = aten::add(%variance.4, %55, %67), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %284 : Float(17:13, 13:1, 1:1) = aten::sqrt(%283), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.20 : Float(17:6656, 13:512, 512:1) = aten::div(%x.19, %284), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.19 : Float(17:6656, 13:512, 512:1) = aten::mul(%278, %x.20), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %287 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.19, %x.19)
  %288 : Float(17:6656, 13:512, 512:1), %289 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%287)
  %290 : __torch__.torch.nn.modules.linear.___torch_mangle_34252.Linear = prim::GetAttr[name="wo"](%276)
  %291 : __torch__.torch.nn.modules.linear.___torch_mangle_34251.Linear = prim::GetAttr[name="wi"](%276)
  %292 : Tensor = prim::GetAttr[name="weight"](%291)
  %293 : Float(512:1, 2048:512) = aten::t(%292), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.DenseReluDense/__module.encoder.block.1.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.20 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%288, %293), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.DenseReluDense/__module.encoder.block.1.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.21 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.20), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.DenseReluDense # torch/nn/functional.py:1119:0
  %input.22 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.21, %56, %65), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.DenseReluDense/__module.encoder.block.1.layer.1.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %297 : Tensor = prim::GetAttr[name="weight"](%290)
  %298 : Float(2048:1, 512:2048) = aten::t(%297), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.DenseReluDense/__module.encoder.block.1.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.23 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.22, %298), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.DenseReluDense/__module.encoder.block.1.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.4 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.23, %56, %65), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1/__module.encoder.block.1.layer.1.dropout # torch/nn/functional.py:973:0
  %x.21 : Float(17:6656, 13:512, 512:1) = aten::add(%289, %y.4, %67), scope: __module.encoder/__module.encoder.block.1/__module.encoder.block.1.layer.1 # transformers/modeling_t5.py:200:0
  %302 : __torch__.torch.nn.modules.container.___torch_mangle_34275.ModuleList = prim::GetAttr[name="layer"](%76)
  %303 : __torch__.transformers.modeling_t5.___torch_mangle_34274.T5LayerFF = prim::GetAttr[name="1"](%302)
  %304 : __torch__.torch.nn.modules.container.___torch_mangle_34275.ModuleList = prim::GetAttr[name="layer"](%76)
  %305 : __torch__.transformers.modeling_t5.___torch_mangle_34267.T5LayerSelfAttention = prim::GetAttr[name="0"](%304)
  %306 : __torch__.transformers.modeling_t5.___torch_mangle_34264.T5Attention = prim::GetAttr[name="SelfAttention"](%305)
  %307 : __torch__.transformers.modeling_t5.___torch_mangle_34265.T5LayerNorm = prim::GetAttr[name="layer_norm"](%305)
  %308 : Tensor = prim::GetAttr[name="weight"](%307)
  %x.22 : Float(17:6656, 13:512, 512:1) = aten::to(%x.21, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %310 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.22, %62), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %311 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.layer_norm
  %variance.5 : Float(17:13, 13:1, 1:1) = aten::mean(%310, %311, %54, %59), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %313 : Float(17:13, 13:1, 1:1) = aten::add(%variance.5, %55, %67), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %314 : Float(17:13, 13:1, 1:1) = aten::sqrt(%313), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.23 : Float(17:6656, 13:512, 512:1) = aten::div(%x.22, %314), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.24 : Float(17:6656, 13:512, 512:1) = aten::mul(%308, %x.23), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %317 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.24, %x.22)
  %318 : Float(17:6656, 13:512, 512:1), %319 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%317)
  %320 : __torch__.torch.nn.modules.linear.___torch_mangle_34263.Linear = prim::GetAttr[name="o"](%306)
  %321 : __torch__.torch.nn.modules.linear.___torch_mangle_34262.Linear = prim::GetAttr[name="v"](%306)
  %322 : __torch__.torch.nn.modules.linear.___torch_mangle_34261.Linear = prim::GetAttr[name="k"](%306)
  %323 : __torch__.torch.nn.modules.linear.___torch_mangle_34260.Linear = prim::GetAttr[name="q"](%306)
  %324 : int = aten::size(%318, %64), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %325 : Tensor = prim::GetAttr[name="weight"](%323)
  %326 : Float(512:1, 512:512) = aten::t(%325), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention/__module.encoder.block.2.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.24 : Float(17:6656, 13:512, 512:1) = aten::matmul(%318, %326), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention/__module.encoder.block.2.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %328 : int[] = prim::ListConstruct(%324, %66, %44, %45), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention
  %329 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.24, %328), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.3 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%329, %67, %62), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %331 : Tensor = prim::GetAttr[name="weight"](%322)
  %332 : Float(512:1, 512:512) = aten::t(%331), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention/__module.encoder.block.2.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.25 : Float(17:6656, 13:512, 512:1) = aten::matmul(%318, %332), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention/__module.encoder.block.2.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %334 : int[] = prim::ListConstruct(%324, %66, %44, %45), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention
  %335 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.25, %334), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.3 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%335, %67, %62), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %337 : Tensor = prim::GetAttr[name="weight"](%321)
  %338 : Float(512:1, 512:512) = aten::t(%337), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention/__module.encoder.block.2.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.26 : Float(17:6656, 13:512, 512:1) = aten::matmul(%318, %338), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention/__module.encoder.block.2.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %340 : int[] = prim::ListConstruct(%324, %66, %44, %45), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention
  %341 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.26, %340), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.3 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%341, %67, %62), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %343 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.3, %61, %62), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.5 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.3, %343), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.6 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.5, %218, %67), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.25 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.6, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %347 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.25, %66, %59), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.3 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%347, %56, %65), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.27 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.3, %v.3), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %350 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.27, %67, %62), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %351 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%350, %64), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %352 : int[] = prim::ListConstruct(%324, %66, %53), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention
  %input.27 : Float(17:6656, 13:512, 512:1) = aten::view(%351, %352), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %354 : Tensor = prim::GetAttr[name="weight"](%320)
  %355 : Float(512:1, 512:512) = aten::t(%354), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention/__module.encoder.block.2.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.28 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.27, %355), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.SelfAttention/__module.encoder.block.2.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %y.5 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.28, %56, %65), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0/__module.encoder.block.2.layer.0.dropout # torch/nn/functional.py:973:0
  %x.28 : Float(17:6656, 13:512, 512:1) = aten::add(%319, %y.5, %67), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.0 # transformers/modeling_t5.py:439:0
  %359 : __torch__.transformers.modeling_t5.___torch_mangle_34271.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%303)
  %360 : __torch__.transformers.modeling_t5.___torch_mangle_34272.T5LayerNorm = prim::GetAttr[name="layer_norm"](%303)
  %361 : Tensor = prim::GetAttr[name="weight"](%360)
  %x.29 : Float(17:6656, 13:512, 512:1) = aten::to(%x.28, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %363 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.29, %62), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %364 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.layer_norm
  %variance.6 : Float(17:13, 13:1, 1:1) = aten::mean(%363, %364, %54, %59), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %366 : Float(17:13, 13:1, 1:1) = aten::add(%variance.6, %55, %67), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %367 : Float(17:13, 13:1, 1:1) = aten::sqrt(%366), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.30 : Float(17:6656, 13:512, 512:1) = aten::div(%x.29, %367), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.29 : Float(17:6656, 13:512, 512:1) = aten::mul(%361, %x.30), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %370 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.29, %x.29)
  %371 : Float(17:6656, 13:512, 512:1), %372 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%370)
  %373 : __torch__.torch.nn.modules.linear.___torch_mangle_34269.Linear = prim::GetAttr[name="wo"](%359)
  %374 : __torch__.torch.nn.modules.linear.___torch_mangle_34268.Linear = prim::GetAttr[name="wi"](%359)
  %375 : Tensor = prim::GetAttr[name="weight"](%374)
  %376 : Float(512:1, 2048:512) = aten::t(%375), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.DenseReluDense/__module.encoder.block.2.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.30 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%371, %376), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.DenseReluDense/__module.encoder.block.2.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.31 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.30), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.DenseReluDense # torch/nn/functional.py:1119:0
  %input.32 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.31, %56, %65), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.DenseReluDense/__module.encoder.block.2.layer.1.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %380 : Tensor = prim::GetAttr[name="weight"](%373)
  %381 : Float(2048:1, 512:2048) = aten::t(%380), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.DenseReluDense/__module.encoder.block.2.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.33 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.32, %381), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.DenseReluDense/__module.encoder.block.2.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.6 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.33, %56, %65), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1/__module.encoder.block.2.layer.1.dropout # torch/nn/functional.py:973:0
  %x.31 : Float(17:6656, 13:512, 512:1) = aten::add(%372, %y.6, %67), scope: __module.encoder/__module.encoder.block.2/__module.encoder.block.2.layer.1 # transformers/modeling_t5.py:200:0
  %385 : __torch__.torch.nn.modules.container.___torch_mangle_34292.ModuleList = prim::GetAttr[name="layer"](%74)
  %386 : __torch__.transformers.modeling_t5.___torch_mangle_34291.T5LayerFF = prim::GetAttr[name="1"](%385)
  %387 : __torch__.torch.nn.modules.container.___torch_mangle_34292.ModuleList = prim::GetAttr[name="layer"](%74)
  %388 : __torch__.transformers.modeling_t5.___torch_mangle_34284.T5LayerSelfAttention = prim::GetAttr[name="0"](%387)
  %389 : __torch__.transformers.modeling_t5.___torch_mangle_34281.T5Attention = prim::GetAttr[name="SelfAttention"](%388)
  %390 : __torch__.transformers.modeling_t5.___torch_mangle_34282.T5LayerNorm = prim::GetAttr[name="layer_norm"](%388)
  %391 : Tensor = prim::GetAttr[name="weight"](%390)
  %x.32 : Float(17:6656, 13:512, 512:1) = aten::to(%x.31, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %393 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.32, %62), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %394 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.layer_norm
  %variance.7 : Float(17:13, 13:1, 1:1) = aten::mean(%393, %394, %54, %59), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %396 : Float(17:13, 13:1, 1:1) = aten::add(%variance.7, %55, %67), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %397 : Float(17:13, 13:1, 1:1) = aten::sqrt(%396), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.33 : Float(17:6656, 13:512, 512:1) = aten::div(%x.32, %397), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.34 : Float(17:6656, 13:512, 512:1) = aten::mul(%391, %x.33), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %400 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.34, %x.32)
  %401 : Float(17:6656, 13:512, 512:1), %402 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%400)
  %403 : __torch__.torch.nn.modules.linear.___torch_mangle_34280.Linear = prim::GetAttr[name="o"](%389)
  %404 : __torch__.torch.nn.modules.linear.___torch_mangle_34279.Linear = prim::GetAttr[name="v"](%389)
  %405 : __torch__.torch.nn.modules.linear.___torch_mangle_34278.Linear = prim::GetAttr[name="k"](%389)
  %406 : __torch__.torch.nn.modules.linear.___torch_mangle_34277.Linear = prim::GetAttr[name="q"](%389)
  %407 : int = aten::size(%401, %64), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %408 : Tensor = prim::GetAttr[name="weight"](%406)
  %409 : Float(512:1, 512:512) = aten::t(%408), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention/__module.encoder.block.3.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.34 : Float(17:6656, 13:512, 512:1) = aten::matmul(%401, %409), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention/__module.encoder.block.3.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %411 : int[] = prim::ListConstruct(%407, %66, %44, %45), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention
  %412 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.34, %411), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.4 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%412, %67, %62), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %414 : Tensor = prim::GetAttr[name="weight"](%405)
  %415 : Float(512:1, 512:512) = aten::t(%414), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention/__module.encoder.block.3.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.35 : Float(17:6656, 13:512, 512:1) = aten::matmul(%401, %415), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention/__module.encoder.block.3.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %417 : int[] = prim::ListConstruct(%407, %66, %44, %45), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention
  %418 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.35, %417), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.4 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%418, %67, %62), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %420 : Tensor = prim::GetAttr[name="weight"](%404)
  %421 : Float(512:1, 512:512) = aten::t(%420), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention/__module.encoder.block.3.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.36 : Float(17:6656, 13:512, 512:1) = aten::matmul(%401, %421), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention/__module.encoder.block.3.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %423 : int[] = prim::ListConstruct(%407, %66, %44, %45), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention
  %424 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.36, %423), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.4 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%424, %67, %62), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %426 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.4, %61, %62), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.7 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.4, %426), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.8 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.7, %218, %67), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.35 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.8, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %430 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.35, %66, %59), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.4 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%430, %56, %65), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.37 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.4, %v.4), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %433 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.37, %67, %62), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %434 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%433, %64), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %435 : int[] = prim::ListConstruct(%407, %66, %53), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention
  %input.37 : Float(17:6656, 13:512, 512:1) = aten::view(%434, %435), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %437 : Tensor = prim::GetAttr[name="weight"](%403)
  %438 : Float(512:1, 512:512) = aten::t(%437), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention/__module.encoder.block.3.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.38 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.37, %438), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.SelfAttention/__module.encoder.block.3.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %y.7 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.38, %56, %65), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0/__module.encoder.block.3.layer.0.dropout # torch/nn/functional.py:973:0
  %x.38 : Float(17:6656, 13:512, 512:1) = aten::add(%402, %y.7, %67), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.0 # transformers/modeling_t5.py:439:0
  %442 : __torch__.transformers.modeling_t5.___torch_mangle_34288.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%386)
  %443 : __torch__.transformers.modeling_t5.___torch_mangle_34289.T5LayerNorm = prim::GetAttr[name="layer_norm"](%386)
  %444 : Tensor = prim::GetAttr[name="weight"](%443)
  %x.39 : Float(17:6656, 13:512, 512:1) = aten::to(%x.38, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %446 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.39, %62), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %447 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.layer_norm
  %variance.8 : Float(17:13, 13:1, 1:1) = aten::mean(%446, %447, %54, %59), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %449 : Float(17:13, 13:1, 1:1) = aten::add(%variance.8, %55, %67), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %450 : Float(17:13, 13:1, 1:1) = aten::sqrt(%449), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.40 : Float(17:6656, 13:512, 512:1) = aten::div(%x.39, %450), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.39 : Float(17:6656, 13:512, 512:1) = aten::mul(%444, %x.40), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %453 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.39, %x.39)
  %454 : Float(17:6656, 13:512, 512:1), %455 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%453)
  %456 : __torch__.torch.nn.modules.linear.___torch_mangle_34286.Linear = prim::GetAttr[name="wo"](%442)
  %457 : __torch__.torch.nn.modules.linear.___torch_mangle_34285.Linear = prim::GetAttr[name="wi"](%442)
  %458 : Tensor = prim::GetAttr[name="weight"](%457)
  %459 : Float(512:1, 2048:512) = aten::t(%458), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.DenseReluDense/__module.encoder.block.3.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.40 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%454, %459), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.DenseReluDense/__module.encoder.block.3.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.41 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.40), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.DenseReluDense # torch/nn/functional.py:1119:0
  %input.42 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.41, %56, %65), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.DenseReluDense/__module.encoder.block.3.layer.1.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %463 : Tensor = prim::GetAttr[name="weight"](%456)
  %464 : Float(2048:1, 512:2048) = aten::t(%463), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.DenseReluDense/__module.encoder.block.3.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.43 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.42, %464), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.DenseReluDense/__module.encoder.block.3.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.8 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.43, %56, %65), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1/__module.encoder.block.3.layer.1.dropout # torch/nn/functional.py:973:0
  %x.41 : Float(17:6656, 13:512, 512:1) = aten::add(%455, %y.8, %67), scope: __module.encoder/__module.encoder.block.3/__module.encoder.block.3.layer.1 # transformers/modeling_t5.py:200:0
  %468 : __torch__.torch.nn.modules.container.___torch_mangle_34309.ModuleList = prim::GetAttr[name="layer"](%72)
  %469 : __torch__.transformers.modeling_t5.___torch_mangle_34308.T5LayerFF = prim::GetAttr[name="1"](%468)
  %470 : __torch__.torch.nn.modules.container.___torch_mangle_34309.ModuleList = prim::GetAttr[name="layer"](%72)
  %471 : __torch__.transformers.modeling_t5.___torch_mangle_34301.T5LayerSelfAttention = prim::GetAttr[name="0"](%470)
  %472 : __torch__.transformers.modeling_t5.___torch_mangle_34298.T5Attention = prim::GetAttr[name="SelfAttention"](%471)
  %473 : __torch__.transformers.modeling_t5.___torch_mangle_34299.T5LayerNorm = prim::GetAttr[name="layer_norm"](%471)
  %474 : Tensor = prim::GetAttr[name="weight"](%473)
  %x.42 : Float(17:6656, 13:512, 512:1) = aten::to(%x.41, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %476 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.42, %62), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %477 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.layer_norm
  %variance.9 : Float(17:13, 13:1, 1:1) = aten::mean(%476, %477, %54, %59), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %479 : Float(17:13, 13:1, 1:1) = aten::add(%variance.9, %55, %67), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %480 : Float(17:13, 13:1, 1:1) = aten::sqrt(%479), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.43 : Float(17:6656, 13:512, 512:1) = aten::div(%x.42, %480), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.44 : Float(17:6656, 13:512, 512:1) = aten::mul(%474, %x.43), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %483 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.44, %x.42)
  %484 : Float(17:6656, 13:512, 512:1), %485 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%483)
  %486 : __torch__.torch.nn.modules.linear.___torch_mangle_34297.Linear = prim::GetAttr[name="o"](%472)
  %487 : __torch__.torch.nn.modules.linear.___torch_mangle_34296.Linear = prim::GetAttr[name="v"](%472)
  %488 : __torch__.torch.nn.modules.linear.___torch_mangle_34295.Linear = prim::GetAttr[name="k"](%472)
  %489 : __torch__.torch.nn.modules.linear.___torch_mangle_34294.Linear = prim::GetAttr[name="q"](%472)
  %490 : int = aten::size(%484, %64), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %491 : Tensor = prim::GetAttr[name="weight"](%489)
  %492 : Float(512:1, 512:512) = aten::t(%491), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention/__module.encoder.block.4.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.44 : Float(17:6656, 13:512, 512:1) = aten::matmul(%484, %492), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention/__module.encoder.block.4.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %494 : int[] = prim::ListConstruct(%490, %66, %44, %45), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention
  %495 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.44, %494), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.5 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%495, %67, %62), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %497 : Tensor = prim::GetAttr[name="weight"](%488)
  %498 : Float(512:1, 512:512) = aten::t(%497), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention/__module.encoder.block.4.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.45 : Float(17:6656, 13:512, 512:1) = aten::matmul(%484, %498), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention/__module.encoder.block.4.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %500 : int[] = prim::ListConstruct(%490, %66, %44, %45), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention
  %501 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.45, %500), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.5 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%501, %67, %62), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %503 : Tensor = prim::GetAttr[name="weight"](%487)
  %504 : Float(512:1, 512:512) = aten::t(%503), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention/__module.encoder.block.4.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.46 : Float(17:6656, 13:512, 512:1) = aten::matmul(%484, %504), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention/__module.encoder.block.4.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %506 : int[] = prim::ListConstruct(%490, %66, %44, %45), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention
  %507 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.46, %506), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.5 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%507, %67, %62), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %509 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.5, %61, %62), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.9 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.5, %509), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.10 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.9, %218, %67), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.45 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.10, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %513 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.45, %66, %59), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.5 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%513, %56, %65), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.47 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.5, %v.5), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %516 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.47, %67, %62), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %517 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%516, %64), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %518 : int[] = prim::ListConstruct(%490, %66, %53), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention
  %input.47 : Float(17:6656, 13:512, 512:1) = aten::view(%517, %518), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %520 : Tensor = prim::GetAttr[name="weight"](%486)
  %521 : Float(512:1, 512:512) = aten::t(%520), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention/__module.encoder.block.4.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.48 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.47, %521), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.SelfAttention/__module.encoder.block.4.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %y.9 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.48, %56, %65), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0/__module.encoder.block.4.layer.0.dropout # torch/nn/functional.py:973:0
  %x.48 : Float(17:6656, 13:512, 512:1) = aten::add(%485, %y.9, %67), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.0 # transformers/modeling_t5.py:439:0
  %525 : __torch__.transformers.modeling_t5.___torch_mangle_34305.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%469)
  %526 : __torch__.transformers.modeling_t5.___torch_mangle_34306.T5LayerNorm = prim::GetAttr[name="layer_norm"](%469)
  %527 : Tensor = prim::GetAttr[name="weight"](%526)
  %x.49 : Float(17:6656, 13:512, 512:1) = aten::to(%x.48, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %529 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.49, %62), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %530 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.layer_norm
  %variance.10 : Float(17:13, 13:1, 1:1) = aten::mean(%529, %530, %54, %59), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %532 : Float(17:13, 13:1, 1:1) = aten::add(%variance.10, %55, %67), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %533 : Float(17:13, 13:1, 1:1) = aten::sqrt(%532), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.50 : Float(17:6656, 13:512, 512:1) = aten::div(%x.49, %533), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.49 : Float(17:6656, 13:512, 512:1) = aten::mul(%527, %x.50), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %536 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.49, %x.49)
  %537 : Float(17:6656, 13:512, 512:1), %538 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%536)
  %539 : __torch__.torch.nn.modules.linear.___torch_mangle_34303.Linear = prim::GetAttr[name="wo"](%525)
  %540 : __torch__.torch.nn.modules.linear.___torch_mangle_34302.Linear = prim::GetAttr[name="wi"](%525)
  %541 : Tensor = prim::GetAttr[name="weight"](%540)
  %542 : Float(512:1, 2048:512) = aten::t(%541), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.DenseReluDense/__module.encoder.block.4.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.50 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%537, %542), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.DenseReluDense/__module.encoder.block.4.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.51 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.50), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.DenseReluDense # torch/nn/functional.py:1119:0
  %input.52 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.51, %56, %65), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.DenseReluDense/__module.encoder.block.4.layer.1.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %546 : Tensor = prim::GetAttr[name="weight"](%539)
  %547 : Float(2048:1, 512:2048) = aten::t(%546), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.DenseReluDense/__module.encoder.block.4.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.53 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.52, %547), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.DenseReluDense/__module.encoder.block.4.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.10 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.53, %56, %65), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1/__module.encoder.block.4.layer.1.dropout # torch/nn/functional.py:973:0
  %x.51 : Float(17:6656, 13:512, 512:1) = aten::add(%538, %y.10, %67), scope: __module.encoder/__module.encoder.block.4/__module.encoder.block.4.layer.1 # transformers/modeling_t5.py:200:0
  %551 : __torch__.torch.nn.modules.container.___torch_mangle_34326.ModuleList = prim::GetAttr[name="layer"](%70)
  %552 : __torch__.transformers.modeling_t5.___torch_mangle_34325.T5LayerFF = prim::GetAttr[name="1"](%551)
  %553 : __torch__.torch.nn.modules.container.___torch_mangle_34326.ModuleList = prim::GetAttr[name="layer"](%70)
  %554 : __torch__.transformers.modeling_t5.___torch_mangle_34318.T5LayerSelfAttention = prim::GetAttr[name="0"](%553)
  %555 : __torch__.transformers.modeling_t5.___torch_mangle_34315.T5Attention = prim::GetAttr[name="SelfAttention"](%554)
  %556 : __torch__.transformers.modeling_t5.___torch_mangle_34316.T5LayerNorm = prim::GetAttr[name="layer_norm"](%554)
  %557 : Tensor = prim::GetAttr[name="weight"](%556)
  %x.52 : Float(17:6656, 13:512, 512:1) = aten::to(%x.51, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %559 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.52, %62), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %560 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.layer_norm
  %variance.11 : Float(17:13, 13:1, 1:1) = aten::mean(%559, %560, %54, %59), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %562 : Float(17:13, 13:1, 1:1) = aten::add(%variance.11, %55, %67), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %563 : Float(17:13, 13:1, 1:1) = aten::sqrt(%562), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.53 : Float(17:6656, 13:512, 512:1) = aten::div(%x.52, %563), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.54 : Float(17:6656, 13:512, 512:1) = aten::mul(%557, %x.53), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %566 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.54, %x.52)
  %567 : Float(17:6656, 13:512, 512:1), %568 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%566)
  %569 : __torch__.torch.nn.modules.linear.___torch_mangle_34314.Linear = prim::GetAttr[name="o"](%555)
  %570 : __torch__.torch.nn.modules.linear.___torch_mangle_34313.Linear = prim::GetAttr[name="v"](%555)
  %571 : __torch__.torch.nn.modules.linear.___torch_mangle_34312.Linear = prim::GetAttr[name="k"](%555)
  %572 : __torch__.torch.nn.modules.linear.___torch_mangle_34311.Linear = prim::GetAttr[name="q"](%555)
  %573 : int = aten::size(%567, %64), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %574 : Tensor = prim::GetAttr[name="weight"](%572)
  %575 : Float(512:1, 512:512) = aten::t(%574), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention/__module.encoder.block.5.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.54 : Float(17:6656, 13:512, 512:1) = aten::matmul(%567, %575), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention/__module.encoder.block.5.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %577 : int[] = prim::ListConstruct(%573, %66, %44, %45), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention
  %578 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.54, %577), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.6 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%578, %67, %62), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %580 : Tensor = prim::GetAttr[name="weight"](%571)
  %581 : Float(512:1, 512:512) = aten::t(%580), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention/__module.encoder.block.5.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.55 : Float(17:6656, 13:512, 512:1) = aten::matmul(%567, %581), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention/__module.encoder.block.5.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %583 : int[] = prim::ListConstruct(%573, %66, %44, %45), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention
  %584 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.55, %583), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.6 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%584, %67, %62), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %586 : Tensor = prim::GetAttr[name="weight"](%570)
  %587 : Float(512:1, 512:512) = aten::t(%586), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention/__module.encoder.block.5.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.56 : Float(17:6656, 13:512, 512:1) = aten::matmul(%567, %587), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention/__module.encoder.block.5.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %589 : int[] = prim::ListConstruct(%573, %66, %44, %45), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention
  %590 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.56, %589), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.6 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%590, %67, %62), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %592 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.6, %61, %62), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.11 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.6, %592), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.12 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.11, %218, %67), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.55 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.12, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %596 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.55, %66, %59), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.6 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%596, %56, %65), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.57 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.6, %v.6), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %599 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.57, %67, %62), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %600 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%599, %64), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %601 : int[] = prim::ListConstruct(%573, %66, %53), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention
  %input.57 : Float(17:6656, 13:512, 512:1) = aten::view(%600, %601), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %603 : Tensor = prim::GetAttr[name="weight"](%569)
  %604 : Float(512:1, 512:512) = aten::t(%603), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention/__module.encoder.block.5.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.58 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.57, %604), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.SelfAttention/__module.encoder.block.5.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %y.11 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.58, %56, %65), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0/__module.encoder.block.5.layer.0.dropout # torch/nn/functional.py:973:0
  %x.58 : Float(17:6656, 13:512, 512:1) = aten::add(%568, %y.11, %67), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.0 # transformers/modeling_t5.py:439:0
  %608 : __torch__.transformers.modeling_t5.___torch_mangle_34322.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%552)
  %609 : __torch__.transformers.modeling_t5.___torch_mangle_34323.T5LayerNorm = prim::GetAttr[name="layer_norm"](%552)
  %610 : Tensor = prim::GetAttr[name="weight"](%609)
  %x.59 : Float(17:6656, 13:512, 512:1) = aten::to(%x.58, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %612 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.59, %62), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %613 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.layer_norm
  %variance.12 : Float(17:13, 13:1, 1:1) = aten::mean(%612, %613, %54, %59), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %615 : Float(17:13, 13:1, 1:1) = aten::add(%variance.12, %55, %67), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %616 : Float(17:13, 13:1, 1:1) = aten::sqrt(%615), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.60 : Float(17:6656, 13:512, 512:1) = aten::div(%x.59, %616), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.59 : Float(17:6656, 13:512, 512:1) = aten::mul(%610, %x.60), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %619 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.59, %x.59)
  %620 : Float(17:6656, 13:512, 512:1), %621 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%619)
  %622 : __torch__.torch.nn.modules.linear.___torch_mangle_34320.Linear = prim::GetAttr[name="wo"](%608)
  %623 : __torch__.torch.nn.modules.linear.___torch_mangle_34319.Linear = prim::GetAttr[name="wi"](%608)
  %624 : Tensor = prim::GetAttr[name="weight"](%623)
  %625 : Float(512:1, 2048:512) = aten::t(%624), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.DenseReluDense/__module.encoder.block.5.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.60 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%620, %625), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.DenseReluDense/__module.encoder.block.5.layer.1.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.61 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.60), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.DenseReluDense # torch/nn/functional.py:1119:0
  %input.62 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.61, %56, %65), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.DenseReluDense/__module.encoder.block.5.layer.1.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %629 : Tensor = prim::GetAttr[name="weight"](%622)
  %630 : Float(2048:1, 512:2048) = aten::t(%629), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.DenseReluDense/__module.encoder.block.5.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.63 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.62, %630), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.DenseReluDense/__module.encoder.block.5.layer.1.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.12 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.63, %56, %65), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1/__module.encoder.block.5.layer.1.dropout # torch/nn/functional.py:973:0
  %x.61 : Float(17:6656, 13:512, 512:1) = aten::add(%621, %y.12, %67), scope: __module.encoder/__module.encoder.block.5/__module.encoder.block.5.layer.1 # transformers/modeling_t5.py:200:0
  %634 : Tensor = prim::GetAttr[name="weight"](%68)
  %x.62 : Float(17:6656, 13:512, 512:1) = aten::to(%x.61, %60, %65, %65, %59), scope: __module.encoder/__module.encoder.final_layer_norm # transformers/modeling_t5.py:167:0
  %636 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.62, %62), scope: __module.encoder/__module.encoder.final_layer_norm # transformers/modeling_t5.py:167:0
  %637 : int[] = prim::ListConstruct(%66), scope: __module.encoder/__module.encoder.final_layer_norm
  %variance.13 : Float(17:13, 13:1, 1:1) = aten::mean(%636, %637, %54, %59), scope: __module.encoder/__module.encoder.final_layer_norm # transformers/modeling_t5.py:167:0
  %639 : Float(17:13, 13:1, 1:1) = aten::add(%variance.13, %55, %67), scope: __module.encoder/__module.encoder.final_layer_norm # transformers/modeling_t5.py:168:0
  %640 : Float(17:13, 13:1, 1:1) = aten::sqrt(%639), scope: __module.encoder/__module.encoder.final_layer_norm # transformers/modeling_t5.py:168:0
  %x.63 : Float(17:6656, 13:512, 512:1) = aten::div(%x.62, %640), scope: __module.encoder/__module.encoder.final_layer_norm # transformers/modeling_t5.py:168:0
  %input.64 : Float(17:6656, 13:512, 512:1) = aten::mul(%634, %x.63), scope: __module.encoder/__module.encoder.final_layer_norm # transformers/modeling_t5.py:172:0
  %kv : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.64, %56, %65), scope: __module.encoder/__module.encoder.dropout # torch/nn/functional.py:973:0
  %644 : int = prim::Constant[value=8](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %645 : int = prim::Constant[value=64](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %646 : int = prim::Constant[value=4](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:291:0
  %647 : int = prim::Constant[value=16](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # torch/tensor.py:22:0
  %648 : Long() = prim::Constant[value={16}](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %649 : Double() = prim::Constant[value={2.07944}](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %650 : int = prim::Constant[value=31](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:284:0
  %651 : Long() = prim::Constant[value={0}](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:286:0
  %652 : int = prim::Constant[value=512](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %653 : bool = prim::Constant[value=1](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %654 : Double() = prim::Constant[value={1e-06}](), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %655 : float = prim::Constant[value=0.10000000000000001](), scope: __module.decoder/__module.decoder.dropout # torch/nn/functional.py:973:0
  %656 : Double() = prim::Constant[value={-1e+09}](), scope: __module.decoder # transformers/modeling_utils.py:203:0
  %657 : Double() = prim::Constant[value={-10000}](), scope: __module.decoder # transformers/modeling_utils.py:258:0
  %658 : float = prim::Constant[value=1.](), scope: __module.decoder # torch/tensor.py:396:0
  %659 : int = prim::Constant[value=3](), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %660 : int = prim::Constant[value=9223372036854775807](), scope: __module.decoder # transformers/modeling_utils.py:239:0
  %661 : int = prim::Constant[value=2](), scope: __module.decoder # transformers/modeling_utils.py:239:0
  %662 : None = prim::Constant(), scope: __module.decoder
  %663 : Device = prim::Constant[value="cpu"](), scope: __module.decoder # transformers/modeling_t5.py:723:0
  %664 : int = prim::Constant[value=6](), scope: __module.decoder # transformers/modeling_t5.py:723:0
  %665 : bool = prim::Constant[value=0](), scope: __module.decoder/__module.decoder.embed_tokens # torch/nn/functional.py:1814:0
  %666 : int = prim::Constant[value=-1](), scope: __module.decoder # transformers/modeling_t5.py:694:0
  %667 : int = prim::Constant[value=1](), scope: __module.decoder # transformers/modeling_t5.py:693:0
  %668 : int = prim::Constant[value=0](), scope: __module.decoder # transformers/modeling_t5.py:693:0
  %669 : __torch__.transformers.modeling_t5.___torch_mangle_34486.T5LayerNorm = prim::GetAttr[name="final_layer_norm"](%3)
  %670 : __torch__.torch.nn.modules.container.___torch_mangle_34485.ModuleList = prim::GetAttr[name="block"](%3)
  %671 : __torch__.transformers.modeling_t5.___torch_mangle_34484.T5Block = prim::GetAttr[name="5"](%670)
  %672 : __torch__.torch.nn.modules.container.___torch_mangle_34485.ModuleList = prim::GetAttr[name="block"](%3)
  %673 : __torch__.transformers.modeling_t5.___torch_mangle_34459.T5Block = prim::GetAttr[name="4"](%672)
  %674 : __torch__.torch.nn.modules.container.___torch_mangle_34485.ModuleList = prim::GetAttr[name="block"](%3)
  %675 : __torch__.transformers.modeling_t5.___torch_mangle_34434.T5Block = prim::GetAttr[name="3"](%674)
  %676 : __torch__.torch.nn.modules.container.___torch_mangle_34485.ModuleList = prim::GetAttr[name="block"](%3)
  %677 : __torch__.transformers.modeling_t5.___torch_mangle_34409.T5Block = prim::GetAttr[name="2"](%676)
  %678 : __torch__.torch.nn.modules.container.___torch_mangle_34485.ModuleList = prim::GetAttr[name="block"](%3)
  %679 : __torch__.transformers.modeling_t5.___torch_mangle_34384.T5Block = prim::GetAttr[name="1"](%678)
  %680 : __torch__.torch.nn.modules.container.___torch_mangle_34485.ModuleList = prim::GetAttr[name="block"](%3)
  %681 : __torch__.transformers.modeling_t5.___torch_mangle_34359.T5Block = prim::GetAttr[name="0"](%680)
  %682 : int = aten::size(%input_ids, %668), scope: __module.decoder # transformers/modeling_t5.py:693:0
  %683 : int = aten::size(%input_ids, %667), scope: __module.decoder # transformers/modeling_t5.py:693:0
  %684 : int[] = prim::ListConstruct(%666, %683), scope: __module.decoder
  %input.65 : Long(17:13, 13:1) = aten::view(%input_ids, %684), scope: __module.decoder # transformers/modeling_t5.py:694:0
  %input.66 : Float(17:6656, 13:512, 512:1) = aten::embedding(%8, %input.65, %666, %665, %665), scope: __module.decoder/__module.decoder.embed_tokens # torch/nn/functional.py:1814:0
  %687 : int[] = prim::ListConstruct(%682, %683), scope: __module.decoder
  %688 : Float(17:13, 13:1) = aten::ones(%687, %664, %668, %663, %665), scope: __module.decoder # transformers/modeling_t5.py:723:0
  %attention_mask : Float(17:13, 13:1) = aten::to(%688, %664, %668, %663, %665, %665, %665, %662), scope: __module.decoder # transformers/modeling_t5.py:723:0
  %seq_ids : Long(13:1) = aten::arange(%683, %662, %668, %663, %665), scope: __module.decoder # transformers/modeling_utils.py:238:0
  %691 : Long(1:13, 13:1) = aten::unsqueeze(%seq_ids, %668), scope: __module.decoder # transformers/modeling_utils.py:239:0
  %692 : Long(1:13, 1:13, 13:1) = aten::unsqueeze(%691, %667), scope: __module.decoder # transformers/modeling_utils.py:239:0
  %693 : Long(1:13, 1:13, 13:1) = aten::slice(%692, %661, %668, %660, %667), scope: __module.decoder # transformers/modeling_utils.py:239:0
  %694 : int[] = prim::ListConstruct(%682, %683, %667), scope: __module.decoder
  %695 : Long(17:169, 13:13, 13:1) = aten::repeat(%693, %694), scope: __module.decoder # transformers/modeling_utils.py:239:0
  %696 : Long(1:13, 13:1) = aten::unsqueeze(%seq_ids, %668), scope: __module.decoder # transformers/modeling_utils.py:239:0
  %697 : Long(1:13, 13:1) = aten::slice(%696, %667, %668, %660, %667), scope: __module.decoder # transformers/modeling_utils.py:239:0
  %698 : Long(1:13, 13:1, 1:1) = aten::unsqueeze(%697, %661), scope: __module.decoder # transformers/modeling_utils.py:239:0
  %causal_mask.1 : Bool(17:169, 13:13, 13:1) = aten::le(%695, %698), scope: __module.decoder # torch/tensor.py:22:0
  %causal_mask : Float(17:169, 13:13, 13:1) = aten::to(%causal_mask.1, %664, %665, %665, %662), scope: __module.decoder # transformers/modeling_utils.py:241:0
  %701 : Float(17:169, 13:13, 13:1) = aten::slice(%causal_mask, %668, %668, %660, %667), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %702 : Float(17:169, 1:169, 13:13, 13:1) = aten::unsqueeze(%701, %667), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %703 : Float(17:169, 1:169, 13:13, 13:1) = aten::slice(%702, %661, %668, %660, %667), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %704 : Float(17:169, 1:169, 13:13, 13:1) = aten::slice(%703, %659, %668, %660, %667), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %705 : Float(17:13, 13:1) = aten::slice(%attention_mask, %668, %668, %660, %667), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %706 : Float(17:13, 1:13, 13:1) = aten::unsqueeze(%705, %667), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %707 : Float(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%706, %661), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %708 : Float(17:13, 1:13, 1:13, 13:1) = aten::slice(%707, %659, %668, %660, %667), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %extended_attention_mask : Float(17:169, 1:169, 13:13, 13:1) = aten::mul(%704, %708), scope: __module.decoder # transformers/modeling_utils.py:242:0
  %710 : Float(17:169, 1:169, 13:13, 13:1) = aten::to(%extended_attention_mask, %664, %665, %665, %662), scope: __module.decoder # transformers/modeling_utils.py:257:0
  %711 : Float(17:169, 1:169, 13:13, 13:1) = aten::rsub(%710, %658, %667), scope: __module.decoder # torch/tensor.py:396:0
  %mask.2 : Float(17:169, 1:169, 13:13, 13:1) = aten::mul(%711, %657), scope: __module.decoder # transformers/modeling_utils.py:258:0
  %713 : Long(17:13, 13:1) = aten::slice(%attention_mask.1, %668, %668, %660, %667), scope: __module.decoder # transformers/modeling_utils.py:192:0
  %714 : Long(17:13, 1:13, 13:1) = aten::unsqueeze(%713, %667), scope: __module.decoder # transformers/modeling_utils.py:192:0
  %715 : Long(17:13, 1:13, 1:13, 13:1) = aten::unsqueeze(%714, %661), scope: __module.decoder # transformers/modeling_utils.py:192:0
  %encoder_extended_attention_mask : Long(17:13, 1:13, 1:13, 13:1) = aten::slice(%715, %659, %668, %660, %667), scope: __module.decoder # transformers/modeling_utils.py:192:0
  %717 : Float(17:13, 1:13, 1:13, 13:1) = aten::to(%encoder_extended_attention_mask, %664, %665, %665, %662), scope: __module.decoder # transformers/modeling_utils.py:198:0
  %718 : Float(17:13, 1:13, 1:13, 13:1) = aten::rsub(%717, %658, %667), scope: __module.decoder # torch/tensor.py:396:0
  %mask : Float(17:13, 1:13, 1:13, 13:1) = aten::mul(%718, %656), scope: __module.decoder # transformers/modeling_utils.py:203:0
  %x.64 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.66, %655, %665), scope: __module.decoder/__module.decoder.dropout # torch/nn/functional.py:973:0
  %721 : __torch__.torch.nn.modules.container.___torch_mangle_34358.ModuleList = prim::GetAttr[name="layer"](%681)
  %722 : __torch__.transformers.modeling_t5.___torch_mangle_34357.T5LayerFF = prim::GetAttr[name="2"](%721)
  %723 : __torch__.torch.nn.modules.container.___torch_mangle_34358.ModuleList = prim::GetAttr[name="layer"](%681)
  %724 : __torch__.transformers.modeling_t5.___torch_mangle_34350.T5LayerCrossAttention = prim::GetAttr[name="1"](%723)
  %725 : __torch__.torch.nn.modules.container.___torch_mangle_34358.ModuleList = prim::GetAttr[name="layer"](%681)
  %726 : __torch__.transformers.modeling_t5.___torch_mangle_34341.T5LayerSelfAttention = prim::GetAttr[name="0"](%725)
  %727 : __torch__.transformers.modeling_t5.___torch_mangle_34338.T5Attention = prim::GetAttr[name="SelfAttention"](%726)
  %728 : __torch__.transformers.modeling_t5.___torch_mangle_34339.T5LayerNorm = prim::GetAttr[name="layer_norm"](%726)
  %729 : Tensor = prim::GetAttr[name="weight"](%728)
  %x.65 : Float(17:6656, 13:512, 512:1) = aten::to(%x.64, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %731 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.65, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %732 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm
  %variance.14 : Float(17:13, 13:1, 1:1) = aten::mean(%731, %732, %653, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %734 : Float(17:13, 13:1, 1:1) = aten::add(%variance.14, %654, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %735 : Float(17:13, 13:1, 1:1) = aten::sqrt(%734), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.66 : Float(17:6656, 13:512, 512:1) = aten::div(%x.65, %735), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.67 : Float(17:6656, 13:512, 512:1) = aten::mul(%729, %x.66), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %738 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.67, %x.65)
  %739 : Float(17:6656, 13:512, 512:1), %740 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%738)
  %741 : __torch__.torch.nn.modules.linear.___torch_mangle_34336.Linear = prim::GetAttr[name="o"](%727)
  %742 : __torch__.torch.nn.modules.sparse.___torch_mangle_34337.Embedding = prim::GetAttr[name="relative_attention_bias"](%727)
  %743 : __torch__.torch.nn.modules.linear.___torch_mangle_34335.Linear = prim::GetAttr[name="v"](%727)
  %744 : __torch__.torch.nn.modules.linear.___torch_mangle_34334.Linear = prim::GetAttr[name="k"](%727)
  %745 : __torch__.torch.nn.modules.linear.___torch_mangle_34333.Linear = prim::GetAttr[name="q"](%727)
  %746 : int = aten::size(%739, %668), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %747 : int = aten::size(%739, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %748 : Tensor = prim::GetAttr[name="weight"](%745)
  %749 : Float(512:1, 512:512) = aten::t(%748), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention/__module.decoder.block.0.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.67 : Float(17:6656, 13:512, 512:1) = aten::matmul(%739, %749), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention/__module.decoder.block.0.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %751 : int[] = prim::ListConstruct(%746, %666, %644, %645), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention
  %752 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.67, %751), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.7 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%752, %667, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %754 : Tensor = prim::GetAttr[name="weight"](%744)
  %755 : Float(512:1, 512:512) = aten::t(%754), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention/__module.decoder.block.0.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.68 : Float(17:6656, 13:512, 512:1) = aten::matmul(%739, %755), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention/__module.decoder.block.0.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %757 : int[] = prim::ListConstruct(%746, %666, %644, %645), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention
  %758 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.68, %757), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.7 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%758, %667, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %760 : Tensor = prim::GetAttr[name="weight"](%743)
  %761 : Float(512:1, 512:512) = aten::t(%760), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention/__module.decoder.block.0.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.69 : Float(17:6656, 13:512, 512:1) = aten::matmul(%739, %761), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention/__module.decoder.block.0.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %763 : int[] = prim::ListConstruct(%746, %666, %644, %645), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention
  %764 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.69, %763), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.7 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%764, %667, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %766 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.7, %659, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.13 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.7, %766), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %768 : Long(13:1) = aten::arange(%747, %646, %668, %663, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:291:0
  %769 : Long(13:1) = aten::slice(%768, %668, %668, %660, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:291:0
  %context_position.2 : Long(13:1, 1:1) = aten::unsqueeze(%769, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:291:0
  %771 : Long(13:1) = aten::arange(%747, %646, %668, %663, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:292:0
  %772 : Long(1:13, 13:1) = aten::unsqueeze(%771, %668), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:292:0
  %memory_position.2 : Long(1:13, 13:1) = aten::slice(%772, %667, %668, %660, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:292:0
  %relative_position.2 : Long(13:13, 13:1) = aten::sub(%memory_position.2, %context_position.2, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:293:0
  %n.3 : Long(13:13, 13:1) = aten::neg(%relative_position.2), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:267:0
  %776 : Long(13:13, 13:1) = aten::zeros_like(%n.3, %646, %668, %663, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:273:0
  %n.4 : Long(13:13, 13:1) = aten::max(%n.3, %776), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:273:0
  %is_small.2 : Bool(13:13, 13:1) = aten::lt(%n.4, %647), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # torch/tensor.py:22:0
  %779 : Float(13:13, 13:1) = aten::to(%n.4, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %780 : Float(13:13, 13:1) = aten::div(%779, %648), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %781 : Float(13:13, 13:1) = aten::log(%780), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %782 : Float(13:13, 13:1) = aten::div(%781, %649), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %783 : Float(13:13, 13:1) = aten::mul(%782, %648), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:282:0
  %784 : Long(13:13, 13:1) = aten::to(%783, %646, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:281:0
  %val_if_large.3 : Long(13:13, 13:1) = aten::add(%784, %648, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:281:0
  %786 : Long(13:13, 13:1) = aten::full_like(%val_if_large.3, %650, %646, %668, %663, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:284:0
  %val_if_large.4 : Long(13:13, 13:1) = aten::min(%val_if_large.3, %786), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:284:0
  %788 : Long(13:13, 13:1) = aten::where(%is_small.2, %n.4, %val_if_large.4), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:286:0
  %rp_bucket.2 : Long(13:13, 13:1) = aten::add(%788, %651, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:286:0
  %input.68 : Long(13:13, 13:1) = aten::to(%rp_bucket.2, %646, %668, %663, %665, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:299:0
  %791 : Tensor = prim::GetAttr[name="weight"](%742)
  %values.2 : Float(13:104, 13:8, 8:1) = aten::embedding(%791, %input.68, %666, %665, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention/__module.decoder.block.0.layer.0.SelfAttention.relative_attention_bias # torch/nn/functional.py:1814:0
  %793 : int[] = prim::ListConstruct(%661, %668, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention
  %794 : Float(8:1, 13:104, 13:8) = aten::permute(%values.2, %793), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:301:0
  %position_bias.3 : Float(1:8, 8:1, 13:104, 13:8) = aten::unsqueeze(%794, %668), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:301:0
  %position_bias.4 : Float(17:1352, 8:1, 13:104, 13:8) = aten::add(%position_bias.3, %mask.2, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:387:0
  %scores.14 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.13, %position_bias.4, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.69 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.14, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %799 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.69, %666, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.7 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%799, %655, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.70 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.7, %v.7), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %802 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.70, %667, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %803 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%802, %668), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %804 : int[] = prim::ListConstruct(%746, %666, %652), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention
  %input.71 : Float(17:6656, 13:512, 512:1) = aten::view(%803, %804), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %806 : Tensor = prim::GetAttr[name="weight"](%741)
  %807 : Float(512:1, 512:512) = aten::t(%806), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention/__module.decoder.block.0.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.72 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.71, %807), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.SelfAttention/__module.decoder.block.0.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %809 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:1352, 8:1, 13:104, 13:8), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.72, %k.7, %position_bias.4, %v.7)
  %810 : Float(17:6656, 13:512, 512:1), %811 : Float(17:6656, 8:64, 13:512, 64:1), %812 : Float(17:1352, 8:1, 13:104, 13:8), %813 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%809)
  %y.13 : Float(17:6656, 13:512, 512:1) = aten::dropout(%810, %655, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0/__module.decoder.block.0.layer.0.dropout # torch/nn/functional.py:973:0
  %x.71 : Float(17:6656, 13:512, 512:1) = aten::add(%740, %y.13, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.0 # transformers/modeling_t5.py:439:0
  %816 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 13:512, 512:1), Float(17:1352, 8:1, 13:104, 13:8), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%811, %x.71, %812, %813)
  %817 : Float(17:6656, 8:64, 13:512, 64:1), %818 : Float(17:6656, 13:512, 512:1), %819 : Float(17:1352, 8:1, 13:104, 13:8), %820 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%816)
  %821 : __torch__.transformers.modeling_t5.___torch_mangle_34347.T5Attention = prim::GetAttr[name="EncDecAttention"](%724)
  %822 : __torch__.transformers.modeling_t5.___torch_mangle_34348.T5LayerNorm = prim::GetAttr[name="layer_norm"](%724)
  %823 : Tensor = prim::GetAttr[name="weight"](%822)
  %x.72 : Float(17:6656, 13:512, 512:1) = aten::to(%818, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %825 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.72, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %826 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.layer_norm
  %variance.15 : Float(17:13, 13:1, 1:1) = aten::mean(%825, %826, %653, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %828 : Float(17:13, 13:1, 1:1) = aten::add(%variance.15, %654, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %829 : Float(17:13, 13:1, 1:1) = aten::sqrt(%828), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.73 : Float(17:6656, 13:512, 512:1) = aten::div(%x.72, %829), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.73 : Float(17:6656, 13:512, 512:1) = aten::mul(%823, %x.73), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %832 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.73, %x.72)
  %833 : Float(17:6656, 13:512, 512:1), %834 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%832)
  %835 : __torch__.torch.nn.modules.linear.___torch_mangle_34345.Linear = prim::GetAttr[name="o"](%821)
  %836 : __torch__.torch.nn.modules.sparse.___torch_mangle_34346.Embedding = prim::GetAttr[name="relative_attention_bias"](%821)
  %837 : __torch__.torch.nn.modules.linear.___torch_mangle_34344.Linear = prim::GetAttr[name="v"](%821)
  %838 : __torch__.torch.nn.modules.linear.___torch_mangle_34343.Linear = prim::GetAttr[name="k"](%821)
  %839 : __torch__.torch.nn.modules.linear.___torch_mangle_34342.Linear = prim::GetAttr[name="q"](%821)
  %840 : int = aten::size(%833, %668), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:322:0
  %841 : int = aten::size(%833, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:322:0
  %842 : int = aten::size(%kv, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:338:0
  %843 : Tensor = prim::GetAttr[name="weight"](%839)
  %844 : Float(512:1, 512:512) = aten::t(%843), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention/__module.decoder.block.0.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %x.74 : Float(17:6656, 13:512, 512:1) = aten::matmul(%833, %844), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention/__module.decoder.block.0.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %846 : int[] = prim::ListConstruct(%840, %666, %644, %645), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention
  %847 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.74, %846), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %q.8 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%847, %667, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %849 : Tensor = prim::GetAttr[name="weight"](%838)
  %850 : Float(512:1, 512:512) = aten::t(%849), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention/__module.decoder.block.0.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %x.75 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %850), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention/__module.decoder.block.0.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %852 : int[] = prim::ListConstruct(%840, %666, %644, %645), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention
  %853 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.75, %852), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %k.8 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%853, %667, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %855 : Tensor = prim::GetAttr[name="weight"](%837)
  %856 : Float(512:1, 512:512) = aten::t(%855), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention/__module.decoder.block.0.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %x.76 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %856), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention/__module.decoder.block.0.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %858 : int[] = prim::ListConstruct(%840, %666, %644, %645), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention
  %859 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.76, %858), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %v.8 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%859, %667, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %861 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.8, %659, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:373:0
  %scores.15 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.8, %861), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:372:0
  %863 : Long(13:1) = aten::arange(%841, %646, %668, %663, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:291:0
  %864 : Long(13:1) = aten::slice(%863, %668, %668, %660, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:291:0
  %context_position : Long(13:1, 1:1) = aten::unsqueeze(%864, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:291:0
  %866 : Long(13:1) = aten::arange(%842, %646, %668, %663, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:292:0
  %867 : Long(1:13, 13:1) = aten::unsqueeze(%866, %668), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:292:0
  %memory_position : Long(1:13, 13:1) = aten::slice(%867, %667, %668, %660, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:292:0
  %relative_position : Long(13:13, 13:1) = aten::sub(%memory_position, %context_position, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:293:0
  %n.5 : Long(13:13, 13:1) = aten::neg(%relative_position), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:267:0
  %871 : Long(13:13, 13:1) = aten::zeros_like(%n.5, %646, %668, %663, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:273:0
  %n : Long(13:13, 13:1) = aten::max(%n.5, %871), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:273:0
  %is_small : Bool(13:13, 13:1) = aten::lt(%n, %647), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # torch/tensor.py:22:0
  %874 : Float(13:13, 13:1) = aten::to(%n, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:282:0
  %875 : Float(13:13, 13:1) = aten::div(%874, %648), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:282:0
  %876 : Float(13:13, 13:1) = aten::log(%875), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:282:0
  %877 : Float(13:13, 13:1) = aten::div(%876, %649), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:282:0
  %878 : Float(13:13, 13:1) = aten::mul(%877, %648), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:282:0
  %879 : Long(13:13, 13:1) = aten::to(%878, %646, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:281:0
  %val_if_large.5 : Long(13:13, 13:1) = aten::add(%879, %648, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:281:0
  %881 : Long(13:13, 13:1) = aten::full_like(%val_if_large.5, %650, %646, %668, %663, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:284:0
  %val_if_large : Long(13:13, 13:1) = aten::min(%val_if_large.5, %881), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:284:0
  %883 : Long(13:13, 13:1) = aten::where(%is_small, %n, %val_if_large), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:286:0
  %rp_bucket : Long(13:13, 13:1) = aten::add(%883, %651, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:286:0
  %input.74 : Long(13:13, 13:1) = aten::to(%rp_bucket, %646, %668, %663, %665, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:299:0
  %886 : Tensor = prim::GetAttr[name="weight"](%836)
  %values : Float(13:104, 13:8, 8:1) = aten::embedding(%886, %input.74, %666, %665, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention/__module.decoder.block.0.layer.1.EncDecAttention.relative_attention_bias # torch/nn/functional.py:1814:0
  %888 : int[] = prim::ListConstruct(%661, %668, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention
  %889 : Float(8:1, 13:104, 13:8) = aten::permute(%values, %888), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:301:0
  %position_bias.5 : Float(1:8, 8:1, 13:104, 13:8) = aten::unsqueeze(%889, %668), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:301:0
  %position_bias : Float(17:1352, 8:1, 13:104, 13:8) = aten::add(%position_bias.5, %mask, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:387:0
  %scores.16 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.15, %position_bias, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:389:0
  %input.75 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.16, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:390:0
  %894 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.75, %666, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # torch/nn/functional.py:1498:0
  %weights.8 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%894, %655, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # torch/nn/functional.py:973:0
  %x.77 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.8, %v.8), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:397:0
  %897 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.77, %667, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %898 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%897, %668), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %899 : int[] = prim::ListConstruct(%840, %666, %652), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention
  %input.77 : Float(17:6656, 13:512, 512:1) = aten::view(%898, %899), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %901 : Tensor = prim::GetAttr[name="weight"](%835)
  %902 : Float(512:1, 512:512) = aten::t(%901), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention/__module.decoder.block.0.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %input.78 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.77, %902), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.EncDecAttention/__module.decoder.block.0.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %904 : (Float(17:6656, 13:512, 512:1), Float(17:1352, 8:1, 13:104, 13:8), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.78, %position_bias, %k.8, %v.8)
  %905 : Float(17:6656, 13:512, 512:1), %906 : Float(17:1352, 8:1, 13:104, 13:8), %907 : Float(17:6656, 8:64, 13:512, 64:1), %908 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%904)
  %y.14 : Float(17:6656, 13:512, 512:1) = aten::dropout(%905, %655, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1/__module.decoder.block.0.layer.1.dropout # torch/nn/functional.py:973:0
  %x.78 : Float(17:6656, 13:512, 512:1) = aten::add(%834, %y.14, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.1 # transformers/modeling_t5.py:476:0
  %911 : (Float(17:6656, 13:512, 512:1), Float(17:1352, 8:1, 13:104, 13:8), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.78, %906, %907, %908)
  %912 : Float(17:6656, 13:512, 512:1), %913 : Float(17:1352, 8:1, 13:104, 13:8), %914 : Float(17:6656, 8:64, 13:512, 64:1), %915 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%911)
  %916 : __torch__.transformers.modeling_t5.___torch_mangle_34354.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%722)
  %917 : __torch__.transformers.modeling_t5.___torch_mangle_34355.T5LayerNorm = prim::GetAttr[name="layer_norm"](%722)
  %918 : Tensor = prim::GetAttr[name="weight"](%917)
  %x.79 : Float(17:6656, 13:512, 512:1) = aten::to(%912, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %920 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.79, %661), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %921 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.layer_norm
  %variance.16 : Float(17:13, 13:1, 1:1) = aten::mean(%920, %921, %653, %662), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %923 : Float(17:13, 13:1, 1:1) = aten::add(%variance.16, %654, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %924 : Float(17:13, 13:1, 1:1) = aten::sqrt(%923), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %x.80 : Float(17:6656, 13:512, 512:1) = aten::div(%x.79, %924), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %input.79 : Float(17:6656, 13:512, 512:1) = aten::mul(%918, %x.80), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.layer_norm # transformers/modeling_t5.py:172:0
  %927 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.79, %x.79)
  %928 : Float(17:6656, 13:512, 512:1), %929 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%927)
  %930 : __torch__.torch.nn.modules.linear.___torch_mangle_34352.Linear = prim::GetAttr[name="wo"](%916)
  %931 : __torch__.torch.nn.modules.linear.___torch_mangle_34351.Linear = prim::GetAttr[name="wi"](%916)
  %932 : Tensor = prim::GetAttr[name="weight"](%931)
  %933 : Float(512:1, 2048:512) = aten::t(%932), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.DenseReluDense/__module.decoder.block.0.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.80 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%928, %933), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.DenseReluDense/__module.decoder.block.0.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.81 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.80), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.DenseReluDense # torch/nn/functional.py:1119:0
  %input.82 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.81, %655, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.DenseReluDense/__module.decoder.block.0.layer.2.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %937 : Tensor = prim::GetAttr[name="weight"](%930)
  %938 : Float(2048:1, 512:2048) = aten::t(%937), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.DenseReluDense/__module.decoder.block.0.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.83 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.82, %938), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.DenseReluDense/__module.decoder.block.0.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.15 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.83, %655, %665), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2/__module.decoder.block.0.layer.2.dropout # torch/nn/functional.py:973:0
  %x.81 : Float(17:6656, 13:512, 512:1) = aten::add(%929, %y.15, %667), scope: __module.decoder/__module.decoder.block.0/__module.decoder.block.0.layer.2 # transformers/modeling_t5.py:200:0
  %942 : (Float(17:6656, 13:512, 512:1), Float(17:1352, 8:1, 13:104, 13:8), Float(17:1352, 8:1, 13:104, 13:8), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.81, %819, %913, %817, %820, %914, %915)
  %943 : Float(17:6656, 13:512, 512:1), %944 : Float(17:1352, 8:1, 13:104, 13:8), %945 : Float(17:1352, 8:1, 13:104, 13:8), %946 : Float(17:6656, 8:64, 13:512, 64:1), %947 : Float(17:6656, 8:64, 13:512, 64:1), %948 : Float(17:6656, 8:64, 13:512, 64:1), %949 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%942)
  %950 : __torch__.torch.nn.modules.container.___torch_mangle_34383.ModuleList = prim::GetAttr[name="layer"](%679)
  %951 : __torch__.transformers.modeling_t5.___torch_mangle_34382.T5LayerFF = prim::GetAttr[name="2"](%950)
  %952 : __torch__.torch.nn.modules.container.___torch_mangle_34383.ModuleList = prim::GetAttr[name="layer"](%679)
  %953 : __torch__.transformers.modeling_t5.___torch_mangle_34375.T5LayerCrossAttention = prim::GetAttr[name="1"](%952)
  %954 : __torch__.torch.nn.modules.container.___torch_mangle_34383.ModuleList = prim::GetAttr[name="layer"](%679)
  %955 : __torch__.transformers.modeling_t5.___torch_mangle_34367.T5LayerSelfAttention = prim::GetAttr[name="0"](%954)
  %956 : __torch__.transformers.modeling_t5.___torch_mangle_34364.T5Attention = prim::GetAttr[name="SelfAttention"](%955)
  %957 : __torch__.transformers.modeling_t5.___torch_mangle_34365.T5LayerNorm = prim::GetAttr[name="layer_norm"](%955)
  %958 : Tensor = prim::GetAttr[name="weight"](%957)
  %x.82 : Float(17:6656, 13:512, 512:1) = aten::to(%943, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %960 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.82, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %961 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.layer_norm
  %variance.17 : Float(17:13, 13:1, 1:1) = aten::mean(%960, %961, %653, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %963 : Float(17:13, 13:1, 1:1) = aten::add(%variance.17, %654, %667), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %964 : Float(17:13, 13:1, 1:1) = aten::sqrt(%963), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.83 : Float(17:6656, 13:512, 512:1) = aten::div(%x.82, %964), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.84 : Float(17:6656, 13:512, 512:1) = aten::mul(%958, %x.83), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %967 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.84, %x.82)
  %968 : Float(17:6656, 13:512, 512:1), %969 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%967)
  %970 : __torch__.torch.nn.modules.linear.___torch_mangle_34363.Linear = prim::GetAttr[name="o"](%956)
  %971 : __torch__.torch.nn.modules.linear.___torch_mangle_34362.Linear = prim::GetAttr[name="v"](%956)
  %972 : __torch__.torch.nn.modules.linear.___torch_mangle_34361.Linear = prim::GetAttr[name="k"](%956)
  %973 : __torch__.torch.nn.modules.linear.___torch_mangle_34360.Linear = prim::GetAttr[name="q"](%956)
  %974 : int = aten::size(%968, %668), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %975 : Tensor = prim::GetAttr[name="weight"](%973)
  %976 : Float(512:1, 512:512) = aten::t(%975), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention/__module.decoder.block.1.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.84 : Float(17:6656, 13:512, 512:1) = aten::matmul(%968, %976), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention/__module.decoder.block.1.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %978 : int[] = prim::ListConstruct(%974, %666, %644, %645), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention
  %979 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.84, %978), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.9 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%979, %667, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %981 : Tensor = prim::GetAttr[name="weight"](%972)
  %982 : Float(512:1, 512:512) = aten::t(%981), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention/__module.decoder.block.1.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.85 : Float(17:6656, 13:512, 512:1) = aten::matmul(%968, %982), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention/__module.decoder.block.1.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %984 : int[] = prim::ListConstruct(%974, %666, %644, %645), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention
  %985 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.85, %984), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.9 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%985, %667, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %987 : Tensor = prim::GetAttr[name="weight"](%971)
  %988 : Float(512:1, 512:512) = aten::t(%987), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention/__module.decoder.block.1.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.86 : Float(17:6656, 13:512, 512:1) = aten::matmul(%968, %988), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention/__module.decoder.block.1.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %990 : int[] = prim::ListConstruct(%974, %666, %644, %645), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention
  %991 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.86, %990), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.9 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%991, %667, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %993 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.9, %659, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.17 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.9, %993), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.18 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.17, %944, %667), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.85 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.18, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %997 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.85, %666, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.9 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%997, %655, %665), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.87 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.9, %v.9), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %1000 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.87, %667, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1001 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1000, %668), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1002 : int[] = prim::ListConstruct(%974, %666, %652), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention
  %input.87 : Float(17:6656, 13:512, 512:1) = aten::view(%1001, %1002), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1004 : Tensor = prim::GetAttr[name="weight"](%970)
  %1005 : Float(512:1, 512:512) = aten::t(%1004), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention/__module.decoder.block.1.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.88 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.87, %1005), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.SelfAttention/__module.decoder.block.1.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %1007 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.88, %k.9, %v.9)
  %1008 : Float(17:6656, 13:512, 512:1), %1009 : Float(17:6656, 8:64, 13:512, 64:1), %1010 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1007)
  %y.16 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1008, %655, %665), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0/__module.decoder.block.1.layer.0.dropout # torch/nn/functional.py:973:0
  %x.88 : Float(17:6656, 13:512, 512:1) = aten::add(%969, %y.16, %667), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.0 # transformers/modeling_t5.py:439:0
  %1013 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%1009, %x.88, %1010)
  %1014 : Float(17:6656, 8:64, 13:512, 64:1), %1015 : Float(17:6656, 13:512, 512:1), %1016 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1013)
  %1017 : __torch__.transformers.modeling_t5.___torch_mangle_34372.T5Attention = prim::GetAttr[name="EncDecAttention"](%953)
  %1018 : __torch__.transformers.modeling_t5.___torch_mangle_34373.T5LayerNorm = prim::GetAttr[name="layer_norm"](%953)
  %1019 : Tensor = prim::GetAttr[name="weight"](%1018)
  %x.89 : Float(17:6656, 13:512, 512:1) = aten::to(%1015, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1021 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.89, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1022 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.layer_norm
  %variance.18 : Float(17:13, 13:1, 1:1) = aten::mean(%1021, %1022, %653, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1024 : Float(17:13, 13:1, 1:1) = aten::add(%variance.18, %654, %667), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %1025 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1024), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.90 : Float(17:6656, 13:512, 512:1) = aten::div(%x.89, %1025), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.89 : Float(17:6656, 13:512, 512:1) = aten::mul(%1019, %x.90), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %1028 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.89, %x.89)
  %1029 : Float(17:6656, 13:512, 512:1), %1030 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1028)
  %1031 : __torch__.torch.nn.modules.linear.___torch_mangle_34371.Linear = prim::GetAttr[name="o"](%1017)
  %1032 : __torch__.torch.nn.modules.linear.___torch_mangle_34370.Linear = prim::GetAttr[name="v"](%1017)
  %1033 : __torch__.torch.nn.modules.linear.___torch_mangle_34369.Linear = prim::GetAttr[name="k"](%1017)
  %1034 : __torch__.torch.nn.modules.linear.___torch_mangle_34368.Linear = prim::GetAttr[name="q"](%1017)
  %1035 : int = aten::size(%1029, %668), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:322:0
  %1036 : Tensor = prim::GetAttr[name="weight"](%1034)
  %1037 : Float(512:1, 512:512) = aten::t(%1036), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention/__module.decoder.block.1.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %x.91 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1029, %1037), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention/__module.decoder.block.1.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %1039 : int[] = prim::ListConstruct(%1035, %666, %644, %645), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention
  %1040 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.91, %1039), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %q.10 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1040, %667, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1042 : Tensor = prim::GetAttr[name="weight"](%1033)
  %1043 : Float(512:1, 512:512) = aten::t(%1042), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention/__module.decoder.block.1.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %x.92 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1043), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention/__module.decoder.block.1.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %1045 : int[] = prim::ListConstruct(%1035, %666, %644, %645), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention
  %1046 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.92, %1045), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %k.10 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1046, %667, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1048 : Tensor = prim::GetAttr[name="weight"](%1032)
  %1049 : Float(512:1, 512:512) = aten::t(%1048), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention/__module.decoder.block.1.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %x.93 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1049), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention/__module.decoder.block.1.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %1051 : int[] = prim::ListConstruct(%1035, %666, %644, %645), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention
  %1052 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.93, %1051), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %v.10 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1052, %667, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1054 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.10, %659, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:373:0
  %scores.19 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.10, %1054), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:372:0
  %scores.20 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.19, %945, %667), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:389:0
  %input.90 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.20, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:390:0
  %1058 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.90, %666, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # torch/nn/functional.py:1498:0
  %weights.10 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%1058, %655, %665), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # torch/nn/functional.py:973:0
  %x.94 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.10, %v.10), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:397:0
  %1061 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.94, %667, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1062 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1061, %668), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1063 : int[] = prim::ListConstruct(%1035, %666, %652), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention
  %input.92 : Float(17:6656, 13:512, 512:1) = aten::view(%1062, %1063), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1065 : Tensor = prim::GetAttr[name="weight"](%1031)
  %1066 : Float(512:1, 512:512) = aten::t(%1065), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention/__module.decoder.block.1.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %input.93 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.92, %1066), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.EncDecAttention/__module.decoder.block.1.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %1068 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.93, %k.10, %v.10)
  %1069 : Float(17:6656, 13:512, 512:1), %1070 : Float(17:6656, 8:64, 13:512, 64:1), %1071 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1068)
  %y.17 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1069, %655, %665), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1/__module.decoder.block.1.layer.1.dropout # torch/nn/functional.py:973:0
  %x.95 : Float(17:6656, 13:512, 512:1) = aten::add(%1030, %y.17, %667), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.1 # transformers/modeling_t5.py:476:0
  %1074 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.95, %1070, %1071)
  %1075 : Float(17:6656, 13:512, 512:1), %1076 : Float(17:6656, 8:64, 13:512, 64:1), %1077 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1074)
  %1078 : __torch__.transformers.modeling_t5.___torch_mangle_34379.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%951)
  %1079 : __torch__.transformers.modeling_t5.___torch_mangle_34380.T5LayerNorm = prim::GetAttr[name="layer_norm"](%951)
  %1080 : Tensor = prim::GetAttr[name="weight"](%1079)
  %x.96 : Float(17:6656, 13:512, 512:1) = aten::to(%1075, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1082 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.96, %661), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1083 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.layer_norm
  %variance.19 : Float(17:13, 13:1, 1:1) = aten::mean(%1082, %1083, %653, %662), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1085 : Float(17:13, 13:1, 1:1) = aten::add(%variance.19, %654, %667), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %1086 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1085), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %x.97 : Float(17:6656, 13:512, 512:1) = aten::div(%x.96, %1086), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %input.94 : Float(17:6656, 13:512, 512:1) = aten::mul(%1080, %x.97), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.layer_norm # transformers/modeling_t5.py:172:0
  %1089 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.94, %x.96)
  %1090 : Float(17:6656, 13:512, 512:1), %1091 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1089)
  %1092 : __torch__.torch.nn.modules.linear.___torch_mangle_34377.Linear = prim::GetAttr[name="wo"](%1078)
  %1093 : __torch__.torch.nn.modules.linear.___torch_mangle_34376.Linear = prim::GetAttr[name="wi"](%1078)
  %1094 : Tensor = prim::GetAttr[name="weight"](%1093)
  %1095 : Float(512:1, 2048:512) = aten::t(%1094), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.DenseReluDense/__module.decoder.block.1.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.95 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%1090, %1095), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.DenseReluDense/__module.decoder.block.1.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.96 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.95), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.DenseReluDense # torch/nn/functional.py:1119:0
  %input.97 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.96, %655, %665), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.DenseReluDense/__module.decoder.block.1.layer.2.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %1099 : Tensor = prim::GetAttr[name="weight"](%1092)
  %1100 : Float(2048:1, 512:2048) = aten::t(%1099), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.DenseReluDense/__module.decoder.block.1.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.98 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.97, %1100), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.DenseReluDense/__module.decoder.block.1.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.18 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.98, %655, %665), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2/__module.decoder.block.1.layer.2.dropout # torch/nn/functional.py:973:0
  %x.98 : Float(17:6656, 13:512, 512:1) = aten::add(%1091, %y.18, %667), scope: __module.decoder/__module.decoder.block.1/__module.decoder.block.1.layer.2 # transformers/modeling_t5.py:200:0
  %1104 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.98, %1014, %1016, %1076, %1077)
  %1105 : Float(17:6656, 13:512, 512:1), %1106 : Float(17:6656, 8:64, 13:512, 64:1), %1107 : Float(17:6656, 8:64, 13:512, 64:1), %1108 : Float(17:6656, 8:64, 13:512, 64:1), %1109 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1104)
  %1110 : __torch__.torch.nn.modules.container.___torch_mangle_34408.ModuleList = prim::GetAttr[name="layer"](%677)
  %1111 : __torch__.transformers.modeling_t5.___torch_mangle_34407.T5LayerFF = prim::GetAttr[name="2"](%1110)
  %1112 : __torch__.torch.nn.modules.container.___torch_mangle_34408.ModuleList = prim::GetAttr[name="layer"](%677)
  %1113 : __torch__.transformers.modeling_t5.___torch_mangle_34400.T5LayerCrossAttention = prim::GetAttr[name="1"](%1112)
  %1114 : __torch__.torch.nn.modules.container.___torch_mangle_34408.ModuleList = prim::GetAttr[name="layer"](%677)
  %1115 : __torch__.transformers.modeling_t5.___torch_mangle_34392.T5LayerSelfAttention = prim::GetAttr[name="0"](%1114)
  %1116 : __torch__.transformers.modeling_t5.___torch_mangle_34389.T5Attention = prim::GetAttr[name="SelfAttention"](%1115)
  %1117 : __torch__.transformers.modeling_t5.___torch_mangle_34390.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1115)
  %1118 : Tensor = prim::GetAttr[name="weight"](%1117)
  %x.99 : Float(17:6656, 13:512, 512:1) = aten::to(%1105, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1120 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.99, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1121 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.layer_norm
  %variance.20 : Float(17:13, 13:1, 1:1) = aten::mean(%1120, %1121, %653, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1123 : Float(17:13, 13:1, 1:1) = aten::add(%variance.20, %654, %667), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %1124 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1123), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.100 : Float(17:6656, 13:512, 512:1) = aten::div(%x.99, %1124), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.99 : Float(17:6656, 13:512, 512:1) = aten::mul(%1118, %x.100), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %1127 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.99, %x.99)
  %1128 : Float(17:6656, 13:512, 512:1), %1129 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1127)
  %1130 : __torch__.torch.nn.modules.linear.___torch_mangle_34388.Linear = prim::GetAttr[name="o"](%1116)
  %1131 : __torch__.torch.nn.modules.linear.___torch_mangle_34387.Linear = prim::GetAttr[name="v"](%1116)
  %1132 : __torch__.torch.nn.modules.linear.___torch_mangle_34386.Linear = prim::GetAttr[name="k"](%1116)
  %1133 : __torch__.torch.nn.modules.linear.___torch_mangle_34385.Linear = prim::GetAttr[name="q"](%1116)
  %1134 : int = aten::size(%1128, %668), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %1135 : Tensor = prim::GetAttr[name="weight"](%1133)
  %1136 : Float(512:1, 512:512) = aten::t(%1135), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention/__module.decoder.block.2.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.101 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1128, %1136), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention/__module.decoder.block.2.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %1138 : int[] = prim::ListConstruct(%1134, %666, %644, %645), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention
  %1139 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.101, %1138), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.11 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1139, %667, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1141 : Tensor = prim::GetAttr[name="weight"](%1132)
  %1142 : Float(512:1, 512:512) = aten::t(%1141), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention/__module.decoder.block.2.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.102 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1128, %1142), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention/__module.decoder.block.2.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %1144 : int[] = prim::ListConstruct(%1134, %666, %644, %645), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention
  %1145 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.102, %1144), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.11 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1145, %667, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1147 : Tensor = prim::GetAttr[name="weight"](%1131)
  %1148 : Float(512:1, 512:512) = aten::t(%1147), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention/__module.decoder.block.2.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.103 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1128, %1148), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention/__module.decoder.block.2.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %1150 : int[] = prim::ListConstruct(%1134, %666, %644, %645), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention
  %1151 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.103, %1150), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.11 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1151, %667, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1153 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.11, %659, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.21 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.11, %1153), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.22 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.21, %944, %667), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.100 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.22, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %1157 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.100, %666, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.11 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%1157, %655, %665), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.104 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.11, %v.11), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %1160 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.104, %667, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1161 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1160, %668), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1162 : int[] = prim::ListConstruct(%1134, %666, %652), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention
  %input.102 : Float(17:6656, 13:512, 512:1) = aten::view(%1161, %1162), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1164 : Tensor = prim::GetAttr[name="weight"](%1130)
  %1165 : Float(512:1, 512:512) = aten::t(%1164), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention/__module.decoder.block.2.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.103 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.102, %1165), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.SelfAttention/__module.decoder.block.2.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %1167 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.103, %k.11, %v.11)
  %1168 : Float(17:6656, 13:512, 512:1), %1169 : Float(17:6656, 8:64, 13:512, 64:1), %1170 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1167)
  %y.19 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1168, %655, %665), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0/__module.decoder.block.2.layer.0.dropout # torch/nn/functional.py:973:0
  %x.105 : Float(17:6656, 13:512, 512:1) = aten::add(%1129, %y.19, %667), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.0 # transformers/modeling_t5.py:439:0
  %1173 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%1169, %x.105, %1170)
  %1174 : Float(17:6656, 8:64, 13:512, 64:1), %1175 : Float(17:6656, 13:512, 512:1), %1176 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1173)
  %1177 : __torch__.transformers.modeling_t5.___torch_mangle_34397.T5Attention = prim::GetAttr[name="EncDecAttention"](%1113)
  %1178 : __torch__.transformers.modeling_t5.___torch_mangle_34398.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1113)
  %1179 : Tensor = prim::GetAttr[name="weight"](%1178)
  %x.106 : Float(17:6656, 13:512, 512:1) = aten::to(%1175, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1181 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.106, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1182 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.layer_norm
  %variance.21 : Float(17:13, 13:1, 1:1) = aten::mean(%1181, %1182, %653, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1184 : Float(17:13, 13:1, 1:1) = aten::add(%variance.21, %654, %667), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %1185 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1184), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.107 : Float(17:6656, 13:512, 512:1) = aten::div(%x.106, %1185), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.104 : Float(17:6656, 13:512, 512:1) = aten::mul(%1179, %x.107), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %1188 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.104, %x.106)
  %1189 : Float(17:6656, 13:512, 512:1), %1190 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1188)
  %1191 : __torch__.torch.nn.modules.linear.___torch_mangle_34396.Linear = prim::GetAttr[name="o"](%1177)
  %1192 : __torch__.torch.nn.modules.linear.___torch_mangle_34395.Linear = prim::GetAttr[name="v"](%1177)
  %1193 : __torch__.torch.nn.modules.linear.___torch_mangle_34394.Linear = prim::GetAttr[name="k"](%1177)
  %1194 : __torch__.torch.nn.modules.linear.___torch_mangle_34393.Linear = prim::GetAttr[name="q"](%1177)
  %1195 : int = aten::size(%1189, %668), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:322:0
  %1196 : Tensor = prim::GetAttr[name="weight"](%1194)
  %1197 : Float(512:1, 512:512) = aten::t(%1196), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention/__module.decoder.block.2.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %x.108 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1189, %1197), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention/__module.decoder.block.2.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %1199 : int[] = prim::ListConstruct(%1195, %666, %644, %645), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention
  %1200 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.108, %1199), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %q.12 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1200, %667, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1202 : Tensor = prim::GetAttr[name="weight"](%1193)
  %1203 : Float(512:1, 512:512) = aten::t(%1202), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention/__module.decoder.block.2.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %x.109 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1203), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention/__module.decoder.block.2.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %1205 : int[] = prim::ListConstruct(%1195, %666, %644, %645), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention
  %1206 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.109, %1205), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %k.12 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1206, %667, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1208 : Tensor = prim::GetAttr[name="weight"](%1192)
  %1209 : Float(512:1, 512:512) = aten::t(%1208), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention/__module.decoder.block.2.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %x.110 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1209), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention/__module.decoder.block.2.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %1211 : int[] = prim::ListConstruct(%1195, %666, %644, %645), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention
  %1212 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.110, %1211), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %v.12 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1212, %667, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1214 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.12, %659, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:373:0
  %scores.23 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.12, %1214), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:372:0
  %scores.24 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.23, %945, %667), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:389:0
  %input.105 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.24, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:390:0
  %1218 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.105, %666, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # torch/nn/functional.py:1498:0
  %weights.12 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%1218, %655, %665), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # torch/nn/functional.py:973:0
  %x.111 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.12, %v.12), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:397:0
  %1221 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.111, %667, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1222 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1221, %668), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1223 : int[] = prim::ListConstruct(%1195, %666, %652), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention
  %input.107 : Float(17:6656, 13:512, 512:1) = aten::view(%1222, %1223), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1225 : Tensor = prim::GetAttr[name="weight"](%1191)
  %1226 : Float(512:1, 512:512) = aten::t(%1225), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention/__module.decoder.block.2.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %input.108 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.107, %1226), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.EncDecAttention/__module.decoder.block.2.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %1228 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.108, %k.12, %v.12)
  %1229 : Float(17:6656, 13:512, 512:1), %1230 : Float(17:6656, 8:64, 13:512, 64:1), %1231 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1228)
  %y.20 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1229, %655, %665), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1/__module.decoder.block.2.layer.1.dropout # torch/nn/functional.py:973:0
  %x.112 : Float(17:6656, 13:512, 512:1) = aten::add(%1190, %y.20, %667), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.1 # transformers/modeling_t5.py:476:0
  %1234 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.112, %1230, %1231)
  %1235 : Float(17:6656, 13:512, 512:1), %1236 : Float(17:6656, 8:64, 13:512, 64:1), %1237 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1234)
  %1238 : __torch__.transformers.modeling_t5.___torch_mangle_34404.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%1111)
  %1239 : __torch__.transformers.modeling_t5.___torch_mangle_34405.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1111)
  %1240 : Tensor = prim::GetAttr[name="weight"](%1239)
  %x.113 : Float(17:6656, 13:512, 512:1) = aten::to(%1235, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1242 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.113, %661), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1243 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.layer_norm
  %variance.22 : Float(17:13, 13:1, 1:1) = aten::mean(%1242, %1243, %653, %662), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1245 : Float(17:13, 13:1, 1:1) = aten::add(%variance.22, %654, %667), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %1246 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1245), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %x.114 : Float(17:6656, 13:512, 512:1) = aten::div(%x.113, %1246), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %input.109 : Float(17:6656, 13:512, 512:1) = aten::mul(%1240, %x.114), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.layer_norm # transformers/modeling_t5.py:172:0
  %1249 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.109, %x.113)
  %1250 : Float(17:6656, 13:512, 512:1), %1251 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1249)
  %1252 : __torch__.torch.nn.modules.linear.___torch_mangle_34402.Linear = prim::GetAttr[name="wo"](%1238)
  %1253 : __torch__.torch.nn.modules.linear.___torch_mangle_34401.Linear = prim::GetAttr[name="wi"](%1238)
  %1254 : Tensor = prim::GetAttr[name="weight"](%1253)
  %1255 : Float(512:1, 2048:512) = aten::t(%1254), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.DenseReluDense/__module.decoder.block.2.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.110 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%1250, %1255), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.DenseReluDense/__module.decoder.block.2.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.111 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.110), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.DenseReluDense # torch/nn/functional.py:1119:0
  %input.112 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.111, %655, %665), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.DenseReluDense/__module.decoder.block.2.layer.2.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %1259 : Tensor = prim::GetAttr[name="weight"](%1252)
  %1260 : Float(2048:1, 512:2048) = aten::t(%1259), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.DenseReluDense/__module.decoder.block.2.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.113 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.112, %1260), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.DenseReluDense/__module.decoder.block.2.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.21 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.113, %655, %665), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2/__module.decoder.block.2.layer.2.dropout # torch/nn/functional.py:973:0
  %x.115 : Float(17:6656, 13:512, 512:1) = aten::add(%1251, %y.21, %667), scope: __module.decoder/__module.decoder.block.2/__module.decoder.block.2.layer.2 # transformers/modeling_t5.py:200:0
  %1264 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.115, %1174, %1176, %1236, %1237)
  %1265 : Float(17:6656, 13:512, 512:1), %1266 : Float(17:6656, 8:64, 13:512, 64:1), %1267 : Float(17:6656, 8:64, 13:512, 64:1), %1268 : Float(17:6656, 8:64, 13:512, 64:1), %1269 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1264)
  %1270 : __torch__.torch.nn.modules.container.___torch_mangle_34433.ModuleList = prim::GetAttr[name="layer"](%675)
  %1271 : __torch__.transformers.modeling_t5.___torch_mangle_34432.T5LayerFF = prim::GetAttr[name="2"](%1270)
  %1272 : __torch__.torch.nn.modules.container.___torch_mangle_34433.ModuleList = prim::GetAttr[name="layer"](%675)
  %1273 : __torch__.transformers.modeling_t5.___torch_mangle_34425.T5LayerCrossAttention = prim::GetAttr[name="1"](%1272)
  %1274 : __torch__.torch.nn.modules.container.___torch_mangle_34433.ModuleList = prim::GetAttr[name="layer"](%675)
  %1275 : __torch__.transformers.modeling_t5.___torch_mangle_34417.T5LayerSelfAttention = prim::GetAttr[name="0"](%1274)
  %1276 : __torch__.transformers.modeling_t5.___torch_mangle_34414.T5Attention = prim::GetAttr[name="SelfAttention"](%1275)
  %1277 : __torch__.transformers.modeling_t5.___torch_mangle_34415.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1275)
  %1278 : Tensor = prim::GetAttr[name="weight"](%1277)
  %x.116 : Float(17:6656, 13:512, 512:1) = aten::to(%1265, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1280 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.116, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1281 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.layer_norm
  %variance.23 : Float(17:13, 13:1, 1:1) = aten::mean(%1280, %1281, %653, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1283 : Float(17:13, 13:1, 1:1) = aten::add(%variance.23, %654, %667), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %1284 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1283), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.117 : Float(17:6656, 13:512, 512:1) = aten::div(%x.116, %1284), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.114 : Float(17:6656, 13:512, 512:1) = aten::mul(%1278, %x.117), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %1287 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.114, %x.116)
  %1288 : Float(17:6656, 13:512, 512:1), %1289 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1287)
  %1290 : __torch__.torch.nn.modules.linear.___torch_mangle_34413.Linear = prim::GetAttr[name="o"](%1276)
  %1291 : __torch__.torch.nn.modules.linear.___torch_mangle_34412.Linear = prim::GetAttr[name="v"](%1276)
  %1292 : __torch__.torch.nn.modules.linear.___torch_mangle_34411.Linear = prim::GetAttr[name="k"](%1276)
  %1293 : __torch__.torch.nn.modules.linear.___torch_mangle_34410.Linear = prim::GetAttr[name="q"](%1276)
  %1294 : int = aten::size(%1288, %668), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %1295 : Tensor = prim::GetAttr[name="weight"](%1293)
  %1296 : Float(512:1, 512:512) = aten::t(%1295), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention/__module.decoder.block.3.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.118 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1288, %1296), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention/__module.decoder.block.3.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %1298 : int[] = prim::ListConstruct(%1294, %666, %644, %645), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention
  %1299 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.118, %1298), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.13 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1299, %667, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1301 : Tensor = prim::GetAttr[name="weight"](%1292)
  %1302 : Float(512:1, 512:512) = aten::t(%1301), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention/__module.decoder.block.3.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.119 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1288, %1302), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention/__module.decoder.block.3.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %1304 : int[] = prim::ListConstruct(%1294, %666, %644, %645), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention
  %1305 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.119, %1304), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.13 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1305, %667, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1307 : Tensor = prim::GetAttr[name="weight"](%1291)
  %1308 : Float(512:1, 512:512) = aten::t(%1307), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention/__module.decoder.block.3.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.120 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1288, %1308), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention/__module.decoder.block.3.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %1310 : int[] = prim::ListConstruct(%1294, %666, %644, %645), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention
  %1311 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.120, %1310), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.13 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1311, %667, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1313 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.13, %659, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.25 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.13, %1313), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.26 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.25, %944, %667), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.115 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.26, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %1317 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.115, %666, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.13 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%1317, %655, %665), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.121 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.13, %v.13), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %1320 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.121, %667, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1321 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1320, %668), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1322 : int[] = prim::ListConstruct(%1294, %666, %652), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention
  %input.117 : Float(17:6656, 13:512, 512:1) = aten::view(%1321, %1322), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1324 : Tensor = prim::GetAttr[name="weight"](%1290)
  %1325 : Float(512:1, 512:512) = aten::t(%1324), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention/__module.decoder.block.3.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.118 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.117, %1325), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.SelfAttention/__module.decoder.block.3.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %1327 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.118, %k.13, %v.13)
  %1328 : Float(17:6656, 13:512, 512:1), %1329 : Float(17:6656, 8:64, 13:512, 64:1), %1330 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1327)
  %y.22 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1328, %655, %665), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0/__module.decoder.block.3.layer.0.dropout # torch/nn/functional.py:973:0
  %x.122 : Float(17:6656, 13:512, 512:1) = aten::add(%1289, %y.22, %667), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.0 # transformers/modeling_t5.py:439:0
  %1333 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%1329, %x.122, %1330)
  %1334 : Float(17:6656, 8:64, 13:512, 64:1), %1335 : Float(17:6656, 13:512, 512:1), %1336 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1333)
  %1337 : __torch__.transformers.modeling_t5.___torch_mangle_34422.T5Attention = prim::GetAttr[name="EncDecAttention"](%1273)
  %1338 : __torch__.transformers.modeling_t5.___torch_mangle_34423.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1273)
  %1339 : Tensor = prim::GetAttr[name="weight"](%1338)
  %x.123 : Float(17:6656, 13:512, 512:1) = aten::to(%1335, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1341 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.123, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1342 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.layer_norm
  %variance.24 : Float(17:13, 13:1, 1:1) = aten::mean(%1341, %1342, %653, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1344 : Float(17:13, 13:1, 1:1) = aten::add(%variance.24, %654, %667), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %1345 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1344), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.124 : Float(17:6656, 13:512, 512:1) = aten::div(%x.123, %1345), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.119 : Float(17:6656, 13:512, 512:1) = aten::mul(%1339, %x.124), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %1348 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.119, %x.123)
  %1349 : Float(17:6656, 13:512, 512:1), %1350 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1348)
  %1351 : __torch__.torch.nn.modules.linear.___torch_mangle_34421.Linear = prim::GetAttr[name="o"](%1337)
  %1352 : __torch__.torch.nn.modules.linear.___torch_mangle_34420.Linear = prim::GetAttr[name="v"](%1337)
  %1353 : __torch__.torch.nn.modules.linear.___torch_mangle_34419.Linear = prim::GetAttr[name="k"](%1337)
  %1354 : __torch__.torch.nn.modules.linear.___torch_mangle_34418.Linear = prim::GetAttr[name="q"](%1337)
  %1355 : int = aten::size(%1349, %668), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:322:0
  %1356 : Tensor = prim::GetAttr[name="weight"](%1354)
  %1357 : Float(512:1, 512:512) = aten::t(%1356), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention/__module.decoder.block.3.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %x.125 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1349, %1357), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention/__module.decoder.block.3.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %1359 : int[] = prim::ListConstruct(%1355, %666, %644, %645), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention
  %1360 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.125, %1359), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %q.14 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1360, %667, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1362 : Tensor = prim::GetAttr[name="weight"](%1353)
  %1363 : Float(512:1, 512:512) = aten::t(%1362), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention/__module.decoder.block.3.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %x.126 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1363), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention/__module.decoder.block.3.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %1365 : int[] = prim::ListConstruct(%1355, %666, %644, %645), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention
  %1366 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.126, %1365), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %k.14 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1366, %667, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1368 : Tensor = prim::GetAttr[name="weight"](%1352)
  %1369 : Float(512:1, 512:512) = aten::t(%1368), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention/__module.decoder.block.3.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %x.127 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1369), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention/__module.decoder.block.3.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %1371 : int[] = prim::ListConstruct(%1355, %666, %644, %645), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention
  %1372 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.127, %1371), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %v.14 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1372, %667, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1374 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.14, %659, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:373:0
  %scores.27 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.14, %1374), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:372:0
  %scores.28 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.27, %945, %667), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:389:0
  %input.120 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.28, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:390:0
  %1378 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.120, %666, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # torch/nn/functional.py:1498:0
  %weights.14 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%1378, %655, %665), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # torch/nn/functional.py:973:0
  %x.128 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.14, %v.14), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:397:0
  %1381 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.128, %667, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1382 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1381, %668), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1383 : int[] = prim::ListConstruct(%1355, %666, %652), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention
  %input.122 : Float(17:6656, 13:512, 512:1) = aten::view(%1382, %1383), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1385 : Tensor = prim::GetAttr[name="weight"](%1351)
  %1386 : Float(512:1, 512:512) = aten::t(%1385), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention/__module.decoder.block.3.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %input.123 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.122, %1386), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.EncDecAttention/__module.decoder.block.3.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %1388 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.123, %k.14, %v.14)
  %1389 : Float(17:6656, 13:512, 512:1), %1390 : Float(17:6656, 8:64, 13:512, 64:1), %1391 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1388)
  %y.23 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1389, %655, %665), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1/__module.decoder.block.3.layer.1.dropout # torch/nn/functional.py:973:0
  %x.129 : Float(17:6656, 13:512, 512:1) = aten::add(%1350, %y.23, %667), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.1 # transformers/modeling_t5.py:476:0
  %1394 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.129, %1390, %1391)
  %1395 : Float(17:6656, 13:512, 512:1), %1396 : Float(17:6656, 8:64, 13:512, 64:1), %1397 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1394)
  %1398 : __torch__.transformers.modeling_t5.___torch_mangle_34429.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%1271)
  %1399 : __torch__.transformers.modeling_t5.___torch_mangle_34430.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1271)
  %1400 : Tensor = prim::GetAttr[name="weight"](%1399)
  %x.130 : Float(17:6656, 13:512, 512:1) = aten::to(%1395, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1402 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.130, %661), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1403 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.layer_norm
  %variance.25 : Float(17:13, 13:1, 1:1) = aten::mean(%1402, %1403, %653, %662), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1405 : Float(17:13, 13:1, 1:1) = aten::add(%variance.25, %654, %667), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %1406 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1405), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %x.131 : Float(17:6656, 13:512, 512:1) = aten::div(%x.130, %1406), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %input.124 : Float(17:6656, 13:512, 512:1) = aten::mul(%1400, %x.131), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.layer_norm # transformers/modeling_t5.py:172:0
  %1409 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.124, %x.130)
  %1410 : Float(17:6656, 13:512, 512:1), %1411 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1409)
  %1412 : __torch__.torch.nn.modules.linear.___torch_mangle_34427.Linear = prim::GetAttr[name="wo"](%1398)
  %1413 : __torch__.torch.nn.modules.linear.___torch_mangle_34426.Linear = prim::GetAttr[name="wi"](%1398)
  %1414 : Tensor = prim::GetAttr[name="weight"](%1413)
  %1415 : Float(512:1, 2048:512) = aten::t(%1414), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.DenseReluDense/__module.decoder.block.3.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.125 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%1410, %1415), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.DenseReluDense/__module.decoder.block.3.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.126 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.125), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.DenseReluDense # torch/nn/functional.py:1119:0
  %input.127 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.126, %655, %665), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.DenseReluDense/__module.decoder.block.3.layer.2.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %1419 : Tensor = prim::GetAttr[name="weight"](%1412)
  %1420 : Float(2048:1, 512:2048) = aten::t(%1419), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.DenseReluDense/__module.decoder.block.3.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.128 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.127, %1420), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.DenseReluDense/__module.decoder.block.3.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.24 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.128, %655, %665), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2/__module.decoder.block.3.layer.2.dropout # torch/nn/functional.py:973:0
  %x.132 : Float(17:6656, 13:512, 512:1) = aten::add(%1411, %y.24, %667), scope: __module.decoder/__module.decoder.block.3/__module.decoder.block.3.layer.2 # transformers/modeling_t5.py:200:0
  %1424 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.132, %1334, %1336, %1396, %1397)
  %1425 : Float(17:6656, 13:512, 512:1), %1426 : Float(17:6656, 8:64, 13:512, 64:1), %1427 : Float(17:6656, 8:64, 13:512, 64:1), %1428 : Float(17:6656, 8:64, 13:512, 64:1), %1429 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1424)
  %1430 : __torch__.torch.nn.modules.container.___torch_mangle_34458.ModuleList = prim::GetAttr[name="layer"](%673)
  %1431 : __torch__.transformers.modeling_t5.___torch_mangle_34457.T5LayerFF = prim::GetAttr[name="2"](%1430)
  %1432 : __torch__.torch.nn.modules.container.___torch_mangle_34458.ModuleList = prim::GetAttr[name="layer"](%673)
  %1433 : __torch__.transformers.modeling_t5.___torch_mangle_34450.T5LayerCrossAttention = prim::GetAttr[name="1"](%1432)
  %1434 : __torch__.torch.nn.modules.container.___torch_mangle_34458.ModuleList = prim::GetAttr[name="layer"](%673)
  %1435 : __torch__.transformers.modeling_t5.___torch_mangle_34442.T5LayerSelfAttention = prim::GetAttr[name="0"](%1434)
  %1436 : __torch__.transformers.modeling_t5.___torch_mangle_34439.T5Attention = prim::GetAttr[name="SelfAttention"](%1435)
  %1437 : __torch__.transformers.modeling_t5.___torch_mangle_34440.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1435)
  %1438 : Tensor = prim::GetAttr[name="weight"](%1437)
  %x.133 : Float(17:6656, 13:512, 512:1) = aten::to(%1425, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1440 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.133, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1441 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.layer_norm
  %variance.26 : Float(17:13, 13:1, 1:1) = aten::mean(%1440, %1441, %653, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1443 : Float(17:13, 13:1, 1:1) = aten::add(%variance.26, %654, %667), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %1444 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1443), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.134 : Float(17:6656, 13:512, 512:1) = aten::div(%x.133, %1444), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.129 : Float(17:6656, 13:512, 512:1) = aten::mul(%1438, %x.134), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %1447 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.129, %x.133)
  %1448 : Float(17:6656, 13:512, 512:1), %1449 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1447)
  %1450 : __torch__.torch.nn.modules.linear.___torch_mangle_34438.Linear = prim::GetAttr[name="o"](%1436)
  %1451 : __torch__.torch.nn.modules.linear.___torch_mangle_34437.Linear = prim::GetAttr[name="v"](%1436)
  %1452 : __torch__.torch.nn.modules.linear.___torch_mangle_34436.Linear = prim::GetAttr[name="k"](%1436)
  %1453 : __torch__.torch.nn.modules.linear.___torch_mangle_34435.Linear = prim::GetAttr[name="q"](%1436)
  %1454 : int = aten::size(%1448, %668), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %1455 : Tensor = prim::GetAttr[name="weight"](%1453)
  %1456 : Float(512:1, 512:512) = aten::t(%1455), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention/__module.decoder.block.4.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.135 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1448, %1456), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention/__module.decoder.block.4.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %1458 : int[] = prim::ListConstruct(%1454, %666, %644, %645), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention
  %1459 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.135, %1458), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.15 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1459, %667, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1461 : Tensor = prim::GetAttr[name="weight"](%1452)
  %1462 : Float(512:1, 512:512) = aten::t(%1461), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention/__module.decoder.block.4.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.136 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1448, %1462), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention/__module.decoder.block.4.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %1464 : int[] = prim::ListConstruct(%1454, %666, %644, %645), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention
  %1465 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.136, %1464), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.15 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1465, %667, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1467 : Tensor = prim::GetAttr[name="weight"](%1451)
  %1468 : Float(512:1, 512:512) = aten::t(%1467), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention/__module.decoder.block.4.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.137 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1448, %1468), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention/__module.decoder.block.4.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %1470 : int[] = prim::ListConstruct(%1454, %666, %644, %645), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention
  %1471 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.137, %1470), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.15 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1471, %667, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1473 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.15, %659, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.29 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.15, %1473), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.30 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.29, %944, %667), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.130 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.30, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %1477 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.130, %666, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.15 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%1477, %655, %665), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.138 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.15, %v.15), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %1480 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.138, %667, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1481 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1480, %668), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1482 : int[] = prim::ListConstruct(%1454, %666, %652), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention
  %input.132 : Float(17:6656, 13:512, 512:1) = aten::view(%1481, %1482), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1484 : Tensor = prim::GetAttr[name="weight"](%1450)
  %1485 : Float(512:1, 512:512) = aten::t(%1484), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention/__module.decoder.block.4.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.133 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.132, %1485), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.SelfAttention/__module.decoder.block.4.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %1487 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.133, %k.15, %v.15)
  %1488 : Float(17:6656, 13:512, 512:1), %1489 : Float(17:6656, 8:64, 13:512, 64:1), %1490 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1487)
  %y.25 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1488, %655, %665), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0/__module.decoder.block.4.layer.0.dropout # torch/nn/functional.py:973:0
  %x.139 : Float(17:6656, 13:512, 512:1) = aten::add(%1449, %y.25, %667), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.0 # transformers/modeling_t5.py:439:0
  %1493 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%1489, %x.139, %1490)
  %1494 : Float(17:6656, 8:64, 13:512, 64:1), %1495 : Float(17:6656, 13:512, 512:1), %1496 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1493)
  %1497 : __torch__.transformers.modeling_t5.___torch_mangle_34447.T5Attention = prim::GetAttr[name="EncDecAttention"](%1433)
  %1498 : __torch__.transformers.modeling_t5.___torch_mangle_34448.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1433)
  %1499 : Tensor = prim::GetAttr[name="weight"](%1498)
  %x.140 : Float(17:6656, 13:512, 512:1) = aten::to(%1495, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1501 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.140, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1502 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.layer_norm
  %variance.27 : Float(17:13, 13:1, 1:1) = aten::mean(%1501, %1502, %653, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1504 : Float(17:13, 13:1, 1:1) = aten::add(%variance.27, %654, %667), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %1505 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1504), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.141 : Float(17:6656, 13:512, 512:1) = aten::div(%x.140, %1505), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.134 : Float(17:6656, 13:512, 512:1) = aten::mul(%1499, %x.141), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %1508 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.134, %x.140)
  %1509 : Float(17:6656, 13:512, 512:1), %1510 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1508)
  %1511 : __torch__.torch.nn.modules.linear.___torch_mangle_34446.Linear = prim::GetAttr[name="o"](%1497)
  %1512 : __torch__.torch.nn.modules.linear.___torch_mangle_34445.Linear = prim::GetAttr[name="v"](%1497)
  %1513 : __torch__.torch.nn.modules.linear.___torch_mangle_34444.Linear = prim::GetAttr[name="k"](%1497)
  %1514 : __torch__.torch.nn.modules.linear.___torch_mangle_34443.Linear = prim::GetAttr[name="q"](%1497)
  %1515 : int = aten::size(%1509, %668), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:322:0
  %1516 : Tensor = prim::GetAttr[name="weight"](%1514)
  %1517 : Float(512:1, 512:512) = aten::t(%1516), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention/__module.decoder.block.4.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %x.142 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1509, %1517), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention/__module.decoder.block.4.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %1519 : int[] = prim::ListConstruct(%1515, %666, %644, %645), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention
  %1520 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.142, %1519), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %q.16 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1520, %667, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1522 : Tensor = prim::GetAttr[name="weight"](%1513)
  %1523 : Float(512:1, 512:512) = aten::t(%1522), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention/__module.decoder.block.4.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %x.143 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1523), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention/__module.decoder.block.4.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %1525 : int[] = prim::ListConstruct(%1515, %666, %644, %645), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention
  %1526 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.143, %1525), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %k.16 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1526, %667, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1528 : Tensor = prim::GetAttr[name="weight"](%1512)
  %1529 : Float(512:1, 512:512) = aten::t(%1528), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention/__module.decoder.block.4.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %x.144 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1529), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention/__module.decoder.block.4.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %1531 : int[] = prim::ListConstruct(%1515, %666, %644, %645), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention
  %1532 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.144, %1531), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %v.16 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1532, %667, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1534 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.16, %659, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:373:0
  %scores.31 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.16, %1534), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:372:0
  %scores.32 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.31, %945, %667), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:389:0
  %input.135 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.32, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:390:0
  %1538 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.135, %666, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # torch/nn/functional.py:1498:0
  %weights.16 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%1538, %655, %665), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # torch/nn/functional.py:973:0
  %x.145 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.16, %v.16), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:397:0
  %1541 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.145, %667, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1542 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1541, %668), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1543 : int[] = prim::ListConstruct(%1515, %666, %652), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention
  %input.137 : Float(17:6656, 13:512, 512:1) = aten::view(%1542, %1543), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1545 : Tensor = prim::GetAttr[name="weight"](%1511)
  %1546 : Float(512:1, 512:512) = aten::t(%1545), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention/__module.decoder.block.4.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %input.138 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.137, %1546), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.EncDecAttention/__module.decoder.block.4.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %1548 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.138, %k.16, %v.16)
  %1549 : Float(17:6656, 13:512, 512:1), %1550 : Float(17:6656, 8:64, 13:512, 64:1), %1551 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1548)
  %y.26 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1549, %655, %665), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1/__module.decoder.block.4.layer.1.dropout # torch/nn/functional.py:973:0
  %x.146 : Float(17:6656, 13:512, 512:1) = aten::add(%1510, %y.26, %667), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.1 # transformers/modeling_t5.py:476:0
  %1554 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.146, %1550, %1551)
  %1555 : Float(17:6656, 13:512, 512:1), %1556 : Float(17:6656, 8:64, 13:512, 64:1), %1557 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1554)
  %1558 : __torch__.transformers.modeling_t5.___torch_mangle_34454.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%1431)
  %1559 : __torch__.transformers.modeling_t5.___torch_mangle_34455.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1431)
  %1560 : Tensor = prim::GetAttr[name="weight"](%1559)
  %x.147 : Float(17:6656, 13:512, 512:1) = aten::to(%1555, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1562 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.147, %661), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1563 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.layer_norm
  %variance.28 : Float(17:13, 13:1, 1:1) = aten::mean(%1562, %1563, %653, %662), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1565 : Float(17:13, 13:1, 1:1) = aten::add(%variance.28, %654, %667), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %1566 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1565), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %x.148 : Float(17:6656, 13:512, 512:1) = aten::div(%x.147, %1566), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %input.139 : Float(17:6656, 13:512, 512:1) = aten::mul(%1560, %x.148), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.layer_norm # transformers/modeling_t5.py:172:0
  %1569 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.139, %x.147)
  %1570 : Float(17:6656, 13:512, 512:1), %1571 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1569)
  %1572 : __torch__.torch.nn.modules.linear.___torch_mangle_34452.Linear = prim::GetAttr[name="wo"](%1558)
  %1573 : __torch__.torch.nn.modules.linear.___torch_mangle_34451.Linear = prim::GetAttr[name="wi"](%1558)
  %1574 : Tensor = prim::GetAttr[name="weight"](%1573)
  %1575 : Float(512:1, 2048:512) = aten::t(%1574), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.DenseReluDense/__module.decoder.block.4.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.140 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%1570, %1575), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.DenseReluDense/__module.decoder.block.4.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.141 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.140), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.DenseReluDense # torch/nn/functional.py:1119:0
  %input.142 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.141, %655, %665), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.DenseReluDense/__module.decoder.block.4.layer.2.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %1579 : Tensor = prim::GetAttr[name="weight"](%1572)
  %1580 : Float(2048:1, 512:2048) = aten::t(%1579), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.DenseReluDense/__module.decoder.block.4.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.143 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.142, %1580), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.DenseReluDense/__module.decoder.block.4.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y.27 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.143, %655, %665), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2/__module.decoder.block.4.layer.2.dropout # torch/nn/functional.py:973:0
  %x.149 : Float(17:6656, 13:512, 512:1) = aten::add(%1571, %y.27, %667), scope: __module.decoder/__module.decoder.block.4/__module.decoder.block.4.layer.2 # transformers/modeling_t5.py:200:0
  %1584 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.149, %1494, %1496, %1556, %1557)
  %1585 : Float(17:6656, 13:512, 512:1), %1586 : Float(17:6656, 8:64, 13:512, 64:1), %1587 : Float(17:6656, 8:64, 13:512, 64:1), %1588 : Float(17:6656, 8:64, 13:512, 64:1), %1589 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1584)
  %1590 : __torch__.torch.nn.modules.container.___torch_mangle_34483.ModuleList = prim::GetAttr[name="layer"](%671)
  %1591 : __torch__.transformers.modeling_t5.___torch_mangle_34482.T5LayerFF = prim::GetAttr[name="2"](%1590)
  %1592 : __torch__.torch.nn.modules.container.___torch_mangle_34483.ModuleList = prim::GetAttr[name="layer"](%671)
  %1593 : __torch__.transformers.modeling_t5.___torch_mangle_34475.T5LayerCrossAttention = prim::GetAttr[name="1"](%1592)
  %1594 : __torch__.torch.nn.modules.container.___torch_mangle_34483.ModuleList = prim::GetAttr[name="layer"](%671)
  %1595 : __torch__.transformers.modeling_t5.___torch_mangle_34467.T5LayerSelfAttention = prim::GetAttr[name="0"](%1594)
  %1596 : __torch__.transformers.modeling_t5.___torch_mangle_34464.T5Attention = prim::GetAttr[name="SelfAttention"](%1595)
  %1597 : __torch__.transformers.modeling_t5.___torch_mangle_34465.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1595)
  %1598 : Tensor = prim::GetAttr[name="weight"](%1597)
  %x.150 : Float(17:6656, 13:512, 512:1) = aten::to(%1585, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1600 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.150, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1601 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.layer_norm
  %variance.29 : Float(17:13, 13:1, 1:1) = aten::mean(%1600, %1601, %653, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:167:0
  %1603 : Float(17:13, 13:1, 1:1) = aten::add(%variance.29, %654, %667), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %1604 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1603), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %x.151 : Float(17:6656, 13:512, 512:1) = aten::div(%x.150, %1604), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:168:0
  %input.144 : Float(17:6656, 13:512, 512:1) = aten::mul(%1598, %x.151), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.layer_norm # transformers/modeling_t5.py:172:0
  %1607 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.144, %x.150)
  %1608 : Float(17:6656, 13:512, 512:1), %1609 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1607)
  %1610 : __torch__.torch.nn.modules.linear.___torch_mangle_34463.Linear = prim::GetAttr[name="o"](%1596)
  %1611 : __torch__.torch.nn.modules.linear.___torch_mangle_34462.Linear = prim::GetAttr[name="v"](%1596)
  %1612 : __torch__.torch.nn.modules.linear.___torch_mangle_34461.Linear = prim::GetAttr[name="k"](%1596)
  %1613 : __torch__.torch.nn.modules.linear.___torch_mangle_34460.Linear = prim::GetAttr[name="q"](%1596)
  %1614 : int = aten::size(%1608, %668), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:322:0
  %1615 : Tensor = prim::GetAttr[name="weight"](%1613)
  %1616 : Float(512:1, 512:512) = aten::t(%1615), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention/__module.decoder.block.5.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %x.152 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1608, %1616), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention/__module.decoder.block.5.layer.0.SelfAttention.q # torch/nn/functional.py:1676:0
  %1618 : int[] = prim::ListConstruct(%1614, %666, %644, %645), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention
  %1619 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.152, %1618), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %q.17 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1619, %667, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1621 : Tensor = prim::GetAttr[name="weight"](%1612)
  %1622 : Float(512:1, 512:512) = aten::t(%1621), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention/__module.decoder.block.5.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %x.153 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1608, %1622), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention/__module.decoder.block.5.layer.0.SelfAttention.k # torch/nn/functional.py:1676:0
  %1624 : int[] = prim::ListConstruct(%1614, %666, %644, %645), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention
  %1625 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.153, %1624), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %k.17 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1625, %667, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1627 : Tensor = prim::GetAttr[name="weight"](%1611)
  %1628 : Float(512:1, 512:512) = aten::t(%1627), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention/__module.decoder.block.5.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %x.154 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1608, %1628), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention/__module.decoder.block.5.layer.0.SelfAttention.v # torch/nn/functional.py:1676:0
  %1630 : int[] = prim::ListConstruct(%1614, %666, %644, %645), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention
  %1631 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.154, %1630), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %v.17 : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1631, %667, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:342:0
  %1633 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k.17, %659, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:373:0
  %scores.33 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q.17, %1633), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:372:0
  %scores.34 : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.33, %944, %667), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:389:0
  %input.145 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores.34, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:390:0
  %1637 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.145, %666, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # torch/nn/functional.py:1498:0
  %weights.17 : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%1637, %655, %665), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # torch/nn/functional.py:973:0
  %x.155 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights.17, %v.17), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:397:0
  %1640 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.155, %667, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1641 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1640, %668), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1642 : int[] = prim::ListConstruct(%1614, %666, %652), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention
  %input.147 : Float(17:6656, 13:512, 512:1) = aten::view(%1641, %1642), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention # transformers/modeling_t5.py:346:0
  %1644 : Tensor = prim::GetAttr[name="weight"](%1610)
  %1645 : Float(512:1, 512:512) = aten::t(%1644), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention/__module.decoder.block.5.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %input.148 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.147, %1645), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.SelfAttention/__module.decoder.block.5.layer.0.SelfAttention.o # torch/nn/functional.py:1676:0
  %1647 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.148, %k.17, %v.17)
  %1648 : Float(17:6656, 13:512, 512:1), %1649 : Float(17:6656, 8:64, 13:512, 64:1), %1650 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1647)
  %y.28 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1648, %655, %665), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0/__module.decoder.block.5.layer.0.dropout # torch/nn/functional.py:973:0
  %x.156 : Float(17:6656, 13:512, 512:1) = aten::add(%1609, %y.28, %667), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.0 # transformers/modeling_t5.py:439:0
  %1653 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%1649, %x.156, %1650)
  %1654 : Float(17:6656, 8:64, 13:512, 64:1), %1655 : Float(17:6656, 13:512, 512:1), %1656 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1653)
  %1657 : __torch__.transformers.modeling_t5.___torch_mangle_34472.T5Attention = prim::GetAttr[name="EncDecAttention"](%1593)
  %1658 : __torch__.transformers.modeling_t5.___torch_mangle_34473.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1593)
  %1659 : Tensor = prim::GetAttr[name="weight"](%1658)
  %x.157 : Float(17:6656, 13:512, 512:1) = aten::to(%1655, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1661 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.157, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1662 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.layer_norm
  %variance.30 : Float(17:13, 13:1, 1:1) = aten::mean(%1661, %1662, %653, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:167:0
  %1664 : Float(17:13, 13:1, 1:1) = aten::add(%variance.30, %654, %667), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %1665 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1664), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %x.158 : Float(17:6656, 13:512, 512:1) = aten::div(%x.157, %1665), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:168:0
  %input.149 : Float(17:6656, 13:512, 512:1) = aten::mul(%1659, %x.158), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.layer_norm # transformers/modeling_t5.py:172:0
  %1668 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.149, %x.157)
  %1669 : Float(17:6656, 13:512, 512:1), %1670 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1668)
  %1671 : __torch__.torch.nn.modules.linear.___torch_mangle_34471.Linear = prim::GetAttr[name="o"](%1657)
  %1672 : __torch__.torch.nn.modules.linear.___torch_mangle_34470.Linear = prim::GetAttr[name="v"](%1657)
  %1673 : __torch__.torch.nn.modules.linear.___torch_mangle_34469.Linear = prim::GetAttr[name="k"](%1657)
  %1674 : __torch__.torch.nn.modules.linear.___torch_mangle_34468.Linear = prim::GetAttr[name="q"](%1657)
  %1675 : int = aten::size(%1669, %668), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:322:0
  %1676 : Tensor = prim::GetAttr[name="weight"](%1674)
  %1677 : Float(512:1, 512:512) = aten::t(%1676), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention/__module.decoder.block.5.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %x.159 : Float(17:6656, 13:512, 512:1) = aten::matmul(%1669, %1677), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention/__module.decoder.block.5.layer.1.EncDecAttention.q # torch/nn/functional.py:1676:0
  %1679 : int[] = prim::ListConstruct(%1675, %666, %644, %645), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention
  %1680 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.159, %1679), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %q : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1680, %667, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1682 : Tensor = prim::GetAttr[name="weight"](%1673)
  %1683 : Float(512:1, 512:512) = aten::t(%1682), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention/__module.decoder.block.5.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %x.160 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1683), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention/__module.decoder.block.5.layer.1.EncDecAttention.k # torch/nn/functional.py:1676:0
  %1685 : int[] = prim::ListConstruct(%1675, %666, %644, %645), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention
  %1686 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.160, %1685), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %k : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1686, %667, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1688 : Tensor = prim::GetAttr[name="weight"](%1672)
  %1689 : Float(512:1, 512:512) = aten::t(%1688), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention/__module.decoder.block.5.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %x.161 : Float(17:6656, 13:512, 512:1) = aten::matmul(%kv, %1689), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention/__module.decoder.block.5.layer.1.EncDecAttention.v # torch/nn/functional.py:1676:0
  %1691 : int[] = prim::ListConstruct(%1675, %666, %644, %645), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention
  %1692 : Float(17:6656, 13:512, 8:64, 64:1) = aten::view(%x.161, %1691), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %v : Float(17:6656, 8:64, 13:512, 64:1) = aten::transpose(%1692, %667, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:342:0
  %1694 : Float(17:6656, 8:64, 64:1, 13:512) = aten::transpose(%k, %659, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:373:0
  %scores.35 : Float(17:1352, 8:169, 13:13, 13:1) = aten::matmul(%q, %1694), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:372:0
  %scores : Float(17:1352, 8:169, 13:13, 13:1) = aten::add_(%scores.35, %945, %667), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:389:0
  %input.150 : Float(17:1352, 8:169, 13:13, 13:1) = aten::to(%scores, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:390:0
  %1698 : Float(17:1352, 8:169, 13:13, 13:1) = aten::softmax(%input.150, %666, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # torch/nn/functional.py:1498:0
  %weights : Float(17:1352, 8:169, 13:13, 13:1) = aten::dropout(%1698, %655, %665), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # torch/nn/functional.py:973:0
  %x.162 : Float(17:6656, 8:832, 13:64, 64:1) = aten::matmul(%weights, %v), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:397:0
  %1701 : Float(17:6656, 13:64, 8:832, 64:1) = aten::transpose(%x.162, %667, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1702 : Float(17:6656, 13:512, 8:64, 64:1) = aten::contiguous(%1701, %668), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1703 : int[] = prim::ListConstruct(%1675, %666, %652), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention
  %input.152 : Float(17:6656, 13:512, 512:1) = aten::view(%1702, %1703), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention # transformers/modeling_t5.py:346:0
  %1705 : Tensor = prim::GetAttr[name="weight"](%1671)
  %1706 : Float(512:1, 512:512) = aten::t(%1705), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention/__module.decoder.block.5.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %input.153 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.152, %1706), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.EncDecAttention/__module.decoder.block.5.layer.1.EncDecAttention.o # torch/nn/functional.py:1676:0
  %1708 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%input.153, %k, %v)
  %1709 : Float(17:6656, 13:512, 512:1), %1710 : Float(17:6656, 8:64, 13:512, 64:1), %1711 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1708)
  %y.29 : Float(17:6656, 13:512, 512:1) = aten::dropout(%1709, %655, %665), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1/__module.decoder.block.5.layer.1.dropout # torch/nn/functional.py:973:0
  %x.163 : Float(17:6656, 13:512, 512:1) = aten::add(%1670, %y.29, %667), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.1 # transformers/modeling_t5.py:476:0
  %1714 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.163, %1710, %1711)
  %1715 : Float(17:6656, 13:512, 512:1), %1716 : Float(17:6656, 8:64, 13:512, 64:1), %1717 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1714)
  %1718 : __torch__.transformers.modeling_t5.___torch_mangle_34479.T5DenseReluDense = prim::GetAttr[name="DenseReluDense"](%1591)
  %1719 : __torch__.transformers.modeling_t5.___torch_mangle_34480.T5LayerNorm = prim::GetAttr[name="layer_norm"](%1591)
  %1720 : Tensor = prim::GetAttr[name="weight"](%1719)
  %x.164 : Float(17:6656, 13:512, 512:1) = aten::to(%1715, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1722 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.164, %661), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1723 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.layer_norm
  %variance.31 : Float(17:13, 13:1, 1:1) = aten::mean(%1722, %1723, %653, %662), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.layer_norm # transformers/modeling_t5.py:167:0
  %1725 : Float(17:13, 13:1, 1:1) = aten::add(%variance.31, %654, %667), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %1726 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1725), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %x.165 : Float(17:6656, 13:512, 512:1) = aten::div(%x.164, %1726), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.layer_norm # transformers/modeling_t5.py:168:0
  %input.154 : Float(17:6656, 13:512, 512:1) = aten::mul(%1720, %x.165), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.layer_norm # transformers/modeling_t5.py:172:0
  %1729 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%input.154, %x.164)
  %1730 : Float(17:6656, 13:512, 512:1), %1731 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1729)
  %1732 : __torch__.torch.nn.modules.linear.___torch_mangle_34477.Linear = prim::GetAttr[name="wo"](%1718)
  %1733 : __torch__.torch.nn.modules.linear.___torch_mangle_34476.Linear = prim::GetAttr[name="wi"](%1718)
  %1734 : Tensor = prim::GetAttr[name="weight"](%1733)
  %1735 : Float(512:1, 2048:512) = aten::t(%1734), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.DenseReluDense/__module.decoder.block.5.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.155 : Float(17:26624, 13:2048, 2048:1) = aten::matmul(%1730, %1735), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.DenseReluDense/__module.decoder.block.5.layer.2.DenseReluDense.wi # torch/nn/functional.py:1676:0
  %input.156 : Float(17:26624, 13:2048, 2048:1) = aten::relu(%input.155), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.DenseReluDense # torch/nn/functional.py:1119:0
  %input.157 : Float(17:26624, 13:2048, 2048:1) = aten::dropout(%input.156, %655, %665), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.DenseReluDense/__module.decoder.block.5.layer.2.DenseReluDense.dropout # torch/nn/functional.py:973:0
  %1739 : Tensor = prim::GetAttr[name="weight"](%1732)
  %1740 : Float(2048:1, 512:2048) = aten::t(%1739), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.DenseReluDense/__module.decoder.block.5.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %input.158 : Float(17:6656, 13:512, 512:1) = aten::matmul(%input.157, %1740), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.DenseReluDense/__module.decoder.block.5.layer.2.DenseReluDense.wo # torch/nn/functional.py:1676:0
  %y : Float(17:6656, 13:512, 512:1) = aten::dropout(%input.158, %655, %665), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2/__module.decoder.block.5.layer.2.dropout # torch/nn/functional.py:973:0
  %x.166 : Float(17:6656, 13:512, 512:1) = aten::add(%1731, %y, %667), scope: __module.decoder/__module.decoder.block.5/__module.decoder.block.5.layer.2 # transformers/modeling_t5.py:200:0
  %1744 : (Float(17:6656, 13:512, 512:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%x.166, %1654, %1656, %1716, %1717)
  %1745 : Float(17:6656, 13:512, 512:1), %1746 : Float(17:6656, 8:64, 13:512, 64:1), %1747 : Float(17:6656, 8:64, 13:512, 64:1), %1748 : Float(17:6656, 8:64, 13:512, 64:1), %1749 : Float(17:6656, 8:64, 13:512, 64:1) = prim::TupleUnpack(%1744)
  %1750 : Tensor = prim::GetAttr[name="weight"](%669)
  %x.167 : Float(17:6656, 13:512, 512:1) = aten::to(%1745, %664, %665, %665, %662), scope: __module.decoder/__module.decoder.final_layer_norm # transformers/modeling_t5.py:167:0
  %1752 : Float(17:6656, 13:512, 512:1) = aten::pow(%x.167, %661), scope: __module.decoder/__module.decoder.final_layer_norm # transformers/modeling_t5.py:167:0
  %1753 : int[] = prim::ListConstruct(%666), scope: __module.decoder/__module.decoder.final_layer_norm
  %variance : Float(17:13, 13:1, 1:1) = aten::mean(%1752, %1753, %653, %662), scope: __module.decoder/__module.decoder.final_layer_norm # transformers/modeling_t5.py:167:0
  %1755 : Float(17:13, 13:1, 1:1) = aten::add(%variance, %654, %667), scope: __module.decoder/__module.decoder.final_layer_norm # transformers/modeling_t5.py:168:0
  %1756 : Float(17:13, 13:1, 1:1) = aten::sqrt(%1755), scope: __module.decoder/__module.decoder.final_layer_norm # transformers/modeling_t5.py:168:0
  %x : Float(17:6656, 13:512, 512:1) = aten::div(%x.167, %1756), scope: __module.decoder/__module.decoder.final_layer_norm # transformers/modeling_t5.py:168:0
  %input : Float(17:6656, 13:512, 512:1) = aten::mul(%1750, %x), scope: __module.decoder/__module.decoder.final_layer_norm # transformers/modeling_t5.py:172:0
  %1759 : Float(17:6656, 13:512, 512:1) = aten::dropout(%input, %655, %665), scope: __module.decoder/__module.decoder.dropout # torch/nn/functional.py:973:0
  %1760 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%946, %947, %948, %949, %1106, %1107, %1108, %1109, %1266, %1267, %1268, %1269, %1426, %1427, %1428, %1429, %1586, %1587, %1588, %1589, %1746, %1747, %1748, %1749, %1759)
  %11 : Float(17:6656, 8:64, 13:512, 64:1), %12 : Float(17:6656, 8:64, 13:512, 64:1), %13 : Float(17:6656, 8:64, 13:512, 64:1), %14 : Float(17:6656, 8:64, 13:512, 64:1), %15 : Float(17:6656, 8:64, 13:512, 64:1), %16 : Float(17:6656, 8:64, 13:512, 64:1), %17 : Float(17:6656, 8:64, 13:512, 64:1), %18 : Float(17:6656, 8:64, 13:512, 64:1), %19 : Float(17:6656, 8:64, 13:512, 64:1), %20 : Float(17:6656, 8:64, 13:512, 64:1), %21 : Float(17:6656, 8:64, 13:512, 64:1), %22 : Float(17:6656, 8:64, 13:512, 64:1), %23 : Float(17:6656, 8:64, 13:512, 64:1), %24 : Float(17:6656, 8:64, 13:512, 64:1), %25 : Float(17:6656, 8:64, 13:512, 64:1), %26 : Float(17:6656, 8:64, 13:512, 64:1), %27 : Float(17:6656, 8:64, 13:512, 64:1), %28 : Float(17:6656, 8:64, 13:512, 64:1), %29 : Float(17:6656, 8:64, 13:512, 64:1), %30 : Float(17:6656, 8:64, 13:512, 64:1), %31 : Float(17:6656, 8:64, 13:512, 64:1), %32 : Float(17:6656, 8:64, 13:512, 64:1), %33 : Float(17:6656, 8:64, 13:512, 64:1), %34 : Float(17:6656, 8:64, 13:512, 64:1), %35 : Float(17:6656, 13:512, 512:1) = prim::TupleUnpack(%1760)
  %36 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%11, %12, %13, %14)
  %37 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%15, %16, %17, %18)
  %38 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%19, %20, %21, %22)
  %39 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%23, %24, %25, %26)
  %40 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%27, %28, %29, %30)
  %41 : (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)) = prim::TupleConstruct(%31, %32, %33, %34)
  %42 : ((Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1))) = prim::TupleConstruct(%36, %37, %38, %39, %40, %41)
  %43 : (Float(17:6656, 13:512, 512:1), ((Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1)), (Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1), Float(17:6656, 8:64, 13:512, 64:1))), Float(17:6656, 13:512, 512:1)) = prim::TupleConstruct(%35, %42, %kv)
  return (%43)
